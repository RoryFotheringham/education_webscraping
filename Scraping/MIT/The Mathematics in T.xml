<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/</course_url>
    <course_title>The Mathematics in Toys and Games</course_title>
    <course_tags>
      <list>Engineering </list>
      <list>Computer Science </list>
      <list>Mathematics </list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>Rubik&#8217;s Cube and group theory</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses6_rubiks/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>15</slideno>
          <text>The Mathematics of the Rubiks Cube
By rst performing F and then reversing this action with f after the macro is 
performed, we ensure that only the top row pieces are aected. We can use our permutation notation to describe what this macro does. First look at g 
before conjugation. corner is of the form (12)(34), since it switches the top 
back corners and the upper right corners. edge is of the form (123), since it 
3-cycles the edge pieces FR, UR, and UB. Then for the conjugated macro, 
corner has the form (12)(34), since it switches two pairs of corners: the top 
front and the top back. edge is of the form (123), since it leaves one edge 
piece in place and 3-cycles the other 3 edge pieces. So the original macro and 
its conjugate have the same cycle structures. The only dierence between a macro and its conjugate are the actual pieces involved in the cycles. Once 
you nd a sequence of moves that performs the operation you want, e.g., 
cycling 3 pieces, ipping pieces, etc., than you can apply it to the desired 
pieces by conjugating it with the appropriate cube move. 
Solving the Cube 
The Screwdriver Method 
We wont be going over this one in class, and in fact you should never need 
it again. It involves turning one face 45 degrees, prying out the edge piece sticking out, and disassembling the cube using a screwdriver. Not much math 
here so well move on. 
The Bottom up method 
This is one of the most intuitive, but probably one of the slowest, ways to 
solve the cube. It averages about 100 moves per solution. 
1st Layer 
This rst layer must be done by inspection. There is usually no set algorithm 
to follow. It is helpful to focus on getting a cross rst with the edge pieces 
correctly in place, and then solving the corners one by one. 
16 ES.268</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>The Mathematics of the Rubiks Cube
cycle back to its original conguration. 
Cayley Graphs 
A useful way to gain insight into the structure of groups and subgroups is 
the Cayley graph . The following properties describe a Cayley graph of a 
group G: 
	Each g  G is a vertex. 
	Each group generator s  S is assigned a color cs. 
	For any g  G, s  S, the elements corresponding to g and gsare joined 
by a directed edge of color cs. 
Drawing the Cayley graph for R would be ridiculous. If would have 43 tril
lion vertices! Instead, well look at some Cayley graphs of small subgroups 
of R. 
The following is the Cayley graph for the subgroup generated by F: 
The moves  = FF and  = RR generate the following graph (note that 
2 = 2 = 1): 
12 Image by Tom Davis. Used with permission. 
Image by Tom Davis. Used with permission. ES.268</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>The M athematics of the Rubiks Cube
What happens when we try to draw the graph for U? Or RRBB ? They 
will have the same Cayley graphs as those shown above, respectively. If two 
groups have the same Cayley graph, they have essentially the same structure, 
and are called isomorphic . Two isomorphic groups will have the same 
order and same eect on the cube. For instance, performing FFRR has the 
same eect as rotating the cube so that the L face is now in front and then 
performing RRBB . 
Macros 
We rst dene some properties of cube group elements, and then use these properties and what we learned above to develop some macros  or combina
ti 
ons of cube moves that will help us accomplish specic cubie rearrangements 
that will enable us to solve the cube. 
Commutator 
The move sequence operations on a Rubiks cube are pretty obviously not 
commutative. For example, rotate the front face ( F), then rotate the right 
face (R ) to make a move FR. This is clearly not the same as rotating the 
right face followed by the front face, or RF. One useful tool to describe 
the relative commutativity of a sequence of operations is the commutator , 
PMP1M1, denoted [P.M ], where P and M are two cube moves. If P and 
M are commutative, then their commutator is the identity, since the terms 
can be rearranged so that P cancels P1 and same with M. 
Let the support of an operator be all the cubies changed by it. Then two op
erations are commutative if either they are the same operation or if supp(P) supp(M) = , that is, if each move aects completely dierent sets of cubies. 
If the commutator is not the identity, then we can measure the relative commutativity by the number of cubies changed by applying the commuta
tor. Looking at the intersection of the supports of the two operations gives 
insight into this measure. Useful pairs of moves have only a small number of 
cubies changed in common, and you will see macros involving commutators come up again and again. 
13 ES.268</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>The Mathematics of the Rubiks Cube
2nd Layer 
Now rotate the bottom (solved) layer so that its edges on the other faces are 
paired with the correct center pieces. Your cube should look as follows: 
For this layer we only have to solve the four middle layer edge pieces. If an 
edge piece is in the top layer, use the following macros: 
URurFrfR
ulULfLFl 
17 ES.268</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>The Mathematics of the Rubiks Cube
If an edge pieces is not in the top layer, but is not oriented correctly, use the 
following to put the piece in the top layer and then proceed as above: 
URurFrfR 
The second layer should now be solved. 
3rd Layer 
We will do this layer in 3 steps: 
1. Flip the edges to form a cross on the top: To ip a top layer edge 
correctly, use this macro: 
FRUrufU
Repeat until all the edge pieces form a cross on the top:
18 ES.268</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>The M athematics of the Rubiks Cube
Cube Moves as Group Elements 
We can conveniently represent cube permutations as group elements. We 
will call the group of permutations R, for Rubik (not to be confused with 
the symbol for real numbers). 
The Binary Operator for the Rubik Group 
Our binary operator, *, will be a concatenation of sequences of cube moves, or 
rotations of a face of the cube. We will almost always omit the * symbol, and interpret fg as f  g. This operation is clearly closed, since any face rotation 
still leaves us with a permutation of the cube, which is in R. Rotations 
are also associative: it does not matter how we group them, as long as the 
order in which operations are performed is conserved. The identity element 
e corresponds to not changing the cube at all. 
Inverses 
The inverse of a group element g is usually written as g 
1 . We saw above 
that if g and h are two elements of a group, then (hg )1 = g1h1 . If we 
think of multiplying something by a group element as an operation on that 
thing, then the reversed order of the elements in the inverse should make 
sense. Think of putting on your shoes and socks: to put them on, you put on your socks rst, then your shoes. But to take them o you must reverse 
the process. 
Let F be the cube move that rotates the front face clockwise. Then f, 
the inverse of F, moves the front face counterclockwise. Suppose there is 
a sequence of moves, say FR, then the inverse of FR is rf: to invert the 
operations they must be done in reverse order. So the inverse of an element 
essentially undoes it. 
Permutations 
The dierent move sequences of cube elements can be viewed as permutations, or rearrangements, of the cubies. Note move sequences that return 
5 ES.268</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>The M athematics of the Rubiks Cube
the same cube conguration are seen to be the same element of the group of 
permutations. So every move can be written as a permutation. For example, the move FFRR is the same as the permutation (DF UF)(DR UR)(BR FR 
FL)(DBR UFR DFL)(ULF URB DRF). 
It is easier to discuss these permutations rst using numbers. An example of 
a permutation written in canonical  cycle notation  is: 
(1
)(234) 
This means that 1 stays in place, and elements 2, 3, and 4 are cycled. For
example, 2 goes to 3, 3 goes to 4, and 4 goes to 2. (234)  (423).
The steps in writing down combinations of permutations in canonical cycle
notation are as follows:
1. Find the smallest item in the list, and begin a cycle with it. In this example, we start with 1. 
2. Complete the rst cycle by following the movements of the objects 
through the permutation. Do this until you close the cycle. For in
stance, in (1 2 4)(3 5) * (6 1 2)(3 4), we start with 1. 1 moves to 2 in the rst permutation, and 2 moves to 6 in the second, so 1 moves to 6. 
Following 6 shows that it moves back to 1, so 6 and 1 form one 2-cycle. 
3. If you have used up all the numbers, you are done. If not, return to step 1 to start a new cycle with the smallest unused element. Continuing in 
this manner gives (1 6)(2 3 5 4). 
If P consists of multiple cycles of varying length, then the order of that 
permutation is n, since applying P n times returns the beginning state. If P 
consists of multiple cycles of varying length, then the order is the least com
mon multiple of the lengths of the cycles, since that number of cycle steps 
will return both chains to their starting states. Below are several examples: 
(1 2 3)(2 3 1) = (1 3 2) order 3 
(2 3)(4 5 6)(3 4 5) = (2 4 3)(5 6) order 6 
(1 2) order 2 
6 ES.268</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>The M athematics of the Rubiks Cube
An equivalence class c(x), x  G is the set of all y  G : y  x. We can 
partition G into disjoint equivalence classes, or conjugacy classes . 
We will not give a formal proof here, but two permutation elements of R 
are conjugates if they have the same cycle structure. The following example 
should make this more clear. 
In solving a cube, one straightforward approach is to solve it layer by layer. 
Once you get to the third layer, some of the edge pieces might be ipped the 
wrong way, as in the following picture: 
We want to ip these pieces correctly, but leave the bottom two layers in
tact. We can use conjugation to do so. Consider the move consisting of the
commutator g = RUru . Applying g to the cube has the eect shown below:
You can see that 7 cubes are aected, 2 of which are not in the top layer, but are instead in the R layer. We can x this by performing a rotation before 
we use the macro that will put top layer cubies in all the positions aected by the macro, so that only top layer cubies are rearranged. 
Now take the conjugate of g by F to get the move FRUruf: 
15 ES.268</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>The M athematics of the Rubiks Cube
essentially equivalent. After n moves the cube has an even number of cubies 
exchanged. Since the n + 1 move will be a face turn, there will be an even 
number of cubies ipped. There was already an even number exchanged, and 
so an even parity of cubie exchanges is preserved overall . 
Since any permutation of the Rubiks cube has even parity, there is no move 
that will exchange a single pair of cubies. This means that when two cubies are exchanged, we know there must be other cubies exchanged as well. We 
will get around this problem by using 3-cycles that will cycle 3 cubies, in
cluding the two that we want to exchange. 
When talking about the cycle structure of cube moves, the following no
tation will be helpful: 
 
corner describes the cycle structure of the corner cubies 
 edge describes the cycle structure of the edge cubies 
There might come a time when we want to focus rst on orienting all the 
edge pieces correctly, and dont care about the corners. In this case, we can 
deal only with corner and ignore whatever happens to the edge pieces. It is 
helpful to separate the two. Also note that any cycles in corner can never 
contain any cubies that are also involved in edge since an cubie cannot be 
both an edge and a corner. We never talk about center  since the center of 
the cube is xed. 
Subgroups 
Given a group R, if S  R is any subset of the group, then the subroup H 
generated  by S is the smallest subroup of R t hat contains all the elements 
of S. For instance, {F}generates a group that is a subgroup of R consisting 
of all possible dierent cube permutations you can get to by rotating the 
front face, {F, F2, F3 F4}. The group generated by {F, B, U, L, R, D }is the 
whole group R. Below are some examples of some generators of subroups of 
R: 
 Any single face rotation, e.g., {F} 
 Any two opposite face rotations, e.g., {LR} 
8 ES.268</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>The Mathematics of the Rubiks Cube
	The operation * is associative, so for any elements f, g, and h, (f  g) 
h = f  (g h). 
	There is an identity element e  G such that e  g = g e = g. 
	Every element in G has an inverse g1 relative to the operation * such 
that g g1 = g1  g = e. 
Note that one of the requirements is not commutativity, and it will soon 
b
ecome clear why this is not included. 
Theorems About Groups 
Keep in mind the following basic theorems about groups: 
	The identity element, e, is unique. 
	If a  b = e, then a = b1 
	If a  x = b x, then a = b 
	The inverse of ( ab) is b1a1 
	(a 1)1 = e 
Examples of Groups 
The following are some of the many examples of groups you probably use 
everyday: 
	The integers form a group under addition. The identity lement is 0, 
and the inverse of any integer a is its negative, a. 
	The nonzero rational numbers form a group under multiplication. The identity element is 1, and the inverse of any x is 
x 1 . 
	The set of n n non-singular matrices form a group under multiplica
tion. This is an example of a non-commutative group, or non-abelian  
gr
oup, as will be the Rubik group. 
4 ES.268</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>The Mat hematics of the Rubiks Cube
Lagranges Theorem 
Try repeating the move FFRR on a solved cube until you get back to the 
starting position. How many times did you repeat it?(hopefully 6) No matter 
what, that number, the size of the subgroup generated by FFRR, must be a 
divisor of (8!38 12!212) . Lagranges Theorem tells us why. (322) 
Before we prove Lagranges Theorem, we dene a coset and note some 
properties of cosets. If G is a group and H is a subgroup of G, then for 
an element g of G: 
 gH = {gh : h  H}is a left coset of H in G. 
 Hg = {gh : h  H}is a right coset of H in G. 
So for instance if H is the subgroup of R generated by F, then one right 
coset is shown below: 
Lemma: If H is a nite subgroup of a group G and H contains n elements 
then any right coset of H contains n elements. 
Proof: For any element g of G, Hg = {hg|h  H} denes the right coset. 
There is one element in the coset for every hinH, so the coset has n elements. 
Lemma: Two right cosets of a subgoup H in a group G are either iden
tical or disjoint. 
Proof: Suppose Hx and Hy have an element in common. Then for some 
h1 and h2: 
h1x = h2y 
h1 h1Then x = 1 h2y, and some h3 = 1 h2 gives x = h3y. So every element of 
Hx can be written as an element of Hy: 
hx = hh3y 
10 ES.268</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>The Mat hematics of the Rubiks Cube
The same notation will be used to refer to face rotations. For example, F 
means to rotate the front face 90 degrees clockwise. A counterclockwise ro
tation is denoted by lowercase letters (f) or by adding a  (F). A 180 degree 
turn is denoted by adding a superscript 2 (F2), or just the move followed by 
a 2 (F2). 
To refer to an individual cubie or a face of a cubie, we use one letter for 
the center cubies, two letters for the edge cubies, and three letters for the 
corner cubies, which give the faces of the cube that the cubie is part of. The rst of the three letters gives the side of the cubie we are referring to. For 
example, in the picture below, the red square is at FUR, yellow at RUF, blue 
at URF, and green at ULB: 
Bounds on Solving a Rubiks Cube 
The number of possible permutations of the squares on a Rubiks cube seems 
daunting. There are 8 corner pieces that can be arranged in 8! ways, each 
of which can be arranged in 3 orientations, giving 38 possibilities for each 
permutation of the corner pieces. There are 12 edge pieces which can be arranged in 12! ways. Each edge piece has 2 possible orientations, so each permutation of edge pieces has 2
12 arrangements. But in the Rubiks cube, 
only 1
3 of the permutations have the rotations of the corner cubies correct. 
Only 1
2 of the permutations have the same edge-ipping orientation as the 
original cube, and only 1
2 of these have the correct cubie-rearrangement par
ity, which will be discussed later. This gives: 
(8! 38  12! 212) = 4.3252 1019 
(3 2 2) 
2 ES.268</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>The Mathematics of the Rubiks Cube
A useful theorem about commutators that we will not prove but will make 
use of is the following: 
If supp( g)supp(h ) consists of a single cubie, then [ g, h] is a 3-cycle. 
Below are some usefull building blocks for commutators that can be used 
to build macros: 
	FUDLLUUDDRU ips exactly one edge cubie on the top face 
	rDRFDf twists one cubie on a face 
	FF swaps a par of edges in a slice 
	rDR cycles three corners 
Conjugation 
Let M be some macro that performs a cube operation, say a three-cycle of 
edge pieces. Then we say for some cube move P, PMP1 is the conjuga
tion  of M b y P. Conjugating a group element is another very useful tool 
that will help us describe and build useful macros. 
First we will introduce a couple useful denitions: An equivalence  relation 
is 
any relation  between elements that are: 
	Reexive: x  x 
	Symmetric: If x  y then y  x 
	Transitive: If x  y and y  z then x  z 
We will let the relation  be conjugacy. So if for some g  G, x  y, then 
gxg1 = y Here we prove that conjugacy is an equivalence relation: 
	Reexive: gxg1 = x if g = 1, so x  x 
	Symmetric: If x  y, then gxg1 = y, so multiplying each side by g on 
the right and g1 on the left gives x = g1yg 
	Transitive: If x  y and y  z, then y = gxg1 and z = hyh1, so 
z = hgxg1h1 = (hg )x(hg)1, so x  z 
14 ES.268</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>The M athematics of the Rubiks Cube
possible arrangements of the Rubiks cube. 
It is not completely known how to nd the minimum distance between two 
arrangements of the cube. Of particular interest is the minimum number of 
moves from any permutation of the cubes cubies back to the initial solved 
state. 
Another important question is the worst possible jumbling of the cube, that 
is, the arrangement requiring the maximum number of minimum steps back 
to the solved state. This number is referred to as Gods number, and has 
been shown (only as recently as August 12 this year) to be as low as 22.1 
The lower bound on Gods number is known. Since the rst twist of a face 
can happen 12 ways (there are 6 faces, each of which can be rotated in 2 
possible directions), and the move after that can twist another face in 11 
ways (since one of the 12 undoes the rst move), we can nd bounds on the worst possible number of moves away from the start state with the following 
pidgeonhole inequality (number of possible outcomes of rearranging must 
be greater than or equal to the number of permutations of the cube): 
12 11
n1  4.3252 1019 
which is solved by n  19. 
The solution mathod we will use in class wont ever go over 100 moves or so, but the fastest speedcubers use about 60. 
Groups 
Denition 
By denition, a group G consists of a set of objects and a binary operator, 
*, 
on those objects satisfying the following four conditions: 
	The operation * is closed, so for any group elements h and g in G, h g
is also in G.
1Rokicki, Tom. Twenty-Two Moves Suce. http://cubezzz.homelinux.org/drupal/?q=node/view/121. 
August 12, 2008. 
3 ES.268</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>The Mathematics of the Rubiks Cube
Parity 
Permutations can also be described in terms of their parity. Any length n 
cycle of a permutation can be expressed as the product of 2-cycles.2 To 
convince yourself that this is true, look at the following examples: 
(1 2) = (1 2) 
(1 2 3) = (1 2)(1 3) 
(1 2 3 4) = (1 2)(1 3)(1 4) 
(1 2 3 4 5) = (1 2)(1 3)(1 4)(1 5) 
The pattern continues for any length cycle. 
The the parity of a length n cycle is given by the number 2 cycles it is 
composed of. If n is even, an odd number of 2-cycles is required, and the 
permutation is odd, and vise versa. So odd permutations end up exchanging 
an odd number of cubies, and even ones an even number. 
Now we will prove an important fact about cube parity that will help us 
solve the cube later: 
Theorem: The cube always has even parity, or an even number of cubies 
exchanged from the starting position. 
Proof (by induction on the number of face rotations, n): 
Base Case: After n = 0 moves on an unsolved cube, there are no cubies 
exchanged, and 0 is even. Let P(n) : after n rotations, there are an even number of cubies exchanged. 
We assume P(n) to show P(n) P(n + 1). Any sequence of moves is com
posed of single face turns. As an example of the permutation created by a 
face turn, look at the move F = (FL FU FR FD)(FUL FUR FDR FDL) 
= (FL FU)(FL FR)(FL FD)(FUL FUR)(FUL FDR)(FUL FDL). Since each of the length 4 chains in this permutation can be written as 3 2-cycles for a total of 6 2-cycles, the parity of the face turn is even. This fact applies to any 
face turn, since all face turns, no matter which face they are applied to, are 
2for proof see Davis, Tom. Permutation Groups and Rubiks Cube. May 6, 2000. 
7 ES.268</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>The Mathematics of the Rubiks Cube
4. Position the top layer corners correctly: Now the top layer should have 
all the same color faces, but the corners might not be oriented correctly. 
Position one corner correctly, and then determine whether the others are solved, need to be rotated clockwise, or need to rotated counter
clockwise, and then apply the following (let x = rD
2R): 
xU2xuxux 
xUxUxU2x 
You should end with a solved cube! 
Other Methods 
The above solution is by no means the only one. Some oter popular methods 
include: 
	CFOP: Cross, First two layers, Orient last layer, Permute last layer. Invented in the 1980s by Jessica Fridrich. 
	Petrus Method: solve a 2 by 2 by 2 block rst, expand this to 2 by 2 by 3, x the improperly oriented edges on the outside layer, and then solve the rest. 
20 ES.268</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>The Mathematics of the Rubiks Cube 
Introduction to Group Theory and Permutation Puzzles 
March 17, 2009 
Introduction 
Almost everyone has tried to solve a Rubiks cube. The rst attempt often 
ends in vain with only a jumbled mess of colored cubies (as I will call one 
small cube in the bigger Rubiks cube) in no coherent order. Solving the cube 
becomes almost trivial once a certain core set of algorithms, called macros, are learned. Using basic group theory, the reason these solutions are not 
incredibly dicult to nd will become clear. 
Notation 
Throughout this discussion, we will use the following notation to refer to the 
sides of the cube: 
Front F 
 Right R 
Down D Up U 
Left L Back B 
1</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>The M athematics of the Rubiks Cube
for every h in H. So if Hx and Hy have any element in common, then every 
element of Hx is in Hy, and a similar argument shows the opposite. There
fore, if they have any one element in common, they have every element in 
common and are identical . 
We now can say that the right cosets of a group partition  the group, or 
di
vide it into disjoint sets, and that each of these partitions contains the 
same number of elements. 
Lagranges Theorem: the size of any group H  G must be a divisor of 
the size of G. So m|H|= |G|for some m  1  N+ . 
Proof: The right cosets of H in G partition G. Suppose there are m cosets 
of H in G. Each one is the size of the number of elements in H, or |H|. G is 
just the sum of all the cosets: G = h1G+h2G+ . . . +hnG, so its size is the 
sum of the sizes of all the cosets. So we can write |G|= m|H|. 
Below is a list3 of some group generators and their sizes, all factors of the 
size of R: 
Generators 
U 
U, RR 
U, R RRLL, UUDD, FFBB 
Rl, Ud, Fb 
RL, UD, FB 
FF, RR 
FF, RR, LL FF, BB, RR, LL, UU 
LLUU 
LLUU, RRUU LLUU, FFUU, RRUU 
LLUU, FFUU, RRUU, BBUU 
LUlu, RUru Size 4 
14400 
73483200 8 
768 
6144 
12 
96 663552 
6 
48 82944 
331776 
486 Factorization 2
2 
26  32  52 
26  38  52 
23 
28  3 
211  3 
2 32 
25  3 
213  34 
2 3 
24  3 
210  34 
212 34 
2 35 
Most of the moves we use will generate relatively small subgroups. Play around with some of the smaller size subgroups above and watch the cube 
3Davis, Tom Group Theory vi a Rubiks Cube  
11 Image by Tom Davis. Used with permission. ES.268</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>The Mathematics of the Rubiks Cube
2. Position the top layer edges correctly: Now position the top layer so 
that one of the edges is solved. If all the edges are solved, move on to the next step. If not, use the following algorithms to permute the 
edges correctly: 
RU2ruRur 
RUrURU2r 
If none of these work, apply one of them until you get to a position 
where one of these will work, then proceed. 
3. Flip the top layer corners: For each corner that does not have the correct color on the top layer, position it at UBR and perform RDrd repreatedly until it is oriented with the correct color on top. Then, 
without rotating the cube, position the next unsolved corner at UBR 
and repeat the process. The bottom two layers will appear to be a 
mess, but they will be correct once all the four corners are facing the 
correct direction. 
19 ES.268</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>The M athematics of the Rubiks Cube
 The two moves {RF}. 
We dene the order of an element g as the number m, such that gm = e, the 
identity. The order of an element is also the size of the subgroup it generates. 
So we can use the notion of order to describe cube move sequences in terms 
of how many times you have to repeat a particular move before returning to 
the identity. For example, the move F generates a subgroup of order 4, since 
rotating a face 4 times returns to the original state. The move FF generates 
a subroup of order 2, since repeating this move twice returns to the original state. Similarly, any sequence of moves forms a generator of a subgroup that 
has a certain nite order. 
Since the cube can only achieve a nite number of arragnements, and each 
move jumbles the facelets, eventually at least some arrangements will start 
repeating. Thus we can prove that if the cube starts at the solved state, then 
applying one move over and over again will eventually recyle to the solved state again after a certain number of moves. 
Theorem: If the cube starts at the solved state, and one move sequence P 
is performed successively, then eventually the cube will return to its solved 
state. 
Proof: Let P be any cube move sequence. Then at some number of times m 
that P is applied, it recycles to the same arrangement k, where k &lt; m and 
m m is the soonest an arrangement appears for the second time. So Pk = P. 
Thus if we show that k must be 0, we have proved that the cube cycles back 
to P0, the solved state. 
mIf k = 0, then we are done, since P0 = 1 = P. Now we prove by con
tradiction that k must  be 0. If k&gt; 0 : if we apply P1 to both Pk and Pm 
mwe get the same thing, since both arrangements Pk and Pare the same. 
Then PkP1 = PmPm1  Pk1 = Pm1 . But this is contradictory, since 
we said that m is the rst time that arrangements repeat, so therefore k must 
equal 0 and every move sequence eventually cycles through the initial state 
again rst before repeating other arrangements. 
9 ES.268</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Dynamic programming with impartial games</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses3_dynamic/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>First-player win: SYMMETRY STRATEGY  
	move to split  into two equal halves (1 pin if odd, 2 if even) 
	whatever opponen t does, do same in other half
(Kn + Kn = 0 . . . just like Nim)
Impartial game, so Sprague-Grund y Theory says Kayles  Nim somehow 
	follo
wers(K n) = {Ki + Kni1, Ki + Kni2 | i = 0, 1, . . . , n  2} 
 nimber( Kn) = mex{nimber(K i + Kni1 ),
nimber(K i + Kni2 )
| i = 0, 1, . . . , n  2}
 nimber(x  +  y) = nimber( x)  nimber(y ) 

 nimber( Kn) = mex{nimber(K i)  nimber(K ni1 ),
nimber(K i)  nimber(K ni2 )
| i = 0, 1, . . . n  2}
RECURRENCE!  write what  y ou want in terms of smaller things 
How do w e compute it? 
nimber(K 0) = 0 (BASE CASE) 
nimber(K 1) = mex{nimber(K 0)  nimber( K0)}
0 0=0 
= 1  
nimb
er(K 2) = mex{nimber(K 0)  nimber( K1),
0 1=1

nimber( K0)  nimber( K0)}
0 0=0 
= 2  
so e.g. K2 + 2 = 0 2nd  player win  
nimber(K 3) = mex{nimber(K 0)  nimber( K2),
0 2=2

nimber( K0)  nimber( K1), 
0 1=1
nimber( K1)  nimber( K1)}
1 1=0 
= 3  
2</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>nimber(K 4) = mex{nimber(K 0)  nimber( K3),
0 3=3

nimber( K0)  nimber( K2), 
0 2=2
nimber( K1)  nimber( K2), 
1 2=3
nimber( K1)  nimber( K1)}
1 1=0 
= 1  
In general :
 if we compute  nimber(K 0), nimber(K 1), nimber(K 2), . . . in order, 
then we always use nimbers that weve already computed (because smaller) 
 in Python, can do  this with for loop: 
k =	 960  4 972  4 984  4 {}
for n in  range(0, 1000): 961  1 973  1 985  1 
k[n] = mex ([k[i]  k[n - i - 1] for i in range(n)] + 962  2 974  2 986  2 
[k[i]  k[n - i - 2] for i in range(n - 1)]) 963  8 975  8 987  8 
print n, -, k[ ]	 964  1 976  1 988  1 
965  4 977  4 989  4 
def mex(nimbers): 966  7 978  7 990  7 
nimbers = set(nimbers) 967  2 979  2 991  2 n = 0 968  1 980  1 992  1 while n in nimbers: 969  8 981  8 993  8 n = n + 1 970  2 982  2 994  2return n 971  7 983  7 995  7 
periodic mod  12! 
(starting at 72) 
[Guy
 &amp; Smith  1972]  
DYNAMIC PROGRAMMING  
How fast?  to compute nim ber(K n): 
 look up   4n previous nimb ers 
 compute  2 n nimsums (XOR)  
 compute one mex  on  2n nimbers  
 call
 all this O( n) w ork order n  
 need to do thi s for n = 0, 1, . . . , m 
m	 m m(m +  1) O(n) = O n = O	 = O(n 2) 	2 n=0 n=0 
POLYNOMIAL TIME  GOOD 
3</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>, ,
 Lecture 3 Feb 16, 2010 
Playing Games with Algorithms: 
	most games are hard to  play well: 
	Chess is EXPTIME-complete: 
	n
  n board, arbitrary position 

	need exponential (cn) time to nd a winning move (if there is one) 
	also: as hard as all games  (problems) that need exponen tial time 
	Checkers is EXPTIME-complete: 
Chess  &amp;
 Checkers are the same computationally: solving one  
solves  the other 
(PSP A
CE-complete if draw after  poly. moves) 
	Shogi (Japanese chess)  is  EXPTIME-complete 
	Japanese Go is EXPTIME-comp lete  
	U. S. Go might b e harder 
	Othello is PSPA CE-complete:  
	conjecture requires exponen tial  time, but not sure (implied by 
P = NP) 
	can solve some games fast: in  polynomial time (mostly 1D) 
Kayles: 
[Dudeney 1908] 
(n bowling pins) 
 move = hit one or  two adjacent pins 
 last player to move  wins (normal play) 
Lets play!
1
http://erikdemaine.org/papers/AlgGameTheory_GONC3ES.268</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Variations: dynamic programming also  works for: 
	Kayles on a  cycle 
(1 move reduces to regular Kayles 2nd player win)  
	Kayles on a  tree: target vertex or 2 adj. vertices 
	Kayles with v arious ball sizes: hit 1 or 2 or 3 pins
(still 1st player win)
Cram: impartial Domineering  

	board = m   n rectangle, possibly  with holes 
	move = place  a domino (make 1  2 hole) 
Symmetry strategies :
 [Gardner  1986] 

	even  ev en:  reect in  both axes
1st player win
 
	even   o dd:  play 2  center s then reect in both axes 
1st player win  
	odd  o dd: OPEN who  wins?
Liner Cram
 = 1  n cram
	easy
 with dynamic programming  
	also periodic [Guy  &amp; Smith 1956] 
 1  3  blocks still easy  with DP

OPEN : periodic? 
Horizon tal
 Cram:
 1 only
sum of linear
 crams!

2  n
 Cram: Nimb ers
OPEN Lets play! 
3  n Cram: winner OPEN  
(dynamic programming doesnt  work) 
4</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Probability topics and Monopoly</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses7_prob/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>13</slideno>
          <text>Monopoly
 
Example 6 
Find the eigenvalues and eigenvectors of A = 1 2 .2 4 
1 2A  I = 2 4 
Take the determinant of this matrix. 
1 2det = (1  )(4  )  (2)(2) = 2  5.2 4 
Set the determinant to 0, and solve for . 
2  5 = 0 gives 1 = 0 and 2 = 5. 
Solve (A  I)x = 0 separately for 1 = 0 and 2 = 5. 
1 2 x1 0 2(A  0I) = 2 4 x2 = 0 gives eigenvector 1 
1 2 x1 0 1(A  5I) = x2 = gives eigenvector 2 4 0 2 
As a side note, because the vectors that make up A are constant multiples of 
each other, we know that A itself is a singular matrix. The determinant of 
a matrix can be found by taking the product of all its eigenvalues, so if the 
determinant is zero, then we know one of the eigenvalues must be zero. 
Markov Chains 
Markov chains are the probabilistic versions of deterministic nite automata. 
For our  , analysis of MONOPOLY Rwell consider each of the 40 game 
squares to be a state H. At each time step n, the probabilistic state dis
tribution Xn will be a 40  1 vector, with each element representing the 
14 ES.268</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Monopoly
 
Number on the two dice Probability 
7 6 
36 
6, 8 5 
36 
5, 9 4 
36 
4, 10 3 
36 
3, 11 21 
36 
2, 12 1 
36 
The initial position probability vector, H0, is a 40-dimensional-vector with 
1 as the 0th element and 0 everywhere else. If we index the board from 0 
through 39, beginning at Go, then after the rst turn, the vector of position 
probabilties H1 would be: 
1 2 3 4 5 6 5 4 3 2 1 [0, 0, , , , , , , , , , , , 0, 0, 0,..., 0] . 36 36 36 36 36 36 36 36 36 36 36    
27 zeros 
The 1st column of our 40  40 Markov transition matrix M would be H1. 
The second column of the matrix would be this vector with 3 zeros before 
the beginning of the fractions and 27 zeros after, in essence, the same vector 
shifted over by 1. The third row would be shifted over again, so on until 
weve completed all 40 rows of the matrix. 
To get our state probability vector after moving n times, we would just 
calculate AnH0. For suciently large n, our state probability vector would 
be the eigenvector of A that corresponds to eigenvalue 1. The eigenvector 
for the simple model of Monopoly has all entries equal to 1, because the 
transition from any square on the board is the same. 
The Real Game 
We made a few simplifying assumptions in the last section: tossing doubles, 
the Go to Jail square, and Chance/Community Chest cards. 
To deal with the rule about tossing doubles, we can modify the initial vector 
and the transition matrix. The maximum number of spaces a player can 
17 ES.268</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Monopoly
 
	 The
 empty set , or a set with no elements, is a proper subset of every 
set. 
	 A proper subset is a set that is strictly contained in another set. 
That is, A is a proper subset of S if and only if there is at least one 
element contained in S that is not contained in A, and all elements of 
A are contained in S. 
The cardinality of a set, denoted |A| here, is the number of elements in that 
set. If A  S, then |A||S|. If A  S, then |A| &lt; |S|. 
Probability and Sets 
Now that we have dened sets generally, lets look at how sets are used when 
applied to probability. The things or items that were concerned with are 
outcomesoutcomes from ipping coins, dealing hands or cards, etc. The 
sample space is the set of all possible outcomes, denoted . A subset of a 
sample space consists of the outcomes that were interested in, called events. 
Suppose we have the events A, B, and C. The interesction of two events 
is the event that they both occur. C = A  B if the event C represents both 
A and B occuring. If A  S = , then the two sets are called disjoint or 
mutually exclusive . The union of two events is the event that either one 
or the other occurs, denoted C = A  B. 
Laws of set operations: 
	 Commutative: 
A  B = B  A 
A  B = B  A 
	 Associative: 
(A  B)  C = A  (B  C) 
(A  B)  C = A  (B  C) 
2 ES.268</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Monopoly
 
of
 the 353 days not taken, and the corresponding probability of such an 
event is 363 . This continues until weve covered all n people. 365 
365  364  363  (365  n + 1) P (Ac) = 365n 
P (A) = 1  P (Ac) 
365! = 1  365n  n! 
b) What is the probability that someone shares your birthday? 
Each person can have your birthday with probability 1 . There are n  1365 
people besides you, so the probability that someone shares your birthday 
n1is .365 
The answers to part a) and part b) are quite dierent, but the way the ques
tions were phrased were only slightly dierent. Half the work in probability 
questions is usually guring out what the question wants from you... 
What happens if n&gt; 365? You can answer part a) without doing any math, 
by the Pigeonhole Principle. The Pigeonhole Principle states that in a 
mapping from set X to set Y , if |X| &gt; |Y |, then more than one element of 
X map to some element in Y . 
Combinations 
We will also want to deal with collections that are unordered. How many 
ways are there to take r objects out of a set of n objects? 
For the rst object, we have n to choose from. For the 2nd object, we have 
n  1 to choose from. For the rth object, we have n  r + 1 to choose from. 
But note that once weve selected r objects this way, they are in some kind 
of order, and the answer n(n  1)(n  2)  (n  r +1) = n! is not correct. (nr )! 
We must divide by r!, which is the number of ways you can order (permute) 
r objects. 
7 ES.268</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Monopoly
 

 32 houses 
 12 hotels 
 16 Chance cards 
 16 Community Chest cards 
 property deeds for each of the 22 MONOPOLY R properties 
 $15140 in MONOPOLY R money 
The Chance and Community Chest cards are placed face down on the game 
board, and a player must pick one of the cards when he lands on the Chance 
or the Community Chest game squares. Each player is given $1500 to be
gin the game. All remaining money, game piece, houses, hotels, and deeds 
of unsold property go to the Bank. The Bank collects all taxes, nes, 
loans, and interest. The Bank never goes broke. If the Bank runs out 
of MONOPOLY R money, then more can be issued (see fun fact above). 
Players begin on the Go square, roll two dice, and advance as many steps as 
dots displayed on the the two dice. A player can buy any property, utility, 
or railroad that isnt already owned by another player, or must to draw 
Chance/Community Chest cards, pay rent, nes, or go to Jail as dictated 
by the square he lands on. If a player throws a double, then he moves his 
token the number of steps, is subject to whatever privileges or penalties of 
the square he lands on, and then tosses the dice again. If a player tosses 
three doubles in a single turn, he must go to Jail. 
Landing on the Jail square is just visiting Jail, while landing on the Go to 
Jail square, drawing a Go to Jail card, and tossing doubles 3 times during 
a turn are actual Jail sentences. Any Jail term lasts 3 turns. A player tosses 
dice at each turn, and if he tosses a double, then he is free to get out of jail 
and advances the number of steps as his double shows. That player does not 
take another turn. A player gets out of Jail if he has a Get out of Jail Free 
card, or if another player is willing to sell him a Get out of Jail Free card 
at a negotiated price, or if the player pays a $50 ne. 
12 ES.268</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Monopoly
 
12there are are 3 ways to choose 3 dierent values besides the value 
thats already a pair, and they can be from any suit. 
# of ways to deal a hand with only 1 pair = 13 4 12 43 = 1098240 2 3 
e) How many ways are there to deal a 3-of-a-kind? 
There are 13 ways to choose the card value of the 3-of-a-kind, and 4 
1  3 48ways to choose the suits of the pair; then there are 2 ways to choose 
the remaining 2 cards of the 5-card hand, making sure that the value of 
the 3-of-a-kind doesnt get chosen (otherwise wed get a 4-of-a-kind). 
4 48 # of ways to deal a 3-of-a-kind = 13 = 58656 3 2 
f) How many ways are there to deal a full house, a 5-card hand with 3 of 
one kind and 2 of another? 
As before, there are 13 ways to choose the card value of the 3-of-a 1 
kind, and 4 ways to choose the suits of the pair. Then there are 12 
3  1 
ways to choose the value of the 2-of-a-kind and 4
2 ways to choose the 
suit. 
4 12 4 # of ways to deal a full house = 13 = 3744 3 1 2 
Conditional Probability 
If were interested in the probability that some event A occurs given that 
some event B has already occurred, the sample space becomes B. The prob
ability of A conditioned on B becomes a probability on the space B. 
The Multiplication Law states that P (A  B) = P (A|B )P (B). 
9 ES.268</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Monopoly
 
mo
ve is 35, (if a player rolls a {(6,6),(6,6),(6,5)}). If a player lands on Go 
to Jail, then he would go immediately to Jail and end his turn there. If a 
player rolls three doubles in row, then he would also have to go to jail. 
The transition at each turn would be a vector of probabilities allowing up 
to 2 tosses with doubles. The transition matrix will have this vector for 
each column (with appropriate osets). Then we adjust the probabilities for 
the Jail square, which is the sum of what it had from routine tossing, the 
probability of the Go to Jail square, and probability of tossing 3 doubles 
in a row (63/363 = 1/63). 
The Chance/Community Chest cards are actually not as complicated as 
they seem. There are 16 Chance cards, 10 of which tell the player to 
move to another square. The probability of staying in Chance is thus 1
8 
the probability it had before, and each of the 10 destinations is increased 
1by 10  P (probability of landing on Chance). The same goes for Commu
nity Chest, which only has 2 cards that send players to other squares. The 
probabilities would be adjusted accordingly. 
As a consequence of the Go to Jail square, tossing doubles, and Chance and 
Community Chest cards sending players to dierent squares, the probability 
distribution is no longer uniformly distributed over all 40 squares. Instead, 
it is skewed toward certain squares. Players are almost twice as likely to be 
in Jail than in any other square; the next-most-frequented square is Illinois 
Avenue, and GO is the third most likely square. B&amp;O Railroad is the most-
often occupied railroad. 
Where and When to Build? 
Rent-collecting is when things actually start to get interesting. After all, the 
whole point of the game is to bankrupt the other players. What strategy 
should we take in building houses and hotels? What can we use from our 
probabilistic analysis? If we take the actual decimal values of the probabil
ities and analyze the time of the break-event point (total cost of buildings 
divided by expected earnings from property per turn; how would you calcu
late the expected earnings?) which is when rents collected becomes greater 
18 ES.268</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Monopoly
 
Example 1 
Excuse this somewhat lame example, but its purpose is to show the sum rule 
at work. In a group of 150 students, 15 use Internet Explorer as their web 
browser of choice, 80 use Firefox, 15 use Safari, and 40 use Chrome. If being 
cool means you use Firefox or Chrome as your main web browser, what is 
the probability that we pick one student who is cool? 
Let the set C be the set of cool students; there are 80 + 40 students in C, 
by the sum rule. Let S be the set of all students; there are 150 students in 
total, as stated in the problem. Therefore, the probability of picking a cool 
student is: 
|C| 120 4 P (picking a cool student) = = = . |S| 150 5 
The multiplication rule states that for a length-k sequence, where the rst 
term is chosen out of set S1, the 2nd term is chosen out of set S2 . . . the last 
term is chosen out of Sk, then 
|Total # of sequences| = |S1  S2   Sk| 
= |S1||S 2||Sk|. 
Example 2 
The Athena combination lock just got changed again. Youre far from any 
Quickstation and theres no one else nearby. Suppose you wanted to try your 
luck at guessing the combo (and you dont have SIPBs hint board). How 
many possible combinations could you try? 
The athena door locks have 5 buttons, 3 on the top row and 1 on the bottom 
row (the bottom-right button is a reset, so it doesnt count). The athena 
passcode is 5 digits. Let Di, for i = 1, 2, 3, 4, 5, represent the set of buttons 
5 ES.268</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Monopoly
 
the
 probability that it stays SLOW the next day is 0.4. If it is BROKEN, 
then the probability that MIT Facilities comes to try to x it (making it 
SLOW) is 0.2, but most likely, with probability 0.8, itll just stay BROKEN. 
If we start the school year in the fall with a SLOW elevator, what kind of 
elevator will we have at the end of the school year? 
Our initial state distribution is xx
21 , with x1 representing the probability of 
having a BROKEN elevator, and x2 representing the probability of having a 
SLOW elevator. 
.6 .8Our transition matrix is A = . It has eigenvalues 1 and -.2, but over .4 .2 
time, the eigenvector associated with -.2 will be multiplied by (.2)n  0. 
We consider the eigenvector with eigenvalue 1. 
(A  I)x = 0 = (normalized) x =
 2 
3
1 
3 
We are twice as likely to end up with a BROKEN elevator. 
MONOPOLY R
Ian Stewart, a math professor at the University of Warwick, wrote a column 
in the April, 1996 issue of Scientic American seeking to answer the question: 
Is Monopoly fair? In other words, is every MONOPOLY R square equally 
likely to be occupied? His initial analysis was only a mathematical exercise, 
and his model abstracted many of the realistic playing rules. 
Initial Analysis 
We abstract away the rules about rolling doubles, Chance/Community Chest 
squares, and the complications involving going to Jail. Then on each roll of 
our dice the number of steps we could possibly take (sum of rolling two dice) 
is distributed as follows: 
16 ES.268</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Monopoly
 
probabilit
y that a player ends his turn in that state. Our state, H, belongs 
to the set S of the state space of size 40. The Markov chain is described 
in terms of its transition probabilities pij , which is the probability that 
well go from state i to state j at a time step. The transition probabilities 
sum to 1. 
pij = P (Hn+1 = j|Hn = i), i,j  S 
pij = 1 
j 
The probability that were in a certain state at time step n depends only 
on our state at time step n  1, and is independent of all states besides the 
previous state: 
P (Hn+1 = j|Hn = i, Hn1 = i  1,...,H o = io) = P (Hn+1 = j|Hn = i) = pij 
The transition matrix captures all the transition probabilities and operates 
on our state distribution vector. Such a matrix is called a Markov matrix, 
and it is also a square matrix. 
 T 

 p
00 p01 ... p0m 
p10 p11 ... p1m 
. . . . . . . . . . . . 
pm0 pm1 ... pmm 
 
Special matrices will have special eigenvalues and eigenvectors, and for Markov 
matrices, all entries are positive and every column sums to 1. Can you see 
why they must add to 1? The largest eigenvalue is 1, and the corresponding 
eigenvector is the state that comes out at the end. The eigenvectors of other 
eigenvalues fall to 0 over time. 
Example 7 
The ESG elevator has two states: SLOW and BROKEN. If it is SLOW 
today, then the probability that it becomes BROKEN tomorrow is 0.6, and 
15 ES.268</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Monopoly
 

 Distributive: 
(A  B)  C = (A  C)  (B  C) 
(A  B)  C = (A  C)  (B  C) 
The probability of an event is a mapping from the set of events to the interval 
[0,1]. When we talk about the probability of some event A in , it will always 
follow these axioms: 
1. The probability of the sample space, , is P () = 1; 
2. P (A)  0 for all A  . 
3. If A1 and A2 are disjoint, then 
P (A1  A2) = P (A1) + P (A2). 
More generally, if Ai for i = 1, 2, 3,... are disjoint, then 
  
P A i = P (Ai). 
i=1 i=1 
The inclusion-exclusion principle is very useful in calculating probabilities. 
It states that for two events, A1 and A2, not necessarily disjoint as in the 
third axiom above, 
|A1  A2| = |A1| + |A2||A 1  A2|. 
The third term in in the equation above subtracts the overlap in A1 and A3, 
which was counted twice. The probability version of the inclusion-exclusion 
principle is 
P (A1  A2) = P (A1) + P (A2)  P (A1  A2). 
The complement of a set A, commonly denoted A,Ac, or A, is all elements 
3 ES.268</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Monopoly
 
in
 the sample space that dont belong to that set. 
Ac =   A, 
|Ac| = |||A|, 
P (Ac) = P ()  P (A) 
= 1  P (A). 
For most problems, the goal will be to nd the likelihood that an event E 
happens, or P (E), out of the set of possible outcomes S. When all the 
outcomes are equally likely, 
|E|P (E) = . |S| 
Were adding up all the elements in E and all the elements in S, then dividing 
them. This leads us to the topic of counting, which is used when dealing with 
discrete, nite sample spaces. 
Counting 
We make the assumption that all the outcomes are equally likely, also known 
as the assumption of uniform probability. All that needs to be done then is 
add up the number of outcomes that we care about and divide that by the 
number of all possible outcomes. The trickiest part is dening the event and 
sample space and making sure that we count everything the right number of 
times. 
Counting Rules 
Weve seen the Sum Rule already, just not labeled with the name. If 
A1,A2,...,An are disjoint sets, then 
|A1  A2  ...  An| = |A1| + |A2| + ... + |An|. 
Whats the probability version of the Sum Rule? 
4 ES.268</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Monopoly
 
The
 number of ways that we can take r objects out of a set of n objects is 
therefore   n! n = . r!(n  r)! r 
Example 4: Hands of cards 
In this example were using a standard 52-card deck. 
a) How many ways are there to deal a 5-card hand? 
52 52! = = 2598960 5 5!(47)! 
b) How many ways are there to deal a ush, a 5-card hand with all cards 
the same suit? 
4 13There are 1 ways to choose the suit, and 5 ways to choose the 5 
cards out of that suit. 
13 # of ways to deal a ush = 4 = 5148 5 
c) How many ways are there to deal a 5-card hand with 1 pair? 
There are 13 ways to choose the card value of the pair, and 4 ways 1  2 50to choose the suits of the pair; then there are 3 ways to choose the 
remaining 3 cards of the 5-card hand. 
4 50 # of ways to deal a hand with 1 pair = 13 = 1528800 2 3 
d) How many ways are there to deal a 5-card hand with only 1 pair? 
As before, there are 13 ways to choose the card value of the pair, and  1 4 ways to choose the suits of the pair. But the problem species only 2 
1 pair. The remaining 3 cards in the hand cannot contain a pair. So 
8 ES.268</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Monopoly
 
If
 a player lands on a property owned by another player, then the owner 
collects rent based on the information on the property deed. Rents are much 
higher for properties with houses or hotels. When a player owns all the 
MONOPOLY R properties in a color group, then he has the option to build 
houses on those properties. If he buys one house, he can put them on any 
one of those properties. The next house he buys must be erected on one of 
the unimproved properties of that or any other complete color group, and so 
on. Thus, players must build evenly across all his properties in a color group. 
More details of the rules of the game will unfurl as we analyze the game. 
First, a bit of linear algebra. 
Matrices, Eigenvalues, and Eigenvectors 
The linear equation Ax = b is at the heart of most introductory linear 
algebra courses. A is a matrix, and x and b are vectors ; the matrix A 
operates on x to give b; x and b lie on the same vector space but are in 
dierent directions unless A is the identity matrix I. 
Eigenvectors are special vectors associated with every operating matrix. 
These vectors dont change directions when multiplied by the matrix, and 
we get the equation Ax = x. Each eigenvector has its own eigenvalue 
. Most 2  2 matrices have two eigenvectors and their two corresponding 
eigenvalues. 
What happens when A operates on x more than once? As in, whats A2x? 
A3x? A100x? 
The number  is an eigenvalue of A if and only if AI (which is a matrix) is 
singular, or det (A  I) = 0. A singular matrix is a square matrix that has 
no inverse, or det A = 0. Then, for each eigenvalue, we solve (A  I)x = 0, 
or Ax = x to nd the eigenvector x. 
13 ES.268</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Monopoly
 
p
ossible for each digit. 
|Total # of combinations| = |D1  D2  D3  D4  D5| 
= |D1||D 2||D 3||D 4||D 5|
= 5  5  5  5  5 
= 55 
Permutations 
The set of permutations on a collection of objects is an example of the 
algebraic structure called a group, which was covered in the Rubiks Cube 
lecture. Here well use a set of ordered objects as a working denition of 
permutations. For a collection of n objects, there are n(n1)(n2)  (1) = 
n! dierent orderings of the objects. 
Example 3: The Birthday Problem 
Youre in a room with a bunch of people, say n  365 people. 
a) What is the probability that two people in the room have the same birth
day? Ignore complications with leap years and assume there are 365 days 
in a year. We also assume that birthdays are random (not exactly true). 
This problem is best approached the other way around, with the proba
bility that no two people have the same birthday. 
Let A be the event that two people have the same birthday. Then Ac is 
the event that no two people have the same birthday. Note that P (A) = 
1P (Ac). We start with person 1; this person can have any 1 of 365 days 
out of the year. A second person can only have a birthday on the 364 
days out of the year that hasnt been taken. By assumption of random 
birthdays, and of uniform probability, the chance that this person has any 
of the 364 birthdays is 364 . A third person can only have a birthday out 365 
6 ES.268</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Monopoly
 
than
 the cost of building the houses and hotels, we nd that with 2 houses 
or fewer, it typically takes 20 moves or more to break even. With 3 houses, 
the chances are signicantly better. It is even better than building 4 houses 
or a hotel. This is preferable strategy because one of the principle strategies 
of MONOPOLY R is to deplete accounts of other players fast while accumu
lating fast yourself (so that you can purchase more property and build more 
buildings). If the break-even point takes too long, then we are wasting valu
able resources that could have been allocated to buildings on other properties 
and raising the rents of those properties. 
Remarks 
Other similar board games can be modeled in the same way. The premesis of 
Markov chains is that the next state is independent of all previous statesit 
ony depends on the current state. 
19 ES.268</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Monopoly
 
the
 game, Darrow approached Parker Brothers to enlarge the production 
scale (hed actually been rebued by the Parker Brothers the rst time in 
1933 due to 52 fundamental playing aws). Today, MONOPOLY R is the 
best-selling board game in the world, distributed in 111 countries and 43 
languages. Some fun facts from the MONOPOLY R website: 
	 The longest MONOPOLY R game ever played was 1, 680 hours long. 
	 The MONOPOLY Rman isnt a Parker Brother. His name is Mr.
 
Monopoly.
 
	 Parker Brothers once sent an armored car with a million MONOPOLY R dollars 
to Pittsburgh because a marathon game there had run out of money. 
	 MONOPOLY R comes in a Braille version. 
	 The four most-landed-on squares are Jail, Illinois Avenue, Go, and
 
the B&amp;O Railroad.
 
The last in the list of fun facts above is more than meets the eye. What makes 
certain game squares more likely to be landed-on than others? Illinois Avenue 
doesnt seem to be special compared to other properties. . . It turns out that 
we can model the MONOPOLY R game board to calculate the probability of 
landing on a certain square. 
Rules 
The objective of the game is to bankrupt all opponents, though most games 
played with family and friends end when it is apparent that someone will 
win. A typical game of MONOPOLY R uses the following items: 
	 1 game board 
	 2 dice 
	 token for players (11 ocial MONOPOLY R ones) 
11
 ES.268</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Monopoly
 
So
 we get that 
P (A  B)P (A|B ) = ,  for P (B) = 0. P (B) 
With some rearranging, we get Bayes Rule , which is commonly seen in 
many dierent forms: 
P (B|A)P (A) = P (A|B )P (B). 
The Law of Total Probability gives us the ability to isolate the probability 
of one event on a partitioned probability space. Given a space  that is 
partitioned by Bn : n = 1, 2,..., and an event A, 
n
P (A) = P (A  Bi) 
i=1 
Example 5 
Melissa and I are going to assign your P/F grades for this seminar by picking 
them out of a hat. We take 100 slips of paper and mark P on half of them, 
F on the other half. Then we put the slips of paper in two hats, and pick 
a slip of paper from one of the hats. Whatever we pick will be your grade. 
But, being as merciful and fair as we so obviously are, and curious how much 
you got out of this class, well leave it up to you to place the slips of paper 
into the two hats any way you want. How will you do it? 
Monopoly 
The game of MONOPOLY R came about during the Great Depression, orig
inating from Charles Darrow of Germantown, Pennsylvania. It started out 
as handmade sets sold in a shop in Philadelphia, and as people grew to love 
10 ES.268</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Markov and Mr. Monopoly Make Millions
 
 Spring 2011
 
Probability 
Probability is key to many elds, such as econometrics, quantum mechanics, 
signal processing, and theoretical computer science. We will go through a 
gentle introduction to the basics of probability, then discuss how probability 
can be used to analyze Monopoly. We will focus on discrete probability here, 
though we could easily convert to the continuous analogs. 
Sets 
A set is a collection of items. An example of a set can be all the Course XIV 
classes oered at MIT: {14.01, 14.02, 14.04, 14.05, 14.32, 14.33, 14.36 . . . }. For 
the following denitions and examples, let A and S be arbitrary sets. 
An element of a set is something belonging to that set. We write a  A if 
a is a member of the set A, and a / A if a is not a member of the set A. 
A subset is a set contained within another set, in other words, if all members 
of a set belongs to another set. A is a subset of S if all members of A belong 
to S, and we write A  S. Note that: 
 A = S if and only if A  S and S  A. 
1
 ES.268</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Surreal numbers</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses2_surreal/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>12</slideno>
          <text>- The Mathematics of Toys and Games
Exercises 
Try evaluating the Domineering and hackenbush positions on the worksheets. 
If yo
u get stuck check them with the programs listed on the software page of 
the website. 
13 
Image by MIT OpenCourseWare.ES.268</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>- The Mathematics of Toys and Games
In a 
game G = {A, B, C, . . . |D, E, F . . . }if A  B or D  E we say that A 
is dominated by B and E is dominated by D. We can eliminate these domi
nated options, since a logical player will only choose the best option available. 
Now to reversible options. Consider the same above, where if right moves 
to D then left has some option DL which is at least as good for left as G 
was to begin with, i.e. DL  G. Then if right ever decides to move to G, 
then left can at least reverse the eect of this move by moving to DL ( and 
his position might even get better!). To get a better feel for this, consider 
the game of poker Nim. This game is similar to the Nim that we played last 
week. We play with three heaps of poker chips and can take any amount of 
chips from any single pile on a single turn. The only dierence is that players 
are now also allowed to add any amount of chips to a single pile. (but not 
both add and subtract on the same turn). At rst this game may seem more 
complicated than regular Nim, until we see that adding any amount of chips 
is a reversible move. Say player 1 adds x chips to a heap. Then player 2 
can just take away x chips from the heap and leave player 1 back where he 
started. So the strategy for poker Nim is the exact same as for regular Nim, 
with the exception of removing any chips your opponent might add to the 
pile. 
Games! 
Domineering 
The game of domineering is played on a checkerboard. Players alternate 
placing dominoes (the size of two checkerboard spaces) on the board. Left 
can only place his dominoes vertically, while Right can only place them hori
zontally. The rst player to not be able to place a domino on the board loses. 
Try evaluating the values of the opening positions on the following partially 
played domineering board. The value of the game is the sum of the values 
of these empty positions: 
12 ES.268</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Surreal Numbers and Games
February 10, 2009 
Introduction 
Last week we began looking at doing arithmetic with impartial games using 
their Sprague-Grundy values. Today well look at an alternative way to repre
sent games as numbers that we will extend to include partisan games as well. 
Surreal numbers w ere introduced in Donald Knuths (ction) book Surreal 
Numbers: How Two Ex-Students Turned on to Pure Mathematics and Found 
Total Happiness , and the full theory was developed by John Conway after 
using the numbers to analyze endgames in GO. Well start by using Conways 
methods to represent games, and then show how these games/numbers form 
a new number system. 
On Numbers and Games 
To begin, well look at a partisan version of the impartial game of Green 
Hackenbush we saw last week. This game is called Red-Blue Hackenbush. 
It is played similarly to Green Hackenbush, but now each line segment might 
be colored either red or blue. There are two players who for convenience 
in notation will be called L and R. On Ls turn, he can only chop o blue 
branches, and R can only chop o red branches. As before, when a player re
moves a branch, all branches that are now disconncected from the ground 
also disappear. The player to chop o the last branch wins. The game below 
is an example: 
1</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>- The Mathematics of Toys and Games
	yR  YR such that yR  x. This is vacuously true, since there is 
no member yR since YR is empty! 
2.	y  x. 
	There is no yL, so always there is no yL such that x  yL. 
	The only member of XR is 41
2 , which is not less than or equal to 
3. 
So we have proven that the value of x must be 3. 
Below are some general forms you might nd helpful: 
1.	{n|n + 1}= n + 12 
2. 2p+1 p |p+1 
2n+1 = {2n 2n }, or in other words, each fraction with a denominator 
as a power of two has as its left and right options the two fractions 
nearest it on the left and right that have a smaller denominator which 
is again a power of two. So {1
2 |43 }= 85 . 
In evaluating numbers and games we will use the Simplicit y  Rule, which 
says that out of all the numbers between the largest member of the left set 
and the smallest number of the right set, the surreal number value of the 
form is the simplest number that ts, where we use simplest as meaning the 
number born earliest. This is just either the smallest integer between the 
two, or else the fraction between them having the highest power of two in 
the denominator. 
(In class well do some hackenbush examples with the simplicity rule) 
Arithmetic with Numbers (and Games) 
We showed last week that it can be helpful to break games up into sums of 
smaller, easier to evaluate, games, and use the sum of the values of these 
games to describe the larger game. The same is true with surreal numbers 
and their representations of games. 
8 ES.268</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>- The Mathematics of Toys and Games
The Negative of a  Number 
The negative of a number x = {XL|XR}is x = {XR| XL}. In terms of 
games, the negative of a game is just the game with the positions of L and 
R reversed. In a hackenbush game, for instance, just interchange all of the 
blue and red segments to get the negative of a game. 
Addition 
To a
dd the numbers x = {XL|XR}and y = {YL|YR}we get: 
x + y = {XL + y, x+ YL|XR + y, x+ YR} 
where X + y  {x + y : x  X}, x + Y = {x + y : y  Y}. Below are a few 
examples: 
 0 + 0 = {|}+ {|}= {|}= 0 
 x + 0 = x + {|}= {XL + 0|XR + 0}= {XL|XR}= x 
 1
2 + 1
2 = {0|1}+ {0|1}= {0 + 12 , 12 + 0|1 + 12 , 1 + 12 }= {12 |32 }= 1 
So in a sum of games G = {GL|GR} and H = {HL|HR}, the sum of the 
games has as left options the value if L moves in G, GL + H, (since H is 
unchanged) and HL + G if L moves in H. Similary, the right options are 
GR + H and HR + G depending on where R moves. This agrees with our 
notion of addition of surreal numbers. To subtract, just add the negative of 
a game. 
Multiplication 
Su
rreal numbers can also be multiplied, but we wont really use this denition 
in our game analysis. I include it here just to show that it can be done and to 
t with our original statement that the surreal numbers form an ordered eld. 
To multiply x = {XL|XR}and y = {YL|YR}: 
xy = {XLy+xYLXLYL, XRy+xYRXRYR|XLy+xYRXLYR, xYL+XRy XRYL} 
9 ES.268</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>- The Mathematics of Toys and Games
Arro
ws 
To il
lustrate these next two values, we will introduce another game called 
Toads and Frogs. We will play the game for implicity on a strip of 5 squares 
starting with two toads on the left two squares and two frogs on the right 
two squares: 
TT FF 
The toads can only move to the right one square each move and the frogs to 
the left. Toads and frogs can also jump over a toad or frog in an adjacent 
square to the next square over (as in Chinese Checkers). The g amei
s over 
when a player cant make a move. 
Consider the position T  TFF. Evaluating the possible T and F posi
tions gives the game: {TTFF |TFT F}= {0|}since no one can move 
in the left option and the rst player to move wins the right option. This 
value arises so often in describing games that it is given a special name, up, 
or . Similarly, the opposite game {|0}is denoted as . Since =  , we 
have  + = 0. 
Look at the starting position G = TT  FF = {T  TFF |TTF  F} = 
{ | } . To evaluate this game we will look at the game G  . Does L 
have a winning strategy from { | } + {0|0}? If he moves from * to 0, F 
will move in G to , which favors R. If L moves to , R will move from  
to * in G leaving *+*=0. So L does not have a winning strategy. We can 
show similarly that R also doesnt have a winning srategy going rst. So 
that means G  = 0. We can rewrite this as G =  and get the following: 
{ | } = { |0}= {0| } = {0|0}=  
Simplifying Games 
When looking at the options available to players in games, it is helpful when 
there are many options to be able to simplify things. Well use the following 
processes to simplify: 
1. Eliminate Dominated Options 
2. Eliminate Reversible Options 
11 ES.268</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>- The Mathematics of Toys and Games
of 0 f
rom last week). 
If the players had started with dierent numbers of branches, say 8 for L 
and 5 for R, then L would have a 3 move advantage, and we will say the 
value of this game G is 3. Similarly, if R has 3 more branches than L, the 
value of the game would be -3. 
In general, well use the following outcome  class es to describe games: 
(Note we use always wins to mean a player always has a winning strategy. 
Of course it is possible for them to make a mistake and lose.) 
 G = 0 The second player to move always wins. 
 G &lt; 0 Player R always wins. 
 G &gt; 0 Player L always wins. 
This seems to cover all possible values of G, but in many games we can imag
ine cases where the rst player to move always wins. This type of game is 
neither less than, greater than, or equal to 0. Instead, we will call it fuzzy or 
confused with 0, denoted as G||0. 
Consider the simple game consisting of a single blue branch. L has one 
move and R has none. This game is denoted as G = {0|}, since L can move 
to the 0 game and R has no moves. We will say this has a value of 1, since it 
is a one move advantage for L. Similarly, the game with a single red stalk has 
value G = {|0}and is equal to -1. So far we have the following numbers: 
{|}= 0, {0|}= 1, {|0}= 1 
Similarly, any game of the form {n|}= n + 1, {|n}= n 1. 
Can our games have fractional values? L ook a t the following red-blue hack
enbush positions: 
3 ES.268</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>- The Mathematics of Toys and Games
Below well use this and other games to dene games and surreal numbers. 
What is a Game 
A game (in combinatorial game theory) is dened as: 
G = {GL|GR} 
where GL, GR are sets of games themselves. This denition is recursive and 
can be confusing at rst, so well look at many examples. So G is a set of 
sets of games. The base case is {|} which will be called the endgame and 
occurs when neither player has any moves left. 
The sets of games in G are th e positions each player can move to. In an 
impartial game, since each player has the same options, both GL and GR 
will always be the same. In a partisan game, such as red-blue hackenbush, 
these options can be dierent. 
First consider the red-blue hackenbush game in which both players have 
ident
ical gures consisting of all branches of their own color. Each player 
has the same number of possible moves. The game will proceed as follows: 
the rst player to move takes one branch of his color, the next player takes 
one branch of her color, and the game alternates back and forth until each 
player has only one branch left. The rst player is forced to take his last 
branch, leaving the last branch on the page to the second player, who wins 
the game. We will call such a game, in which the second player to move 
wins, a zero position (equivalent to the P-position games with SG values 
2 Image by MIT OpenCourseWare. ES.268</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>- The Mathematics of Toys and Games
Special Non-numeric Games 
All of our arithmetic rules are dened for numbers, but we said before that 
a lot of games arent well-formed, or in other words arent actually numbers. 
Can we still do arithmetic with these games? The answer is yes! 
{0|0} 
Earlier we mentioned that we would call the game {0|0} *. Consider the
green hackenbush game with a single line segment left:
*picture here *
If left moves rst, he takes the stalk and wins, and similarly right moves if
he goes rst. What happens if we add another disconnected green stalk?
*picture here *
This is the game of * + *, since it consists of the sum of two * games. First
look at lefts options. He can take either one of the two stalks, after which
right takes the remaining one and wins. It is clear that the rst player to go
loses. But this is just our denition of a 0 game! So we get:
 +  = 0 
What about adding * to a number x? To look at this position we will 
introduce a third type of hackenbush, red-green-blue hackenbush, in which 
there are red, green, and blue segments. The red and blue ones belong to 
right and left, respectively, but the green segments may be cut by either 
player. Consider the game consisting of a stalk of 2 blue segments and a 
stalk of one green segment. This is the game 2 + *. Lef t 
has three options: 
take the green stalk to leave the game with a value of 2, take the bottom 
blue stalk for a value of *, in which case right will win on the next move by 
taking the remaining green stalk, or take the top left stalk to leave the game 
of 1+*. The most positive of these options is clearly to take the green stalk 
to make a value of 2. Right has only one option: take the green stalk to 
create a game of value 2. So we end up with: 
2 + = {2|2} 
Similarly, for any x + , we get {x|x}. Often we omit the star from the 
expression x +  and instead just write x. 
10 ES.268</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>- The Mathematics of Toys and Games
not 
numeric. 
Similar to our denition of games, L and R are themselves sets of surreal 
numbers, so the denition is again recursive. Also note that dierent sets L 
and R may actually form the same number. We say that numeric forms are 
placed in equiva
lence classes . So to be clear, the forms described above 
form equivalence classes, each of which is a (surreal) number . 
The following are useful theorems about surreal numbers. Proofs can be 
found in the reading for the week: 
1.	Theorem 1: If x is a surreal number, then x = x. 
2.	Theorem 2: If A = B and C = D, then {A|C}= {B|D}. 
3. Theorem 3: A surreal number X = {XL|XR}is greater than all mem
bers of its left set xL and less than all members of its right set xR. 
4. Theorem 4: For the number X = {XL|XR}, we can remove any member 
of the left set xL except the largest or any member of the right set xR 
without changing the value of the number. 
Comparing Real Numbers (and games) 
The surreal numbers form a totally ordered eld, and any two forms that are 
numeric can be compared to each other using the following rules: 
	Given two numeric forms x = {XL|XR}and y = {YL|YR}, we say x  y 
i there is no xL  XL such that y  xL and there is no yr  YR such 
that yR  x. The two numeric forms above are equal if x  y and 
y  x. 
Games that are not also numbers are tricky to order, so we often call them 
confused or fuzzy, as noted above. One example of such a game is {0|0}, the 
game in which either player can only move to the endgame, and so the rst 
player to move wins. We denote this special game as  since it comes up 
so often. This game is neither greater than, less than, or equal to 0. More 
about this soon. 
5 ES.268</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>- The Mathematics of Toys and Games
Construction of Numbers (and Games) 
Surreal numbers can be constructed from the base case {|} = 0 using the 
induction rule. We start with the generation S0 = {0}in which 0 is con
structed from just the emptyset (which from now on we will omit, so if there 
is no number in a set it is assumed to be the emptyset). Starting with this 
0th generation, each new generation Xn consists of all of the (well-formed) 
surreal numbers generated from subsets of i&lt;nSi. We say that the numbers 
born in generation Sn all have the same birthday, or were born on day n. So 
0 was born on day 0, and gave birth to all of the numbers that we know in 
the real number system. 
In terms of games, the birthday of a number can be seen as the depth of 
the game in the game tree. So the endgame, or 0, born on day 0, is a game 
thats over. A game with value of 1 is 1 move into the game tree, etc. 
S1 is constructed from combinations of members of S0, or the emptyset and 
0. So possible members of S1 are: 
{0|}, {0|0}, {|0} 
But the middle form is omitted since it is not numeric ( 0 is not less than 0), 
so we only have two new numbers. These are 1 and -1. 
S2 now consists of all combinations of 0, 1, -1, and the emptyset: 
{1, 0|}, {1, 0, 1|}, {1|}, {|0, 1, 1}, {|0, 1}, {| 1}, {0|1}, {1|0}, {1| 1} 
But we omit all of the non-well formed numbers and are left with four new 
numbers: 
{1|}, {| 1}, {0|1}, {1|0} 
which will be called 2, -2, 21 , and 21 , respectively. 
So a pattern emerges. Every new generation Sn has at its extremal ele
ments n and n as {|n  1}, {n  1|}, and all of the fractional numbers 
spaced equally in between all of the new elements and the previously exist
ing numbers. 
6 ES.268</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>- The Mathematics of Toys and Games
In 
gure b, if R moves rst, he can only chop o the top branch, leaving 1 
branch for L and a game with a value of 1 since L now has a one move advan
tage. If L moves, he can only chop o the bottom branch, leaving 0 branches, 
or the endgame. So the game is denoted as G = {{|}| 1}. We can replace 
GR with 0, since we dened the endgame to be so above, giving us: G = {0|1} 
What is the value of G? We know it must be positive, since L clearly has 
the advantage in this game. But does L have a one-move advantage? If so, 
if we give R back an extra move then we would expect the value of the game 
to be 1 - 1 = 0, or a second player win. Let 
s see what happens: 
Now if we were correct that the left stalk has a value of 1, then adding the 
red stalk with value -1 should make this a 0 game. If L goes rst, he leaves 
two red branches with a value of -2. If R moves rst he takes either branch, 
then L takes a branch, and there is still a branch left for R to take and win 
no matter what. Clearly this game has a negative value since R can win all 
the time. So what is the value of the original game? It turns out it is 1
2 , or 
a half move advantage for L. We can verify by adding two of these games 
together to see that they have a value of 1. 
So now our list of numbers is: 
1 1 {|}= 0, {0|}= 1, {|0}= 1, {0|1}= , {1|0}=  , {n|}= n+1, {|n}= n1 2 2
What is a Surreal Number 
We will call a form (game) {L|R}numeric if there is no xL  L and xR  R 
such that xR  xL. So every number to the left of the |must be less than 
every number to the right of the . (note NOT equal! well get to this case). 
Note that all surreal numbers can be games, but not all games can be surreal 
numbers. For instance, the games {0|0}and {1| 3}can be games, but are 
4 ES.268</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>- The Mathematics of Toys and Games
It s
eems that continuing in this manner can only give only all of the in
tegers and all of the dyadic fractions (fractions with denominators as powers 
of two). But what happens if we extend our tree of numbers to innity? 
On day , we eventually come to the number  = {1, 2, 3, 4. . . |} which is 
larger than all natural numbers. We also get , which is smaller than all 
natural numbers, as well as  = {0|1, 1
2 14 18 . . .}, which is the smallest pos , , 
itiv
e number (the opposite for the largest negative number). So we have 
innite and innitesimal numbers in this generation, what else? Numbers 
in the generation S may also belong to the familiar rational numbers. For 
instance, 1 = {1 , 1 + 1 , 1 + 1 + 1 + . . . |1 , 1  1 , . . .}. We also get tran3 4 4 16 4 16 64 2 2 8 
scendental numbers on day , for example  = {3, 25 , 201 , . . . |4, 7 , 13 , 51 , . . .}.8 64 2 4 16 
With a little playing around we can get to any number. We can even get 
beyond innity to generations  + n. 
Evaluating Surreals 
So given a number {x|y}, how do we decide which surreal number it repre
sents? {0|1} = 21 , so we might be tempted to just take the average of the 
larg
est number on the left and the smallest number on the right, but it turns 
out this fails. We see this with an example. Take the number {21
2 |421 }. The 
average of these numbers is 31
2 , but we claim that the number it represents 
is 3. How do we test equality? We choose a form that we know is equal to 
3, {2|}. Now we show that for x = {221 |421 }and y = {2|}, both x  y and 
y  x. 
1.	x  y. 
	xL  XL such that y  xL. This is true, since the only xL is 21
2 , 
which is less than or equal to y = 3. 
7 -1
-2
3 -3
- (w +1) (w +1) 1/(2w) 2/w1/w -w0
-1/21/221
-1/4 1/4 3/4 3/2 -3/4-3/2
wDay 0
Day 1
Day 2
Day 3
Day w
Image by MIT OpenCourseWare. ES.268</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Constraint logic</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses12_slides2/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>32</slideno>
          <text>Constraint LogicConstraint Logic
[Hearn &amp; Demaine 2009][Hearn &amp; Demaine 2009]bounded unbounded 
PSPACE EXPTIME 
P Undecidable 
NEXPTIME PSPACE 
NP 
PSPACE 
0 players 1 player 2 players team, 
(simulation) (puzzle) (game) imperfect info 
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
33</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>RedRed--Blue Conversion 
 Blue Conversion
assume an even number of conversions
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
16</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>OR fromOR from
Protector ORProtector OR
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
25</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Triangular
Triangular
Rush Hour
Rush Hour
[Hearn &amp; Demaine 2009]
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
27</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Wiring Vertices Together
Wiring Vertices Together
AND wants red 
OR wants blue 
2 
OR 
AND 
1 
Copyright (2009)  From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
15</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Boolean
Boolean
Formulas
Formulas
Copyright (2009)  From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. De
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.maine.
18</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>SPLIT vertex
SPLIT vertex
T T FF F 
outputs 1
1 1
2
 input 
T F 
Rule: at least 2 units 
incoming at a vertex 
Copyright (2009)  From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
7</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Constraint Graphs
Constraint Graphs
Machine = graph,
red &amp; blue edges
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
3</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Constraint LogicConstraint Logic
[Hearn &amp; Demaine 2009][Hearn &amp; Demaine 2009]bounded unbounded 
PSPACE EXPTIME 
P Undecidable 
NEXPTIME PSPACE 
NP 
PSPACE 
0 players 1 player 2 players team, 
(simulation) (puzzle) (game) imperfect info 
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
2</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>SlidingSliding--Block PuzzlesBlock PuzzlesCorollary:[Hearn &amp; Demaine 2002][Hearn &amp; Demaine 2002]PSPACE-complete
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
14</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>PushPush--2F2F
[Demaine, Hearn, Hoffmann 2002][Demaine, Hearn, Hoffmann 2002]
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
31</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>AmazonsAmazons
[Hearn 2005]
[Hearn 2005]
fanout 
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
34</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Constraint Logic
Constraint Logic
= 1
1 1
= 2 2
Rule: at least 2 units
incoming at a vertex
Move: reverse an edge, preserving Rule
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
5</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.Universal Quantifier
Universal Quantifier
21</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Existential Quantifier
Existential Quantifier
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
20</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>b unComplexity of Games &amp; Puzzles
Complexity of Games &amp; Puzzles
[Demaine, Hearn &amp; many others][Demaine, Hearn &amp; many others] ounded bounded 
NP PSPACE EXPTIME 
P Undecidable 
NEXPTIME PSPACE PSPACE 
Rengo Kriegspiel? 
bridge? 
Image courtesy of 
Jason Whittaker . 
Courtesy of BigJ_Smack 
Image courtesy of 
Nguyen Dai . 
Image courtesy of 
Herman Hiddema 
Image courtesy of 
Marie-Lan Nguyen . 
Image courtesy 
of PartsnPieces. 
Image is in the 
public domain . 
Courtesy of Sam 
Cancilla . Used 
with permission. 
Courtesy of Glenn Peters . 
Used with permission. 
0 players 1 player 2 players team, 
(simulation) (puzzle) (game) imperfect info 
Images by MIT OpenCourseWare.
1</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>SlidingSliding--Block PuzzlesBlock PuzzlesCorollary:[Hearn &amp; Demaine 2002][Hearn &amp; Demaine 2002]PSPACE-complete
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
13</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Decision Problem
Decision Problem
Copyright (2009)  From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
can you reverse this edge? 
9</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Crossover Gadget
Crossover Gadget
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
24</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Open: 1Open: 1 1 Rush Hour 
 1 Rush Hour
[Tromp &amp; Cilibrasi 2008][Tromp &amp; Cilibrasi 2008]
 P or PSPACE-complete or ?
Image courtesy of John Tromp. Used with permission. 
28</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Constraint Graphs
Constraint Graphs
Machine state
= orientation 
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
constraint graph 
4</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>OR vertex
OR vertex
FT F TT T 
inputs 2 2
2
 2
2
 output 
T F T
not your usual Rule: at least 2 units
OR gate! incoming at a vertex
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
8</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Decision ProblemDecision Problem
Copyright (2009)  From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
can you reverse this edge? 
Theorem: 
PSPACE-complete 
11</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Constraint LogicConstraint Logic
[Hearn &amp; Demaine 2009][Hearn &amp; Demaine 2009]bounded unbounded 
PSPACE EXPTIME 
P Undecidable 
NEXPTIME PSPACE 
NP 
PSPACE 
0 players 1 player 2 players team, 
(simulation) (puzzle) (game) imperfect info 
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
10</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Rush HourRush Hour
[Hearn &amp; Demaine 2002]
[Hearn &amp; Demaine 2002]
PSPACE-completeness known [Flake &amp; Baum 2002]
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
26</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>AND vertex
AND vertex
FT F TT T 
inputs 1 1
1 1
2
 output 
F T 
not your usual Rule: at least 2 units 
AND gate! incoming at a vertex 
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
6</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Constraint LogicConstraint Logic
[Hearn &amp; Demaine 2009][Hearn &amp; Demaine 2009]bounded unbounded 
PSPACE EXPTIME 
P Undecidable 
NEXPTIME PSPACE 
NP 
PSPACE 
0 players 1 player 2 players team, 
(simulation) (puzzle) (game) imperfect info 
Copyright (2009)  From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
32</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>RedRed--Blue Conversion 
 Blue Conversion
assume an even number of conversions
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
17</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>SlidingSliding--BlockBlock
PuzzlesPuzzles
Courtesy of Dr. Jim Storer. Used with permission.
12</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Plank PuzzlesPlank Puzzles [Hearn 2004]
[Hearn 2004]
Copyright (2009)  From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
29</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Latch
Latch
A 
Blockedun
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
22</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Quantified Boolean FormulasQuantified Boolean Formulas (QBF)
(QBF)
xx yy ww zz 
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
19</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Universal Quantifier
Universal Quantifier
Copyright (2009)  From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
23</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>SokobanSokoban
[Hearn &amp; Demaine 2002]
[Hearn &amp; Demaine 2002]
PSPACE-completeness known [Culberson 1998]
Copyright (2009) From Games, Puzzles, and Computation by Robert A. Hearn and Erik D. Demaine.
Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
30</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>NP-completeness</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses11_slides/</lecture_pdf_url>
      <lectureno>11</lectureno>
      <slides>
        <slide>
          <slideno>10</slideno>
          <text>Wire
Either all the x's or all the x''s are mines. If it is the x's, we 
call it true, if the x''s, we call it false x'x x'x x'x x'x x'x x'x x'x1 1 1 1
1
1 1 1 111 1 1 1
1 1 1 1 1 1
1 1 1 11 1 1 1
1 1 1 11 1 1 1
1 1 1 11 1 1 1
1 1 1 11 1
1 1
Image by MIT OpenCourseWare.
11</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Finale
Pieces
28</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Manipulating Wires
(c) Springer-Verlag New York. All rights reserved.This content is excluded from our Creative Commons license. 
For more information, see http://ocw.mit.edu/fairuse.
 Kaye, Richard.  "Minesweeper is NP-complete." Mathematical Intelligencer 22, no .  2 (2000): 9-15. 
Minesweeper is NP-Complete, Kayes
13</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Initial Board 
s columns 
(one per sum)  T notches 
(target sum) T lock 
bane (it is possible to 
actually get here) 
22</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Forced Moves 
25</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Finale
Pieces
27</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>3SAT  MINESWEEPER
z Conversion took polynomial time: 
z 1 gadget for each of the N vars = O(N)
z 1 gadget for each of M clauses = O(MN) 
z Total O(N(M+1)) time 
9</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Reduce from 3SAT
f(w)
3SAT instance w MINESW instance Z 
z Function f converts a 3SAT instance to a 
MINESW instance in polynomial time 
z Z is satisfiable iff w is satisfiable 
5</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Finale
Pieces
29</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>20</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Minesweeper 
z Reducing 3SAT to generalized Minesweeper 
z Reducing cSAT to well-know version of 
Minesweeper 
2</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Minesweeper as we know it
MINESWEEPER Problem: Given a rectangular grid 
partially marked with numbers and/or mines, some squares 
being left blank, determine whether there is some pattern of 
mines in the blank squares giving rise to the numbers seen. 
Deciding if a graph is in the MINESWEEPER language is NP-
complete: 
- Polynomial time verification 
- Reduce from cSAT in polynomial time 
10</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>More gates
z We can now manipulate/invert wires 
z Cross wires? First make planar XOR, then use 
XOR and three way splitter to cross wires 
z We have NOT, and AND, universal! 
15</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Failure to Launch
24</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>NAND is universal!
z (A nand A) nand (B nand B) = A v B 
z (A nand B) nand (A nand B) = A ^ B 
z (A nand A) = ~A 
18</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>AND gate
Minesweeper is NP-Complete, Kayes
(c) Springer-Verlag New York.  All rights reserved. This content is excluded 
from our Creative Commons license. For more information, see http://ocw.mit.edu/fairuse.
Kaye, Richard. "Minesweeper is NP-complete." Mathematical Intelligencer 22, no. 2 (2000): 9-15.
17</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Piece Sequence
 For each input  ai:
(ai reps)
23</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Finale
Pieces
31</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Minesweeper is NP-Complete
Notes by Melissa Gymrek
Based on a paper by Richard Kayes 2000
1</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>More gates
(c) Springer-Verlag New York. All rights reserved. This content is excluded from our Creative Commons license. 
For more information, see http://ocw.mit.edu/fairuse.
Kaye, Richard. "Minesweeper is NP-complete." Mathematical Intelligencer 22, no. 2 (2000): 9-15. 
Minesweeper is NP-Complete, Kayes
16</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Polynomial Time Verification 
z For each node v labeled m: 
z Check that exactly m neighbors contain mines 
z O(E) time  clearly polynomial 
4</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Summary
	If theres a 3partition, can  win Tetris:  
Get tons of lines, Tetrises, live forever, etc. 
	If theres no 3partition, must  lose Tetris:  
Die, no lines, no Tetrises, etc. 
32</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Manipulating Wires
(c) Springer-Verlag New York. All rights reserved. This content is excluded from our Creative Commons license. 
For more information, see http://ocw.mit.edu/fairuse. 
Kaye, Richard. "Minesweeper is NP-complete." Mathematical Intelligencer 22, no. 2 (2000): 9-15. 
Minesweeper is NP-Complete, Kayes
12</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>3SAT  MINESWEEPER
0 0 1 
xi ~xi
Make a gadget for each variable
7</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Open Problems
	What if the initial board  is empty? 
	What about Tetris with O(1)  columns? 
	What about Tetris with O(1)  rows? 
	What about restricted piece  sets (e.g. just )? 
	What if every  move drops  from high up 
(no lastminute slides)? 
	Is
 twoplayer Tetris PSPACEcomplete? 

	What can
 we say about  online (regular) Tetris?
33</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>N
0 0 03SAT  MINESWEEPER
For clause (A V B V ~C) 
Connect to variable 
gadgets 
A A B C N 0 
00 0 0 0 
1 1 0 0 N-1 satellite nodes ... 
0 
1 
Make a gadget for each clause
8</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Finale
Pieces
26</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>3Partition
	Given 3s integers a1, a2, , a3s, can you 
partition into s triples with the same sum? 
	Know the sum must be  T =ai / s 
	This problem is strongly NPcomplete :  
NPcomplete even
 if ai numbers are sO(1) 
 ? 
T 
s triples 
21</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Finale
Pieces
30</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>NOT gate
Inverts the sign of a wire
x'x x'x x'x x xx' xx' xx'1 1 1 1
1
1 1 1 111 1 1 1
1 3 1 1 1 1
1 1 1 111 1 1
2
232
2 11 1 1 1
1 1 1 1
1111 1 1 1
1 1 1 11 1
1 1
Image by MIT OpenCourseWare.
14</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Tetris is NPcomplete
Ron Breukelaar, Erik Demaine,
Susan Hohenberger, 
Hendrik Jan Hoogeboom,

Walter Kosters, David LibenNowell
published 2004
19</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>General Minesweeper
MINESWEEPER: { G,  |G is a graph and  is a partial 
integer labeling of G, and G can be filled
with mines in such a way that any node v labeled m has exactly 
m neighboring nodes containing mines.}

Deciding if a graph is in the MINESWEEPER language is NP-
complete: 
- Polynomial time verification 
- Reduce from 3SAT in polynomial time 
3</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>3SAT Review
Boolean 3CNF formula: 
(A V B V C) ^ (~A V D V ~C) ^ 
N variables (A, B, C, D) in this instance
M clauses (here 2 clauses are shown)
Question: Is this boolean formula satisfiable?
6</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Blackjack/poker-guest lecture</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses9_slides/</lecture_pdf_url>
      <lectureno>9</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>3.	One round of bet ting, starting with the dealers left. 
4.	Trade in from 0 to three cards from the remaining deck (if you have an ace you 
can trade 4 cards). 
5.	After receiving new cards, there is another round of betting. 
6.	Players show their hands to determine who won the pot (using standard hand 
rankings). 
Texas Hold'em Poker Gameplay 
1.	The two players to the left of the dealer put out blind bets . The player directly to 
the dealer's left puts out the small blind while the player two to the dealer's left 
puts out the big bli nd. 
2.	Every player is dealt two cards, face down. These are called hole or pocket cards. 
3.	The action , or the first move, falls on the player to the left of the big blind. She 
can either cal l the bet, raise it, or fold. Betting continues around the table, 
clockwise. 
4.	After the betting is completed, three cards are dealt face up in the center of the 
table, which is referred to as the board . The first three cards in Texas Hold'em are 
called the flop . These cards are community cards meaning everyone can (and 
will) use them in combination with their own hole cards to make the best hand. 
5.	From the flop on, betting begins with the p layer to the dealers left, who can 
check or bet. 
6.	A fourth card is dealt face up onto the board. This is called fourth street or the 
turn card. 
7.	Another round of betting. 
8.	The final card is dealt face up. This card is also called fifth street or the river . 
9.	A final round of betting occurs. The remaining players show their cards and the 
person who can make the best five card hand by combining their pocket cards 
with the cards on the board wins. 
4</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Mathematics of Card Games Appendix 
Probability of Cribbage Scores 
Score Probability 
0 0.0788 
1 0.007801 
2 0.2188 
3 0.03929 
4 0.2212 
5 0.05419 
6 0.1375 
7 0.05803 
8 0.08604 
9 0.02719 
10 0.02887 
11 0.003241 
12 0.02374 
13 0.001172 
14 0.006729 
15 0.00066 
16 0.004407 
17 0.0008613 
18 0.000173 
19 0 
20 0.0006024 
21 0.0001902 
22 0.00003417 
23 0.0000274 
24 0.0002832 
25 0 
26 0 
27 0 
28 0.00000585 
29 0.000000308 
Blackjack Odds of Busting 
Hand Value 
11 or less % Bust if you Hit 
21 100% 
20 92% 
19 85% 
18 77% 
17 69% 
16 62% 
15 58% 
14 56% 
13 39% 
12 31% 
0% 
1</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>dealer reveals the top card, called the "starter". If this card is a Jack, the dealer 
scores two points for "his nibs. 
2.	The Play: S tarting with the player on the dealer's left, each player lays one card 
in turn onto a personal discar d pile, stating the cumulative value of the cards laid 
(for example, the first player lays a five and says "five", the next lays a six and 
says "eleven", and so on), without the total going above 31. Once no more cards 
can be played, the cumulative positio n is reset to zero and those players with 
cards remaining repeat the process until all players' cards have been played. 
Players score points during this process for making a total of fifteen, for reaching 
exactly, or as close as possible to a total of thir ty-one, for runs and for pairs. 
3.	The Show: Once the play is complete, each player in turn receives points based 
on the content of his hand in conjunction with the starter card . Points are scored 
for combinations of cards totaling fifteen, runs, pairs, flushes and having nibs. 
The dealer scores his hand last and then turns the cards in the crib face up. These 
cards are then scored by the dealer as an additional hand in conjunction with the 
starter card. Scores between 0 and 29 are all possible, with the exc eption of 19, 
25, 26 and 27. 
Blackjack Gameplay 
Before each round of play, the player places his bet. Each player and the dealer 
initially receive two cards; only one of the dealer's cards is shown to the player. A card's 
value is equal to its rank, but picture cards are worth 10; an ace is worth either 1 or 11. 
For simplicity, refer to all 10 -valued cards as 10. The player has several options, 
depending on his cards. He may: 
Hit: Draw another card. A player is allowed to hit any hand not exceed ing 21. If 
the player's card total exceeds 21, he has 'busted,' and automatically loses his bet. 
Stand: Draw no more cards. 
Double down : Double the original bet and receive one card only. This option is 
allowed on a two -card hand only. 
Split: If the pla yer has two cards of equal value, he may place another bet equal 
to his original one, and play each card as a separate hand. Exceptions: if the 
player splits two aces, he receives only one card on each; an (A 10) counts as 21, 
not blackjack; and even if r esplitting is allowed otherwise, the player may not 
resplit aces. 
Five-Card Draw Poker Gameplay 
1.	Big/Small blind put in antes (or theres the recreational variation where everyone 
puts in a small ante). 
2.	Each player is dealt five cards. 
3</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Basic Blackjack Strategy 
Hard Hands: Starting hand does not contain an Ace 
	If you have eight or less, always hit. 
	If you have Nine: Double if the dealer has 3 thru 6 -otherw ise hit. 
	If you have Ten : Double if the dealer has 2 thru 9 -otherwise hit. 
	If you have Eleven: Double if the dealer has 2 thru 10, Hit if dealer has Ace. 
	If you have Twelve: Hit if the dealer has 2 or 3, Stand if the dealer has 4 thru 6, 
otherwise hit. 
	If you have 13 -16: Stand if the dealer has2 thru 6, otherwise hit. 
	If you have 17 -21: Always Stand. 
Soft Hands : Starting hand contains an Ace 
	If you have Ace 2 or Ace 3: Double if the dealer has 5 or 6 -otherwise hit. 
	If you have Ace 4 or Ace 5: Doub le if the dealer has 4 thru 6 -otherwise hit. 
	If you have Ace 6: Double if the dealer has 3 thru 6 -otherwise hit. 
	If you have Ace 7: Stand if the dealer has 2, 7 or 8. Double 3 -thru 6 -otherwise 
hit. 
	If you have Ace 8 or Ace 9: Always Stand. 
Pairs : Starting hand contains a pair 
	If you have a pair of Aces or Eights: Always split. 
	If you have a pair of twos or threes: Split if the dealer has 2 -7, otherwise hit. 
	If you have a pair of fours: Split if the dealer has 5 or 6 -otherwise hit. 
	If you have a pair of fives: Double if the dealer has 2 thru 9 -otherwise hit. 
	If you have a pair of sixes: Split if the dealer has 2 thru 6 -otherwise hit. 
	If you have a pair of sevens: Split 2 thru 7 -otherwise hit. 
	If you have a pair of nines: Split 2 thru 6, and 8 or 9. Stand if the dealer has 7, 10 
or Ace. 
	If you have a pair of tens: Always Stand. 
Card Game Rules 
Cribbage Gameplay 
1.	The Deal : The players cut for first deal, and the dealer shuffles and deals five or 
six cards to each player, depending on the num ber of players. For two players, 
each is dealt six cards; for three or four players, each is dealt five cards. In the 
case of three players, a single card is dealt face down in the centre of the table to 
start the crib. Once the cards have been dealt, each player chooses four cards to 
retain, then discards the other one or two face -down to form the "crib" which will 
be used later by the dealer. At this point, each player's hand and the crib will 
contain exactly four cards. The player on the dealer's left c uts the deck and the 
2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Game of Life</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses10_slides2/</lecture_pdf_url>
      <lectureno>10</lectureno>
      <slides>
        <slide>
          <slideno>11</slideno>
          <text>/trianglerightsldHeavy Weight Space Ship (HWSS):
Image by MIT OpenCourseWare.
12</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>c/trianglerightsldLight Weight Space Ship (LWSS) (speed
2):
/trianglerightsldMedium Weight Space Ship (MWSS):Image by MIT OpenCourseWare.
Image by MIT OpenCourseWare.
11</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>For the OR gate, we again position our two input streams
perpendicular to the output of the glider stream, and make use ofa second glider gun as well. Let us go through all possible casesand see why this gives us an OR gate.
/trianglerightsldA=1 ,B=1If Bs stream has a glider, it will collide with the glider fromthe gun and create a vanishing reaction. If A has a glider, butthere is no space from the incoming glider stream, no gliderfrom the stream will reach the next node, a collision path withanother glider gun. Since there is no glider from the incomingstream, the glider from the second gun will reach the output,making the value of A or B 1, as expected.
41</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Consider the grid below:
Courtesy of Nathanial Johnston. Used with permission.
20</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>/trianglerightsldPeriodic Life Forms/Oscillators : the following life-forms
oscillate periodically
Period 2:Blinker:
Toad:Image by MIT OpenCourseWare.
Image by MIT OpenCourseWare.
8</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>Another equivalent statement to saying Life is universal is that we
can build a Turing-machine from it. We start by describingTuring Machines. A Turing Machine has:
/trianglerightsldA nite set of states
/trianglerightsldRules for transitioning between states
/trianglerightsldAn innite sequence of cells (called a tape)
/trianglerightsldA set of symbols describing the possible contents of each cell inthe tape
/trianglerightsldThe ability to read and write the symbol in a single cell
/trianglerightsldThe ability to move along the tape to access dierent cells.
45</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Starting from the initial conguration, these rules are applied, and
the game board evolves, playing the game by itself!This might seem like a rather boring game at rst, but there aremany remarkable facts about this game. Today we will see thetypes of life-forms we can create with this game, whether we can
tell if a game of Life will go on innitely, and see how a game of
Life can be used to solve any computational problem a computercan solve.
4</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>/trianglerightsldIt is not immediately obvious whether a given initial Life
pattern can grow indenitely, or whether any pattern at all
can.
/trianglerightsldConway oered a $50.00 prize to whoever could setlle this
question. In 1970 an MIT group headed by R.W. Gosper wonthe prize by nding the glider gun that emits a new glider
every 30 generations. Since the gliders are not destroyed, andthe gun produces a new glider every 30 generationsindenitely, the pattern grows forever, and thus proves thatthere can exist initial Life patterns that grow innitely.
17</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Using this simple games rules, we can create many dierent types
of life-forms.
/trianglerightsldStill Life : a stable, nite and nonempty pattern. Examples
include various shapes of ponds, and other patterns shownbelow:
/trianglerightsldBlock:
/trianglerightsldBeehive:Image by MIT OpenCourseWare.
Image by MIT OpenCourseWare.
5</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>/trianglerightsldIn the Game of Life, we can dene the speed of light ( c,
just as in physics) as the maximum attainable speed of any
moving object, a propagation rate of one step (horizontally,vertically, or diagonally) per generation. This is both themaximum rate at which information can travel and the upperbound on the speed of any pattern.
/trianglerightsldWe can nd the speed of two patterns weve seen, the gliderand the lightweight spaceship. The glider takes 4 generationsto move one cell diagonally, and so has a speed of
c
4.T h e
light weight spaceship moves one cell orthogonally every othergeneration, and so has a speed of
c
2.
/trianglerightsldAlthough the speed of light is dened as one cell pergeneration, we show here that the maximum attainable speedof any moving object is either
c
 c
4diagonally or
2orthogonally.
No spaceships can move faster than our glider or light weightspaceship.
18</text>
        </slide>
        <slide>
          <slideno>49</slideno>
          <text>References
/trianglerightsldhttp://www.math.com/stude nts/wonders/life/life.html
/trianglerightsldhttp://www.nathanielj ohnston.com/index.php/tag/conways-game-
of-life/
/trianglerightsldWinning Ways
/trianglerightsldCellular Automata and Turing Universality in the Game of Life by
Paul Rendell, presented by David Thue
50</text>
        </slide>
        <slide>
          <slideno>50</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>/trianglerightsldGuns A gun periodically shoots out moving patterns. We will
look soon at the Glider Gun , the rst known gun developed
by Gosper at MIT.
13</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>We will not go into details, but for engineering purposes we note
that we can manipulate the direction of a glider stream however wewant by positioning glider guns to navigate gliders around cornersand taking advantage of the dierent glider-glider reactions wehave. From now on we assume we can direct a glider stream to goin whatever direction we want.
35</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>/trianglerightsldSay we have a spaceship on and to the left of the diagonal
line dened by ABCDE on generation 0. If the spaceship can
travel up and to the right faster thanc
4, then cell Xwould be
alive at generation 2.
/trianglerightsldSuppose this is true, and that Xis alive at generation 2.
Then C,U,and Vmust be alive at generation 1. Then Uand
Vmust have had 3 alive neighbors in generation 0, and so
B,C,D,J,a n d Kmust have been alive at time 0. Then C
must have had at least four live neighbors in generation 0, andso couldnt have survived to generation 1. But we needed C
alive at generation 1, and so we have reached a contradiction.
/trianglerightsldIf the spaceship is behind ABCDE at generation 0, it must be
behind UVat generation 2, and so cant travel faster thanc
4.
21</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Computers represent information as signals or bit streams. We can
use a stream of gliders to represent a signal or bit stream as
follows:
Copyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,
and Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
30</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>/trianglerightsldGlider A glider is a simple 5-cell pattern that repeats itself
every 4 generations, but is oset diagonally by one cell. The
smallest and most common spaceship. The glider is going tobe extremely important when we discuss applications of theGame of Life. The glider is said to travel with speed
c
4.
/trianglerightsldSpaceship A pattern that moves across the game board.
(originally Conway found the Light, Medium, and HeavyWeight Space Ship)Image by MIT OpenCourseWare.
10</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Before we get to building our logical parts, lets examine the
dierent reactions we can get when gliders crash into each other.These collisions of gliders will form the building blocks of thereactions that will make up our computer.
We can simluate crashes that result in the following possiblities
(we will actually simulate these in class):
/trianglerightsld(a) Blinker
/trianglerightsld(b) Block
/trianglerightsld(c) Pond
/trianglerightsld(d) Vanishing reaction
31</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>To see an image of a primer, please visit the following 
website: http://www.conwaylife.com/wiki/index.php?title=Primer
26</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>/trianglerightsldA=0 ,B=1
If Bs stream has a glider, it will vanish when it collides withthe glider from G. When the stream gets to A, there will bean empty space, and so the glider stream will continueupwards and get eaten by the eater, E. Therefore the outputA and B will be 0, as expected.
/trianglerightsldA=0 ,B=0If Bs stream has no glider, the stream from the glider gun willcontinue to cross As path. A also has no glider, so the gliderfro the gun continues on to the Eater to be eaten, and the
output of A and B is 0, as expected.
40</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>It is not easy to tell from looking at an initial Life pattern exactly
how it will evolve. For instance, in looking at what happens to astraight line of nlive cells as a start conguration:
/trianglerightsldn=1 ,2: fades immediately
/trianglerightsldn= 3: Blinker
/trianglerightsldn= 4: becomes a Beehive at time 2
/trianglerightsldn= 5: trac lights at time 6
/trianglerightsldn= 6: fades at t=1 2
/trianglerightsldn= 7: makes a symmetric display before terminating in the
Honey Farm (see picture in Winning Ways)
/trianglerightsldn= 8: gives 4 blocks and 4 beehives
/trianglerightsldn= 9: makes two sets of trac lights
/trianglerightsldn= 10: turns into pentadecathlon, with life cycle of 15
/trianglerightsldn= 11: becomes two blinkers
/trianglerightsldn= 12: makes two beehives
/trianglerightsldn= 13: turns into two blinkers
15</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Oscillators of many more periods exist:
9</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>/trianglerightsldGarden of Eden A pattern that can only exist as initial
pattern. In other words, no parent could possibly produce the
pattern.
14</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Theorem
No spaceship can travel diagonally faster thanc
4.
19</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>/trianglerightsldA=0 ,B=0
If both A and B have no gliders, there is nothing to interruptthe path of the rst glider gun. Therefore, gliders from bothof the glider guns will collide and vanish, and therefore themake the output, A or B, be 0, as expected.
43</text>
        </slide>
        <slide>
          <slideno>48</slideno>
          <text>Now let us see how we might actually construct a Turing Machine
from the building blocks of the Game of Life.We will go through slides 61-80 of the Rendell notes in class to see
the construction. We will also show a demo of the TM in action!
49</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>We can also get rid of unwanted glider streams by forming an
eater. T
he eater is able to devour gliders. (see demo in class)
We also note that we can use gliders as the building blocks for
almost all the pieces we will need. For instance, two gliders cancollide to make an eater. Gliders can also collide to make blocks
and ponds, and therefore a whole glider gun!.Image by MIT OpenCourseWare.
37</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>One interesting and surprising application of the Game of Life is
that we can construct an initial pattern that will generate theprime numbers sequentially. The primer below is due to Dick
Hickerson, 1991:
25</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Introduction
The Game of Life is a cellular-automaton, zero player game,
developed by John Conway in 1970. The game is played on aninnite grid of square cells, and its evolution is only determined byits initial state.
2</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>/trianglerightsldThe famous Church-Turing Thesis states that everything
computable is computable by a Turing Machine. This statement
is not proven, but is almost univerally accepted. If it is true, thenTMs have power greater than modern day computers.
/trianglerightsldWe call something Turing-complete if it has rules followed in
sequence that have the same computational power as a TuringMachine.
/trianglerightsldIf we can show that the Game of Life is Turing-complete, then wecan say that Life is as powerful as any computer, and that we can
compute any computational problem using the Game of Life.
48</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>We can use the reactions we learned above to build a logical NOT
gate. If we let one stream of gliders be our bit stream, we caninvert this stream of gliders through the use of a glider gun andvanishing reactions. We can construct and position a glider gunsuch that every space or 0 in our input glider stream allowsone glider to escape from the glider gun, while every glider, or 1
in our input stream collides with the glider from the glider gun to
make a 0. This is illustrated in the image below:
33</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>/trianglerightsldIf a spaceship is on and below the diagonal lines dened by
the solid black squares in generation 0, then we can use theargument above to claim that it must be on or below the linesdened by the striped squares at generation 2. Therefore, it
can move at most 1 square forward every 2 generations, and
so has maximum speed
c
2.
24</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Copyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,
and Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
34</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>Copyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,
and Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
36</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Theorem
No spaceship can travel orthogonally faster thanc
2.
22</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Copyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,
and Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
32</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>/trianglerightsldA=1 ,B=0
If Bs stream has no glider, the glider from the gun willcontinue onward to collide with A, leaving a space to interactwith the second glider gun. Therefore, the glider from thesecond gun will reach the output, making the value of A or B1, as expected.
/trianglerightsldA=0 ,B=1If Bs stream has a glider, it will create a vanishing reactionwith the stream from G, leaving a space for A. A also has no
glider, and therefore there will be no incoming glider to collide
with the glider stream from the second gun, and the outputwill again be 1, as expected.
42</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>/trianglerightsldLoaf:
Image by MIT OpenCourseWare.
7</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Conways Game of Life
Melissa Gymrek
May 2010
1</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>For the orthogonal case consider the following grid:
Courtesy of Nathaniel Johnston. Used with permission. 
23</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Here we show (glossing over some of the details) how we could use
t h eG a m eo fL i f et om a k ef u n c t i o n i n gl o g i cg a t e sa n dp e r f o r moperations on bit streams.
29</text>
        </slide>
        <slide>
          <slideno>45</slideno>
          <text>Each state transition rule species:
/trianglerightsldThe current state
/trianglerightsldThe symbol read from the current cell
/trianglerightsldThe state to move to
/trianglerightsldThe symbol to write to the current cell
/trianglerightsldThe direction to move the machine along the tape
46</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>For the AND gate, we position our two glider streams that we are
ANDing perpendicular to the line of re of a glider gun, with aneater to eat up unwanted gliders. Let us go through all possiblecases and see why this gives us an AND gate.
/trianglerightsldA=1 ,B=1If Bs stream has a glider, it will vanish when it collides withthe glider from G. When the stream gets to A, As glider willbe able to pass through where the vanishing reaction left a
hole, making the value of A and B 1, as expected.
/trianglerightsldA=1 ,B=0
If Bs stream has no glider, the glider from the gun will reacha collision point with As glider and cause a vanishingreaction, making the output of A and B 0, as expected.
39</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>/trianglerightsldThe primer res a light weight space ship westward, and
destroys the spaceships with gliders from a gun that simulatesthe Sieve of Eratosthenes.
/trianglerightsldThe light weight spaceship makes it past the left edge of thegun at generation 120 Nif and only if Nis a prime number.
/trianglerightsldThere are extensions of the primer that can be used to
generate twin primes, Fermat primes, and several others.
28</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>/trianglerightsldTherefore, using these parts, we could construct a slow and
primitive, but functioning, computer out of the Game of Life. TheGame of Life exhibits a property we call universality , meaning that
it can theoretically compute anything that can be computed.
/trianglerightsldFor more details on how exactly we could construct a computerfrom the Game of Life, see Winning Ways.
44</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>Copyright (2001). From Winning Ways for Your Mathematical Plays, Vol. 4 by Elwyn R. Berlekamp,John H. Conway,
and Ricard K. Guy. Reproduced by permission of Taylor and Francis Group, LLC, a division of Informa plc.
38</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>/trianglerightsldOn each time step, the Turing Machine (TM) reads from the
current cell on the tape, nds the appropriate transition rule thatmatches the current state and symbol just read, then changes tothe specied new state, writes the specied symbol, and moves themachine in the specied direction.
/trianglerightsldHere in class we will go through an example Turing machinecalculation (slides 37-54 of Rendell slides)
47</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>/trianglerightsldBoat:
/trianglerightsldShip:Image by MIT OpenCourseWare.
Image by MIT OpenCourseWare.
6</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>/trianglerightsldn=1 4 ,15: vanish completely
/trianglerightsldn=1 6 ,17: becomes 4 blocks
/trianglerightsldn=1 8 ,19: vanish completely
/trianglerightsldn= 20: makes 2 blocks
16</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Before describing how the primer works, we describe the Sieve of
Eratosthenes . The sieve is a simple ancient algorithm for nding
all prme numbers up to a specied integer. The algorithm is as
follows:
/trianglerightsldCreate a list of consecutive integers from 1 to n.
/trianglerightsldSet p=2( t h e r s tp r i m e )
/trianglerightsldCross out all multiples of pgreater than p.
/trianglerightsldFind the rst number still left that is greater than p.
/trianglerightsldRepeat steps 3 and 4 until p2is greater than n.
/trianglerightsldAll he remaining numbers on the list are prime.
27</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>T h er u l e so ft h eg a m ea r es i m p l e ,a n dd e s c r i b et h ee v o l u t i o no ft h e
grid:
/trianglerightsldBirth: a cell that is dead at time twill be alive at time t+1
if exactly 3 of its eight neighbors were alive at time t.
/trianglerightsldDeath : a cell can die by:
/trianglerightsldOvercrowding : if a cell is alive at time t+1a n d4o rm o r eo f
its neighbors are also alive at time t, the cell will be dead at
time t+1 .
/trianglerightsldExposure : If a live cell at time thas only 1 live neighbor or no
live neighbors, it will be dead at time t+1 .
/trianglerightsldSurvival : a cell survives from time tto time t+1i fa n do n l y
if 2 or 3 of its neighbors are alive at time t.
3</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Connect Four and additional AI topics</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses5_confour/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
Well explore possible strategies to follow for Connect Four below. After 
describing a set of general rules to follow, we will see a new type of search, 
conspiracy number search, related to the pn-search technique from last week. 
First well learn some terminology associated with describing the strategy. 
Nomenclature We will number the 7 x 6 board with columns a to g left to right and 
numbers 1 to 6 from bottom to top. So the coveted middle bottom 
square is d1. 
Threat A threat is a square that if taken by opponent forms a game-winning 
group of four. For example, in the game board below White has threats 
at b1 and f1. 
Useless Threat A useless threat is a threat that will never be able to be carried out
3 Courtesy of Victor Allis. Used with permission. Figure 3.9 in "A Knowledge-based Approach of 
Connect-Four. The Game is Solved: White Wins." Master's Thesis, Vrije University, 1988, pp. 22.ES.268</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
Note that all columns contain an even number of pieces, so White will 
never ll up a column since it must take only odd squares. So Black 
can just play follow-up and mimic Whites every move. This will result in the following position: 
Now White must play either b1 or f1, which Black will follow, and win the game with a group of four on the second row. 
So in conclusion, Zugzwang involves being able to divide up how even 
and odd squares are distributed to the two players. Black wanted only 
even squares because eventually it would be able to fulll its threat at either b2 or f2. But if it had wanted odd squares, it could have just 
stopped playing follow up and played in a dierent column. 
Rules 
As an example of using a knowledge based approach to teach a computer to play a game, the following rules were used in programming VICTOR to 
6 Courtesy of Victor Allis. Used with permission. Figure 4.2 in "A Knowledge-based Approach of 
Connect-Four. The Game is Solved: White Wins." Master's Thesis, Vrije University, 1988, pp. 25.
Courtesy of Victor Allis. Used with permission. Figure 4.3 in "A Knowledge-based Approach of Connect-Four. The Game is Solved: White Wins. " Master's Thesis, Vrije University, 1988,  p 
p. 26.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
win connect four. Each rule classies threats and gives solutions to some of 
them. Each rule is valid for the player that controls the Zugzwang, which is assumed to be black in the following examples. Each of these rules is a 
possible winning connection for the player. 
Claimeven Controller of zugzwang can get all empty even squares which are not 
directly playable by letting the opponent play all empty odd squares. 
Required: Two squares, directly above each other. Both squares are 
empty, the upper square must be empty. 
Solutions: All groups which contain the upper square. 
Baseinverse Based on the fact that a player cannot play two directly playable 
squares in one turn. Required: Two directly playable squares Solutions: All groups which contain both squares. 
Vertical Based on the face that a player cannot play two men in the same col
umn in one turn, while by playing one man in the column, the square 
directly above becomes immediately playable. 
Required: two squares directly above each other. Both squares empty, 
upper square must be odd. 
Solutions: all groups which contain both squares 
Aftereven Side-eect of one or more claimevens. If a player in control of zugzwang 
can complete a group using squares from claimeven, he will eventually 
be able to nish the group. 
Required: a group which can be completed by the controller of the 
zugzwang, using only squares of a set of claimevens. 
Solutions: all groups which have at least one square in all aftereven 
column,s above the empty aftereven group in that column. Also, all 
groups which are solved by the claimevens. 
7 ES.268</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
Solvability  
When looking for a strong solution to a game (recall from last time that 
a strong solution means knowing the outcome of the game from any given 
board position) one strategy to try would be storing all possible game posi
tions in a database, exploring the tree of game play from each position, and 
determining the winner in each case. We will see that this strategy, at least 
at this time, is not really feasible for Connect Four (and even much less so for more complex games like GO and chess...). 
First we look for an upper bound on the number of possible Connect Four 
board positions. Each grid square can be in one of 3 states: black, white, 
or empty. Since there are 7x6 = 42 squares, this gives a very crude upper 
bound of 3
42  1020 . A not so much closer look reveals that we can get a 
much tighter upper bound by noticing that many positions we counted before were illegal. For instance, if one square is empty in a column, then all the squares above it must also be empty. So we throw these possible positions 
out. Removing these congurations gives a better upper bound of 7 .1 10
13 
possible positions. 
There are other types of illegal positions that are harder to detect. For 
instance, if we are assuming that white moves rst, then some game cong
urations, such as a stack in one column from bottom up of BWBWBW is 
impossible, since black would have had to move rst. It turns out that no one has been able to weed out all of these positions from databases, but the 
best lower bound on the number of possible positions has been calculated by 
a computer program to be around 1 .6 10
13 . So we would need at least  that 
man
y positions stored to do a brute force search of the game. That would 
take an estimated 4 Terabytes of memory. Not so practical... 
As we saw last time with the tic-tac-toe example, this strategy wont al
ways work. In general, we must classify these sorts of rules into two classes: 
	Rules that guarantee a certain results (and require proof that they do 
so) 
	Heuristic rules that are generally advantageous but are not without downfall (like the strategy given above) 
2 ES.268</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
Lowinverse Based on the face that the sum of two odd numbers is even. 
Required: two dierent columns, each with 2 squares lying directly 
above each other. All must be empty and the upper square must be 
odd. 
Solution: All groups which contain both upper squares, all groups 
which are solved by verticals. 
Highinverse Based on the same principle as lowinverse: 
Required: Two columns which 3 empty squares each, upper square is even. 
Solutions: all groups which contain the two upper squares, groups 
which contain the two middle squares, all vertical groups which contain 
the two highest squares of one of the highinverse columns 
If the lower square of the rst columns is directly playable: all groups 
which contain both he lower square of the rst column and the upper 
square of the second. 
If the lower square of the second column is directly playable: all groups 
which contain both the lower square of the second column and the 
upper square of the rst column. 
Baseclaim Combination of two basinverses and a claimeven. 
Required:Three directly playable squares and the square above the second playable square. The non-playable square must be even. 
Solutions:Solutions: All groups which contain the rst playable square 
and the square above the second playable square. All groups which 
contain the second and third playable square. 
Before Based on a combination of claimevens and verticals 
Required: A group without men of the opponent, which is called the 
Before group. All empty squares of the Before group should not lie in 
8 ES.268</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
if (P == E mptySet) { 
Eureka() /* W e have found a subset C which meets all constraints. */ 
} else { 
M
ostDifficultNode = No deWithLeastNumberOfNeighbours(P); 
for (all ne ighbours of MostDifficultNode) { 
FindChosenSet(P - { M ostDifficultNode }, 
S - AllNeighboursOf(ChosenNeighbour)); 
} 
} 
} 
Conspiracy Number Search 
The actual solution to connect four was arrived at using the above methods 
combined with search tables storing the values of dierent game positions 
as well as using traditional game search methods. In particular, Allis used 
conspiracy-number search , which is very closely related to the proof num
ber search that we talked about last week. In the instance of connect four, consider three types of nodes: -1 black can at least draw the game, 1 the game is a win for white, or 0 the game is as yet undecided. Now any node 
that has as a child a node with a value of 1 can be colored 1. Any node that 
has all nodes colored -1 can be colored -1. Note it is much easier to change 
a node to a 1 than a -1. 
The conspiracy number of a node is a tuple of counts for the number of 
chi
ldren needed to conspire to change the value of the node to each of the 
possible values. Let (x, y) be the conspiracy number of a node, with x the 
number of nodes that need to conspire to change the value to 1, and y to 
-1. We know x will always be 1, since we only need one child of value 1 to 
change our value to 1. But y is the number of ones of the node yet to be 
evaluated if all those evaluated so far have been -1. If sons have already been 
evaluated to 1, then y is . 
The purpose of conspiracy number search, like pn-search is to evaluate as few 
nodes as possible to nd the result of the game tree. Therefore, we try 
to avoid evaluating nodes with large conspiracy numbers. If we want to eval
uate a node at the top of the tree, we choose the neighbors with the lowest 
11 FindChosenSet(P, S) 
{
 
Courtesy of Victor Allis. Used with permission. In "A Knowledge-based Approach of Connect-Four. 
The Game is Solved: White Wins." Master's Thesis, Vrije University, 1988, pp. 59. ES.268</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
odds). So if we get to the last column and White has an even threat 
and Black has an odd threat, the game will end in a draw. 
If White has an odd threat and Black has an even threat in the same col
umn, the lower threat will win. If the threats are in dierent columns, 
Whites is stronger. In general, we see the following patterns: 
	White has an odd threat, Black even: White wins 
	White and Black both have even threats: there is no column where 
an odd number of squares can be played, so both players will get 
their normal squares (as dened above), and Black will be able to 
refute Whites threat and win. 
	White has an even threat, Black an odd threat: draw. 
	White and Black both have odd threats: usually neither of these threats end up working and depend on other threats. 
In a careful analysis of threats it is important to make sure that taking care of one threat does not allow another threat to be created. 
Zugzwang The formal denition of this strange German word: a situation where 
a player is forced to make a move when he would rather make no move at all. 
In connect four, a player is able to control the zugzwang if the player 
is able to guide the way odd and even squares are divided up among 
players. 
As an example, we look at the following game situation (Allis 26), 
where White is about to move: 
5 ES.268</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
lutions are assembled as nodes into an undirected graph, where two nodes 
are connected if and only if they cant be used simultaneously. These connections are stored in an adjacency matrix. Then, the problems (threats) are 
added as nodes, and solutions are connected with problems if they solve the 
problem (no problems are connected). 
Note that two rules might not necessarily be able to be used at the same 
time. The following table describes the relationships between rules (taken 
from Allis, section 7.4): 
Then we solve the following problem: 
Given: Two sets of nodes, S(olutions) and P (roblems). Try to nd an in
dependent subset C of S with the property that P is contained in the set 
of all neighbors of C, B(C). (Note this is a potentially NP-complete problem) 
The following recursive algorithm was used by Allis: 
10 Courtesy of Victor Allis. Used with permission. In "A Knowledge-based Approach of Connect-Four. 
The Game is Solved: White Wins." Master's Thesis, Vrije University, 1988, pp. 50. ES.268</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
by the opponent. Note that a threat can only be carried out if the 
opponent is forced to play the square below the threat. 
The picture below illustrates the concept of a useless threat. In this 
game, it is Whites turn to move. It appears that White has threats 
at b2, b3, b4, b5, b6, f2, f3, f4, f5, and f6. But Black has threats at 
b2, b6, f2, and f6. Clearly the lower numbered squares will be lled in rst, and so since both White and Black have threats at b2 and f2, no 
other threats matter, since they are all above threats shared between 
players. So all squares but b2 and f2 are useless threats. 
Odd and Even Threats It is clear that a threat can only be carried out if the opponent is forced 
to play the square below (or he allows you to play below the threat). 
In analyzing threats, certain patterns show up in how the squares are 
dividing among players. 
The odd/evenness of a threat is determined by the row number. So d1 is an odd threat, etc. If we were to just ll up the board, for the 
most part, White will get the odd squares and Black will get the evens. 
Clearly, White starts with an odd square (1). Say we have lled up 
the entire board except the last column. If play continues until the 
board is lled up, it must be true that White will get the remaining odd squares and Black the remaining evens: we must end with Black, 
since play alternates between players and there are an even number of 
squares, and so black must get the top (6), white must get 5, etc. This even/odd pattern continues throughout the game in general (of course 
it is possible for White to get some even squares and Black to get some 
4 Courtesy of Victor Allis. Used with permission. Figure 3.1 in "A Knowledge-based Approach of Connect-Four. 
The Game is Solved: White Wins." Master's Thesis, Vrije University, 1988, pp. 16.ES.268</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Intro to A.I. T opics
Connect Four 
March 12, 2009 
Introduction 
Connect Four is a tic-tac-toe like game in which two players drop discs into 
a 7x6 board. The rst player to get four in a row (either vertically, horizon
tally, or diagonally) wins. 
The game was rst known as The Captains Mistress, but was released 
in its current form by Milton Bradley in 1974. In 1988 Victor Allis solved 
the game, showing that with perfect play by both players, the rst player can always win if he plays the middle column rst, and if he chooses another 
column rst the second player can always force a draw. 
Today we will explore the dierent strategies involved in playing connect 
four, how a computer could emulate these strategies, and how these techniques relate to other articial intelligence topics involved in solving games 
with large search spaces. 
For convenience, we will call the rst player white (W) and the second player 
black (B). 
Note that we initially get somewhat detailed about game situations, but 
do not get bogged down in the details. The important part is how we will use t
he fact that these details exist to make a game-winning strategy. 
1</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
conspiracy numbers to evaluate until we are sure of their value. We move up 
the tree in this way, whenever possible avoiding evaluating nodes with large conspiracy numbers. 
12 ES.268</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Connect Four / Intro to A.I. and Board Representation
the upper row of the board. 
Solutions:All groups which contain all squares which are successors of 
empty squares in the Before group. All groups which are solved by the 
Verticals which are part of the Before. All groups which are solved by 
the Claimevens which are part of the Before 
Specialbefore A version of the before 
Required: A group without men of the opponent, which is called the 
Specialbefore group. A directly playable square in another column. All empty squares of the Specialbefore group should not lie in the up
per row of the board. One empty square of the Before group must be 
playable. 
Solutions: All groups which contain all successors of empty squares 
of the Specialbefore group and the extra playable square. All groups 
which contain the two playable squares. All groups which are solved 
by one of the Claimevens. All groups which are solved by one of the Verticals. 
Computer  Solution Implementation  
Victor Alliss program VICTOR developed a method of nding an optimal 
strategy based on the 9 rules given above. The position evaluator (white or 
black) is given a description of the board and comes up with an optimal next move. 
First all possible instances of the nine rules above are found and checked 
against all 69 possibilities to connect winning groups. The rule applications 
that solve at least one problem are stored in a list of solutions with a list of 
the groups solved by the solution and a list of other solutions that can be 
used to solve the problem. 
The next step is nding which solutions can work together. First all so
9 ES.268</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Theory of impartial games</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses1_theory/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>- The Mathematics of Toys and Games
The Game of Nim 
We rst look at the simple game of Nim, which led to some of the biggest 
advances in the eld of combinatorial game theory. There are many versions 
of this game, but we will look at one of the most common. 
How To Play 
There are three piles, or nim-heaps , of stones. Players 1 and 2 alternate 
taking o any number of stones from a pile until there are no stones left. 
There are two possible versions of this game and two corresponding winning 
strategies that we will see. Note that these denitions extend beyond the 
game of Nim and can be used to talk about impartial games in general. 
	Normal  Play The player to take the last stone (or in general to make 
the 
last move in a game) wins. This is called normal play since most 
impartial games are played this way, although Nim usually is not. 
	Misere Play The player that is forced to take the last stone loses. 
An e
xample normal play game is shown below: 
Sizes of heaps Moves 
A B C 
3
4 5 I
tak e 2 from A 
1 4 5
 You t ake 3 from C 
1 4 2 Itak e 1 from B 
1 3 2
 You t ake 1 from B 
1 2 2
 I take entire A heap le aving two 2s. 
0 2 2 You t ake 1 from B 
0 1 2
 I take 1 from C l eaving tw o 1s. 
0 1 1 You t ake 1 from B 
0 0 1
 I take entire C heap an d win. 
What 
is your winning strategy? Luckily, we can nd one. Nim has been 
solved (we use the term solved loosely here, but there are several categories of solutions to games) for all starting positions and for any number of 
heaps. 
2 ES.268</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Theory of Impartial Games 
February 3, 2009 
Introduction 
Kinds of Games Well Discuss 
Much of the game theory we will talk about will be on combinatorial 
gam
es which have the following properties: 
	T
here are two players. 
	There is a nite set of positions available in the game (only on rare 
occasions will we mention games with innite sets of positions). 
	Rules specify which game positions each player can move to. 
	Players alternate moving. 
	The game ends when a player cant make a move. 
	The game eventually ends (its not innite). 
Today well mostly talk about impartial  games. In this type of game, the 
set of allowable moves depends only on the position of the game and not on which of the two players is moving. For example, Nim, sprouts, and green hackenbush are impartial, while games like GO and chess are not (they are 
called partisan ). 
1</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>- The Mathematics of Toys and Games
First well look at dierent types of game positions, then well do some work 
with nimbers (yes, that really is a word) and then apply them to nding a solution to Nim. 
Types of impartial game positions 
	A game is in a P-position if it secures a win for the Previous player 
(the one who just moved). 
	A game is in a N-position if it secures a win for the Next player. 
So in normal play Nim with three heaps, (0,0,1) is an N-position and (1,1,0) 
is a P-position. We call the position from which no possible moves are left a 
terminal position . 
To 
nd whether a Nim position is N or P, we work backwards from the 
end of the game to the beginning in a process called backwards  induction 
: 
1.	La
bel every terminal position as P. 
2.	Label every position that can reach a P position as N. 
3.	For positions that only move to N positions, label P. 
4. At this point either all positions are labeled or return to step 2 and repeat the process until all positions are labeled. 
For misere play, just invert step 1: every terminal position is N. 
Applying these rules to Nim, we rst set the only terminal position (in other 
games there could be many) 0,0,0, to P. It is obvious that any position (0,0, n) 
is an N position, since the next player can just take the last heap in one turn. 
Practice With N and P
  positions  
C
on
sider the subtraction game in which you start with a pile of chips and 
players alternate taking away any number si from the set S = {1, 3, 4} of 
ch
ips from the heap. The player to take the last chip loses. 
3 ES.268</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>- The Mathematics of Toys and Games
---------We can see that 1, 3 and 4 must be N-positions, since the next player can 
just take all of the chips. 0 must be a P-position of course, since the player that moved to 0 wins. 2 must be a P position since the only legal move is to 
an N-position. Then 5 and 6 must be N since they can be moved to 2. If we 
continue analyzing the game in this manner we get the following sequence of 
N and P positions: 
x 0 1 2 3
  4 5 6 7 8 9 10 11 12 13 14 
pos P N P  N N N N P N P N N N N P 
This period sequence of Ns and Ps (PNPNNNN) continues forever. In fact, 
almost all subtraction games have such periodic sequences of N and P values. 
Nimber Arithmetic  
The key operation in the solution to Nim is binary addition without carrying. To add two numbers in this manner, rst write out their binary expansions, 
and then take the exclusive or (XOR) of the two numbers bit by bit. The 
following is an example: 
3 011 
+5 100 
7 11
1 
In t
he XOR operation, 1+1= 0 = 0+0, 1+0=1=1+0. Another way to look 
at it is that if you are adding an odd number of ones the answer is 1, an even 
number of ones gives 0. We will write this kind of addition of two numbers 
x and y as x y. 
B
el
ow is an addition table for nimbers: 
4 ES.268</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>AI and game search</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/es-268-the-mathematics-in-toys-and-games-spring-2010/resources/mites_268s10_ses4_ai/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>16</slideno>
          <text>AI Techniques For Solving Games
When we get to a leaf, we will have (pn,dn) either (0, ), (, 0), or (1,1), 
s
ince the game is either a sure win or sure loss at that point, with itself as 
its proof set. The tree is considered solved when either pn = 0 (the answer 
is true) or dn = 0 (the answer is false) for the root node. 
When we take a step back and think about it, an AND/OR tree is very 
much a minimax tree. The root starts out as an OR node. So the rst player has his choice of options, and he will pick one that allows his root node to 
evaluate to true. The second player must play at an AND node: unless he 
can make his node T no matter what, (so F for player 1), then player one 
will just take one of the favorable options left for him. So an AND/OR tree 
is just a min/max tree in a sense, with ORs replacing the MAX levels and AND replacing the MIN levels. 
PN search is carried out using the following rough outline: 
1. Expand nodes, update pn and dn numbers. 
2. Take the node with the lowest pn or dn, propagate the values back up 
until you reach the root node 
 . 
3. Repeat until the root node has pn=0 or dn = 0. 
The slightly tricky part of this is the second step. What we really want to nd is the Most Proving  Node . 
 Formally, this is dened as the frontier 
node of an AND/OR tree, which by obtaining a value of True reduces the trees pn value by 1, and obtaining a value of False reduces the dn by 1. 
So evaluating this node is guaranteed to make progress in either proving or 
disproving the tree. 
An important observation is that the smallest proof set to disprove a node 
and the smallest proof set to prove a node will always have some nodes in common. That is, their intersection will not be empty. Why is this? In a 
brief sketch of a proof by contradiction, assume for the contrary that they 
had completely disjoint sets of nodes. Then we could theoretically have a 
complete proof set and a complete disproof set at the same time. But we 
c
annot both prove and disprove a node! So the sets must share some nodes 
in common. 
17 ES.268</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Introduction to AI T echniques
Game Search, Minimax, and Alpha Beta Pruning 
June 8, 2009 
Introduction 
One of the biggest areas of research in modern Articial Intelligence is in 
making computer players for popular games. It turns out that games that 
most humans can become reasonably good at after some practice, such as 
GO, Chess, or Checkers, are actually dicult for computers to solve. 
In exploring how we could make machines play the games we play, we are 
forced to ask ourselves how we p lay those games. Although it seems that 
humans use some notion of intelligence in playing a game like chess, our approaches in solving such games have not progressed much farther than the 
sort of brute force approaches that we experimented with in the 50s. Unfortunately, present computer players usually rely on some sort of search over 
possible game outcomes to nd the optimal move, rather than using what 
we would deem intelligent behavior. 
In this discussion we will see some of the ideas behind these computer play
ers, as well as future directions the eld might take, and how these computer 
approaches can both help us learn to play the games better as well as point 
out some fundamental dierences between human play and machine play. 
As a quick time line to show how (not very) far we have come since Claude 
Shannons (a famous MIT professor, the father of Information Theory, etc.) 
Programming  a
 Computer P laying C hess, 1 948 : 
 1
948 Claude Shannon 
1</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>AI Techniques For Solving Games
Note that we are assuming a nite branching factor, or in other words, each 
player has only nitely many options open to them when it is his or her turn. 
Implementation  
As we have said over and over again, actually implementing these huge game trees is often a huge if not impossible challenge. Clearly we cannot search 
all the way to the bottom  of a search tree. But if we dont go to the bottom, 
h 
ow will we ever know the value of the game? 
The answer is we dont. Well, we guess. Most searches will involve search
ing to some preset depth of the tree, and then using a static  evaluation 
fu
nction  to guess the value of game positions at that depth. 
U
sing an evaluation function is an example of a heuristic approach to solv
i
ng the problem. To get an idea of what we mean by heuristic, consider the 
following problem: Robby the robot wants to get from MIT to Walden Pond, but doesnt know which roads to take. So he will use the search algorithm 
he wrote to explore every possible combination of roads he could take lead
ing out of Cambridge and take the route to Walden Pond with the shortest 
distance. 
This will work... eventually. But if Robby searches every possible path, 
some other paths will end up leading him to Quincy, some to Providence, 
some to New Hampshire, all of which are nowhere near where he actually 
wants to go. So what if Robby renes his search. He will assign a heuristic 
value, the airplane (straight line) distance to each node (road intersection), and direct his search so as to choose nodes with the minimum heuristic value 
and help direct his search toward the goal. The heuristic acts as an estimate 
that helps guide Robby. 
Similarly, in game search, we will assign a heuristic value to each game state 
node using an evaluation function specic to the game. When we get as far 
as we said we would down the search tree, we will just treat the nodes at 
that depth as leaves evaluating to their heuristic value. 
12 ES.268</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>AI Techniques For Solving Games
would nd the optimal strategy by applying minimax to the tree. 
Alpha-Beta  Pruning 
While the minimax algorithm works very well, it ends up doing some extra 
work. This is not so bad for Helen and Stavros, but when we are dealing 
with trees of size 3640 we want to do as little work as possible (my favorite 
motto of computer scientists... we try to be as lazy as possible!). 
In the example above, Helen really only cares about the value of the node 
at the top, and which outgoing edge she should use. She doesnt really care 
a
bout anything else in the tree. Is there a way for her to avoid having to 
look at the entire thing? 
To evaluate the top node, Helen needs values for the three nodes below. 
So rst she gets the value of the one on the left. (we will move from left to 
right as convention). Since this is the rst node shes evaluating, there arent 
really any short cuts. She has to look at all the nodes on the left branch. 
So she nds a value of 7 and moves on to the middle branch. After looking 
at the rst subbranch of her B option, Helen nds a value of 7. But what happens the next level up? Stavros will try to minimize the value that Helen 
maximized. The left node is already 7, so we know Stavros will not pick 
anything greater  than 7. But we also know Helen will not pick anything in 
t 
he middle branch less than 7. So there is no point in evaluating the rest of 
t
he middle branch. We will just leave it at 7: 
Helen then moves on to the rightmost branch. She has to look at the 10 and
the 11. She also has to look at the 2 and 15. But once she nds the 15, she
knows that she will make the next node up at least 15, and Stavros is going
9 ES.268</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>AI T echniques For Solving Games
Evaluation  Functions  
Evaluation functions, besides the problem above of nding the optimal or
dering of game states to explore, is perhaps the part of game search/play 
that involves the most actual thought (as opposed to brute force search). 
These functions, given a state of the game, will compute a value based only 
on the current state, and cares nothing about future or past states. 
As an example evaluation, consider one of the type that Shannon used in 
his original work on solving chess. His function (from Whites perspective) calculates the value for white as: 
	+1 for each pawn 
	+3 for each knight or bishop 
	+5 for each rook 
	+9 for each queen 
	+ some more points based on pawn structure, board space, threats, 
etc. 
it then calculates the value for black in a similar manner, and the value of the game state is equal to Whites value minus Blacks value. Therefore the 
higher the value of the game, the better for white. 
For many games the evaluation of certain game positions have been stored in 
a huge database that is used to try to solve the game. A couple examples 
are: 
	OHex - partial solutions to Hex games 
	Chinook - database of checkers positions 
As you can see, these functions can get quite complicated. Right now, eval
uation functions require tedious renements by humans and are tested rig
orously through trial and error before good ones are found. There was some 
work done (cs.cmu.edu/ jab/pubs/propo/propo.html) on ways for machines to learn evaluation functions based on machine learning techniques. If ma
chines are able to learn heuristics, the possibilities for computer game playing 
13 ES.268</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
ES.268 The Mathematics in Toys and Games
Spring 2010
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>AI Techniques For Solving Games
will be greatly broadened beyond our current pure search strategies. 
Later well see a dierent way of evaluating games, using a class of num
bers called the surreal numbers, developed by John Conway. 
Solving a G ame 
We often talk about the notion of solving a game. There are three basic types of solutions to games: 
1. Ultra-weak  The result of perfect play by each side is known, but the 
s 
trategy is not known specically. 
2. Weak  The result of perfect play and strategy from the start of the 
g
ame are both known. 
3. Strong  The result and strategy are computed for all possible positions. 
How far do we need to Search? 
How far do we need to search down the tree for our computer player to be successful? Consider the following graph (the vertical axis is a chess ability 
score): 
(taken from 6.034 coursenotes).
Deep Blue used 32 processors, searched 50-10 billion moves in 3 minutes, and
looked at 13-30 plys per search.
Clearly, to approach the chess -playing level of world champion humans,
14 ES.268</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>AI Techniques For Solving Games
people. Maybe exciting for the hardware guys that build faster pro
cessors and smaller memory to that we have the computational power to solve these games, but other than that not very cool... It would be 
much more exciting to come up with a thinking player. 
So what should we do? We cant use just simple rules, but only using search doesnt really work out either. What if we combine both? This is what is done 
most of the time. Part of the game tree is searched, and then an evaluation, a kind of heuristic (to be discussed more soon) is used. This approach works 
relatively well, and there is a good deal of intelligence needed in designing 
the evaluation functions of games. 
Games  as Trees  
For most cases the most convenient way to represent game play is on a graph. We will use graphs with nodes representing game states (game position, 
score, etc.) and edges representing a move by a player that moves the game 
from one state to another: 
Using these conventions, we can turn the problem of solving a game into a 
version of graph search, although this problem diers from other types of 
graph search. For instance, in many cases we want to nd a single state in 
a graph, and the path from our start state to that state, whereas in game 
search we are not looking for a single path, but a winning move. The path we take might change, since we cannot control what our opponent does. 
Below is a small example of a game graph. The game starts in some ini
tial state at the root of the game tree. To get to the next level, player one 
chooses a move, A, B, C, or D. To get to the next level, player two makes a move, etc. Each level of the tree is called a ply. 
4</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>AI Techniques For Solving Games
If we assign all the leaves to values (T)rue or (F)alse, we can move up the 
tree, evaluating each node as either the AND of its leaves or the OR of its 
leaves. Eventually we will get the value of the root node, which is what we are looking for. 
For any given node, we have the following denitions: 
	PN-number : The proof number of a node is the minimum number of 
children nodes required to be expanded to prove the goal. 
	AND: pn = (pn of all the children nodes) 
	OR: pn = (argmin(pn of children nodes)) 
	DN-number : The disproof number is the minimum number of chil
dren nodes required to disprove the goal. 
	AND: dn = argmin(dn of children nodes) 
	OR: dn = (dn of children nodes) 
16 ES.268</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>AI Techniques For Solving Games
	1951 Alan Turing works out a plan on paper for a chess-playing com
puter program. 
	1966-1967 Mac Hack 6, developed at MIT, rst chess program to beat a person in tournament play 
	1997 Deep Blue beats Kasparov, the reigning world chess champion at the time, in a best out of 6 match. This was seen as a landmark in the chess program world, but really Deep Blue was just like previous 
chess playing machines with bigger and better computing power, and 
no more intelligence than any previous model. 
Well-known Players  
Th
e most popular recent game to be solved is checkers, which had up to 200 
processors running night and day from 1989 to 2007. Checkers has 5  1020 
possible positions on its 8 by 8 board. It is now known that perfect play 
by each side results in a draw. You can play around with the database on 
the Chinook projects website: The 
game is strongly solved, and for every move Chinook tells you whether it 
leads to a winning strategy, a losing strategy, or a draw. 
Another famous computer player is Deep Blue, who beat chess world champio
n Garry Kasparov in 1997, which was capable of evaluating 200 million 
positions per second. 
How To Solve a G ame? 
What if we just give the computer simple rules to follow in what is known as a knowledge based  approach . 
 This is how a lot of beginner and sometimes 
advanced human players might play certain games, and in some games it actually works (well take a closer look using Connect Four next time). Take the following rules for tic-tac-toe, for instance. You give it the following 
instructions to blindly follow in order of importance: 
1.	If there is a winning move, take it. 
2. If your opponent has a winning move, take the move so he cant take 
it. 
2 http://webdocs.cs.ualberta.ca/~chinook/.ES.268</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>AI Techniques For Solving Games
So if we are player one, our goal is to nd what move to take to try to ensure 
we reach one of the W states. Note that we cannot just learn a strategy 
and specify it beforehand, because our opponent can do whatever it wants 
and mess up our plan. 
When we talk about game graphs some terms you might want to be familiar with are: 
 Branching  factor (
 b) 
Th
e number of outgoing edges from a single node. In a game graph, 
this corresponds to the number of possible moves a player can make. So for instance, if we were graphing tic-tac-toe, the branching factor 
would be 9 (or less, since after a person moves the possible moves are limited, but you get the idea) 
 Ply 
A l
evel of the game tree. When a player makes a move the game 
tree moves to the next ply. 
 Depth (d) 
Ho
w many plys we need to go down the game tree, or how many moves 
the game takes to complete. In tic-tac-toe this is probably somewhere around 6 or 7 (just made that up...). In chess this is around 40. 
5</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>AI Techniques For Solving Games
Helen maximizes:
So Helen should choose option C as her rst move. 
This game tree assumes that each player is rational, or in other words they 
are assumed to always make the optimal moves. If Helen makes her decision 
based on what she thinks Stavros will do, is her strategy ruined if Stavros 
does something else (not the optimal move for him)? The answer is no! Helen is doing the best she can given Stavros is doing the best he can. If Stavros 
doesnt do the best he can, then Helen will be even better o! 
Consider the following situation: Helen is smart and picks C, expecting that 
after she picks C that Stavros will choose A to minimize Helens score. But 
then Helen will choose B and have a score of 15 compared to the best she 
could do, 10, if Stavros played the best he could. 
So when we go to solve a game like chess, a tree like this (except with many 
more nodes...) would have leaves as endgames with certain scores assigned 
to them by an evaluation function (discussed below), and the player to move 
8 ES.268</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>AI Techniques For Solving Games
3.	Take the center square over edges and corners. 
4.	Take corner squares over edges. 
5.	Take edges if they are the only thing available. 
Lets see what happens when the computer plays this game (picture taken 
from Victor Alliss Connect Four Thesis): 
This approach clearly will not always work. There are so many exceptions to 
rules that for a game like chess enumerating all the possible rules to follow 
would be completely infeasible. The next logical option to try is search. If a 
player could predict how the other player would respond to the next move, and how he himself would respond to that, and how the next player would 
respond next, etc., then clearly our player would have a huge advantage and 
would be able to play the best move possible. So why dont we just build 
our computer players to search all the possible next moves down the game 
tree (which we will see in more detail soon) and chooses the best move from these results? I can think of at least two of many good reasons: 
	Complexity - As we will see below, if a game oers players b di erent 
possible moves each turn, and the game takes d moves total, then 
the possible number of games is around bd . Thats an exponential 
search space, not looking good! For tic-tac-toe, there are about 255,168 possible games. Denitely reasonable. But for chess, this number is around 36
40, something like more than the number of particles in the 
universe. No good. 
	Its not intelligence! Brute computational force is not exactly intell
gie
nce. Not very exciting science here, at least not for us theoretical 
3 Courtesy of Victor Allis. Used with permission. Figure 2.5 in "A Knowledge-based Approach of 
Connect-Four. The Game is Solved: White Wins." Master's Thesis, Vrije University, 1988, pp. 14.</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>AI Techniques For Solving Games
What we get out of all of this is that we dont really have to decide whether 
we will work on proving or disproving the root node, as we can make progress doing both. So now we can be certain of what we will do at each step of the 
algorithm. The revised step 2 from above is: 
At an OR level, choose the node with the smallest pn to expand. At an 
AND level, choose the node with the smallest dn to expand. 
The tree below is an example of pn search, taken from Victor Alliss Search
ing for Solutions,  in which R is the most-proving node. 
Others 
I will just briey mention a couple of other variations on game search that have been tried, many with great success. 
	Alpha-beta, choosing a constrained range for alpha and beta before
han
d. 
	Monte Carlo with PN search: randomly choose some nodes to expand, and 
then perform pn-search on this tree 
	Machine learning of heuristic values 
	Group edges of the search tree into macros (we will see this) 
	A gazillion more. 18 Courtesy of Victor Allis. Used with permission. Fig. 2.3 from "Searching for Solutions in Games and 
Articial Intelligence." Doctoral Thesis. State University of Limburg in Maastricht, 1994, pp. 24.ES.268</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>AI Techniques For Solving Games
Next Time: Connect  Four  and Conspiracy Number Search! 
References  
	Victor Allis, Searching for Solutions, http://fragrieu.free.fr/SearchingForSolutions.pdf 
	Intelligent Search Techniques: Proof Number Search, MICC/IKAT
Universiteit Maastricht
	Various years of 6.034 lecture notes 
19
ES.268</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>AI Techniques For Solving Games
Minimax  
The most used game tree search is the minimax algorithm. To get a sense 
f
or how this works, consider the following: 
Helen and Stavros are playing a game. The rules of this game are very 
mysterious, but we know that each state involves Helen having a certain number of drachmas at each state. Poor Stavros never gets any drachmas, 
but he doesnt want Helen to get any richer and keep bossing him around. 
So Helen wants to maximize her drachmas, while Stavros wants to minimize them. What should each player do? At each level Helen will choose the move 
leading to the greatest value, and Stavros will move to the minimum-valued 
state, hence the name minimax. 
Formally, the minimax algorithm is described by the following pseudocode: 
def max-value(state,depth):  
if (depth  == 0): return  value(state)  
v =
 -infinite  
fo
r each s i n SUCCESSORS(state):  
v = MAX(v,min-value(s,depth-1)) 
re
turn  v
d
ef min-value(state,depth):  
if (depth  == 0): return  value(state)  
v =
 infinite  
fo
r each s i n SUCCESSORS(state):  
v = MIN(v,max-value(s,depth-1)) 
re
turn  v
6</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>AI Techniques For Solving Games
with current techniques searching deeper is the key. Also obvious, is that 
real players couldnt possibly be searching 13 moves deep, so there must be some other factor involved in being good at chess. 
Is game-play  all about  how  many moves we see ahead? 
If searching deep into the game tree is so hard, how are humans able to play games like Chess and GO so well? Do we play by mentally drawing 
out a game board and performing minimax? It seems that instead humans 
use superior heuristic evaluations, and base their moves on experience from 
previous game play or some sort of intuition. Good players do look ahead, 
but only a couple of plys. The question still remains as to how humans can do so well compared to machines. Why is it hardest for a machine to do 
what is easiest for a human? 
Alternative Search  Methods 
There are countless tweaks and alternatives to the maximin and alpha-beta 
pruning search algorithms. We will go over one, the proof-number search, here, and leave another variation, conspiracy number search, for our discus
sion next week on connect four. 
PN-search 
While alpha-beta search deals with assigning nodes of the game tree continuous values, proof number search decides whether a given node is a win 
or a loss. Informally, pn-search can be described as looking for the shortest solution to tell whether or not a given game state is a win or a loss for our 
player of interest. 
Before we talk about proof number search, we introduce AND-OR trees. 
These are two level alternating trees, where the rst level is an OR node, the second level consists of AND nodes, etc. The tree below is an example: 
15 ES.268</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>AI Techniques For Solving Games
 Are we guaranteed a correct solution? 
Yes! Alpha-beta does not actually change the minimax algorithm, ex
cept for allowing us to skip some steps of it sometimes. We will always 
get the same solution from alpha-beta and minimax. 
 Are we guaranteed to get to a solution faster? 
No! Even using alpha-beta, we might still have to explore all bd nodes. 
A LOT of the success of alpha-beta depends on the ordering in which 
we explore dierent nodes. Pessimal ordering might causes us to do no better than Manamas, but an optimal ordering of always exploring 
the best options rst can get us to only the square root of that. That 
means we can go twice as far down the tree using no more resources 
than before. In fact, the majority of the computational power when 
trying to solve games goes into cleverly ordering which nodes are explored when, and the rest is used on performing the actual alpha-beta 
algorithm. 
Interesting Side Note  - Konigs  Lemma 
I will use this opportunity to introduce an interesting theorem from graph theory that applies to our game graphs, called Konigs Lemma: 
Theorem: Any graph with a nite branching factor and an innite num
ber of nodes must have an innite path. 
Proof: Assume we have a graph with each node having nitely many branches 
but innitely many nodes. Start at the root. At least one of its branches 
must have an innite number of nodes below it. Choose this node to start our innite path. Now treat this new node as the root. Repeat. We have 
found an innite path. 
How does this apply to our game trees? This tells us that for every game, 
either: 
1. It is possible for the game to never end. 
2. There is a nite maximum number of moves the game will take to 
terminate. 
11 ES.268</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>AI Techniques For Solving Games
We will play out this game on the following tree:
The values at the leaves are the actual values of games corresponding to the 
paths leading to those nodes. We will say Helen is the rst player to move. 
So she wants to take the option (A,B,C,D) that will maximize her score. But she knows in the next ply down Stavros will try to minimize the score, etc. So 
we must ll in the values of the tree recursively, starting from the bottom up. 
Helen maximizes: 
Stavros minimizes:
7 ES.268</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>AI Techniques For Solving Games
to choose the minimum, so he will denitely choose the 10. So there is no 
need to evaluate the 7. 
So we saved evaluating 6 out of 26 nodes. Not bad, and often alpha-beta 
does a lot better than that. 
Formally, the alpha-beta pruning optimization to the minimax algorithm is as follows: 
a = best score  for max-player  (helen) 
b = 
 best  score  for min-player  (stavros) 
in
itially,  we call max-value(initial,  -infinite,  infinite,  max-depth) 
de
f	max-value(state,  a, b, depth):  
if (depth  == 0): return  value(state)  
fo
r s i n SUCCESSORS(state):  
a = max(a,  min-value(s,a,b,depth-1)) 
if a &gt; = b: return  a \ \ this ia a c utoff  point 
re
turn  a
d
ef	min-value(state,  a, b, depth):  
if (depth  == 0): return  value(state)  
fo
r s i n SUCCESSORS(state):  
b = min(b,max-value(s,a,b,depth-1)) 
if b &lt; = a: return  b \ \ this is a c utoff  point 
re
turn  b
T
here are a couple things we should point out about alpha-beta compared 
to minimax: 
10 ES.268</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
