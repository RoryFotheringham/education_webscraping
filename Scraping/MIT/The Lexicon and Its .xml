<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/24-941j-the-lexicon-and-its-features-spring-2007/</course_url>
    <course_title>The Lexicon and Its Features</course_title>
    <course_tags>
      <list>Science </list>
      <list>Humanities </list>
      <list>Linguistics </list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>KS</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-941j-the-lexicon-and-its-features-spring-2007/resources/lec2ks/</lecture_pdf_url>
      <lectureno>2-3</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 5
Perturbation theory 
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 6
Shifting position of a constriction 
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 12
The feature [nasal] for vowels
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 3
Some vowel spectra illustrating variations in amplitudes of formant peaks as well
as differences in frequencies
Reprinted with permission from Klatt, D. H., and L. C. Klatt. "Analysis, Synthesis, and Perception
of Voice Quality Variations Among Female and Male Talkers." J Acoust Soc Am  87 (1990): 820-857.
Copyright 1990, Acoustical Society of America.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 13
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 11
The tense-lax distinction (in English) 
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 1
THE LEXICON AND ITS FEATURES 
6.976-9.912-24.921  FALL 2004 
Professor Kenneth N. Stevens 
Lecture 2 09/16/04
SOME ARTICULATOR-BOUND FEATURES
Features for vowels 
back
high
low
round
tense
nasal
Dispersion theory (Liljencrants and Lindblom) Quantal theory
Three parts to speech production system</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 2
Some midsagittal vocal tract shapes for vowels 
Courtesy of MIT Press. Used with permission.
Source: Perkell, J. S. Physiology of Speech Production: Results and Implications of a Quantitative
Cineradiographic Study. Research monograph No. 53 . Cambridge, MA: MIT Press, 1969.Courtesy of MIT Press. Used with permission.
Source: Perkell, J. S. Physiology of Speech Production: Results and Implications of a Quantitative
Cineradiographic Study. Research monograph No. 53 . Cambridge, MA: MIT Press, 1969.
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 7
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 9
Effect of subglottal resonance on vowel spectrum 
Effect of vocal tract walls on F1 
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 10
Rounding
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu
24.941J / 6.543J / 9.587J / HST.727J The Lexicon and Its Features
Spring 2007
For information about citing these mate rials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 4
Some simple resonator shapes 
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Stevens, K.N.  Lecture 2  09/16/04 8
Effect of coupling to trachea 
Source: Stevens, K. N. "Acoustic and Perceptual Evidence
for Universal Phonological Features." Proceedings of the
15th International Congress of Phonetic Sciences, Barcelona,
pp. 33-38, August 3-9, 2003.
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>DS</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-941j-the-lexicon-and-its-features-spring-2007/resources/lec4ds_features/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>38</slideno>
          <text>Extrapolation
 e i 
low, +syllabic 
+syllabic 
training e i 
testing 
 e i 
38</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>Exp 1: back harmony in high V 
	Stem: CVCV 
C from {p, t, k, b, d, g, m, n}
V from {i, u,e, o, , a} 
	Sufx: -mi/-mu 
	Target rule: [+high] -&gt; [aback]/ [aback] C_ 
3 Conditions 
Low Hold-Out: stem vowel {i, e, u, o}
Mid Hold-Out: stem vowel {i, , u, a}
Control: stems only, harmonic and disharmonic. 
	
41 Testing: forced choice, which word is in the language?</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Or else you dene the set through properties that
all and only its members share: 
	-&gt; /[+strident]_z 
	z -&gt; s/[-voice]_ 
	Then you might not need positive evidence for
the behavior of each member 
5</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>3Learning rules
buz[z] soo[z] ba[s] lea[sz] lab[z] lap[s] 
lea[z] lo[vz] buff[s] le[dz] bed[z] text[s] ri[tz] bag[z] book[s] -z 
after 
s, z, , , t, d -z 
after 
b,d,g,v, -s 
after 
p,t,k,f,</text>
        </slide>
        <slide>
          <slideno>52</slideno>
          <text>Lower performance on [i] vs. [u] 
No signif . diff 
 Signif . diff 
Signif . diff. 
52</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Exp 3 
	{p, d, k} _ {b, t, g} condition 
	{b, t, g} _ {p, d, k} condition 
	Induction and segmentation phases are the
same as in Exp. 2. 
30</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>6Albright and Hayes (Cognition 2003) 
	Minimal generalization learner of alternations 
	Take each learning pair as a word specic rule 
lab	 lab[z] 
	Structural description and structural change 
 -&gt; [z]/ [lb_]pl 
	Compare rules 
kid	 kid[z] 
	Find narrowest rule that covers both cases, using a
feature description to collapse different SDs 
[+syll, -back,-round] [-son,+voic,-cont] 
l  b
 k I d</text>
        </slide>
        <slide>
          <slideno>48</slideno>
          <text>Interpretation: Mid Hold-Out
Possible cause: the feature set lacks of a feature grouping 
{low, high}. This forces subjects to learn a broad rule,
including mid vowels in the trigger set. 
 e i 
low, +syllabic 
+syllabic 
training  i 
testing  e i 
48</text>
        </slide>
        <slide>
          <slideno>75</slideno>
          <text>Subjects comment on the
unsuccessful  attempt to resist the
urge to lenite aspirates
75</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Functions of DFs
	Guide learning and generalization
beyond observed data 
	Dene natural classes 
	Structure and compress the phone inventory
	Dene representations in mental lexicon
and in mapping lexical entries to sounds
perceived and produced 
2</text>
        </slide>
        <slide>
          <slideno>79</slideno>
          <text>Sapir
	distributional similarity as the possible basis
of a phonological category 
79</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Will infants learn to tell the
difference between (a) and (b)
with equal ease in this case?
32</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Spotty evidence
	Will force the learner to generalize beyond
the observed data 
	Subject to the limits imposed by his feature
theory 
8</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>Interpretation: Mid Hold-Out 
 We observe an interpolation in this condition
 e i 
low, +syllabic 
+syllabic 
training  i 
testing  e i 
47</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Do these results say anything about the
role of features in learning rules?
	2 differences betw. Harmony/Disharmony vs. Arb 
	Complexity of the analysis (how many rules, symbols) 
	Relevance of context to the nature of the change. 
	Even if the set {, u, a} forms a class describable by some
feature set, it is probably irrelevant to the change in
backness. 
	Wilson (2003) shows that equally complex, feature-based
rules are learned differently in an AG experiment: 
	Nasal Harmony: dome-na , suto-la , doke-la 
	Nasal Disharmony: dome-la, suto-na , doke-na 
	Random(velar triggered nasalization): dome-la, suto-la , doke-na 
23 Random differs in having a context unrelated to the change.</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Errors in the Arb condition
	92on CC-k: 
	Maybe a rule is partly learned that disfavors 
[] after back vowels: 
	 -&gt;  /[-back, +tense]C_ 
22</text>
        </slide>
        <slide>
          <slideno>67</slideno>
          <text>Experiment
67</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>Extrapolation
a b c 
F, H 
H 
training b c 
testing 
a b c 
37</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>20
Courtesy of Anne Pycha. Used with permission. Source: Pycha, A., P. Nowak, E. Shin, and  R. Shosted. "Phonological Rule-learning and its
Implications for a Theory of Vowel Harmony." Edited by G. Garding,  M. Tsujimura. Proceedings of the West Coast Conference on FormalLinguistics (WCCFL) 22. (pp. 423-435). Somerville, MA: Cascadilla Press.</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Anecdotal evidence
(Lise Menn , p.c. to Morris Halle)
 Ba[x], Ba[xs], out-Ba[xt] 
 bei[], bei[z] 
 Suggests 
a. that speakers form featurally dened categories, to
which novel phones are automatically assigned, without
any evidence other than their sound quality 
b. the process learned depends on assignment of
distinctive feature values.
14</text>
        </slide>
        <slide>
          <slideno>76</slideno>
          <text>Nielsen 2006 
 Imitation task extends long VOT from /p/ to /k/ 
 Generalization involves a never-contrastive VOT diff.
 Training stimuli withhold /k/. Hi, lo frequencies. 
 Stages: 
 Warm-up: read list silently 
 Baseline: read list aloud, prompted for each item 
 Listen: all 120 list items, 2x avg; /p/: 113ms VOT 
 Test: read list loud, as above 
76</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>Exp 1, more detail
	Training: 24 pairs {stem, stem+harmonic sufx}; 5x each
Mid Hold-Out: buda, buda-mu; bni, bni-mi, 
Low Hold-Out: budo, budo-mu; bide, bide-mi 
Control: 24 harmonic, 24 disharmonic stems: muku, bigu 
 Task: Hear 2 sufxed forms (e.g. bidi-mu, bidi-mi}
Choose which is most likely to be in the language. 
	Test items: 
Old items (heard in training): e.g. bugu-mu 
New items (identical Vs as in training): e.g. tuku-mu 
New vowels (the held-out Vs) in these stems: 
Mid Hold-Out: nike-mi; Low Hold-Out: nuka-mu 
42</text>
        </slide>
        <slide>
          <slideno>85</slideno>
          <text>Yokuts 
 Both T and R can occur syllable nally.
 So can all other Cs: no natural class here
 Sufxes turn R into R, but not T into T
 -feature seeks R, ignoring intervening T
From Howe and Pulleyblank 2001, Phonology 
85</text>
        </slide>
        <slide>
          <slideno>61</slideno>
          <text>Back-Hold-Out: training
mid
 high 
front
e

i 

61</text>
        </slide>
        <slide>
          <slideno>59</slideno>
          <text>Lax-Hold-Out: training
mid
 high 
e
 itense o
 u 
59</text>
        </slide>
        <slide>
          <slideno>73</slideno>
          <text>The ND aspirates lenite!
73</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>Interpolation
a b c 
F, H 
G, H 
H 
training a c 
testing 
a b c 
39</text>
        </slide>
        <slide>
          <slideno>86</slideno>
          <text>Suppose T and R share a phonetic feature:
[+constricted glottis] 
	Evidence was consistent with 2 classes: 
[-son, +c.g] and [+son, +c.g.] 
	Spelling encouraged Alex to focus on 2 classes:
&lt;p!&gt; vs. &lt;m&gt; 
	[spelling effect on analysis in &lt;melon&gt;, &lt;cello&gt;]
	Alex disregards spelling, glottal timing
difference, probable auditory difference between
T and R, to focus just on a shared articulatory 
property. 86</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Wilson 2003,
comparison of dissimilation and
random conditions
24 Figure by MIT OpenCourseWare. Data from Wilson, Colin. "Experimental Investigation of Phonological Naturalness."
Edited by G. Garding and M. Tsujimura. Proceedings of the West Coast Conference on Formal Linguistics (WCCFL) 22.Somerville, MA: Cascadilla Press, 2003.Stem old .73 (.17) .47 (.17)
.47 (.15).68 (.12) .52 (.19)ungramm. ungramm.Grammaticality GrammaticalityGroup 2B Group 2A(8) Mean (SD) proportion "yes" by group and item type
gramm. gramm.
.41 (.15) .35 (.12) .50 (.13) new Type</text>
        </slide>
        <slide>
          <slideno>58</slideno>
          <text>Exp. 3: Height Harmony 
 Non-low sufx: mi/me. 
 2 Conditions: stem V in the training set 
Lax Hold-Out: stem vowel {i, u, e, o}
Back Hold-Out: stem vowel {i, ,e, }
58</text>
        </slide>
        <slide>
          <slideno>54</slideno>
          <text>Interpretation: High-Hold-Out
 We observe an extrapolation effect, casting some
doubt on the conservative learner hypothesis 
 e i 
high, +syllabic 
+syllabic 
training  e 
testing  e i 
54</text>
        </slide>
        <slide>
          <slideno>71</slideno>
          <text>Northern Dialect
71</text>
        </slide>
        <slide>
          <slideno>74</slideno>
          <text>Closure duration reduces
74</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>Interpretation: Low Hold-Out 
 We observe no extrapolation 
 e i 
low, +syllabic 
+syllabic 
training e i 
testing  e i 
44</text>
        </slide>
        <slide>
          <slideno>63</slideno>
          <text>Sinif. 
Sinif 
 no diff. 
63</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>Testing three points 
1. How many rules: 
feature analysis permits some descriptions, but not others, to be
unied as one rule 
2. Forced generalization: 
feature analysis forces even a conservative learner to make
predictions about segments not yet observed. 
35</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>bb, d,g
[+voice,-son,-cont]b, d, g, ,v r, j, l , w 
[-syllabic, +voice, -nasal] 
10</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Target patterns 
	In segment terms 
{p, t, k}_ {b, d, g}; 
{b, d, g} _ {p, t, k} 
	In feature terms: 
[+voice, -son]_[-voice, -son] 
[-voice, -son]_ [+voice, -son] 
29</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>7Albright and Hayes (Cognition 2003)
	Minimal generalization learner of alternations 
	Take each learning pair as a word specic rule 
lab	 lab[z] 
	Structural description and structural change 
 -&gt; [z]/ [lb_]pl 
	Compare rules 
kid	 kid[z] 
	Find narrowest rule that covers both cases; use a feature
description to collapse different SDs 
 -&gt; [z]/C [+syll, -back,-round] [-son,+voic,-cont]/_</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>33 
Saffran, J. R., and E. D. Thiessen. "Pattern Induction by Infant Language Learners."</text>
        </slide>
        <slide>
          <slideno>45</slideno>
          <text>Interpretation: Low Hold-Out 
 Possible cause: the learner is conservative
 e i 
low, +syllabic 
+syllabic 
training e i 
testing e  i 
45</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>19
Courtesy of Anne Pycha. Used with permission. Source: Pycha, A., P. Nowak, E. Shin, and  R. Shosted. "Phonological Rule-learning and its
Implications for a Theory of Vowel Harmony." Edited by G. Garding,  M. Tsujimura. Proceedings of the West Coast Conference on FormalLinguistics (WCCFL) 22. (pp. 423-435). Somerville, MA: Cascadilla Press.</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>43 
No signif . diff. 
Poor performance on low V's in all conditions</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Target rules: features 
	Harmony: 
-&gt;  / [-back, +syllabic] C__ 
	Disharmony 
-&gt;  / [+back, +syllabic] C__ 
	Arbitrary 
-&gt;  / [+high, +tense, +back, +syllabic]C__ 
-&gt;  / [+high, -tense, -back, +syllabic]C__ 
-&gt;  / [+low, +back, +syllabic]C__ 
18</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>Interpolation
 e i 
low, +syllabic 
high, +syllabic 
+syllabic 
training  i 
testing 
 e i 
40</text>
        </slide>
        <slide>
          <slideno>68</slideno>
          <text>Subjects and Schedule
68</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Back to Pycha et al. 
	The results don't speak clearly for a difference
in ease of learning that's due to feature-based 
complexity. 
	As in Wilson's case, the Arbitrary rule could
be hard to learn because its context is unrelated 
to the change. 
 Still unclear: does the feature analysis clarify
the relation of the context to the change?
25</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Sample stimuli
TVD
todkad
kigpid
kobtig
pudkad
DVT
dakdot
dipgik
gitbok
gakdip
27</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu
 
 
24.941J / 6.543J / 9.587J / HST.727J The Lexicon and Its Features
Spring 2007
 
 
 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>87</slideno>
          <text>Why
	because features refer primarily to constrictions in
the vocal tract -not timing or auditory properties?
(cf. Browman and Goldstein) 
 or because Alex is enforcing feature economy?
(cf. Clements: reducing the feature/segment ratio) 
 or underspecication? (cf. Clements, Lahiri) 
 or because sounds are categorized primarily on the
evidence of distributional similarities?
(Sapir, and now Mielke and others; possibly
Goldricks data).
	This is an anecdote, not a controlled experiment 
87</text>
        </slide>
        <slide>
          <slideno>64</slideno>
          <text>Interpretation 
	The learner is not conservative, but biased. 
	Extrapolates in Back-Hold-Out condition, from [-back,
-low, +syllabic] to [(-low), +syllabic]. 
	Nature of the bias? "backness can't affect height"
[perhaps a problem here: no preference for similar
triggers-targets] 
	Does not extrapolate in the Lax-Hold-Out condition. 
	Bias? Lax high is less high than tense high. So [, ]
might be disfavored as raising triggers.
[but [, ] might be favored as triggers of lowering] 
64</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Distinctive features in phonology
part 1: learning
24.941/6.976
1</text>
        </slide>
        <slide>
          <slideno>50</slideno>
          <text>Interpretation: Mid Hold-Out
 Low triggers are disfavored even with overt evidence.
 Hierarchy: if [] is a trigger, [e] should be one too. 
 Independent evidence favors this. 
 Unclear if we need assumptions about the feature set
testing training 
   &lt; 
e e &lt; 
i i i 
50</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Process is feature-dependent
 the learner will generalize differently if she
operates with SPEs place feature theory
b d g 
anterior + + -
coronal - + -
12</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>Maybe this result is not relevant either
	There is a difference in learning the
DVT/TVD pattern of Exp2 vs. the random 
pattern of Exp3. 
	But is it due to infants' use of [voice] as a
classicatory property of segments? 
	Or to the fact that the syllable templates in
Exp.2 -but not on Exp. 3 -can be described
in terms of a global amplitude contour? 
34</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>21
Courtesy of Anne Pycha. Used with permission. Source: Pycha, A., P. Nowak, E. Shin, and  R. Shosted. "Phonological Rule-learning and its
Implications for a Theory of Vowel Harmony." Edited by G. Garding,  M. Tsujimura. Proceedings of the West Coast Conference on FormalLinguistics (WCCFL) 22. (pp. 423-435). Somerville, MA: Cascadilla Press.</text>
        </slide>
        <slide>
          <slideno>66</slideno>
          <text>Greek (1th -4th cent AD)
66 
generalization blocked: 
p and f differ by 2 F: 
[contin ]. and [noise] 
generalization to aspirates: 
ph and f differ by 1F (continuant) 
primum movens : 
b, d, g lenite 
IO diff = 1F</text>
        </slide>
        <slide>
          <slideno>70</slideno>
          <text>Orthography
70</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Target patterns 
	In segment terms 
{p, t, k}_ {b, d, g}; 
{b, d, g} _ {p, t, k} 
	In feature terms: 
[+voice, -son]_[-voice, -son] 
[-voice, -son]_ [+voice, -son] 
28</text>
        </slide>
        <slide>
          <slideno>69</slideno>
          <text>Inventory
69</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>Interpretation: Low Hold-Out
 Alternative: low triggers are disfavored (if high targets).
 e i 
low, +syllabic 
+syllabic 
training e i 
testing  e i 
46</text>
        </slide>
        <slide>
          <slideno>53</slideno>
          <text>Interpretation: Mid-Hold-Out 
 A feature-based interpolation effect. 
 Low triggers ok in this case: perhaps bec. targets are low too.
 e i 
low, +syllabic 
+syllabic 
training  i 
testing  e i 
53</text>
        </slide>
        <slide>
          <slideno>62</slideno>
          <text>Back-Hold-Out: testing
mid
 high 
e ifront 
  
back
o 

u

62</text>
        </slide>
        <slide>
          <slideno>49</slideno>
          <text>Interpretation: Mid Hold-Out
Alternative: Low triggers are disfavored even with overt
evidence. There may be a hierarchy of triggers, where
low V's are at the bottom. The learner knows the 
hierarchy and infers: if [] is a trigger, [e] should be
one too. 
 &lt; e &lt; i 
training  i 
testing  e i 
49</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Segment based rules 
 -&gt;  {t,d, , s, z}_ z 
 z -&gt; s/{p, t, k, f, }_ 
 Learning each set: 
for each segment, you wait to get positive
evidence that it is a member of the set 
4</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>bb, d,g
[+voice,-son,-cont]b, d,g, D,v r, j, l ,w
[+voice, -syllabic, -nasal]b, db, d,,g,,v, r,j, l , ww, a, e, ,u,y ii
[+voice, -nasal] 
11</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>Finley &amp; Badecker 2007; AG
 Task: which word is in the language
Poverty of Stimulus Method (Wilson 2006): 
In the training phase, withhold from the 
stimulus set a class of segments. 
In the testing phase, expose subjects to 
the full set of segments. 
Observe if pattern learned in training is
extended to the set withheld in training. 
36</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Target rules: segments 
	Harmony: 
-&gt;  / {i, , }C__ 
	Disharmony 
-&gt;  / {u, ,a }C__ 
	Arbitrary 
-&gt;  -&gt; / {, u, a}C__ 
17</text>
        </slide>
        <slide>
          <slideno>55</slideno>
          <text>Interpretation: High-Hold-Out
 High triggers not so ok: perhaps bec. targets are low. 
 Lends support to the idea that target-trigger similarity plays a role
 e i 
high, +syllabic 
+syllabic 
training  e 
testing  e i 
55</text>
        </slide>
        <slide>
          <slideno>65</slideno>
          <text>Graff 2006
	Learner is not conservative, but constrained
by the assumption that all instances of a
process will exhibit a constant I-O distance,
where the distance is measured in features. 
	Next slides come from raffs paper. 
65</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Saffran and Thiessen 2003
Exp. 2: infants; task is segmentation 
	30 9 mo olds; DVT vs. TVD conditions 
	Stage 1
pattern induction: hear a list of CVCCVC conforming to
a DVT/TVD template 
	Stage 2
segmentation: hear stream containing repeated old and
new CVCCVC; new CVCCVC vary in whether they
conform to earlier template 
	Difference in listening times for streams of new words
that t the template vs. streams that don't. 
26 	Novelty vs. familiarity preference: here it was novelty.</text>
        </slide>
        <slide>
          <slideno>83</slideno>
          <text>Sapir: distributional parallelism
 Neither T nor R can occur syllable nally.
 Sufxes that turn T into T and R into R: 
 wi:nap stay 
 wi:nap-a/a stay on the rocks 
 tlum to be hot 
 tlum-a/a be hot on the rocks 
83</text>
        </slide>
        <slide>
          <slideno>80</slideno>
          <text>q! kw! k! tS! ts! t! p!Nootka
w j l n m qh kwh kh tSh tsh th ph 
l ts 
j tS 
w kw 
n m q k t p 
q kw k tS ts t p 
Sapir 1933, reprinted in Mandelbaum ed. 1963
80</text>
        </slide>
        <slide>
          <slideno>51</slideno>
          <text>Exp. 2 
	Low sufx: mak/mk. 
	2 Conditions: stem V in the training set 
Mid Hold-Out: stem vowel {i, , u, a} 
High Hold-Out: stem vowel {e, , o, a} 
	All else is the same 
51</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>__ 
__ Target patterns 
	In segment terms: as complex as pattern of Exp 2.
a. {p, d, k} _ {b, t, g} 
b. {b, t, g} _ {p, d, k} 
	In feature terms: much more complex than Exp2. 
Here is the feature translation of (a): 
[-voice, -cor] [+voice, -son, -cor] 
[+voice, -son, +cor] [-voice, +cor] 
31</text>
        </slide>
        <slide>
          <slideno>77</slideno>
          <text>120.0
100.0
80.0
60.0
40.0
20.0
Target P Low Target P High Novel P Low Novel K Low
Stimulus Type
Imitation effect (in VOT) plotted across four types of stimuli.V oice onset time (ms)Order of production
Baseline
Test
Figure by MIT OpenCourseWare.
77</text>
        </slide>
        <slide>
          <slideno>72</slideno>
          <text>Sample
72</text>
        </slide>
        <slide>
          <slideno>57</slideno>
          <text>Finley and Badecker 
	appeal to slightly different biases: 
Bias against low triggers (Exp.1)
Bias against i-triggers (Exp.2) 
	The typological or other basis of this is
unclear. 
	Low triggers are ok in Exp. 2 and High
triggers are ok in Exp 1. 
57</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Pycha et al. 2003: AG experiment;
task is judgment of correctness
	Palatal Vowel Harmony (VH): 
-k: CiC-k, CC-k, CC-k 
-k: CuC-k, CC-k, CaC-k 
 Palatal Vowel Disharmony (DH):
-k: CiC-k, CC-k, CC-k
-k: CuC-k, CC-k, CaC-k
	Palatal Arbitrary (ARB): 
After [i, , ], front suffix -k: CiC-k, CC-k, CC-k 
After [, u, a], back suffix -k: CC-k, CuC-k, CaC-k 
16</text>
        </slide>
        <slide>
          <slideno>56</slideno>
          <text>Overall
 Exp. 1 and 2 suggest the following: 
Bias for similar trigger-target pairs (cf. Rose&amp;Walker) 
explains bad performance on lowV in Exp1; and MHO-HHO in Exp.2 
Learning is feature-not segment-based.
explains high overall performance relative to Control in Exp.2
Not clear we need this:
Learner is moderately conservative:
more willing to interpolate than extrapolate.
56</text>
        </slide>
        <slide>
          <slideno>84</slideno>
          <text>Language specic sound classes
	Morphology supports the phonologic 
proportion p:p= m:m[] In other
languages, with different phonologic and
morpholgic understandings, such a parallel
of orthography might not be justied at all
and the phonetic differences that actually
obtain between m and p would have a 
signicantly different psychologic 
weighting 
84</text>
        </slide>
        <slide>
          <slideno>60</slideno>
          <text>Lax-Hold-Out: testing
mid
 high 
e
 itense o
 u 
lax 



60</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Checking two points 
1. How many rules: 
feature analysis permits some descriptions, but not others,
to be unied as one rule: is the difference in complexity
between analyses reected in the learning process? 
2. Forced generalization: 
feature analysis forces even a conservative learner to make
predictions about segments not yet observed. Is this
conrmed? (Also: is the learner really conservative?)
15</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>bb, d
[+voice,-son,-cont
+anterior]b, d,v, ,l, r, j, w
[+voice, -syllabic, -nasal, 
+anterior]b, db, d, v, , l, r, j, ww, a, e,.. ii
[+voice, -nasal] 
13</text>
        </slide>
        <slide>
          <slideno>78</slideno>
          <text>The nature of featural categories 
	Goldrick (JML 2004) reports on a set of AG results
suggesting that English speakers expect /f/ and /v/ to 
pattern alike; also /s/ and /z/. But not /k/ and /g/. 
	What makes {f, v}, {s,z} cohesive classes for English 
speakers? 
	Shared phonetic attributes? 
	Why not also {k, g}? 
 Alternating status, suggesting equivalence?
roof, roo[vz]; elf, el[vz]; life, alive 
pack[s], bag[z]; hou[s], hou[z], hou[z]es 
	A mix of both? 78</text>
        </slide>
        <slide>
          <slideno>81</slideno>
          <text>Phonetic differences 
	p! is an ejective: synchronous closure of lips and 
glottal cords [] sudden release of lip closure, a
moment of pause and then the release of glottal
closure [] click-like character 
	m is a preglottalized sonorant: while lip closure
and glottal closure are synchronous as before, the
glottal closure must be released at the point of initial 
sonancy of the m. 
 Spelling difference p! vs. m [] was not
unjustied on purely phonetic grounds
81</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>bb, d, g
[-syll,+voice,-son,-cont, -nas] 
9</text>
        </slide>
        <slide>
          <slideno>82</slideno>
          <text>Alex Thomas
	Taught &lt;p!ap!i:&gt;but &lt;ma:mi:qsu&gt; 
	Accepts &lt;p!ap!i:&gt; 
	Volunteers &lt;m!a:m!i:qsu&gt; 
	valuable evidence for the phonologic reality of a
glottalized class of consonants, which included both 
type p (with prior release of oral closure) and type m 
(with prior release of glottal closure). 
	basis for choosing this broader class, when a narrower
one was suggested by the spelling? 
82</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>EF, DS</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-941j-the-lexicon-and-its-features-spring-2007/resources/lec7ef_contrast/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>34</slideno>
          <text>End</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>24.941
The Lexicon and its Features
Contrasts and features</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Constraining contrasts
 The range of attested linguistic contrasts is much smaller
than the range of phonetic differences. 
 Analysis implicit in Keating, McCarthy: 
 All representable differences are possible contrasts.
 So impossible contrasts must not be representable .
 Implication: phonetic detail must be severely restricted
to avoid over-predicting the range of possible contrasts. 
 Response: 
 This is not the only conceivable theory of contrast.
 It is an inadequate theory of contrast.</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Constraining contrasts
 The argument for limiting the phonetic detail in
phonological representations: 
 ...[Halle and Stevens] (and SPE) don t simply have the
wrong features in these instances; they will ALWAYS
have TOO MANY features because they want to
describe exactly how individual sounds are articulated.
While we want the phonological features to have some
phonetic basis, we also want to distinguish possible
contrasts from possible differences.  (Keating 1984:289) 
 An adequate theory of phonological distinctive features
must...be able to describe all and only the distinctions
made by the sound systems of any of the world s 
languages  (McCarthy 1994:191)</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Dispersion Theory of Contrast - OT implementation
 Integration of differences on multiple dimensions is not well understood
- here assume distance = largest distance on any dimension.
F2
654321
ii/.notdef.g000Cy/.notdef.g0010/.notdef.g000Du1
/.notdef.g0006/.notdef.g0008 /.notdef.g00072
e/.notdef.g0001/.notdef.g0001 /.notdef.g0005/.notdef.g0001o/.notdef.g00013
e/.notdef.g000B/.notdef.g0005o4F
/.notdef.g0004/.notdef.g000F/.notdef.g000E/.notdef.g000A5
/.notdef.g0009 /.notdef.g00036
aa/.notdef.g0002 71MINDIST
=2MINDIST
=3MAXIMIZE
CONTRASTSMINDIST
=4MINDIST
=5
a.i
au 3!
b./.notdef.g0001i
e
auo5 *** *****
c.i
e
/.notdef.g0002
au
o
/.notdef.g0003*!***** 7 ******** ********
*******
d.i
e
au
o
a/.notdef.g0001*! * 6 ****** ********
e.i
e/.notdef.g0005
au
o*! 6 ******* ********
*
f.i
e
a/.notdef.g0004o5 *** ******!*</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Neutralization due to indistinctness
 Tense vowels are safe from neutralization due to greater
duration (less nasalization?) and larger formant differences. 
 Non-front lax vowels: F1 difference between [ , ] is larger
than [ , ] (also rounding). Rarely contrast before nasals.</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Backness and rounding in vowels
 Non-low vowels are generally front and unrounded or back 
and rounded (86% of the vowels in the UPSID database of
phonological inventories).
i u
e o
a
 Every language has a front unrounded vowel. 
 Every language has a back rounded vowel. 
 One reported exception: Jaqaru (Hardman 1966). Listen at:
http://www.quechua.org.uk/Eng/Sounds/Home/HomeWords.htm
and decide for yourself. 
 Not every language has front rounded (y, , etc), central (,
 etc) or back unrounded (,  etc) vowels.</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Natural Classes
	Each constraint family refers to different aspects of phonological
representation in particular ways: 
	Distinctiveness constraints refer to perceptual distance only -not to
articulatory features, and not to particular values of perceptual 
features. 
	Effort constraints refer to (certain aspects) of articulatory
representations.
	Correspondence constraints may also refer to perceptual distance (cf. 
Steriade 2001). 
	I.e. strong restrictions on reference to features. 
	Examining the set of features independently of the constraint families
with which they are associated is uninformative.</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Contrasts on multiple dimensions
 Consonantal contrasts are typically based on differences on 
multiple dimensions. 
 Stop place: quality of burst spectrum, F2 &amp; F3 transitions
(closure and release). 
 Stop voicing: VOT, preceding vowel duration, f0 in
preceding and following vowels, burst intensity, etc. 
 A contrast may be adequately distinct as a result of the
combined contributions of multiple cues. 
 e.g. pre-pausal fricative voicing contrasts in English. 
 A contrast may be neutralized because it is not possible to
realize sufcient cues in the context ( Steriade 1997 etc).
 e.g. Lithuanian stop voicing contrasts are neutralized
where VOT cannot be realized.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Phonological representations
	Longstanding claim: Phonology is sensitive to a very limited set of
properties (Jakobson, Fant &amp; Halle 1952, Chomsky &amp; Halle 1968, etc) 
	About 20-30 binary/privative features. 
	Limited temporal resolution 
	In particular it has been claimed that phonology is only sensitive to 
properties that can be contrastive. 
On the other hand: 
	We have seen evidence that phonology is sensitive to never contrastive
features. 
	There are proposals that many more than 20-30 features are needed, and
ner temporal resolution (Flemming 1995, Kirchner 1997, Steriade 2000 
etc).</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Neutralization due to indistinctness
 Mindist = F1:1.5 &gt;&gt; Max Contrasts &gt;&gt; Mindist = F1:2 
F1 2.5 3 3.5 4 4.5 5 5.5 6 6.5 7 
i    
   
/_N
    Mindist = F1:1.5 
3 Max 
Contrasts 
** Mindist = 
F1:2 
     
*!* 3 2! 
** 
   2 
  *! 2 *</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Nasalized vowels
	This analysis relates the pin-pen neutralization to the 
generalization fact that, in languages with contrastive
vowel nasalization, the nasal vowel inventory is always
the same as or smaller than the oral vowel inventory,
never larger (Ferguson 1963, Ruhlen 1973).</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Constraint-based theories of contrast
 In OT it is more natural to derive restrictions on possible
contrasts from constraints rather than from representations
(cf. Kirchner 1997). 
 I.e. representations can encode unattested contrasts, but
they are excluded by constraints. 
 Dispersion Theory of Contrast (Flemming 2004, 2006): 
 Select an inventory of contrasts that best satises a
ranked set of constraints: 
 Maximize the distinctiveness of contrasts (MinDist) 
 Maximize the number of contrasts. 
 Minimize Effort.</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Problems with the representational theory of contrast
Ejectives [t] vs. (pre-)glottalized stops [t]. 
 Lombardi (1995) represents both as [+constricted glottis]
because they never contrast minimally. 
 But these sounds pattern very differently: 
 Ejectives commonly neutralize with plain stops in
coda, e.g. Klamath, Shapsug , Peruvian Aymara ,
Maidu (Steriade 1997). 
ta ta at *at 
 Glottalized stops are commonly restricted to coda, e.g.
English, Cantonese, Thai.
ta  *ta at *at
 These generalizations cannot be formulated if the two types
of sounds are not distinguished.</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Summary
 The fundamental criterion for proposing that a feature (or
representational distinction) is part of phonological
representation is evidence that a constraint is sensitive to 
that difference. 
 The evidence suggests that constraints can be sensitive to
phonetic differences that never serve as the sole basis for a
contrast. 
 E.g. correspondence to burst strength. 
 Limitations on possible contrasts derive from constraints on 
what constitutes a good constrast - particularly 
distinctiveness constraints.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Vowel nasalization in English
 But it is not clear that the relevant vowels are [+nasal] in
English - vowels are only partially nasalized before nasals. 
 velum lowers during vowel 
 about half of the tense vowel is nasalized 
 perhaps effect is greater in shorter lax vowel. 
Cohn 1993
nasal airow
Krakow 1993 
velotrace 
Time (in units of 100 ms.)Vertical positionHome E
velum
lip
0 2 4 6 -2 -4 -6
Time (in units of 100 ms.)Seam E
0 2 4 6 -2 -4 -6d n i d n e
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Possible vs. Preferred Contrasts
 The representational theory of contrast only seeks to 
distinguish possible contrasts from impossible contrasts. 
 There are many generalizations about relative preferences
for contrasts, e.g. [i] vs. [u] is less marked than [y] vs. [u].
 A theory of preferred contrasts can also account for
restrictions on possible contrasts.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>pin-pen neutralization
	Southern US (and Bakerseld) accents: 
 /_ [+nasal]
	pin-pen, him-hem are homophonous, pit-pet contrast. 
	The process can be described with conventional features, but an analysis
in terms of more detailed representations allows us to relate it to broader 
phenomena in English and elsewhere. 
	Outline (cf. Padgett 1997) 
	vowels are nasalized before nasals 
	nasalization makes height contrasts less distinct perceptually,
resulting in neutralization of //, //. 
	neutralization yields high [] because it is more distinct from [].</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Phonological representations 
The basic role of features in phonological theory: 
 Constraints regulate the phonetic properties of words. 
 Marked congurations are characterized in phonetic
terms. 
 Correspondence constraints assess phonetic similarity 
between representations. 
 Features represent these phonetic properties. 
 What phonetic properties are relevant to phonology? 
 What properties do constraints refer to? 
 How discriminating are phonological constraints?</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu
 
 
24.941J / 6.543J / 9.587J / HST.727J The Lexicon and Its Features
Spring 2007
 
 
 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Neutralization due to indistinctness
	There are constraints on the distinctiveness of contrasts. 
	Measuring distinctiveness: distance between sounds in perceptual space. 
	Dimensions of the perceptual space for vowel quality correspond well to
the frequencies of the rst 2 or 3 formants. 
F1 2.5 3 3.5 4 4.5 5 5.5 6 6.5 7 
i    
   
	Maximize distinctiveness: a hierarchy of constraints setting
minimum distance requirements:
Mindist = F1:1 &gt;&gt; Mindist = F1:1.5 &gt;&gt; Mindist = F1:2 etc</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Effects of nasalization on vowel perception
 Perceptually, nasal vowels are less distinct from each other
than oral vowels, both in terms of confusability (Bond 1975)
and similarity judgements (Wright 1986). 
 So although oral [ ]-[] are adequately distinct for contrast, 
nasalized []-[] are not. 
 Padgett (1997) cites examples of height neutralizations
among nasalized vowels in Old Church Slavonic.</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Limitations of the representational theory of contrast
 The representational theory does not account for
combinatorial restrictions on feature contrasts.
 [nasal] can be contrastive on vowels and stops, but not
on glottal stops or ejectives. 
 Front, central and back vowels can contrast [y  u], but 
these differences are not contrastive as secondary
articulations on consonants. 
 These restrictions plausibly follow from minimum
distinctiveness requirements.</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Backness and rounding in vowels
	Explanation based on preference for maximizing distinctiveness of 
contrasts: 
	Covarying backness and rounding in this way maximizes the F2
difference between front and back vowels (Liljencrants &amp; Lindblom 
1972, Stevens, Keyser &amp; Kawasaki 1986). 
F2 14 13 12 11 10 9 8 7 
i y 	 u 
	MinDist = F2:6 &gt;&gt; Max Contrasts &gt;&gt; Mindist = F2:5 
	No non-peripheral vowels 
	More distinct contrasts are preferred, some differences are insufciently 
distinct to provide an adequate contrast. 
	Representational theory has nothing to say about preferences -
distinctiveness constraints also necessary.</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Constraint-based theories of contrast
 Preference for maximally distinct contrasts. 
 Some distinctiveness constraints are undominated.
 E.g. even if phonological representations distinguish
25% and 50% nasalized vowels, this may never be the 
sole basis for a contrast because it violates an inviolable 
Minimum Distance constraint.</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Implementation 
 Vowel nasalization: velum must be fully lowered ~50 ms
before closure of nasal. 
TT 
Velum 
TB  n 
mid, front Lower closure 
 I.e. some kind of specication of coordination of
articulators, referring to subsegmental durations.
 E.g. Browman &amp; Goldsteins gestural score.</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Implementation 
 Vowel nasalization: velum must be fully lowered ~50 ms
before closure of nasal. 
i n 
mid, front TB Lower Velum closure TT 
 I.e. some kind of specication of coordination of
articulators, referring to subsegmental durations.
 E.g. Browman &amp; Goldsteins gestural score.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Effects of nasalization on vowel perception
 Perceptually, nasal vowels are less distinct from each other
than oral vowels, both in terms of confusability (Bond 1975)
and similarity judgements (Wright 1986). 
Figure removed due to copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Natural Classes
 McCarthy (1994) asserts that an adequate theory of 
phonological features must be able to characterize all and 
only the natural classes of sounds that recur in the
phonological phenomena of different languages  
 Not clear how this is supposed to work. Perhaps every
conjunction of feature values must specify a natural class. 
 If so, increasing the number of features risks predicting too
many natural classes. 
 Are [F2 12] or [F2 9, +coronal] natural classes? 
 Not clear that standard small feature sets come anywhere
near to meeting this criterion. 
 Does any constraint need to refer to [+high tone, +round]?</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>The nature of phonological features
	The evidence for the relevance of never-contrastive features comes from 
their role in analyzing phonological processes -we need constraints that 
refer to these features. 
	E.g. the acceptability of -ee sufxation depends on the acceptability of stop 
release. 
	Correspondence constraint must refer to (properties of) stop releases. 
	The arguments for restricting the size of the feature is based on the
observation that the range of possible contrasts is limited. 
Plan: 
	Sharpen the issue by sketching an analysis that makes use of ner
details. 
	Show that generalization about contrasts are better accounted for in
terms of constraints on the distinctiveness of contrasts rather than 
restrictions on representations.</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Problems with the representational theory of contrast
 All theories allow for the representation of universally non-
contrastive properties, e.g. syllable structure, prosodic
structure ( Steriade 1993). 
 Real criterion: representational elements are justied by
evidence that they play a role in the formulation of
phonological rules/constraints. 
 Non-contrastive features are necessary for the formulation
of phonological generalizations. E.g. ejectives [t] vs. 
(pre-) glottalized stops [t]. 
 Lombardi (1995) represents both as [+constricted
glottis] because they never contrast minimally.</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Natural Classes
 An alternative approach to possible natural classes: 
 Possible natural classes are those that are mentioned in 
the universal set of constraints. 
 There is no reason why any particular combination of
features has to be mentioned in a constraint - depends on 
the theory of constraints. 
 There are distinct constraint families that regulate different
aspects of phonological form: 
 Perceptual distinctiveness ( MinDist ) 
 Articulatory effort 
 Correspondence</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Phonetic detail in representations
 Rather than 20-30 binary features and coarse temporal
segmentation we have articulatory and perceptual
representations specied in terms of scalar dimensions, with
much ner temporal resolution. 
 Partial nasalization of vowels 
 Evaluation of perceptual differences 
 stop releases 
 The general objection to enriching phonological
representations is based on the question: Why arent 
most of these differences ever contrastive?</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>pin-pen neutralization
 Southern US (and Bakerseld) accents: 
 /_ [+nasal] 
 pin-pen, him-hem are homophonous, pit-pet contrast. 
Figure removed due to copyright restrictions. 
Please see the Phonological Atlas of North America, the Telsur Project at the 
Linguistics Laboratory, University of Pennsylvania.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Neutralization due to indistinctness
	Pre-nasal []-[] neutralize because they would be too similar 
perceptually and therefore too confusable. 
	General principle: Maximize the distinctiveness of contrasts. 
	Contrasts can minimally distinguish words. 
	So if contrasting sounds are perceptually confusable, then listeners
are more likely to be slow or inaccurate in identifying words. 
	In OT terms: contrasts are more marked, the less distinct they are. 
*- &gt;&gt; *- 
	Opposing constraint: Maximize the number of contrasts 
 More contrasting sounds allows speakers to differentiate words
faster (i.e. increases the information content of each sound). 
	*- &gt;&gt; Maximize Contrasts &gt;&gt; * -</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>DS</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-941j-the-lexicon-and-its-features-spring-2007/resources/lec5ds_lexical/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>63</slideno>
          <text>Coronal vs. Labial primes
	Target: Krach crash 
	Acoustic primes: 
	P: Lrm [lrm] noise 
	T: *Lrn 
	Predicted: only P primes should facilitate reaction
to target, since only [m] activates /m/ while [n] 
mismatches. 
590 Lrp 
591 599 *571 598 RT Lrs Lrn Lrm Krach prime 
63</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>[-cons] -&gt; [+sonorant]
s i n 
nasal - + + 
continuant + + -
consonantal + - + 
sonorant - + + 
19</text>
        </slide>
        <slide>
          <slideno>70</slideno>
          <text>Underspecication and faithfulness 
	In a grammar with a faithfulness component, a value
that is identied as [0F] is more deletable than [F]: 
no MAX F violation 
	But any feature inserted will cause a DEP F violation,
so to distinguish between features more or less likely
to be inserted we need rankings of DEP F, not
underspecication. 
70</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>[+nasal] -&gt; [+sonorant]
s i n 
nasal + 
continuant + + -
consonantal + - + 
sonorant + 
16</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>CV[+nas]C, CVN, CVC words probably differ in 
duration: 
	CV[+ nas]C tend to contain just long V s (M.Ohala 1973)
	CVN tend to have short V s, 
	Voiceless C shorten Vs in Hindi. (JASA 2001 115, 5, pp. 2540) 
	If so, the rst few gates may present different points in
the V depending on whether they originate as
CV[+nas]C, CVN, or CVC. 
	Also CV[+nas]C words might get more gates. 
	Not clear if this affected the outcome. 
29</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>CVC stimuli:
should elicit equal # CVN and CVC responses up to V-offset
lexical frequency effect (CVC:67%; CVN 16%; CVC 17%) 
explains difference.
Courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission.46Source: Lahiri, Aditi, and William Marslen-Wilson. "The Mental Representation of 
Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294. )</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Shrink the lexicon 
 For any binary feature, one SR value can
be left out of lexicon and entered by rule
V -&gt; [+ nas] / _[+ nas] s[i)
n] 
[+cont] -&gt; [ -nas]/ s[i] 
 Sometimes both values: 
[+son, -cont] -&gt; [+nasal] 
8</text>
        </slide>
        <slide>
          <slideno>65</slideno>
          <text>Why one might still be sceptical:
most phonological evidence for
underspecication is better
attributed to other factors.
65</text>
        </slide>
        <slide>
          <slideno>57</slideno>
          <text>A third option interpretation
	The lexical entry for [CV)N] is /CVN/, as claimed.
	Not because a lexical minimality principle forces 
elimination of redundant Fs from lexicon. 
	But because nasality is parsed out of the V) in 
[CV)N] and attributed to the neighboring N. (cf. 
Gow literature to be presented.) 
	why do that? How can Bengali speakers exclude
the possibility that [CV) ) N] is /CVN/, if not forced 
by lexical minimality? 
57</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>[+son, -cont, -lateral] -&gt; [+nasal]
s i n 
sonorant - + + 
continuant + + -
consonantal + - + 
nasal + 
10</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>UR
s i n 
sonorant - + + 
continuant + + -
consonantal + - + 
nasal 
9</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Cant tell UR value
 Segment alternates
Turkish ACC: kz-, kul-u, diS-i, gyl-y 
	All SR values are guaranteed by context
sensitive rules. 
FH: V -&gt; [ back]/ V[back]C0_
RH: [+high] -&gt; [ rd]/ V[rd]C0_
7</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>[-cons] -&gt; [+nasal]/_[+nasal]
s i) n 
sonorant - + + 
continuant + + -
consonantal + - + 
nasal + + 
11</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>Results over all gates up to 0 gate
40 Figure by MIT OpenCourseWare. Adapted from Table 2 in Lahiri, Aditi, and William Marslen-Wilson. 
"The Mental Representation of Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294.CV[+nas]C and CVN elicit very similar responsesType of Response
CVC CVN
CVC
CVCStimulus
80.3
33.213.4
5.20.7
56.8
CVN 23.5 7.9 63.0
Bengali triplets: Percentage responses up to vowel offset~CVC~</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Lexical access model
	Access is continuously attempted 
	Begin with multiple access of all words consistent
with rst information received. Cohort. 
	Activation level for lexical entries increases as 
more supporting evidence is processed. 
	It decreases as more mismatching evidence arises.
	Decision is competitive: a candidate may be best
in cohort without being a perfect t to the
stimulus. 
24</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>UR
s i n 
nasal + 
continuant + + -
consonantal + - + 
sonorant 
15</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>33English: cntd
signal lexical Matching condition
+nasal CVN Match
-nasal CVN Mismatch
+nasal CVC No mismatch
-nasal CVC No mismatch
+nasal CVC No mismatch
-nasal CVC No mismatch)
)</text>
        </slide>
        <slide>
          <slideno>61</slideno>
          <text>The real test 
	Of the underspecication theory outlined by L&amp;MW
involves context-free redundancy effects: 
	Cases of this sort have been reported (e.g. Lahiri and 
Reetz 2002 and later Lahiri and colleagues) 
	If [t] = [0place] the matches below should be equally
good No mismatch candidates 
[ta] [pa] [ka]
/ta/
61</text>
        </slide>
        <slide>
          <slideno>72</slideno>
          <text>Unmarked  underspecied 
	3+-step hierarchies in assimilation, deletion and insertion 
	Korean Place Assimilation (Jun 1995, 2004): K &gt; P &gt; T 
 tp, tk -&gt; pp, kk	 pt, kt intact. 
 pk -&gt; kk~pk	 kp intact 
	Coalescence/F-Sensitive Elision in hiatus (Casali 1997): a &gt; e &gt; i 
 Japanese epenthesis(Ito&amp;Mester 1995): o/t, d_; i/tS, k_; /other 
C_ &gt; other V 
	coronal = [0 place]: explains 1/2 of Korean pattern of assimilation. 
	 = [0 high, 0back]:  does nor explain i, o vs. other preference 
	Other hierarchies of deletion and assimilation cannot be recoded as 
[F]-[0F]: root vs. afx segment, initial vs. non-initial. 
72</text>
        </slide>
        <slide>
          <slideno>73</slideno>
          <text>Unmarked  underspecied
	The hierarchies are analyzable with MAX/DEP rankings: 
	MAX F/root &gt;&gt; MAX F/afx 
	MAX Dorsal &gt;&gt; MAX Labial &gt;&gt; MAX Coronal 
	MAX/DEP [+Low]  &gt;&gt; MAX/DEP [-High]  &gt;&gt; MAX/DEP [+High] 
	Perhaps all the necessary MAX/DEP rankings can be predicted from
effects of input-output similarity. 
 Preference for [o] over []  in epenthesis after t, d_ in Japanese is
indirectly aimed at preventing DEP [strident] IO violations. 
	Then the uses of underspecication are subsumed by mechanisms 
needed independently. 
	Maybe not all that is clear as yet. What is clear is that under-
specication accounts for just a fragment of the patterns it was
designed to explain. 
73</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>26 Signal feature Lexical feature Matching condition
F
F
FF
FXmatch
no mismatch
mismatch (F                 ) X
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>31Bengali: cntd
No mismatch CV)C +nasal
No mismatch CV )C -nasal
No mismatch CVC -nasalNo mismatch CVC +nasalMismatch CVN -nasalMatch CVN +nasalMatching condition lexical signal
These predictions hold only if nasal Cs are [+nasal] in UR.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Relates to contrast
	French, also in Cohn 1989: 
NVC; CVN; NVN 
	Oral vowels are fully oral in French because
they contrast with nasal vowels. 
5</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>signal lexical Matching condition
+nasal CVN No mismatch
-nasal CVN No mismatch
+nasal CVC No mismatch
-nasal CVC No mismatch
+nasal CVC No mismatch
-nasal CVC No mismatchPredictions of signal-UR match: English</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>[+cont] -&gt; [-nasal]
s i) n 
sonorant - + + 
continuant + + -
consonantal + - + 
nasal - + + 
12</text>
        </slide>
        <slide>
          <slideno>58</slideno>
          <text>Ferguson and Chowdhury 1960
(Hindi)
	Next to nasal consonants there is no oral-
nasal contrast. In this environment the 
vowels are somewhat nasalized[] but 
since nasality in this position is optional
and since oral vowels in general are
unmarked and much more frequent in the
language these neutralized vowels next to 
nasals Cs are regarded here as oral. 
Language 36, 1, 37 
58</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Many ways to shrink the lexicon
	Why leave [nasal] values out of UR when we can 
do that with [sonorant] values? 
 Redundancy Rules and URs: 
/n/ = [+nasal]: 
[+nasal] -&gt; [+sonorant] 
/s/ = [-nasal, +cons]:
[-nasal, +cons] -&gt; [-sonorant] 
/i/ = [-cons]:
[-cons] -&gt; [+sonorant]; [-cons] -&gt; [-nasal]
[-cons] -&gt; [+nasal]/ __[+nasal] 14</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>signal lexical Matching condition
+nasal CVN Match
-nasal CVN Mismatch
+nasal CVC Match
-nasal CVC Mismatch
+nasal CVC Mismatch
-nasal CVC MismatchBengali signal-SR: cntd
))))</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>Stimuli 
 2 English tapes: practice + 1 word from each doublet 
 3 Bengali tapes: practice + 1 word from each B-triplet 
 2 Bengali tapes: 1 word from each B-doublet 
 each subject hears same # of CVN, CVC, CV[+nas]C words 
 6s intervals between stimuli 
 28 B English subjects 
 60 Bengali subjects: 36 for triplet tapes, 24 for doublet tapes.
39</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>signal lexical Matching condition
+nasal CVN Match
-nasal CVN Mismatch
+nasal CVC Match
-nasal CVC Mismatch
+nasal CVC Mismatch
-nasal CVC MatchPredictions of signal-SR match: Bengali
)
)))</text>
        </slide>
        <slide>
          <slideno>45</slideno>
          <text>Relevance to underspecication
	Same as before: 
Up to gate 0 stimulus gives just information about
a nasal V. That should be consistent with CVN 
and CV[+nas]C but it isnt, because their lexical 
entries differ. 
45</text>
        </slide>
        <slide>
          <slideno>60</slideno>
          <text>Results replicated for Hindi
	By Ohala and Ohala 1995, who give a different 
interpretation to L&amp;MWs views: 
	O&amp;O believe that the listeners ability to match
vowel nasalization to an /N/ in English CVN
demonstrates that the signal is mapped to SR. By
allowing the listener to access a form exhibiting
[coarticulatory nasalization of V by N] they have
endorsed the SR hypothesis. 
	The listener has access to all the features in the 
signal; nothing in L&amp;MWs story says that listeners 
cant re-assign these Fs to various segments. 60</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>44CVC  stimuli )
lexical frequency effect (CVC:67%; CVN 16%; CVC 17%) 
explains the difference between actual numbers of
 CV C and CVC responses and predictions. )
[+nas]
Courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission.
Source: Lahiri, Aditi, and William Marslen-Wilson. "The Mental Representation of 
Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294.</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Gating experiment
	Subjects presented with an incomplete
fragment taken from beginning of word: e.g.
CV from a CVC word. 
	Task is to identify a complete word. 
27</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>20 Bengali doubles
missing lm lop SR 
UR lom CVN 
missing lop CV[+nas]C CVC 
37</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>41CVN stimuli:
note/.notdef.g0001CVC vs.  CVN responses )
Courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission.
Source: Lahiri, Aditi, and William Marslen-Wilson. "The Mental Representation of 
Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294.</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>[-nasal, +cons] -&gt; [-sonorant]
s i n 
nasal - + 
continuant + + -
consonantal + - + 
sonorant - + 
17</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>20 English doubles 
Matching the Bengali doubles in Ci and Cf 
CVC CVN 
SR lop lm 
UR lop lom 
38</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>20 "In SPE-type underlying representations, features were
assigned marked or unmarked values which where translatedinto binary '+' or '-' values by marking conventions..."
Courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission.
For more explanation, see page 253 of Lahiri, Aditi, and William Marslen-Wilson."The Mental Representation of Lexical Form: A Phonological Approach to the Recognition
Lexicon." Cognition 38 (1991): 245-294.</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>25 
Acoustic stream
Feature extraction
Feature stream
Feature matching
no mismatch mismatch
A set of ranked candidate lexical forms[
[
[]
]
]c o n e
v o c
c o r
match
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>64</slideno>
          <text>Coronal vs. Labial primes 
	Target: Krach crash 
	Acoustic primes: 
	P: Lrm [lrm] noise 
	T: *Lrn 
	Predicted: only P primes should facilitate
reaction to target, since only [m] activates 
/m/ while [n] mismatches. 
64</text>
        </slide>
        <slide>
          <slideno>66</slideno>
          <text>Markedness and underspecication
 [-nasal] is not specied because it is unmarked 
 Diagnostics of unmarked status (Trubetzkoy 1938) 
	implied in implicational laws: 
	e.g. if nasalized V then oral V (French vs. Italian) 
 target structure in context-free neutralization processes: 
	e.g. no contrast of nasality in stressless syllables (Acehnese) 
 only nasal V s after nasal segment, only oral otherwise. 
 Diagnostics of underspecied status (Archangeli 1983) 
	target of assimilation/deletion 
	e.g. oral C (e.g. /d/) assimilate to nasals, not vice-versa. 
	target structure in epenthesis 
	illustrative conjecture: epenthetic segments are not nasalized, unless by 
assimilation 
	invisible in long-distance processes, inert 
	E.g. oral segments betw. trigger and target dont block some nasal 
assimilations: Kikongo nsuk-idi we washed vs. tunik-ini we ground 
66</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Lahiri and Marslen Wilson
	Which mental representation of the word is
matched against the signal? 
	SR? [si)n] 
	UR? /sin/ ? 
	if so what F-values does the UR contain? 
	How is the stimulus-form match achieved? 
21</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Temporary underspecication 
E.g. Hungarian [i], [e:] act as if they lack [-back].
Why omit feature values from UR?
(a) Cant tell what they are
(b) To shrink the lexicon
unmarked feature values targeted for omission
(c) To solve the invariance/variability problem:
if surface value of F varies between [+F] and [-F] and the 
lexical entry contains [0F], neither surface value will
contradict the lexical specication.
These reasons correspond to different theories of
underspecication: data may support some but not others. 
Lahiri and Marslen-Wilson invoke (b) and (c). 6</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>13 Basic hypothesis of phonological analysis: "...every linguistic 
item has a single unique underlying representation which is minimally specified in its phonetic description."
Courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission.
For more complete definition, see page 252 of Lahiri, Aditi, and William Marslen-Wilson.
"The Mental Representation of Lexical Form: A Phonological Approach to the Recognition
Lexicon." Cognition 38 (1991): 245-294.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Underspecication
 Feature values present in SR are absent in UR
	seen: SR[sin], UR /sin/ 
[+nas] [-nas][+nas] 
3</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu
 
 
24.941J / 6.543J / 9.587J / HST.727J The Lexicon and Its Features
Spring 2007
 
 
 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>[-cons] -&gt; [+nasal]/ __[+nasal]
s i n 
nasal - + + 
continuant + + -
consonantal + - + 
sonorant - + 
18</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Resulting UR, SR: Bengali 
22 Figure by MIT OpenCourseWare. Adapted from p. 259 in: Lahiri, Aditi, and William Marslen-Wilson. 
"The Mental Representation of Lexical Form: A Phonological Approach to the Recognition Lexicon."
Cognition 38 (1991): 245-294.Bengali
CVN CVC
Underlying
SurfaceV C V C
V C V CV CV C[+nas]
[+nas] [+nas][+nas]CVC~</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Underspecication, briey 
	From signal to underspecied lexical entries: 
Lahiri and Marslen-Wilson 1991 
Lahiri and Reetz 2002 
	Underspecication in more detail 
2</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Surface underspecication 
 Throughout the segment, F-value is
determined by external context.
	Cohn 1989: 
nasal airow in English V:
	Permanent underspecication: 
no evidence of F value at UR or SR NVC; CVN; NVN 
4</text>
        </slide>
        <slide>
          <slideno>54</slideno>
          <text>54 Bengali doublets: CVN
Courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission. Source: page 275 in Lahiri, Aditi, and William Marslen-Wilson.
"The Mental Representation of Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294.</text>
        </slide>
        <slide>
          <slideno>56</slideno>
          <text>Overall 
 What is debated here is the UR of nasalized
vowels in CVN and of oral vowels in CVC.
	Underspecication predicts these are [0 nasal].
	Full specication predicts, incorrectly: 
CVN = [+nasal] 
CVC = [-nasal] 
56</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Predictions of signal-UR match:
Bengali stimuli, CV gate
signal lexical Matching condition
+nasal CVN +/0: No mismatch
-nasal CVN -/0: No mismatch
+nasal CVC +/+: Match
-nasal -/+: Mismatch CVC[-nas]
+nasal +/0: No mismatch CVC[-nas]
-nasal CVC -/0: No mismatch
1)CVC responses should predominate in response to any CV stimulus onset
2)CVC, CVN responses should be evenly split in response to CV or CV
stimulus onsets. 30)
)
) )
)</text>
        </slide>
        <slide>
          <slideno>69</slideno>
          <text>Deletion, insertion in rule-based
underspecication
	Underspecied segments more likely to be
deleted because they have fewer or no
features. 
	More likely to be inserted because you only
insert their X slots, not the features: the 
latter come from the application of context-
free redundancy rules. 
69</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>Relevance to underspecication
	Up to 21 % of CVN responses to oral V of CVC.
	Higher than for the nasal V of CVN, CV[+nas]C 
	This is inconsistent with the listed form of the 
CVN word containing nasality on V. 
	This is consistent with having an unspecied or
oral V in the lexical entry of CVN. 
	21%, not 50%, because of the pro-CVC bias. 
47</text>
        </slide>
        <slide>
          <slideno>53</slideno>
          <text>53
I dont think this is relevant to underspecication:  hearing more of an
oral vowel should be very relevant because it rules out an upcoming
nasal segment.  This should be so even with an underspecied lexicon:
the listener ought to change his estimate of the target item (CVC vs.
CVN) as evidence of orality mounts. We have an unexplained facthere, not something that underspecication sheds light on.Cant do better than No
mismatch for V in CVC
Courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission. Source: page 275 in Lahiri, Aditi, and William Marslen-Wilson.
"The Mental Representation of Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294.</text>
        </slide>
        <slide>
          <slideno>67</slideno>
          <text>For features like [nasal], diagnostics of
unmarkedness and underspecication
converge on the same value.
Hence the conjecture:
unmarked = underspecied in UR.
67</text>
        </slide>
        <slide>
          <slideno>55</slideno>
          <text>55 Interpretation
 Two striking things here: roughly equal number of
CV[+nas]C and CVN responses up to gate 0.
   Instead of producing the CVN that was lexically available,
    listeners produced as responses CVCs that were phonologically closely related
to to the CV sequence they were hearing. p.279
  No big increase in CVN responses up to gate 0.
   the perceptual representations of CVN and CVC vowels seem to be truly
indifferent to the presence or absence of nasalization in the signal. (p. 280)
   Does underspecication explain these points?
 Shouldnt Bengali doublets work like English doublets?)</text>
        </slide>
        <slide>
          <slideno>62</slideno>
          <text>Coronal vs. Labial primes
	Target: Zug train 
	Acoustic primes: 
	T: Bahn [ba:n] railroad 
	P: *Bahm [ba:m] 
	Predicted: both T and P primes should facilitate
reaction to target, since both [ba:n] and [ba:m] 
activate Bahn /ba:N/, N nasal unspecied for place. 
598 Bahp 
588 *570 *558 590 RT Bahl Bahm Bahn Maus prime 
62</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>UR, SR: English 
23 Figure by MIT OpenCourseWare. Adapted from p. 259 in: Lahiri, Aditi, and William Marslen-Wilson. 
"The Mental Representation of Lexical Form: A Phonological Approach to the Recognition Lexicon."
Cognition 38 (1991): 245-294.English
CVN CVC
Underlying
SurfaceV C V C
V C V C[+nas]
[+nas]</text>
        </slide>
        <slide>
          <slideno>52</slideno>
          <text>Relevance to underspecication
	Up to 17% CVN responses to completely 
oral Vs 
	This is inconsistent with lexical listing of 
nasality on the vowel. 
	Its consistent with the vowel being listed as
underspecied or as oral. 
52</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>21 Bengali triplets,
real words
CVC CVN CV[+nas]C 
SR kap km kp 
UR kap kam kp 
Members of any triplet matched for perceived frequency 
36</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>Why isnt perceived nasality in
 Bengali CVN attributed to an upcoming N?
 Preference to interpret the signal locally. 
43</text>
        </slide>
        <slide>
          <slideno>48</slideno>
          <text>48 English CVN
Courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission. Source: Lahiri, Aditi, and William Marslen-Wilson.
"The Mental Representation of Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294.</text>
        </slide>
        <slide>
          <slideno>49</slideno>
          <text>English CVN
49 Figure by MIT OpenCourseWare. Adapted from Table 3 in Lahiri, Aditi and William Marslen-Wilson.
 "The Mental Representation of Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294.Type of Response
CVC CVN
CVC
CVNStimulus
83.4
59.316.640.7
English doublets: Percentage responses up to vowel offset</text>
        </slide>
        <slide>
          <slideno>51</slideno>
          <text>51 English CVC
Courtesy of Elsevier, Inc., http://www.sciencedirect.com. Used with permission. Source: Lahiri, Aditi, and William Marslen-Wilson.
"The Mental Representation of Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294.</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>Relevance to underspecication 
	At or before gate 0, the signal indicates a nasal V. 
	The lexicon offers a perfect match: CV[+nas]C 
	The CVN lexical items do not match (or mismatch) the
signal, if the V is listed as oral or underspecied. 
	So underspecication makes them a less good t. 
	Large number of CVC responses in early gates suggests a
no-mismatcheffect -no [-nasal] value on the UR of oral 
Vs -but this turns out to be a statistics driven bias for 
CVC. 
42</text>
        </slide>
        <slide>
          <slideno>50</slideno>
          <text>Relevance to underspecication 
	More CVC than CVN lexical entries: 
explains preference for CVC up to gate -2 
	Increase in CVN responses from gate -2 to gate 0
should be interpreted as increasing evidence for 
upcoming N. 
 No English CV (C): so perceived [+nas] in signal must
be attributed to an upcoming segment. That explains
 )
larger % of CVN than in Bengali in the early gates.
	The large total of CVC responses up to gate 0 
suggests that V in CVN is not entered as [+nasal] in
the lexicon. 
50</text>
        </slide>
        <slide>
          <slideno>59</slideno>
          <text>If V-nasality is optional in CVN
	then distributional evidence (variation CV)N~ CVN vs. 
invariant CV)C) tells speakers that V) in CV)N has a 
different representation from other V): its an effect of 
context. 
	Under this interpretation, lexical entries are abstract -
they reduce surface variability to invariance -but theyre 
not minimal i.e. by dropping surface invariant Fs. 
	Under this interpretation, there is no possibility of
treating Ns as oral Cs in UR (= [+son, +cons, -lateral]). 
59</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Distinctive features in lexical
entries
24.941/6.729
1</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Gates for grade
-8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3
1st: 4th glottal pulse into VGates
40 ms V offset last
Figure by MIT OpenCourseWare. Adapted from Figure 2 (p. 267) in Lahiri, Aditi, and William Marslen-Wilson. "The Mental Representation of
Lexical Form: A Phonological Approach to the Recognition Lexicon." Cognition 38 (1991): 245-294.</text>
        </slide>
        <slide>
          <slideno>71</slideno>
          <text>N-ary scales and underspecication 
	Binary differences can be characterized, with
underspecication, as [F]-[0F]: 
	Catalan coda t, d assimilates to p, b  and k, g: 
	p and k do not assimilate to each other or to t, d. 
	so [0Place] assimilates to [ Place] 
	But for n-ary scales (n &gt;3) of assimilation, deletability 
or epenthesis, underspecication explains only a
fragment of the data to be analyzed. 
71</text>
        </slide>
        <slide>
          <slideno>68</slideno>
          <text>Caveat
	Some asymmetry between marked and unmarked values holds
cross-linguistically for some F s: 
	nasal, round, spread/constricted glottis. 
	But it is hard to show or false for others: 
	[+high] and [-high] are marked or not in this sense only in combination with
other features. [+voice] and [-voice] are each marked in some contexts (_#,
V_V, N_; Flemming 2004). 
	More examples in Steriade 1995 in Goldsmith (ed.), latest in Rice 2006 in de Lacy 
(ed.) Cambridge Handbook ) 
68</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>DG</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-941j-the-lexicon-and-its-features-spring-2007/resources/lec12dg_percep/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>7</slideno>
          <text>Spoken language processes probably involve a 
combination of perceptual and top-down processes
Perceptual processes impose direct systematic constraints
on the listener that may influence the evolution of phonological
systems
Top-down processes are less likely to directly pose 
systematic constraints (but may indirectly reflect productionconstraints)
Implication: Theories that ground phonology in listener 
phenomena must be premised on an explicit processing model   Relevance to phonologists</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>is a mode in which each acoustic pattern, 
whatever its context , is always and only 
perceived as a token of a particular phonetic type.
Studdert-Kennedy (1971)Categorical Perception</text>
        </slide>
        <slide>
          <slideno>45</slideno>
          <text>Word-final lexical effects
Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Some broad characteristics of the 
computation
Its fast (~200 ms from onset):
Fast shadowing
Online lexical effects (shadowing and 
mispronunciation monitoring)
Electrophysiological measures: N400 onset
There is parallel activation of candidates
Homophone processing: She found a bugon the lamp.
Fragment priming: captain/captive</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Non-independence: Multimodal Effects
McGurk Effect (1976)
Perception of stop place
infuenced by visual cues
Speaker articulates [ga]Audio recording of [ba]Listener hears [da]
working demo at: McGurk Effect Demonstration</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>The identification-discrimination 
relationship
CP effects in discrimination increase with memory load
and task characteristics biasing subjects towards basing comparison on coded labels.
Covert labeling strategies make discrimination a variant of 
identification that could tap the same strategic decision 
mechanisms</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>Representation
Localist representation of: 211 words, 14 
phonemes, 9 values for 7 features
Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Defining the computational problem (Marr, 1981)
What is the goal of the computation?
What is the appropriate strategy?
What is the logic of the strategy for carrying it out?</text>
        </slide>
        <slide>
          <slideno>54</slideno>
          <text>TRACE weaknesses
 No role for basic perceptual processes
 No role for learning
 Unrealistic temporal representation
 Questionable phonemic representation, arbitrary 
choice of feature system
 Incomplete integration (i.e. different inputs, 
parameters for different problems)
 No role for effects of attention or strategy
 Unrealistically small lexicon
 Little concern for biological plausibility</text>
        </slide>
        <slide>
          <slideno>50</slideno>
          <text>Categorical Perception: 
Discrimination
Phoneme-feature activation minimizes differences in 
activation to reduce within category discriminationApplication of Luce decision ru le further sharpens id functionsFigure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>51</slideno>
          <text>Compensation for 
Coarticulation (TRACE I)
Context dependent reweighing of feature cues dramatically
improves performance (75% accuracy without it, 90% with it)
Simulation of data only  Does this reflect spectral contrast? 
Articulatory parsing? Feature parsing? Higher level 
perceptual units?</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>Some possible implications of non-
independence in CP
 Variance (noise) versus covariance (potential 
signal)
 Spoken word recognition is fundamentally a 
problem of integration over time, sensory 
modalities, and across all levels of 
representation that requires a high degree of 
interactivity</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Within Category Structure
Weak exemplars slow online processing, especially near 
boundaries with native phonetic categories
Figure removed due to copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Methodological factors shown to influence 
CP 
Task effects: ABX data more categorical than AX
Timing: Between category discrimination improves as 
ISI increases from 100-2000 ms  in AX
Within category discrimination decreases over the
same increase in ISI (van Hessen &amp; Schouten, 1992)
Issue: Lexical access effects show up roughly 200 ms after 
word onset, meaning interp retation may normally happen
before perception is strongly categorical</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>Part 2: The TRACE model</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>Ganong Effect
Lexical effects only emerge when one lexical candidate 
dominates. Competition at all levels magnifies activation 
Differences.</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>Phonotactic Effects
Phonotactic effects produced by top-down excitation. 
Partial lexical matches produ ce gang effects in nonword
stimuli.</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>Graded Input Needed for 
Category Effects
Other modifications: Lexical influences removed, phoneme
to feature activation addedFigure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>Activation Dynamics
Activation passed between levels to 
all consistent representations
Competition (inhibition proportionate
to activation) between nodes within 
levels
Activation decays over time
Activation may continue to evolve 
after word offsetsFigure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Implications of nave CP for models of 
spoken word recognition
 Speech percept is largely unambiguous
 Features (and higher levels of representation) 
are perceived independently
 Within category variance is lost early in 
processing and so cannot influence higher 
levels of processing</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Non-independence: Adjacent features
2. Fricative-stop effect
Bias towards velar categorization of
ambiguous stops following [s] v. [ ]
with coronal bias following [ ]
Similar effect of stop on fricative 
categorization
Modulated by temporal separation
of potential syllable boundaries
suggesting role of low-level processes
Mann &amp; Repp (1981)Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>53</slideno>
          <text>Lexical Segmentation
Continuous access IS implicit segmentation. 
Competition and decay create systematic biasesFigure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Categorical perception (CP)
CP empirically characterized by:
Sharp transitions in ID functions
A peak in discrimination across category boundaries (ID should 
predict discrimination)
Better between than within category discrimination
Note: The function properties used to identify CP are themselves
continuous 
Please also see Liberman, Harris, Hoffman &amp; Griffith (1957).</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Spoken word recognition as sequential 
pattern mapping 
Speech signalFeaturesSegmentsWords</text>
        </slide>
        <slide>
          <slideno>49</slideno>
          <text>Categorical Perception
Competition sharpens boundaries, effects increase over time.Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>CP effects are malleable
Identification function can be arbitrarily reshaped by 
feedback
Figure removed due to copyright restrictions.
Please see Carney et al. (1977).</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Early cohort model - sequential pattern mapping 
structured by temporal constraints
Figure removed due to copyright restrictions.
Please see Marslen-Wilson (1984).</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Non-independence: Cue-Trading
Summerfield &amp; Haggard (1977)Multiple cues are integrated in feature 
perception
 F1 onset is higher, VOT longer in 
unvoiced velar stops
 If F1  200 Hz, crossover 
VOT = 34ms
 If F1 = 400 Hz,crossover
VOT = 23ms
 Implication: 
1. Continuous feature values may 
emerge despite the use of some 
quantal cues
2.   Multiple cues are integratedFigure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu
 
 
24.941J / 6.543J / 9.587J / HST.727J The Lexicon and Its Features
Spring 2007
 
 
 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>TRACE Architecture
 Feature, phoneme 
and word levels
 All representations 
time-aligned and 
repeated</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Dependencies that influence category
Structure and boundaries</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>Summary of Dependencies
Phenomenon Dependency
Rate normalization   nonspeech sounds-cue
Cue trading cue-cue (within)
Compensation         cue-cue (between)
for coarticulation
McGurk Effect          speech-vision
Ganong Effect         cue-lexical representation</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>An evaluation of categorical perception 
and its limits
 CP as laboratory artifact
 Within category structure
 Non-independence</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>CP tasks all demand explicit  binary judgments, but can 
we assume that such judgments are implicit in natural ASR?
(Massaro)
Figure removed due to copyright restrictions.
Please see Figure 2 in Massaro.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>By implication:
The goal of psychological research into spoken word 
recognition is to understand the direct mapping 
between acoustic phonetic structure and phonological representations.
kind of</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Are CP data irrelevant, if they reflect strategic, 
task-specific processes that may not be part of 
normal spoken word recognition?
Even if CP results reflect 
strategic decision 
mechanisms, these 
mechanisms still operate 
over a distribution derived from listenersperception of stimuli Goodness
Threshold</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>Three Varieties of Input
TRACE  I: Automatically extracted features from CVs 
spoken by one speaker (15 features, 5 ms windows)
TRACE II: Mock speech (11 slices/segment, mock 
coarticulation)
Graded mock speech input structure for categorical 
perception and trading relations simulations</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Categorical perception and its 
implications for spoken word 
recognition
24.941/6.976
10/28/04</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>Background: Lexical Access 
70s and 80s style
Logogen Model - parallel, interactive, 
continuous activation, vague
Autonomous Search Model- serial, 
bottom-up
LAFS - bottom-up, concerned with context  
effects, no intermediate representation
Cohort-parallel, bottom-up, early, discrete</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>A psychological perspective*
Acoustic phonetics : Characterization of the
relevant structure of the input representation, what 
information is available, and why it is structured the way it 
is.  
Phonology : ~is a theory of the representations in 
the lexicon that allow us to produce and recognize words.
-DS
*the view from the valley</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Non-independence: Rate normalization
2. Global Effects
Holt &amp; Wade (2004)/ba/-/wa/ discrimination
F1 and F2 transitions of 15-65 
ms. followed with 40 ms.steady 
state
Syllable preceded by 1.2 second 
sequence of random fast (30 ms) 
or slow (110 ms) tones in the 
F1-F2 frequency range
Attributed to putative durational 
contrast effect (Webers Law)Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Within Category Structure
Discrimination performance is 
highly dependent on task and synthesis
details
Ratings of category goodness, and RT
measures in ID and monitoring tasks
suggest the existence of structure within
categories
Discrimination accuracyGoodness rating
Within Category Continuum</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>TRACE Simulations
 Ganong effect
 Word-final lexical effects
 Phonotactic effects
 Trading relations
 Categorical perception
 Compensation for coarticulation
 Early activation
 Lexical segmentation</text>
        </slide>
        <slide>
          <slideno>55</slideno>
          <text>TRACEs strengths
 Dynamic activation processes
 Raises role of competition
 Framework useful for considering effects of graded 
and partial activation
 Attempts to address temporal effects including roles 
of decay, timecourse of activation
 Well articulated account of top-down processes
 Recognizes some role for featural representation</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Non-independence: Rate normalization
1. Local Effects
/wa/ - /ba/ discrimination
 Faster transitions heard as /ba/
 Interpretation of the same transition 
shifts as a function of vowel duration
 Crossover point shifts from 32-47 ms. 
As syllable duration move from 80-296 
ms
 Effect depends on syllable duration ( 
c), not stimulus duration
 Could be construed as a trading effect
Miller &amp; Liberman (1979)Duration cues vary with rate
Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Within Category Structure
CP as normalization
Discrimination data suggest that 
listeners are insensitive 
to within-category variation
Normalization strips away within-category variation, 
Simplifying mapping at the possible cost of losing useful information%50
Continuum Stimulus Pair</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Non-independence: Cue-Trading
Lisker (1978)Individual features tend to be encoded by many cues.
E.g. A subset of known voice cues
Voice onset time
Duration of voiced formant transitionsF1 onset frequency
F2 onset frequency
F3 onset frequencySpectral characteristics of following vowelDuration of following vowelDuration of aspiration
Intensity of aspirationDirection of F0 change at onset of voicing</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Non-independence: Adjacent features
1. Vowel-fricative effect
Anticipatory lip rounding for [o] and [u]
lowers the fricative noise spectrum in FVs
[] generally has a lower frequency 
spectrum than [s]
Listeners appear to compensate for round
vowel contexts and show an [s] bias in F                   
categorization before a round ([u])  v. 
nonround ([a]) context
Effect broken by temporal separation, or loss of formant transitions into vowel (suggests a role of cue grouping?) Note: This effect operates backwards in time suggesting either reanalysis or delayed analysis operating over a buffer
Mann &amp; Repp (1980)Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Non-independence: Lexical effects
Ganong effect (1980)
 2AFC identification of 
segments in syllabic/lexical 
context
 Set up so one end of 
continuum yields a word, 
other end a nonword 
(e.g.gift-*kift )
 Function biased towards 
lexicality in transitional 
region
 Word-final effects (rug-
*ruk) larger than word-
initial ones, extending to unambiguous tokens
Pitt &amp; Samuel, 1993Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>48</slideno>
          <text>Trading Relations
Additive effects of bottom-up activation produce tradingFigure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Are CP data irrelevant, if they reflect strategic, 
task-specific processes that may not be part of 
normal spoken word recognition?
Evidence for shifting 
goodness functions (e.g. 
Miller, 2001) suggest 
that non-independence 
effects reflect perceptual processes Goodness
Threshold</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>Modeling Dependency
Parallel Top-Down Interactivea1
aa2
a1 a2bb
Driven by perceptual 
Process (possibly shaped
by signal constraints)Driven by lexical or implicit 
knowledge  onlyPerception, implicitand lexical knowledge
all play roles</text>
        </slide>
        <slide>
          <slideno>52</slideno>
          <text>Early Access
Competition suppresses candidates as mismatch 
emerges. Loss of competition leads to rapid rise in activation.
Note the early activation advantage for short words ( priest).Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Non-independence: Feature interaction
Benki, 2001In production:
VOT: unvoiced &gt; voiced
VOT: velar &gt; labial
In VOT&amp; F1 stop continua 
onset identification varies as a 
function of place (burst, F2, F3)Figure removed due to 
copyright restrictions.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Defining characteristics of the problem
Input 
 Transient, rapid, highly variable
 Small phonetic inventories, phonotactic 
constraints, preference for relatively short 
words and large vocabularies create difficult 
discrimination
 Highly structured due to physiological. 
mechanical and aerodynamic constraints on production</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>What is the output?
Ultimate goal is communication
 activation of correct word forms is an intermediate 
step, not the ultimate goal of spoken language 
perception
 activation of phonological representations may be 
mediated by lexical/semantic/syntactic/pragmatic factors 
Ultimate goal is to communicate (generally 
contextualized)
What might be communicated?
 Meaning, identity (individual, gender, size, region, 
class.), affect.
 Implication: What is noise v. signal? 
It depends on what you want to get out of the signal</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>KS</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-941j-the-lexicon-and-its-features-spring-2007/resources/lec1ks_intro/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 4
A very simple schematization of the respirator y system during speech production, together with 
some rough values of components is shown below. 
 
 
 
During phonation, the action of the s ubglottal pressure on the vocal fo lds can set these structures 
into vibration.  A section through the larynx (Fig ure 1.4) shows the vocal folds.  The subglottal 
pressure below the vocal folds (in the trachea) will  cause them to vibrate.  Pulses of air pass 
between the folds. Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu
 
 
24.941J / 6.543J / 9.587J / HST.727J The Lexicon and Its Features
Spring 200 7 
 
 
 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 1
THE LEXICON AND ITS FEATURES 
6.543J/HST.727J/9.587J/ 24.941J  SPRING 2007 
 
Professor Kenneth N. Stevens 
Lecture 1           02/08/07  
           
Readings:  
1. Halle, M. and K.N. Stevens (1991) Knowledge of  language and the sounds of speech.   In J. 
Sundberg, L. Nord, and R. Carlson (eds.), Music, Language, Speech and Brain , Basingstoke, 
Hampshire: Macmillan  Press, 1-19. 
2. Stevens, K.N. (1998) Acoustic Phonetics .  Cambridge MA: MIT Press.  Chapters 1 and 4.  
3. Stevens, K.N. (2001) The properties of the voc al-tract walls help to shape several phonetic 
distinctions in language.  In Travaux du Cercle Linguistique de Copenhague,Vol. XXXI , 
285-297. 
4. Keyser, S.J. and K.N. Stevens (2006) Enha ncement and Overlap in the Speech Chain.  
Language 82 , no. 1, 33-63. 
5. Stevens, K.N. and S.J. Keyser (manuscript) Presented at Colloquium, Paris, France, July 2006.  
 
Components of the speech production system 
 
 
 
There are three major parts to the speech production system: airw ays below the glottis, the vocal 
tract proper from the glottis to the lips, and th e nasal cavity.  Usually the glottis forms a narrow 
opening so that the acoustic coup ling between the subglot tal and supraglottal system is small.  
However, the air from the lungs passes through the trachea and the glottis and there is a pressure 
drop across the glottis.  Thus the glottis plays an  important role in regulating airflow.  The 
velopharyngeal port usually remains closed at all times except in the vicinity of a nasal 
consonant (in English). Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 10
[+strident] consonant achieves its high amplitude at high freque ncies because of the relative 
position of the source. 
 
[Stiff vocal folds] 
 
We turn next to the voicing distinction for obstruents.  All obstruent consonants in English can 
be either voiced or voiceless.  One defining attr ibute of obstruent consona nts is that they are 
produced with a raised intraoral pressure.  This m eans that the transglottal pressure (the pressure 
drop across the glottis) is reduced relative to the subglottal pressure.   
 
The various conditions are schematized in Figur e C, where the phonation amplitude is plotted 
against vocal-fold stiffness for several values of  intraoral pressure (assuming a fixed subglottal 
pressure of 8 cm H 2O).  For an intraoral pressure of more than 6 cm H 2O, the transglottal 
pressure is 2 cm H 2O, and is below the threshold of phonation, and hence there will be no 
phonation.  For smaller values of intraoral pressu re (say 4 cm in the figure), phonation will occur 
over a range in which the vocal folds are slack, but for greater stiffness phonation will not occur.  
There is a value of stiffness where there is an abrupt change from phonation to no phonation.  
The name [stiff vocal folds] has been used to iden tify this feature: for [+stiff vocal folds] glottal 
vibration is inhibited, and for [- stiff vocal folds] glottal vibration is facilitated within the 
consonant region.  Other articulato r actions can also be implemented to inhibit vibration, such as 
spreading of the glottis.  These matters relati ng to enhancing gestures for features will be 
discussed later. 
The voicing feature [stiff vocal folds]
For a given intraoral pressure, increase in vocal-fold 
stiffness causes an abrupt termination of glottal 
vibration a particular threshol d of transglottal pressure.  
Subglottal pressure assumed to be 8 cm H2O
Figure C</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 6
schematically in Figure A above.  It is also shown as an equiva lent circuit in Figure 1.36.  In 
Figure 1.36, the additional cons triction is at the lips. 
 
 
Figure 1.36 shows the subglottal pr essure Ps, the glottal constr iction Zg, the supraglottal 
constriction Zc, and some other circuit elements representing the yielding wa lls of the vocal tract 
(Rw, Mw, Cw), the acoustic compliance Cv of the air between the two constrictions, and a 
source Ua that represents active expansion of the volume between the constrictions (or 
contraction if Ua is negative).  All of these components can play a role in producing consonants 
that involve a pressure increas e (or decrease?) in the oral cav ity.  These are the so-called 
obstruent  consonants.  For these consonants, the vocal folds no longer vibrate freely wit no 
supraglottal pressure, but either vi brate less strongly or not at a ll.  Also for these consonants, 
there is a pressure drop across th e supraglottal constricti on, equal to the interaural pressure Pm.  
As a consequence there is a rapid flow of air through this constriction, and turbulence in this 
flow can generate a source of sound.  This gene ration of noise (or some times a transient sound) 
is a kind of defining acoustic at tribute of an obstruent consonant.  Also when producing an 
obstruent consonant, a speaker senses the buildup  of pressure in the mouth, and hence such a 
consonant has a somatosensory component. 
 
[Sonorant] 
 
With regard to the distinctive feature [sonorant] , then, we have the following defining attributes: 
For the feature value [+sonorant]: 
(a) The glottal source can be generated with full amplitude without forming a downstream 
pressure increase. Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 3
 
 
 
This figure schematizes the respiratory system.  When we take a breath in preparation for 
speaking, we expand the lungs by contracti ng intercostal muscles and by lowering the 
diaphragm.  Following the inspiration the lung volume  decreases in part due to passive return to 
a smaller volume, but with continued adjustment of the muscles of inspir ation and inspiration.  
The net result is that the trach eal pressure remains roughly co nstant through much of the 
expiration, except for creating special prominences or inserting pauses.  A typical subglottal 
pressure during normal speaking is in the range 6-8 cm H 2O.  
 
 
 
 Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 7
(b) There is no noise generated by turbulent airflow at a supraglottal constriction. 
(c) There is no excitation of somatosensory receptors due to a pressure increase. 
For the feature value [-sonorant]: 
(a) The glottal source is attenuate d or obliterated due to a re duced transglottal pressure. 
(b) Noise is generated due to turbulent airflow in  the vicinity of a s upraglottal constriction. 
(c) Pressure is built up in the oral cavity be hind the constriction; this pressure buildup 
produces a distinctive somatosensory re sponse in the speakers oral cavity. 
 
Sound sources for speech 
 
The defining attributes for the distinctive feature [sonorant] are concerned with sound sources  
that are produced in speech --- a noise source due to  turbulence in the airflow near a constriction 
in the vocal tract, and a period ic source arising from vocal-fold vibration.  Well discuss these 
sources briefly before we move on to other features. 
 
A general model of speech sound production is given below. 
 
 
 
Glottal source:  
          
 
 
 
 
 
 Source: Fig. 1.27 and Fig. 3.1 in Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 9
vibration, the amplitude of the volume-velocity source is roughly proportional to the transglottal 
pressure to the power 3/2. 
 
The amplitude of the turbulence noise source in the vicinity of  a narrow constriction is roughly 
proportional to21
23
.A P , where Pis the pressure drop across the constriction and A is the cross-
sectional area of the constriction.  Turbulence noise can also be gene rated at the glottal 
constriction, and is called aspiration noise. 
 
[Continuant] and [Strident] 
 
A [-sonorant] or obstruent consona nt is produced by creating a na rrow constriction in the airway, 
usually in the oral cavity, and by building up pressure behind this constriction.  The constriction 
can form a complete closure to generate a stop consonant, or can form a narrow opening to 
produce a fricative consonant.  The contrast between these two types of obstruent consonants is 
captured by the distinctive feature.  [continuant]: + for fricatives, - for stops.   In the case of a 
[+continuant] segment, there is continuous generation of noise dur ing the constricted interval.  
For a [-continuant] segment, no sound is generate d during the closure interval, and then a short 
burst of noise is produced at the time the cl osure is released.  Th e pressure behind the 
constriction for these obstruent consonants creates forces on the surface of the articulator that is 
forming the constriction, and these forces influence the positioning of the articulator both during 
the fricative and in the time interval following the release.  
 
Within the class of [+continuant] consonants, th ere are some consonants, produced by forming a 
constriction with the tongue blade, for which the amplitude of the noise spectrum at high 
frequencies (in the range of the third formant or higher) is grea ter than the amplitude of the 
spectrum in the adjacent vowel in the same fr equency range.  These consonants have been 
classified as [+strident].  For other fricative consonants the spectrum am plitude of the noise in 
this frequency range is much less. 
 
The special characteristic of th e production of [+strident] consona nts can be illustrated with the 
models in Figure B. 
        
 
  a   b   
 Schematic representations of the 
front cavity in a sound like /s/ 
(part a), and like // (part b). 
Figure B  
 
The model in Part a is intended to represen t a sound like /s/ where ther e is constriction and an 
opening into a front cavity. The model in part b shows a shorter front cavity and a source closer 
to the constriction, as might exist in the fricative / /.  Estimates of the sound pressure of the 
radiated sound show that the amplitude is much greater in a than in b.  The difference is about 15 
dB, assuming the same source amplitudes in the two cases.  In a the source is located at a place 
where it is more effective in exciting the front cavity resonance.  Thus it appears that the</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 2
 
 
     F i g .  A  
 
This picture schematizes the airflows and pressu res in this three-component system, including a 
representation of a narrow constriction ac in the main vocal tract that  might exist in the airway 
when a consonant is being produced.  The dashed lines indicate that the vocal-tract walls can 
yield or move in response to changes in the intraoral pressure Pm.  The subglottal pressure in ps 
and the opening to the nasal cavity is an.  Ug, Un, Uw and Uc are airflows.  
 
Our discussion of human production and percepti on of speech will cover four different areas: 
 
(1) respiration, airflows, pressures, interaction with yielding walls 
 
(2) generation of sources of sound, the filtering of  these sources by the vocal tract and other 
airways, and the radiation of sound from the lips, the nose, and the vocal-tract walls 
 
(3) the role of the human somatosensory char acteristics in controlling speech production 
 
(4) the role of auditory  response to sound 
 
Airflow through a constriction 
 
 
    
      
 22
21 2AUP P    
 
Pressures P are in dynes/cm2, sometimes in cm H 2O 
1 cm H 2O 1000 dynes/cm2
Volume velocities U are in cm2/sec 
Area A is in cm2
 
It is approximately true for this  type of constriction that there is no pressure recovery at the 
outlet.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 5
 
 
A typical waveform of the volume velocity th rough the glottis (the space between the vocal 
folds) is shown below in Figure 1.27.  In this example, the airflow is zero for about one-half of a 
cycle and the airflow has a peak value of about 600 cm3/s.  The average value is about 150 cm3/s. 
 
 
 
During a typical respiratory cycle in speech, the lung volume might fluctuate by about 1000 cm3 
(1 liter).  Thus during phonati on like that in Figure 1.27, a stea dy phonation could be maintained 
for about 7 seconds.  During this kind of phona tion for a vowel, there is just one narrow 
constriction in the airway --- the constricti on at the glottis (although during phonation it is a 
time-varying phonation).  Phonation of  this kind, with just one majo r constriction, also occurs for 
some consonants, like nasal consonants, liquids ( /l/ and /r/), and glides (/ w/ and /j/).  These are 
called sonorant consonants. 
 
The flows, pressures, and the sound become more complicated when there is a constriction in the 
vocal tract above the glottis as well as a constric tion at the glottis.  This situation was represented Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.
Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
Courtesy of MIT Press. Used with permission.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Stevens, K. N.   6.543J Lecture 1  02/08/07 8
 
Turbulence noise source: 
 
 
 
      
   
 
 
 
 
 
 
 
 
   
      
 
 
 
  Source: Fig. 3.1 in Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
 Courtesy of MIT Press. Used with permission.
 
 
 
The filtering of these sources modifies the spectrum by introducing peaks in particular frequency 
ranges. One way of looking at it is  that the sources exci te the resonances or natural frequencies 
of the vocal tract.  In the case of a noise source near a constric tion, it will tend to excite the 
resonances of the part of the vocal  tract anterior to the constricti on.  Usually, much of the noise is 
produced by a jet of air from the constriction impinging on an obstacle, su ch as the lower teeth. 
 
There are a few things about the glottal source and the noise source that  are relevant to the 
discussion of distinctive features. 
 
The glottal source is produced by setting the voc al folds into vibrati on by applying a subglottal 
pressure.  The vocal folds will only vibrate when certain conditions are met.  If they are too far 
apart, they will not vibrate.  If  they are pushed too tightly togeth er, the subglottal pressure will 
not be enough to start them vibrating.  For an  intermediate spacing, a glottal source with 
maximum amplitude will be generated.  Also the s tiffness of the vocal folds affects their ability 
to vibrate.  When they are stiff, a greater tr ansglottal pressure is needed to set them into 
vibration.  When they are more slack, they will vibrate with a lower tran sglottal pressure.  And 
there is a minimum transglottal pressure below which vibration cannot occur.  When there is  Source: Stevens, K. N. Acoustic Phonetics. MIT Press, 1998.
 Courtesy of MIT Press. Used with permission.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
