<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/</course_url>
    <course_title>Introduction to Algorithms (SMA 5503)</course_title>
    <course_tags>
      <list>Engineering </list>
      <list>Computer Science </list>
      <list>Algorithms and Data Structures</list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>Skip Lists</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/resources/l12_skiplists/</lecture_pdf_url>
      <lectureno>L12</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>2 Handout 17: Lecture Notes on Skip Lists 
 Cost: 
 Minimized when |L1| + |L2| 
|L1| = |L1| + n 
|L1| 
n |L1| = |L1| 
 |L1| 2 = n 
 |L1| = n 
 search cost = 2n 
 Resulting 2-level structure: 
sqrt n sqrt n sqrt n sqrt n sqrt n 
33 linked lists: 3 n 	  
kk linked lists: k n 	  
lg nlg n linked lists: lg n n = lg n n 1/ lg n = (lg n) 	   
=2 
 Becomes like a binary tree: 
23 42 72 50 59 66 79 86 103 110 116 125 14 96 14 14 14 
50 50 
79 79 79 
96 110 110 
125 
34 34 66  (In fact, a level-linked B+-tree; see Problem Set 5.) 
	Example: Search for 72 
 Level 1: 14 too small, 79 too big; go down 14 
 Level 2: 14 too small, 50 too small, 79 too big; go down 50 
 Level 3: 50 too small, 66 too small, 79 too big; go down 66 
 Level 4: 66 too small, 72 spot on</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>5 Handout 17: Lecture Notes on Skip Lists 
Analysis: Proof of Theorem 
Cool idea: Analyze search backwardsfrom leaf to root  
 Search starts at leaf (element in bottommost level) 
 At each node visited: 
 If node wasnt promoted higher (got TAILS here), then we go [came from] left 
 If node was promoted higher (got HEADS here), then we go [came from] up 
 Search stops at root of tree 
 Know height is O(lg n) with high probability; say its c lg n 
 Thus, the number of up moves is at most c lg n with high probability 
	Thus, search cost is at most the following quantity:
How many times do we need to ip a coin to get c lg n heads?
 Intuitively, (lg n) 
Analysis: Coin Flipping 
Claim: Number of ips till c lg n heads is (lg n) with high probability  
 Again, constant in (lg n) bound will depend on  
Proof of claim:  
 Say we make 10c lg n ips 
 When are there at least c lg n heads? 
c lg n	 1 9c lg n 
 Pr{exactly c lg n heads}= 
10c lg n  1 
c lg n  2  2          
heads tails orders 
HHHTTT vs. HTHTHT 
9c lg n 
 Pr{at most c lg n heads}  
10c lg n  1 
c lg n  2      
tails overestimate 
on orders 
y Recall bounds on 
: x  y x 
  y  y x 
e x  x  x</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Introduction to Algorithms October 25, 2005
Massachusetts Institute of Technology 6.046J/18.410J
Professors Erik D. Demaine and Charles E. Leiserson Handout 17
Lecture Notes on Skip Lists 
Lecture 12  October 26, 2005 
Erik Demaine 
Balanced tree structures we know at this point: red-black trees, B-trees, treaps.  
Could you implement them right now? Probably, with time. . . but without looking up any  
details? 
Skip lists are a simple randomized structure youll never forget.  
Starting from scratch 
Initial goal: just searches  ignore updates (Insert/Delete) for now  
Simplest data structure: linked list  
Sorted linked list: (n) time  
2 sorted linked lists:  
	Each element can appear in 1 or both lists 
	How to speed up search? 
	Idea: Express and local subway lines 
	Example: 14 , 23, 34 , 42 , 50, 59, 66, 72 , 79, 86, 96 , 103, 110, 116, 125 
(What is this sequence?) 
	Boxed values are express stops; others are normal stops 
	Can quickly jump from express stop to next express stop, or from any stop to next 
normal stop 
	Represented as two linked lists, one for express stops and one for all stops: 
14 14 
23 34 42 72 96 34 42 72 96 
50 59 66 79 86 103 110 116 125 
	Every element  is in bottom  linked list (L2); some  elements  also in top linked list (L1) 
	Link  equal  elements  between  the two levels 
	To search,  rst search  in L1 until about  to go too far, then go down and search  in L2</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 Handout 17: Lecture Notes on Skip Lists 
Analysis: Claim of With High Probability 
Theorem: With high probability, every search costs O(lg n) in a skip list with n elements  
	What do we need to do to prove this? [Calculate the probability, and show that its high!] 
	We need to dene the notion of with high probability; this is a powerful technical notion, 
used throughout randomized algorithms 
Informal denition: An event occurs with high probability if, for any  1, there is an 	 
appropriate choice of constants for which E occurs with probability at least 1 O(1/n) 
	In reality, the constant hidden within O(lg n) in the theorem statement actually depends on c. 
Precise denition: A (parameterized) event E occurs with high probability if, for any  
 1, E occurs with probability at least 1  c/n, where c is a constant depending 
only on . 
The term O(1/n) or more precisely c/n is called the error probability  
	The idea is that the error probability can be made very very very small by setting  to 
something big, e.g., 100 
Analysis: Warmup 
Lemma: With high probability, skip list with n elements has O(lg n) levels  
	(In fact, the number of levels is (log n), but we only need an upper bound.) 
Proof:  
	Pr{element x is in more than c lg n levels}= 1/2c lg n = 1/nc 
	Recall Booles inequality / union bound: 
+ Pr{Ek} Pr{E1 E2      Ek }  Pr{E1}+ Pr{E2}+   
	Applying this inequality:
Pr{any element is in more than c lg n levels}  n 1/nc = 1/nc1

	Thus, error probability is polynomially small and exponent ( = c 1) can be made 
arbitrarily large by appropriate choice of constant in level bound of O(lg n)</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>3 Handout 17: Lecture Notes on Skip Lists 
Insert 
New element should certainly be added to bottommost level  
(Invariant: Bottommost list contains all elements) 
Which other lists should it be added to?  
(Is this the entire balance issue all over again?) 
Idea: Flip a coin  
	With what probability should it go to the next level? 
	To mimic a balanced binary tree, wed like half of the elements to advance to the next-
to-bottommost level 
	So, when you insert an element, ip a fair coin 
	If heads: add element to next level up, and ip another coin (repeat) 
Thus, on average:  
	1/2 the elements go up 1 level 
	1/4 the elements go up 2 levels 
	1/8 the elements go up 3 levels 
	Etc. 
Thus, approximately even  
Example 
Get out a real coin and try an example  
You should put a special value  at the beginning of each list, and always promote this  
special value to the highest level of promotion 
This forces the leftmost element to be present in every list, which is necessary for searching  
. . . many coins are ipped . . . 
(Isnt this easy?) 
The result is a skip list.  
It probably isnt as balanced as the ideal congurations drawn above.  
Its clearly good on average.  
Claim its really really good, almost always.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>6 Handout 17: Lecture Notes on Skip Lists 
 Applying this formula to the previous equation: 

Pr{at most c lg n heads}  10c lg n 1 9c lg n 
c lg n 2 

 e 10c lg n c lg n 1 9c lg n  c lg n  2 
9c lg n 
= (10e)c lg n 1  2 
9c lg n1 = 2lg(10e)c lg n  2 
= 2= 2(lg(10e)9)c lg n 
 lg n 
= 1/n 
 The point here is that, as 10   ,  = 9 lg(10e)   , independent of (for all) c 
 End of proof of claim and theorem 
Acknowledgments 
This lecture is based on discussions with Michael Bender at SUNY Stony Brook.</text>
        </slide>
      </slides>
      <videos>
        <video>
          <video_url>https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/resources/lecture-1-administrivia-introduction-analysis-of-algorithms-insertion-sort-mergesort/</video_url>
          <video_title>Lecture 1: Administrivia; Introduction; Analysis of Algorithms, Insertion Sort, Mergesort</video_title>
          <transcript>
            <slice>
              <time_slice>0:06</time_slice>
              <text_slice>And finally we look at the 6
And at that point we are done.</text_slice>
            </slice>
            <slice>
              <time_slice>0:10</time_slice>
              <text_slice>We're going to get started.</text_slice>
            </slice>
            <slice>
              <time_slice>0:11</time_slice>
              <text_slice>Handouts are the by the door
if anybody didn't pick one up.</text_slice>
            </slice>
            <slice>
              <time_slice>0:16</time_slice>
              <text_slice>My name is Charles Leiserson.</text_slice>
            </slice>
            <slice>
              <time_slice>0:18</time_slice>
              <text_slice>I will be lecturing this
course this term, Introduction</text_slice>
            </slice>
            <slice>
              <time_slice>0:22</time_slice>
              <text_slice>to Algorithms,
with Erik Demaine.</text_slice>
            </slice>
            <slice>
              <time_slice>0:25</time_slice>
              <text_slice>In addition, this is an
SMA course, a Singapore MIT</text_slice>
            </slice>
            <slice>
              <time_slice>0:29</time_slice>
              <text_slice>Alliance course which will be
run in Singapore by David Hsu.</text_slice>
            </slice>
            <slice>
              <time_slice>0:35</time_slice>
              <text_slice>And so all the lectures
will be videotaped and made</text_slice>
            </slice>
            <slice>
              <time_slice>0:39</time_slice>
              <text_slice>available on the Web for
the Singapore students,</text_slice>
            </slice>
            <slice>
              <time_slice>0:42</time_slice>
              <text_slice>as well as for MIT students
who choose to watch them</text_slice>
            </slice>
            <slice>
              <time_slice>0:47</time_slice>
              <text_slice>on the Web.</text_slice>
            </slice>
            <slice>
              <time_slice>0:49</time_slice>
              <text_slice>If you have an issue of not
wanting to be on the videotape,</text_slice>
            </slice>
            <slice>
              <time_slice>0:55</time_slice>
              <text_slice>you should sit in the back row.</text_slice>
            </slice>
            <slice>
              <time_slice>0:57</time_slice>
              <text_slice>OK?</text_slice>
            </slice>
            <slice>
              <time_slice>0:58</time_slice>
              <text_slice>Otherwise, you will be on it.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00</time_slice>
              <text_slice>There is a video
recording policy,</text_slice>
            </slice>
            <slice>
              <time_slice>1:03</time_slice>
              <text_slice>but it seems like they ran out.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06</time_slice>
              <text_slice>If anybody wants
to see it, people,</text_slice>
            </slice>
            <slice>
              <time_slice>1:08</time_slice>
              <text_slice>if they could just
sort of pass them</text_slice>
            </slice>
            <slice>
              <time_slice>1:11</time_slice>
              <text_slice>around maybe a little bit,
once you're done reading it,</text_slice>
            </slice>
            <slice>
              <time_slice>1:14</time_slice>
              <text_slice>or you can come up.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16</time_slice>
              <text_slice>I did secure one copy.</text_slice>
            </slice>
            <slice>
              <time_slice>1:18</time_slice>
              <text_slice>Before we get into the
content of the course,</text_slice>
            </slice>
            <slice>
              <time_slice>1:21</time_slice>
              <text_slice>let's briefly go over
the course information</text_slice>
            </slice>
            <slice>
              <time_slice>1:24</time_slice>
              <text_slice>because there are some
administrative things that we</text_slice>
            </slice>
            <slice>
              <time_slice>1:27</time_slice>
              <text_slice>sort of have to do.</text_slice>
            </slice>
            <slice>
              <time_slice>1:30</time_slice>
              <text_slice>As you can see, this
term we have a big staff.</text_slice>
            </slice>
            <slice>
              <time_slice>1:33</time_slice>
              <text_slice>Take a look at the handout here.</text_slice>
            </slice>
            <slice>
              <time_slice>1:35</time_slice>
              <text_slice>Including this
term six TAs, which</text_slice>
            </slice>
            <slice>
              <time_slice>1:37</time_slice>
              <text_slice>is two more TAs than we
normally get for this course.</text_slice>
            </slice>
            <slice>
              <time_slice>1:42</time_slice>
              <text_slice>That means recitations
will be particularly small.</text_slice>
            </slice>
            <slice>
              <time_slice>1:45</time_slice>
              <text_slice>There is a World Wide Web page,
and you should bookmark that</text_slice>
            </slice>
            <slice>
              <time_slice>1:50</time_slice>
              <text_slice>and go there regularly
because that is where</text_slice>
            </slice>
            <slice>
              <time_slice>1:55</time_slice>
              <text_slice>everything will be distributed.</text_slice>
            </slice>
            <slice>
              <time_slice>1:57</time_slice>
              <text_slice>Email.</text_slice>
            </slice>
            <slice>
              <time_slice>1:58</time_slice>
              <text_slice>You should not be
emailing directly to,</text_slice>
            </slice>
            <slice>
              <time_slice>2:00</time_slice>
              <text_slice>even though we give you
our email addresses,</text_slice>
            </slice>
            <slice>
              <time_slice>2:04</time_slice>
              <text_slice>to the individual
members of the staff.</text_slice>
            </slice>
            <slice>
              <time_slice>2:06</time_slice>
              <text_slice>You should email us generally.</text_slice>
            </slice>
            <slice>
              <time_slice>2:07</time_slice>
              <text_slice>And the reason is you will
get much faster response.</text_slice>
            </slice>
            <slice>
              <time_slice>2:11</time_slice>
              <text_slice>And also, for any
communications,</text_slice>
            </slice>
            <slice>
              <time_slice>2:13</time_slice>
              <text_slice>generally we like to monitor
what the communications are</text_slice>
            </slice>
            <slice>
              <time_slice>2:17</time_slice>
              <text_slice>so it's helpful to have
emails coming to everybody</text_slice>
            </slice>
            <slice>
              <time_slice>2:21</time_slice>
              <text_slice>on the course staff.</text_slice>
            </slice>
            <slice>
              <time_slice>2:23</time_slice>
              <text_slice>As I mentioned, we will be doing
distance learning this term.</text_slice>
            </slice>
            <slice>
              <time_slice>2:26</time_slice>
              <text_slice>And so you can watch
lectures online</text_slice>
            </slice>
            <slice>
              <time_slice>2:29</time_slice>
              <text_slice>if you choose to do that.</text_slice>
            </slice>
            <slice>
              <time_slice>2:32</time_slice>
              <text_slice>I would recommend, for people
who have the opportunity</text_slice>
            </slice>
            <slice>
              <time_slice>2:37</time_slice>
              <text_slice>to watch, to come live.</text_slice>
            </slice>
            <slice>
              <time_slice>2:38</time_slice>
              <text_slice>It's better live.</text_slice>
            </slice>
            <slice>
              <time_slice>2:40</time_slice>
              <text_slice>You get to interact.</text_slice>
            </slice>
            <slice>
              <time_slice>2:42</time_slice>
              <text_slice>There's an intangible that
comes with having it live.</text_slice>
            </slice>
            <slice>
              <time_slice>2:45</time_slice>
              <text_slice>In fact, in addition
to the videos,</text_slice>
            </slice>
            <slice>
              <time_slice>2:48</time_slice>
              <text_slice>I meet weekly with
the Singapore students</text_slice>
            </slice>
            <slice>
              <time_slice>2:51</time_slice>
              <text_slice>so that they have a
live session as well.</text_slice>
            </slice>
            <slice>
              <time_slice>2:57</time_slice>
              <text_slice>Prerequisites.</text_slice>
            </slice>
            <slice>
              <time_slice>2:58</time_slice>
              <text_slice>The prerequisites
for this course</text_slice>
            </slice>
            <slice>
              <time_slice>3:00</time_slice>
              <text_slice>are 6.042, which is Math for
Computer Science, and 6.001.</text_slice>
            </slice>
            <slice>
              <time_slice>3:05</time_slice>
              <text_slice>You basically need discrete
mathematics and probability,</text_slice>
            </slice>
            <slice>
              <time_slice>3:09</time_slice>
              <text_slice>as well as
programming experience</text_slice>
            </slice>
            <slice>
              <time_slice>3:11</time_slice>
              <text_slice>to take this course
successfully.</text_slice>
            </slice>
            <slice>
              <time_slice>3:13</time_slice>
              <text_slice>People do not have that
background should not</text_slice>
            </slice>
            <slice>
              <time_slice>3:17</time_slice>
              <text_slice>be in the class.</text_slice>
            </slice>
            <slice>
              <time_slice>3:19</time_slice>
              <text_slice>We will be checking
prerequisites.</text_slice>
            </slice>
            <slice>
              <time_slice>3:22</time_slice>
              <text_slice>If you have any
questions, please</text_slice>
            </slice>
            <slice>
              <time_slice>3:24</time_slice>
              <text_slice>come to talk to us after class.</text_slice>
            </slice>
            <slice>
              <time_slice>3:27</time_slice>
              <text_slice>Let's see.</text_slice>
            </slice>
            <slice>
              <time_slice>3:29</time_slice>
              <text_slice>Lectures are here.</text_slice>
            </slice>
            <slice>
              <time_slice>3:30</time_slice>
              <text_slice>For SMA students, they
have the videotapes</text_slice>
            </slice>
            <slice>
              <time_slice>3:33</time_slice>
              <text_slice>and they will also
have a weekly meeting.</text_slice>
            </slice>
            <slice>
              <time_slice>3:36</time_slice>
              <text_slice>Students must attend a one hour
recitation session each week.</text_slice>
            </slice>
            <slice>
              <time_slice>3:41</time_slice>
              <text_slice>There will be new material
presented in the recitation.</text_slice>
            </slice>
            <slice>
              <time_slice>3:45</time_slice>
              <text_slice>Unlike the lectures,
they will not be online.</text_slice>
            </slice>
            <slice>
              <time_slice>3:49</time_slice>
              <text_slice>Unlike the lectures,
there will not</text_slice>
            </slice>
            <slice>
              <time_slice>3:52</time_slice>
              <text_slice>be lecture notes distributed
for the recitations in general.</text_slice>
            </slice>
            <slice>
              <time_slice>3:56</time_slice>
              <text_slice>And, yet, there will
be material there</text_slice>
            </slice>
            <slice>
              <time_slice>4:00</time_slice>
              <text_slice>that is directly on the exams.</text_slice>
            </slice>
            <slice>
              <time_slice>4:03</time_slice>
              <text_slice>And so every term we say
oh, when did you cover that?</text_slice>
            </slice>
            <slice>
              <time_slice>4:07</time_slice>
              <text_slice>That was in recitation.</text_slice>
            </slice>
            <slice>
              <time_slice>4:08</time_slice>
              <text_slice>You missed that one.</text_slice>
            </slice>
            <slice>
              <time_slice>4:10</time_slice>
              <text_slice>So, recitations are mandatory.</text_slice>
            </slice>
            <slice>
              <time_slice>4:12</time_slice>
              <text_slice>And, in particular,
also let me just</text_slice>
            </slice>
            <slice>
              <time_slice>4:15</time_slice>
              <text_slice>mention your recitation
instructor is the one who</text_slice>
            </slice>
            <slice>
              <time_slice>4:18</time_slice>
              <text_slice>assigns your final grade.</text_slice>
            </slice>
            <slice>
              <time_slice>4:20</time_slice>
              <text_slice>So we have a grade meeting
and keep everybody normal,</text_slice>
            </slice>
            <slice>
              <time_slice>4:24</time_slice>
              <text_slice>but your recitation has the
final say on your grade.</text_slice>
            </slice>
            <slice>
              <time_slice>4:29</time_slice>
              <text_slice>Handouts.</text_slice>
            </slice>
            <slice>
              <time_slice>4:30</time_slice>
              <text_slice>Handouts are available
on the course Web page.</text_slice>
            </slice>
            <slice>
              <time_slice>4:34</time_slice>
              <text_slice>We will not generally, except
for this one, first handout,</text_slice>
            </slice>
            <slice>
              <time_slice>4:39</time_slice>
              <text_slice>be bringing handouts to class.</text_slice>
            </slice>
            <slice>
              <time_slice>4:42</time_slice>
              <text_slice>Textbook is this book,
Introduction to Algorithms.</text_slice>
            </slice>
            <slice>
              <time_slice>4:46</time_slice>
              <text_slice>MIT students can get it any of
the local bookstores, including</text_slice>
            </slice>
            <slice>
              <time_slice>4:50</time_slice>
              <text_slice>the MIT Coop.</text_slice>
            </slice>
            <slice>
              <time_slice>4:52</time_slice>
              <text_slice>There is also a
new online service</text_slice>
            </slice>
            <slice>
              <time_slice>4:55</time_slice>
              <text_slice>that provides textbooks.</text_slice>
            </slice>
            <slice>
              <time_slice>4:57</time_slice>
              <text_slice>You can also get a
discount if you buy it</text_slice>
            </slice>
            <slice>
              <time_slice>5:02</time_slice>
              <text_slice>at the MIT Press Bookstore.</text_slice>
            </slice>
            <slice>
              <time_slice>5:04</time_slice>
              <text_slice>There is a coupon in the MIT
Student Telephone Directory</text_slice>
            </slice>
            <slice>
              <time_slice>5:09</time_slice>
              <text_slice>for a discount on
MIT Press books.</text_slice>
            </slice>
            <slice>
              <time_slice>5:11</time_slice>
              <text_slice>And you can use that to purchase
this book at a discount.</text_slice>
            </slice>
            <slice>
              <time_slice>5:17</time_slice>
              <text_slice>Course website.</text_slice>
            </slice>
            <slice>
              <time_slice>5:18</time_slice>
              <text_slice>This is the course website.</text_slice>
            </slice>
            <slice>
              <time_slice>5:21</time_slice>
              <text_slice>It links to the
Stellar website, which</text_slice>
            </slice>
            <slice>
              <time_slice>5:24</time_slice>
              <text_slice>is where, actually,
everything will be kept.</text_slice>
            </slice>
            <slice>
              <time_slice>5:30</time_slice>
              <text_slice>And SMA students have
their own website.</text_slice>
            </slice>
            <slice>
              <time_slice>5:33</time_slice>
              <text_slice>Some students find this
course particularly challenges</text_slice>
            </slice>
            <slice>
              <time_slice>5:36</time_slice>
              <text_slice>so we will have extra help.</text_slice>
            </slice>
            <slice>
              <time_slice>5:38</time_slice>
              <text_slice>We will post weekly
office hours on the course</text_slice>
            </slice>
            <slice>
              <time_slice>5:42</time_slice>
              <text_slice>website for the TAs.</text_slice>
            </slice>
            <slice>
              <time_slice>5:44</time_slice>
              <text_slice>And then as an
experiment this term,</text_slice>
            </slice>
            <slice>
              <time_slice>5:46</time_slice>
              <text_slice>we are going to offer
homework labs for this class.</text_slice>
            </slice>
            <slice>
              <time_slice>5:51</time_slice>
              <text_slice>What a homework lab is,
is it's a place and a time</text_slice>
            </slice>
            <slice>
              <time_slice>5:55</time_slice>
              <text_slice>you can go where other
people in the course</text_slice>
            </slice>
            <slice>
              <time_slice>5:58</time_slice>
              <text_slice>will go to do homework.</text_slice>
            </slice>
            <slice>
              <time_slice>6:01</time_slice>
              <text_slice>And there will be typically
two TAs who staff the lab.</text_slice>
            </slice>
            <slice>
              <time_slice>6:05</time_slice>
              <text_slice>And so, as you're
working on your homework,</text_slice>
            </slice>
            <slice>
              <time_slice>6:07</time_slice>
              <text_slice>you can get help from
the TAs if you need it.</text_slice>
            </slice>
            <slice>
              <time_slice>6:11</time_slice>
              <text_slice>And it's generally a place,
we're going to schedule those,</text_slice>
            </slice>
            <slice>
              <time_slice>6:14</time_slice>
              <text_slice>and they will be on the course
calendar for where it is</text_slice>
            </slice>
            <slice>
              <time_slice>6:18</time_slice>
              <text_slice>and when it is that they
will be held, but usually</text_slice>
            </slice>
            <slice>
              <time_slice>6:22</time_slice>
              <text_slice>Sundays 2:00 to 4:00 pm, or
else it will be some evening.</text_slice>
            </slice>
            <slice>
              <time_slice>6:26</time_slice>
              <text_slice>I think the first one
is an evening, right?</text_slice>
            </slice>
            <slice>
              <time_slice>6:29</time_slice>
              <text_slice>Near to when the
homework is due.</text_slice>
            </slice>
            <slice>
              <time_slice>6:33</time_slice>
              <text_slice>Your best bet is try
to do the homework</text_slice>
            </slice>
            <slice>
              <time_slice>6:36</time_slice>
              <text_slice>in advance of the homework lab.</text_slice>
            </slice>
            <slice>
              <time_slice>6:39</time_slice>
              <text_slice>But then, if you
want extra help,</text_slice>
            </slice>
            <slice>
              <time_slice>6:41</time_slice>
              <text_slice>if you want to talk over
your solutions with people</text_slice>
            </slice>
            <slice>
              <time_slice>6:45</time_slice>
              <text_slice>because as we will
talk about problem sets</text_slice>
            </slice>
            <slice>
              <time_slice>6:49</time_slice>
              <text_slice>you can solve in collaboration
with other people in the class.</text_slice>
            </slice>
            <slice>
              <time_slice>6:54</time_slice>
              <text_slice>In addition, there are several
peer assistance programs.</text_slice>
            </slice>
            <slice>
              <time_slice>7:00</time_slice>
              <text_slice>Also the office of
Minority Education</text_slice>
            </slice>
            <slice>
              <time_slice>7:02</time_slice>
              <text_slice>has an assistance
program, and those usually</text_slice>
            </slice>
            <slice>
              <time_slice>7:05</time_slice>
              <text_slice>get booked up pretty quickly.</text_slice>
            </slice>
            <slice>
              <time_slice>7:08</time_slice>
              <text_slice>If you're interested
in those, good idea</text_slice>
            </slice>
            <slice>
              <time_slice>7:10</time_slice>
              <text_slice>to make an appointment to
get there and get help soon.</text_slice>
            </slice>
            <slice>
              <time_slice>7:15</time_slice>
              <text_slice>The homework labs, I hope a lot
of people will try that out.</text_slice>
            </slice>
            <slice>
              <time_slice>7:19</time_slice>
              <text_slice>We've never done this.</text_slice>
            </slice>
            <slice>
              <time_slice>7:21</time_slice>
              <text_slice>I don't know of
any other course.</text_slice>
            </slice>
            <slice>
              <time_slice>7:24</time_slice>
              <text_slice>Do other people know of courses
at MIT that have done this?</text_slice>
            </slice>
            <slice>
              <time_slice>7:28</time_slice>
              <text_slice>6.011 did it, OK.</text_slice>
            </slice>
            <slice>
              <time_slice>7:30</time_slice>
              <text_slice>Good.</text_slice>
            </slice>
            <slice>
              <time_slice>7:31</time_slice>
              <text_slice>And was it successful
in that class?</text_slice>
            </slice>
            <slice>
              <time_slice>7:34</time_slice>
              <text_slice>It never went,</text_slice>
            </slice>
            <slice>
              <time_slice>7:35</time_slice>
              <text_slice>OK.</text_slice>
            </slice>
            <slice>
              <time_slice>7:36</time_slice>
              <text_slice>Good. [LAUGHTER] We will see.</text_slice>
            </slice>
            <slice>
              <time_slice>7:38</time_slice>
              <text_slice>If it's not paying
off then we will just</text_slice>
            </slice>
            <slice>
              <time_slice>7:43</time_slice>
              <text_slice>return to ordinary office
hours for those TAs,</text_slice>
            </slice>
            <slice>
              <time_slice>7:47</time_slice>
              <text_slice>but I think for some students
that is a good opportunity.</text_slice>
            </slice>
            <slice>
              <time_slice>7:52</time_slice>
              <text_slice>If you wish to be
registered in this course,</text_slice>
            </slice>
            <slice>
              <time_slice>7:55</time_slice>
              <text_slice>you must sign up on
the course Web page.</text_slice>
            </slice>
            <slice>
              <time_slice>8:00</time_slice>
              <text_slice>So, that is requirement one.</text_slice>
            </slice>
            <slice>
              <time_slice>8:04</time_slice>
              <text_slice>It must be done today.</text_slice>
            </slice>
            <slice>
              <time_slice>8:06</time_slice>
              <text_slice>You will find it difficult to
pass the course if you are not</text_slice>
            </slice>
            <slice>
              <time_slice>8:11</time_slice>
              <text_slice>in the class.</text_slice>
            </slice>
            <slice>
              <time_slice>8:13</time_slice>
              <text_slice>And you should
notify your TA if you</text_slice>
            </slice>
            <slice>
              <time_slice>8:16</time_slice>
              <text_slice>decide to drop so that
we can get you off</text_slice>
            </slice>
            <slice>
              <time_slice>8:20</time_slice>
              <text_slice>and stop the mailings,
stop the spam.</text_slice>
            </slice>
            <slice>
              <time_slice>8:23</time_slice>
              <text_slice>And you should register
today before 7:00 PM.</text_slice>
            </slice>
            <slice>
              <time_slice>8:29</time_slice>
              <text_slice>And then we're going to email
your recitation assignment</text_slice>
            </slice>
            <slice>
              <time_slice>8:32</time_slice>
              <text_slice>to you before Noon tomorrow.</text_slice>
            </slice>
            <slice>
              <time_slice>8:34</time_slice>
              <text_slice>And if you don't receive this
information by Thursday Noon,</text_slice>
            </slice>
            <slice>
              <time_slice>8:37</time_slice>
              <text_slice>please send us an email
to the course staff</text_slice>
            </slice>
            <slice>
              <time_slice>8:41</time_slice>
              <text_slice>generally, not to
me individually,</text_slice>
            </slice>
            <slice>
              <time_slice>8:44</time_slice>
              <text_slice>saying that you didn't receive
your recitation assignment.</text_slice>
            </slice>
            <slice>
              <time_slice>8:48</time_slice>
              <text_slice>And so if you haven't
received it by Thursday Noon</text_slice>
            </slice>
            <slice>
              <time_slice>8:51</time_slice>
              <text_slice>you want to.</text_slice>
            </slice>
            <slice>
              <time_slice>8:52</time_slice>
              <text_slice>I think generally they
are going to send them</text_slice>
            </slice>
            <slice>
              <time_slice>8:55</time_slice>
              <text_slice>out tonight or at least
by tomorrow morning.</text_slice>
            </slice>
            <slice>
              <time_slice>8:59</time_slice>
              <text_slice>Yeah.</text_slice>
            </slice>
            <slice>
              <time_slice>9:00</time_slice>
              <text_slice>OK.</text_slice>
            </slice>
            <slice>
              <time_slice>9:00</time_slice>
              <text_slice>SMA students don't have
to worry about this.</text_slice>
            </slice>
            <slice>
              <time_slice>9:02</time_slice>
              <text_slice>Problem sets.</text_slice>
            </slice>
            <slice>
              <time_slice>9:03</time_slice>
              <text_slice>We have nine problem sets
that we project will be</text_slice>
            </slice>
            <slice>
              <time_slice>9:06</time_slice>
              <text_slice>assigned during the semester.</text_slice>
            </slice>
            <slice>
              <time_slice>9:08</time_slice>
              <text_slice>A couple things
about problem sets.</text_slice>
            </slice>
            <slice>
              <time_slice>9:10</time_slice>
              <text_slice>Homeworks won't
generally be accepted,</text_slice>
            </slice>
            <slice>
              <time_slice>9:12</time_slice>
              <text_slice>if you have extenuating
circumstances you</text_slice>
            </slice>
            <slice>
              <time_slice>9:15</time_slice>
              <text_slice>should make prior arrangements
with your recitation</text_slice>
            </slice>
            <slice>
              <time_slice>9:17</time_slice>
              <text_slice>instructor.</text_slice>
            </slice>
            <slice>
              <time_slice>9:18</time_slice>
              <text_slice>In fact, almost all of
the administrative stuff,</text_slice>
            </slice>
            <slice>
              <time_slice>9:21</time_slice>
              <text_slice>you shouldn't come
to me to ask and say</text_slice>
            </slice>
            <slice>
              <time_slice>9:23</time_slice>
              <text_slice>can I hand in something late?</text_slice>
            </slice>
            <slice>
              <time_slice>9:25</time_slice>
              <text_slice>You should be talking to
your recitation instructor.</text_slice>
            </slice>
            <slice>
              <time_slice>9:28</time_slice>
              <text_slice>You can read the other
things about the form,</text_slice>
            </slice>
            <slice>
              <time_slice>9:32</time_slice>
              <text_slice>but let me just mention that
there are exercises that</text_slice>
            </slice>
            <slice>
              <time_slice>9:36</time_slice>
              <text_slice>should be solved but not handed
in as well to give you drill</text_slice>
            </slice>
            <slice>
              <time_slice>9:41</time_slice>
              <text_slice>on the material.</text_slice>
            </slice>
            <slice>
              <time_slice>9:43</time_slice>
              <text_slice>I highly recommend you
doing the exercises.</text_slice>
            </slice>
            <slice>
              <time_slice>9:46</time_slice>
              <text_slice>They both test your
understanding of the material,</text_slice>
            </slice>
            <slice>
              <time_slice>9:50</time_slice>
              <text_slice>and exercises have this way of
finding themselves on quizzes.</text_slice>
            </slice>
            <slice>
              <time_slice>9:55</time_slice>
              <text_slice>You're often asked to
describe algorithms.</text_slice>
            </slice>
            <slice>
              <time_slice>10:00</time_slice>
              <text_slice>And here is a little
outline of what you can</text_slice>
            </slice>
            <slice>
              <time_slice>10:04</time_slice>
              <text_slice>use to describe an algorithm.</text_slice>
            </slice>
            <slice>
              <time_slice>10:06</time_slice>
              <text_slice>The grading policy is
something that somehow I cover.</text_slice>
            </slice>
            <slice>
              <time_slice>10:11</time_slice>
              <text_slice>And always every term
there are at least</text_slice>
            </slice>
            <slice>
              <time_slice>10:15</time_slice>
              <text_slice>a couple of students who pretend
like I never showed them this.</text_slice>
            </slice>
            <slice>
              <time_slice>10:20</time_slice>
              <text_slice>If you skip problems it has a
nonlinear effect on your grade.</text_slice>
            </slice>
            <slice>
              <time_slice>10:28</time_slice>
              <text_slice>Nonlinear, OK?</text_slice>
            </slice>
            <slice>
              <time_slice>10:30</time_slice>
              <text_slice>If you don't skip any problems,
no effect on your grade.</text_slice>
            </slice>
            <slice>
              <time_slice>10:34</time_slice>
              <text_slice>If you skip one problem, a
hundredth of a letter grade,</text_slice>
            </slice>
            <slice>
              <time_slice>10:38</time_slice>
              <text_slice>we can handle that.</text_slice>
            </slice>
            <slice>
              <time_slice>10:39</time_slice>
              <text_slice>But two problems it's a tenth.</text_slice>
            </slice>
            <slice>
              <time_slice>10:42</time_slice>
              <text_slice>And, as you see, by the time you
have skipped like five letter</text_slice>
            </slice>
            <slice>
              <time_slice>10:47</time_slice>
              <text_slice>grades, it is already
five problems.</text_slice>
            </slice>
            <slice>
              <time_slice>10:50</time_slice>
              <text_slice>This is not problem
sets, by the way.</text_slice>
            </slice>
            <slice>
              <time_slice>10:53</time_slice>
              <text_slice>This is problems, OK?</text_slice>
            </slice>
            <slice>
              <time_slice>10:54</time_slice>
              <text_slice>You're down a third
of a letter grade.</text_slice>
            </slice>
            <slice>
              <time_slice>10:59</time_slice>
              <text_slice>And if you don't
do nine or more,</text_slice>
            </slice>
            <slice>
              <time_slice>11:01</time_slice>
              <text_slice>so that's typically about
three to four problem sets,</text_slice>
            </slice>
            <slice>
              <time_slice>11:05</time_slice>
              <text_slice>you don't pass the class.</text_slice>
            </slice>
            <slice>
              <time_slice>11:07</time_slice>
              <text_slice>I always have some students
coming at the end of the year</text_slice>
            </slice>
            <slice>
              <time_slice>11:11</time_slice>
              <text_slice>saying oh, I didn't
do any of my problems.</text_slice>
            </slice>
            <slice>
              <time_slice>11:14</time_slice>
              <text_slice>Can you just pass me because
I did OK on the exams?</text_slice>
            </slice>
            <slice>
              <time_slice>11:18</time_slice>
              <text_slice>Answer no, a very simple answer
because we've said it upfront.</text_slice>
            </slice>
            <slice>
              <time_slice>11:23</time_slice>
              <text_slice>So, the problem sets are an
integral part of the course.</text_slice>
            </slice>
            <slice>
              <time_slice>11:27</time_slice>
              <text_slice>Collaboration policy.</text_slice>
            </slice>
            <slice>
              <time_slice>11:28</time_slice>
              <text_slice>This is extremely important
so everybody pay attention.</text_slice>
            </slice>
            <slice>
              <time_slice>11:32</time_slice>
              <text_slice>If you are asleep now wake up.</text_slice>
            </slice>
            <slice>
              <time_slice>11:35</time_slice>
              <text_slice>Like that's going to
wake anybody up, right?</text_slice>
            </slice>
            <slice>
              <time_slice>11:39</time_slice>
              <text_slice>[LAUGHTER] The goal of homework.</text_slice>
            </slice>
            <slice>
              <time_slice>11:41</time_slice>
              <text_slice>Professor Demaine
and my philosophy</text_slice>
            </slice>
            <slice>
              <time_slice>11:43</time_slice>
              <text_slice>is that the goal of homework is
to help you learn the material.</text_slice>
            </slice>
            <slice>
              <time_slice>11:48</time_slice>
              <text_slice>And one way of helping
to learn is not</text_slice>
            </slice>
            <slice>
              <time_slice>11:50</time_slice>
              <text_slice>to just be stuck and
unable to solve something</text_slice>
            </slice>
            <slice>
              <time_slice>11:53</time_slice>
              <text_slice>because then you're
in no better shape</text_slice>
            </slice>
            <slice>
              <time_slice>11:56</time_slice>
              <text_slice>when the exam roles around,
which is where we're actually</text_slice>
            </slice>
            <slice>
              <time_slice>12:00</time_slice>
              <text_slice>evaluating you.</text_slice>
            </slice>
            <slice>
              <time_slice>12:01</time_slice>
              <text_slice>So, you're encouraged
to collaborate.</text_slice>
            </slice>
            <slice>
              <time_slice>12:04</time_slice>
              <text_slice>But there are some commonsense
things about collaboration.</text_slice>
            </slice>
            <slice>
              <time_slice>12:08</time_slice>
              <text_slice>If you go and you
collaborate to the extent</text_slice>
            </slice>
            <slice>
              <time_slice>12:12</time_slice>
              <text_slice>that all you're doing is getting
the information from somebody</text_slice>
            </slice>
            <slice>
              <time_slice>12:15</time_slice>
              <text_slice>else, you're not
learning the material</text_slice>
            </slice>
            <slice>
              <time_slice>12:18</time_slice>
              <text_slice>and you're not going to
do well on the exams.</text_slice>
            </slice>
            <slice>
              <time_slice>12:22</time_slice>
              <text_slice>In our experience, students
who collaborate generally</text_slice>
            </slice>
            <slice>
              <time_slice>12:25</time_slice>
              <text_slice>do better than students
who work alone.</text_slice>
            </slice>
            <slice>
              <time_slice>12:30</time_slice>
              <text_slice>But you owe it to
yourself, if you're</text_slice>
            </slice>
            <slice>
              <time_slice>12:31</time_slice>
              <text_slice>going to work in a study group,
to be prepared for your study</text_slice>
            </slice>
            <slice>
              <time_slice>12:36</time_slice>
              <text_slice>group meeting.</text_slice>
            </slice>
            <slice>
              <time_slice>12:37</time_slice>
              <text_slice>And specifically you
should spend a half an hour</text_slice>
            </slice>
            <slice>
              <time_slice>12:39</time_slice>
              <text_slice>to 45 minutes on each
problem before you</text_slice>
            </slice>
            <slice>
              <time_slice>12:41</time_slice>
              <text_slice>go to group so
you're up to speed</text_slice>
            </slice>
            <slice>
              <time_slice>12:44</time_slice>
              <text_slice>and you've tried out your ideas.</text_slice>
            </slice>
            <slice>
              <time_slice>12:47</time_slice>
              <text_slice>And you may have
solutions to some,</text_slice>
            </slice>
            <slice>
              <time_slice>12:48</time_slice>
              <text_slice>you may be stuck
on some other ones,</text_slice>
            </slice>
            <slice>
              <time_slice>12:50</time_slice>
              <text_slice>but at least you
applied yourself to it.</text_slice>
            </slice>
            <slice>
              <time_slice>12:54</time_slice>
              <text_slice>After 30 to 45 minutes, if
you cannot get the problem,</text_slice>
            </slice>
            <slice>
              <time_slice>12:57</time_slice>
              <text_slice>just sitting there and banging
your head against it makes no</text_slice>
            </slice>
            <slice>
              <time_slice>13:00</time_slice>
              <text_slice>sense.</text_slice>
            </slice>
            <slice>
              <time_slice>13:01</time_slice>
              <text_slice>It's not a productive
use of your time.</text_slice>
            </slice>
            <slice>
              <time_slice>13:04</time_slice>
              <text_slice>And I know most of you have
issues with having time</text_slice>
            </slice>
            <slice>
              <time_slice>13:08</time_slice>
              <text_slice>on your hands, right?</text_slice>
            </slice>
            <slice>
              <time_slice>13:09</time_slice>
              <text_slice>Like it's not there.</text_slice>
            </slice>
            <slice>
              <time_slice>13:10</time_slice>
              <text_slice>So, don't go banging your
head against problems</text_slice>
            </slice>
            <slice>
              <time_slice>13:13</time_slice>
              <text_slice>that are too hard or
where you don't understand</text_slice>
            </slice>
            <slice>
              <time_slice>13:16</time_slice>
              <text_slice>what's going on or whatever.</text_slice>
            </slice>
            <slice>
              <time_slice>13:18</time_slice>
              <text_slice>That's when the study
group can help out.</text_slice>
            </slice>
            <slice>
              <time_slice>13:21</time_slice>
              <text_slice>And, as I mentioned,
we'll have homework labs</text_slice>
            </slice>
            <slice>
              <time_slice>13:23</time_slice>
              <text_slice>which will give
you an opportunity</text_slice>
            </slice>
            <slice>
              <time_slice>13:25</time_slice>
              <text_slice>to go and do that and
coordinate with other students</text_slice>
            </slice>
            <slice>
              <time_slice>13:29</time_slice>
              <text_slice>rather than necessarily
having to form your own group.</text_slice>
            </slice>
            <slice>
              <time_slice>13:32</time_slice>
              <text_slice>And the TAs will be there.</text_slice>
            </slice>
            <slice>
              <time_slice>13:35</time_slice>
              <text_slice>If your group is unable
to solve the problem then</text_slice>
            </slice>
            <slice>
              <time_slice>13:39</time_slice>
              <text_slice>talk to other groups or ask
your recitation instruction.</text_slice>
            </slice>
            <slice>
              <time_slice>13:43</time_slice>
              <text_slice>And, that's how you
go about solving them.</text_slice>
            </slice>
            <slice>
              <time_slice>13:46</time_slice>
              <text_slice>Writing up the
problem sets, however,</text_slice>
            </slice>
            <slice>
              <time_slice>13:49</time_slice>
              <text_slice>is your individual
responsibility</text_slice>
            </slice>
            <slice>
              <time_slice>13:51</time_slice>
              <text_slice>and should be done alone.</text_slice>
            </slice>
            <slice>
              <time_slice>13:54</time_slice>
              <text_slice>You don't write up your problem
solutions with other students,</text_slice>
            </slice>
            <slice>
              <time_slice>13:58</time_slice>
              <text_slice>you write them up on your own.</text_slice>
            </slice>
            <slice>
              <time_slice>14:01</time_slice>
              <text_slice>And you should on
your problem sets,</text_slice>
            </slice>
            <slice>
              <time_slice>14:04</time_slice>
              <text_slice>because this is
an academic place,</text_slice>
            </slice>
            <slice>
              <time_slice>14:07</time_slice>
              <text_slice>we understand that the source
of academic information</text_slice>
            </slice>
            <slice>
              <time_slice>14:11</time_slice>
              <text_slice>is very important, if you
collaborated on solutions</text_slice>
            </slice>
            <slice>
              <time_slice>14:15</time_slice>
              <text_slice>you should write a list
of the collaborators.</text_slice>
            </slice>
            <slice>
              <time_slice>14:18</time_slice>
              <text_slice>Say I worked with so
and so on this solution.</text_slice>
            </slice>
            <slice>
              <time_slice>14:22</time_slice>
              <text_slice>It does not affect your grade.</text_slice>
            </slice>
            <slice>
              <time_slice>14:25</time_slice>
              <text_slice>It's just a question
of being scholarly.</text_slice>
            </slice>
            <slice>
              <time_slice>14:30</time_slice>
              <text_slice>It is a violation of this policy
to submit a problem solution</text_slice>
            </slice>
            <slice>
              <time_slice>14:34</time_slice>
              <text_slice>that you cannot orally explain
to a member of the course</text_slice>
            </slice>
            <slice>
              <time_slice>14:38</time_slice>
              <text_slice>staff.</text_slice>
            </slice>
            <slice>
              <time_slice>14:39</time_slice>
              <text_slice>You say oh, well, my write up is
similar to that other person's.</text_slice>
            </slice>
            <slice>
              <time_slice>14:44</time_slice>
              <text_slice>I didn't copy them.</text_slice>
            </slice>
            <slice>
              <time_slice>14:45</time_slice>
              <text_slice>We may ask you to orally
explain your solution.</text_slice>
            </slice>
            <slice>
              <time_slice>14:49</time_slice>
              <text_slice>If you are unable,
according to this policy,</text_slice>
            </slice>
            <slice>
              <time_slice>14:52</time_slice>
              <text_slice>the presumption is
that you cheated.</text_slice>
            </slice>
            <slice>
              <time_slice>14:55</time_slice>
              <text_slice>So, do not write up stuff
that you don't understand.</text_slice>
            </slice>
            <slice>
              <time_slice>14:59</time_slice>
              <text_slice>You should be able to write up
the stuff that you understand.</text_slice>
            </slice>
            <slice>
              <time_slice>15:06</time_slice>
              <text_slice>Understand why you're putting
down what you're putting down.</text_slice>
            </slice>
            <slice>
              <time_slice>15:10</time_slice>
              <text_slice>If it isn't obvious, no
collaboration whatsoever</text_slice>
            </slice>
            <slice>
              <time_slice>15:13</time_slice>
              <text_slice>is permitted on exams.</text_slice>
            </slice>
            <slice>
              <time_slice>15:15</time_slice>
              <text_slice>Exams is when we evaluate you.</text_slice>
            </slice>
            <slice>
              <time_slice>15:17</time_slice>
              <text_slice>And now we're not interested
in evaluating other people,</text_slice>
            </slice>
            <slice>
              <time_slice>15:21</time_slice>
              <text_slice>we're interested
in evaluating you.</text_slice>
            </slice>
            <slice>
              <time_slice>15:23</time_slice>
              <text_slice>So, no collaboration on exams.</text_slice>
            </slice>
            <slice>
              <time_slice>15:26</time_slice>
              <text_slice>We will have a take home
exam for the second quiz.</text_slice>
            </slice>
            <slice>
              <time_slice>15:31</time_slice>
              <text_slice>You should look at the schedule.</text_slice>
            </slice>
            <slice>
              <time_slice>15:33</time_slice>
              <text_slice>If there are problems
with the schedule of that,</text_slice>
            </slice>
            <slice>
              <time_slice>15:36</time_slice>
              <text_slice>we want to know early.</text_slice>
            </slice>
            <slice>
              <time_slice>15:37</time_slice>
              <text_slice>And we will give
you more details</text_slice>
            </slice>
            <slice>
              <time_slice>15:39</time_slice>
              <text_slice>about the collaboration in the
lecture on Monday, November</text_slice>
            </slice>
            <slice>
              <time_slice>15:43</time_slice>
              <text_slice>28th.</text_slice>
            </slice>
            <slice>
              <time_slice>15:44</time_slice>
              <text_slice>Now, generally, the lectures
here, they're mandatory</text_slice>
            </slice>
            <slice>
              <time_slice>15:47</time_slice>
              <text_slice>and you have to know them, but
I know that some people say gee,</text_slice>
            </slice>
            <slice>
              <time_slice>15:52</time_slice>
              <text_slice>9:30 is kind of
early, especially</text_slice>
            </slice>
            <slice>
              <time_slice>15:53</time_slice>
              <text_slice>on a Monday or whatever.</text_slice>
            </slice>
            <slice>
              <time_slice>15:55</time_slice>
              <text_slice>It can be kind of
early to get up.</text_slice>
            </slice>
            <slice>
              <time_slice>15:58</time_slice>
              <text_slice>However, on Monday,
November 28th,</text_slice>
            </slice>
            <slice>
              <time_slice>16:01</time_slice>
              <text_slice>you fail the exam if you do
not show up to lecture on time.</text_slice>
            </slice>
            <slice>
              <time_slice>16:07</time_slice>
              <text_slice>That one day you must show up.</text_slice>
            </slice>
            <slice>
              <time_slice>16:10</time_slice>
              <text_slice>Any questions about that?</text_slice>
            </slice>
            <slice>
              <time_slice>16:11</time_slice>
              <text_slice>That one day you
must show up here,</text_slice>
            </slice>
            <slice>
              <time_slice>16:14</time_slice>
              <text_slice>even if you've been
watching them on the Web.</text_slice>
            </slice>
            <slice>
              <time_slice>16:18</time_slice>
              <text_slice>And generally, if you think
you have transgressed,</text_slice>
            </slice>
            <slice>
              <time_slice>16:21</time_slice>
              <text_slice>the best is to come to
us to talk about it.</text_slice>
            </slice>
            <slice>
              <time_slice>16:25</time_slice>
              <text_slice>We can usually
work something out.</text_slice>
            </slice>
            <slice>
              <time_slice>16:28</time_slice>
              <text_slice>It's when we find somebody has
transgressed from a third party</text_slice>
            </slice>
            <slice>
              <time_slice>16:34</time_slice>
              <text_slice>or from obvious analyses
that we do with homeworks,</text_slice>
            </slice>
            <slice>
              <time_slice>16:38</time_slice>
              <text_slice>that's when things get messy.</text_slice>
            </slice>
            <slice>
              <time_slice>16:41</time_slice>
              <text_slice>So, if you think, for
some reason or other,</text_slice>
            </slice>
            <slice>
              <time_slice>16:45</time_slice>
              <text_slice>oh, I may have done
something wrong,</text_slice>
            </slice>
            <slice>
              <time_slice>16:47</time_slice>
              <text_slice>please come and talk to us.</text_slice>
            </slice>
            <slice>
              <time_slice>16:49</time_slice>
              <text_slice>We actually were students once,
too, albeit many years ago.</text_slice>
            </slice>
            <slice>
              <time_slice>16:54</time_slice>
              <text_slice>Any questions?</text_slice>
            </slice>
            <slice>
              <time_slice>16:56</time_slice>
              <text_slice>So, this class has
great material.</text_slice>
            </slice>
            <slice>
              <time_slice>17:00</time_slice>
              <text_slice>Fabulous material.</text_slice>
            </slice>
            <slice>
              <time_slice>17:02</time_slice>
              <text_slice>And it's really fun, but
you do have to work hard.</text_slice>
            </slice>
            <slice>
              <time_slice>17:13</time_slice>
              <text_slice>Let's talk content.</text_slice>
            </slice>
            <slice>
              <time_slice>17:29</time_slice>
              <text_slice>This is the topic of the
first part of the course.</text_slice>
            </slice>
            <slice>
              <time_slice>17:32</time_slice>
              <text_slice>The first part of the course
is focused on analysis.</text_slice>
            </slice>
            <slice>
              <time_slice>17:35</time_slice>
              <text_slice>The second part of the
course is focused on design.</text_slice>
            </slice>
            <slice>
              <time_slice>17:39</time_slice>
              <text_slice>Before you can do
design, you have</text_slice>
            </slice>
            <slice>
              <time_slice>17:41</time_slice>
              <text_slice>to master a bunch of techniques
for analyzing algorithms.</text_slice>
            </slice>
            <slice>
              <time_slice>17:45</time_slice>
              <text_slice>And then you'll be in a
position to design algorithms</text_slice>
            </slice>
            <slice>
              <time_slice>17:49</time_slice>
              <text_slice>that you can analyze and
that which are efficient.</text_slice>
            </slice>
            <slice>
              <time_slice>17:52</time_slice>
              <text_slice>The analysis of algorithm is
the theoretical study -- --</text_slice>
            </slice>
            <slice>
              <time_slice>18:06</time_slice>
              <text_slice>of computer program performance
-- -- and resource usage.</text_slice>
            </slice>
            <slice>
              <time_slice>18:21</time_slice>
              <text_slice>And a particular
focus on performance.</text_slice>
            </slice>
            <slice>
              <time_slice>18:24</time_slice>
              <text_slice>We're studying how
to make things fast.</text_slice>
            </slice>
            <slice>
              <time_slice>18:29</time_slice>
              <text_slice>In particular,
computer programs.</text_slice>
            </slice>
            <slice>
              <time_slice>18:32</time_slice>
              <text_slice>We also will discover and
talk about other resources</text_slice>
            </slice>
            <slice>
              <time_slice>18:37</time_slice>
              <text_slice>such as communication, such
as memory, whether RAM memory</text_slice>
            </slice>
            <slice>
              <time_slice>18:43</time_slice>
              <text_slice>or disk memory.</text_slice>
            </slice>
            <slice>
              <time_slice>18:44</time_slice>
              <text_slice>There are other resources
that we may care about,</text_slice>
            </slice>
            <slice>
              <time_slice>18:49</time_slice>
              <text_slice>but predominantly we
focus on performance.</text_slice>
            </slice>
            <slice>
              <time_slice>18:52</time_slice>
              <text_slice>Because this is a course
about performance,</text_slice>
            </slice>
            <slice>
              <time_slice>18:57</time_slice>
              <text_slice>I like to put things in
perspective a little bit</text_slice>
            </slice>
            <slice>
              <time_slice>19:02</time_slice>
              <text_slice>by starting out and asking,
in programming, what is more</text_slice>
            </slice>
            <slice>
              <time_slice>19:10</time_slice>
              <text_slice>important than performance?</text_slice>
            </slice>
            <slice>
              <time_slice>19:13</time_slice>
              <text_slice>If you're in an engineering
situation and writing code,</text_slice>
            </slice>
            <slice>
              <time_slice>19:18</time_slice>
              <text_slice>writing software, what's more
important than performance?</text_slice>
            </slice>
            <slice>
              <time_slice>19:24</time_slice>
              <text_slice>Correctness.</text_slice>
            </slice>
            <slice>
              <time_slice>19:26</time_slice>
              <text_slice>Good.</text_slice>
            </slice>
            <slice>
              <time_slice>19:26</time_slice>
              <text_slice>OK.</text_slice>
            </slice>
            <slice>
              <time_slice>19:27</time_slice>
              <text_slice>What else?</text_slice>
            </slice>
            <slice>
              <time_slice>19:28</time_slice>
              <text_slice>Simplicity can be.</text_slice>
            </slice>
            <slice>
              <time_slice>19:31</time_slice>
              <text_slice>Very good.</text_slice>
            </slice>
            <slice>
              <time_slice>19:31</time_slice>
              <text_slice>Yeah.</text_slice>
            </slice>
            <slice>
              <time_slice>19:32</time_slice>
              <text_slice>Maintainability often much more
important than performance.</text_slice>
            </slice>
            <slice>
              <time_slice>19:40</time_slice>
              <text_slice>Cost.</text_slice>
            </slice>
            <slice>
              <time_slice>19:40</time_slice>
              <text_slice>And what type of cost
are you thinking?</text_slice>
            </slice>
            <slice>
              <time_slice>19:44</time_slice>
              <text_slice>No, I mean cost of what?</text_slice>
            </slice>
            <slice>
              <time_slice>19:49</time_slice>
              <text_slice>We're talking
software here, right?</text_slice>
            </slice>
            <slice>
              <time_slice>19:53</time_slice>
              <text_slice>What type of cost
do you have in mind?</text_slice>
            </slice>
            <slice>
              <time_slice>20:00</time_slice>
              <text_slice>There are some costs that
are involved when programming</text_slice>
            </slice>
            <slice>
              <time_slice>20:04</time_slice>
              <text_slice>like programmer time.</text_slice>
            </slice>
            <slice>
              <time_slice>20:05</time_slice>
              <text_slice>So, programmer time is another
thing also that might be.</text_slice>
            </slice>
            <slice>
              <time_slice>20:10</time_slice>
              <text_slice>Stability.</text_slice>
            </slice>
            <slice>
              <time_slice>20:11</time_slice>
              <text_slice>Robustness of the software.</text_slice>
            </slice>
            <slice>
              <time_slice>20:13</time_slice>
              <text_slice>Does it break all the time?</text_slice>
            </slice>
            <slice>
              <time_slice>20:16</time_slice>
              <text_slice>What else?</text_slice>
            </slice>
            <slice>
              <time_slice>20:25</time_slice>
              <text_slice>Come on.</text_slice>
            </slice>
            <slice>
              <time_slice>20:25</time_slice>
              <text_slice>We've got a bunch
of engineers here.</text_slice>
            </slice>
            <slice>
              <time_slice>20:28</time_slice>
              <text_slice>A lot of things.</text_slice>
            </slice>
            <slice>
              <time_slice>20:30</time_slice>
              <text_slice>How about features?</text_slice>
            </slice>
            <slice>
              <time_slice>20:31</time_slice>
              <text_slice>Features can be more important.</text_slice>
            </slice>
            <slice>
              <time_slice>20:33</time_slice>
              <text_slice>Having a wider collection of
features than your competitors.</text_slice>
            </slice>
            <slice>
              <time_slice>20:37</time_slice>
              <text_slice>Functionality.</text_slice>
            </slice>
            <slice>
              <time_slice>20:38</time_slice>
              <text_slice>Modularity.</text_slice>
            </slice>
            <slice>
              <time_slice>20:39</time_slice>
              <text_slice>Is it designed in a way
where you can make changes</text_slice>
            </slice>
            <slice>
              <time_slice>20:42</time_slice>
              <text_slice>in a local part of the code and
you don't have to make changes</text_slice>
            </slice>
            <slice>
              <time_slice>20:47</time_slice>
              <text_slice>across the code in order
to affect a simple change</text_slice>
            </slice>
            <slice>
              <time_slice>20:50</time_slice>
              <text_slice>in the functionality?</text_slice>
            </slice>
            <slice>
              <time_slice>20:52</time_slice>
              <text_slice>There is one big one
which definitely,</text_slice>
            </slice>
            <slice>
              <time_slice>20:54</time_slice>
              <text_slice>especially in the `90s, was
like the big thing in computers.</text_slice>
            </slice>
            <slice>
              <time_slice>21:01</time_slice>
              <text_slice>The big thing.</text_slice>
            </slice>
            <slice>
              <time_slice>21:01</time_slice>
              <text_slice>Well, security actually.</text_slice>
            </slice>
            <slice>
              <time_slice>21:03</time_slice>
              <text_slice>Good.</text_slice>
            </slice>
            <slice>
              <time_slice>21:03</time_slice>
              <text_slice>I don't even have that one down.</text_slice>
            </slice>
            <slice>
              <time_slice>21:06</time_slice>
              <text_slice>Security is excellent.</text_slice>
            </slice>
            <slice>
              <time_slice>21:08</time_slice>
              <text_slice>That's actually been
more in the 2000.</text_slice>
            </slice>
            <slice>
              <time_slice>21:11</time_slice>
              <text_slice>Security has been
far more important</text_slice>
            </slice>
            <slice>
              <time_slice>21:13</time_slice>
              <text_slice>often than performance.</text_slice>
            </slice>
            <slice>
              <time_slice>21:14</time_slice>
              <text_slice>Scalability has been important,
although scalability,</text_slice>
            </slice>
            <slice>
              <time_slice>21:18</time_slice>
              <text_slice>in some sense, is
performance related.</text_slice>
            </slice>
            <slice>
              <time_slice>21:21</time_slice>
              <text_slice>But, yes, scalability is good.</text_slice>
            </slice>
            <slice>
              <time_slice>21:24</time_slice>
              <text_slice>What was the big breakthrough
and why do people use Macintosh</text_slice>
            </slice>
            <slice>
              <time_slice>21:29</time_slice>
              <text_slice>rather than Windows,
those people who</text_slice>
            </slice>
            <slice>
              <time_slice>21:30</time_slice>
              <text_slice>are of that religion?</text_slice>
            </slice>
            <slice>
              <time_slice>21:34</time_slice>
              <text_slice>User-friendliness.</text_slice>
            </slice>
            <slice>
              <time_slice>21:35</time_slice>
              <text_slice>Wow.</text_slice>
            </slice>
            <slice>
              <time_slice>21:36</time_slice>
              <text_slice>If you look at the number of
cycles of computers that went</text_slice>
            </slice>
            <slice>
              <time_slice>21:40</time_slice>
              <text_slice>into user friendliness
in the `90s,</text_slice>
            </slice>
            <slice>
              <time_slice>21:43</time_slice>
              <text_slice>it grew from almost nothing to
where it's now the vast part</text_slice>
            </slice>
            <slice>
              <time_slice>21:48</time_slice>
              <text_slice>of the computation goes
into user friendly.</text_slice>
            </slice>
            <slice>
              <time_slice>21:52</time_slice>
              <text_slice>So, all those things are more
important than performance.</text_slice>
            </slice>
            <slice>
              <time_slice>21:56</time_slice>
              <text_slice>This is a course on performance.</text_slice>
            </slice>
            <slice>
              <time_slice>22:00</time_slice>
              <text_slice>Then you can say OK,
well, why do we bother</text_slice>
            </slice>
            <slice>
              <time_slice>22:04</time_slice>
              <text_slice>and why study algorithms
and performance if it's</text_slice>
            </slice>
            <slice>
              <time_slice>22:08</time_slice>
              <text_slice>at the bottom of the heap?</text_slice>
            </slice>
            <slice>
              <time_slice>22:12</time_slice>
              <text_slice>Almost always
people would rather</text_slice>
            </slice>
            <slice>
              <time_slice>22:15</time_slice>
              <text_slice>have these other things
than performance.</text_slice>
            </slice>
            <slice>
              <time_slice>22:20</time_slice>
              <text_slice>You go off and you
say to somebody,</text_slice>
            </slice>
            <slice>
              <time_slice>22:24</time_slice>
              <text_slice>would I rather have performance
or more user friendliness?</text_slice>
            </slice>
            <slice>
              <time_slice>22:32</time_slice>
              <text_slice>It's almost always more
important than performance.</text_slice>
            </slice>
            <slice>
              <time_slice>22:36</time_slice>
              <text_slice>Why do we care then?</text_slice>
            </slice>
            <slice>
              <time_slice>22:38</time_slice>
              <text_slice>Yeah?</text_slice>
            </slice>
            <slice>
              <time_slice>22:44</time_slice>
              <text_slice>That wasn't user friendly.</text_slice>
            </slice>
            <slice>
              <time_slice>22:45</time_slice>
              <text_slice>Sometimes performance
is correlated with user</text_slice>
            </slice>
            <slice>
              <time_slice>22:49</time_slice>
              <text_slice>friendliness, absolutely.</text_slice>
            </slice>
            <slice>
              <time_slice>22:50</time_slice>
              <text_slice>Nothing is more frustrating than
sitting there waiting, right?</text_slice>
            </slice>
            <slice>
              <time_slice>22:55</time_slice>
              <text_slice>So, that's a good reason.</text_slice>
            </slice>
            <slice>
              <time_slice>22:56</time_slice>
              <text_slice>What are some other reasons why?</text_slice>
            </slice>
            <slice>
              <time_slice>22:58</time_slice>
              <text_slice>Sometimes they have
real time constraints</text_slice>
            </slice>
            <slice>
              <time_slice>23:02</time_slice>
              <text_slice>so they don't actually work
unless they perform adequately.</text_slice>
            </slice>
            <slice>
              <time_slice>23:09</time_slice>
              <text_slice>Yeah?</text_slice>
            </slice>
            <slice>
              <time_slice>23:10</time_slice>
              <text_slice>Hard to get, well,
we don't usually</text_slice>
            </slice>
            <slice>
              <time_slice>23:13</time_slice>
              <text_slice>quantify user friendliness
so I'm not sure,</text_slice>
            </slice>
            <slice>
              <time_slice>23:17</time_slice>
              <text_slice>but I understand
what you're saying.</text_slice>
            </slice>
            <slice>
              <time_slice>23:20</time_slice>
              <text_slice>He said we don't get exponential
performance improvements</text_slice>
            </slice>
            <slice>
              <time_slice>23:25</time_slice>
              <text_slice>in user friendliness.</text_slice>
            </slice>
            <slice>
              <time_slice>23:27</time_slice>
              <text_slice>We often don't get that in
performance either, by the way.</text_slice>
            </slice>
            <slice>
              <time_slice>23:34</time_slice>
              <text_slice>[LAUGHTER] Sometimes
we do, but that's good.</text_slice>
            </slice>
            <slice>
              <time_slice>23:38</time_slice>
              <text_slice>There are several reasons
that I think are important.</text_slice>
            </slice>
            <slice>
              <time_slice>23:42</time_slice>
              <text_slice>Once is that often
performance measures</text_slice>
            </slice>
            <slice>
              <time_slice>23:45</time_slice>
              <text_slice>the line between the
feasible and the infeasible.</text_slice>
            </slice>
            <slice>
              <time_slice>23:48</time_slice>
              <text_slice>We have heard some
of these things.</text_slice>
            </slice>
            <slice>
              <time_slice>23:51</time_slice>
              <text_slice>For example, when there
are real time requirements,</text_slice>
            </slice>
            <slice>
              <time_slice>23:56</time_slice>
              <text_slice>if it's not fast enough
it's simply not functional.</text_slice>
            </slice>
            <slice>
              <time_slice>24:02</time_slice>
              <text_slice>Or, if it uses too much
memory it's simply not</text_slice>
            </slice>
            <slice>
              <time_slice>24:04</time_slice>
              <text_slice>going to work for you.</text_slice>
            </slice>
            <slice>
              <time_slice>24:05</time_slice>
              <text_slice>And, as a consequence,
what you find is algorithms</text_slice>
            </slice>
            <slice>
              <time_slice>24:08</time_slice>
              <text_slice>are on the cutting edge
of entrepreneurship.</text_slice>
            </slice>
            <slice>
              <time_slice>24:10</time_slice>
              <text_slice>If you're talking about
just re implementing stuff</text_slice>
            </slice>
            <slice>
              <time_slice>24:13</time_slice>
              <text_slice>that people did ten
years ago, performance</text_slice>
            </slice>
            <slice>
              <time_slice>24:16</time_slice>
              <text_slice>isn't that important
at some level.</text_slice>
            </slice>
            <slice>
              <time_slice>24:19</time_slice>
              <text_slice>But, if you're talking
about doing stuff</text_slice>
            </slice>
            <slice>
              <time_slice>24:21</time_slice>
              <text_slice>that nobody has done
before, one of the reasons</text_slice>
            </slice>
            <slice>
              <time_slice>24:24</time_slice>
              <text_slice>often that they haven't
done it is because it's too</text_slice>
            </slice>
            <slice>
              <time_slice>24:28</time_slice>
              <text_slice>time consuming.</text_slice>
            </slice>
            <slice>
              <time_slice>24:29</time_slice>
              <text_slice>Things don't scale and so forth.</text_slice>
            </slice>
            <slice>
              <time_slice>24:31</time_slice>
              <text_slice>So, that's one reason, is the
feasible versus infeasible.</text_slice>
            </slice>
            <slice>
              <time_slice>24:36</time_slice>
              <text_slice>Another thing is that
algorithms give you</text_slice>
            </slice>
            <slice>
              <time_slice>24:39</time_slice>
              <text_slice>a language for talking
about program behavior,</text_slice>
            </slice>
            <slice>
              <time_slice>24:42</time_slice>
              <text_slice>and that turns out
to be a language that</text_slice>
            </slice>
            <slice>
              <time_slice>24:45</time_slice>
              <text_slice>has been pervasive
through computer science,</text_slice>
            </slice>
            <slice>
              <time_slice>24:48</time_slice>
              <text_slice>is that the theoretical language
is what gets adopted by all</text_slice>
            </slice>
            <slice>
              <time_slice>24:53</time_slice>
              <text_slice>the practitioners because
it's a clean way of thinking</text_slice>
            </slice>
            <slice>
              <time_slice>24:57</time_slice>
              <text_slice>about things.</text_slice>
            </slice>
            <slice>
              <time_slice>24:58</time_slice>
              <text_slice>A good way I think
about performance,</text_slice>
            </slice>
            <slice>
              <time_slice>25:02</time_slice>
              <text_slice>and the reason it's on
the bottom of the heap,</text_slice>
            </slice>
            <slice>
              <time_slice>25:07</time_slice>
              <text_slice>is sort of like performance is
like money, it's like currency.</text_slice>
            </slice>
            <slice>
              <time_slice>25:13</time_slice>
              <text_slice>You say what good does a
stack of hundred dollar bills</text_slice>
            </slice>
            <slice>
              <time_slice>25:17</time_slice>
              <text_slice>do for you?</text_slice>
            </slice>
            <slice>
              <time_slice>25:18</time_slice>
              <text_slice>Would you rather have food or
water or shelter or whatever?</text_slice>
            </slice>
            <slice>
              <time_slice>25:23</time_slice>
              <text_slice>And you're willing to
pay those hundred dollar</text_slice>
            </slice>
            <slice>
              <time_slice>25:28</time_slice>
              <text_slice>bills, if you have
hundred dollar bills,</text_slice>
            </slice>
            <slice>
              <time_slice>25:31</time_slice>
              <text_slice>for that commodity.</text_slice>
            </slice>
            <slice>
              <time_slice>25:33</time_slice>
              <text_slice>Even though water is far more
important to your living.</text_slice>
            </slice>
            <slice>
              <time_slice>25:39</time_slice>
              <text_slice>Well, similarly,
performance is what you use</text_slice>
            </slice>
            <slice>
              <time_slice>25:42</time_slice>
              <text_slice>to pay for user friendliness.</text_slice>
            </slice>
            <slice>
              <time_slice>25:44</time_slice>
              <text_slice>It's what you pay for security.</text_slice>
            </slice>
            <slice>
              <time_slice>25:46</time_slice>
              <text_slice>And you hear people
say, for example,</text_slice>
            </slice>
            <slice>
              <time_slice>25:48</time_slice>
              <text_slice>that I want greater
functionality,</text_slice>
            </slice>
            <slice>
              <time_slice>25:50</time_slice>
              <text_slice>so people will program
in Java, even though it's</text_slice>
            </slice>
            <slice>
              <time_slice>25:54</time_slice>
              <text_slice>much slower than
C, because they'll</text_slice>
            </slice>
            <slice>
              <time_slice>25:57</time_slice>
              <text_slice>say it costs me maybe
a factor of three</text_slice>
            </slice>
            <slice>
              <time_slice>26:00</time_slice>
              <text_slice>or something in performance
to program in Java.</text_slice>
            </slice>
            <slice>
              <time_slice>26:03</time_slice>
              <text_slice>But Java is worth
it because it's</text_slice>
            </slice>
            <slice>
              <time_slice>26:06</time_slice>
              <text_slice>got all these object oriented
features and so forth,</text_slice>
            </slice>
            <slice>
              <time_slice>26:10</time_slice>
              <text_slice>exception mechanisms and so on.</text_slice>
            </slice>
            <slice>
              <time_slice>26:12</time_slice>
              <text_slice>And so people are willing
to pay a factor of three</text_slice>
            </slice>
            <slice>
              <time_slice>26:15</time_slice>
              <text_slice>in performance.</text_slice>
            </slice>
            <slice>
              <time_slice>26:16</time_slice>
              <text_slice>So, that's why you
want performance</text_slice>
            </slice>
            <slice>
              <time_slice>26:18</time_slice>
              <text_slice>because you can use it to
pay for these other things</text_slice>
            </slice>
            <slice>
              <time_slice>26:22</time_slice>
              <text_slice>that you want.</text_slice>
            </slice>
            <slice>
              <time_slice>26:22</time_slice>
              <text_slice>And that's why, in some sense,
it's on the bottom of the heap,</text_slice>
            </slice>
            <slice>
              <time_slice>26:27</time_slice>
              <text_slice>because it's the universal
thing that you quantify.</text_slice>
            </slice>
            <slice>
              <time_slice>26:32</time_slice>
              <text_slice>Do you want to spend a
factor of two on this</text_slice>
            </slice>
            <slice>
              <time_slice>26:35</time_slice>
              <text_slice>or spend a factor of three
on security, et cetera?</text_slice>
            </slice>
            <slice>
              <time_slice>26:39</time_slice>
              <text_slice>And, in addition, the
lessons generalize</text_slice>
            </slice>
            <slice>
              <time_slice>26:42</time_slice>
              <text_slice>to other resource measures
like communication,</text_slice>
            </slice>
            <slice>
              <time_slice>26:46</time_slice>
              <text_slice>like memory and so forth.</text_slice>
            </slice>
            <slice>
              <time_slice>26:47</time_slice>
              <text_slice>And the last reason we
study algorithm performance</text_slice>
            </slice>
            <slice>
              <time_slice>26:51</time_slice>
              <text_slice>is it's tons of fun.</text_slice>
            </slice>
            <slice>
              <time_slice>26:54</time_slice>
              <text_slice>Speed is always fun, right?</text_slice>
            </slice>
            <slice>
              <time_slice>26:56</time_slice>
              <text_slice>Why do people drive fast
cars, race horses, whatever?</text_slice>
            </slice>
            <slice>
              <time_slice>27:00</time_slice>
              <text_slice>Rockets, et cetera,
why do we do that?</text_slice>
            </slice>
            <slice>
              <time_slice>27:04</time_slice>
              <text_slice>Because speed is fun.</text_slice>
            </slice>
            <slice>
              <time_slice>27:05</time_slice>
              <text_slice>Ski.</text_slice>
            </slice>
            <slice>
              <time_slice>27:06</time_slice>
              <text_slice>Who likes to ski?</text_slice>
            </slice>
            <slice>
              <time_slice>27:07</time_slice>
              <text_slice>I love to ski.</text_slice>
            </slice>
            <slice>
              <time_slice>27:08</time_slice>
              <text_slice>I like going fast on those skis.</text_slice>
            </slice>
            <slice>
              <time_slice>27:10</time_slice>
              <text_slice>It's fun.</text_slice>
            </slice>
            <slice>
              <time_slice>27:11</time_slice>
              <text_slice>Hockey, fast sports, right?</text_slice>
            </slice>
            <slice>
              <time_slice>27:13</time_slice>
              <text_slice>We all like the fast sports.</text_slice>
            </slice>
            <slice>
              <time_slice>27:14</time_slice>
              <text_slice>Not all of us, I mean.</text_slice>
            </slice>
            <slice>
              <time_slice>27:16</time_slice>
              <text_slice>Some people say he's
not talking to me.</text_slice>
            </slice>
            <slice>
              <time_slice>27:18</time_slice>
              <text_slice>OK, let's move on.</text_slice>
            </slice>
            <slice>
              <time_slice>27:20</time_slice>
              <text_slice>That's sort of a little bit of a
notion as to why we study this,</text_slice>
            </slice>
            <slice>
              <time_slice>27:24</time_slice>
              <text_slice>is that it does,
in some sense, form</text_slice>
            </slice>
            <slice>
              <time_slice>27:27</time_slice>
              <text_slice>a common basis for all these
other things we care about.</text_slice>
            </slice>
            <slice>
              <time_slice>27:30</time_slice>
              <text_slice>And so we want to understand
how can we generate money</text_slice>
            </slice>
            <slice>
              <time_slice>27:37</time_slice>
              <text_slice>for ourselves in computation?</text_slice>
            </slice>
            <slice>
              <time_slice>27:40</time_slice>
              <text_slice>We're going to start out
with a very simple problem.</text_slice>
            </slice>
            <slice>
              <time_slice>27:44</time_slice>
              <text_slice>It's one of the
oldest problems that</text_slice>
            </slice>
            <slice>
              <time_slice>27:47</time_slice>
              <text_slice>has been studied in algorithms,
is the problem of sorting.</text_slice>
            </slice>
            <slice>
              <time_slice>27:52</time_slice>
              <text_slice>We're going to actually study
this for several lectures</text_slice>
            </slice>
            <slice>
              <time_slice>27:57</time_slice>
              <text_slice>because sorting contains
many algorithmic techniques.</text_slice>
            </slice>
            <slice>
              <time_slice>28:03</time_slice>
              <text_slice>The sorting problem
is the following.</text_slice>
            </slice>
            <slice>
              <time_slice>28:10</time_slice>
              <text_slice>We have a sequence a 1, a 2
up to a n of numbers as input.</text_slice>
            </slice>
            <slice>
              <time_slice>28:21</time_slice>
              <text_slice>And our output is a
permutation of those numbers.</text_slice>
            </slice>
            <slice>
              <time_slice>28:42</time_slice>
              <text_slice>A permutation is a
rearrangement of the numbers.</text_slice>
            </slice>
            <slice>
              <time_slice>28:47</time_slice>
              <text_slice>Every number appears exactly
once in the rearrangement such</text_slice>
            </slice>
            <slice>
              <time_slice>28:53</time_slice>
              <text_slice>that, I sometimes use a dollar
sign to mean "such that,"</text_slice>
            </slice>
            <slice>
              <time_slice>28:57</time_slice>
              <text_slice>a 1 is less than or
equal to a 2 prime.</text_slice>
            </slice>
            <slice>
              <time_slice>29:03</time_slice>
              <text_slice>Such that they are monotonically
increasing in size.</text_slice>
            </slice>
            <slice>
              <time_slice>29:11</time_slice>
              <text_slice>Take a bunch of numbers,
put them in order.</text_slice>
            </slice>
            <slice>
              <time_slice>29:17</time_slice>
              <text_slice>Here's an algorithm to do it.</text_slice>
            </slice>
            <slice>
              <time_slice>29:23</time_slice>
              <text_slice>It's called insertion sort.</text_slice>
            </slice>
            <slice>
              <time_slice>29:40</time_slice>
              <text_slice>And we will write this algorithm
in what we call pseudocode.</text_slice>
            </slice>
            <slice>
              <time_slice>29:44</time_slice>
              <text_slice>It's sort of a
programming language,</text_slice>
            </slice>
            <slice>
              <time_slice>29:47</time_slice>
              <text_slice>except it's got
English in there often.</text_slice>
            </slice>
            <slice>
              <time_slice>29:51</time_slice>
              <text_slice>And it's just a shorthand for
writing for being precise.</text_slice>
            </slice>
            <slice>
              <time_slice>29:57</time_slice>
              <text_slice>So this sorts A from 1 to n.</text_slice>
            </slice>
            <slice>
              <time_slice>30:01</time_slice>
              <text_slice>And here is the code for it.</text_slice>
            </slice>
            <slice>
              <time_slice>30:59</time_slice>
              <text_slice>This is what we call pseudocode.</text_slice>
            </slice>
            <slice>
              <time_slice>31:01</time_slice>
              <text_slice>And if you don't understand
the pseudocode then</text_slice>
            </slice>
            <slice>
              <time_slice>31:04</time_slice>
              <text_slice>you should ask questions
about any of the notations.</text_slice>
            </slice>
            <slice>
              <time_slice>31:09</time_slice>
              <text_slice>You will start to get
used to it as we go on.</text_slice>
            </slice>
            <slice>
              <time_slice>31:13</time_slice>
              <text_slice>One thing is that
in the pseudocode</text_slice>
            </slice>
            <slice>
              <time_slice>31:16</time_slice>
              <text_slice>we use indentation,
where in most languages</text_slice>
            </slice>
            <slice>
              <time_slice>31:19</time_slice>
              <text_slice>they have some kind of begin
end delimiters like curly braces</text_slice>
            </slice>
            <slice>
              <time_slice>31:24</time_slice>
              <text_slice>or something in Java
or C, for example.</text_slice>
            </slice>
            <slice>
              <time_slice>31:28</time_slice>
              <text_slice>We just use indentation.</text_slice>
            </slice>
            <slice>
              <time_slice>31:31</time_slice>
              <text_slice>The whole idea of
the pseudocode is</text_slice>
            </slice>
            <slice>
              <time_slice>31:33</time_slice>
              <text_slice>to try to get the algorithms
as short as possible</text_slice>
            </slice>
            <slice>
              <time_slice>31:37</time_slice>
              <text_slice>while still understanding
what the individual steps are.</text_slice>
            </slice>
            <slice>
              <time_slice>31:41</time_slice>
              <text_slice>In practice, there
actually have been</text_slice>
            </slice>
            <slice>
              <time_slice>31:44</time_slice>
              <text_slice>languages that use indentation
as a means of showing</text_slice>
            </slice>
            <slice>
              <time_slice>31:47</time_slice>
              <text_slice>the nesting of things.</text_slice>
            </slice>
            <slice>
              <time_slice>31:49</time_slice>
              <text_slice>It's generally a bad idea,
because if things go over one</text_slice>
            </slice>
            <slice>
              <time_slice>31:52</time_slice>
              <text_slice>page to another, for example,
you cannot tell what level</text_slice>
            </slice>
            <slice>
              <time_slice>31:56</time_slice>
              <text_slice>of nesting it is.</text_slice>
            </slice>
            <slice>
              <time_slice>31:59</time_slice>
              <text_slice>Whereas, with explicit braces
it's much easier to tell.</text_slice>
            </slice>
            <slice>
              <time_slice>32:03</time_slice>
              <text_slice>So, there are reasons why this
is a bad notation if you were</text_slice>
            </slice>
            <slice>
              <time_slice>32:09</time_slice>
              <text_slice>doing software engineering.</text_slice>
            </slice>
            <slice>
              <time_slice>32:10</time_slice>
              <text_slice>But it's a good one
for us because it just</text_slice>
            </slice>
            <slice>
              <time_slice>32:15</time_slice>
              <text_slice>keeps things short and makes
fewer things to write down.</text_slice>
            </slice>
            <slice>
              <time_slice>32:20</time_slice>
              <text_slice>So, this is insertion sort.</text_slice>
            </slice>
            <slice>
              <time_slice>32:23</time_slice>
              <text_slice>Let's try to figure out a
little bit what this does.</text_slice>
            </slice>
            <slice>
              <time_slice>32:29</time_slice>
              <text_slice>It basically takes an
array A and at any point</text_slice>
            </slice>
            <slice>
              <time_slice>32:34</time_slice>
              <text_slice>the thing to understand is,
we're setting basically,</text_slice>
            </slice>
            <slice>
              <time_slice>32:42</time_slice>
              <text_slice>we're running the outer
loop from j is 2 to n,</text_slice>
            </slice>
            <slice>
              <time_slice>32:48</time_slice>
              <text_slice>and the inner loop that
starts at j minus 1</text_slice>
            </slice>
            <slice>
              <time_slice>32:53</time_slice>
              <text_slice>and then goes down
until it's zero.</text_slice>
            </slice>
            <slice>
              <time_slice>32:57</time_slice>
              <text_slice>Basically, if we look at
any point in the algorithm,</text_slice>
            </slice>
            <slice>
              <time_slice>33:03</time_slice>
              <text_slice>we essentially are looking
at some element here j.</text_slice>
            </slice>
            <slice>
              <time_slice>33:07</time_slice>
              <text_slice>A of j, the jth element.</text_slice>
            </slice>
            <slice>
              <time_slice>33:10</time_slice>
              <text_slice>And what we do essentially
is we pull a value out</text_slice>
            </slice>
            <slice>
              <time_slice>33:14</time_slice>
              <text_slice>here that we call the key.</text_slice>
            </slice>
            <slice>
              <time_slice>33:16</time_slice>
              <text_slice>And at this point the
important thing to understand,</text_slice>
            </slice>
            <slice>
              <time_slice>33:20</time_slice>
              <text_slice>and we'll talk more about
this in recitation on Friday,</text_slice>
            </slice>
            <slice>
              <time_slice>33:25</time_slice>
              <text_slice>is that there is an invariant
that is being maintained</text_slice>
            </slice>
            <slice>
              <time_slice>33:30</time_slice>
              <text_slice>by this loop each time through.</text_slice>
            </slice>
            <slice>
              <time_slice>33:35</time_slice>
              <text_slice>And the invariant is that this
part of the array is sorted.</text_slice>
            </slice>
            <slice>
              <time_slice>33:40</time_slice>
              <text_slice>And the goal each time through
the loop is to increase,</text_slice>
            </slice>
            <slice>
              <time_slice>33:45</time_slice>
              <text_slice>is to add one to the length
of the things that are sorted.</text_slice>
            </slice>
            <slice>
              <time_slice>33:51</time_slice>
              <text_slice>And the way we do that
is we pull out the key</text_slice>
            </slice>
            <slice>
              <time_slice>33:54</time_slice>
              <text_slice>and we just copy
values up like this.</text_slice>
            </slice>
            <slice>
              <time_slice>33:58</time_slice>
              <text_slice>And keep copying
up until we find</text_slice>
            </slice>
            <slice>
              <time_slice>34:02</time_slice>
              <text_slice>the place where this
key goes, and then we</text_slice>
            </slice>
            <slice>
              <time_slice>34:05</time_slice>
              <text_slice>insert it in that place.</text_slice>
            </slice>
            <slice>
              <time_slice>34:07</time_slice>
              <text_slice>And that's why it's
called insertion sort.</text_slice>
            </slice>
            <slice>
              <time_slice>34:11</time_slice>
              <text_slice>We just sort of move the
things, copy the things up</text_slice>
            </slice>
            <slice>
              <time_slice>34:16</time_slice>
              <text_slice>until we find where it goes,
and then we put it into place.</text_slice>
            </slice>
            <slice>
              <time_slice>34:21</time_slice>
              <text_slice>And now we have it from A
from one to j is sorted,</text_slice>
            </slice>
            <slice>
              <time_slice>34:25</time_slice>
              <text_slice>and now we can
work on j plus one.</text_slice>
            </slice>
            <slice>
              <time_slice>34:28</time_slice>
              <text_slice>Let's give an example of that.</text_slice>
            </slice>
            <slice>
              <time_slice>34:33</time_slice>
              <text_slice>Imagine we are doing
8, 2, 4, 9, 3, 6.</text_slice>
            </slice>
            <slice>
              <time_slice>34:38</time_slice>
              <text_slice>We start out with j equals 2.</text_slice>
            </slice>
            <slice>
              <time_slice>34:41</time_slice>
              <text_slice>And we figure out that we
want to insert it there.</text_slice>
            </slice>
            <slice>
              <time_slice>34:47</time_slice>
              <text_slice>Now we have 2, 8, 4, 9, 3, 6.</text_slice>
            </slice>
            <slice>
              <time_slice>34:51</time_slice>
              <text_slice>Then we look at the four and say
oh, well, that goes over here.</text_slice>
            </slice>
            <slice>
              <time_slice>35:00</time_slice>
              <text_slice>We get 2, 4, 8, 9, 3, 6
after the second iteration</text_slice>
            </slice>
            <slice>
              <time_slice>35:03</time_slice>
              <text_slice>of the outer loop.</text_slice>
            </slice>
            <slice>
              <time_slice>35:05</time_slice>
              <text_slice>Then we look at 9 and
discover immediately it just</text_slice>
            </slice>
            <slice>
              <time_slice>35:10</time_slice>
              <text_slice>goes right there.</text_slice>
            </slice>
            <slice>
              <time_slice>35:12</time_slice>
              <text_slice>Very little work
to do on that step.</text_slice>
            </slice>
            <slice>
              <time_slice>35:15</time_slice>
              <text_slice>So, we have exactly the same
output after that iteration.</text_slice>
            </slice>
            <slice>
              <time_slice>35:20</time_slice>
              <text_slice>Then we look at the
3 and that's going</text_slice>
            </slice>
            <slice>
              <time_slice>35:24</time_slice>
              <text_slice>to be inserted over there.</text_slice>
            </slice>
            <slice>
              <time_slice>35:26</time_slice>
              <text_slice>2, 3, 4, 8, 9, and
that goes in there.</text_slice>
            </slice>
            <slice>
              <time_slice>35:36</time_slice>
              <text_slice>2, 3, 4, 6, 8,</text_slice>
            </slice>
            <slice>
              <time_slice>35:44</time_slice>
              <text_slice>Question?</text_slice>
            </slice>
            <slice>
              <time_slice>35:58</time_slice>
              <text_slice>The array initially
starts at one, yes.</text_slice>
            </slice>
            <slice>
              <time_slice>36:01</time_slice>
              <text_slice>A[1...n], OK?</text_slice>
            </slice>
            <slice>
              <time_slice>36:02</time_slice>
              <text_slice>So, this is the
insertion sort algorithm.</text_slice>
            </slice>
            <slice>
              <time_slice>36:05</time_slice>
              <text_slice>And it's the first algorithm
that we're going to analyze.</text_slice>
            </slice>
            <slice>
              <time_slice>36:11</time_slice>
              <text_slice>And we're going to
pull out some tools</text_slice>
            </slice>
            <slice>
              <time_slice>36:15</time_slice>
              <text_slice>that we have from
our math background</text_slice>
            </slice>
            <slice>
              <time_slice>36:18</time_slice>
              <text_slice>to help to analyze it.</text_slice>
            </slice>
            <slice>
              <time_slice>36:21</time_slice>
              <text_slice>First of all, let's take a look
at the issue of running time.</text_slice>
            </slice>
            <slice>
              <time_slice>36:29</time_slice>
              <text_slice>The running time depends,
of this algorithm</text_slice>
            </slice>
            <slice>
              <time_slice>36:33</time_slice>
              <text_slice>depends on a lot of things.</text_slice>
            </slice>
            <slice>
              <time_slice>36:37</time_slice>
              <text_slice>One thing it depends
on is the input itself.</text_slice>
            </slice>
            <slice>
              <time_slice>36:42</time_slice>
              <text_slice>For example, if the input
is already sorted -- --</text_slice>
            </slice>
            <slice>
              <time_slice>36:55</time_slice>
              <text_slice>then insertion sort has
very little work to do.</text_slice>
            </slice>
            <slice>
              <time_slice>37:00</time_slice>
              <text_slice>Because every time through it's
going to be like this case.</text_slice>
            </slice>
            <slice>
              <time_slice>37:04</time_slice>
              <text_slice>It doesn't have to
shuffle too many guys over</text_slice>
            </slice>
            <slice>
              <time_slice>37:07</time_slice>
              <text_slice>because they're
already in place.</text_slice>
            </slice>
            <slice>
              <time_slice>37:09</time_slice>
              <text_slice>Whereas, in some sense,
what's the worst case</text_slice>
            </slice>
            <slice>
              <time_slice>37:12</time_slice>
              <text_slice>for insertion sort?</text_slice>
            </slice>
            <slice>
              <time_slice>37:14</time_slice>
              <text_slice>If it is reverse
sorted then it's</text_slice>
            </slice>
            <slice>
              <time_slice>37:16</time_slice>
              <text_slice>going to have to
do a lot of work</text_slice>
            </slice>
            <slice>
              <time_slice>37:19</time_slice>
              <text_slice>because it's going to have
to shuffle everything over</text_slice>
            </slice>
            <slice>
              <time_slice>37:23</time_slice>
              <text_slice>on each step of the outer loop.</text_slice>
            </slice>
            <slice>
              <time_slice>37:26</time_slice>
              <text_slice>In addition to the actual
input it depends, of course,</text_slice>
            </slice>
            <slice>
              <time_slice>37:30</time_slice>
              <text_slice>on the input size.</text_slice>
            </slice>
            <slice>
              <time_slice>37:38</time_slice>
              <text_slice>Here, for example,
we did six elements.</text_slice>
            </slice>
            <slice>
              <time_slice>37:41</time_slice>
              <text_slice>It's going to take longer if
we, for example, do six times</text_slice>
            </slice>
            <slice>
              <time_slice>37:47</time_slice>
              <text_slice>ten to the ninth elements.</text_slice>
            </slice>
            <slice>
              <time_slice>37:50</time_slice>
              <text_slice>If we were sorting
a lot more stuff,</text_slice>
            </slice>
            <slice>
              <time_slice>37:53</time_slice>
              <text_slice>it's going to take
us a lot longer.</text_slice>
            </slice>
            <slice>
              <time_slice>37:57</time_slice>
              <text_slice>Typically, the way
we handle that is we</text_slice>
            </slice>
            <slice>
              <time_slice>38:01</time_slice>
              <text_slice>are going to parameterize
things in the input size.</text_slice>
            </slice>
            <slice>
              <time_slice>38:06</time_slice>
              <text_slice>We are going to talk
about time as a function</text_slice>
            </slice>
            <slice>
              <time_slice>38:11</time_slice>
              <text_slice>of the size of
things that we are</text_slice>
            </slice>
            <slice>
              <time_slice>38:14</time_slice>
              <text_slice>sorting so we can look at
what is the behavior of that.</text_slice>
            </slice>
            <slice>
              <time_slice>38:19</time_slice>
              <text_slice>And the last thing I want
to say about running time</text_slice>
            </slice>
            <slice>
              <time_slice>38:23</time_slice>
              <text_slice>is generally we want upper
bonds on the running time.</text_slice>
            </slice>
            <slice>
              <time_slice>38:30</time_slice>
              <text_slice>We want to know that the time is
no more than a certain amount.</text_slice>
            </slice>
            <slice>
              <time_slice>38:34</time_slice>
              <text_slice>And the reason is because
that represents a guarantee</text_slice>
            </slice>
            <slice>
              <time_slice>38:38</time_slice>
              <text_slice>to the user.</text_slice>
            </slice>
            <slice>
              <time_slice>38:40</time_slice>
              <text_slice>If I say it's not going to
run, for example, if I tell</text_slice>
            </slice>
            <slice>
              <time_slice>38:44</time_slice>
              <text_slice>you here's a program
and it won't run</text_slice>
            </slice>
            <slice>
              <time_slice>38:46</time_slice>
              <text_slice>more than three
seconds, that gives you</text_slice>
            </slice>
            <slice>
              <time_slice>38:50</time_slice>
              <text_slice>real information about how
you could use it, for example,</text_slice>
            </slice>
            <slice>
              <time_slice>38:55</time_slice>
              <text_slice>in a real time setting.</text_slice>
            </slice>
            <slice>
              <time_slice>38:58</time_slice>
              <text_slice>Whereas, if I said
here's a program</text_slice>
            </slice>
            <slice>
              <time_slice>39:00</time_slice>
              <text_slice>and it goes at
least three seconds,</text_slice>
            </slice>
            <slice>
              <time_slice>39:02</time_slice>
              <text_slice>you don't know if it's
going to go for three years.</text_slice>
            </slice>
            <slice>
              <time_slice>39:07</time_slice>
              <text_slice>It doesn't give you
that much guarantee</text_slice>
            </slice>
            <slice>
              <time_slice>39:10</time_slice>
              <text_slice>if you are a user of it.</text_slice>
            </slice>
            <slice>
              <time_slice>39:13</time_slice>
              <text_slice>Generally we want upper
bonds because it represents</text_slice>
            </slice>
            <slice>
              <time_slice>39:16</time_slice>
              <text_slice>a guarantee to the user.</text_slice>
            </slice>
            <slice>
              <time_slice>39:30</time_slice>
              <text_slice>There are different kinds
of analyses that people do.</text_slice>
            </slice>
            <slice>
              <time_slice>39:44</time_slice>
              <text_slice>The one we're mostly
going to focus on</text_slice>
            </slice>
            <slice>
              <time_slice>39:50</time_slice>
              <text_slice>is what's called
worst case analysis.</text_slice>
            </slice>
            <slice>
              <time_slice>39:55</time_slice>
              <text_slice>And this is what we do
usually where we define T of n</text_slice>
            </slice>
            <slice>
              <time_slice>40:04</time_slice>
              <text_slice>to be the maximum time
on any input of size n.</text_slice>
            </slice>
            <slice>
              <time_slice>40:12</time_slice>
              <text_slice>So, it's the maximum input,
the maximum it could possibly</text_slice>
            </slice>
            <slice>
              <time_slice>40:16</time_slice>
              <text_slice>cost us on an input of size n.</text_slice>
            </slice>
            <slice>
              <time_slice>40:19</time_slice>
              <text_slice>What that does is, if
you look at the fact</text_slice>
            </slice>
            <slice>
              <time_slice>40:21</time_slice>
              <text_slice>that sometimes the
inputs are better</text_slice>
            </slice>
            <slice>
              <time_slice>40:24</time_slice>
              <text_slice>and sometimes
they're worse, we're</text_slice>
            </slice>
            <slice>
              <time_slice>40:26</time_slice>
              <text_slice>looking at the
worst case of those</text_slice>
            </slice>
            <slice>
              <time_slice>40:28</time_slice>
              <text_slice>because that's the
way we're going</text_slice>
            </slice>
            <slice>
              <time_slice>40:30</time_slice>
              <text_slice>to be able to make a guarantee.</text_slice>
            </slice>
            <slice>
              <time_slice>40:34</time_slice>
              <text_slice>It always does something
rather than just sometimes</text_slice>
            </slice>
            <slice>
              <time_slice>40:36</time_slice>
              <text_slice>does something.</text_slice>
            </slice>
            <slice>
              <time_slice>40:37</time_slice>
              <text_slice>So, we're looking
at the maximum.</text_slice>
            </slice>
            <slice>
              <time_slice>40:40</time_slice>
              <text_slice>Notice that if I didn't have
maximum then T(n) in some sense</text_slice>
            </slice>
            <slice>
              <time_slice>40:44</time_slice>
              <text_slice>is a relation, not a
function, because the time</text_slice>
            </slice>
            <slice>
              <time_slice>40:47</time_slice>
              <text_slice>on an input of size n depends
on which input of size n.</text_slice>
            </slice>
            <slice>
              <time_slice>40:52</time_slice>
              <text_slice>I could have many
different times,</text_slice>
            </slice>
            <slice>
              <time_slice>40:54</time_slice>
              <text_slice>but by putting
the maximum at it,</text_slice>
            </slice>
            <slice>
              <time_slice>40:56</time_slice>
              <text_slice>it turns that relation
into a function</text_slice>
            </slice>
            <slice>
              <time_slice>40:59</time_slice>
              <text_slice>because there's only one
maximum time that it will take.</text_slice>
            </slice>
            <slice>
              <time_slice>41:04</time_slice>
              <text_slice>Sometimes we will talk
about average case.</text_slice>
            </slice>
            <slice>
              <time_slice>41:13</time_slice>
              <text_slice>Sometimes we will do this.</text_slice>
            </slice>
            <slice>
              <time_slice>41:21</time_slice>
              <text_slice>Here T of n is then the expected
time over all inputs of size n.</text_slice>
            </slice>
            <slice>
              <time_slice>41:36</time_slice>
              <text_slice>It's the expected time.</text_slice>
            </slice>
            <slice>
              <time_slice>41:39</time_slice>
              <text_slice>Now, if I talk about
expected time, what else do</text_slice>
            </slice>
            <slice>
              <time_slice>41:43</time_slice>
              <text_slice>I need to say here?</text_slice>
            </slice>
            <slice>
              <time_slice>41:45</time_slice>
              <text_slice>What does that
mean, expected time?</text_slice>
            </slice>
            <slice>
              <time_slice>41:48</time_slice>
              <text_slice>I'm sorry.</text_slice>
            </slice>
            <slice>
              <time_slice>41:49</time_slice>
              <text_slice>Raise your hand.</text_slice>
            </slice>
            <slice>
              <time_slice>41:50</time_slice>
              <text_slice>Expected inputs.</text_slice>
            </slice>
            <slice>
              <time_slice>41:52</time_slice>
              <text_slice>What does that mean,
expected inputs?</text_slice>
            </slice>
            <slice>
              <time_slice>42:05</time_slice>
              <text_slice>I need more math.</text_slice>
            </slice>
            <slice>
              <time_slice>42:06</time_slice>
              <text_slice>What do I need by
expected time here, math?</text_slice>
            </slice>
            <slice>
              <time_slice>42:10</time_slice>
              <text_slice>You have to take the
time of every input</text_slice>
            </slice>
            <slice>
              <time_slice>42:15</time_slice>
              <text_slice>and then average them, OK.</text_slice>
            </slice>
            <slice>
              <time_slice>42:18</time_slice>
              <text_slice>That's kind of what we
mean by expected time.</text_slice>
            </slice>
            <slice>
              <time_slice>42:22</time_slice>
              <text_slice>Good.</text_slice>
            </slice>
            <slice>
              <time_slice>42:22</time_slice>
              <text_slice>Not quite.</text_slice>
            </slice>
            <slice>
              <time_slice>42:24</time_slice>
              <text_slice>I mean, what you say
is completely correct,</text_slice>
            </slice>
            <slice>
              <time_slice>42:28</time_slice>
              <text_slice>except is not quite enough.</text_slice>
            </slice>
            <slice>
              <time_slice>42:32</time_slice>
              <text_slice>Yeah?</text_slice>
            </slice>
            <slice>
              <time_slice>42:33</time_slice>
              <text_slice>It's the time of every
input times the probability</text_slice>
            </slice>
            <slice>
              <time_slice>42:37</time_slice>
              <text_slice>that it will be that input.</text_slice>
            </slice>
            <slice>
              <time_slice>42:40</time_slice>
              <text_slice>It's a way of taking a weighted
average, exactly right.</text_slice>
            </slice>
            <slice>
              <time_slice>42:45</time_slice>
              <text_slice>How do I know what the
probability of every input is?</text_slice>
            </slice>
            <slice>
              <time_slice>42:51</time_slice>
              <text_slice>How do I know what the
probability a particular input</text_slice>
            </slice>
            <slice>
              <time_slice>42:57</time_slice>
              <text_slice>occurs is in a given situation?</text_slice>
            </slice>
            <slice>
              <time_slice>43:02</time_slice>
              <text_slice>I don't.</text_slice>
            </slice>
            <slice>
              <time_slice>43:03</time_slice>
              <text_slice>I have to make an assumption.</text_slice>
            </slice>
            <slice>
              <time_slice>43:06</time_slice>
              <text_slice>What's that assumption called?</text_slice>
            </slice>
            <slice>
              <time_slice>43:08</time_slice>
              <text_slice>What kind of assumption
do I have to meet?</text_slice>
            </slice>
            <slice>
              <time_slice>43:13</time_slice>
              <text_slice>I need an assumption -- -- of
the statistical distribution</text_slice>
            </slice>
            <slice>
              <time_slice>43:26</time_slice>
              <text_slice>of inputs.</text_slice>
            </slice>
            <slice>
              <time_slice>43:28</time_slice>
              <text_slice>Otherwise, expected time
doesn't mean anything</text_slice>
            </slice>
            <slice>
              <time_slice>43:31</time_slice>
              <text_slice>because I don't know what the
probability of something is.</text_slice>
            </slice>
            <slice>
              <time_slice>43:38</time_slice>
              <text_slice>In order to do probability,
you need some assumptions</text_slice>
            </slice>
            <slice>
              <time_slice>43:42</time_slice>
              <text_slice>and you've got to state
those assumptions clearly.</text_slice>
            </slice>
            <slice>
              <time_slice>43:48</time_slice>
              <text_slice>One of the most
common assumptions</text_slice>
            </slice>
            <slice>
              <time_slice>43:51</time_slice>
              <text_slice>is that all inputs
are equally likely.</text_slice>
            </slice>
            <slice>
              <time_slice>43:54</time_slice>
              <text_slice>That's called the
uniform distribution.</text_slice>
            </slice>
            <slice>
              <time_slice>43:57</time_slice>
              <text_slice>Every input of size n is equally
likely, that kind of thing.</text_slice>
            </slice>
            <slice>
              <time_slice>44:04</time_slice>
              <text_slice>But there are other ways that
you could make that assumption,</text_slice>
            </slice>
            <slice>
              <time_slice>44:09</time_slice>
              <text_slice>and they may not all be true.</text_slice>
            </slice>
            <slice>
              <time_slice>44:11</time_slice>
              <text_slice>This is much more
complicated, as you can see.</text_slice>
            </slice>
            <slice>
              <time_slice>44:15</time_slice>
              <text_slice>Fortunately, all of you have a
strong probability background.</text_slice>
            </slice>
            <slice>
              <time_slice>44:20</time_slice>
              <text_slice>And so we will not have
any trouble addressing</text_slice>
            </slice>
            <slice>
              <time_slice>44:23</time_slice>
              <text_slice>these probabilistic
issues of dealing</text_slice>
            </slice>
            <slice>
              <time_slice>44:27</time_slice>
              <text_slice>with expectations and such.</text_slice>
            </slice>
            <slice>
              <time_slice>44:30</time_slice>
              <text_slice>If you don't, time
to go and say gee,</text_slice>
            </slice>
            <slice>
              <time_slice>44:34</time_slice>
              <text_slice>maybe I should take
that Probability class</text_slice>
            </slice>
            <slice>
              <time_slice>44:38</time_slice>
              <text_slice>that is a prerequisite
for this class.</text_slice>
            </slice>
            <slice>
              <time_slice>44:42</time_slice>
              <text_slice>The last one I am going to
mention is best case analysis.</text_slice>
            </slice>
            <slice>
              <time_slice>44:49</time_slice>
              <text_slice>And this I claim is bogus.</text_slice>
            </slice>
            <slice>
              <time_slice>44:53</time_slice>
              <text_slice>Bogus.</text_slice>
            </slice>
            <slice>
              <time_slice>44:53</time_slice>
              <text_slice>No good.</text_slice>
            </slice>
            <slice>
              <time_slice>44:55</time_slice>
              <text_slice>Why is best-case analysis bogus?</text_slice>
            </slice>
            <slice>
              <time_slice>44:59</time_slice>
              <text_slice>Yeah?</text_slice>
            </slice>
            <slice>
              <time_slice>45:00</time_slice>
              <text_slice>The best case probably
doesn't ever happen.</text_slice>
            </slice>
            <slice>
              <time_slice>45:03</time_slice>
              <text_slice>Actually, it's interesting
because for the sorting</text_slice>
            </slice>
            <slice>
              <time_slice>45:06</time_slice>
              <text_slice>problem, the most common
things that get sorted</text_slice>
            </slice>
            <slice>
              <time_slice>45:10</time_slice>
              <text_slice>are things that are already
sorted interestingly,</text_slice>
            </slice>
            <slice>
              <time_slice>45:15</time_slice>
              <text_slice>or at least almost sorted.</text_slice>
            </slice>
            <slice>
              <time_slice>45:17</time_slice>
              <text_slice>For example, one of the most
common things that are sorted</text_slice>
            </slice>
            <slice>
              <time_slice>45:21</time_slice>
              <text_slice>is check numbers by banks.</text_slice>
            </slice>
            <slice>
              <time_slice>45:23</time_slice>
              <text_slice>They tend to come in, in
the same order that they</text_slice>
            </slice>
            <slice>
              <time_slice>45:28</time_slice>
              <text_slice>are written.</text_slice>
            </slice>
            <slice>
              <time_slice>45:30</time_slice>
              <text_slice>They're sorting things that
are almost always sorted.</text_slice>
            </slice>
            <slice>
              <time_slice>45:36</time_slice>
              <text_slice>I mean, it's good.</text_slice>
            </slice>
            <slice>
              <time_slice>45:38</time_slice>
              <text_slice>When upper bond,
not lower bound?</text_slice>
            </slice>
            <slice>
              <time_slice>45:42</time_slice>
              <text_slice>Yeah, you want to
make a guarantee.</text_slice>
            </slice>
            <slice>
              <time_slice>45:46</time_slice>
              <text_slice>And so why is this
not a guarantee?</text_slice>
            </slice>
            <slice>
              <time_slice>45:51</time_slice>
              <text_slice>You're onto something there, but
we need a little more precision</text_slice>
            </slice>
            <slice>
              <time_slice>46:01</time_slice>
              <text_slice>here.</text_slice>
            </slice>
            <slice>
              <time_slice>46:02</time_slice>
              <text_slice>How can I cheat?</text_slice>
            </slice>
            <slice>
              <time_slice>46:03</time_slice>
              <text_slice>Yeah?</text_slice>
            </slice>
            <slice>
              <time_slice>46:04</time_slice>
              <text_slice>Yeah, you can cheat.</text_slice>
            </slice>
            <slice>
              <time_slice>46:06</time_slice>
              <text_slice>You cheat.</text_slice>
            </slice>
            <slice>
              <time_slice>46:07</time_slice>
              <text_slice>You take any slow
algorithm that you want</text_slice>
            </slice>
            <slice>
              <time_slice>46:11</time_slice>
              <text_slice>and just check for
some particular input,</text_slice>
            </slice>
            <slice>
              <time_slice>46:15</time_slice>
              <text_slice>and if it's that input, then you
say immediately yeah, OK, here</text_slice>
            </slice>
            <slice>
              <time_slice>46:23</time_slice>
              <text_slice>is the answer.</text_slice>
            </slice>
            <slice>
              <time_slice>46:25</time_slice>
              <text_slice>And then it's got
a good best case.</text_slice>
            </slice>
            <slice>
              <time_slice>46:30</time_slice>
              <text_slice>But I didn't tell you anything
about the vast majority</text_slice>
            </slice>
            <slice>
              <time_slice>46:35</time_slice>
              <text_slice>of what is going on.</text_slice>
            </slice>
            <slice>
              <time_slice>46:38</time_slice>
              <text_slice>So, you can cheat
with a slow algorithm</text_slice>
            </slice>
            <slice>
              <time_slice>46:42</time_slice>
              <text_slice>that works fast on some input.</text_slice>
            </slice>
            <slice>
              <time_slice>46:46</time_slice>
              <text_slice>It doesn't really
do much for you</text_slice>
            </slice>
            <slice>
              <time_slice>46:50</time_slice>
              <text_slice>so we normally don't
worry about that.</text_slice>
            </slice>
            <slice>
              <time_slice>46:54</time_slice>
              <text_slice>Let's see.</text_slice>
            </slice>
            <slice>
              <time_slice>46:56</time_slice>
              <text_slice>What is insertion
sorts worst case time?</text_slice>
            </slice>
            <slice>
              <time_slice>47:02</time_slice>
              <text_slice>Now we get into some
sort of funny issues.</text_slice>
            </slice>
            <slice>
              <time_slice>47:07</time_slice>
              <text_slice>First of all, it sort of
depends on the computer</text_slice>
            </slice>
            <slice>
              <time_slice>47:12</time_slice>
              <text_slice>you're running on.</text_slice>
            </slice>
            <slice>
              <time_slice>47:15</time_slice>
              <text_slice>Whose computer, right?</text_slice>
            </slice>
            <slice>
              <time_slice>47:17</time_slice>
              <text_slice>Is it a big supercomputer
or is it your wristwatch?</text_slice>
            </slice>
            <slice>
              <time_slice>47:24</time_slice>
              <text_slice>They have different
computational abilities.</text_slice>
            </slice>
            <slice>
              <time_slice>47:29</time_slice>
              <text_slice>And when we compare
algorithms, we</text_slice>
            </slice>
            <slice>
              <time_slice>47:34</time_slice>
              <text_slice>compare them typically
for relative speed.</text_slice>
            </slice>
            <slice>
              <time_slice>47:37</time_slice>
              <text_slice>This is if you compared two
algorithms on the same machine.</text_slice>
            </slice>
            <slice>
              <time_slice>47:42</time_slice>
              <text_slice>You could argue, well,
it doesn't really</text_slice>
            </slice>
            <slice>
              <time_slice>47:44</time_slice>
              <text_slice>matter what the machine
is because I will just</text_slice>
            </slice>
            <slice>
              <time_slice>47:48</time_slice>
              <text_slice>look at their relative speed.</text_slice>
            </slice>
            <slice>
              <time_slice>47:50</time_slice>
              <text_slice>But, of course, I may also be
interested in absolute speed.</text_slice>
            </slice>
            <slice>
              <time_slice>47:55</time_slice>
              <text_slice>Is one algorithm
actually better no matter</text_slice>
            </slice>
            <slice>
              <time_slice>47:58</time_slice>
              <text_slice>what machine it's run on?</text_slice>
            </slice>
            <slice>
              <time_slice>48:08</time_slice>
              <text_slice>And so this kind of
gets sort of confusing</text_slice>
            </slice>
            <slice>
              <time_slice>48:11</time_slice>
              <text_slice>as to how I can talk
about the worst case</text_slice>
            </slice>
            <slice>
              <time_slice>48:14</time_slice>
              <text_slice>time of an algorithm
of a piece of software</text_slice>
            </slice>
            <slice>
              <time_slice>48:18</time_slice>
              <text_slice>when I am not talking
about the hardware because,</text_slice>
            </slice>
            <slice>
              <time_slice>48:23</time_slice>
              <text_slice>clearly, if I had run
on a faster machine,</text_slice>
            </slice>
            <slice>
              <time_slice>48:27</time_slice>
              <text_slice>my algorithms are
going to go faster.</text_slice>
            </slice>
            <slice>
              <time_slice>48:30</time_slice>
              <text_slice>So, this is where you get
the big idea of algorithms.</text_slice>
            </slice>
            <slice>
              <time_slice>48:36</time_slice>
              <text_slice>Which is why algorithm
is such a huge field,</text_slice>
            </slice>
            <slice>
              <time_slice>48:39</time_slice>
              <text_slice>why it spawns companies
like Google, like Akamai,</text_slice>
            </slice>
            <slice>
              <time_slice>48:43</time_slice>
              <text_slice>like Amazon.</text_slice>
            </slice>
            <slice>
              <time_slice>48:44</time_slice>
              <text_slice>Why algorithmic analysis,
throughout the history</text_slice>
            </slice>
            <slice>
              <time_slice>48:47</time_slice>
              <text_slice>of computing, has been
such a huge success,</text_slice>
            </slice>
            <slice>
              <time_slice>48:50</time_slice>
              <text_slice>is our ability to
master and to be</text_slice>
            </slice>
            <slice>
              <time_slice>48:53</time_slice>
              <text_slice>able to take what is
apparently a really</text_slice>
            </slice>
            <slice>
              <time_slice>48:57</time_slice>
              <text_slice>messy, complicated situation
and reduce it to being</text_slice>
            </slice>
            <slice>
              <time_slice>49:02</time_slice>
              <text_slice>able to do some mathematics.</text_slice>
            </slice>
            <slice>
              <time_slice>49:05</time_slice>
              <text_slice>And that idea is called
asymptotic analysis.</text_slice>
            </slice>
            <slice>
              <time_slice>49:17</time_slice>
              <text_slice>And the basic idea of
asymptotic analysis is to ignore</text_slice>
            </slice>
            <slice>
              <time_slice>49:21</time_slice>
              <text_slice>machine-dependent
constants -- --</text_slice>
            </slice>
            <slice>
              <time_slice>49:34</time_slice>
              <text_slice>and, instead of the
actual running time,</text_slice>
            </slice>
            <slice>
              <time_slice>49:38</time_slice>
              <text_slice>look at the growth
of the running time.</text_slice>
            </slice>
            <slice>
              <time_slice>49:59</time_slice>
              <text_slice>So, we don't look at
the actual running time.</text_slice>
            </slice>
            <slice>
              <time_slice>50:02</time_slice>
              <text_slice>We look at the growth.</text_slice>
            </slice>
            <slice>
              <time_slice>50:04</time_slice>
              <text_slice>Let's see what we mean by that.</text_slice>
            </slice>
            <slice>
              <time_slice>50:07</time_slice>
              <text_slice>This is a huge idea.</text_slice>
            </slice>
            <slice>
              <time_slice>50:08</time_slice>
              <text_slice>It's not a hard
idea, otherwise I</text_slice>
            </slice>
            <slice>
              <time_slice>50:11</time_slice>
              <text_slice>wouldn't be able to teach
it in the first lecture,</text_slice>
            </slice>
            <slice>
              <time_slice>50:16</time_slice>
              <text_slice>but it's a huge idea.</text_slice>
            </slice>
            <slice>
              <time_slice>50:17</time_slice>
              <text_slice>We are going to spend
a couple of lectures</text_slice>
            </slice>
            <slice>
              <time_slice>50:21</time_slice>
              <text_slice>understanding the
implications of that</text_slice>
            </slice>
            <slice>
              <time_slice>50:23</time_slice>
              <text_slice>and will basically be doing
it throughout the term.</text_slice>
            </slice>
            <slice>
              <time_slice>50:30</time_slice>
              <text_slice>And if you go on to be
practicing engineers,</text_slice>
            </slice>
            <slice>
              <time_slice>50:33</time_slice>
              <text_slice>you will be doing
it all the time.</text_slice>
            </slice>
            <slice>
              <time_slice>50:36</time_slice>
              <text_slice>In order to do that,
we adopt some notations</text_slice>
            </slice>
            <slice>
              <time_slice>50:39</time_slice>
              <text_slice>that are going to help us.</text_slice>
            </slice>
            <slice>
              <time_slice>50:42</time_slice>
              <text_slice>In particular, we will
adopt asymptotic notation.</text_slice>
            </slice>
            <slice>
              <time_slice>50:46</time_slice>
              <text_slice>Most of you have seen some
kind of asymptotic notation.</text_slice>
            </slice>
            <slice>
              <time_slice>50:51</time_slice>
              <text_slice>Maybe a few of you
haven't, but mostly you</text_slice>
            </slice>
            <slice>
              <time_slice>50:53</time_slice>
              <text_slice>should have seen a little bit.</text_slice>
            </slice>
            <slice>
              <time_slice>50:56</time_slice>
              <text_slice>The one we're going to
be using in this class</text_slice>
            </slice>
            <slice>
              <time_slice>51:01</time_slice>
              <text_slice>predominantly is theta notation.</text_slice>
            </slice>
            <slice>
              <time_slice>51:05</time_slice>
              <text_slice>And theta notation is
pretty easy notation</text_slice>
            </slice>
            <slice>
              <time_slice>51:09</time_slice>
              <text_slice>to master because all you
do is, from a formula,</text_slice>
            </slice>
            <slice>
              <time_slice>51:16</time_slice>
              <text_slice>just drop low order terms
and ignore leading constants.</text_slice>
            </slice>
            <slice>
              <time_slice>51:30</time_slice>
              <text_slice>For example, if I have a formula
like 3n^3 = 90n^2 - 5n + 6046,</text_slice>
            </slice>
            <slice>
              <time_slice>51:37</time_slice>
              <text_slice>I say, well, what low
order terms do I drop?</text_slice>
            </slice>
            <slice>
              <time_slice>51:43</time_slice>
              <text_slice>Well, n^3 is a
bigger term n^2 than.</text_slice>
            </slice>
            <slice>
              <time_slice>51:48</time_slice>
              <text_slice>I am going to drop all these
terms and ignore the leading</text_slice>
            </slice>
            <slice>
              <time_slice>51:56</time_slice>
              <text_slice>constant, so I say
that's Theta(n^3).</text_slice>
            </slice>
            <slice>
              <time_slice>52:01</time_slice>
              <text_slice>That's pretty easy.</text_slice>
            </slice>
            <slice>
              <time_slice>52:04</time_slice>
              <text_slice>So, that's theta notation.</text_slice>
            </slice>
            <slice>
              <time_slice>52:06</time_slice>
              <text_slice>Now, this is an engineering way
of manipulating theta notation.</text_slice>
            </slice>
            <slice>
              <time_slice>52:11</time_slice>
              <text_slice>There is actually a
mathematical definition</text_slice>
            </slice>
            <slice>
              <time_slice>52:14</time_slice>
              <text_slice>for this, which we
are going to talk</text_slice>
            </slice>
            <slice>
              <time_slice>52:18</time_slice>
              <text_slice>about next time, which
is a definition in terms</text_slice>
            </slice>
            <slice>
              <time_slice>52:22</time_slice>
              <text_slice>of sets of functions.</text_slice>
            </slice>
            <slice>
              <time_slice>52:23</time_slice>
              <text_slice>And, you are going
to be responsible,</text_slice>
            </slice>
            <slice>
              <time_slice>52:25</time_slice>
              <text_slice>this is both a math and a
computer science engineering</text_slice>
            </slice>
            <slice>
              <time_slice>52:30</time_slice>
              <text_slice>class.</text_slice>
            </slice>
            <slice>
              <time_slice>52:31</time_slice>
              <text_slice>Throughout the
course you are going</text_slice>
            </slice>
            <slice>
              <time_slice>52:34</time_slice>
              <text_slice>to be responsible both
for mathematical rigor</text_slice>
            </slice>
            <slice>
              <time_slice>52:37</time_slice>
              <text_slice>as if it were a math
course and engineering</text_slice>
            </slice>
            <slice>
              <time_slice>52:41</time_slice>
              <text_slice>commonsense because it's
an engineering course.</text_slice>
            </slice>
            <slice>
              <time_slice>52:43</time_slice>
              <text_slice>We are going to be doing both.</text_slice>
            </slice>
            <slice>
              <time_slice>52:46</time_slice>
              <text_slice>This is the engineering way
of understanding what you do,</text_slice>
            </slice>
            <slice>
              <time_slice>52:50</time_slice>
              <text_slice>so you're responsible for being
able to do these manipulations.</text_slice>
            </slice>
            <slice>
              <time_slice>52:54</time_slice>
              <text_slice>You're also going to be
responsible for understanding</text_slice>
            </slice>
            <slice>
              <time_slice>52:57</time_slice>
              <text_slice>the mathematical
definition of theta notion</text_slice>
            </slice>
            <slice>
              <time_slice>52:59</time_slice>
              <text_slice>and of its related O
notation and omega notation.</text_slice>
            </slice>
            <slice>
              <time_slice>53:03</time_slice>
              <text_slice>If I take a look as n
approached infinity,</text_slice>
            </slice>
            <slice>
              <time_slice>53:09</time_slice>
              <text_slice>a Theta(n^2) algorithm
always beats, eventually,</text_slice>
            </slice>
            <slice>
              <time_slice>53:16</time_slice>
              <text_slice>a Theta(n^3) algorithm.</text_slice>
            </slice>
            <slice>
              <time_slice>53:20</time_slice>
              <text_slice>As n gets bigger, it doesn't
matter what these other terms</text_slice>
            </slice>
            <slice>
              <time_slice>53:27</time_slice>
              <text_slice>were if I were describing
the absolute precise behavior</text_slice>
            </slice>
            <slice>
              <time_slice>53:34</time_slice>
              <text_slice>in terms of a formula.</text_slice>
            </slice>
            <slice>
              <time_slice>53:37</time_slice>
              <text_slice>If I had a Theta(n^2) algorithm,
it would always be faster</text_slice>
            </slice>
            <slice>
              <time_slice>53:44</time_slice>
              <text_slice>for sufficiently large n
than a Theta(n^3) algorithm.</text_slice>
            </slice>
            <slice>
              <time_slice>53:47</time_slice>
              <text_slice>It wouldn't matter what
those low order terms were.</text_slice>
            </slice>
            <slice>
              <time_slice>53:51</time_slice>
              <text_slice>It wouldn't matter what
the leading constant was.</text_slice>
            </slice>
            <slice>
              <time_slice>53:55</time_slice>
              <text_slice>This one will always be faster.</text_slice>
            </slice>
            <slice>
              <time_slice>53:59</time_slice>
              <text_slice>Even if you ran the Theta(n^2)
algorithm on a slow computer</text_slice>
            </slice>
            <slice>
              <time_slice>54:04</time_slice>
              <text_slice>and the Theta(n^3) algorithm
on a fast computer.</text_slice>
            </slice>
            <slice>
              <time_slice>54:09</time_slice>
              <text_slice>The great thing about
asymptotic notation</text_slice>
            </slice>
            <slice>
              <time_slice>54:12</time_slice>
              <text_slice>is it satisfies
our issue of being</text_slice>
            </slice>
            <slice>
              <time_slice>54:16</time_slice>
              <text_slice>able to compare both
relative and absolute speed,</text_slice>
            </slice>
            <slice>
              <time_slice>54:20</time_slice>
              <text_slice>because we are able
to do this no matter</text_slice>
            </slice>
            <slice>
              <time_slice>54:25</time_slice>
              <text_slice>what the computer platform.</text_slice>
            </slice>
            <slice>
              <time_slice>54:29</time_slice>
              <text_slice>On different platforms we may
get different constants here,</text_slice>
            </slice>
            <slice>
              <time_slice>54:34</time_slice>
              <text_slice>machine dependent constants
for the actual running time,</text_slice>
            </slice>
            <slice>
              <time_slice>54:39</time_slice>
              <text_slice>but if I look at the growth
as the size of the input</text_slice>
            </slice>
            <slice>
              <time_slice>54:44</time_slice>
              <text_slice>gets larger, the asymptotics
generally won't change.</text_slice>
            </slice>
            <slice>
              <time_slice>54:49</time_slice>
              <text_slice>For example, I will just
draw that as a picture.</text_slice>
            </slice>
            <slice>
              <time_slice>54:53</time_slice>
              <text_slice>If I have n on this axis
and T(n) on this axis.</text_slice>
            </slice>
            <slice>
              <time_slice>54:59</time_slice>
              <text_slice>This may be, for example, a
Theta(n^3) algorithm and this</text_slice>
            </slice>
            <slice>
              <time_slice>55:04</time_slice>
              <text_slice>may be a Theta(n^2) algorithm.</text_slice>
            </slice>
            <slice>
              <time_slice>55:06</time_slice>
              <text_slice>There is always going to be some
point n o where for everything</text_slice>
            </slice>
            <slice>
              <time_slice>55:12</time_slice>
              <text_slice>larger the Theta(n^2) algorithm
is going to be cheaper than</text_slice>
            </slice>
            <slice>
              <time_slice>55:17</time_slice>
              <text_slice>the Theta(n^3) algorithm not
matter how much advantage you</text_slice>
            </slice>
            <slice>
              <time_slice>55:21</time_slice>
              <text_slice>give it at the beginning
in terms of the speed</text_slice>
            </slice>
            <slice>
              <time_slice>55:26</time_slice>
              <text_slice>of the computer
you are running on.</text_slice>
            </slice>
            <slice>
              <time_slice>55:30</time_slice>
              <text_slice>Now, from an engineering
point of view,</text_slice>
            </slice>
            <slice>
              <time_slice>55:32</time_slice>
              <text_slice>there are some issues we have to
deal with because sometimes it</text_slice>
            </slice>
            <slice>
              <time_slice>55:36</time_slice>
              <text_slice>could be that that n o is so
large that the computers aren't</text_slice>
            </slice>
            <slice>
              <time_slice>55:40</time_slice>
              <text_slice>big enough to run the problem.</text_slice>
            </slice>
            <slice>
              <time_slice>55:43</time_slice>
              <text_slice>That's why we, nevertheless,
are interested in some</text_slice>
            </slice>
            <slice>
              <time_slice>55:47</time_slice>
              <text_slice>of the slower algorithms,
because some of the slower</text_slice>
            </slice>
            <slice>
              <time_slice>55:51</time_slice>
              <text_slice>algorithms, even though they may
not asymptotically be slower,</text_slice>
            </slice>
            <slice>
              <time_slice>55:55</time_slice>
              <text_slice>I mean asymptotically
they will be slower.</text_slice>
            </slice>
            <slice>
              <time_slice>56:00</time_slice>
              <text_slice>They may still be faster on
reasonable sizes of things.</text_slice>
            </slice>
            <slice>
              <time_slice>56:03</time_slice>
              <text_slice>And so we have to both balance
our mathematical understanding</text_slice>
            </slice>
            <slice>
              <time_slice>56:07</time_slice>
              <text_slice>with our engineering
commonsense in order</text_slice>
            </slice>
            <slice>
              <time_slice>56:10</time_slice>
              <text_slice>to do good programming.</text_slice>
            </slice>
            <slice>
              <time_slice>56:12</time_slice>
              <text_slice>So, just having done
analysis of algorithms</text_slice>
            </slice>
            <slice>
              <time_slice>56:14</time_slice>
              <text_slice>doesn't automatically make
you a good programmer.</text_slice>
            </slice>
            <slice>
              <time_slice>56:18</time_slice>
              <text_slice>You also need to learn
how to program and use</text_slice>
            </slice>
            <slice>
              <time_slice>56:21</time_slice>
              <text_slice>these tools in
practice to understand</text_slice>
            </slice>
            <slice>
              <time_slice>56:23</time_slice>
              <text_slice>when they are relevant and
when they are not relevant.</text_slice>
            </slice>
            <slice>
              <time_slice>56:27</time_slice>
              <text_slice>There is a saying.</text_slice>
            </slice>
            <slice>
              <time_slice>56:30</time_slice>
              <text_slice>If you want to be
a good program,</text_slice>
            </slice>
            <slice>
              <time_slice>56:32</time_slice>
              <text_slice>you just program ever
day for two years,</text_slice>
            </slice>
            <slice>
              <time_slice>56:35</time_slice>
              <text_slice>you will be an
excellent programmer.</text_slice>
            </slice>
            <slice>
              <time_slice>56:38</time_slice>
              <text_slice>If you want to be a
world class programmer,</text_slice>
            </slice>
            <slice>
              <time_slice>56:42</time_slice>
              <text_slice>you can program every
day for ten years,</text_slice>
            </slice>
            <slice>
              <time_slice>56:46</time_slice>
              <text_slice>or you can program
every day for two years</text_slice>
            </slice>
            <slice>
              <time_slice>56:49</time_slice>
              <text_slice>and take an algorithms class.</text_slice>
            </slice>
            <slice>
              <time_slice>56:51</time_slice>
              <text_slice>Let's get back to
what we were doing,</text_slice>
            </slice>
            <slice>
              <time_slice>56:55</time_slice>
              <text_slice>which is analyzing
insertion sort.</text_slice>
            </slice>
            <slice>
              <time_slice>57:00</time_slice>
              <text_slice>We are going to look
at the worse case.</text_slice>
            </slice>
            <slice>
              <time_slice>57:16</time_slice>
              <text_slice>Which, as we mentioned before,
is when the input is reverse</text_slice>
            </slice>
            <slice>
              <time_slice>57:21</time_slice>
              <text_slice>sorted.</text_slice>
            </slice>
            <slice>
              <time_slice>57:21</time_slice>
              <text_slice>The biggest element comes
first and the smallest last</text_slice>
            </slice>
            <slice>
              <time_slice>57:25</time_slice>
              <text_slice>because now every time you
do the insertion you've</text_slice>
            </slice>
            <slice>
              <time_slice>57:30</time_slice>
              <text_slice>got to shuffle everything over.</text_slice>
            </slice>
            <slice>
              <time_slice>57:35</time_slice>
              <text_slice>You can write down
the running time</text_slice>
            </slice>
            <slice>
              <time_slice>57:36</time_slice>
              <text_slice>by looking at the
nesting of loops.</text_slice>
            </slice>
            <slice>
              <time_slice>57:38</time_slice>
              <text_slice>What we do is we sum up.</text_slice>
            </slice>
            <slice>
              <time_slice>57:40</time_slice>
              <text_slice>What we assume is
that every operation,</text_slice>
            </slice>
            <slice>
              <time_slice>57:42</time_slice>
              <text_slice>every elemental operation
is going to take</text_slice>
            </slice>
            <slice>
              <time_slice>57:45</time_slice>
              <text_slice>some constant amount of time.</text_slice>
            </slice>
            <slice>
              <time_slice>57:47</time_slice>
              <text_slice>But we don't have
to worry about what</text_slice>
            </slice>
            <slice>
              <time_slice>57:49</time_slice>
              <text_slice>that constant is because
we're going to be</text_slice>
            </slice>
            <slice>
              <time_slice>57:51</time_slice>
              <text_slice>doing asymptotic analysis.</text_slice>
            </slice>
            <slice>
              <time_slice>57:53</time_slice>
              <text_slice>As I say, the
beautify of the method</text_slice>
            </slice>
            <slice>
              <time_slice>57:54</time_slice>
              <text_slice>is that it causes
all these things that</text_slice>
            </slice>
            <slice>
              <time_slice>57:57</time_slice>
              <text_slice>are real distinctions
to sort of vanish.</text_slice>
            </slice>
            <slice>
              <time_slice>58:01</time_slice>
              <text_slice>We sort of look at
them from 30,000 feet</text_slice>
            </slice>
            <slice>
              <time_slice>58:03</time_slice>
              <text_slice>rather than from three
millimeters or something.</text_slice>
            </slice>
            <slice>
              <time_slice>58:06</time_slice>
              <text_slice>Each of these operations
is going to sort of</text_slice>
            </slice>
            <slice>
              <time_slice>58:10</time_slice>
              <text_slice>be a basic operation.</text_slice>
            </slice>
            <slice>
              <time_slice>58:12</time_slice>
              <text_slice>One way to think about this, in
terms of counting operations,</text_slice>
            </slice>
            <slice>
              <time_slice>58:16</time_slice>
              <text_slice>is counting memory references.</text_slice>
            </slice>
            <slice>
              <time_slice>58:19</time_slice>
              <text_slice>How many times do you
actually access some variable?</text_slice>
            </slice>
            <slice>
              <time_slice>58:23</time_slice>
              <text_slice>That's another way of sort
of thinking about this model.</text_slice>
            </slice>
            <slice>
              <time_slice>58:29</time_slice>
              <text_slice>When we do that, well, we're
going to go through this loop,</text_slice>
            </slice>
            <slice>
              <time_slice>58:33</time_slice>
              <text_slice>j is going from 2
to n, and then we're</text_slice>
            </slice>
            <slice>
              <time_slice>58:37</time_slice>
              <text_slice>going to add up the work
that we do within the loop.</text_slice>
            </slice>
            <slice>
              <time_slice>58:43</time_slice>
              <text_slice>We can sort of write that
in math as summation of j</text_slice>
            </slice>
            <slice>
              <time_slice>58:48</time_slice>
              <text_slice>equals 2 to n.</text_slice>
            </slice>
            <slice>
              <time_slice>58:49</time_slice>
              <text_slice>And then what is the work
that is going on in this loop?</text_slice>
            </slice>
            <slice>
              <time_slice>58:55</time_slice>
              <text_slice>Well, the work that is
going on in this loop</text_slice>
            </slice>
            <slice>
              <time_slice>58:59</time_slice>
              <text_slice>varies, but in the worst case
how many operations are going</text_slice>
            </slice>
            <slice>
              <time_slice>59:05</time_slice>
              <text_slice>on here for each value of j?</text_slice>
            </slice>
            <slice>
              <time_slice>59:10</time_slice>
              <text_slice>For a given value of j, how
much work goes on in this loop?</text_slice>
            </slice>
            <slice>
              <time_slice>59:17</time_slice>
              <text_slice>Can somebody tell me?</text_slice>
            </slice>
            <slice>
              <time_slice>59:20</time_slice>
              <text_slice>Asymptotically.</text_slice>
            </slice>
            <slice>
              <time_slice>59:21</time_slice>
              <text_slice>It's j times some
constant, so it's theta j.</text_slice>
            </slice>
            <slice>
              <time_slice>59:28</time_slice>
              <text_slice>So, there is theta
j work going on here</text_slice>
            </slice>
            <slice>
              <time_slice>59:33</time_slice>
              <text_slice>because this loop starts
out with i being j minus 1,</text_slice>
            </slice>
            <slice>
              <time_slice>59:38</time_slice>
              <text_slice>and then it's doing just
a constant amount of stuff</text_slice>
            </slice>
            <slice>
              <time_slice>59:43</time_slice>
              <text_slice>for each step of the value
of i, and i is running</text_slice>
            </slice>
            <slice>
              <time_slice>59:47</time_slice>
              <text_slice>from j minus one down to zero.</text_slice>
            </slice>
            <slice>
              <time_slice>59:50</time_slice>
              <text_slice>So, we can say that is theta
j work that is going on.</text_slice>
            </slice>
            <slice>
              <time_slice>59:57</time_slice>
              <text_slice>Do people follow that?</text_slice>
            </slice>
            <slice>
              <time_slice>59:59</time_slice>
              <text_slice>OK.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:00</time_slice>
              <text_slice>And now we have a
formula we can evaluate.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:03</time_slice>
              <text_slice>What is the evaluation?</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:05</time_slice>
              <text_slice>If I want to simplify this
formula, what is that equal to?</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:19</time_slice>
              <text_slice>Sorry.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:20</time_slice>
              <text_slice>In the back there.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:28</time_slice>
              <text_slice>Yeah.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:29</time_slice>
              <text_slice>OK.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:30</time_slice>
              <text_slice>That's just Theta(n^2), good.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:34</time_slice>
              <text_slice>Because when you're saying is
the sum of consecutive numbers,</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:38</time_slice>
              <text_slice>you mean what?</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:39</time_slice>
              <text_slice>What's the mathematic
term we have</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:41</time_slice>
              <text_slice>for that so we can communicate?</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:43</time_slice>
              <text_slice>You've got to know these
things so you can communicate.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:48</time_slice>
              <text_slice>It's called what
type of sequence?</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:50</time_slice>
              <text_slice>It's actually a
series, but that's OK.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:53</time_slice>
              <text_slice>What type of series
is this called?</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:56</time_slice>
              <text_slice>Arithmetic series, good.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:57</time_slice>
              <text_slice>Wow, we've got some sharp
people who can communicate.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:02</time_slice>
              <text_slice>This is an arithmetic series.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:05</time_slice>
              <text_slice>You're basically summing 1 + 2 +
3 + 4, some constants in there,</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:11</time_slice>
              <text_slice>but basically it's 1 + 2
+ 3 + 4 + 5 + 6 up to n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:17</time_slice>
              <text_slice>That's Theta(n^2).</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:18</time_slice>
              <text_slice>If you don't know this math,
there is a chapter in the book,</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:25</time_slice>
              <text_slice>or you could have
taken the prerequisite.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:28</time_slice>
              <text_slice>Arithmetic series.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:31</time_slice>
              <text_slice>People have this
vague recollection.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:33</time_slice>
              <text_slice>Oh, yeah.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:34</time_slice>
              <text_slice>Good.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:34</time_slice>
              <text_slice>Now, you have to learn
these manipulations.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:38</time_slice>
              <text_slice>We will talk about
a bit next time,</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:40</time_slice>
              <text_slice>but you have to learn
your theta manipulations</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:43</time_slice>
              <text_slice>for what works with theta.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:45</time_slice>
              <text_slice>And you have to be very
careful because theta</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:48</time_slice>
              <text_slice>is a weak notation.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:50</time_slice>
              <text_slice>A strong notation is something
like Leibniz notation</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:53</time_slice>
              <text_slice>from calculus where
the chain rule is just</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:57</time_slice>
              <text_slice>canceling two things.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:58</time_slice>
              <text_slice>It's just fabulous that you
can cancel in the chain rule.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:03</time_slice>
              <text_slice>And Leibniz notation just
expresses that so directly you</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:06</time_slice>
              <text_slice>can manipulate.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:07</time_slice>
              <text_slice>Theta notation is not like that.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:09</time_slice>
              <text_slice>If you think it is like
that you are in trouble.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:12</time_slice>
              <text_slice>You really have to think
of what is going on</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:15</time_slice>
              <text_slice>under the theta notation.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:16</time_slice>
              <text_slice>And it is more of a
descriptive notation</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:18</time_slice>
              <text_slice>than it is a
manipulative notation.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:20</time_slice>
              <text_slice>There are manipulations
you can do with it,</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:23</time_slice>
              <text_slice>but unless you
understand what is really</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:25</time_slice>
              <text_slice>going on under the theta
notation you will find yourself</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:29</time_slice>
              <text_slice>in trouble.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:30</time_slice>
              <text_slice>And next time we will
talk a little bit more</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:34</time_slice>
              <text_slice>about theta notation.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:35</time_slice>
              <text_slice>Is insertion sort fast?</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:49</time_slice>
              <text_slice>Well, it turns out for small
n it is moderately fast.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:02</time_slice>
              <text_slice>But it is not at
all for large n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:18</time_slice>
              <text_slice>So, I am going to give you
an algorithm that is faster.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:21</time_slice>
              <text_slice>It's called merge sort.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:22</time_slice>
              <text_slice>I wonder if I should
leave insertion sort up.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:26</time_slice>
              <text_slice>Why not.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:46</time_slice>
              <text_slice>I am going to write
on this later,</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:49</time_slice>
              <text_slice>so if you are taking notes,
leave some space on the left.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:56</time_slice>
              <text_slice>Here is merge sort of an
array A from 1 up to n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:02</time_slice>
              <text_slice>And it is basically three steps.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:05</time_slice>
              <text_slice>If n equals 1 we are done.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:10</time_slice>
              <text_slice>Sorting one element,
it is already sorted.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:14</time_slice>
              <text_slice>All right.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:15</time_slice>
              <text_slice>Recursive algorithm.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:17</time_slice>
              <text_slice>Otherwise, what we do is we
recursively sort A from 1</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:24</time_slice>
              <text_slice>up to the ceiling of n over 2.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:30</time_slice>
              <text_slice>And the array A of the ceiling
of n over 2 plus one up to n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:39</time_slice>
              <text_slice>So, we sort two
halves of the input.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:44</time_slice>
              <text_slice>And then, three, we take those
two lists that we have done</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:53</time_slice>
              <text_slice>and we merge them.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:03</time_slice>
              <text_slice>And, to do that, we
use a merge subroutine</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:05</time_slice>
              <text_slice>which I will show you.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:14</time_slice>
              <text_slice>The key subroutine here is
merge, and it works like this.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:20</time_slice>
              <text_slice>I have two lists.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:22</time_slice>
              <text_slice>Let's say one of them is 20.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:25</time_slice>
              <text_slice>I am doing this
in reverse order.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:30</time_slice>
              <text_slice>I have sorted this like this.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:32</time_slice>
              <text_slice>And then I sort another one.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:35</time_slice>
              <text_slice>I don't know why I do it
this order, but anyway.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:39</time_slice>
              <text_slice>Here is my other list.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:41</time_slice>
              <text_slice>I have my two lists
that I have sorted.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:45</time_slice>
              <text_slice>So, this is AA[1] to AA[|n/2|] and
AA[|n/2|+1] to AA[n] for the way</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:50</time_slice>
              <text_slice>it will be called
in this program.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:54</time_slice>
              <text_slice>And now to merge these
two, what I want to do</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:59</time_slice>
              <text_slice>is produce a sorted list
out of both of them.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:04</time_slice>
              <text_slice>What I do is first observe
where is the smallest</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:07</time_slice>
              <text_slice>element of any two lists
that are already sorted?</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:11</time_slice>
              <text_slice>It's in one of two places,
the head of the first list</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:15</time_slice>
              <text_slice>or the head of the second list.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:18</time_slice>
              <text_slice>I look at those two elements
and say which one is smaller?</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:23</time_slice>
              <text_slice>This one is smaller.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:24</time_slice>
              <text_slice>Then what I do is output
into my output array</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:28</time_slice>
              <text_slice>the smaller of the two.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:30</time_slice>
              <text_slice>And I cross it off.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:32</time_slice>
              <text_slice>And now where is the
next smallest element?</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:35</time_slice>
              <text_slice>And the answer is it's going to
be the head of one of these two</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:40</time_slice>
              <text_slice>lists.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:40</time_slice>
              <text_slice>Then I cross out this
guy and put him here</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:44</time_slice>
              <text_slice>and circle this one.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:45</time_slice>
              <text_slice>Now I look at these two guys.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:47</time_slice>
              <text_slice>This one is smaller so I output
that and circle that one.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:52</time_slice>
              <text_slice>Now I look at these
two guys, output 9.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:55</time_slice>
              <text_slice>So, every step here is some
fixed number of operations</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:58</time_slice>
              <text_slice>that is independent of the size
of the arrays at each step.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:04</time_slice>
              <text_slice>Each individual step is just
me looking at two elements</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:10</time_slice>
              <text_slice>and picking out the smallest
and advancing some pointers</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:15</time_slice>
              <text_slice>into the array so
that I know where</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:19</time_slice>
              <text_slice>the current head
of that list is.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:23</time_slice>
              <text_slice>And so, therefore, the time is
order n on n total elements.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:30</time_slice>
              <text_slice>The time to actually go through
this and merge two lists</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:34</time_slice>
              <text_slice>is order n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:35</time_slice>
              <text_slice>We sometimes call this linear
time because it's not quadratic</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:40</time_slice>
              <text_slice>or whatever.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:41</time_slice>
              <text_slice>It is proportional to n,
proportional to the input size.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:45</time_slice>
              <text_slice>It's linear time.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:46</time_slice>
              <text_slice>I go through and just do
this simple operation,</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:50</time_slice>
              <text_slice>just working up these
lists, and in the end</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:54</time_slice>
              <text_slice>I have done essentially
n operations,</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:56</time_slice>
              <text_slice>order n operations each of
which cost constant time.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:02</time_slice>
              <text_slice>That's a total of order n time.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:05</time_slice>
              <text_slice>Everybody with me?</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:06</time_slice>
              <text_slice>OK.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:07</time_slice>
              <text_slice>So, this is a recursive program.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:10</time_slice>
              <text_slice>We can actually now
write what is called</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:14</time_slice>
              <text_slice>a recurrence for this program.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:17</time_slice>
              <text_slice>The way we do that is
say let's let the time</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:21</time_slice>
              <text_slice>to sort n elements to be T(n).</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:24</time_slice>
              <text_slice>Then how long does it
take to do step one?</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:35</time_slice>
              <text_slice>That's just constant time.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:36</time_slice>
              <text_slice>We just check to see if n is
1, and if it is we return.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:41</time_slice>
              <text_slice>That's independent of the size
of anything that we are doing.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:45</time_slice>
              <text_slice>It just takes a certain
number of machine instructions</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:48</time_slice>
              <text_slice>on whatever machine and we
say it is constant time.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:52</time_slice>
              <text_slice>We call that theta one.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:54</time_slice>
              <text_slice>This is actually a little bit
of an abuse if you get into it.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:00</time_slice>
              <text_slice>And the reason is because
typically in order to say it</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:04</time_slice>
              <text_slice>you need to say what
it is growing with.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:07</time_slice>
              <text_slice>Nevertheless, we use this
as an abuse of the notation</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:10</time_slice>
              <text_slice>just to mean it is a constant.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:13</time_slice>
              <text_slice>So, that's an abuse
just so people know.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:16</time_slice>
              <text_slice>But it simplifies things if
I can just write theta one.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:20</time_slice>
              <text_slice>And it basically
means the same thing.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:23</time_slice>
              <text_slice>Now we recursively
sort these two things.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:26</time_slice>
              <text_slice>How can I describe that?</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:29</time_slice>
              <text_slice>The time to do this, I
can describe recursively</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:34</time_slice>
              <text_slice>as T of ceiling
of n over 2 plus T</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:40</time_slice>
              <text_slice>of n minus ceiling of n over 2.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:44</time_slice>
              <text_slice>That is actually kind of messy,
so what we will do is just be</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:52</time_slice>
              <text_slice>sloppy and write 2T(n/2).</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:54</time_slice>
              <text_slice>So, this is just
us being sloppy.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:00</time_slice>
              <text_slice>And we will see on
Friday in recitation</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:02</time_slice>
              <text_slice>that it is OK to be sloppy.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:04</time_slice>
              <text_slice>That's the great thing
about algorithms.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:06</time_slice>
              <text_slice>As long as you are
rigorous and precise,</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:09</time_slice>
              <text_slice>you can be as
sloppy as you want.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:12</time_slice>
              <text_slice>[LAUGHTER] This is sloppy
because I didn't worry</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:15</time_slice>
              <text_slice>about what was going
on, because it turns out</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:19</time_slice>
              <text_slice>it doesn't make any difference.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:20</time_slice>
              <text_slice>And we are going to actually
see that that is the case.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:25</time_slice>
              <text_slice>And, finally, I have to merge
the two sorted lists which</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:28</time_slice>
              <text_slice>have a total of n elements.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:30</time_slice>
              <text_slice>And we just analyze that
using the merge subroutine.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:32</time_slice>
              <text_slice>And that takes us
to theta n time.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:40</time_slice>
              <text_slice>That allows us now to write a
recurrence for the performance</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:43</time_slice>
              <text_slice>of merge sort.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:57</time_slice>
              <text_slice>Which is to say that T
of n is equal to theta 1</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:03</time_slice>
              <text_slice>if n equals 1 and 2T of
n over 2 plus theta of n</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:09</time_slice>
              <text_slice>if n is bigger than 1.</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:12</time_slice>
              <text_slice>Because either I
am doing step one</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:16</time_slice>
              <text_slice>or I am doing all steps
one, two and three.</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:21</time_slice>
              <text_slice>Here I am doing step one
and I return and I am done.</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:28</time_slice>
              <text_slice>Or else I am doing step
one, I don't return,</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:33</time_slice>
              <text_slice>and then I also do
steps two and three.</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:36</time_slice>
              <text_slice>So, I add those together.</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:38</time_slice>
              <text_slice>I could say theta n plus theta
1, but theta n plus theta 1</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:43</time_slice>
              <text_slice>is just theta n because
theta 1 is a lower order</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:47</time_slice>
              <text_slice>term than theta n and
I can throw it away.</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:50</time_slice>
              <text_slice>It is either theta 1 or it is
2T of n over 2 plus theta n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:56</time_slice>
              <text_slice>Now, typically we
won't be writing this.</text_slice>
            </slice>
            <slice>
              <time_slice>1:11:59</time_slice>
              <text_slice>Usually we omit this.</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:01</time_slice>
              <text_slice>If it makes no difference to
the solution of the recurrence,</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:05</time_slice>
              <text_slice>we will usually omit
constant base cases.</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:08</time_slice>
              <text_slice>In algorithms, it's not true
generally in mathematics,</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:11</time_slice>
              <text_slice>but in algorithms if you
are running something</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:15</time_slice>
              <text_slice>on a constant size input it
takes constant time always.</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:19</time_slice>
              <text_slice>So, we don't worry about
what this value is.</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:22</time_slice>
              <text_slice>And it turns out it
has no real impact</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:25</time_slice>
              <text_slice>on the asymptotic solution
of the recurrence.</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:28</time_slice>
              <text_slice>How do we solve a
recurrence like this?</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:32</time_slice>
              <text_slice>I now have T of n expressed
in terms of T of n over 2.</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:36</time_slice>
              <text_slice>That's in the book and
it is also in Lecture 2.</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:40</time_slice>
              <text_slice>We are going to do
Lecture 2 to solve that,</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:43</time_slice>
              <text_slice>but in the meantime
what I am going</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:46</time_slice>
              <text_slice>to do is give you a visual
way of understanding what</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:51</time_slice>
              <text_slice>this costs, which is
one of the techniques</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:54</time_slice>
              <text_slice>we will elaborate on next time.</text_slice>
            </slice>
            <slice>
              <time_slice>1:12:57</time_slice>
              <text_slice>It is called a recursion
tree technique.</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:02</time_slice>
              <text_slice>And I will use it for the
actual recurrence that is almost</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:07</time_slice>
              <text_slice>the same 2T(n/2), but I am
going to actually explicitly,</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:12</time_slice>
              <text_slice>because I want you to
see where it occurs,</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:17</time_slice>
              <text_slice>plus some constant times n where
c is a constant greater than</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:23</time_slice>
              <text_slice>zero.</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:23</time_slice>
              <text_slice>So, we are going to look at
this recurrence with a base</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:29</time_slice>
              <text_slice>case of order one.</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:32</time_slice>
              <text_slice>I am just making the
constant in here,</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:34</time_slice>
              <text_slice>the upper bound
on the constant be</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:37</time_slice>
              <text_slice>explicit rather than implicit.</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:39</time_slice>
              <text_slice>And the way you do a recursion
tree is the following.</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:43</time_slice>
              <text_slice>You start out by writing
down the left hand</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:46</time_slice>
              <text_slice>side of the recurrence.</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:47</time_slice>
              <text_slice>And then what you do is you
say well, that is equal to,</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:51</time_slice>
              <text_slice>and now let's
write it as a tree.</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:53</time_slice>
              <text_slice>I do c of n work plus now I
am going to have to do work</text_slice>
            </slice>
            <slice>
              <time_slice>1:13:58</time_slice>
              <text_slice>on each of my two children.</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:01</time_slice>
              <text_slice>T of n over 2 and T of n over
If I sum up what is in here,</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:08</time_slice>
              <text_slice>I get this because that is
what the recurrence says,</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:14</time_slice>
              <text_slice>T(n)=2T(n/2)+cn.</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:15</time_slice>
              <text_slice>I have 2T(n/2)+cn.</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:17</time_slice>
              <text_slice>Then I do it again.</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:19</time_slice>
              <text_slice>I have cn here.</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:21</time_slice>
              <text_slice>I now have here cn/2.</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:23</time_slice>
              <text_slice>And here is cn/2.</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:25</time_slice>
              <text_slice>And each of these
now has a T(n/4).</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:36</time_slice>
              <text_slice>And these each have a T(n/4).</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:39</time_slice>
              <text_slice>And this has a T(n/4).</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:43</time_slice>
              <text_slice>And I keep doing that, the
dangerous dot, dot, dots.</text_slice>
            </slice>
            <slice>
              <time_slice>1:14:50</time_slice>
              <text_slice>And, if I keep doing that, I end
up with it looking like this.</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:18</time_slice>
              <text_slice>And I keep going down
until I get to a leaf.</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:23</time_slice>
              <text_slice>And a leaf, I have
essentially a T(1).</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:27</time_slice>
              <text_slice>That is T(1).</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:29</time_slice>
              <text_slice>And so the first question
I ask here is, what</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:35</time_slice>
              <text_slice>is the height of this tree?</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:38</time_slice>
              <text_slice>Yeah.</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:39</time_slice>
              <text_slice>It's log n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:41</time_slice>
              <text_slice>It's actually very
close to exactly log n</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:45</time_slice>
              <text_slice>because I am starting
out at the top with n</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:51</time_slice>
              <text_slice>and then I go to n/2 and n/4
and all the way down until I</text_slice>
            </slice>
            <slice>
              <time_slice>1:15:59</time_slice>
              <text_slice>get to The number of halvings
of n until I get to 1 is</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:04</time_slice>
              <text_slice>log n so the height
here is log n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:07</time_slice>
              <text_slice>It's OK if it is
constant times log n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:10</time_slice>
              <text_slice>It doesn't matter.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:11</time_slice>
              <text_slice>How many leaves are in
this tree, by the way?</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:25</time_slice>
              <text_slice>How many leaves
does this tree have?</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:28</time_slice>
              <text_slice>Yeah.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:28</time_slice>
              <text_slice>The number of
leaves, once again,</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:31</time_slice>
              <text_slice>is actually pretty close.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:34</time_slice>
              <text_slice>It's actually n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:35</time_slice>
              <text_slice>If you took it all the way down.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:38</time_slice>
              <text_slice>Let's make some simplifying
assumption. n is</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:42</time_slice>
              <text_slice>a perfect power of 2, so it
is an integer power of 2.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:47</time_slice>
              <text_slice>Then this is exactly log
n to get down to T(1).</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:52</time_slice>
              <text_slice>And then there are
exactly n leaves,</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:55</time_slice>
              <text_slice>because the number
of leaves here,</text_slice>
            </slice>
            <slice>
              <time_slice>1:16:58</time_slice>
              <text_slice>the number of nodes at
this level is 1, 2, 4, 8.</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:05</time_slice>
              <text_slice>And if I go down
height h, I have</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:08</time_slice>
              <text_slice>2 to the h leaves, 2 to
the log n, that is just n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:13</time_slice>
              <text_slice>We are doing math here, right?</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:17</time_slice>
              <text_slice>Now let's figure
out how much work,</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:20</time_slice>
              <text_slice>if I look at adding up
everything in this tree</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:25</time_slice>
              <text_slice>I am going to get T(n),
so let's add that up.</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:31</time_slice>
              <text_slice>Well, let's add it
up level by level.</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:36</time_slice>
              <text_slice>How much do we have
in the first level?</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:40</time_slice>
              <text_slice>Just cn.</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:41</time_slice>
              <text_slice>If I add up the second
level, how much do I have?</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:47</time_slice>
              <text_slice>cn.</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:48</time_slice>
              <text_slice>How about if I add up
the third level? cn.</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:53</time_slice>
              <text_slice>How about if I add
up all the leaves?</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:57</time_slice>
              <text_slice>Theta n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:17:58</time_slice>
              <text_slice>It is not necessarily cn
because the boundary case</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:05</time_slice>
              <text_slice>may have a different constant.</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:09</time_slice>
              <text_slice>It is actually theta n,
but cn all the way here.</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:14</time_slice>
              <text_slice>If I add up the
total amount, that</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:18</time_slice>
              <text_slice>is equal to cn times
log n, because that's</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:23</time_slice>
              <text_slice>the height, that is how many
cn's I have here, plus theta n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:31</time_slice>
              <text_slice>And this is a higher order term
than this, so this goes away,</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:39</time_slice>
              <text_slice>get rid of the constants, that
is equal to theta(n lg n).</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:45</time_slice>
              <text_slice>And theta(n lg n) is
asymptotically faster than</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:51</time_slice>
              <text_slice>theta(n^2).</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:52</time_slice>
              <text_slice>So, merge sort, on a
large enough input size,</text_slice>
            </slice>
            <slice>
              <time_slice>1:18:58</time_slice>
              <text_slice>is going to beat insertion sort.</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:03</time_slice>
              <text_slice>Merge sort is going to
be a faster algorithm.</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:07</time_slice>
              <text_slice>Sorry, you guys,
I didn't realize</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:10</time_slice>
              <text_slice>you couldn't see over there.</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:13</time_slice>
              <text_slice>You should speak up
if you cannot see.</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:16</time_slice>
              <text_slice>So, this is a faster algorithm
because theta(n lg n) grows</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:22</time_slice>
              <text_slice>more slowly than theta(n^2).</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:25</time_slice>
              <text_slice>And merge sort asymptotically
beats insertion sort.</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:31</time_slice>
              <text_slice>Even if you ran insertion
sort on a supercomputer,</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:35</time_slice>
              <text_slice>somebody running on a PC with
merge sort for sufficient large</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:40</time_slice>
              <text_slice>input will clobber them because
actually n^2 is way bigger than</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:46</time_slice>
              <text_slice>n log n once you get
the n's to be large.</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:50</time_slice>
              <text_slice>And, in practice, merge sort
tends to win here for n bigger</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:55</time_slice>
              <text_slice>than, say, 30 or so.</text_slice>
            </slice>
            <slice>
              <time_slice>1:19:58</time_slice>
              <text_slice>If you have a very small
input like 30 elements,</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:02</time_slice>
              <text_slice>insertion sort is a
perfectly decent sort to use.</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:06</time_slice>
              <text_slice>But merge sort is going to be
a lot faster even for something</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:11</time_slice>
              <text_slice>that is only a few
dozen elements.</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:14</time_slice>
              <text_slice>It is going to actually
be a faster algorithm.</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:18</time_slice>
              <text_slice>That's sort of the lessons, OK?</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:20</time_slice>
              <text_slice>Remember that to get your
recitation assignments</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:24</time_slice>
              <text_slice>and attend recitation on Friday.</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:27</time_slice>
              <text_slice>Because we are going to be going
through a bunch of the things</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:33</time_slice>
              <text_slice>that I have left
on the table here.</text_slice>
            </slice>
            <slice>
              <time_slice>1:20:36</time_slice>
              <text_slice>And see you next Monday.</text_slice>
            </slice>
          </transcript>
        </video>
      </videos>
    </lecture>
    <lecture>
      <lecture_title>Advanced Topics</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/resources/dyn_multi_alg/</lecture_pdf_url>
      <lectureno>L22</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>6 Handout 29: Dynamic Multithreaded Algorithms 
during the development of Socrates which was resolved by understanding the measures of work 
and critical-path length. 
The Socrates program was initially developed on a 32-processor computer at MIT, but it was 
intended to run on a 512-processor computer at the National Center for Supercomputing Appli
cations (NCSA) at the University of Illinois. A clever optimization was proposed which, during 
testing at MIT, caused the program to run much faster than the original program. Nevertheless, the 
optimization was abandoned, because an analysis of work and critical-path length indicated that 
the program would actually be slower on the NCSA machine. 
Let us examine this anomaly in more detail. For simplicity, the actual timing numbers have 
been simplied. The original program ran in T32 = 65 seconds at MIT on 32 processors. The 
optimized program ran in T= 40 seconds also on 32 processors. The original program had 32 
work T1 = 2048 seconds and critical-path length T = 1 second. Using the formula TP = 
T1/P+T as a good approximation of runtime, we discover that indeed T32 = 65 = 2048 /32+1. 
The optimized program had work T1 = 1024 seconds and critical-path length T = 8 seconds, 
yielding T = 40 = 1024 /32 + 8. But, now let us determine the runtimes on 512 processors. 32 
We have T512 = 2048/ 512 + 1 = 5 and T512 = 1024/ 512 + 8 = 10 , which is twice as slow! 
Thus, by using work and critical-path length, we can predict the performance of a multithreaded 
computation. 
Exercise 1-1. Sketch the multithreaded computation that results from executing F IB(5). Assume 
that all threads in the computation execute in unit time. What is the work of the computation? What is the critical-path length? Show how to schedule the dag on 2 processors in a greedy fashion 
by labeling each thread with the time step on which it executes. 
Exercise 1-2. Consider the following multithreaded procedure S UM for pairwise adding the ele
ments of arrays A[1. .n]and B[1. .n]and storing the sums in C[1. .n]: 
SUM(A, B, C ) 
1 for i 1 to length [A] 
2 do C[i]  spawn ADD(A[i], B[i]) 
3 sync 
ADD(x, y) 
1 return (x+ y) 
Determine an asymptotic bound on the work, the critical-path length, and the parallelism of the 
computation in terms of n. Give a divide-and-conquer algorithm for the problem that is as parallel 
as possible. Analyze your algorithm. 
Exercise 1-3. Prove that a greedy scheduler achieves the stronger bound 
TP  (T1  T)/P+ T . (4) 
Exercise 1-4. Prove that the time for a greedy scheduler to execute any multithreaded computa
tion is within a factor of 2 of the time required by an optimal scheduler.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>4 Handout29: DynamicMultithreadedAlgorithms
/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
/0/0/0/0/0/0/0/0/0/0/0/0
/1/1/1/1/1/1/1/1/1/1/1/1fib(3)
fib(2)
fib(1)fib(1)fib(2)
fib(1) fib(0)
fib(0)fib(4)
Figure 1:A dag representing the multithreaded computation of F IB(4). Threads are shown as circles, and
each group of threads belonging to the same procedure are sur rounded by a rounded rectangle. Downward
edges are spawns dependencies, horizontal edges represent continuation dependencies within a procedure,
and upward edges are return dependencies.
example, the computation in Figure 1. Suppose that every thr ead can be executed in unit time.
Then, thework ofthecomputationis 17,and thecritical-pathlengthis 8.
Whenamultithreadedcomputationisexecutedonagivennumb erPofprocessors,itsrunning
timedependsonhowefcientlytheunderlyingschedulercan executeit. Denoteby TPtherunning
time of a given computation on Pprocessors. Then, the work of the computation can be viewed
asT1,and thecritical-pathlengthcan beviewedas T.
The work and critical-path lengthcan beused to providelowe rboundson therunningtimeon
Pprocessors. Wehave
TPT1/P , (1)
sinceinonestep,a P-processorcomputercan doat most Pwork. Wealsohave
TPT, (2)
sincea P-processorcomputercandonomoreworkinonestepthananin nite-processorcomputer.
Thespeedupof a computation on Pprocessors is the ratio T1/TP, which indicates how many
times faster the P-processor execution is than a one-processor execution. If T1/TP= (P), then
wesaythatthe P-processorexecutionexhibits linearspeedup . Themaximumpossiblespeedupis
T1/T, which is also called the parallelism of the computation, because it represents the average
amount of work that can be done in parallel for each step along the critical path. We denote the
parallelismofacomputationby P.
1.3 Greedy Scheduling
Theprogrammerofamultithreadedapplicationhastheabili tytocontroltheworkandcritical-path
length of his application, but he has no direct control over t he scheduling of his application on a</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Handout 29: Dynamic Multithreaded Algorithms 9 
Thus, the parallelism for M ULT is M1(n)/M (n) = ( n3/lg 2 n), which is quite high. To multiply 
1000 1000 matrices, for example, the parallelism is (ignoring constants) about 10003/102 = 107 . 
Most parallel computers have far fewer processors. 
To achieve high performance, it is often advantageous for an algorithm to use less space, 
because more space usually means more time. For the matrix-multiplication problem, we can 
eliminate the temporary matrix T in exchange for reducing the parallelism. Our new algorithm 
MULT-ADD performs C C+ A Busing a similar divide-and-conquer strategy to M ULT. 
MULT-ADD (C, A, B, n ) 
1 if n= 1 
2 then C[1,1] C[1,1] + A[1,1] B[1,1] 
3 return 
4 partition A, B, and Cinto (n/2) (n/2)submatrices 
5 spawn MULT-ADD(C11, A11, B11, n/2) 
6 spawn MULT-ADD(C12, A11, B12, n/2) 
7 spawn MULT-ADD(C21, A21, B11, n/2) 
8 spawn MULT-ADD(C22, A21, B12, n/2) 
9 sync 
10 spawn MULT-ADD(C11, A12, B21, n/2) 
11 spawn MULT-ADD(C12, A12, B22, n/2) 
12 spawn MULT-ADD(C21, A22, B21, n/2) 
13 spawn MULT-ADD(C22, A22, B22, n/2) 
14 sync 
15 return 
Let MAP (n)be the P-processor running time of M ULT-ADD on n nmatrices. The work for 
MULT-ADD is MA1(n) = ( n3), following the same analysis as for M ULT, but the critical-path 
length is now 
MA(n) = 2 MA(n/2) + (1) 
= (n ), 
since only 4 recursive calls can be executed in parallel. 
2Thus, the parallelism is MA1(n)/MA(n) = ( n). On 10001000 matrices, for example, the 
parallelism is (ignoring constants) still quite high: about 10002 = 106. In practice, this algorithm 
often runs somewhat faster than the rst, since saving space often saves time due to hierarchical memory.</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>14 Handout 29: Dynamic Multithreaded Algorithms 
[4] Robert D.	 Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, 
Keith H. Randall, and Yuli Zhou. Cilk: An efcient multithreaded runtime system. In 
Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Paral
lel Programming (PPoPP) , pages 207216, Santa Barbara, California, July 1995. 
[5] Robert D. Blumofe and Charles E. Leiserson.	 Scheduling multithreaded computations by 
work stealing. In Proceedings of the 35th Annual Symposium on Foundations of Computer 
Science (FOCS) , pages 356368, Santa Fe, New Mexico, November 1994. 
[6] Richard P. Brent.	 The parallel evaluation of general arithmetic expressions. Journal of the 
ACM, 21(2):201206, April 1974. 
[7] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction 
to Algorithms . The MIT Press and McGraw-Hill, second edition, 2001. 
[8] Matteo Frigo, Charles E. Leiserson, and Keith H. Randall.	 The implementation of the Cilk
5 multithreaded language. In ACM SIGPLAN 98 Conference on Programming Language 
Design and Implementation (PLDI) , pages 212223, Montreal, Canada, June 1998. 
[9] R. L. Graham.	 Bounds on multiprocessing timing anomalies. SIAM Journal on Applied 
Mathematics , 17(2):416429, March 1969. 
[10] Keith H. Randall.	 Cilk: Efcient Multithreaded Computing . PhD thesis, Department of 
Electrical Engineering and Computer Science, Massachusetts Institute of Technology, May 
1998. 
[11] Supercomputing Technologies Group,	 MIT Computer Science and Articial Intelligence 
Laboratory. Cilk 5.3.2 Reference Manual , November 2001.</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Handout 29: Dynamic Multithreaded Algorithms	 13 
Exercise 2-7. Generalize the algorithm from Exercise 2-6 to nd arbitrary order statistics. De
scribe a merge-sorting algorithm with (nlgn) work that achieves a parallelism of (n/lgn). 
(Hint: Merge many subarrays in parallel.) 
Exercise 2-8. The length of a longest-common subsequence of two length- n sequences x and y 
can be computed in parallel using a divide-and-conquer multithreaded algorithm. Denote by c[i, j] 
the length of a longest common subsequence of x[1. .i] and y[1. .j]. First, the multithreaded 
algorithm recursively computes c[i, j] for all i in the range 1  i  n/2 and all j in the range 
1  j  n/2. Then, it recursively computes c[i, j] for 1  i  n/2 and n/2 &lt; j  n, while in 
parallel recursively computing c[i, j] for n/2 &lt; i  n and 1  j  n/2. Finally, it recursively 
computes c[i, j] for n/2 &lt; i  n and n/2 &lt; j  n. For the base case, the algorithm computes 
c[i, j] in terms of c[i 1, j 1], c[i 1, j], and c[i, j 1] in the ordinary way, since the logic of 
the algorithm guarantees that these three values have already been computed. 
That is, if the dynamic programming tableau is broken into four pieces 
I II 
III IV , 
then the recursive multithreaded code would look something like this: 
I 
spawn II 
spawn III 
sync 
IV 
return 
Analyze the work, critical-path length, and parallelism of this algorithm. Describe and analyze 
an algorithm that is asymptotically as efcient (same work) but more parallel. Make whatever 
interesting observations you can. Write an efcient Cilk program for the problem. 
References 
[1] Selim G. Akl and Nicola Santoro.	 Optimal parallel merging and sorting without memory 
conicts. IEEE Transactions on Computers , C-36(11), November 1987. 
[2] M. Akra and L. Bazzi.	 On the solution of linear recurrence equations. Computational Opti
mization and Application , 10:195210, 1998. 
[3] Robert D. Blumofe.	 Executing Multithreaded Programs Efciently . PhD thesis, Depart
ment of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, September 1995.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>12 Handout 29: Dynamic Multithreaded Algorithms 
constants a, b &gt; 0. We have 
PM1(n)  an  blg(n) + a(1  )n  blg((1  )n) + (lg n) 
= an  b(lg(n ) + lg((1  )n)) + (lg n) 
= an  b(lg + lgn + lg(1  ) + lg n) + (lg n) 
= an  blgn  (b(lgn + lg((1  ))) (lgn)) 
 an  blgn , 
since we can choose b large enough so that b(lgn + lg( (1  )))dominates (lgn). Moreover, 
we can pick a large enough to satisfy the base conditions. Thus, PM1(n) = ( n), which is the 
same work asymptotically as the ordinary, serial merging algorithm. 
We can now reanalyze the M ERGE -SORT using the P-M ERGE subroutine. The work T1(n) 
remains the same, but the worst-case critical-path length now satises 
T(n) = T(n/2) + (lg 2 n) 
= (lg 3 n). 
The parallelism is now (n lgn)/(lg 3 n) = ( n/lg 2 n). 
Exercise 2-1. Give an efcient and highly parallel multithreaded algorithm for multiplying an 
n n matrix A by a length- n vector x that achieves work (n2)and critical path (lgn). Analyze 
the work and critical-path length of your implementation, and give the parallelism. 
Exercise 2-2. Describe a multithreaded algorithm for matrix multiplication that achieves work 
(n3)and critical path (lgn). Comment informally on the locality displayed by your algorithm 
in the ideal cache model as compared with the two algorithms from this section. 
Exercise 2-3. Write a Cilk program to multiply an n1 n2 matrix by an n2 n3 matrix in parallel. 
Analyze the work, critical-path length, and parallelism of your implementation. Your algorithm 
should be efcient even if any of n1, n2, and n3 are 1. 
Exercise 2-4. Write a Cilk program to implement Strassens matrix multiplication algorithm in 
parallel as efciently as you can. Analyze the work, critical-path length, and parallelism of your 
implementation. 
Exercise 2-5. Write a Cilk program to invert a symmetric and positive-denite matrix in parallel. 
(Hint: Use a divide-and-conquer approach based on the ideas of Theorem 31.12 from [7].) 
Exercise 2-6. Akl and Santoro [1] have proposed a merging algorithm in which the rst step is to 
nd the median of all the elements in the two sorted input arrays (as opposed to the median of the 
elements in the larger subarray, as is done in P-M ERGE ). Show that if the total number of elements 
in the two arrays is n, this median can be found using (lgn)time on one processor in the worst 
case. Describe a linear-work multithreaded merging algorithm based on this subroutine that has a 
parallelism of (n/lg 2 n). Give and solve the recurrences for work and critical-path length, and 
determine the parallelism. Implement your algorithm as a Cilk program.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Handout 29: Dynamic Multithreaded Algorithms 7 
Exercise 1-5. For what number P of processors do the two chess programs described in this 
section run equally fast? 
TExercise 1-6. Professor Tweed takes some measurements of his (deterministic) multithreaded 
program, which is scheduled using a greedy scheduler, and nds that T4 = 80 seconds and 
64 = 10 seconds. What is the fastest that the professors computation could possibly run on 
10 processors? Use Inequality (4) and the two lower bounds from Inequalities (1) and (2) to derive 
your answer. 
2 Analysis of multithreaded algorithms 
We now turn to the design and analysis of multithreaded algorithms. Because of the divide-and-
conquer nature of the multithreaded model, recurrences are a natural way to express the work 
and critical-path length of a multithreaded algorithm. We shall investigate algorithms for matrix 
multiplication and sorting and analyze their performance. 
2.1 Parallel Matrix Multiplication 
To multiply two n  n matrices A and B in parallel to produce a matrix C, we can recursively 
formulate the problem as follows: 
 
C11 C12 
C21 C22  
= 
=  
 A11 A12 
A21 A22  
  
B11 B12 
B21 B22  
A11B11 + A12B21 A11B12 + A12B22  
. A21B11 + A22B21 A21B12 + A22B22 
Thus, each n  n matrix multiplication can be expressed as 8 multiplications and 4 additions of 
(n/2) (n/2) submatrices. The multithreaded procedure M ULT multiplies two n  n matrices, 
where n is a power of 2, using an auxiliary procedure A DD to add n  n matrices. This algorithm 
is not in-place. 
ADD(C, T, n ) 
1 if n = 1 
2 then C[1,1] C[1,1] + T[1,1] 
3 return 
4 partition C and T into (n/2) (n/2)submatrices 
5 spawn ADD(C11, T11, n/2) 
6 spawn ADD(C12, T12, n/2) 
7 spawn ADD(C21, T21, n/2) 
8 spawn ADD(C22, T22, n/2) 
9 sync 
10 return</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>8 Handout 29: Dynamic Multithreaded Algorithms 
MULT(C, A, B, n ) 
1 if n= 1 
2 then C[1,1] A[1,1] B[1,1] 
3 return 
4 allocate a temporary matrix T[1. .n,1. .n] 
5 partition A, B, C, and T into (n/2) (n/2)submatrices 
6 spawn MULT(C11, A11, B11, n/2) 
7 spawn MULT(C12, A11, B12, n/2) 
8 spawn MULT(C21, A21, B11, n/2) 
9 spawn MULT(C22, A21, B12, n/2) 
10 spawn MULT(T11, A12, B21, n/2) 
11 spawn MULT(T12, A12, B22, n/2) 
12 spawn MULT(T21, A22, B21, n/2) 
13 spawn MULT(T22, A22, B22, n/2) 
14 sync 
15 ADD(C, T, n ) 
The matrix partitionings in line 5 of M ULT and line 4 of ADD take O(1)time, since only a constant 
number of indexing operations are required. 
To analyze this algorithm, let AP (n)be the P-processor running time of A DD on nnmatrices, 
and let MP (n) be the P-processor running time of M ULT on n nmatrices. The work (running 
time on one processor) for A DD can be expressed by the recurrence 
A1(n) = 4 A1(n/2) + (1) 
= ( n 2), 
which is the same as for the ordinary double-nested-loop serial algorithm. Since the spawned 
procedures can be executed in parallel, the critical-path length for A DD is 
A(n) = A(n/2) + (1) 
= (lg n). 
The work for M ULT can be expressed by the recurrence 
M1(n) = 8 M1(n/2) + A1(n) 
= 8M1(n/2) + ( n 2) 
= ( n 3), 
which is the same as for the ordinary triple-nested-loop serial algorithm. The critical-path length 
for M ULT is 
M(n) = M(n/2) + (lg n) 
= (lg 2 n).</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>11 Handout 29: Dynamic Multithreaded Algorithms 
P-M ERGE (A[1. .l], B[1. .m], C[1. .n]) 
1 if m &gt; l  without loss of generality, larger array should be rst 
2 then P-M ERGE (B[1. .m], A[1. .l], C[1. .n]) 
3 return 
4 if n= 1 
5 then C[1]  A[1] 
6 return 
7 if l= 1  and m= 1 
8 then if A[1]  B[1] 
9 then C[1]  A[1]; C[2] B[1] 
10 else C[1]  B[1]; C[2] A[1] 
11 return 
12 nd jsuch that B[j]  A[l/2]  B[j+ 1] using binary search 
13 spawn P-M ERGE (A[1. .(l/2)], B[1. .j], C[1. .(l/2 + j)]) 
14 spawn P-M ERGE (A[(l/2 + 1) . .l], B[(j+ 1). .m], C[(l/2 + j+ 1). .n]) 
15 sync 
16 return 
This merging algorithm nds the median of the larger array and uses it to partition the smaller 
array. Then, the lower portions of the two arrays are recursively merged, and in parallel, so are the 
upper portions. 
To analyze P-M ERGE , let PMP (n) be the P-processor time to merge two arrays A and B 
having n = m+ l elements in total. Without loss of generality, let Abe the larger of the two 
arrays, that is, assume l m. 
Well analyze the critical-path length rst. The binary search of Btakes (lgm) time, which 
in the worst case is (lgn). Since the two recursive spawns in lines 13 and 14 operate in parallel, 
the worst-case critical-path length is (lgn) plus the worst-case critical path-length of the spawn 
operating on the larger subarrays. In the worst case, we must merge half of Awith all of B, in 
which case the recursive spawn operates on at most 3n/4 elements. Thus, we have 
PM(n)  PM(3n/4) + (lg n) 
= (lg 2 n). 
To analyze the work of M ERGE , observe that although the two recursive spawns may operate 
on different numbers of elements, they always operate on n elements between them. Let n 
be the number of elements operated on by the rst spawn, where  is a constant in the range 
1/4   3/4. Thus, the second spawn operates on (1  )nelements, and the worst-case work 
satises the recurrence 
PM1(n) = PM1(n) + PM1((1  )n) + (lg n). (5) 
We shall show that PM1(n) = ( n) using the substitution method. (Actually, the Akra-Bazzi 
method [2], if you know it, is simpler.) We assume inductively that PM1(n)  an blgnfor some</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Introduction to Algorithms December 5, 2005 
Massachusetts Institute of Technology 6.046J/18.410J 
Professors Erik D. Demaine and Charles E. Leiserson Handout 29 
A Minicourse on Dynamic Multithreaded Algorithms 
Charles E. Leiserson 
MIT Computer Science and Articial Intelligence Laboratory
Cambridge, Massachusetts 02139, USA
December 5, 2005 
Abstract 
This tutorial teaches dynamic multithreaded algorithms using a Cilk-like [11, 8, 10] model. 
The material was taught in the MIT undergraduate class 6.046 Introduction to Algorithms as 
two 80-minute lectures. The style of the lecture notes follows that of the textbook by Cormen, 
Leiserson, Rivest, and Stein [7], but the pseudocode from that textbook has been Cilkied 
to allow it to describe multithreaded algorithms. The rst lecture teaches the basics behind 
multithreading, including dening the measures of work and critical-path length. It culminates 
in the greedy scheduling theorem due to Graham and Brent [9, 6]. The second lecture shows 
how parallel applications, including matrix multiplication and sorting, can be analyzed using 
divide-and-conquer recurrences. 
1 Dynamic multithreaded programming 
As multiprocessor systems have become increasingly available, interest has grown in parallel pro
gramming. Multithreaded programming is a programming paradigm in which a single program 
is broken into multiple threads of control which interact to solve a single problem. These notes 
provide an introduction to the analysis of dynamic multithreaded algorithms, where threads can 
be created and destroyed as easily as an ordinary subroutine can be called and return. 
1.1 Model 
Our model of dynamic multithreaded computation is based on the procedure abstraction found in 
virtually any programming language. As an example, the procedure F IB gives a multithreaded 
algorithm for computing the Fibonacci numbers:1 
Support was provided in part by the Defense Advanced Research Projects Agency (DARPA) under Grant F30602-
97-1-0270, by the National Science Foundation under Grants EIA-9975036 and ACI-0324974, and by the Singapore-MIT Alliance. 
1This algorithm is a terrible way to compute Fibonacci numbers, since it runs in exponential time when logarithmic 
methods are known [7, pp. 902903], but it serves as a good didactic example. 
2</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Handout 29: Dynamic Multithreaded Algorithms 5 
given number of processors. It is up to the runtime scheduler to map the dynamically unfolding 
computation onto the available processors so that the computation executes efciently. Good on
line schedulers are known [3, 4, 5] but their analysis is complicated. For simplicity, well illustrate 
the principles behind these schedulers using an off-line greedy scheduler. 
A greedy scheduler schedules as much as it can at every time step. On a P-processor computer, 
time steps can be classied into two types. If there are P or more threads ready to execute, the step 
is a complete step, and the scheduler executes any P threads of those ready to execute. If there are 
fewer than P threads ready to execute, the step is an incomplete step, and the scheduler executes 
all of them. This greedy strategy is provably good. 
Theorem 1 (Graham [9], Brent [6]) A greedy scheduler executes any multithreaded computation 
G with work T1 and critical-path length T in time 
TP  T1/P + T (3) 
on a computer with P processors. 
Proof. For each complete step, P work is done by the P processors. Thus, the number of com
plete steps is at most T1/P, because after T1/P such steps, all the work in the computation has been 
performed. Now, consider an incomplete step, and consider the subdag G of G that remains to be 
executed. Without loss of generality, we can view each of the threads executing in unit time, since 
we can replace a longer thread with a chain of unit-time threads. Every thread with in-degree 0 is 
ready to be executed, since all of its predecessors have already executed. By the greedy scheduling policy, all such threads are executed, since there are strictly fewer than P such threads. Thus, the 
critical-path length of G
 is reduced by 1. Since the critical-path length of the subdag remaining 
to be executed decreases by 1 each for each incomplete step, the number of incomplete steps is at 
most T. Each step is either complete or incomplete, and hence Inequality (3) follows. 
Corollary 2 A greedy scheduler achieves linear speedup when P = O(P). 
Proof. Since P = T1/T, we have P = O(T1/T), or equivalently, that T = O(T1/P). Thus, 
we have TP  T1/P + T = O(T1/P). 
1.4 Cilk and Socrates 
Cilk [4, 11, 10] is a parallel, multithreaded language based on the serial programming language C. 
Instrumentation in the Cilk scheduler provides an accurate measure of work and critical path. Cilks 
randomized scheduler provably executes a multithreaded computation on a P-processor computer 
in TP = T1/P + O(T) expected time. Empirically, the scheduler achieves TP  T1/P + T 
time, yielding near-perfect linear speedup if P  P. 
Among the applications that have been programmed in Cilk are the Socrates and Cilkchess 
chess-playing programs. These programs have won numerous prizes in international competition and are considered to be among the strongest in the world. An interesting anomaly occurred</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Handout 29: Dynamic Multithreaded Algorithms 3 
FIB(n) 
1 if n &lt;2 
2 then return n 
3 x spawn FIB(n 1) 
4 y spawn FIB(n 2) 
5 sync 
6 return (x+ y) 
A spawn is the parallel analog of an ordinary subroutine call. The keyword spawn before the 
subroutine call in line 3 indicates that the subprocedure F IB(n 1) can execute in parallel with 
the procedure F IB(n) itself. Unlike an ordinary function call, however, where the parent is not 
resumed until after its child returns, in the case of a spawn, the parent can continue to execute in 
parallel with the child. In this case, the parent goes on to spawn F IB(n 2). In general, the parent 
can continue to spawn off children, producing a high degree of parallelism. 
A procedure cannot safely use the return values of the children it has spawned until it executes 
a sync statement. If any of its children have not completed when it executes a sync , the procedure 
suspends and does not resume until all of its children have completed. When all of its children 
return, execution of the procedure resumes at the point immediately following the sync statement. 
In the Fibonacci example, the sync statement in line 5 is required before the return statement 
in line 6 to avoid the anomaly that would occur if x and ywere summed before each had been 
computed. 
The spawn and sync keywords specify logical parallelism, not actual parallelism. That is, 
these keywords indicate which code may possibly execute in parallel, but what actually runs in 
parallel is determined by a scheduler , which maps the dynamically unfolding computation onto 
the available processors. 
We can view a multithreaded computation in graph-theoretic terms as a dynamically unfolding 
dag G= (V, E ), as is shown in Figure 1 for F IB. We dene a thread to be a maximal sequence 
of instructions not containing the parallel control statements spawn , sync , and return . Threads 
make up the set V of vertices of the multithreaded computation dag G. Each procedure execution is 
a linear chain of threads, each of which is connected to its successor in the chain by a continuation 
edge. When a thread u spawns a thread v, the dag contains a spawn edge (u, v)  E, as well 
as a continuation edge from u to us successor in the procedure. When a thread u returns, the 
dag contains an edge (u, v), where v is the thread that immediately follows the next sync in the 
parent procedure. Every computation starts with a single initial thread and (assuming that the 
computation terminates), ends with a single nal thread . Since the procedures are organized in a 
tree hierarchy, we can view the computation as a dag of threads embedded in the tree of procedures. 
1.2 Performance Measures 
Two performance measures sufce to gauge the theoretical efciency of multithreaded algorithms. 
We dene the work of a multithreaded computation to be the total time to execute all the operations 
in the computation on one processor. We dene the critical-path length of a computation to be 
the longest time to execute the threads along any path of dependencies in the dag. Consider, for</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>10 Handout 29: Dynamic Multithreaded Algorithms 
1 l/2 l 
A A[ 2] A[ 2] 
1 m j j l/ l/
+ 1 
A[l/2] A[l/2] B 
Figure 2 : Illustration of P-M ERGE . The median of array A is used to partition array B, and then the lower 
portions of the two arrays are recursively merged, as, in parallel, are the upper portions. 
2.2 Parallel Merge Sort 
This section shows how to parallelize merge sort. We shall see the parallelism of the algorithm 
depends on how well the merge subroutine can be parallelized. 
The most straightforward way to parallelize merge sort is to run the recursion in parallel, as is 
done in the following pseudocode: 
MERGE -SORT (A, p, r ) 
1 if p &lt; r 
2 then q (p+ r)/2 
3 spawn MERGE -SORT (A, p, q ) 
4 spawn MERGE -SORT (A, q + 1, r) 
5 sync 
6 M ERGE(A, p, q, r ) 
7 return 
The work of M ERGE -SORT on an array of n elements is 
T1(n) = 2 T1(n/2) + ( n) 
= (n lgn), 
since the running time of M ERGE is (n). Since the two recursive spawns operate in parallel, the 
critical-path length of M ERGE -SORT is 
T(n) = T(n/2) + ( n) 
= ( n). 
Consequently, the parallelism of the algorithm is T1(n)/T(n) = (lg n), which is puny. The 
obvious bottleneck is M ERGE . 
The following pseudocode, which is illustrated in Figure 2, performs the merge in parallel.</text>
        </slide>
      </slides>
      <videos>
        <video>
          <video_url>https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/resources/lecture-2-asymptotic-notation-recurrences-substitution-master-method/</video_url>
          <video_title>Lecture 2: Asymptotic Notation; Recurrences; Substitution, Master Method</video_title>
          <transcript>
            <slice>
              <time_slice>0:10</time_slice>
              <text_slice>My name is Erik Demaine.
You should call me Erik.</text_slice>
            </slice>
            <slice>
              <time_slice>0:13</time_slice>
              <text_slice>Welcome back to 6.046.
This is Lecture 2.</text_slice>
            </slice>
            <slice>
              <time_slice>0:16</time_slice>
              <text_slice>And today we are going to
essentially fill in some of the</text_slice>
            </slice>
            <slice>
              <time_slice>0:20</time_slice>
              <text_slice>more mathematical underpinnings
of Lecture 1.</text_slice>
            </slice>
            <slice>
              <time_slice>0:23</time_slice>
              <text_slice>So, Lecture 1,
we just sort of barely got our</text_slice>
            </slice>
            <slice>
              <time_slice>0:26</time_slice>
              <text_slice>feet wet with some analysis of
algorithms, insertion sort and</text_slice>
            </slice>
            <slice>
              <time_slice>0:31</time_slice>
              <text_slice>mergesort.
And we needed a couple of</text_slice>
            </slice>
            <slice>
              <time_slice>0:34</time_slice>
              <text_slice>tools.
We had this big idea of</text_slice>
            </slice>
            <slice>
              <time_slice>0:36</time_slice>
              <text_slice>asymptotics and forgetting about
constants, just looking at the</text_slice>
            </slice>
            <slice>
              <time_slice>0:40</time_slice>
              <text_slice>lead term.
And so, today,</text_slice>
            </slice>
            <slice>
              <time_slice>0:41</time_slice>
              <text_slice>we're going to develop
asymptotic notation so that we</text_slice>
            </slice>
            <slice>
              <time_slice>0:44</time_slice>
              <text_slice>know that mathematically.
And we also ended up with a</text_slice>
            </slice>
            <slice>
              <time_slice>0:47</time_slice>
              <text_slice>recurrence with mergesort,
the running time of mergesort,</text_slice>
            </slice>
            <slice>
              <time_slice>0:51</time_slice>
              <text_slice>so we need to see how to solve
recurrences.</text_slice>
            </slice>
            <slice>
              <time_slice>0:53</time_slice>
              <text_slice>And we will do those two things
today.</text_slice>
            </slice>
            <slice>
              <time_slice>0:55</time_slice>
              <text_slice>Question?
Yes, I will speak louder.</text_slice>
            </slice>
            <slice>
              <time_slice>0:58</time_slice>
              <text_slice>Thanks.
Good.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00</time_slice>
              <text_slice>Even though I have a
microphone, I am not amplified.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03</time_slice>
              <text_slice>OK, so let's start with
asymptotic notation.</text_slice>
            </slice>
            <slice>
              <time_slice>1:16</time_slice>
              <text_slice>We have seen some basic
asymptotic notation.</text_slice>
            </slice>
            <slice>
              <time_slice>1:19</time_slice>
              <text_slice>I am sure you have seen it in
other classes before,</text_slice>
            </slice>
            <slice>
              <time_slice>1:22</time_slice>
              <text_slice>things like big O-notation.
And today we are going to</text_slice>
            </slice>
            <slice>
              <time_slice>1:26</time_slice>
              <text_slice>really define this rigorously so
we know what is true and what is</text_slice>
            </slice>
            <slice>
              <time_slice>1:30</time_slice>
              <text_slice>not, what is valid and what is
not.</text_slice>
            </slice>
            <slice>
              <time_slice>1:40</time_slice>
              <text_slice>We are going to define,
and unfortunately today is
This will be true if c_1 is</text_slice>
            </slice>
            <slice>
              <time_slice>1:43</time_slice>
              <text_slice>going to be really mathematical
and really no algorithms today,</text_slice>
            </slice>
            <slice>
              <time_slice>1:48</time_slice>
              <text_slice>which is sort of an anticlimax.
But next lecture we will talk</text_slice>
            </slice>
            <slice>
              <time_slice>1:52</time_slice>
              <text_slice>about real algorithms and will
apply all the things we learned</text_slice>
            </slice>
            <slice>
              <time_slice>1:57</time_slice>
              <text_slice>today to real algorithms.
This is big O-notation,</text_slice>
            </slice>
            <slice>
              <time_slice>2:04</time_slice>
              <text_slice>capital O-notation.
We have f(n)=O[g(n)].</text_slice>
            </slice>
            <slice>
              <time_slice>2:12</time_slice>
              <text_slice>This means that there are some
suitable constants,</text_slice>
            </slice>
            <slice>
              <time_slice>2:21</time_slice>
              <text_slice>c and n_o, such that f is
bounded by cg(n) for all</text_slice>
            </slice>
            <slice>
              <time_slice>2:30</time_slice>
              <text_slice>sufficiently large n.
So, this is pretty intuitive</text_slice>
            </slice>
            <slice>
              <time_slice>2:38</time_slice>
              <text_slice>notion.
We have seen it before.</text_slice>
            </slice>
            <slice>
              <time_slice>2:42</time_slice>
              <text_slice>We are going to assume that
f(n) is non-negative here.</text_slice>
            </slice>
            <slice>
              <time_slice>2:47</time_slice>
              <text_slice>And I just want f(n) to be
bounded above by g(n).</text_slice>
            </slice>
            <slice>
              <time_slice>2:52</time_slice>
              <text_slice>We have seen a bunch of
examples, but something like</text_slice>
            </slice>
            <slice>
              <time_slice>2:57</time_slice>
              <text_slice>2n^2=O(n^3) defined.
And roughly this means if you</text_slice>
            </slice>
            <slice>
              <time_slice>3:02</time_slice>
              <text_slice>drop leading constants and low
order terms then this is less</text_slice>
            </slice>
            <slice>
              <time_slice>3:07</time_slice>
              <text_slice>than or equal to that.
So, big O corresponds roughly</text_slice>
            </slice>
            <slice>
              <time_slice>3:10</time_slice>
              <text_slice>to less than or equal to.
But this is the formalization.</text_slice>
            </slice>
            <slice>
              <time_slice>3:14</time_slice>
              <text_slice>Another way to think of it
formally, a funny thing about</text_slice>
            </slice>
            <slice>
              <time_slice>3:18</time_slice>
              <text_slice>this notation is it is
asymmetric.</text_slice>
            </slice>
            <slice>
              <time_slice>3:20</time_slice>
              <text_slice>Normally, you think of
equality being symmetric.</text_slice>
            </slice>
            <slice>
              <time_slice>3:23</time_slice>
              <text_slice>If A=B then B=A.
But it's not true here.</text_slice>
            </slice>
            <slice>
              <time_slice>3:26</time_slice>
              <text_slice>We do not have n^3 being big O
of n^2.</text_slice>
            </slice>
            <slice>
              <time_slice>3:30</time_slice>
              <text_slice>We don't even have big O of n^3
equaling n^2.</text_slice>
            </slice>
            <slice>
              <time_slice>3:33</time_slice>
              <text_slice>So, we will see exactly what
that means in a second.</text_slice>
            </slice>
            <slice>
              <time_slice>3:38</time_slice>
              <text_slice>But before we get there,
this is a bit bizarre notation</text_slice>
            </slice>
            <slice>
              <time_slice>3:43</time_slice>
              <text_slice>and you should always think
about what it really means.</text_slice>
            </slice>
            <slice>
              <time_slice>3:47</time_slice>
              <text_slice>Another way to think about what
it really means is that f(n) is</text_slice>
            </slice>
            <slice>
              <time_slice>3:53</time_slice>
              <text_slice>in some set of functions that
are like g.</text_slice>
            </slice>
            <slice>
              <time_slice>3:58</time_slice>
              <text_slice>You could define big O[g(n)] to
be a set of functions,</text_slice>
            </slice>
            <slice>
              <time_slice>4:04</time_slice>
              <text_slice>let's call it f(n),
such that there exist</text_slice>
            </slice>
            <slice>
              <time_slice>4:10</time_slice>
              <text_slice>constants.
They are the same definition,</text_slice>
            </slice>
            <slice>
              <time_slice>4:15</time_slice>
              <text_slice>I think, fancy here,
c and n_o, such that we have</text_slice>
            </slice>
            <slice>
              <time_slice>4:21</time_slice>
              <text_slice>the bound f(n) is between zero
and cg(n).</text_slice>
            </slice>
            <slice>
              <time_slice>4:34</time_slice>
              <text_slice>It is a bit of a long
definition, and that is why we</text_slice>
            </slice>
            <slice>
              <time_slice>4:37</time_slice>
              <text_slice>use the notation,
to avoid having to write this</text_slice>
            </slice>
            <slice>
              <time_slice>4:41</time_slice>
              <text_slice>over and over.
You can think of instead of n^2</text_slice>
            </slice>
            <slice>
              <time_slice>4:44</time_slice>
              <text_slice>being equal to big O of n^3,
what we really mean is that</text_slice>
            </slice>
            <slice>
              <time_slice>4:48</time_slice>
              <text_slice>2n^2 is in the set big O(n^3).
When we write equal sign,</text_slice>
            </slice>
            <slice>
              <time_slice>4:52</time_slice>
              <text_slice>we in some sense mean this in
the set, but we are going to use</text_slice>
            </slice>
            <slice>
              <time_slice>4:56</time_slice>
              <text_slice>equal sign.
You could write this.</text_slice>
            </slice>
            <slice>
              <time_slice>5:00</time_slice>
              <text_slice>And occasionally you see papers
that write this,</text_slice>
            </slice>
            <slice>
              <time_slice>5:03</time_slice>
              <text_slice>but this is the notation that
we are going to use.</text_slice>
            </slice>
            <slice>
              <time_slice>5:08</time_slice>
              <text_slice>That has the consequence the
equal sign is asymmetric,</text_slice>
            </slice>
            <slice>
              <time_slice>5:12</time_slice>
              <text_slice>just like this operator.
We have some nifty ways that we</text_slice>
            </slice>
            <slice>
              <time_slice>5:17</time_slice>
              <text_slice>actually use big O-notation.</text_slice>
            </slice>
            <slice>
              <time_slice>5:29</time_slice>
              <text_slice>And it is using it as a macro.
By the way, we have a lot to</text_slice>
            </slice>
            <slice>
              <time_slice>5:33</time_slice>
              <text_slice>cover today, so I am going to go
relatively fast.</text_slice>
            </slice>
            <slice>
              <time_slice>5:37</time_slice>
              <text_slice>If anything is unclear,
just stop, ask questions,</text_slice>
            </slice>
            <slice>
              <time_slice>5:41</time_slice>
              <text_slice>then I will slow down.
Otherwise, I will take this as</text_slice>
            </slice>
            <slice>
              <time_slice>5:45</time_slice>
              <text_slice>all completely obvious and I can
keep going at full speed.</text_slice>
            </slice>
            <slice>
              <time_slice>5:50</time_slice>
              <text_slice>The convention,
this is intuitive,</text_slice>
            </slice>
            <slice>
              <time_slice>5:52</time_slice>
              <text_slice>I guess, if you do some macro
programming or something,</text_slice>
            </slice>
            <slice>
              <time_slice>5:57</time_slice>
              <text_slice>but it's a bit more
mathematical.</text_slice>
            </slice>
            <slice>
              <time_slice>6:09</time_slice>
              <text_slice>We have defined big O-notation
and it equals big O of</text_slice>
            </slice>
            <slice>
              <time_slice>6:13</time_slice>
              <text_slice>something.
And so we have only defined big</text_slice>
            </slice>
            <slice>
              <time_slice>6:16</time_slice>
              <text_slice>O when on the equal sign we have
big O of some function.</text_slice>
            </slice>
            <slice>
              <time_slice>6:20</time_slice>
              <text_slice>But it is useful to have some
general expression on the</text_slice>
            </slice>
            <slice>
              <time_slice>6:24</time_slice>
              <text_slice>right-hand side that involves
big O.</text_slice>
            </slice>
            <slice>
              <time_slice>6:28</time_slice>
              <text_slice>For example,
let's say we have f(n) = n^3 +</text_slice>
            </slice>
            <slice>
              <time_slice>6:34</time_slice>
              <text_slice>O(n^2).
This is attempting to get an</text_slice>
            </slice>
            <slice>
              <time_slice>6:39</time_slice>
              <text_slice>error bound.
This is saying f(n) is</text_slice>
            </slice>
            <slice>
              <time_slice>6:45</time_slice>
              <text_slice>basically n^3 but there are
these lower order terms that are</text_slice>
            </slice>
            <slice>
              <time_slice>6:54</time_slice>
              <text_slice>O(n^2).
And so this means that there is</text_slice>
            </slice>
            <slice>
              <time_slice>7:00</time_slice>
              <text_slice>a function, shorthand for a
function, h(n) which is in</text_slice>
            </slice>
            <slice>
              <time_slice>7:08</time_slice>
              <text_slice>O(n^2) or equals O(n^2) such
that f(n) = n^3 + h(n).</text_slice>
            </slice>
            <slice>
              <time_slice>7:18</time_slice>
              <text_slice>It is saying that there are
some lower order terms that are</text_slice>
            </slice>
            <slice>
              <time_slice>7:21</time_slice>
              <text_slice>bounded above by some constant
times n^2 for sufficiently large</text_slice>
            </slice>
            <slice>
              <time_slice>7:25</time_slice>
              <text_slice>n, and that is what is here.
And then f(n) equals,</text_slice>
            </slice>
            <slice>
              <time_slice>7:28</time_slice>
              <text_slice>now this is a true equality,
n^3 plus that error term.</text_slice>
            </slice>
            <slice>
              <time_slice>7:32</time_slice>
              <text_slice>This is very useful here.
Essentially,</text_slice>
            </slice>
            <slice>
              <time_slice>7:34</time_slice>
              <text_slice>I am expressing what the lead
constant is and then saying</text_slice>
            </slice>
            <slice>
              <time_slice>7:37</time_slice>
              <text_slice>well, there is other stuff and
it's all at most n^2.</text_slice>
            </slice>
            <slice>
              <time_slice>7:40</time_slice>
              <text_slice>Saying that f(n) therefore is
also order n^3,</text_slice>
            </slice>
            <slice>
              <time_slice>7:42</time_slice>
              <text_slice>but that is a bit weaker of a
statement.</text_slice>
            </slice>
            <slice>
              <time_slice>7:44</time_slice>
              <text_slice>This is a bit more refined.
We won't need to use this too</text_slice>
            </slice>
            <slice>
              <time_slice>7:47</time_slice>
              <text_slice>often, but it is useful.
Sometimes we will see,</text_slice>
            </slice>
            <slice>
              <time_slice>7:50</time_slice>
              <text_slice>like in last class we even had
a big O inside a summation.</text_slice>
            </slice>
            <slice>
              <time_slice>7:53</time_slice>
              <text_slice>So, you can use them all over
the place.</text_slice>
            </slice>
            <slice>
              <time_slice>7:55</time_slice>
              <text_slice>The point is they represent
some function in that set.</text_slice>
            </slice>
            <slice>
              <time_slice>8:00</time_slice>
              <text_slice>A bit less intuitive,
and this is more subtle,</text_slice>
            </slice>
            <slice>
              <time_slice>8:04</time_slice>
              <text_slice>is what it means to have big O
on the left-hand side.</text_slice>
            </slice>
            <slice>
              <time_slice>8:10</time_slice>
              <text_slice>It means the same thing,
but there is some convention</text_slice>
            </slice>
            <slice>
              <time_slice>8:15</time_slice>
              <text_slice>what equality means.
And this is why equal sign is</text_slice>
            </slice>
            <slice>
              <time_slice>8:20</time_slice>
              <text_slice>asymmetric.
You should read equals like</text_slice>
            </slice>
            <slice>
              <time_slice>8:24</time_slice>
              <text_slice>"is".
Is means that everything over</text_slice>
            </slice>
            <slice>
              <time_slice>8:27</time_slice>
              <text_slice>here is something over here.
So, there is an implicit for</text_slice>
            </slice>
            <slice>
              <time_slice>8:34</time_slice>
              <text_slice>all on the left-hand side and
there exists on the right-hand</text_slice>
            </slice>
            <slice>
              <time_slice>8:39</time_slice>
              <text_slice>side.
This is a true statement.</text_slice>
            </slice>
            <slice>
              <time_slice>8:41</time_slice>
              <text_slice>Anything that is n^2 + O(n) is
also O(n^2), but not the other</text_slice>
            </slice>
            <slice>
              <time_slice>8:47</time_slice>
              <text_slice>way around.
So, this is a bit asymmetric.</text_slice>
            </slice>
            <slice>
              <time_slice>8:50</time_slice>
              <text_slice>If you think about it,
this is pretty intuitive but it</text_slice>
            </slice>
            <slice>
              <time_slice>8:55</time_slice>
              <text_slice>is subtle so you should be
careful.</text_slice>
            </slice>
            <slice>
              <time_slice>9:15</time_slice>
              <text_slice>This says for any expansion of
the macro on the left-hand side,</text_slice>
            </slice>
            <slice>
              <time_slice>9:20</time_slice>
              <text_slice>which should be f(n),
there is an expansion of the</text_slice>
            </slice>
            <slice>
              <time_slice>9:24</time_slice>
              <text_slice>macro on the right-hand side
such that we get equality.</text_slice>
            </slice>
            <slice>
              <time_slice>9:30</time_slice>
              <text_slice>And what this allows you to do
is if you have a chain of equal</text_slice>
            </slice>
            <slice>
              <time_slice>9:34</time_slice>
              <text_slice>signs relations,
a chain of "is"s,</text_slice>
            </slice>
            <slice>
              <time_slice>9:36</time_slice>
              <text_slice>then the very first one is
equal to or bounded by the very</text_slice>
            </slice>
            <slice>
              <time_slice>9:40</time_slice>
              <text_slice>last one.
So, you can chain equal signs</text_slice>
            </slice>
            <slice>
              <time_slice>9:42</time_slice>
              <text_slice>the way you normally would.
You just cannot flip them</text_slice>
            </slice>
            <slice>
              <time_slice>9:45</time_slice>
              <text_slice>around.
Good.</text_slice>
            </slice>
            <slice>
              <time_slice>9:46</time_slice>
              <text_slice>So, that's big O-notation.
Any questions about that?</text_slice>
            </slice>
            <slice>
              <time_slice>9:58</time_slice>
              <text_slice>So, big O is great for
expressing upper bounds.</text_slice>
            </slice>
            <slice>
              <time_slice>10:01</time_slice>
              <text_slice>But we also want to talk about
lower bounds.</text_slice>
            </slice>
            <slice>
              <time_slice>10:04</time_slice>
              <text_slice>For algorithms,
we usually care about upper</text_slice>
            </slice>
            <slice>
              <time_slice>10:06</time_slice>
              <text_slice>bounds on their running time.
Running times at most n^2 is at</text_slice>
            </slice>
            <slice>
              <time_slice>10:11</time_slice>
              <text_slice>most n log n up to big O,
but sometimes we need to</text_slice>
            </slice>
            <slice>
              <time_slice>10:14</time_slice>
              <text_slice>express functions that are at
least some quantity.</text_slice>
            </slice>
            <slice>
              <time_slice>10:17</time_slice>
              <text_slice>For example,
we will show that sorting</text_slice>
            </slice>
            <slice>
              <time_slice>10:20</time_slice>
              <text_slice>requires at least n log n time
in some model.</text_slice>
            </slice>
            <slice>
              <time_slice>10:23</time_slice>
              <text_slice>So, we need some other notation
for that.</text_slice>
            </slice>
            <slice>
              <time_slice>10:26</time_slice>
              <text_slice>And the notation is big
Omega-notation.</text_slice>
            </slice>
            <slice>
              <time_slice>10:30</time_slice>
              <text_slice>And it is pretty symmetric.
I will just write out the set</text_slice>
            </slice>
            <slice>
              <time_slice>10:35</time_slice>
              <text_slice>definition here.
And we are going to write f(n)=</text_slice>
            </slice>
            <slice>
              <time_slice>10:40</time_slice>
              <text_slice>big Omega[g(n)] to mean f(n) is
at least some constant times</text_slice>
            </slice>
            <slice>
              <time_slice>10:46</time_slice>
              <text_slice>g(n) --</text_slice>
            </slice>
            <slice>
              <time_slice>10:55</time_slice>
              <text_slice>-- for sufficiently large n.</text_slice>
            </slice>
            <slice>
              <time_slice>11:09</time_slice>
              <text_slice>So, I am basically just
reversing the inequality</text_slice>
            </slice>
            <slice>
              <time_slice>11:12</time_slice>
              <text_slice>relation between f and g,
nothing surprising,</text_slice>
            </slice>
            <slice>
              <time_slice>11:16</time_slice>
              <text_slice>just to have it there.
A random example,</text_slice>
            </slice>
            <slice>
              <time_slice>11:19</time_slice>
              <text_slice>and now we will get a little
bit more sophisticated,</text_slice>
            </slice>
            <slice>
              <time_slice>11:24</time_slice>
              <text_slice>root n= big Omega(lg n).
And you should read this that</text_slice>
            </slice>
            <slice>
              <time_slice>11:29</time_slice>
              <text_slice>up to constant factors root n is
at least log n for sufficiently</text_slice>
            </slice>
            <slice>
              <time_slice>11:34</time_slice>
              <text_slice>large n.
So, omega sort of corresponds</text_slice>
            </slice>
            <slice>
              <time_slice>11:38</time_slice>
              <text_slice>to greater than or equal to.
Let me give you some analogies.</text_slice>
            </slice>
            <slice>
              <time_slice>11:43</time_slice>
              <text_slice>We have big O,
we have big omega,</text_slice>
            </slice>
            <slice>
              <time_slice>11:46</time_slice>
              <text_slice>this is less than or equal to,
this is greater than or equal</text_slice>
            </slice>
            <slice>
              <time_slice>11:51</time_slice>
              <text_slice>to.
And I am going to fill in some</text_slice>
            </slice>
            <slice>
              <time_slice>11:53</time_slice>
              <text_slice>more here in a moment.</text_slice>
            </slice>
            <slice>
              <time_slice>12:10</time_slice>
              <text_slice>It's nice to have all the usual
operators we have.</text_slice>
            </slice>
            <slice>
              <time_slice>12:12</time_slice>
              <text_slice>Normally we have strict less
than, strict greater than and</text_slice>
            </slice>
            <slice>
              <time_slice>12:16</time_slice>
              <text_slice>equal sign.
And we want those sort of</text_slice>
            </slice>
            <slice>
              <time_slice>12:18</time_slice>
              <text_slice>analogs in the asymptotic world
where we ignore constant factors</text_slice>
            </slice>
            <slice>
              <time_slice>12:22</time_slice>
              <text_slice>and ignore lower order terms.
We have, for example,</text_slice>
            </slice>
            <slice>
              <time_slice>12:25</time_slice>
              <text_slice>big Theta[g(n)].
This is a capital theta which</text_slice>
            </slice>
            <slice>
              <time_slice>12:28</time_slice>
              <text_slice>means you write the horizontal
bar in the middle as opposed to</text_slice>
            </slice>
            <slice>
              <time_slice>12:31</time_slice>
              <text_slice>all the way through.
I didn't invent Greek,</text_slice>
            </slice>
            <slice>
              <time_slice>12:35</time_slice>
              <text_slice>so that is the way it is.
Theta means that you are less</text_slice>
            </slice>
            <slice>
              <time_slice>12:40</time_slice>
              <text_slice>than or equal to and you are
greater than or equal to up to</text_slice>
            </slice>
            <slice>
              <time_slice>12:44</time_slice>
              <text_slice>constant factors,
so it is the inner section of</text_slice>
            </slice>
            <slice>
              <time_slice>12:48</time_slice>
              <text_slice>these two sets,
big O and big Omega.</text_slice>
            </slice>
            <slice>
              <time_slice>12:51</time_slice>
              <text_slice>That is sort of like equal sign
but, of course,</text_slice>
            </slice>
            <slice>
              <time_slice>12:55</time_slice>
              <text_slice>this is very different.
You have things like n^2 is big</text_slice>
            </slice>
            <slice>
              <time_slice>13:00</time_slice>
              <text_slice>Theta of 2(n^2) because you
ignore constant factors,</text_slice>
            </slice>
            <slice>
              <time_slice>13:04</time_slice>
              <text_slice>but all of these other
relations, OK,</text_slice>
            </slice>
            <slice>
              <time_slice>13:07</time_slice>
              <text_slice>n^2 + O(n) = Theta(n^2),
but this does not hold with</text_slice>
            </slice>
            <slice>
              <time_slice>13:11</time_slice>
              <text_slice>theta because square root of n
is really asymptotically bigger</text_slice>
            </slice>
            <slice>
              <time_slice>13:16</time_slice>
              <text_slice>than log n.
And some of the other examples</text_slice>
            </slice>
            <slice>
              <time_slice>13:19</time_slice>
              <text_slice>we saw like n^2 versus n^3,
those don't hold with T.</text_slice>
            </slice>
            <slice>
              <time_slice>13:25</time_slice>
              <text_slice>And we have some strict
notation which are the little</text_slice>
            </slice>
            <slice>
              <time_slice>13:29</time_slice>
              <text_slice>o-notation and little
omega-notation.</text_slice>
            </slice>
            <slice>
              <time_slice>13:32</time_slice>
              <text_slice>There is no little theta
because there is not notion of</text_slice>
            </slice>
            <slice>
              <time_slice>13:37</time_slice>
              <text_slice>strict equality versus unstrict
equality.</text_slice>
            </slice>
            <slice>
              <time_slice>13:41</time_slice>
              <text_slice>Little o is going to correspond
roughly to less than and little</text_slice>
            </slice>
            <slice>
              <time_slice>13:47</time_slice>
              <text_slice>omega is going to correspond to
greater than.</text_slice>
            </slice>
            <slice>
              <time_slice>13:51</time_slice>
              <text_slice>This is a notation you will
just have to get used to.</text_slice>
            </slice>
            <slice>
              <time_slice>13:57</time_slice>
              <text_slice>And I am not going to define it
precisely here because it is</text_slice>
            </slice>
            <slice>
              <time_slice>14:03</time_slice>
              <text_slice>almost exactly the same.
The difference is that instead</text_slice>
            </slice>
            <slice>
              <time_slice>14:08</time_slice>
              <text_slice>of saying there exists constant
c and n_o, you have to say for</text_slice>
            </slice>
            <slice>
              <time_slice>14:15</time_slice>
              <text_slice>every constant c there exists a
constant n_o.</text_slice>
            </slice>
            <slice>
              <time_slice>14:19</time_slice>
              <text_slice>The relationship between f and
g, this inequality must hold for</text_slice>
            </slice>
            <slice>
              <time_slice>14:26</time_slice>
              <text_slice>all c instead of just for 1.
And so n_o can now depend on c.</text_slice>
            </slice>
            <slice>
              <time_slice>14:32</time_slice>
              <text_slice>You can assume that really n is
sufficiently large,</text_slice>
            </slice>
            <slice>
              <time_slice>14:37</time_slice>
              <text_slice>but this gives you a strict
inequality.</text_slice>
            </slice>
            <slice>
              <time_slice>14:40</time_slice>
              <text_slice>No matter what constant you put
here, in front of g,</text_slice>
            </slice>
            <slice>
              <time_slice>14:45</time_slice>
              <text_slice>let's say we are doing little
o, f will be still less than c</text_slice>
            </slice>
            <slice>
              <time_slice>14:50</time_slice>
              <text_slice>times g for sufficiently large
n.</text_slice>
            </slice>
            <slice>
              <time_slice>14:53</time_slice>
              <text_slice>We have some random examples.</text_slice>
            </slice>
            <slice>
              <time_slice>15:04</time_slice>
              <text_slice>We are again ignoring
constants.</text_slice>
            </slice>
            <slice>
              <time_slice>15:06</time_slice>
              <text_slice>n^2 is always less than n^3 for
sufficiently large n.</text_slice>
            </slice>
            <slice>
              <time_slice>15:11</time_slice>
              <text_slice>And it is a bit subtle here.
I mean in order to prove</text_slice>
            </slice>
            <slice>
              <time_slice>15:15</time_slice>
              <text_slice>something like this,
it will become intuitive after</text_slice>
            </slice>
            <slice>
              <time_slice>15:19</time_slice>
              <text_slice>you manipulate it a little bit.
You have to figure out what n_o</text_slice>
            </slice>
            <slice>
              <time_slice>15:25</time_slice>
              <text_slice>is in terms of c.
I think it something like 2/c.</text_slice>
            </slice>
            <slice>
              <time_slice>15:30</time_slice>
              <text_slice>If we have less than or equal
to, that should be right.</text_slice>
            </slice>
            <slice>
              <time_slice>15:34</time_slice>
              <text_slice>As long n is at least this big,
no matter how small of a c,</text_slice>
            </slice>
            <slice>
              <time_slice>15:38</time_slice>
              <text_slice>you should think of c here as
being epsilon now,</text_slice>
            </slice>
            <slice>
              <time_slice>15:42</time_slice>
              <text_slice>in the usual epsilon and
deltas.</text_slice>
            </slice>
            <slice>
              <time_slice>15:44</time_slice>
              <text_slice>No matter how small c gets,
still I can bound n^2 in terms</text_slice>
            </slice>
            <slice>
              <time_slice>15:49</time_slice>
              <text_slice>of n^3, upper bound,
but whenever you have theta you</text_slice>
            </slice>
            <slice>
              <time_slice>15:53</time_slice>
              <text_slice>do not have either of these
relations.</text_slice>
            </slice>
            <slice>
              <time_slice>15:57</time_slice>
              <text_slice>For example,
&#937;n^2 = Theta(n^2) and it is not</text_slice>
            </slice>
            <slice>
              <time_slice>16:00</time_slice>
              <text_slice>little o(n^2) and it not little
omega(n^2) because it is exactly</text_slice>
            </slice>
            <slice>
              <time_slice>16:06</time_slice>
              <text_slice>n^2.
You will get some sense in</text_slice>
            </slice>
            <slice>
              <time_slice>16:08</time_slice>
              <text_slice>order relation out of this,
although there are some messy</text_slice>
            </slice>
            <slice>
              <time_slice>16:13</time_slice>
              <text_slice>behaviors as you will see in
your problem set.</text_slice>
            </slice>
            <slice>
              <time_slice>16:17</time_slice>
              <text_slice>Any questions about asymptotic
notation?</text_slice>
            </slice>
            <slice>
              <time_slice>16:21</time_slice>
              <text_slice>That is the quick rundown.
Now we are going to use it to</text_slice>
            </slice>
            <slice>
              <time_slice>16:25</time_slice>
              <text_slice>solve some recurrences.
Although we won't use it that</text_slice>
            </slice>
            <slice>
              <time_slice>16:31</time_slice>
              <text_slice>much today, we will use it a lot
more on Wednesday.</text_slice>
            </slice>
            <slice>
              <time_slice>16:35</time_slice>
              <text_slice>OK.</text_slice>
            </slice>
            <slice>
              <time_slice>16:53</time_slice>
              <text_slice>We will move onto the second
topic of today,</text_slice>
            </slice>
            <slice>
              <time_slice>16:57</time_slice>
              <text_slice>which is solving recurrences.
You have probably solved some</text_slice>
            </slice>
            <slice>
              <time_slice>17:02</time_slice>
              <text_slice>recurrences before in 6.042 or
whatever discrete math class you</text_slice>
            </slice>
            <slice>
              <time_slice>17:06</time_slice>
              <text_slice>have taken.
We are going to do more and</text_slice>
            </slice>
            <slice>
              <time_slice>17:09</time_slice>
              <text_slice>have some techniques here that
are particularly useful for</text_slice>
            </slice>
            <slice>
              <time_slice>17:14</time_slice>
              <text_slice>analyzing recursive algorithms,
and we will see that mostly on</text_slice>
            </slice>
            <slice>
              <time_slice>17:18</time_slice>
              <text_slice>Wednesday.
There are three main methods</text_slice>
            </slice>
            <slice>
              <time_slice>17:21</time_slice>
              <text_slice>that we are going to use here
for solving recurrences.</text_slice>
            </slice>
            <slice>
              <time_slice>17:25</time_slice>
              <text_slice>The first one is the
substitution method.</text_slice>
            </slice>
            <slice>
              <time_slice>17:30</time_slice>
              <text_slice>There is no general procedure
for solving a recurrence.</text_slice>
            </slice>
            <slice>
              <time_slice>17:32</time_slice>
              <text_slice>There is no good algorithm for
solving recurrences,</text_slice>
            </slice>
            <slice>
              <time_slice>17:35</time_slice>
              <text_slice>unfortunately.
We just have a bunch of</text_slice>
            </slice>
            <slice>
              <time_slice>17:37</time_slice>
              <text_slice>techniques.
Some of them work some of the</text_slice>
            </slice>
            <slice>
              <time_slice>17:39</time_slice>
              <text_slice>time, and if you are lucky yours
will work for your recurrence,</text_slice>
            </slice>
            <slice>
              <time_slice>17:42</time_slice>
              <text_slice>but it is sort of like solving
an integral.</text_slice>
            </slice>
            <slice>
              <time_slice>17:44</time_slice>
              <text_slice>You have to just know some of
them, you have to know various</text_slice>
            </slice>
            <slice>
              <time_slice>17:47</time_slice>
              <text_slice>methods for solving them.
It is usually easy to check if</text_slice>
            </slice>
            <slice>
              <time_slice>17:50</time_slice>
              <text_slice>you have the right answer.
Just like with integrals,</text_slice>
            </slice>
            <slice>
              <time_slice>17:53</time_slice>
              <text_slice>you just differentiate and say
oh, I got the right answer.</text_slice>
            </slice>
            <slice>
              <time_slice>17:56</time_slice>
              <text_slice>And that is essentially the
idea of substitution method.</text_slice>
            </slice>
            <slice>
              <time_slice>18:00</time_slice>
              <text_slice>Substitution method will always
work, but unfortunately Step 1</text_slice>
            </slice>
            <slice>
              <time_slice>18:04</time_slice>
              <text_slice>is guess the answer.
And you have to guess it</text_slice>
            </slice>
            <slice>
              <time_slice>18:07</time_slice>
              <text_slice>correctly.
That makes it a big difficult.</text_slice>
            </slice>
            <slice>
              <time_slice>18:09</time_slice>
              <text_slice>You don't have to guess it
completely.</text_slice>
            </slice>
            <slice>
              <time_slice>18:12</time_slice>
              <text_slice>You can usually get away with
not knowing the constant</text_slice>
            </slice>
            <slice>
              <time_slice>18:15</time_slice>
              <text_slice>factors, which is a good thing
because we don't really care</text_slice>
            </slice>
            <slice>
              <time_slice>18:19</time_slice>
              <text_slice>about the constant factors.
You guess the form.</text_slice>
            </slice>
            <slice>
              <time_slice>18:22</time_slice>
              <text_slice>You say oh, it is going to be
roughly n^2, and so it's some</text_slice>
            </slice>
            <slice>
              <time_slice>18:26</time_slice>
              <text_slice>constant times n^2 presumably.
So, you guess that.</text_slice>
            </slice>
            <slice>
              <time_slice>18:31</time_slice>
              <text_slice>We are going to figure out the
constants.</text_slice>
            </slice>
            <slice>
              <time_slice>18:34</time_slice>
              <text_slice>You try to verify whether the
recurrence satisfies this bound</text_slice>
            </slice>
            <slice>
              <time_slice>18:38</time_slice>
              <text_slice>by induction,
and that is the key.</text_slice>
            </slice>
            <slice>
              <time_slice>18:40</time_slice>
              <text_slice>Substitution uses induction.
And from that you usually get</text_slice>
            </slice>
            <slice>
              <time_slice>18:44</time_slice>
              <text_slice>the constants for free.
You figure out what the</text_slice>
            </slice>
            <slice>
              <time_slice>18:48</time_slice>
              <text_slice>constants have to be in order to
make this work.</text_slice>
            </slice>
            <slice>
              <time_slice>18:51</time_slice>
              <text_slice>So, that is the general idea.
You will see a few examples of</text_slice>
            </slice>
            <slice>
              <time_slice>18:55</time_slice>
              <text_slice>this.
Actually, the same example</text_slice>
            </slice>
            <slice>
              <time_slice>18:57</time_slice>
              <text_slice>several times.
Unfortunately,</text_slice>
            </slice>
            <slice>
              <time_slice>19:01</time_slice>
              <text_slice>this is what you might call,
I don't know.</text_slice>
            </slice>
            <slice>
              <time_slice>19:04</time_slice>
              <text_slice>This is an algorithm,
but it uses an oracle which is</text_slice>
            </slice>
            <slice>
              <time_slice>19:08</time_slice>
              <text_slice>knowing the right answer.
But sometimes it is not too</text_slice>
            </slice>
            <slice>
              <time_slice>19:12</time_slice>
              <text_slice>hard to guess the answer.
It depends.</text_slice>
            </slice>
            <slice>
              <time_slice>19:14</time_slice>
              <text_slice>If you look at this recurrence,
T(n) = 4T(n/2) + n,</text_slice>
            </slice>
            <slice>
              <time_slice>19:18</time_slice>
              <text_slice>we should implicitly always
have some base case of T of some</text_slice>
            </slice>
            <slice>
              <time_slice>19:23</time_slice>
              <text_slice>constant, usually 1 is a
constant, so we don't really</text_slice>
            </slice>
            <slice>
              <time_slice>19:26</time_slice>
              <text_slice>care about the base case.
For algorithms that is always</text_slice>
            </slice>
            <slice>
              <time_slice>19:32</time_slice>
              <text_slice>the case.
And we want to solve this</text_slice>
            </slice>
            <slice>
              <time_slice>19:34</time_slice>
              <text_slice>thing.
Does anyone have a guess to</text_slice>
            </slice>
            <slice>
              <time_slice>19:37</time_slice>
              <text_slice>what the solution is?
Ideally someone who doesn't</text_slice>
            </slice>
            <slice>
              <time_slice>19:40</time_slice>
              <text_slice>already know how to solve this
recurrence.</text_slice>
            </slice>
            <slice>
              <time_slice>19:43</time_slice>
              <text_slice>OK.
How many people know how to</text_slice>
            </slice>
            <slice>
              <time_slice>19:45</time_slice>
              <text_slice>solve this recurrence?
A few, OK.</text_slice>
            </slice>
            <slice>
              <time_slice>19:48</time_slice>
              <text_slice>And, of the rest,
any guesses?</text_slice>
            </slice>
            <slice>
              <time_slice>19:50</time_slice>
              <text_slice>If you look at what is going on
here, here you have T(n/2) and</text_slice>
            </slice>
            <slice>
              <time_slice>19:55</time_slice>
              <text_slice>let's ignore this term more or
less.</text_slice>
            </slice>
            <slice>
              <time_slice>19:59</time_slice>
              <text_slice>We have n/2 here.
If we double n and get T(n)</text_slice>
            </slice>
            <slice>
              <time_slice>20:02</time_slice>
              <text_slice>then we multiply the value by 4.
And then there is this additive</text_slice>
            </slice>
            <slice>
              <time_slice>20:06</time_slice>
              <text_slice>end, but that doesn't matter so
much.</text_slice>
            </slice>
            <slice>
              <time_slice>20:08</time_slice>
              <text_slice>What function do you know that
when you double the argument the</text_slice>
            </slice>
            <slice>
              <time_slice>20:13</time_slice>
              <text_slice>output goes up by a factor of 4?
Sorry?</text_slice>
            </slice>
            <slice>
              <time_slice>20:15</time_slice>
              <text_slice>n^2,yeah.
You should think n^2 and you</text_slice>
            </slice>
            <slice>
              <time_slice>20:18</time_slice>
              <text_slice>would be right.
But we won't prove n^2 yet.</text_slice>
            </slice>
            <slice>
              <time_slice>20:21</time_slice>
              <text_slice>Let's prove something simpler,
because it turns out proving</text_slice>
            </slice>
            <slice>
              <time_slice>20:25</time_slice>
              <text_slice>that it is at most n^2 is a bit
of a pain.</text_slice>
            </slice>
            <slice>
              <time_slice>20:29</time_slice>
              <text_slice>We will see that in just a few
minutes.</text_slice>
            </slice>
            <slice>
              <time_slice>20:31</time_slice>
              <text_slice>But let's guess that T(n) =
O(n^3) first because that will</text_slice>
            </slice>
            <slice>
              <time_slice>20:36</time_slice>
              <text_slice>be easier to prove by induction.
You sort of see how it is done</text_slice>
            </slice>
            <slice>
              <time_slice>20:41</time_slice>
              <text_slice>in the easy case,
and then we will actually get</text_slice>
            </slice>
            <slice>
              <time_slice>20:44</time_slice>
              <text_slice>the right answer,
n^2, later.</text_slice>
            </slice>
            <slice>
              <time_slice>20:47</time_slice>
              <text_slice>I need to prove.
What I am going to do is guess</text_slice>
            </slice>
            <slice>
              <time_slice>20:50</time_slice>
              <text_slice>that T(n) is some constant times
n^3 at most, so I will be a</text_slice>
            </slice>
            <slice>
              <time_slice>20:55</time_slice>
              <text_slice>little more precise.
I cannot use the big O-notation</text_slice>
            </slice>
            <slice>
              <time_slice>20:59</time_slice>
              <text_slice>in the substitution method so I
have to expand it out to use</text_slice>
            </slice>
            <slice>
              <time_slice>21:03</time_slice>
              <text_slice>constants.
I will show you why in a little</text_slice>
            </slice>
            <slice>
              <time_slice>21:08</time_slice>
              <text_slice>bit, but let me just tell you at
a high level what is important</text_slice>
            </slice>
            <slice>
              <time_slice>21:13</time_slice>
              <text_slice>in not using big O-notation.
Big O-notation is great if you</text_slice>
            </slice>
            <slice>
              <time_slice>21:17</time_slice>
              <text_slice>have a finite chain of big O
relations, you know,</text_slice>
            </slice>
            <slice>
              <time_slice>21:21</time_slice>
              <text_slice>n^2 is big O(n^3) is big O(n^4)
is big O(n^4) is big O(n^4).</text_slice>
            </slice>
            <slice>
              <time_slice>21:25</time_slice>
              <text_slice>That is all true.
And so you get that n^2 is big</text_slice>
            </slice>
            <slice>
              <time_slice>21:29</time_slice>
              <text_slice>O(n^4).
But if you have an infinite</text_slice>
            </slice>
            <slice>
              <time_slice>21:33</time_slice>
              <text_slice>chain of those relations then
the first thing is not big O of</text_slice>
            </slice>
            <slice>
              <time_slice>21:37</time_slice>
              <text_slice>the last thing.
You have to be very careful.</text_slice>
            </slice>
            <slice>
              <time_slice>21:41</time_slice>
              <text_slice>For example,
this is a total aside on the</text_slice>
            </slice>
            <slice>
              <time_slice>21:44</time_slice>
              <text_slice>lecture notes.
Suppose you want to prove that</text_slice>
            </slice>
            <slice>
              <time_slice>21:47</time_slice>
              <text_slice>n = O(1).
This is a great relation.</text_slice>
            </slice>
            <slice>
              <time_slice>21:50</time_slice>
              <text_slice>If it were true,
every algorithm would have</text_slice>
            </slice>
            <slice>
              <time_slice>21:53</time_slice>
              <text_slice>constant running time.
This is not true.</text_slice>
            </slice>
            <slice>
              <time_slice>21:56</time_slice>
              <text_slice>Not in Wayne's World notation.
You could "prove this by</text_slice>
            </slice>
            <slice>
              <time_slice>22:02</time_slice>
              <text_slice>induction" by saying well,
base case is 1 = O(1).</text_slice>
            </slice>
            <slice>
              <time_slice>22:07</time_slice>
              <text_slice>OK, that is true.
And then the induction step as</text_slice>
            </slice>
            <slice>
              <time_slice>22:12</time_slice>
              <text_slice>well, if I know that n-1,
so let's suppose that n-1 =</text_slice>
            </slice>
            <slice>
              <time_slice>22:18</time_slice>
              <text_slice>O(1), well, that implies that n,
which is (n-1) +1,</text_slice>
            </slice>
            <slice>
              <time_slice>22:23</time_slice>
              <text_slice>if this is O(1) and 1 = O(1),
the whole thing is O(1).</text_slice>
            </slice>
            <slice>
              <time_slice>22:30</time_slice>
              <text_slice>And that is true.
If you knew that (n-1) = O(1)</text_slice>
            </slice>
            <slice>
              <time_slice>22:32</time_slice>
              <text_slice>and 1 = O(1) then their sum is
also O(1), but this is a false</text_slice>
            </slice>
            <slice>
              <time_slice>22:35</time_slice>
              <text_slice>proof.
You cannot induct over big Os.</text_slice>
            </slice>
            <slice>
              <time_slice>22:37</time_slice>
              <text_slice>What is going on here is that
the constants that are implicit</text_slice>
            </slice>
            <slice>
              <time_slice>22:40</time_slice>
              <text_slice>in here are changing.
Here you have some big O of 1,</text_slice>
            </slice>
            <slice>
              <time_slice>22:43</time_slice>
              <text_slice>here you have some big O of 1.
You are probably doubling the</text_slice>
            </slice>
            <slice>
              <time_slice>22:46</time_slice>
              <text_slice>constant in there every time you
do this relation.</text_slice>
            </slice>
            <slice>
              <time_slice>22:49</time_slice>
              <text_slice>If you have a finite number of
doubling of constants,</text_slice>
            </slice>
            <slice>
              <time_slice>22:52</time_slice>
              <text_slice>no big deal,
it is just a constant,</text_slice>
            </slice>
            <slice>
              <time_slice>22:54</time_slice>
              <text_slice>two the power number of
doublings.</text_slice>
            </slice>
            <slice>
              <time_slice>22:55</time_slice>
              <text_slice>But here you are doing n
doublings and that is no good.</text_slice>
            </slice>
            <slice>
              <time_slice>23:00</time_slice>
              <text_slice>The constant is now depending
on n.</text_slice>
            </slice>
            <slice>
              <time_slice>23:02</time_slice>
              <text_slice>So, we are avoiding this kind
of problem by writing out the</text_slice>
            </slice>
            <slice>
              <time_slice>23:06</time_slice>
              <text_slice>constant.
We have to make sure that</text_slice>
            </slice>
            <slice>
              <time_slice>23:08</time_slice>
              <text_slice>constant doesn't change.
Good.</text_slice>
            </slice>
            <slice>
              <time_slice>23:11</time_slice>
              <text_slice>Now I have written out the
constant.</text_slice>
            </slice>
            <slice>
              <time_slice>23:13</time_slice>
              <text_slice>I should be safe.
I am assuming it for all k less</text_slice>
            </slice>
            <slice>
              <time_slice>23:16</time_slice>
              <text_slice>than n, now I have to prove it
for k equal to n.</text_slice>
            </slice>
            <slice>
              <time_slice>23:20</time_slice>
              <text_slice>I am going to take T(n) and
just expand it.</text_slice>
            </slice>
            <slice>
              <time_slice>23:23</time_slice>
              <text_slice>I am going to do the obvious
thing.</text_slice>
            </slice>
            <slice>
              <time_slice>23:25</time_slice>
              <text_slice>I have this recurrence how to
expand T(n).</text_slice>
            </slice>
            <slice>
              <time_slice>23:30</time_slice>
              <text_slice>Then it involves T(n/2).
And I know some fact about</text_slice>
            </slice>
            <slice>
              <time_slice>23:35</time_slice>
              <text_slice>T(n/2) because n/2 is less than
n.</text_slice>
            </slice>
            <slice>
              <time_slice>23:39</time_slice>
              <text_slice>So, let's expand.
T(n) = 4T(n/2) + n.</text_slice>
            </slice>
            <slice>
              <time_slice>23:43</time_slice>
              <text_slice>And now I have an upper bound
on this thing from the induction</text_slice>
            </slice>
            <slice>
              <time_slice>23:50</time_slice>
              <text_slice>hypothesis.
This is at most 4 times c times</text_slice>
            </slice>
            <slice>
              <time_slice>23:55</time_slice>
              <text_slice>the argument cubed plus n.</text_slice>
            </slice>
            <slice>
              <time_slice>24:40</time_slice>
              <text_slice>Continuing on here.
Let's expand this a little bit.</text_slice>
            </slice>
            <slice>
              <time_slice>24:48</time_slice>
              <text_slice>We have n cubed over 2 cubed.
Two cubed is 8,</text_slice>
            </slice>
            <slice>
              <time_slice>24:56</time_slice>
              <text_slice>so 4 over 8 is a half.
So, we have &#937;cn^3 + n.</text_slice>
            </slice>
            <slice>
              <time_slice>25:05</time_slice>
              <text_slice>And what I would like this to
be is, so at the bottom where I</text_slice>
            </slice>
            <slice>
              <time_slice>25:10</time_slice>
              <text_slice>would like to go is that this is
at most cn3.</text_slice>
            </slice>
            <slice>
              <time_slice>25:13</time_slice>
              <text_slice>That is what I would like to
prove to reestablish the</text_slice>
            </slice>
            <slice>
              <time_slice>25:18</time_slice>
              <text_slice>induction hypothesis for n.
What I will do,</text_slice>
            </slice>
            <slice>
              <time_slice>25:21</time_slice>
              <text_slice>in order to see when that is
case, is just write this as what</text_slice>
            </slice>
            <slice>
              <time_slice>25:26</time_slice>
              <text_slice>I want, so this is sort of the
desired value,</text_slice>
            </slice>
            <slice>
              <time_slice>25:30</time_slice>
              <text_slice>cn3, minus whatever I don't
want.</text_slice>
            </slice>
            <slice>
              <time_slice>25:34</time_slice>
              <text_slice>This is called the residual.
Now I have to actually figure</text_slice>
            </slice>
            <slice>
              <time_slice>25:39</time_slice>
              <text_slice>this out.
Let's see.</text_slice>
            </slice>
            <slice>
              <time_slice>25:41</time_slice>
              <text_slice>We have cn^3,
but only &#937;cn^3 here,</text_slice>
            </slice>
            <slice>
              <time_slice>25:44</time_slice>
              <text_slice>so I need to subtract off &#937;cn^3
to get that lead term correct.</text_slice>
            </slice>
            <slice>
              <time_slice>25:49</time_slice>
              <text_slice>And then I have plus n and
there is a minus here,</text_slice>
            </slice>
            <slice>
              <time_slice>25:54</time_slice>
              <text_slice>so it is minus n.
And that is the residual.</text_slice>
            </slice>
            <slice>
              <time_slice>25:59</time_slice>
              <text_slice>In order for this to be at most
this, I need that the residual</text_slice>
            </slice>
            <slice>
              <time_slice>26:04</time_slice>
              <text_slice>is non-negative.
This is if the residual part is</text_slice>
            </slice>
            <slice>
              <time_slice>26:07</time_slice>
              <text_slice>greater than or equal to zero,
which is pretty easy to do</text_slice>
            </slice>
            <slice>
              <time_slice>26:12</time_slice>
              <text_slice>because here I have control over
c.</text_slice>
            </slice>
            <slice>
              <time_slice>26:15</time_slice>
              <text_slice>I get to pick c to be whatever
I want.</text_slice>
            </slice>
            <slice>
              <time_slice>26:18</time_slice>
              <text_slice>And, as long as c is at least,
oh, I don't know,</text_slice>
            </slice>
            <slice>
              <time_slice>26:22</time_slice>
              <text_slice>2, then this is a 1 at least.
Then I have n^3 should be</text_slice>
            </slice>
            <slice>
              <time_slice>26:26</time_slice>
              <text_slice>greater than or equal to n.
And that is always the case.</text_slice>
            </slice>
            <slice>
              <time_slice>26:33</time_slice>
              <text_slice>For example,
this is true if c is at least</text_slice>
            </slice>
            <slice>
              <time_slice>0:01</time_slice>
              <text_slice>And I don't think it matters</text_slice>
            </slice>
            <slice>
              <time_slice>26:41</time_slice>
              <text_slice>what n is, but let's say n is at
least 1 just for kicks.</text_slice>
            </slice>
            <slice>
              <time_slice>26:47</time_slice>
              <text_slice>So, what we have done is proved
that T(n) is at most some</text_slice>
            </slice>
            <slice>
              <time_slice>26:53</time_slice>
              <text_slice>constant times n^3.
And the constant is like 1.</text_slice>
            </slice>
            <slice>
              <time_slice>27:00</time_slice>
              <text_slice>So, that is an upper bound.
It is not a tight upper bound.</text_slice>
            </slice>
            <slice>
              <time_slice>27:03</time_slice>
              <text_slice>We actually believed that it is
n^2, and it is,</text_slice>
            </slice>
            <slice>
              <time_slice>27:06</time_slice>
              <text_slice>but you have to be a little
careful.</text_slice>
            </slice>
            <slice>
              <time_slice>27:09</time_slice>
              <text_slice>This does not mean that the
answer is n^3.</text_slice>
            </slice>
            <slice>
              <time_slice>27:11</time_slice>
              <text_slice>It just means that at most n^3
is big O(n^3).</text_slice>
            </slice>
            <slice>
              <time_slice>27:14</time_slice>
              <text_slice>And this is a proof by
induction.</text_slice>
            </slice>
            <slice>
              <time_slice>27:16</time_slice>
              <text_slice>Now, technically I should have
put a base case in this</text_slice>
            </slice>
            <slice>
              <time_slice>27:20</time_slice>
              <text_slice>induction, so there is a little
bit missing.</text_slice>
            </slice>
            <slice>
              <time_slice>27:22</time_slice>
              <text_slice>The base case is pretty easy
because T(1) is some constant,</text_slice>
            </slice>
            <slice>
              <time_slice>27:26</time_slice>
              <text_slice>but it will sort of influence
things.</text_slice>
            </slice>
            <slice>
              <time_slice>27:29</time_slice>
              <text_slice>If the base case T(1) is some
constant.</text_slice>
            </slice>
            <slice>
              <time_slice>27:33</time_slice>
              <text_slice>And what we need is that it is
at most c times one cubed,</text_slice>
            </slice>
            <slice>
              <time_slice>27:37</time_slice>
              <text_slice>which is c.
And that will be true as long</text_slice>
            </slice>
            <slice>
              <time_slice>27:40</time_slice>
              <text_slice>as you choose c to be
sufficiently large.</text_slice>
            </slice>
            <slice>
              <time_slice>27:43</time_slice>
              <text_slice>So, this is true if c is chosen
sufficiently large.</text_slice>
            </slice>
            <slice>
              <time_slice>27:47</time_slice>
              <text_slice>Now, we don't care about
constants, but the point is just</text_slice>
            </slice>
            <slice>
              <time_slice>27:52</time_slice>
              <text_slice>to be a little bit careful.
It is not true that T(n) is at</text_slice>
            </slice>
            <slice>
              <time_slice>27:56</time_slice>
              <text_slice>most 1 times n^2,
even though here all we need is</text_slice>
            </slice>
            <slice>
              <time_slice>28:00</time_slice>
              <text_slice>that c is at least 1.
For the base case to work,</text_slice>
            </slice>
            <slice>
              <time_slice>28:05</time_slice>
              <text_slice>c actually might have to be a
hundred or whatever T(1) is.</text_slice>
            </slice>
            <slice>
              <time_slice>28:10</time_slice>
              <text_slice>So, be a little bit careful
there.</text_slice>
            </slice>
            <slice>
              <time_slice>28:14</time_slice>
              <text_slice>It doesn't really affect the
answer, usually it won't because</text_slice>
            </slice>
            <slice>
              <time_slice>28:19</time_slice>
              <text_slice>we have very simple base cases
here.</text_slice>
            </slice>
            <slice>
              <time_slice>28:23</time_slice>
              <text_slice>OK, so let's try to prove the
tight bound of O(n^2).</text_slice>
            </slice>
            <slice>
              <time_slice>28:29</time_slice>
              <text_slice>I am not going to prove an
omega bound, but you can prove</text_slice>
            </slice>
            <slice>
              <time_slice>28:33</time_slice>
              <text_slice>an omega n squared bound as well
using substitution method.</text_slice>
            </slice>
            <slice>
              <time_slice>28:38</time_slice>
              <text_slice>I will just be satisfied for
now proving an upper bound of n</text_slice>
            </slice>
            <slice>
              <time_slice>28:43</time_slice>
              <text_slice>squared.
Let's try to prove that T(n),</text_slice>
            </slice>
            <slice>
              <time_slice>28:46</time_slice>
              <text_slice>this is the same recurrence,
I want to prove that it is</text_slice>
            </slice>
            <slice>
              <time_slice>28:51</time_slice>
              <text_slice>O(n^2).
I am going to do the same</text_slice>
            </slice>
            <slice>
              <time_slice>28:53</time_slice>
              <text_slice>thing.
And I will write a bit faster</text_slice>
            </slice>
            <slice>
              <time_slice>28:56</time_slice>
              <text_slice>because this is basically
copying.</text_slice>
            </slice>
            <slice>
              <time_slice>29:06</time_slice>
              <text_slice>Except now, instead of three,
I have two.</text_slice>
            </slice>
            <slice>
              <time_slice>29:10</time_slice>
              <text_slice>Then I have T(n) = 4T(n/2) + n.
I expand this T(n/2).</text_slice>
            </slice>
            <slice>
              <time_slice>29:17</time_slice>
              <text_slice>This is at most 4c(n/2)^2 + n.
And now, instead of have 2</text_slice>
            </slice>
            <slice>
              <time_slice>29:24</time_slice>
              <text_slice>cubed, I have 2 squared,
which is only 4.</text_slice>
            </slice>
            <slice>
              <time_slice>29:30</time_slice>
              <text_slice>The fours cancel.
I get cn^2 + n.</text_slice>
            </slice>
            <slice>
              <time_slice>29:32</time_slice>
              <text_slice>And if you prefer to write it
as desired minus residual,</text_slice>
            </slice>
            <slice>
              <time_slice>29:37</time_slice>
              <text_slice>then I have cn^2 - (-n).
And I want this to be</text_slice>
            </slice>
            <slice>
              <time_slice>29:42</time_slice>
              <text_slice>non-negative.
And it is damn hard for minus n</text_slice>
            </slice>
            <slice>
              <time_slice>29:46</time_slice>
              <text_slice>to be non-negative.
If n is zero we are happy,</text_slice>
            </slice>
            <slice>
              <time_slice>29:50</time_slice>
              <text_slice>but unfortunately this is an
induction on n.</text_slice>
            </slice>
            <slice>
              <time_slice>29:54</time_slice>
              <text_slice>It's got to hold for all n
greater than or equal to 1.</text_slice>
            </slice>
            <slice>
              <time_slice>30:00</time_slice>
              <text_slice>This is not less than or equal
to cn^2.</text_slice>
            </slice>
            <slice>
              <time_slice>30:02</time_slice>
              <text_slice>Notice the temptation is to
write that this equals O(n^2),</text_slice>
            </slice>
            <slice>
              <time_slice>30:06</time_slice>
              <text_slice>which is true for this one
step.</text_slice>
            </slice>
            <slice>
              <time_slice>30:09</time_slice>
              <text_slice>cn^2 - (-n),
well, these are both order n,</text_slice>
            </slice>
            <slice>
              <time_slice>30:12</time_slice>
              <text_slice>or this is order n,
this is order n squared.</text_slice>
            </slice>
            <slice>
              <time_slice>30:15</time_slice>
              <text_slice>Certainly this thing is O(n^2),
that is true,</text_slice>
            </slice>
            <slice>
              <time_slice>30:18</time_slice>
              <text_slice>but it is not completing the
induction.</text_slice>
            </slice>
            <slice>
              <time_slice>30:21</time_slice>
              <text_slice>To complete the induction,
you have to prove the induction</text_slice>
            </slice>
            <slice>
              <time_slice>30:25</time_slice>
              <text_slice>hypothesis for n with this
constant c.</text_slice>
            </slice>
            <slice>
              <time_slice>30:29</time_slice>
              <text_slice>Here you are getting a constant
c of like c + 1,</text_slice>
            </slice>
            <slice>
              <time_slice>30:32</time_slice>
              <text_slice>which is not good.
This is true but useless.</text_slice>
            </slice>
            <slice>
              <time_slice>30:36</time_slice>
              <text_slice>It does not finish the
induction, so you can sort of</text_slice>
            </slice>
            <slice>
              <time_slice>30:40</time_slice>
              <text_slice>ignore that.
This proof doesn't work,</text_slice>
            </slice>
            <slice>
              <time_slice>30:42</time_slice>
              <text_slice>which is kind of annoying
because we feel,</text_slice>
            </slice>
            <slice>
              <time_slice>30:46</time_slice>
              <text_slice>in our heart of hearts,
that T(n) = n^2.</text_slice>
            </slice>
            <slice>
              <time_slice>30:49</time_slice>
              <text_slice>It turns out to fix this you
need to express T(n) in a</text_slice>
            </slice>
            <slice>
              <time_slice>30:53</time_slice>
              <text_slice>slightly different form.
This is, again,</text_slice>
            </slice>
            <slice>
              <time_slice>30:56</time_slice>
              <text_slice>divine inspiration.
And, if you have a good</text_slice>
            </slice>
            <slice>
              <time_slice>31:00</time_slice>
              <text_slice>connection to some divinity,
you are all set.</text_slice>
            </slice>
            <slice>
              <time_slice>31:03</time_slice>
              <text_slice>[LAUGHTER] But it is a little
bit harder for the rest of us</text_slice>
            </slice>
            <slice>
              <time_slice>31:06</time_slice>
              <text_slice>mere mortals.
It turns out,</text_slice>
            </slice>
            <slice>
              <time_slice>31:08</time_slice>
              <text_slice>and maybe you could guess this,
that the idea is we want to</text_slice>
            </slice>
            <slice>
              <time_slice>31:12</time_slice>
              <text_slice>strengthen the induction
hypothesis.</text_slice>
            </slice>
            <slice>
              <time_slice>31:14</time_slice>
              <text_slice>We assumed this relatively weak
thing, T(k) is less than or</text_slice>
            </slice>
            <slice>
              <time_slice>31:18</time_slice>
              <text_slice>equal to some constant times
k^2.</text_slice>
            </slice>
            <slice>
              <time_slice>31:20</time_slice>
              <text_slice>We didn't know what the
constant was,</text_slice>
            </slice>
            <slice>
              <time_slice>31:22</time_slice>
              <text_slice>that is fine,
but we assumed that there were</text_slice>
            </slice>
            <slice>
              <time_slice>31:25</time_slice>
              <text_slice>no lower order terms.
I want to look at lower order</text_slice>
            </slice>
            <slice>
              <time_slice>31:28</time_slice>
              <text_slice>terms.
Maybe they play a role.</text_slice>
            </slice>
            <slice>
              <time_slice>31:31</time_slice>
              <text_slice>And if you look at this
progression you say,</text_slice>
            </slice>
            <slice>
              <time_slice>31:33</time_slice>
              <text_slice>oh, well, I am getting
something like n^2 and the</text_slice>
            </slice>
            <slice>
              <time_slice>31:36</time_slice>
              <text_slice>constants are pretty damn tight.
I mean the fours are canceling</text_slice>
            </slice>
            <slice>
              <time_slice>31:40</time_slice>
              <text_slice>and the c just is preserved.
How am I going to get rid of</text_slice>
            </slice>
            <slice>
              <time_slice>31:43</time_slice>
              <text_slice>this lower order term plus n?
Well, maybe I could subtract</text_slice>
            </slice>
            <slice>
              <time_slice>31:46</time_slice>
              <text_slice>off a linear term in here and,
if I am lucky,</text_slice>
            </slice>
            <slice>
              <time_slice>31:49</time_slice>
              <text_slice>it will cancel with this one.
That is all the intuition we</text_slice>
            </slice>
            <slice>
              <time_slice>31:52</time_slice>
              <text_slice>have at this point.
It turns out it works.</text_slice>
            </slice>
            <slice>
              <time_slice>31:56</time_slice>
              <text_slice>We look at T(n) and this is
4T(n/2) + n as usual.</text_slice>
            </slice>
            <slice>
              <time_slice>32:01</time_slice>
              <text_slice>Now we expand a slightly
messier form.</text_slice>
            </slice>
            <slice>
              <time_slice>32:05</time_slice>
              <text_slice>We have 4[c_1*(n/2)^2 -
c_2*(n/2)] + n.</text_slice>
            </slice>
            <slice>
              <time_slice>32:09</time_slice>
              <text_slice>This part is the same because
the fours cancel again.</text_slice>
            </slice>
            <slice>
              <time_slice>32:14</time_slice>
              <text_slice>So, we get c_1*n^2,
which is good.</text_slice>
            </slice>
            <slice>
              <time_slice>32:18</time_slice>
              <text_slice>I mean that is sort of the form
we want.</text_slice>
            </slice>
            <slice>
              <time_slice>32:22</time_slice>
              <text_slice>Then we have something times n,
so let's figure it out.</text_slice>
            </slice>
            <slice>
              <time_slice>32:30</time_slice>
              <text_slice>We have a plus 1 times n,
so let's write it 1 minus c_2</text_slice>
            </slice>
            <slice>
              <time_slice>32:34</time_slice>
              <text_slice>over 2 times n.
Oops, got that wrong.</text_slice>
            </slice>
            <slice>
              <time_slice>32:38</time_slice>
              <text_slice>There is four times a two so,
in fact, the two is upstairs.</text_slice>
            </slice>
            <slice>
              <time_slice>32:43</time_slice>
              <text_slice>Let me double check.
Right.</text_slice>
            </slice>
            <slice>
              <time_slice>32:46</time_slice>
              <text_slice>OK.
Now we can write this as</text_slice>
            </slice>
            <slice>
              <time_slice>32:48</time_slice>
              <text_slice>desired minus residual.
And we have to be a little</text_slice>
            </slice>
            <slice>
              <time_slice>32:53</time_slice>
              <text_slice>careful here because now we have
a stronger induction hypothesis</text_slice>
            </slice>
            <slice>
              <time_slice>32:58</time_slice>
              <text_slice>to prove.
We don't just need it is at</text_slice>
            </slice>
            <slice>
              <time_slice>33:03</time_slice>
              <text_slice>most c_1*n^2,
which would be fine here</text_slice>
            </slice>
            <slice>
              <time_slice>33:07</time_slice>
              <text_slice>because we could choose c_2 to
be large, but what we really</text_slice>
            </slice>
            <slice>
              <time_slice>33:12</time_slice>
              <text_slice>need is c_1*n^2 - c_2*n,
and then minus some other</text_slice>
            </slice>
            <slice>
              <time_slice>33:17</time_slice>
              <text_slice>stuff.
This is, again,</text_slice>
            </slice>
            <slice>
              <time_slice>33:19</time_slice>
              <text_slice>desired minus residual.
And minus residual,</text_slice>
            </slice>
            <slice>
              <time_slice>33:23</time_slice>
              <text_slice>let's see, we have a minus 1
and we have a minus c_2.</text_slice>
            </slice>
            <slice>
              <time_slice>33:30</time_slice>
              <text_slice>That doesn't look so happy.
Plus c_2, thank you,</text_slice>
            </slice>
            <slice>
              <time_slice>33:35</time_slice>
              <text_slice>because that again looked
awfully negative.</text_slice>
            </slice>
            <slice>
              <time_slice>33:40</time_slice>
              <text_slice>It is plus c_2.
I am getting my signs,</text_slice>
            </slice>
            <slice>
              <time_slice>33:44</time_slice>
              <text_slice>there is a minus here and there
is one minus here,</text_slice>
            </slice>
            <slice>
              <time_slice>33:50</time_slice>
              <text_slice>so there we go.
Again, I want my residual to be</text_slice>
            </slice>
            <slice>
              <time_slice>33:55</time_slice>
              <text_slice>greater than or equal to zero.
And if I have that I will be</text_slice>
            </slice>
            <slice>
              <time_slice>34:03</time_slice>
              <text_slice>all set in making this inductive
argument.</text_slice>
            </slice>
            <slice>
              <time_slice>34:07</time_slice>
              <text_slice>Office hours start this week,
in case you are eager to go.</text_slice>
            </slice>
            <slice>
              <time_slice>34:14</time_slice>
              <text_slice>They are all held in some room
in Building 24,</text_slice>
            </slice>
            <slice>
              <time_slice>34:19</time_slice>
              <text_slice>which is roughly the midpoint
between here and Stata,</text_slice>
            </slice>
            <slice>
              <time_slice>34:25</time_slice>
              <text_slice>I think, for no particular
reason.</text_slice>
            </slice>
            <slice>
              <time_slice>34:30</time_slice>
              <text_slice>And you can look at the Web
page for details on the office</text_slice>
            </slice>
            <slice>
              <time_slice>34:34</time_slice>
              <text_slice>hours.
Continuing along,</text_slice>
            </slice>
            <slice>
              <time_slice>34:35</time_slice>
              <text_slice>when is c_2 - 1 going to be
greater than or equal to zero?</text_slice>
            </slice>
            <slice>
              <time_slice>34:39</time_slice>
              <text_slice>Well, that is true if c_2 is at
least 1, which is no big deal.</text_slice>
            </slice>
            <slice>
              <time_slice>34:44</time_slice>
              <text_slice>Again, we get to choose the
constants however we want.</text_slice>
            </slice>
            <slice>
              <time_slice>34:47</time_slice>
              <text_slice>It only has to hold for some
choice of constants.</text_slice>
            </slice>
            <slice>
              <time_slice>34:51</time_slice>
              <text_slice>So, we can set c_2 greater than
or equal to 1.</text_slice>
            </slice>
            <slice>
              <time_slice>34:54</time_slice>
              <text_slice>And then we are happy.
That means this whole thing is</text_slice>
            </slice>
            <slice>
              <time_slice>34:59</time_slice>
              <text_slice>less than or equal to c_1*n^2 -
c_2*n if c_2 is greater than or</text_slice>
            </slice>
            <slice>
              <time_slice>35:03</time_slice>
              <text_slice>equal to 1.
It is kind of funny here.</text_slice>
            </slice>
            <slice>
              <time_slice>35:06</time_slice>
              <text_slice>This finishes the induction,
at least the induction step.</text_slice>
            </slice>
            <slice>
              <time_slice>35:10</time_slice>
              <text_slice>We proved now that for any
value of c_1,</text_slice>
            </slice>
            <slice>
              <time_slice>35:13</time_slice>
              <text_slice>and provided c_2 is at least
one.</text_slice>
            </slice>
            <slice>
              <time_slice>35:16</time_slice>
              <text_slice>We have to be a little more
careful that c_1 does actually</text_slice>
            </slice>
            <slice>
              <time_slice>35:20</time_slice>
              <text_slice>have to be sufficiently large.
Any particular reason why?</text_slice>
            </slice>
            <slice>
              <time_slice>35:32</time_slice>
              <text_slice>c_1 better not be negative,
indeed.</text_slice>
            </slice>
            <slice>
              <time_slice>35:34</time_slice>
              <text_slice>c_1 has to be positive for this
to work, but it even has to be</text_slice>
            </slice>
            <slice>
              <time_slice>35:39</time_slice>
              <text_slice>larger than positive depending.
Sorry.</text_slice>
            </slice>
            <slice>
              <time_slice>35:43</time_slice>
              <text_slice>I have been going so fast,
I haven't asked you questions.</text_slice>
            </slice>
            <slice>
              <time_slice>35:47</time_slice>
              <text_slice>Now you are caught off guard.
Yeah?</text_slice>
            </slice>
            <slice>
              <time_slice>35:50</time_slice>
              <text_slice>Because of the base case,
exactly.</text_slice>
            </slice>
            <slice>
              <time_slice>35:53</time_slice>
              <text_slice>So, the base case will have
T(1) is c_1 time 1 squared minus</text_slice>
            </slice>
            <slice>
              <time_slice>35:58</time_slice>
              <text_slice>c_2, we want to prove that it is
at most this,</text_slice>
            </slice>
            <slice>
              <time_slice>36:02</time_slice>
              <text_slice>and T(1) is some constant we
have assumed.</text_slice>
            </slice>
            <slice>
              <time_slice>36:07</time_slice>
              <text_slice>We need to choose c_1 to be
sufficiently larger than c_2,</text_slice>
            </slice>
            <slice>
              <time_slice>36:11</time_slice>
              <text_slice>in fact, so c_2 has to be at
least 1.</text_slice>
            </slice>
            <slice>
              <time_slice>36:14</time_slice>
              <text_slice>c_1 may have to be at least a
hundred more than one if this is</text_slice>
            </slice>
            <slice>
              <time_slice>36:22</time_slice>
              <text_slice>sufficiently large.
And sufficiently large now</text_slice>
            </slice>
            <slice>
              <time_slice>36:26</time_slice>
              <text_slice>means with respect to c_2.
You have to be a little bit</text_slice>
            </slice>
            <slice>
              <time_slice>36:31</time_slice>
              <text_slice>careful, but in this case it
doesn't matter.</text_slice>
            </slice>
            <slice>
              <time_slice>36:34</time_slice>
              <text_slice>Any questions about the
substitution method?</text_slice>
            </slice>
            <slice>
              <time_slice>36:37</time_slice>
              <text_slice>That was the same example three
times.</text_slice>
            </slice>
            <slice>
              <time_slice>36:40</time_slice>
              <text_slice>In the end, it turned out we
got the right answer.</text_slice>
            </slice>
            <slice>
              <time_slice>36:43</time_slice>
              <text_slice>But we sort of had to know the
answer in order to find it,</text_slice>
            </slice>
            <slice>
              <time_slice>36:47</time_slice>
              <text_slice>which is a bit of a pain.
It would certainly be nicer to</text_slice>
            </slice>
            <slice>
              <time_slice>36:51</time_slice>
              <text_slice>just figure out the answer by
some procedure,</text_slice>
            </slice>
            <slice>
              <time_slice>36:54</time_slice>
              <text_slice>and that will be the next two
techniques we talk about.</text_slice>
            </slice>
            <slice>
              <time_slice>36:58</time_slice>
              <text_slice>Sorry?
How would you prove a lower</text_slice>
            </slice>
            <slice>
              <time_slice>37:02</time_slice>
              <text_slice>bound?
I haven't tried it for this</text_slice>
            </slice>
            <slice>
              <time_slice>37:04</time_slice>
              <text_slice>recurrence, but you should be
able to do exactly the same</text_slice>
            </slice>
            <slice>
              <time_slice>37:09</time_slice>
              <text_slice>form.
Argue that T(n) is greater than</text_slice>
            </slice>
            <slice>
              <time_slice>37:12</time_slice>
              <text_slice>or equal to c_1*n^2 - c_2*n.
I didn't check whether that</text_slice>
            </slice>
            <slice>
              <time_slice>37:16</time_slice>
              <text_slice>particular form will work,
but I think it does.</text_slice>
            </slice>
            <slice>
              <time_slice>37:20</time_slice>
              <text_slice>Try it.
These other methods will give</text_slice>
            </slice>
            <slice>
              <time_slice>37:22</time_slice>
              <text_slice>you, in some sense,
upper and lower bounds if you</text_slice>
            </slice>
            <slice>
              <time_slice>37:26</time_slice>
              <text_slice>are a little bit careful.
But, to really check things,</text_slice>
            </slice>
            <slice>
              <time_slice>37:31</time_slice>
              <text_slice>you pretty much have to do the
substitution method.</text_slice>
            </slice>
            <slice>
              <time_slice>37:33</time_slice>
              <text_slice>And you will get some practice
with that.</text_slice>
            </slice>
            <slice>
              <time_slice>37:35</time_slice>
              <text_slice>Usually we only care about
upper bounds.</text_slice>
            </slice>
            <slice>
              <time_slice>37:37</time_slice>
              <text_slice>Proving upper bounds like this
is what we will focus on,</text_slice>
            </slice>
            <slice>
              <time_slice>37:39</time_slice>
              <text_slice>but occasionally we need lower
bounds.</text_slice>
            </slice>
            <slice>
              <time_slice>37:41</time_slice>
              <text_slice>It is always nice to know that
you have the right answer by</text_slice>
            </slice>
            <slice>
              <time_slice>37:43</time_slice>
              <text_slice>proving a matching lower bound.</text_slice>
            </slice>
            <slice>
              <time_slice>37:51</time_slice>
              <text_slice>The next method we will talk
about is the recursion-tree</text_slice>
            </slice>
            <slice>
              <time_slice>37:54</time_slice>
              <text_slice>method.
And it is a particular way of</text_slice>
            </slice>
            <slice>
              <time_slice>37:57</time_slice>
              <text_slice>adding up a recurrence,
and it is my favorite way.</text_slice>
            </slice>
            <slice>
              <time_slice>38:00</time_slice>
              <text_slice>It usually just works.
That's the great thing about</text_slice>
            </slice>
            <slice>
              <time_slice>38:04</time_slice>
              <text_slice>it.
It provides you intuition for</text_slice>
            </slice>
            <slice>
              <time_slice>38:06</time_slice>
              <text_slice>free.
It tells you what the answer is</text_slice>
            </slice>
            <slice>
              <time_slice>38:08</time_slice>
              <text_slice>pretty much.
It is slightly nonrigorous,</text_slice>
            </slice>
            <slice>
              <time_slice>38:11</time_slice>
              <text_slice>this is a bit of a pain,
so you have to be really</text_slice>
            </slice>
            <slice>
              <time_slice>38:14</time_slice>
              <text_slice>careful when you apply it.
Otherwise, you might get the</text_slice>
            </slice>
            <slice>
              <time_slice>38:18</time_slice>
              <text_slice>wrong answer.
Because it involves dot,</text_slice>
            </slice>
            <slice>
              <time_slice>38:20</time_slice>
              <text_slice>dot, dots, our favorite three
characters, but dot,</text_slice>
            </slice>
            <slice>
              <time_slice>38:24</time_slice>
              <text_slice>dot, dots are always a little
bit nonrigorous so be careful.</text_slice>
            </slice>
            <slice>
              <time_slice>38:30</time_slice>
              <text_slice>Technically,
what you should do is find out</text_slice>
            </slice>
            <slice>
              <time_slice>38:32</time_slice>
              <text_slice>what the answer is with
recursion-tree method.</text_slice>
            </slice>
            <slice>
              <time_slice>38:34</time_slice>
              <text_slice>Then prove that it is actually
right with the substitution</text_slice>
            </slice>
            <slice>
              <time_slice>38:37</time_slice>
              <text_slice>method.
Usually that is not necessary,</text_slice>
            </slice>
            <slice>
              <time_slice>38:39</time_slice>
              <text_slice>but you should at least have in
your mind that that is required</text_slice>
            </slice>
            <slice>
              <time_slice>38:42</time_slice>
              <text_slice>rigorously.
And probably the first few</text_slice>
            </slice>
            <slice>
              <time_slice>38:43</time_slice>
              <text_slice>recurrences you solve,
you should do it that way.</text_slice>
            </slice>
            <slice>
              <time_slice>38:46</time_slice>
              <text_slice>When you really understand the
recursion-tree method,</text_slice>
            </slice>
            <slice>
              <time_slice>38:48</time_slice>
              <text_slice>you can be a little bit more
sloppy if you are really sure</text_slice>
            </slice>
            <slice>
              <time_slice>38:51</time_slice>
              <text_slice>you have the right answer.
Let's do an example.</text_slice>
            </slice>
            <slice>
              <time_slice>38:55</time_slice>
              <text_slice>We saw recursion trees very
briefly last time with mergesort</text_slice>
            </slice>
            <slice>
              <time_slice>38:59</time_slice>
              <text_slice>as the intuition why it was n
log n.</text_slice>
            </slice>
            <slice>
              <time_slice>39:01</time_slice>
              <text_slice>And, if you took an example
like the one we just did with</text_slice>
            </slice>
            <slice>
              <time_slice>39:05</time_slice>
              <text_slice>the recursion-tree method,
it is dead simple.</text_slice>
            </slice>
            <slice>
              <time_slice>39:08</time_slice>
              <text_slice>Just to make our life harder,
let's do a more complicated</text_slice>
            </slice>
            <slice>
              <time_slice>39:12</time_slice>
              <text_slice>recursion.
Here we imagine we have some</text_slice>
            </slice>
            <slice>
              <time_slice>39:15</time_slice>
              <text_slice>algorithm.
It starts with a problem size</text_slice>
            </slice>
            <slice>
              <time_slice>39:17</time_slice>
              <text_slice>n, it recursively solves a
problem of size n/4,</text_slice>
            </slice>
            <slice>
              <time_slice>39:21</time_slice>
              <text_slice>it then recursively solves a
problem of size n/2,</text_slice>
            </slice>
            <slice>
              <time_slice>39:24</time_slice>
              <text_slice>and it does n^2 work on the
side without nonrecursive work.</text_slice>
            </slice>
            <slice>
              <time_slice>39:30</time_slice>
              <text_slice>What is that?
I mean that is a bit less</text_slice>
            </slice>
            <slice>
              <time_slice>39:33</time_slice>
              <text_slice>obvious, I would say.
What we are going to do is draw</text_slice>
            </slice>
            <slice>
              <time_slice>39:38</time_slice>
              <text_slice>a picture, and we are just going
to expand out that recursion in</text_slice>
            </slice>
            <slice>
              <time_slice>39:45</time_slice>
              <text_slice>tree form --</text_slice>
            </slice>
            <slice>
              <time_slice>39:56</time_slice>
              <text_slice>-- and then just add everything
up.</text_slice>
            </slice>
            <slice>
              <time_slice>40:00</time_slice>
              <text_slice>We want the general picture,
and the general principle in</text_slice>
            </slice>
            <slice>
              <time_slice>40:05</time_slice>
              <text_slice>the recursion-tree method is we
just draw this as a picture.</text_slice>
            </slice>
            <slice>
              <time_slice>40:12</time_slice>
              <text_slice>We say well,
T(n) equals the sum of n^2,</text_slice>
            </slice>
            <slice>
              <time_slice>40:16</time_slice>
              <text_slice>T(n/4) and T(n/2).
This is a weird way of writing</text_slice>
            </slice>
            <slice>
              <time_slice>40:21</time_slice>
              <text_slice>a sum but why not write it that
way.</text_slice>
            </slice>
            <slice>
              <time_slice>40:25</time_slice>
              <text_slice>This is going to be a tree.
And it is going to be a tree by</text_slice>
            </slice>
            <slice>
              <time_slice>40:31</time_slice>
              <text_slice>recursively expanding each of
these two leaves.</text_slice>
            </slice>
            <slice>
              <time_slice>40:35</time_slice>
              <text_slice>I start by expanding T(n) to
this, then I keep expanding,</text_slice>
            </slice>
            <slice>
              <time_slice>40:40</time_slice>
              <text_slice>expanding, expanding
everything.</text_slice>
            </slice>
            <slice>
              <time_slice>40:42</time_slice>
              <text_slice>Let's go one more step.
We have this n^2,</text_slice>
            </slice>
            <slice>
              <time_slice>40:46</time_slice>
              <text_slice>T(n/4), T(n/2).
If we expand one more time,</text_slice>
            </slice>
            <slice>
              <time_slice>40:49</time_slice>
              <text_slice>this is going to be n^2 plus
two things.</text_slice>
            </slice>
            <slice>
              <time_slice>40:53</time_slice>
              <text_slice>The first thing is going to be
(n/4)^2, the second thing is</text_slice>
            </slice>
            <slice>
              <time_slice>40:58</time_slice>
              <text_slice>going to be (n/2)^2.
Plus their recursive branches.</text_slice>
            </slice>
            <slice>
              <time_slice>41:03</time_slice>
              <text_slice>We have T(n/16) and T(n/8).
Here my arithmetic shows thin.</text_slice>
            </slice>
            <slice>
              <time_slice>41:08</time_slice>
              <text_slice>This better be the same,
T(n/8), and this should be</text_slice>
            </slice>
            <slice>
              <time_slice>41:12</time_slice>
              <text_slice>T(n/4), I believe.
You just keep going forever,</text_slice>
            </slice>
            <slice>
              <time_slice>41:15</time_slice>
              <text_slice>I mean, until you get down to
the base case where T is a</text_slice>
            </slice>
            <slice>
              <time_slice>41:20</time_slice>
              <text_slice>constant.
So, I am now going to skip some</text_slice>
            </slice>
            <slice>
              <time_slice>41:23</time_slice>
              <text_slice>steps and say dot,
dot, dot.</text_slice>
            </slice>
            <slice>
              <time_slice>41:25</time_slice>
              <text_slice>This is where you have to be
careful.</text_slice>
            </slice>
            <slice>
              <time_slice>41:30</time_slice>
              <text_slice>We have n^2,
(n/4)^2, (n/2)^2.</text_slice>
            </slice>
            <slice>
              <time_slice>41:33</time_slice>
              <text_slice>Now this is easy because I have
already done them all.</text_slice>
            </slice>
            <slice>
              <time_slice>41:39</time_slice>
              <text_slice>(n/16)^2, (n/8)^2,
(n/8)^2 again,</text_slice>
            </slice>
            <slice>
              <time_slice>41:43</time_slice>
              <text_slice>(n/4)^2 and et cetera,
dot, dot, dot,</text_slice>
            </slice>
            <slice>
              <time_slice>41:47</time_slice>
              <text_slice>of various levels of recursion
here.</text_slice>
            </slice>
            <slice>
              <time_slice>41:52</time_slice>
              <text_slice>At the bottom,
we are going to get a bunch of</text_slice>
            </slice>
            <slice>
              <time_slice>41:57</time_slice>
              <text_slice>constants.
These are the leaves.</text_slice>
            </slice>
            <slice>
              <time_slice>42:01</time_slice>
              <text_slice>I would like to know how many
leaves there are.</text_slice>
            </slice>
            <slice>
              <time_slice>42:04</time_slice>
              <text_slice>One challenge is how many
leaves in this tree could there</text_slice>
            </slice>
            <slice>
              <time_slice>42:07</time_slice>
              <text_slice>be?
This is a bit subtle,</text_slice>
            </slice>
            <slice>
              <time_slice>42:09</time_slice>
              <text_slice>unlike mergesort or unlike the
previous recurrence we solved,</text_slice>
            </slice>
            <slice>
              <time_slice>42:13</time_slice>
              <text_slice>the number of leaves here is a
bit funny because we are</text_slice>
            </slice>
            <slice>
              <time_slice>42:16</time_slice>
              <text_slice>recursing at different speeds.
This tree is going to be much</text_slice>
            </slice>
            <slice>
              <time_slice>42:20</time_slice>
              <text_slice>smaller than this tree.
It is going to have smaller</text_slice>
            </slice>
            <slice>
              <time_slice>42:23</time_slice>
              <text_slice>depth because it has already
done down to (n/16).</text_slice>
            </slice>
            <slice>
              <time_slice>42:26</time_slice>
              <text_slice>Here it has only gone down to
(n/4).</text_slice>
            </slice>
            <slice>
              <time_slice>42:30</time_slice>
              <text_slice>But how many leaves are there
in this recursion tree?</text_slice>
            </slice>
            <slice>
              <time_slice>42:35</time_slice>
              <text_slice>All I need is an upper bound,
some reasonable upper bound.</text_slice>
            </slice>
            <slice>
              <time_slice>42:41</time_slice>
              <text_slice>I can tell you it is at most
T(n^10), but that is a bit</text_slice>
            </slice>
            <slice>
              <time_slice>42:47</time_slice>
              <text_slice>unreasonable.
It should be less than n,</text_slice>
            </slice>
            <slice>
              <time_slice>42:51</time_slice>
              <text_slice>good.
Why is it less than n?</text_slice>
            </slice>
            <slice>
              <time_slice>42:54</time_slice>
              <text_slice>Exactly.
I start with a problem of size</text_slice>
            </slice>
            <slice>
              <time_slice>42:58</time_slice>
              <text_slice>n.
And I recurse into a problem</text_slice>
            </slice>
            <slice>
              <time_slice>43:02</time_slice>
              <text_slice>that n/4 and a problem that says
n/2.</text_slice>
            </slice>
            <slice>
              <time_slice>43:04</time_slice>
              <text_slice>When I get down to one I stop.
So, n/4 + n/2 = &#230;n,</text_slice>
            </slice>
            <slice>
              <time_slice>43:08</time_slice>
              <text_slice>which is strictly less than n.
So, definitely the total number</text_slice>
            </slice>
            <slice>
              <time_slice>43:13</time_slice>
              <text_slice>of leaves has to be at most n.
If I start out with n sort of</text_slice>
            </slice>
            <slice>
              <time_slice>43:17</time_slice>
              <text_slice>stuff and get rid of a quarter
of it and then recurse,</text_slice>
            </slice>
            <slice>
              <time_slice>43:21</time_slice>
              <text_slice>it is definitely going to be
less than n stuff at the bottom.</text_slice>
            </slice>
            <slice>
              <time_slice>43:26</time_slice>
              <text_slice>So, strictly less than n
leaves.</text_slice>
            </slice>
            <slice>
              <time_slice>43:30</time_slice>
              <text_slice>At this point,
I have done nothing</text_slice>
            </slice>
            <slice>
              <time_slice>43:32</time_slice>
              <text_slice>interesting.
And then the second cool idea</text_slice>
            </slice>
            <slice>
              <time_slice>43:34</time_slice>
              <text_slice>in recursion trees is you don't
just expand this tree and see</text_slice>
            </slice>
            <slice>
              <time_slice>43:38</time_slice>
              <text_slice>what it looks like and then say,
well, God, how the hell am I</text_slice>
            </slice>
            <slice>
              <time_slice>43:42</time_slice>
              <text_slice>going to sum that?
You sum it level by level.</text_slice>
            </slice>
            <slice>
              <time_slice>43:45</time_slice>
              <text_slice>That is the only other idea.
It usually works really,</text_slice>
            </slice>
            <slice>
              <time_slice>43:48</time_slice>
              <text_slice>really well.
Here it is a bit complicated</text_slice>
            </slice>
            <slice>
              <time_slice>43:50</time_slice>
              <text_slice>and I have to think a bit to
figure out n^2 is n^2.</text_slice>
            </slice>
            <slice>
              <time_slice>43:54</time_slice>
              <text_slice>That is the first level.
Easy.</text_slice>
            </slice>
            <slice>
              <time_slice>43:55</time_slice>
              <text_slice>The second level,
I have to think a lot harder.</text_slice>
            </slice>
            <slice>
              <time_slice>44:00</time_slice>
              <text_slice>There are three kinds of
mathematicians,</text_slice>
            </slice>
            <slice>
              <time_slice>44:03</time_slice>
              <text_slice>those who can add and those who
cannot, and I am the latter kind</text_slice>
            </slice>
            <slice>
              <time_slice>44:08</time_slice>
              <text_slice>so I need your help.
Can you add these things</text_slice>
            </slice>
            <slice>
              <time_slice>44:12</time_slice>
              <text_slice>together?
It's n^2 over something.</text_slice>
            </slice>
            <slice>
              <time_slice>44:15</time_slice>
              <text_slice>Please?
(5/16)n^2.</text_slice>
            </slice>
            <slice>
              <time_slice>44:16</time_slice>
              <text_slice>Now I really need your help.
I think that one I could have</text_slice>
            </slice>
            <slice>
              <time_slice>44:21</time_slice>
              <text_slice>done, but this one is a little
bit harder.</text_slice>
            </slice>
            <slice>
              <time_slice>44:24</time_slice>
              <text_slice>I will go look at my notes
while you compute that.</text_slice>
            </slice>
            <slice>
              <time_slice>44:35</time_slice>
              <text_slice>Any answers?
73/256.</text_slice>
            </slice>
            <slice>
              <time_slice>44:37</time_slice>
              <text_slice>Anyone else confirm that?
It seems a bit high to me.</text_slice>
            </slice>
            <slice>
              <time_slice>44:44</time_slice>
              <text_slice>73 does not sound right to me.
64?</text_slice>
            </slice>
            <slice>
              <time_slice>44:49</time_slice>
              <text_slice>Closer.
It is actually important that</text_slice>
            </slice>
            <slice>
              <time_slice>44:54</time_slice>
              <text_slice>we get this right.
The 256 is correct.</text_slice>
            </slice>
            <slice>
              <time_slice>44:59</time_slice>
              <text_slice>I can tell.
Everyone should know that 16^2</text_slice>
            </slice>
            <slice>
              <time_slice>45:04</time_slice>
              <text_slice>= 256.
We are computer scientists.</text_slice>
            </slice>
            <slice>
              <time_slice>45:06</time_slice>
              <text_slice>25, good.
We have two people saying 25,</text_slice>
            </slice>
            <slice>
              <time_slice>45:09</time_slice>
              <text_slice>therefore it is correct by
democracy.</text_slice>
            </slice>
            <slice>
              <time_slice>45:12</time_slice>
              <text_slice>[LAUGHTER] 25 is also what my
notes say, and I computed it at</text_slice>
            </slice>
            <slice>
              <time_slice>45:17</time_slice>
              <text_slice>home.
(25/256)n^2 is the right</text_slice>
            </slice>
            <slice>
              <time_slice>45:19</time_slice>
              <text_slice>answer.
Now, did anyone notice</text_slice>
            </slice>
            <slice>
              <time_slice>45:21</time_slice>
              <text_slice>something magical about this
progression?</text_slice>
            </slice>
            <slice>
              <time_slice>45:24</time_slice>
              <text_slice>It squares each time,
good.</text_slice>
            </slice>
            <slice>
              <time_slice>45:28</time_slice>
              <text_slice>And, if we were going to add
these up, you might call it?</text_slice>
            </slice>
            <slice>
              <time_slice>45:32</time_slice>
              <text_slice>A geometric series,
very good.</text_slice>
            </slice>
            <slice>
              <time_slice>45:34</time_slice>
              <text_slice>So, it turns out this is
geometric.</text_slice>
            </slice>
            <slice>
              <time_slice>45:37</time_slice>
              <text_slice>And we know how to sum
geometric series,</text_slice>
            </slice>
            <slice>
              <time_slice>45:40</time_slice>
              <text_slice>at least you should.</text_slice>
            </slice>
            <slice>
              <time_slice>45:59</time_slice>
              <text_slice>We started n^2.
We know that at the bottom,</text_slice>
            </slice>
            <slice>
              <time_slice>46:01</time_slice>
              <text_slice>well, this is not quite a
level, we get something like n,</text_slice>
            </slice>
            <slice>
              <time_slice>46:05</time_slice>
              <text_slice>but we are decreasing
geometrically.</text_slice>
            </slice>
            <slice>
              <time_slice>46:07</time_slice>
              <text_slice>So, the total,
I mean the solution to the</text_slice>
            </slice>
            <slice>
              <time_slice>46:10</time_slice>
              <text_slice>recurrence is the sum of all the
numbers in this tree.</text_slice>
            </slice>
            <slice>
              <time_slice>46:13</time_slice>
              <text_slice>If we added it up level by
level and then add up all the</text_slice>
            </slice>
            <slice>
              <time_slice>46:17</time_slice>
              <text_slice>levels that is going to give us
the answer.</text_slice>
            </slice>
            <slice>
              <time_slice>46:20</time_slice>
              <text_slice>This is the total computed
level by level.</text_slice>
            </slice>
            <slice>
              <time_slice>46:22</time_slice>
              <text_slice>It is just a cute way to
compute it.</text_slice>
            </slice>
            <slice>
              <time_slice>46:25</time_slice>
              <text_slice>It usually gives you nice
answers like geometric answers.</text_slice>
            </slice>
            <slice>
              <time_slice>46:30</time_slice>
              <text_slice>We have n^2(1 + 5/16 + 25/256 +
...).</text_slice>
            </slice>
            <slice>
              <time_slice>46:32</time_slice>
              <text_slice>And, if we believe in fate and
we see this three number</text_slice>
            </slice>
            <slice>
              <time_slice>46:37</time_slice>
              <text_slice>recurrence, we know that we have
the right answer.</text_slice>
            </slice>
            <slice>
              <time_slice>46:41</time_slice>
              <text_slice>In general, it is going to be
(5/16)k, at least we hope,</text_slice>
            </slice>
            <slice>
              <time_slice>46:45</time_slice>
              <text_slice>and so on.
And it keeps going.</text_slice>
            </slice>
            <slice>
              <time_slice>46:47</time_slice>
              <text_slice>It doesn't go on infinitely,
but let's just assume it goes</text_slice>
            </slice>
            <slice>
              <time_slice>46:52</time_slice>
              <text_slice>on infinitely.
That will be an upper bound</text_slice>
            </slice>
            <slice>
              <time_slice>46:55</time_slice>
              <text_slice>that goes on forever.
This is all times n^2.</text_slice>
            </slice>
            <slice>
              <time_slice>47:00</time_slice>
              <text_slice>Now, if you are going to know
one thing about geometric</text_slice>
            </slice>
            <slice>
              <time_slice>47:05</time_slice>
              <text_slice>series, you should know that 1 +
&#937; + &#186;, if you sum all the powers</text_slice>
            </slice>
            <slice>
              <time_slice>47:10</time_slice>
              <text_slice>of 2 you get 2.
We are computer scientists.</text_slice>
            </slice>
            <slice>
              <time_slice>47:14</time_slice>
              <text_slice>We have got to know at least
the binary case.</text_slice>
            </slice>
            <slice>
              <time_slice>47:19</time_slice>
              <text_slice>This is like writing 0.1111111
in binary, actually,</text_slice>
            </slice>
            <slice>
              <time_slice>0:01</time_slice>
              <text_slice>And 11111 forever is the same</text_slice>
            </slice>
            <slice>
              <time_slice>47:27</time_slice>
              <text_slice>as 1, so this is 2.
This is even smaller.</text_slice>
            </slice>
            <slice>
              <time_slice>47:31</time_slice>
              <text_slice>We have 5/16,
that is less than a half and</text_slice>
            </slice>
            <slice>
              <time_slice>47:34</time_slice>
              <text_slice>then we are squaring each time,
so this is even less than 2.</text_slice>
            </slice>
            <slice>
              <time_slice>47:39</time_slice>
              <text_slice>If you want,
there is a nifty formula for</text_slice>
            </slice>
            <slice>
              <time_slice>47:42</time_slice>
              <text_slice>solving the general geometric
series, but all we need is that</text_slice>
            </slice>
            <slice>
              <time_slice>47:47</time_slice>
              <text_slice>it is a constant.
This is O(n^2).</text_slice>
            </slice>
            <slice>
              <time_slice>47:49</time_slice>
              <text_slice>It is also O(n^2).
It is pretty obvious that it is</text_slice>
            </slice>
            <slice>
              <time_slice>47:53</time_slice>
              <text_slice>O(n^2) because the top thing is
n^2.</text_slice>
            </slice>
            <slice>
              <time_slice>47:56</time_slice>
              <text_slice>So, there is our lower bound of
n^2.</text_slice>
            </slice>
            <slice>
              <time_slice>48:00</time_slice>
              <text_slice>And we have it within a factor
of 2, which is pretty good.</text_slice>
            </slice>
            <slice>
              <time_slice>48:03</time_slice>
              <text_slice>You actually get a better
factor here.</text_slice>
            </slice>
            <slice>
              <time_slice>48:05</time_slice>
              <text_slice>So, that is recursion-tree
method.</text_slice>
            </slice>
            <slice>
              <time_slice>48:07</time_slice>
              <text_slice>It is a little shaky here
because we have these dot,</text_slice>
            </slice>
            <slice>
              <time_slice>48:10</time_slice>
              <text_slice>dot, dots, and we just believe
that it is geometric.</text_slice>
            </slice>
            <slice>
              <time_slice>48:13</time_slice>
              <text_slice>It turns out most of the time
it is geometric.</text_slice>
            </slice>
            <slice>
              <time_slice>48:16</time_slice>
              <text_slice>No problem here.
I would definitely check it</text_slice>
            </slice>
            <slice>
              <time_slice>48:18</time_slice>
              <text_slice>with the substitution method
because this is not obvious to</text_slice>
            </slice>
            <slice>
              <time_slice>48:21</time_slice>
              <text_slice>me that it is going to be
geometric.</text_slice>
            </slice>
            <slice>
              <time_slice>48:23</time_slice>
              <text_slice>In the cases we will look at in
a moment, it will be much</text_slice>
            </slice>
            <slice>
              <time_slice>48:27</time_slice>
              <text_slice>clearer, so clear that we can
state a theorem that everything</text_slice>
            </slice>
            <slice>
              <time_slice>48:30</time_slice>
              <text_slice>is working fine.
And still time,</text_slice>
            </slice>
            <slice>
              <time_slice>48:34</time_slice>
              <text_slice>good.
So, that was recursion-trees.</text_slice>
            </slice>
            <slice>
              <time_slice>48:38</time_slice>
              <text_slice>There is one more method we are
going to talk about,</text_slice>
            </slice>
            <slice>
              <time_slice>48:43</time_slice>
              <text_slice>and you could essentially think
of it as an application of the</text_slice>
            </slice>
            <slice>
              <time_slice>48:49</time_slice>
              <text_slice>recursion-tree method but it is
made more precise.</text_slice>
            </slice>
            <slice>
              <time_slice>48:55</time_slice>
              <text_slice>And it is an actual theorem,
whereas recursion trees,</text_slice>
            </slice>
            <slice>
              <time_slice>49:00</time_slice>
              <text_slice>if the dot, dot,
dots aren't obvious,</text_slice>
            </slice>
            <slice>
              <time_slice>49:04</time_slice>
              <text_slice>you better check them.
The sad part about the master</text_slice>
            </slice>
            <slice>
              <time_slice>49:10</time_slice>
              <text_slice>method is it is pretty
restrictive.</text_slice>
            </slice>
            <slice>
              <time_slice>49:13</time_slice>
              <text_slice>It only applies to a particular
family of recurrences.</text_slice>
            </slice>
            <slice>
              <time_slice>49:27</time_slice>
              <text_slice>It should be T(n) = aT(n/b) +
f(n).</text_slice>
            </slice>
            <slice>
              <time_slice>49:29</time_slice>
              <text_slice>Am I going to call it f?
Yes, I will call it f.</text_slice>
            </slice>
            <slice>
              <time_slice>49:32</time_slice>
              <text_slice>In particular,
it will not cover the</text_slice>
            </slice>
            <slice>
              <time_slice>49:35</time_slice>
              <text_slice>recurrence I just solved because
I was recursing on two different</text_slice>
            </slice>
            <slice>
              <time_slice>49:40</time_slice>
              <text_slice>problems of different sizes.
Here, every problem you recurse</text_slice>
            </slice>
            <slice>
              <time_slice>49:44</time_slice>
              <text_slice>on should be of the same size.
There are a subproblems.</text_slice>
            </slice>
            <slice>
              <time_slice>49:48</time_slice>
              <text_slice>A way to think of this is a
recursive algorithm.</text_slice>
            </slice>
            <slice>
              <time_slice>49:51</time_slice>
              <text_slice>You have a subproblems.
Each of them is of size n/b,</text_slice>
            </slice>
            <slice>
              <time_slice>49:55</time_slice>
              <text_slice>so the total costs will be
this.</text_slice>
            </slice>
            <slice>
              <time_slice>49:57</time_slice>
              <text_slice>Then you are doing f(n)
nonrecursive work.</text_slice>
            </slice>
            <slice>
              <time_slice>50:02</time_slice>
              <text_slice>A few constraints.
a should be at least 1,</text_slice>
            </slice>
            <slice>
              <time_slice>50:05</time_slice>
              <text_slice>should have at least 1
recursion.</text_slice>
            </slice>
            <slice>
              <time_slice>50:08</time_slice>
              <text_slice>b should be strictly greater
than 1.</text_slice>
            </slice>
            <slice>
              <time_slice>50:12</time_slice>
              <text_slice>You better make the problem
smaller or else it is going to</text_slice>
            </slice>
            <slice>
              <time_slice>50:17</time_slice>
              <text_slice>be infinity.
And f should have some nice</text_slice>
            </slice>
            <slice>
              <time_slice>50:21</time_slice>
              <text_slice>property.
f(n) should be asymptotically</text_slice>
            </slice>
            <slice>
              <time_slice>50:25</time_slice>
              <text_slice>positive.</text_slice>
            </slice>
            <slice>
              <time_slice>50:32</time_slice>
              <text_slice>How many people know what
asymptotically positive means?</text_slice>
            </slice>
            <slice>
              <time_slice>50:37</time_slice>
              <text_slice>No one.
OK, you haven't read the</text_slice>
            </slice>
            <slice>
              <time_slice>50:40</time_slice>
              <text_slice>textbook.
That's OK.</text_slice>
            </slice>
            <slice>
              <time_slice>50:41</time_slice>
              <text_slice>I haven't read it either,
although don't tell Charles.</text_slice>
            </slice>
            <slice>
              <time_slice>50:46</time_slice>
              <text_slice>And he'd notice.
And what might you think</text_slice>
            </slice>
            <slice>
              <time_slice>50:50</time_slice>
              <text_slice>asymptotically positive means?
That we can do a little bit</text_slice>
            </slice>
            <slice>
              <time_slice>50:55</time_slice>
              <text_slice>better.
Sorry?</text_slice>
            </slice>
            <slice>
              <time_slice>50:56</time_slice>
              <text_slice>Yes, it means for large enough
n, f(n) is positive.</text_slice>
            </slice>
            <slice>
              <time_slice>51:03</time_slice>
              <text_slice>This means f(n) is greater than
zero for n, at least some n_o,</text_slice>
            </slice>
            <slice>
              <time_slice>51:07</time_slice>
              <text_slice>so for some constant n_o.
Eventually it should be</text_slice>
            </slice>
            <slice>
              <time_slice>51:10</time_slice>
              <text_slice>positive.
I mean, we don't care about</text_slice>
            </slice>
            <slice>
              <time_slice>51:12</time_slice>
              <text_slice>whether it's negative 1 for n=1,
not a big deal.</text_slice>
            </slice>
            <slice>
              <time_slice>51:16</time_slice>
              <text_slice>It won't affect the answer
because we only care about the</text_slice>
            </slice>
            <slice>
              <time_slice>51:20</time_slice>
              <text_slice>asympotics within.</text_slice>
            </slice>
            <slice>
              <time_slice>51:28</time_slice>
              <text_slice>The master method,
you gave it a recurrence of</text_slice>
            </slice>
            <slice>
              <time_slice>51:30</time_slice>
              <text_slice>this form, it tells you the
answer.</text_slice>
            </slice>
            <slice>
              <time_slice>51:33</time_slice>
              <text_slice>That is the great thing about
the master method.</text_slice>
            </slice>
            <slice>
              <time_slice>51:36</time_slice>
              <text_slice>The annoying thing about the
master method is that it has</text_slice>
            </slice>
            <slice>
              <time_slice>51:39</time_slice>
              <text_slice>three cases.
It is a big long.</text_slice>
            </slice>
            <slice>
              <time_slice>51:41</time_slice>
              <text_slice>It takes a little bit longer to
memorize than all the others</text_slice>
            </slice>
            <slice>
              <time_slice>51:45</time_slice>
              <text_slice>because the others are just
ideas.</text_slice>
            </slice>
            <slice>
              <time_slice>51:47</time_slice>
              <text_slice>Here we need to actually
remember a few things.</text_slice>
            </slice>
            <slice>
              <time_slice>51:50</time_slice>
              <text_slice>Let me state the theorem.
Well, not quite yet.</text_slice>
            </slice>
            <slice>
              <time_slice>51:53</time_slice>
              <text_slice>There is one very simple idea,
which is we are going to</text_slice>
            </slice>
            <slice>
              <time_slice>51:57</time_slice>
              <text_slice>compare this nonrecursive work
f(n) with a very particular</text_slice>
            </slice>
            <slice>
              <time_slice>52:01</time_slice>
              <text_slice>function n^(log_b(a)).
Why n^(log_b(a))?</text_slice>
            </slice>
            <slice>
              <time_slice>52:05</time_slice>
              <text_slice>You will see later.
It turns out it is the number</text_slice>
            </slice>
            <slice>
              <time_slice>52:08</time_slice>
              <text_slice>of leaves in the recursion tree,
but that is foreshadowing.</text_slice>
            </slice>
            <slice>
              <time_slice>52:13</time_slice>
              <text_slice>So, it is either less,
equal or bigger.</text_slice>
            </slice>
            <slice>
              <time_slice>52:16</time_slice>
              <text_slice>And here we care about
asymptotics.</text_slice>
            </slice>
            <slice>
              <time_slice>52:18</time_slice>
              <text_slice>And we have to be a little bit
more precious about less,</text_slice>
            </slice>
            <slice>
              <time_slice>52:22</time_slice>
              <text_slice>equal or bigger.
You might think well,</text_slice>
            </slice>
            <slice>
              <time_slice>52:25</time_slice>
              <text_slice>it means little o,
big Theta, or little omega.</text_slice>
            </slice>
            <slice>
              <time_slice>52:30</time_slice>
              <text_slice>It would be nice if the theorem
held for all of those cases,</text_slice>
            </slice>
            <slice>
              <time_slice>52:34</time_slice>
              <text_slice>but it leaves some gaps.
Let's start with Case 1.</text_slice>
            </slice>
            <slice>
              <time_slice>52:38</time_slice>
              <text_slice>Case 1 is when f is smaller.
And not just that it is little</text_slice>
            </slice>
            <slice>
              <time_slice>52:42</time_slice>
              <text_slice>o, but it is actually quite a
bit smaller.</text_slice>
            </slice>
            <slice>
              <time_slice>52:46</time_slice>
              <text_slice>It has got to be polynomially
smaller than n^(log_b(a)).</text_slice>
            </slice>
            <slice>
              <time_slice>53:00</time_slice>
              <text_slice>For some positive epsilon,
the running time should be this</text_slice>
            </slice>
            <slice>
              <time_slice>53:04</time_slice>
              <text_slice>n to this constant log base b of
a minus that epsilon,</text_slice>
            </slice>
            <slice>
              <time_slice>53:09</time_slice>
              <text_slice>so it is really polynomially
smaller than n^(log_b(a)).</text_slice>
            </slice>
            <slice>
              <time_slice>53:13</time_slice>
              <text_slice>We cannot handle the little o
case, that's a little bit too</text_slice>
            </slice>
            <slice>
              <time_slice>53:18</time_slice>
              <text_slice>strong.
This is saying it is really</text_slice>
            </slice>
            <slice>
              <time_slice>53:21</time_slice>
              <text_slice>quite a bit smaller.
But the answer then is really</text_slice>
            </slice>
            <slice>
              <time_slice>53:25</time_slice>
              <text_slice>simple, T(n) =
Theta(n^(log_b(a))).</text_slice>
            </slice>
            <slice>
              <time_slice>53:28</time_slice>
              <text_slice>Great.
That is Case 1.</text_slice>
            </slice>
            <slice>
              <time_slice>53:31</time_slice>
              <text_slice>Case 2 is when f(n) is pretty
much equal to n^(log_b(a)).</text_slice>
            </slice>
            <slice>
              <time_slice>53:39</time_slice>
              <text_slice>And by pretty much equal I mean
up to poly log factors.</text_slice>
            </slice>
            <slice>
              <time_slice>53:46</time_slice>
              <text_slice>This is log base 2 of n to the
power k.</text_slice>
            </slice>
            <slice>
              <time_slice>53:51</time_slice>
              <text_slice>You should know this notation.
For example,</text_slice>
            </slice>
            <slice>
              <time_slice>53:56</time_slice>
              <text_slice>k could be zero.
And then they are equal up to</text_slice>
            </slice>
            <slice>
              <time_slice>54:02</time_slice>
              <text_slice>constant factors,
for some k greater than or</text_slice>
            </slice>
            <slice>
              <time_slice>54:06</time_slice>
              <text_slice>equal to zero.
Less than will not work,</text_slice>
            </slice>
            <slice>
              <time_slice>54:09</time_slice>
              <text_slice>so it is really important that
k is non-negative.</text_slice>
            </slice>
            <slice>
              <time_slice>54:13</time_slice>
              <text_slice>It should probably be an
integer.</text_slice>
            </slice>
            <slice>
              <time_slice>54:16</time_slice>
              <text_slice>It doesn't actually matter
whether there is an integer,</text_slice>
            </slice>
            <slice>
              <time_slice>54:20</time_slice>
              <text_slice>but there it is.
It could n^(log_b(a)) times log</text_slice>
            </slice>
            <slice>
              <time_slice>54:24</time_slice>
              <text_slice>n or just times nothing,
whatever.</text_slice>
            </slice>
            <slice>
              <time_slice>54:27</time_slice>
              <text_slice>Again, the solution is easy
here, T(n) = Theta(n^(log_b(a))*</text_slice>
            </slice>
            <slice>
              <time_slice>54:32</time_slice>
              <text_slice>lg^(k+1)(n)).
Presumably it has to be at</text_slice>
            </slice>
            <slice>
              <time_slice>54:38</time_slice>
              <text_slice>least times log k.
It turns out it is log to the k</text_slice>
            </slice>
            <slice>
              <time_slice>54:44</time_slice>
              <text_slice>plus 1 of n.
That is Case 2.</text_slice>
            </slice>
            <slice>
              <time_slice>54:47</time_slice>
              <text_slice>We have one more case which is
slightly more complicated.</text_slice>
            </slice>
            <slice>
              <time_slice>54:53</time_slice>
              <text_slice>We need to assume slightly more
for Case 3.</text_slice>
            </slice>
            <slice>
              <time_slice>55:00</time_slice>
              <text_slice>But Case 3 is roughly when f(n)
grows bigger than n^(log_b(a)).</text_slice>
            </slice>
            <slice>
              <time_slice>55:05</time_slice>
              <text_slice>So, it should be capital Omega,
here is one place where we get</text_slice>
            </slice>
            <slice>
              <time_slice>55:10</time_slice>
              <text_slice>to use omega,
(n^(log_b(a)) + epsilon) for</text_slice>
            </slice>
            <slice>
              <time_slice>55:14</time_slice>
              <text_slice>some positive epsilon.
It should grow not just bigger</text_slice>
            </slice>
            <slice>
              <time_slice>55:19</time_slice>
              <text_slice>but polynomially bigger.
Here it was growing just a log</text_slice>
            </slice>
            <slice>
              <time_slice>55:23</time_slice>
              <text_slice>factor bigger,
poly log, and here it is a</text_slice>
            </slice>
            <slice>
              <time_slice>55:27</time_slice>
              <text_slice>polynomial factor.
In this case,</text_slice>
            </slice>
            <slice>
              <time_slice>55:31</time_slice>
              <text_slice>we need another assumption
about f because we worry a</text_slice>
            </slice>
            <slice>
              <time_slice>55:36</time_slice>
              <text_slice>little bit about how quickly f
grows.</text_slice>
            </slice>
            <slice>
              <time_slice>55:40</time_slice>
              <text_slice>We want to make sure that as
you go down the recursion f gets</text_slice>
            </slice>
            <slice>
              <time_slice>55:46</time_slice>
              <text_slice>smaller.
It would be kind of nice if f</text_slice>
            </slice>
            <slice>
              <time_slice>55:49</time_slice>
              <text_slice>gets smaller as you go down,
otherwise you are,</text_slice>
            </slice>
            <slice>
              <time_slice>55:54</time_slice>
              <text_slice>again, trying to sum to
infinity or whatever.</text_slice>
            </slice>
            <slice>
              <time_slice>55:58</time_slice>
              <text_slice>I see why this is for some
epsilon prime greater than zero.</text_slice>
            </slice>
            <slice>
              <time_slice>56:06</time_slice>
              <text_slice>What I would like is that if I
just sort of take the</text_slice>
            </slice>
            <slice>
              <time_slice>56:09</time_slice>
              <text_slice>recurrence, this T(n) and just
throw in fs instead,</text_slice>
            </slice>
            <slice>
              <time_slice>56:13</time_slice>
              <text_slice>f(n) should be somehow related
to af(n/b).</text_slice>
            </slice>
            <slice>
              <time_slice>56:16</time_slice>
              <text_slice>What I would like is that f(n),
which is at the top of the</text_slice>
            </slice>
            <slice>
              <time_slice>56:20</time_slice>
              <text_slice>recursion tree,
should be bigger than the thing</text_slice>
            </slice>
            <slice>
              <time_slice>56:23</time_slice>
              <text_slice>at the next level down.
The sum of all the values at</text_slice>
            </slice>
            <slice>
              <time_slice>56:27</time_slice>
              <text_slice>the next level down should be
bigger by some constant factor.</text_slice>
            </slice>
            <slice>
              <time_slice>56:33</time_slice>
              <text_slice>Here I have the next level down
is at most some 1 - e,</text_slice>
            </slice>
            <slice>
              <time_slice>56:37</time_slice>
              <text_slice>something strictly less than 1,
some constant strictly less</text_slice>
            </slice>
            <slice>
              <time_slice>56:42</time_slice>
              <text_slice>than 1 times the thing at the
top level.</text_slice>
            </slice>
            <slice>
              <time_slice>56:45</time_slice>
              <text_slice>I need that to make sure things
are getting smaller as I go</text_slice>
            </slice>
            <slice>
              <time_slice>56:49</time_slice>
              <text_slice>down.
Then T(n) = Theta[f(n)].</text_slice>
            </slice>
            <slice>
              <time_slice>56:52</time_slice>
              <text_slice>And that is the theorem.
This is the master theorem or</text_slice>
            </slice>
            <slice>
              <time_slice>56:56</time_slice>
              <text_slice>whatever you want to call it.
It is not named after some guy</text_slice>
            </slice>
            <slice>
              <time_slice>57:02</time_slice>
              <text_slice>name Master.
It is just the master of all</text_slice>
            </slice>
            <slice>
              <time_slice>57:05</time_slice>
              <text_slice>methods because it is very easy
to apply.</text_slice>
            </slice>
            <slice>
              <time_slice>57:09</time_slice>
              <text_slice>Let's apply it a few times.
It is a bit much to take in all</text_slice>
            </slice>
            <slice>
              <time_slice>57:14</time_slice>
              <text_slice>at once.
And then I will give you a</text_slice>
            </slice>
            <slice>
              <time_slice>57:16</time_slice>
              <text_slice>sketch of the proof to see that
it is really not that surprising</text_slice>
            </slice>
            <slice>
              <time_slice>57:22</time_slice>
              <text_slice>this is true if you look at the
recursion-tree.</text_slice>
            </slice>
            <slice>
              <time_slice>57:26</time_slice>
              <text_slice>But first let's just try using
it.</text_slice>
            </slice>
            <slice>
              <time_slice>57:30</time_slice>
              <text_slice>For example,
we could take T(n) = 4T(n/2) +</text_slice>
            </slice>
            <slice>
              <time_slice>57:35</time_slice>
              <text_slice>n.
This is a, this is b,</text_slice>
            </slice>
            <slice>
              <time_slice>57:38</time_slice>
              <text_slice>this is f(n).
The first thing we should</text_slice>
            </slice>
            <slice>
              <time_slice>57:44</time_slice>
              <text_slice>compute is n^(log_b(a)).
This I think even I can do.</text_slice>
            </slice>
            <slice>
              <time_slice>57:51</time_slice>
              <text_slice>Log base 2 of 4.
Yeah, log base 2 I can do.</text_slice>
            </slice>
            <slice>
              <time_slice>57:56</time_slice>
              <text_slice>This is n^2.
OK, so is f(n) smaller or</text_slice>
            </slice>
            <slice>
              <time_slice>58:04</time_slice>
              <text_slice>bigger than n^2?
Well, f(n) = n.</text_slice>
            </slice>
            <slice>
              <time_slice>58:10</time_slice>
              <text_slice>n^2 is clearly bigger by a
polynomial factor.</text_slice>
            </slice>
            <slice>
              <time_slice>58:19</time_slice>
              <text_slice>So, we are in Case 1.
What is the answer?</text_slice>
            </slice>
            <slice>
              <time_slice>58:26</time_slice>
              <text_slice>n^2, yeah.
It is T(n^(log_b(a))),</text_slice>
            </slice>
            <slice>
              <time_slice>58:32</time_slice>
              <text_slice>which here it is just n^2.
Let's do some slight variation.</text_slice>
            </slice>
            <slice>
              <time_slice>58:40</time_slice>
              <text_slice>I am going to keep a and b the
same and just change f.</text_slice>
            </slice>
            <slice>
              <time_slice>58:46</time_slice>
              <text_slice>Let's say T(n) = 4T(n/2) + n^2.
This is like drill spelling.</text_slice>
            </slice>
            <slice>
              <time_slice>58:54</time_slice>
              <text_slice>n^2 is asymptotically the same
as n^2 even up to constants.</text_slice>
            </slice>
            <slice>
              <time_slice>59:03</time_slice>
              <text_slice>What is the answer?
This is Case 2.</text_slice>
            </slice>
            <slice>
              <time_slice>59:12</time_slice>
              <text_slice>It is slightly harder.</text_slice>
            </slice>
            <slice>
              <time_slice>59:22</time_slice>
              <text_slice>What is k in this example? Zero.
The answer is?</text_slice>
            </slice>
            <slice>
              <time_slice>59:31</time_slice>
              <text_slice>Survey says?
n^2 log n.</text_slice>
            </slice>
            <slice>
              <time_slice>59:44</time_slice>
              <text_slice>Good.
And a couple more.</text_slice>
            </slice>
            <slice>
              <time_slice>59:49</time_slice>
              <text_slice>T(n) = 4T(n/2) + n^3.
What is the answer?</text_slice>
            </slice>
            <slice>
              <time_slice>59:58</time_slice>
              <text_slice>n^3.
This is Case 3.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:01</time_slice>
              <text_slice>I know this is pretty boring.
At this point we are just</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:08</time_slice>
              <text_slice>applying this stupid theorem.
How about n^2/lg n?</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:15</time_slice>
              <text_slice>What is the answer?
Good.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:18</time_slice>
              <text_slice>In this case no one should
answer.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:22</time_slice>
              <text_slice>It is a big tricky.
I forget exactly the answer.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:30</time_slice>
              <text_slice>I think it is like n^2 log log
n over log n,</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:31</time_slice>
              <text_slice>no?
Oh, no.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:31</time_slice>
              <text_slice>n^2 log log n,
that's right.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:32</time_slice>
              <text_slice>Yeah.
But you shouldn't know that,</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:34</time_slice>
              <text_slice>and this doesn't follow from
the master method.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:35</time_slice>
              <text_slice>This is something you would
have to solve,</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:37</time_slice>
              <text_slice>probably with the
recursion-tree would be a good</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:38</time_slice>
              <text_slice>way to do this one,
and you need to know some</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:40</time_slice>
              <text_slice>properties of logs to know how
that goes.</text_slice>
            </slice>
            <slice>
              <time_slice>1:00:41</time_slice>
              <text_slice>But here the master method does
not apply.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:05</time_slice>
              <text_slice>And so you have to use a
different method.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:08</time_slice>
              <text_slice>OK.
The last thing I want to do is</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:10</time_slice>
              <text_slice>tell you why the master method
is true, and that makes it much</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:15</time_slice>
              <text_slice>more intuitive,
especially using</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:17</time_slice>
              <text_slice>recursion-trees,
why everything works.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:35</time_slice>
              <text_slice>This is a sketch of a proof,
not the full thing.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:38</time_slice>
              <text_slice>You should read the proof in
the textbook.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:42</time_slice>
              <text_slice>It is not that much harder than
what I will show,</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:45</time_slice>
              <text_slice>but it is good for you to know
the formal details.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:49</time_slice>
              <text_slice>I don't have time here to do
all of the details.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:53</time_slice>
              <text_slice>I will just tell you the
salient parts.</text_slice>
            </slice>
            <slice>
              <time_slice>1:01:56</time_slice>
              <text_slice>This is the proof sketch or the
intuition behind the master</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:01</time_slice>
              <text_slice>method.
What we are going to do is just</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:06</time_slice>
              <text_slice>take the recursion-tree for this
recurrence and add up each level</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:12</time_slice>
              <text_slice>and then add up all the levels
and see what we get.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:17</time_slice>
              <text_slice>We start with f(n) at the top
after we have expanded one</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:23</time_slice>
              <text_slice>level.
Then we get a different</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:25</time_slice>
              <text_slice>problems, each of n/b.
And after we expand them it</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:31</time_slice>
              <text_slice>will f(n/b) for each one.
They are all the same size.</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:36</time_slice>
              <text_slice>Then we expand all of those and
so on, and we get another a</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:41</time_slice>
              <text_slice>subproblems from there.
We are going to get like</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:46</time_slice>
              <text_slice>f((n/b)^2).
That is sort of decreasing</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:49</time_slice>
              <text_slice>geometrically the size,
and so on and so on and so on,</text_slice>
            </slice>
            <slice>
              <time_slice>1:02:54</time_slice>
              <text_slice>until at the bottom we get
constant size problems.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:00</time_slice>
              <text_slice>This is a bit special because
this is the base case,</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:03</time_slice>
              <text_slice>but we have some other constant
at the bottom.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:07</time_slice>
              <text_slice>We would like to know how many
leaves there are,</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:10</time_slice>
              <text_slice>but that is a little bit tricky
at the moment.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:14</time_slice>
              <text_slice>Let's first compute the height
of this tree.</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:17</time_slice>
              <text_slice>Let me draw it over here.
What is the height of this</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:21</time_slice>
              <text_slice>tree?
I start with a problem of size</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:24</time_slice>
              <text_slice>n.
I want to get down to a problem</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:26</time_slice>
              <text_slice>of size 1.
How long does that take?</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:29</time_slice>
              <text_slice>How many levels?</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:38</time_slice>
              <text_slice>This is probably too easy for
some and not at your fingertips</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:44</time_slice>
              <text_slice>for others.
Log base b of n,</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:47</time_slice>
              <text_slice>good.
The height of this tree is</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:50</time_slice>
              <text_slice>n^(log_b(a)),
because it is just how many</text_slice>
            </slice>
            <slice>
              <time_slice>1:03:54</time_slice>
              <text_slice>times I divide by b until I get
down to 1.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:00</time_slice>
              <text_slice>That is great.
Now I should be able to compute</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:04</time_slice>
              <text_slice>the number of leaves because I
have branching factor a,</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:09</time_slice>
              <text_slice>I have height h.
The number of leaves is a^h,</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:13</time_slice>
              <text_slice>a^log_b(n).
Let me expand that a little</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:16</time_slice>
              <text_slice>bit.
a^log_b(n), properties of logs,</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:20</time_slice>
              <text_slice>we can take the n downstairs
and put the a upstairs,</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:24</time_slice>
              <text_slice>and we get n^(log_b(a)).
Our good friend n^(log_b(a)).</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:31</time_slice>
              <text_slice>So, that is why Our good friend
n^(log_b(a)) is so important in</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:35</time_slice>
              <text_slice>the master method.
What we are doing is comparing</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:38</time_slice>
              <text_slice>f, which is the top level,
to n^(log_b(a)),</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:41</time_slice>
              <text_slice>which up to theta is the bottom
level.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:43</time_slice>
              <text_slice>Now the leaves are all at the
same level because we are</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:47</time_slice>
              <text_slice>decreasing at the same rate in
every branch.</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:50</time_slice>
              <text_slice>If I add up the cost at the
bottom level,</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:53</time_slice>
              <text_slice>it is Theta(n^(log_b(a))).
I add up the things at the top</text_slice>
            </slice>
            <slice>
              <time_slice>1:04:57</time_slice>
              <text_slice>level it is f(n),
not terribly exciting.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:01</time_slice>
              <text_slice>But the next level,
this is a little bit more</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:04</time_slice>
              <text_slice>interesting, is af(n/b),
which should look familiar if</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:08</time_slice>
              <text_slice>you had the master method
already memorized,</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:12</time_slice>
              <text_slice>it is that.
So, we know that af(n/b) has</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:15</time_slice>
              <text_slice>decreased by some constant
factor, 1-epsilon prime.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:19</time_slice>
              <text_slice>We have gone down.
This is a constant factor</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:22</time_slice>
              <text_slice>smaller than this.
And then you sum up the next</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:26</time_slice>
              <text_slice>level.
It is going to be like</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:28</time_slice>
              <text_slice>a^2f(n/b^2).
I see that I actually wrote</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:33</time_slice>
              <text_slice>this wrong, the parentheses.
Sorry about that.</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:37</time_slice>
              <text_slice>It is not (n/b)^2.
It is (n/b^2).</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:40</time_slice>
              <text_slice>So, this sequence,
in Case 3 at least,</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:44</time_slice>
              <text_slice>is decreasing geometrically.
If it is decreasing</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:48</time_slice>
              <text_slice>geometrically up to constant
factors, it is dominated by the</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:54</time_slice>
              <text_slice>biggest term,
which is f(n).</text_slice>
            </slice>
            <slice>
              <time_slice>1:05:56</time_slice>
              <text_slice>Therefore, in Case 3,
we get Theta[f(n)].</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:02</time_slice>
              <text_slice>Let's look at the other cases,
and let me adapt those cases to</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:07</time_slice>
              <text_slice>how much time we have left.
Wow, lot's of time.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:11</time_slice>
              <text_slice>Five minutes.
Tons of time.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:14</time_slice>
              <text_slice>What to do?
Let me write that down.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:17</time_slice>
              <text_slice>Case 3, the costs decrease.
Now, this is a place I would</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:22</time_slice>
              <text_slice>argue where the dot,
dot, dot is pretty obvious.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:26</time_slice>
              <text_slice>Here, this is damn simple,
it is a^kf(n/b^k).</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:32</time_slice>
              <text_slice>And, in Case 3,
we assume that the costs</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:37</time_slice>
              <text_slice>decrease geometrically as we go
down the tree.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:43</time_slice>
              <text_slice>That was sort of backwards to
start with Case 3.</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:49</time_slice>
              <text_slice>Let's do Case 1,
which is sort of the other</text_slice>
            </slice>
            <slice>
              <time_slice>1:06:55</time_slice>
              <text_slice>intuitively easy case.
In Case 1, we know that f(n) is</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:01</time_slice>
              <text_slice>polynomially smaller than this
thing.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:03</time_slice>
              <text_slice>And we are sort of changing by
this very simple procedure in</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:07</time_slice>
              <text_slice>the middle.
I am going to wave my hands if</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:10</time_slice>
              <text_slice>this is where you need a more
formal argument.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:13</time_slice>
              <text_slice>I claim that this will increase
geometrically.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:16</time_slice>
              <text_slice>It has to increase
geometrically because this f(n)</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:19</time_slice>
              <text_slice>is polynomially smaller than
this one, you are going to get</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:23</time_slice>
              <text_slice>various polynomials in the
middle which interpret</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:26</time_slice>
              <text_slice>geometrically from the small one
to the big one.</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:31</time_slice>
              <text_slice>Therefore, the big one
dominates because it is,</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:34</time_slice>
              <text_slice>again, geometric series.
As I said, this is intuition,</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:38</time_slice>
              <text_slice>not a formal argument.
This one was pretty formal</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:42</time_slice>
              <text_slice>because we assumed it,
but here you need a bit more</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:45</time_slice>
              <text_slice>argument.
They may not increase</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:47</time_slice>
              <text_slice>geometrically but they could
increase faster,</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:51</time_slice>
              <text_slice>and that is also fine.
So, in Case 3,</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:53</time_slice>
              <text_slice>you are dominated,
I mean you are always dominated</text_slice>
            </slice>
            <slice>
              <time_slice>1:07:57</time_slice>
              <text_slice>by the biggest term in a
geometric series.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:02</time_slice>
              <text_slice>Here it happens to be f(n) and
here you are dominated by</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:08</time_slice>
              <text_slice>n^(log_b(a)) with a bottom term,
oh, Theta.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:13</time_slice>
              <text_slice>Case 2, here it is pretty easy
but you need to know some</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:19</time_slice>
              <text_slice>properties of logs.
In Case 2, we assume that all</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:25</time_slice>
              <text_slice>of these are basically the same.
I mean, we assume that the top</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:31</time_slice>
              <text_slice>is equal to the bottom.
And this is changing in this</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:35</time_slice>
              <text_slice>very procedural way.
Therefore, all of the ones in</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:38</time_slice>
              <text_slice>the middle have to be pretty
much the same.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:40</time_slice>
              <text_slice>Not quite because here we don't
have the log factor.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:44</time_slice>
              <text_slice>Here we have a log to the k.
We have n^(log_b(a)) times log</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:47</time_slice>
              <text_slice>to the kn.
Here we don't have the log to</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:50</time_slice>
              <text_slice>the k.
So, the logs do disappear here.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:52</time_slice>
              <text_slice>It turns out the way they
disappear is pretty slowly.</text_slice>
            </slice>
            <slice>
              <time_slice>1:08:57</time_slice>
              <text_slice>If you look at the top half of
these terms, they will all have</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:02</time_slice>
              <text_slice>log to the k.
The bottom half they will start</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:06</time_slice>
              <text_slice>to disappear.
I am giving you some oracle</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:09</time_slice>
              <text_slice>information.
If you take logs and you don't</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:13</time_slice>
              <text_slice>change the argument by too much,
the logs remain.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:17</time_slice>
              <text_slice>Maybe halfway is too far.
The claim is that each level is</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:22</time_slice>
              <text_slice>roughly the same,
especially the upper most</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:25</time_slice>
              <text_slice>levels are all asymptotically
equal.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:30</time_slice>
              <text_slice>Roughly the same.
And, therefore,</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:34</time_slice>
              <text_slice>the cost is one level,
here like f(n) times the number</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:42</time_slice>
              <text_slice>of levels, h.
And h is log base b of n.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:47</time_slice>
              <text_slice>B is a constant so we don't
care.</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:52</time_slice>
              <text_slice>This is Theta(lg n).
And, therefore,</text_slice>
            </slice>
            <slice>
              <time_slice>1:09:57</time_slice>
              <text_slice>we get T(n) = (n^(log_b(a))
lg^(k+1)(n)) times another log</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:05</time_slice>
              <text_slice>n.
So, we get [f(n)lg n].</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:11</time_slice>
              <text_slice>That is the very quick sketch.
Sorry, I am being pretty fuzzy</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:20</time_slice>
              <text_slice>on Cases 1 and 2.
Read the proof because you will</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:27</time_slice>
              <text_slice>have to, at some point,
manipulate logs in that way.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:34</time_slice>
              <text_slice>And that is all.
Any questions?</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:38</time_slice>
              <text_slice>Or, you are all eager to go.
OK.</text_slice>
            </slice>
            <slice>
              <time_slice>1:10:43</time_slice>
              <text_slice>Thanks.
See you Wednesday.</text_slice>
            </slice>
          </transcript>
        </video>
      </videos>
    </lecture>
  </lectures>
</doc>
