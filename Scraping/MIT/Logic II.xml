<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/</course_url>
    <course_title>Logic II</course_title>
    <course_tags>
      <list>Engineering </list>
      <list>Computer Science </list>
      <list>Humanities </list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>Nonstandard Models of Arithmetic (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/nonstandrd_modls/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Nonstandard Models of True Arithmetic 
We have talked a lot about the standard model of the language of arithmetic, but there are 
other models of true arithmetic (the set of sentences true in the standard model) that aren't 
isomorphic to the standard model. Indeed, consider the theory r' consisting of true arithmetic, 
together with all sentences "[n] &lt; c," where "c" is a new constant. If A is a finite subset of I?, 
then we can model of A by expanding the standard model by letting "c" denote a number larger 
than any of the numbers n with "[n] &lt; c" E A. It follows by the compactness theorem that there 
is a model of r'. A model of r will be a nonstandard model of true arithmetic, that is, a model of 
true arithmetic that isn't isomorphic1 to the standard model. 
An initial segment of a nonstandard model U of true arithmetic is defined just as it is for 
the standard model: S r IUI is an initial segment iff, for any y E S, any element of IUI that is &lt;' y 
is an element of S. The map taking n to [n]' is an isomorphism from the standard models onto an 
initial segment of 9. The elements of 191 that aren't in the range of this isomorphism are the 
nonstandard elements. To see that the range of the isomorphism is an initial segment, note first 
that U can't hide any nonstandard elements below o', because "(Vx)- x &lt; 0" is part of true 
arithmetic. It can't sneak any nonstandard elements below [n+l]', because ('dx)(x &lt; [n+l] - (x = 
1 Where U and 23 are models of the language of arithmetic, an isomorphism from U to 23 is 
a bijection f from IUI to 1231 with the property that f(0') =0', f(x +' y) = f(x) +' f(y), x 2' 
y iff f(x) &lt;' f(y), and so on. If o is a variable assignment for U, then o satisfies the same 
formulas in U that foo satisfies in 23. (Here foo is the variable assignment for 23 given by 
foo(v) = f(o(v)).) It follows that the same sentences are true in U and in 23.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Nonstandard Models, p. 5 
practices. Some ideas that we used to refer to as "mathematical" notions have now been 
rechristened "logical" notions, so that what used to be a problem about the foundations of 
mathematics is now a problem about the foundations of logic. We've relabeled a problem, but 
we haven't solved anything, since the old difficulty about fixing the meanings of mathematical 
terms has reemerged as a problem about fixing the meaning of the new logical terms we 
introduce when we move beyond the first-order predicate calculus. Or so one suspects. The issue 
remains highly controversial, and we've no hope of resolving it here.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Nonstandard Models, p. 4 
the structure of the natural numbers as a whole. It is only a slight exaggeration to say that the 
meaning of our mathematical terms is given by ow mathematical theories. 
Now we have a problem. As we shall see in detail later on, our arithmetical theory - the 
set of arithmetical sentences we can recognize as true - stops far short of true arithmetic. But 
even if we were able to help ourselves to true arithmetic, that isn't enough to pin down the 
meanings of the arithmetical terms. Even if our arithmetical theory were true arithmetic, that 
wouldn't be enough to pin down the structure of the natural numbers, because the theory has 
nonstandard models. 
An easy response would be to say that our arithmetical theory isn't isolated. Our beliefs 
about natural numbers are embedded in a larger system of beliefs that include our beliefs about 
real numbers and our beliefs about sets. We should be looking at the role of arithmetical terms 
within that larger theoretical system. 
This is an easy response, but not a useful one, since we can apply the same argument to a 
larger language that includes the language of set theory and the language of real analysis. The 
compactness theorem still applies, so the set of true sentences of the larger language will still 
have models with nonstandard natural numbers. We are still left with a deeply disturbing cause 
for skepticism about arithmetic. 
A different response is that we shouldn't be formalizing our mathematical theory within 
the predicate calculus, but within some more robust logic to which the compactness theorem 
does not apply. (The alternative that is usually proposed is the second-order predicate calculus, 
which we'll describe briefly presently.) This response is potentially more helpful, but it's not as 
easy. It arouses the suspicion that we have "solved" our problem by Enron-style accounting</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Nonstandard Models, p. 3 
copies is isomorphic to the order on the rational numbers. This description characterizes the 
order relation on countable, nonstandard models of true arithmetic, uniquely up to isomorphism. 
(For uncountable models, the picture is similar, but harder to make precise, since uncountable 
nonstandard models aren't mutually isomorphic.) I won't go through the proof here, but you 
could look it up in Chapter 17 of Boolos and Jeffre~.~ 
Nonstandard models are troubling, epistemologically. The name "Fido" refers to 
something we've scratched behind the ears, and the causal connection between our usage of the 
word "Fido" and the dog Fido is part of the explanation of how it came to pass that the word 
refers as it does. For theoretical terms and other terms that don't refer to things to which we are 
causally connected, there isn't a direct causal explanation, but there may be an indirect causal 
explanation. We have a, probably informal, theory that tells how the theoretical entities are 
related to the entities to which we are directly causally connected, and the theoretical terms refer 
to whatever entities come the closest to playing the role the theory ascribes to them. ("Comes the 
closest to playing the role" rather than "plays the role," since it would be silly to pretend that our 
theories are completely accurate.) The closer the theoretical entity is to the objects of experience, 
the more prominent the role that causal connections will play in pinning down reference. When 
we get to things that are very far removed from the objects of experience, like numbers, the 
causal connections have nearly dropped out of the picture. To be sure, we use numbers to count 
everyday objects, but for counting purposes, we use only numbers at the very beginning of the 
natural number system, so the way we use those numbers doesn't go far at all in telling us about 
3 George Boolos and Richard Jeffrey, Computability and Logic, 3rd ed. (New York and 
Cambridge: Cambridge University Press, 1989).</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Nonstandard Models, p. 2 
[0] V x = [I] V ... V x = [n]))" is in true arithmetic. Because we have "(Vx)(Vy)(x &lt; y V x = y V 
y &lt; x)," all the nonstandard elements are greater than all the standard elements. 
Let a be a nonstandard element. Because true arithmetic assures us that every number has 
an immediate successor and that every number other than 0 has an immediate predecessor, the 
immediate neighborhood of a looks just like the (positive and negative) integers. [2]' *' a is 
bigger than all the a +' [nl's, and the immediate neighborhood of [2]' 0' a looks just like the 
integers. Similarly, [3]' *' a is bigger than all the ([2]' *' a) +' [nl's, and the immediate 
neighborhood of [3]' *' a looks just like the integers. a *' a is bigger than all the [n]' *' as, and 
the immediate neighborhood of a *' a looks just like the integers. 
a satisfies either "x is even" or "x is odd."2 If the former, then there is a nonstandard 
element that when doubled yields a. If the latter, there is a nonstandard element that, when 
doubled yields a +' [I]'. Either way, we get a nonstandard number that is approximately one- 
half of a. The immediate neighborhood of that nonstandard model looks just like the integers. 
Similarly, there is a nonstandard number that is approximately one-third of a, one that is 
approximately two-thirds of a, and so on. For any positive integers p and q, there is a 
nonstandard number b such that [q]' 0' b and [p]' *' a differ by a standard number. In other 
words, there is a nonstandard number that is approximately equal to times a. 
Just looking at the order, we can say precisely what the countable nonstandard models 
look like. There is an initial segment that looks like the natural numbers, followed by a bunch of 
copies of the integers. The copies of the integers are ordered; we can say that one copy is less 
than another iff the members of the first are -?" the members of the second. The order on the 
2 That is, a satisfies either "(3y)([2]0y) = x" or (3y)(([2]*y) + [I]) = x."</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Church-Turing Thesis (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/chuh_trng_thesis/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>Church-Turing Thesis, p. 3 
arrived at is the right one. This is particularly so if the methods employed by different reseachers 
are highly dissimilar, since this lessens the likelihood that they have all made the same mistake. 
If you come upon the same concept starting from several quite different approaches, this 
is reason to suppose that the concept you have reached is a basic and natural one; for it is likely 
to avoid the arbitrariness that often afflicts concepts that are only constructed from a single point 
of view. 
Let me describe some of these methods that arrive at the identification of the effectively 
enumerable sets with the Z sets. The proofs that these methods all yield the same result is labor 
intensive and not a little tedious, so I won't attempt it here. 
Turing machines. Alan Turing, in his senior undergraduate thesis at Cambridge, attempted to 
give a model, pared down to its bare essentials, of what a human computing agent does when 
solving a computational problem by applying a system of rules. The agent writes symbols down 
in a zigzag fashion, starting at the left, proceeding until she reaches the right margin, then 
starting again at the left, this time one line down. Our first simplification is to cut the lines apart 
and glue them together, so that they all lie along a single very long line. Thus our agent writes 
symbols side-by-side along a very long tape.' Actually, we shall assume the tape is infinite, since 
1 Being able to depict a problem pictorially may help us find a solution that would elude us 
if we were forced to do all our symbolic representations in one dimension. So if we were 
attempting to describe the creative processes by which new problem solutions are 
discovered, demanding that all our symbols be laid in a line would introduce terrible 
distortions. But that's not our aim. We want to look at the purely mechanical 
implementation of computational algorithms, a stage of problem-solving at which</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Church-Turing Thesis, p. 10 
be formalized within a finite system of axioms and axiom schemata. S will be weakly 
represented within the axiom system, and so, according to the theorem, E.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Church-Turing Thesis, p. 4 
we don't want to count a problem as unsolvable in principle if the only reason we've failed to 
solve it is that we've run out of scratch paper. 
In deciding what to write next, the agent will sometimes look back over her previous 
work. There is no real loss of generality in supposing that the agent looks over her previous work 
one symbol at a time, so that we can think of the agent as having a movable tape reader that she 
passes over the tape one symbol at a time, moving sometimes one square to the left and 
sometimes one square to the right, and pausing sometimes to erase an old symbol or write a new 
one. In having her work one symbol at a time, we are just breaking down what the agent does 
into the simplest possible steps. 
A finite, numbered list of detailed instructions tells the agent how to proceed with the 
computation. Things like, "If the square you are examining is blank, write the letter 'Q' in it and 
go to instruction 112" and "If the square you are examining has 'W' written in it, erase it and 
proceed to instruction 13" and "If the square you are examining has 'B' written in it, move one 
square to the right, and go to instruction 99." If the input number is n, the computation begins 
with the reader at the left end of a sequence of n "1" on an otherwise blank tape. If, when the 
computation finally ends, the reader is at the left end of a sequence of exactly m "l"s, then m is 
the output. If the computation never ends, then n isn't in the domain of the partial function being 
computed. If the machine halts on a certain input, that input is said to be accepted by a machine. 
A mechanical device that implements such a system of instructions is called a Turing 
machine. Turing proposed such machines as a model of human computation. Of course, what the 
machine does isn't what the human computing agent does; it's a highly simplified and stylized 
creativity is no longer called for.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Church-Turing Thesis, p. 7 
Notice that, even iff is total, px,[f(x,,,x,, ...,a = 01 needn't be total, for there might not be any 
value of x, that makes f(x,,,xl, ...,a equal to 0. 
It's clear that, iff is calculable, pxo[f(xo,xl, ...,%) = 0] is also calculable. Just plug in 
successive numbers until you get the output 0. 
Definition. The p-recursiveJicnctions constitute the smallest class of total 
partial functions that includes the successor function, the constant function 
0 (the unary function that gives 0 for every input), and the projection 
functions (for each j and n, j I n, there is a projection function that takes 
&lt;xl,x,, ...,%&gt; to x,; we need them for bookkeeping purposes), and is closed 
under substitution, recursive definition, and the p operator. 
A partial function is p-recursive iff it is x. 
Markov algorithms. Our next characterization of the x sets is based upon syntactic, rather than 
arithmetical, computations. We start with a finite alphabet. A word is a finite string of letters 
(including the empty string). Aproduction system is a finite set of ordered pairs of words. A 
word u is derivable from a word p iff there is finite system of transformations of the form 
aApA6 - aAyA6, 
where &lt;p,y&gt; is in the production system, that begins with p and ends with o; here "A" denotes 
the concatenation operation. A set of words S is accepted by given production system iff, for any 
word o, o E S iff there is a derivation of the empty word from S. A set is iff there is a 
production system that accepts it. 
Representability in a theory. Our final characterization takes seriously the idea that, if there is 
a "proof procedure" for S, then, if n is in S, one ought to be able to right down a description of S</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Church-Turing Thesis, p. 8 
on the basis of which it is possible to prove that n is in S. There must be some theory that 
describes the natural number system and some predicate a describing S such that o([n]) is a 
consequence of I? if and only if n is in S. We introduce a name for this state of affairs: 
Definition. The formula o weakly represents S in the theory r just in 
case, for any n, n is an element of S if and only if o([n]) is a consequence 
of r. 
If n is in S, you can prove that n is in S by providing a proof of o([n]). If n isn't in S, you don't 
necessarily have any way of proving that n isn't in S. In cases, whenever n isn't in S, you can 
prove that n isn't in S by proving -o([n]), a is said to strongly represent S: 
Definition. The formula o strongly represents S in the theory just in 
case, for any n, n is an element of S if and only if o([n]) is a consequence 
of I?, whereas n is outside S if and only if -o([n]) is a consequence of r. 
We'll actually prove the following result, instead of me asking you to take my word for 
it: 
Theorem. A set natural numbers S is iff there is a finite set of axioms 
and a formula o of the language of arithmetic that weakly represents S in 
r. S is A iff there is a formula o that strongly represents S in r. 
When we attempt to formalize ordinary mathematical reasoning, often we find ourselves 
working, not within a finite system of axioms, but within a finite system of axioms and axiom 
schemata. For example, the principle of mathematical induction is represented within the 
language of arithmetic, not by a single axiom, but by the induction axiom schema: 
((R(O) A (W@(x) - R(sx))) - Wx)R(x))</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>The Church-Turing Thesis 
We now know that every 2 set or relation is effectively enumerable. The central thesis of 
recursion theory is that the converse also holds, so that we have: 
Church-Turing Thesis. A set or relation is effectively enumerable iff it's 2. 
Since we know that a set is decidable iff it and its complement are both effectively enumerable, 
and we also know that a set is A iff it and its complement are both 2, we see that the Church- 
Turing thesis entails that a set or relation is decidable iff it's A. Also, a partial function is 
calculable iff it's x, and a total function is calculable iff it's A. 
"Calculable" here means calculable in principle: there is a mechanical procedure that, if 
carried out tirelessly and without error, will compute the function. The notion makes no 
allowance for senility, death, or limited disk space. If a computation takes up more bits of 
memory than there are particles in the universe, we still allow it. The theoretical aim is to give an 
extreme outer limit of what it's possible to compute, then to leave it to more practical-minded 
engineers to attempt to approximate that ideal in practice. 
One cannot hope rigorously to prove the Church-Turing. Before we can rigorously prove 
things about decidability and effective enumerability, we first have to have mathematically 
precise characterizations of those notions, and we are looking to the thesis to give us such 
characterizations. There is, however, quite a body of evidence in the thesis' favor. Let us now 
survey some of it. 
The biggest piece of evidence is simply that every known enumeration procedure 
generates a 2 set and every known decision procedure determines a A set. It's more than that. 
Every know enumeration procedure produces a set that is obviously x. Once you know a few 
tricks of the trade, it will be easy, once you know an algorithm of producing a set, to write down</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Church-Turing Thesis, p. 6 
We say that a register machine accepts a set of sentences S iff, for any n, if the machine 
is started with n in register 0 and 0 in all the other registers, the machine will eventually halt if n 
is in S, whereas if n isn't in S the computation will do on forever. 
There is a register machine that accepts S if and only if S is X. Once again, this result is 
resilient, so that, for example, we get nothing new if we permit indeterministic register machines. 
p-recursive functions. Our next characterization looks at the ways calculable functions are 
defined in arithmetic, specifically, at the ways new calculable functions are defined on the basis 
of old ones. Two such methods we have discussed previously, substitution and recursive 
definition. 
For example, if we have 0 and s, we can recursively define +, *, and E: 
x+o=x 
x + (y+l) = s(x + y) 
x*O = 0 
x*(y+l) = (xay) + x 
xEO = 1 
xE(y+l) = (xEy)*x 
Here is another way to make new calculable functions out of old: 
Definition. Given an n-ary partial function f, pxo[f(x,,,xl, ...,a = 0] is the 
n-ary partial function defined as follows: Given &lt;xl, ...,%&gt; as input, 
pxo[f(xo,xl ,..., %) = 0] will be defined and equal to y iff f(y,x ,,.., %) is 
defined and equal to 0 and, for each z &lt; y, f(z,xl, ...,a is defined and 
different fiom 0.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Church-Turing Thesis, p. 5 
mimicry of what the human agent does. But the differences are in inessential details, not in 
fundamental computational capacities. Everything a human compute? can do can be simulated, 
or so Turing proposes, by a Turing machine. 
The details here are pretty arbitrary. The number of symbols can be few or many, as long 
as it's finite. The inputs and outputs can be Arabic numerals, instead of strings of "1"s. We can 
allow auxiliary tapes for scratch work. We can even allow indeterministic computations. These 
are machines programmed with conflicting sets of instructions, so that, at certain junctures, the 
machine chooses, arbitrarily, which instruction to follow. 
However we work out the details, the result is the same. A function is computed by a 
Turing machine iff it is x. A set is accepted by a Turing machine iff it is x. 
Register machines. Turing's machines were intended to provide a model of what human 
computing agents do. Register machines are intended as a model of what electronic computers 
do. A machine contains an unlimited numbe? of memory locations or registers, and a program 
for the machine consists of simple instructions for manipulating the numbers contained in those 
memory locations. Thus we can add 1 to the number in a particular register; we can set a 
particular register equal to 0; we can compare the contents of two different registers, then decide 
what to do next on the basis of whether the two contents are equal; and so on. 
2 When Turing talked about a "computer," he meant a human computing agent, since at the 
time he wrote, in the early 30s, elecronic computers hadn't been invented yet. During the 
40s (after the war; during the war he was busy breaking the German naval code), he went 
on to build one of the first electronic computers. 
3 Keep in mind that we are attempting to characterize computability in principle.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Church-Turing Thesis, p. 2 
a x formula that describes the set. The only times we get stuck is when we don't really know the 
algorithm, or we don't know it explicitly. For example, we don't know how to write down a x 
formula that lists the code numbers of grammatical English sentences, but that's because, even 
though we presume there is an algorithm that generates the set, we don't know what it is. 
After the Church-Turing thesis was proposed during the 1930s, a fair amount of effort 
was devoted specifically to the program of showing the thesis to be false by presenting a 
decision procedure that wasn't A. None of these efforts got anywhere. The utter failure to obtain 
a counterexample to the thesis makes it quite likely that there is no such counterexample, and it 
makes it a moral certainty that, if there is a counterexample, it must be an algorithm that is quite 
unlike any algorithm that we have today. 
There are certain standard procedures for taking familiar algorithms and using them to 
create new algorithms; for example, substitution and recursive definition. The fact that the class 
of x partial functions is closed under all known techniques of this sort is another bit of evidence 
in favor of the Church-Turing thesis. Any counterexample to the thesis would have to involve 
some completely novel method of computation. There is no hope of getting a counterexample by 
combining familiar algorithms in complex ways. 
During the 1930s and 1940s, many different people were working on the problem of 
understanding computability, which may different approaches and perspectives. All of them 
came up with the same answer. This convergence gives us reason to suppose that the answer they 
came up with was the right one. Generally speaking, if different clever people working 
independently on a problem all arrive at the same answer, this is reason to think that the answer</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Church-Turing Thesis, p. 9 
Each of the infinitely many sentences you get from this schema by plugging in a formula for "R," 
then prefixing universal quantifiers to bind the resulting free variables is an induction axiom. Ow 
earlier theorem is upheld when we allow axiom schemata as well as single axioms: 
Theorem. For S a set of natural numbers, the following are equivalent: 
S is E. 
S is weakly represented within some finite system of axioms. 
S is weakly represented within some finite system of axioms and axiom 
schemata. 
S is weakly represented within some E system of axioms and axiom 
schemata. 
Likewise, the following are equivalent: 
S is A. 
S is strongly represented within some finite system of axioms. 
S is strongly represented within some finite system of axioms and axiom 
schemata. 
S is strongly represented within some system of axioms and axiom 
schemata. 
Throughout its history, mathematics has been a demonstrative science. Because of the 
preeminence of the axiomatic method in mathematical reasoning, this theorem provides potent 
evidence for the Church-Turing Thesis. If there is an algorithm that enumerates the set S, then it 
ought to be possible to describe the algorithm precisely, and then to verifl mathematically that 
computations are correct. If this verification looks anything like traditional mathematics, it can</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Self-Reference Lemma (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/self_reference/</lecture_pdf_url>
      <lectureno>13-14</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Self-reference 
The following result is a cornerstone of modern logic: 
Self-reference Lemma. For any formula q(x), there is a sentence 4 such 
that (4 - $([re])) is a consequence of Q. 
Proof: The proof breaks down into two parts. The hard part is to see what sentence 4 to use, and 
the easy part is to verifl that it works. In approaching the hard part, I'll be following Gyorgy 
Sereny's presentation in "Godel, Tarski, Church, and the Liar,"' although the main idea is 
already there in Godel's original paper.2 
The key idea goes back to the 6th century BCE, when the Cretan Epimenides said that 
Cretans always lie. Assuming for argument that the other statements made by Cretans are all 
blatent falsehoods, we find ourselves inexorably driven to the unhappy conclusion that, if what 
Epimenides says is true, it is false, whereas if what he says is false, it is true. It is doubtful that 
Epimenides realized the paradoxical nature of what he said, but someone who was fully aware of 
the cognitive disturbance was Eubulides of Miletas, a contemporary of Aristotle, who asked us to 
assess what is said by someone who declares, "What I am now saying is false." Eubulides is 
credited with other notorious paradoxes, notably the sorites (The observation that taking a single 
straw fiom a heap of straw still leaves you with a heap of straw leads, by multiple applications, 
1. Bulletin of Symbolic Logic 9 (2003): 3-25. 
2. "aer formal unentscheidbare Satze der Principia mathematica und venvandter Systeme 
I." Monatsheftefir Mathematik und Physik 38 (1 93 1): 173- 198. English translations in 
Jean van Heijenoort, ed., From Frege to Godel (Cambridge, Mass., and London: Harvard 
University Press, 1967), pp. 596-6 16, and in Martin Davis, ed., The Undecidable 
(Hewlett, N.Y.: Raven Press, 1965), pp. 4-38.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Self-reference Theorem, p. 5 
Transferring this construction from English to the formal language, we use Godel 
numbers in place of quotation names. Specifically, we define a function Z taking a number to the 
Godel number for the numeral for that number, thus: 
Z(0) = Q' = 4 
Z(n+l) = r[n=l] 1 = Pair(4,Z(n)) 
The usual technique for converting recursive definitions to explicit definitions shows that Z is A. 
The partial function that takes the code number of a formula and the code number of a 
term to the code of the formula obtained by substituting the term for free occurrences of the 
variable "x"in the formula is A.7 We explicitly wrote out the formula for substituting a term into 
a term, and the formula for substituting a term into a term is completely analogous. I won't write 
it out, but I could if I wanted to. We just noted that the formula Z taking a number n to [n] is A. 
Composing the two, we see that the function g given by: 
g(n) = the code of the sentence obtained from the formula coded by n by 
substituting [n] for free occurrenes of "x," if n is the code of a formula 
whose only free variable is "x"; 
= 0, otherwise; 
is A, so there is a formula y(x,y) that functionally represents it. 
Continuing with our formalization of the generalized version of Grelling paradox, with 
"$(x)" taking the place of "property P," let e(x) be the formula 
7. "x" isn't really a variable of the formal language; the official variables are "x,," "x,," 
"x,," and so on, but I'll pretend "x" is a variable, because too many subscripts are 
annoying.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Self-reference Theorem, p. 2 
to the conclusion that there is a heap of straw that contains no straw at all) and the hooded man 
(You do not know who the hooded man is, but you do know who your father is, even though, 
unknown to you, the hooded man is your father; this contradicts the logical principle that names 
that denote the same thing can be exchanged). Eubulides' formulation is in one way sharper than 
Epimenides', since it doesn't depend on the mendacity of all one's neighbors. However, it 
introduces a new level of complexity, since it contains the indexicals "now" and "I." You can 
avoid these complexities by looking at page 65 of the June 1969 issue of ScientiJc Ameri~an,~ 
where you will find the sentence, "The sentence printed in red on page 65 of the June 1969 issue 
of ScientiJc American is false," printed in red. This still isn't what we need for present 
purposes. For present purposes, we would like to reproduce a version of the liar paradox (with 
is place of "is false") within the language of arithmetic, and contingent facts about who said 
what when and where aren't expressible within the language of arithmetic. What is expressible 
within the language of arithmetic is syntax, which we can express by means of the Godel coding. 
So we would like to examine a version of the lair paradox that identifies the offending sentence 
in purely syntactic terms. 
A purely syntactic version of the liar paradox is given by Q~ine:~ 
"Yields a falsehood when appended to its own quotation" yields a falsehood 
when appended to its own quotation. 
3. This is Tarski's article, "Truth and Proof." 
4. "The Ways of Paradox" from The Ways of Paradox and Other Essays, revised ed. 
(Cambrdige, Mass., and London: Harvard University Press), 1976.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Self-reference Theorem, p. 6 
(3y)(y is a sentence A y(x,y) A $(y)). 
Let k be the Godel number of k, and let 4 be the sentence 
(3Y)(Y is a sentence A (y([kI,y) A $(Y)). 
Then r@ = g(k), and so 
Q ~(~Y)(Y([~I,Y) - Y = [ r@l). 
Also, 
Q 1 [r@] is a sentence. 
Consequently, 
Q t((3~)([ r@l is a sentence A ~([kl,~) A $(Y)) - $Ur@l), 
that is, 
Q t (4 - $([ r@).m 
Generalized Self-Referential Lemma. For any formula $(x,z,,z2, ...,q), 
there is a formula 4(z,,z ,,..., 4 such that: 
Q t(vzl)(vz2)...(v4(4(~1,~2 ,---, 4 - $( '@,z1,z2,...,43). 
Proof: In the proof of the Self-Referential Lemma, the extra variables quietly go along for the 
ride. H</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Self-reference Theorem, p. 4 
satisfies itself because '"x has fewer than ten words' has fewer than ten words" is true. If an 
expression doesn't satisfy an open sentence, then the result of substituting the quotation name of 
the expression for the variable in the open sentence is false. Thus "x is a horse" doesn't satisfy 
itself, and so "'x is a horse' is a horse" is false. An open sentence S does not satisfy itself if and 
only if the sentence obtained by substituting the quotation name of S for its variable is false. 
Thus Grelling's paradox consists in asking whether a false sentence is obtained from "A false 
sentence is obtained from the open sentence x when its quotation name is substituted for its 
variable" when its quotation name is substituted for its variable. This gives us a version of 
Eubulides' paradox in which the paradoxical sentence is identified entirely by its syntactic 
features. 
The sentence "This sentence is false" is a sentence that asserts its own falsity, but it does 
so by making use of the demonstrative "this," and demonstratives aren't available in the formal 
language of arithmetic. "A false sentence is obtained from 'A false sentence is obtained from the 
open sentence x when its quotation name is substituted for its variable' when its quotation name 
is substituted for its variable" likewise asserts its own falsity, and it does so without relying on 
demonstratives. Right at the moment, our focus isn't on the liar paradox. We'll come back to talk 
about the paradox later on, although what we'll have to say won't be even remotely satisfying. 
Right now, however, our interest in self-reference, and we're in luck, for the same construction 
works generally. Specifically, given a property P, the sentence "A sentence with property P is 
obtained from the open sentence 'A sentence with property P is obtained from the open sentence 
x when its quotation name is substituted for its variable' when its quotation name is substituted 
for its variable" is true if and only if it has property P.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Self-reference Theorem, p. 3 
Quine's construction generalizes nicely. Given a property P, consider the following sentence: 
"Yields a sentence with property P when appended to its own quotation" 
yields a sentence with property P when appended to its own quotation. 
The sentence is true if and only if it has property P. 
This still isn't quite what we want, however, because it relies on a syntactic feature that 
English doesn't share with the formal language, namely, that you can form a sentence by 
concatenating a (possibly complex) noun phrase with a (possibly complex) verb phrase. An 
alternative formulation that does generalize uses the operation of substituting a noun phrase for a 
~ariable.~ Grelling 's paradox6 asks us to partition open sentences into those that satisfy 
themselves and those that do not. "x contains fewer than ten words" contains fewer than ten 
words, and so it satisfies itself, unlike "x contains fewer than five words." "x is an open sentence 
of Eng1ish"is an open sentence of English, so it satisfies itself. "x is an open sentence of 
Portuguese" is not an open sentence of Portuguese, so it does not satisfy itself. Also, "x is a 
horse" is not a horse, and thus it does not satisfy itself. Now consider "x does not satisfy itself." 
It would appear that it satisfies itself if and only if it does not. 
To generalize the Grelling paradox, note that an expression of English satisfies an open 
sentence just in case the sentence obtained by substituting the quotation name of the expression 
for the variable in the open sentence is true. Thus "x contains fewer than ten words is true" 
5. Explicit variables are part of the dialect of English employed in math and science. 
Everyday speech employs pronouns for the much the same purpose. 
6. Grelling, Kurt, and Leonard Nelson. "Bemerkungen zu den Paradoxien von Russell und 
Burali-Forti." Abhandlungen der Fries 'schen Schule neue Folge 2 (1 908): 30 1-334.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Why Study Computability? (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/why_study_comptt/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>Why Computability? p. 6 
how we formulate the axioms doesn't matter. However we formulate the axioms of 
number theory, as long as we can see that they're all true, there will be Wher sentences 
that we can recognize as true even though they aren't derivable from the axioms. 
Godel's theorem takes on a particular urgency when we connect it to the question, 
"How do mathematical terms get their meanings?" It appears that the answer has to be 
something like, "The meanings of the terms are established by the mathematical theory." 
That can't be the whole answer, because we need to take account of the use of 
mathematical terms in such activities as counting and measuring, but these activities 
don't go very far toward pinning down the meanings of the terms. What emphatically we 
don't have for the names of numbers is an analogue for what we have for the names of 
dogs: our causal connection with the dog Fido helps to pin down the meaning of the 
name "Fido." In the absence of causal connections, there is precious little left, other than 
the theory, to pin down the meanings of the terms. Yet the theory can't pin down the 
meanings, since there are sentences that, as far as the theory is concerned might be true 
and might be false, even though it follows from the biconditionals 
r@ is true if and only if 4 
r@ is false if and only if -4 
that every sentence is either true or false. This discrepancy has driven some philosophers 
to mathematical skepticism. 
A close relative of Godel's result is a theorem of Tarski's to the effect that, if our 
commonsense understanding of the notion of truth is correct, then it will not be possible 
to develop a theory of truth for a language within the language itself. Instead, the theory</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Why Computability? p. 4 
in kind from the processes that occur on a silicon chip. Thus any problem we can solve is 
going to be decidable.' 
The content of this observation is not entirely abstract. Computer models of the 
mind have become prominent in recent psychology and philosophy of mind. 
Recursion theory is concerned with problems that can be solved by following a 
rule or a system of rules. Linguistic conventions, in particular, are rules for the use of a 
language, and so human language is the sort of rule-governed behavior to which 
recursion theory applies. Thus, if, as seems likely, an English-speaking child learns a 
system of rules that enable her to tell which strings of English words are English 
sentences, then the set of English sentences has to be a decidable set. This observation 
puts nontrivial constraints upon what the grammar of a natural language can look like. 
As Wittgenstein never tired of pointing out, when we learn the meaning of a 
word, we learn how to use the word.2 That is, we learn a rule that governs the word's use. 
1 It appears likely that our stimuli don't uniquely determine our behaviors; instead, there 
are elements of chance involved. But this makes no difference, since it turns out that the 
same problems can be solved by nondeterministic computing machines as can be solved 
by deterministic machines. 
2 It may be that, when we learn the word "duck," we learn to associate the word this the 
universal canardity. But even if that's true as a matter of metaphysics, it has no value in 
explaining how we learned the word, for our parents didn't teach us the word by 
repeating the word "duck" while pointing to the universal.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Why Computability? p. 9 
analytical techniques that gave us a successful analysis of decidability will point out to us some 
of the obstacles that lie in the way of a successfbl analysis of the right. 
Incidentally, the only other example I know of a successful conceptual analysis (apart 
from trivialities like "Vixen are female foxes") is the E-6 analysis of the concepts of limit and 
continuity.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Why Computability? p. 7 
of truth for a language 9 must be developed within a metalanguage which is essentially 
richer than 9 in expressive power. The philosophical consequences of this result are 
staggering. It implies that we cannot give a theory of truth for English (or for any natural 
language) for we don't have any metalanguage richer than English in expressive power. 
Moreover, the result entails that it is not possible to obtain a unified science that 
comprehends nature, human language, and human thought as a unified whole, for the 
language we use when we talk about language lies outside the reach of linguistic inquiry. 
Another, quite different, reason why philosophers ought to be interested in 
recursion theory is this: since Plato, philosophers have been trying to give analyses, in 
which the meaning of a difficult or troublesome term is explained in terms of other terms 
which are simple, clearer, and better understood. For example, to fill in the blank in 
It is right for S to do A iff , 
where the blank is filled in by something from outside the circle of moral terms.3 The 
right sort of thing would be: 
It is right for S to do A iff, of the possible acts available to S, A is most 
conducive to the greatest happiness for the greatest number, 
provided that "happiness" is understood in such a way that it is not infused with moral value. 
The biconditional you get by filling in the blank needs to be a conceptual truth. If we give a 
3 If we explain the meaning of "right" in terms of other moral terms, we may have done 
something quite valuable and helpful, but we will not have done what has traditionally 
been regarded as an analysis. An analysis of "right" would explain the meaning of "right" 
to someone who doen't have any moral vocabulary at all.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Why Computability? p. 3 
An example is Hilbert's tenth problem, the tenth problem on a famous list of the 
world's most prominent unsolved mathematical problems, promulgated by David Hilbert 
in 1900. The problem was to find when a polynomial (in several variables) with integer 
coefficients has an integer solution. It is clear that there is a proof procedure for the set of 
polynomials with integer coefficients and integer solutions. You just test possible 
solutions one by one by multiplying and adding. It is not so clear whether there is a 
method for identifling those problems that don't have integer solutions. Many bright 
people worked many hours on this problem, and they would be working on it still had not 
Yuri Matijasevic in 1970 applied the methods of computability theory (or recursion 
theory, as it's called) to prove that there is no such algorithm. 
Let me now give some reasons why recursion theory ought also to be of interest 
to philosophers. 
Recursion theory is concerned with problems that can be solved by a computing 
machine. What counts as a computing machine? It doesn't matter what they thing is made 
of. A computing machine could be made of TinkertoysB, of embroidery thread, or of 
animal flesh. What matters is how the thing is organized. The device has to make its way 
from inputs to outputs in a sequence of purely mechanical steps; an IBM PC that acts 
under demonic influences will not count as a computing machine. The philosophically 
interesting thesis is that we ourselves ought to be counted as computing machines. Our 
inputs are sensory stimuli and our outputs are behaviors. The chemical and electrical 
processes by which our behaviors are produced are simple natural processes not different</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Why Study Computability? 
A decision procedure for a set S is an algorithm - a fully mechanical computation 
procedure - that correctly answers questions of the form "Is so-and-so in S?" A proofprocedure 
for S is the positive half of a decision procedure. If a is in S, then there is a "proof' that a is in S, 
and the proof can be found by diligent seaching; if a isn't in S, then there is no such proof. 
Moreover, the processes of searching for a proof and recognizing a proof when you find one can 
be carried out in a purely mechanical fashion. 
In Logic I, we learned a couple of decision procedures for the set of valid sentences of 
the sentential calculus, the method of truth tables and the search-for-counterexamples method. 
We also learned a system of rules that enable us to derive any valid sentence of the predicate 
calculus. These rules constitute a proof procedure for the set of valid sentences. We did not, 
however, learn a decision procedure. If we try to prove 4 and we don't succeed, there will be no 
stage at which we can be sure that the reason we haven't succeeded is that 4 isn't provable, 
rather than we haven't looked long enough. The explanation why we haven't found a decision 
procedure for the set of valid sentences of the predicate calculus shows more than merely that we 
haven't been clever enough to devise one. There is, in fact, no decision procedure there to be 
had. This was demonstrated by Alonzo Church and Alan Turing: 
Church-Turing Theorem. There is no decision procedure for the set of 
valid sentences of the predicate calculus. 
What a remarkable result! To point out that there is no known procedure for 
testing validity in the predicate calculus is no big deal; it just means that finding a test for 
validity is an unsolved problem. But the Church-Turing theorem tells us much more than</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Why Computability? p. 2 
this. It tells us that no time, ever, even in the distant future, will anyone discover a 
decision procedure for the validity in the predicate calculus. 
The Church-Turing theorem is a result of an extensive investigation, carried out 
during the 1930s by Turing, Godel, Kleene, Church, and others, of the question, "When 
is there an algorithm for solving a particular mathematical problem?" That is, when is 
there a system of explicit rules, which can be followed in a perfectly mechanical way and 
which will always give a correct answer to a certain category of mathematical question? 
The investigation was quite fi-uitfbl. For one thing, the investigation preceded the 
development of the electronic computer and facilitated its development. Turing 
developed a highly simplified and schematic model of what we do when we calculate 
with pencil and paper, and much of the early work in developing digital computers was 
aimed at implementing Turing's model electronically. 
It is not surprising that these investigations have been of interest of 
mathematicians and computer scientists. For one thing, before these investigations, one 
had no way of showing an undecidable problem to be undecidable. Thus if one were 
working on a problem of the form "Find an algorithm for so-and-so" - and a great many 
important mathematical problems take this form - and if there were, in fact, no such 
algorithm, then one might spend one's entire career in a fbtile search for an algorithm 
that isn't there. This could still happen, even after the advent of the theory of 
computability, but it's made less likely by the advent of techniques that enable you to 
work on the problem fiom both ends. Try to find an algorithm, and if that doesn't work, 
try to prove that there is no such algorithm.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Why Computability? p. 5 
So a theory that gives us the limitation on what we can accomplish by following a rule 
also gives us limitations on the structure of the meanings of words. 
In particular, when we are learning arithmetic, what we are learning, presumably, 
are the rules for the use of numerical language. The natural alternative, which is that the 
child learns to use "three" the way she learns to use "Mama" or "duck," by learning to 
recognize three when she sees it, seems preposterous. But if learning arithmetic really 
consists in learning rules of language, then, it would seem, we ought to be able to state 
what the rules are, then to say that a sentence is recognizable as a truth of arithmetic if 
and only if it is can be produces by following the rules. But, in fact, we cannot do this. A 
deep theorem of Kurt Godel, which we shall discuss presently, shows that, for any system 
of rules, either there si a false arithmetical sentence that is a consequence of the rules, or 
else there is a true arithmetical sentence that is not a consequence of the rules. Worse: for 
any system of rule we can specifl for generating truths of arithmetic, there will be an 
arithmetical sentence that isn't a consequence of the rules that we can recognize as true. 
Godel's theorem places important limits upon the power of the axiomatic method. 
Before Godel's theorem, it was generally supposed that hoe we acquired mathematical 
knowledge was by drawing out the consequences of mathematical axioms. The axioms 
themselves were traditionally regarded as self-evident truths; after the advent of non- 
Euclidean geometry, it became common to suppose that the mathematician's job was 
simply to develop the consequences of axiom systems, without concerning themselves 
with whether the axiom systems are true. Godel's theorem shows that that traditional 
account can't be all there is to the epistemology of mathematics. The precise details of</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Why Computability? p. 8 
characterization of the class of right acts whose correctness is merely accidental, or even if we 
give a characterization is a matter of physical law, we would not say that we have given an 
analysis of what it is for an act to be right. 
The program of trying to understand a difficult concept by presenting a conceptual 
analysis is a venerable part of our philosophical heritage, but it is a program which has scarcely 
ever succeeded. One such example is the analysis of decidability that we get from recursion 
theory. Recursion theory gives us a biconditional of the form 
There is an algorithm for testing membership in S if and only if 9 
where the blank is filled in with a statement form pure mathematics. Thus on the left there is a 
statement about procedures and capacities, and on the right there is a statement that has nothing 
to do with procedures and capacities, a statement you would be able to understand even if you 
were a member of a race of superbeings that could recognize mathematical truths by direct 
intuition and had no inkling what computations or algorithms are.4 Moreover, the biconditional, 
if it is true at all, is a conceptual truth. So we have a successfbl analysis. 
If we are interested in giving conceptual analyses, it is a good idea to look carehlly at the 
few examples we already have of successfbl analyses. One reason this is so is that it is usually a 
good strategy to emulate success. See what methods were employed to give our successful 
analysis of decidability in order to see whether these same methods can be applied to give 
analyses of other concepts. Even if this doesn't give us the analysis we seek, it may still give us 
some usefbl information. Understanding why the concept of rightness doesn't yield to the same 
4 According to Thomas Aquinas, that the way it is with angels.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>The Language of Arithmetic (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/lange_of_arithmt/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>The Language of Arithmetic, p. 6 
$([k])s for k &lt;  den(^). Continue this until you've eliminated all the bounded quantifiers, then 
test the truth of the quantifier-free sentence that resu1ts.H 
Corollary. There is a decision procedure for each bounded set. 
Proof: If S is a bounded set, then it is the extension of a bounded formula @(x). To test whether 
n is in S, check whether @([n]) is true.H 
Every bounded set is decidable, but not every decidable set is bounded. To see this, we 
employ a variant of Cantor's diagonal argument. We can recognize a bounded formula by its 
syntactic structure, so it is possible to list all the bounded formulas that have "x" as their only 
free variable. This gives us a list of all the bounded sets. Let C = {n: n is not an element of the 
nth bounded set on the list}. C is decidable. To check whether n is in C, just write out the nth 
bounded formula on the list and check whether n satisfies it. C is not, however, bounded. For, is 
C were bounded, then there would be a number k such that C = the kth set of the list. But then 
we would have: 
k E the kth set on the list 
iff k E C (by the way k was chosen) 
iff k B the kth set of the list (by the way C was defined) 
We can employ the same argument to thwart any attempt to provide a program that 
generates programs that decide each decidable set. Either some of the programs generated won't 
just $, and the conjunction of the empty set of formulas is "0 = 0." For the conjunction fo 
a many-element set of formulas, the order in which the conjuncts are taken and the way 
they are grouped together can be chosen any way you like. Similarly, the disjunction of 
($1 is $, and the disjunction of the empty set of formulas is "- 0 = 0."</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>The Language of Arithmetic, p. 5 
$) will be labeled "true" if and only if one or both of the nodes immediately beneath it is labeled 
"true."H 
We introduce the bounded quantiJiers: for 4 a formula and T term, (3% &lt; T)@ will be an 
abbreviation for (3rZ3(% &lt; T A 4). (b'q &lt; T)@ abbreviates (b'%)(x, &lt; T - 4). The bounded 
formulas are characterized as follows: 
Every atomic formula is bounded. 
If 4 and $ are bounded formulas, so are (4 V $), (4 A $), (4 - $), (4 - $) 
-4, (3% &lt; T)@, and @'% &lt; T)@, for each n and T. 
Nothing else is a bounded formula. 
We use "p I T" and an abbreviation for "p &lt; ST." Thus, if 4 is a bounded formula, so are (3% I 
T)@ and @iZ, I T)@, for each n and T. 
A bounded set is the extension of a bounded formula, that is, it is a set of the 
form {x: @([XI)), for some bounded formula 4. Similarly for bounded relations. 
The functions Pair, 1 st, and 2nd are bounded. So is the relation that holds between x and 
y iff x is an element of the set whose code number is y; we'll abuse notation slightly by writing 
"x E y." The set of code numbers of sequences is a bounded set, as is the partial function that 
takes x and i to the ith member of the sequence coded by x (which we write "(x)?) if x codes a 
sequence of length i or greater, and is undefined otherwise. 
Proposition. There is a decision procedure for the set of true bounded sentences. 
Proof: Working fiom the outside in, replace each subformula of the form (Vx &lt; T)@ by the 
conjunction4 of all the $([k])s for k &lt; Den(z). Replace (3x &lt; T)$ by the disjunction of all the 
4 To make this work out smoothly, we adopt the convention that the conjunction of ($1 is</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>The Language of Arithmetic, p. 2 
If a node is labeled by (T + p), by (zap), or by (TE~), then there are two 
nodes directly beneath it, the left labeled by T and the right by p. 
Each leaf of the tree is labeled either by "0" or by a variable. 
A closed term is a term that contains no variables. Within the standard model, each 
closed term denotes a natural number, uniquely determined as follows: 
Den("0") = 0. 
Den(sz) = Den(T) + 1. 
Den((T + p)) = Den(7) + Den@). 
Den((vp)) = Den(z)*Den(p) 
Den((TEp)) = ~en(T)~"(~). 
We introduce a standard numeral for each number by stipulating that [n] is the symbol obtained 
by writing n "s"s in fiont of "0," so that, for example [7] = "sssssssO." 
The function that takes the symbol T to the number Den(z) is calculable. One algorithm 
you might use for this purpose is, first, to produce a labeled tree with T at its trunk, representing 
the structure of T, as described above; and then to associate a number with the label for each 
node, working fiom the leaves toward the trunk. "0," which labels the leaves, is associated with 
0. If If the nodes associated with p and p are associated with n and m, respectively, associate 
n+m with (p + p). And so on. 
The atomic formulas of the language of the arithmetic are expressions of one of the forms 
T &lt; p or T = p, for T and p terms. The formulas are characterized by the following stipulation: 
Every atomic formula is a formula. 
If0 and q are formulas, so are (0 V q), (0 A q), (0 - q), (0 - q), -0,</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>The Language of Arithmetic, p. 1 1 
In other words, 
f(n) = lst(the least z such that @(lst(z),2nd(z)) A (b'w &lt; z)(either 
-@(lst(w),2nd(w)) or (3i &lt; n)f(i) = lst(w))). 
Put a different way, f(x) = y iff there is a finite sequence s of length m that meets the following 
conditions: 
(b'n &lt; m)(3z)(@(l st(z),2nd(z)) A @iy &lt; z)(-@(1 st(w),2nd(w)) V (3i&lt;n)(s), = 
lst(w))A lst(z) = (s)$. 
x &lt; m A (s), = y. 
This all gets encoded as a x formula. There is a little more to this than meets the eye, since "lst," 
"2nd," and the notation for the components of a finite sequence aren't part of the language of 
arithmetic, but part of the dialect of English we use in talking about numbers informally. The 
relation "y = lst(x)," "y = 2nd(x)," "x encodes a sequence of length y," and "x encodes a 
sequence whose yth component is z" can all be written out as bounded formulas of the language 
of arithmetic. f(x) = y iff 
(3s)(3m I s)(s encodes a sequence of length m A 
(b'n &lt; m)(3z I s((3u I z)(3v I z)((u = lst(z) A v = lst(z)) A @(u,v)) A 
(b'w &lt; z)((3u I x)(3v1 W)(U = lst(w) A v = 2nd(w) A -@(u,v)) 
V (3i &lt; n)(3t I s)(s encodes a sequence whose ith member is t A t = lst(w))) A 
(3u I z)(u = lst(z) A s encodes a finite sequence whose nth member is u)) 
A x &lt; m A s encodes a finite sequence whose xth member is y). 
When you write this out in primitive notation and apply our rules for pulling quantifiers to the 
front (taking care to avoid collisions of bound variables), you really do get a x formu1a.H</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>The Language of Arithmetic, p. 13 
&lt;f(O),f(l), ..., f(n-I)&gt;. For s the code number of a sequence of length n or greater, let s In be the 
code number for the sequence &lt;(s),,(s),, ...,( s),-~&gt;. I realize I'm using the same symbol for two 
different purposes, but it should be harmless. Our recursive definition takes the form 
f(n) = h(f I n), 
where h is already known. It's explicit version is this: 
f(x) = Y =a, 
(3 finite sequence s)(3m I s)(m is the length of s A 
(b'n &lt; m)(s), = h(s I n) A x &lt; m A (s), = y). 
If h is x, so is f. 
Here again, I am claiming that a set is x on the basis of having described it by a x hybrid 
formula that contains symbols from both formal and informal arithmetic. Let me describe a 
general procedure that justifies such claims. The procedure only applies to formulas that don't 
contain "-" or "-," apart from the "-"s that occur in bounded universal quantifiers, but there's 
no loss of generality in that. Suppose a set S is defined by a x formula of the language obtained 
from the language of arithmetic by adding an extra unary function sign f that is used to denote a 
unary total recursive function. The same technique will work for sets and relations defined using 
more than one function sign, and it will work with function signs with more than one agurnent. 
We restrict our attention to the single unary function case just to keep the notation manageable. 
The strategy is simple. We cash out any atomic formula containing "f' either in terms of 
the x definition or the II definition, as appropriate, then pull the quantifiers to the front. The 
details are messy, however. 
A recursive total function is II as well as x. Let's say we have f(x) = y iff (3z)@(x,y,z) iff</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>The Language of Arithmetic, p. 3 
(3xJ4, and (VxJ4, for each n. 
Nothing is a formula, unless it's required to be by the clauses above. 
We have unique readability for formulas, just as for terms. 
An occurrence of the variable x, within a formula is bound iff it occurs within some 
subformula that begins with (Vq) or (3%). Occurrences that aren't bound areji-ee. A sentence is 
a formula that contains no free variables. 
For 4 a formula and r a term, let 4%lr be the formula obtained from 4 by substituting r 
for each free occurrence of x, in 4. Where there's no threat of confbsion about which variable is 
involved, we'll sometime write @(r) instead. 
Truth in the standard model is defined by first stating the truth conditions for atomic 
sentences, then seeing how the truth conditions for complex sentences are determined by the 
truth conditions for simpler sentences. A special feature of the standard model is that every 
member of the domain of discourse is named by some numeral. This special feature will simplifl 
the definition of truth, since we can define truth directly, rather than having to define truth in 
terms of satisfaction. 
r &lt; p is true if the standard model iff Den(.r;) &lt; Den@). 
r = p is true in the standard model iff Den(r) = Den@). 
(4 V $) is true in the standard model iff either or both of 4 and $ are true in 
the standard model. 
(4 A $) is true in the standard model iff both 4 and $ are true in the standard 
model. 
(4 - $) is true in the standard model iff either 4 isn't true in the standard model</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>The Language of Arithmetic, p. 8 
to a bounded formula. 
Proposition. There is a proof procedure for the set of true 2 sentences. 
Proof: Say the sentence is (3vl)(3v,) ...( 3vb4, where 4 is bounded. The proof procedure is to 
substitute various k-tuples of numerals for the free variables in 4 until you get a sentence that's 
true. 
To prove a X procedure, all you have to do is to provide a witness. To rehte a X 
sentence, you have to shoot down infinitely many potential witnesses, and it's not too surprising 
that there is no algorithm for doing that. As we shall see later on, the set of true X sentences is 
effectively enumerable but not decidable. 
A Cset of natural numbers is the extension of a X formula; that is, S is X iff there is a X 
formula 4 such that S = {n: @([n])). X relations are defined similarly. 
Corollary. There is proof procedure for each 2 set. 
Proof: Say S is the set of numbers that satisfy the X formula $(x). To enumerate S, start 
enumerating the true X sentences, and add n to the list for S whenever you add @([n]) to the list 
of true X sentences.H 
Proposition. If S is a 2 set, then there is a bounded formula @(x,y) such 
that S = {x: (3y)@([x],y)}. In other words, to define a X set, we don't 
require a block of existential quantifiers. A single existential quantifier 
will do. 
Proof: If S is a X set, then there is a bounded formula $(x,yl,y2, ...,ym) such that S = {x: 
(~Y~)(~Y~)...(~YJ$([xI,Y~,Y~,-.-,Y~)~. Then S = {x: (~z)(~YI &lt; z)(3~2 &lt; z).--(3Ym &lt; z) 
$([x],y,,y2, ...,y,)); the stuff that comes after the "(32)" is a bounded formu1a.H</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>The Language of Arithmetic, p. 15 
Replace (V V (3v)p) by (3v)(v V p) 
Replace (@ir)p v V) by (b'v)(p V v). 
Replace (V V (Vv)p) by (VV)(V V p) 
Replace ((3v)p A V) by (3v)(p A v). 
Replace (V A (3v)p) by (3v)(v A p) 
Replace (@ir)p A V) by ('dv)(p A v). 
Replace (V A (Vv)p) by (VV)(V A p) 
Replace (3u &lt; ~)(3v)p by (3v)(3u &lt; ~)p. 
Replace (3u &lt; ~)(Vv)p by ('dt)(3u &lt; T)(Vv &lt; t)p. 
Replace ('du &lt; ~)(3v)p by (3t)('du &lt; ~)(3v &lt; t)p. 
Replace (Vu &lt; ~)(Vv)p by ('dv)(Vu &lt; T)p. 
Replace -(3v)p by ('dv)-p. 
Replace -(Vv)p by (3~)-p. 
The eventual result will be a x formula defining S. 
Let me now state, without going through the proofs, a couple of structural properties of x 
sets and relations, directly analogous to properties we noted earlier for effectively enumerable 
sets and relations: 
Proposition (Reduction Principle for x sets). For any 2 sets A and B, 
therearexsetsCandDsuchthatCcA,DrB,CnD=ca,andCuD= 
A u B. 
Proposition (Uniformization Priniciple for x relations). For any 2 
relation R, there is a x partial hction f with Dom(f) = {x: (3y) &lt;x,y&gt; E</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>The Language of Arithmetic, p. 9 
If, instead of starting with a block of existential quantifiers, we start with a block of 
universal quantifiers,followed by a bounded formula, the result is a ll formula. The block of 
universal quantifiers can be replaced with a single quantifier. The extension of a formula is a 
ll set. Thus the ll sets are the complements of the x sets. A set that is both x and ll is said to be 
A. 
A confusing terminology has become entrenched. A set or relation is said to be recursive 
iff it's A. A set or relation is recursively enumerable or r.e. iff it's x. So far so good, but a x 
partial function is referred to as apartial recursive function. That's confusing, for two reasons. 
First, the phrase - "partial recursive function" as opposed to "recursive partial function" - 
suggests that what we are dealing with is a part of a total recursive function, but in fact, as we 
shall see later on, there are partial recursive functions that cannot be extended to total recursive 
functions. Second, it means that, even though a partial function (of one variable) is a kind of 
binary relation, a partial recursive function isn't a recursive binary relation, but only a 
recursively enumerable one. When there's any chance of confusion, I'll try to use ''A" and "x" 
in place of "recursive" and "recursively enumerable."(For total functions, the confusion happily 
dissipates, since a recursive total function is recursive.) 
Note that the extension of a bounded set is always x, since we can tack a vacuous 
existential quantifier onto the front of the bounded formula. Since the negation of a bounded 
formula is bounded, it follows that the extension of a bounded formula is always A. 
The union of two x sets is x, as is their intersection. If R is a x relation, {x: (3y)Rxy), 
{x: (3y &lt; k)Rxy), and (x: (Vy &lt; k)Rxy) are all x sets, for each k.</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>The Language of Arithmetic, p. 16 
R) and &lt;x,f(x)&gt;  R for each x  Dom(f).</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>The Language of Arithmetic, p. 14 
(VZ)~(X,~,Z), where $ and 0 are bounded. We describe a procedure for converting a x formula 
containing f that defines S to a x formula containing one fewer occurrence off that also defines 
S. By applying the procedure repeatedly, we obtain a x formula of the language of arithmetic that 
defines S. 
Our given occurrence off is either within an atomic formula or within a bounded 
existential quantifier or within a bounded universal quantifier. It is this multiplicity of 
possibilities, as well as the fact that we sometimes utilizize the x definition off and other times 
the II definition, that makes the procedure complicated to describe. 
The procedure proceeds in two stages. At the first stage, if the given occurrence off 
appears within an atomic formula of the form xVIf( replace the atomic formula with 7)' 
(3~)(3z)($(z,v,z) A x), if the atomic sentence is within the scope of an even number of negation 
signs, or with @ir)(Vz)(~(z,v,z) + x), if it's within the scope of an odd number of negation signs. 
If, on the other hand, the given occurrence off takes the form (3u &lt; pv~f(T))~, replace it with 
(3~)(3z)(x(z,v,z) A (3u &lt; p)~), if the occurrence is within the scope of an even number of 
negation signs, or with (Vv)(Vz)(e(z,v,z) - (3u &lt; p)~), if the number of negations is odd. If, on 
the third hand (!), the given occurrence off takes the form (tlu &lt; pvIf(T))~, replace it with either 
(~v)~z)($(T,v,z) A (Vu &lt; p)~) or (Vv)(Vz)(e(z,v,z) - (Vu &lt; p)~), depending on whether the 
occurrence is within the scope of an even or odd number of negation signs. 
The first stage has introduced a new unbounded quantifier. The second stage applies the 
usual methods for pulling the negation sign to the front. Here are the "usual methods"; we assume 
that v doesn't occur free in V, and we change bound variables as required to avoid collisions: 
Replace ((3v)p V V) by (3v)(p V v).</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>The Language of Arithmetic, p. 7 
be decision procedures (because they will fail to provide answers for some membership 
questions) or there will be some decidable sets for which no decision procedure is generated. 
We can, however, provide a program that list programs that list each effectively 
enumerable set. For any decidable set S, there will be a program on the list that enumerates S and 
another program that enumerates the complement of S. Taken together, these two programs 
provide a program that decides S. Knowing this doesn't provide us with a method for listing 
decision procedures, because we have no algorithm for matching up the program that enumerates 
S with the program that enumerates its complement. 
In a similar way, we can show that there isn't any program that lists programs for 
calculating the calculable total functions. Any program that attempts to do this will either list a 
program for a function that isn't total or it will leave out some calculable total function. To see 
this, suppose, for reduction ad absurdum, that we had such a master program. Define a total 
function f by: 
f(n) = 1 + the output given by the nth program on input n. 
Because f is a calculable total function, there will be a program on the list that calculates f; say 
it's the kth program. Then 
the output given by the kth program on input k 
= f(k) (by the way k was chosen) 
= 1 + the output given by the kth program on input k (by the way f was defined) 
Thus the best we can obtain is a program that lists programs that list the calculable partial 
functions. 
The Zformulas are the formulas obtained by prefixing a block of existential quantifiers</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>The Language of Arithmetic, p. 4 
or $ is. 
(4 - $) is true in the standard model iff either 4 and $ are both true in the 
standard model or neither of them is. 
-4 is true in the standard model iff 4 isn't true in the standard model. 
(3x39 is true in the standard model iff, for some k, is true in the 
standard model. 
(VxJ@ is true in the standard model iff, for every k, @%I is true in the [kl 
standard model. 
4 is false in the standard model iff -4 is true in the standard model. 
True arithmetic is the set of sentences true in the standard model We shall see that there 
is no decision procedure for true arithmetic, or even a proof procedure. We do, however, have 
this much: 
Proposition. There is a decision procedure for the set of true quantifier-free 
 sentence^.^ 
Proof: First note that there is a decision procedure for the set of true atomic sentences. Namely, 
T &lt; p is true iff Den(7) &lt; Den(p) and T = p is true iff  den(^) = Den@). The truth of a quantifier- 
free sentence is determine by the truth or untruth of its atomic components by the laws of the 
sentential calculus. A way to determine the truth or falsity of a quantifier-free sentence 0 is to 
form the structure true for 0, then associating a truth value, truth or falsity, with the label of each 
node, starting with the leaves and working toward the trunk. For example, a node labeled (4 V 
3 Except when there's an indication to the contrary, by "true" arithmetical sentence, I shall 
mean an arithmetical sentences true in the standard model.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>The Language of Arithmetic, p. 10 
Any x total function is A, as indeed is any x partial function with a A domain. A set is 
A iff its characteristic function is A. 
Proposition. The following are equivalent, for any set S of natural numbers: 
S is x. 
S is the domain of a Z partial function. 
There is a x partial function f with domain including S such that f(n) = 1 iff n E 
S. 
There is a A relation R such that S = {x: (3y)R([x],y)). 
There is a Z relation R such that S = {x: (3y)R([x],y)). 
S is either empty or the range of a x total function. 
S is the range of a x partial function whose domain is an initial segment of the 
natural numbers. 
S is the range of a x partial function. 
S is either finite or the range of a one-one x total function. 
Proof: The proofs are analogous to the proofs of the corresponding propositions with 
"effectively enumerable" in place of "Z." The only part I want to prove here is that, if S is x, 
then it's either finite or the range of a one-one x total function. If S is x, it has the form {x: 
(3y)@([x],y)}, for some bounded formula @. If S is infinite, we can define a total function with 
range S as follows: 
f(0) = lst(the least z with @(lst(z),2nd(z)). 
f(n+l) = 1 st(the least z such that @(lst(z),2nd(z)) and 1 st(z) is different from all 
the f(i)s with i I n)</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>The Language of Arithmetic 
The language of arithmetic is the language whose only individual constant is "0," whose 
function signs are "s," "+," "a," and "E," and whose predicates are "&lt;" and "=." In the standard 
model, which we call 'bN,"l "0" denotes the number 0, the four functions signs denote the 
successor function, addition, multiplication, and exponentiation, respectively, "&lt;" stands for 
"less than," and "=" stands for identity. More specifically: 
"0" is a term of the language of arithmetic. 
The variables "x,," "x,," "x,," "x,," and so on are terms of the language of 
arithmetic., 
If T and p are symbols of the language of arithmetic, so are ST, (T + p), 
(Top), and (TEP). 
Nothing else is a term of the language of arithmetic, unless it is required to 
be by the three clauses above. 
We have unique readability: every term is built up in a unique way. More specifically, 
for each term o, there is a unique finite labeled tree, called the structure tree for a, with the 
following features: 
The trunk of the tree is labeled with o. 
If a node of the true is labeled by ST, then there is directly beneath it one 
node labeled by T. 
1 We also use "N" to denote the set of natural numbers. I hope that no confusion will 
result. 
2 We'll only use these variables on black-tie occasions. Most of the time, we'll use other 
letters from the end of the alphabet as variables, to avoid proliferation of subscripts.</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>The Language of Arithmetic, p. 12 
We have just witnessed a special case of a general technique, devised by Frege and Godel, 
for turning recursive definitions into explicit definitions. Let us now describe the technique a little 
more abstractly. Recursive definitions of functions of one variable take two familiar forms. (For 
functions of more than one variable, not much changes. The extra variables go along for the ride.) 
The more common form of recursive definition occurs when the value of the function only 
depends on the immediately preceding value of the function. Thus the definition takes the form: 
f(0) = k 
f(n+ 1) = g(n+ 1, f(n)) 
where k is a number and g is a (total) function that is already known. We turn this into an explicit 
definition by stipulating 
f(x) = Y =I,,, 
(3 sequence s)(3m I s)(m is the length of s A (s), = k 
A (for any n with n+l &lt; m, (s),, = g(n+l ,(s)J) A x &lt; m and (s), = y). 
A little more explicitly: 
(3s)(3m I s)(s encodes a sequence of length m A 
s encodes a sequence whose 0th member is [k] A 
(Vn &lt; m)((n + [I]) &lt; m - (3w I s)(3z I s)(s encodes a sequence 
whose (n + [l])st member is w A s encodes a sequence whose nth member is z 
A g((n + [l]),z) = w) A s encodes a sequence whose xth member is y) 
We can write this out a a x formula, once we replace "g((n + [l],z) = w)" by a x formula. 
The other form, which was the form we witnessed above, is where a value of the function 
depends on all the earlier values. For fa function, let f I n be the code number for the sequence</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Tarski&#8217;s Theory of Truth (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/tarski/</lecture_pdf_url>
      <lectureno>18</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>Tarski's Theory of Truth, p. 4 
With Convention T in place, it is possible actually to prove that a proposed definition of 
truth is adequate. You can make a strong case for the Church-Turing thesis, but you can't prove 
it mathematically. For truth, you can provide an honest-to-gosh proof. 
Tarski's theory of truth accomplished three main things. First, he propounded the 
condition of adequacy, Convention T. Second, he established a range of circumstances in which 
the condition could be met. Third, he established a range of conditions under which the condition 
cannot be met. 
Let's turn to the second component. Tarski wanted to provide an explicit definition of 
truth in nonsemantic terms, that is, he wanted to give a biconditional of the form 
(b'x)(x is true - '~(x)), 
where '~(x) doesn't contain any semantic terms, that is adequate in the sense of Convention T. 
For the language of arithmetic, here it is; keep in mind that the hction Den that takes a closed 
term to the number it denotes can be explicitly defined by a formula, so that the arithmetical 
expression we abbreviate Den(x) isn't really a semantic term; also the substitution operation: 
(b'x)[x is true - 
(3 set S of sentences of the language of arithmetic) 
[('d closed term u)(V closed term v)(Triple(g,u,v) E S - Den(u) = Den(v)) A 
(b' closed term u)(V closed term v)(Triple(9,u,v) E S - Den(u) &lt; Den(v)) A 
(b' sentence y)(Pair(lO,y) E S - y B S) A 
(b' sentence y)@' sentence z)(Triple(l l,y,z) E S - (y E S V z E S)) A 
(b' sentence y)(V sentence z)(Triple(l2,y,z) E S - (y E S A z E S)) A 
(b' sentence y)@' sentence z)(Triple(l3,y,z) E S - (y B S V z E S)) A</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Tarski's Theory of Truth 
During the 1920s and early 1930s, scientifically minded philosophers (in particular, the 
positivists of the Vienna Circle) regarded the notion of truth with considerable suspicion, not 
only on account of the liar paradox, but also because the quasi-mystical connection between 
language and the world in virtue of which true statements are true looked like the sort of thing 
properly empirical-minded philosophers ought to avoid. Alfied Tarski1 sought to dispel these 
worries by showing that the notion of truth could be defined in terms of other notations whose 
scientific respectability was unquestioned. Let me qualify that. Tarski didn't define a general 
notion of truth, but rather he showed how, for a large class of languages 'Sf, one could define a 
notion of truth in 'Sf, applicable to the sentences of Sf. The languages involved were all 
formalized languages. As we shall see, the same methods cannot be used to define a notion of 
truth applicable to a natural language. Here we shall illustrate Tarski's methods by defining truth 
in the language of arithmetic. 
A puzzle arises at the outset. Our current understanding of the notion of truth is 
insufficiently clear and precise, so we'd like to clarify the notion by providing a definition in 
terms that we already fully understand. But unless we already fully understand the notion of 
truth, how are we going to know whether the proposed definition actually succeeds? We're 
looking for a corrrect definition of truth, but unless we already understand the notion of truth, 
how will we know when we've found one? 
1 "Der Wahrheitsbegriff in den formalisierten Sprachen," Studia Logica 1 : 26 1-405. 
English translation by J. H. Woodger in Tarski Logic, Semantics, Metamathematics, 2nd 
ed. (Indianapolis: Hackett, 1983), pp. 152-278.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Tarski's Theory of Truth, p. 9 
Knowledge isn't a semantic notion, but knowledge entails truth, and truth is a semantic 
notion. This indirect connection is enough to implicate the notion of knowledge in semantic 
paradox. To see this, let the Unknown Sentence be the following sentence: 
What the Unknown Sentence says is not known. 
What the Unknown Sentence says is that what the Unknown Sentence says is not known.4 
Consequently, 
If it is not known that what the Unknown Sentence says is not known, then 
what the Unknown Sentence says is not known. 
The first principle of epistemology - if it is known that 4 then 4 - gives us this: 
If it is known that what the Unknown Sentence says is not known, then 
what the Unknown Sentence says is not known. 
Putting these two observations together, by means of an inference of the form 
If not-$, then 0. 
If $, then 0. 
Therefore, 0. 
we get this: 
What the Unknown Sentence says is not known. 
4 A rather desperate attempt to evade the paradox would be to say that the Unknown 
Sentence doesn't express a proposition at all. It's a rather short-lived attempt, as we can 
see by examining the Other Unknown Sentence: 
Either the Other Unknown Sentence doesn't express a proposition, or the 
proposition it expresses is not known.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Tarski's Theory of Truth, p. 3 
nonsentences lie outside the extension of "true." But there are plenty of sentences for which we 
don't know on which side of the divide the sentence ought to fall. For example, no one now 
knows whether Goldbach's Conjecture ought to fall into the extension of "true" or outside it. A 
satisfactory definition of "true" will have to adjudicate all the unknown cases correctly, but, 
lacking arithmetical omniscience, how can we know when we've done this? 
To be able to recognize a proposed definition of truth as satisfactory, it is not required 
that we know already which sentences are true. It is enough that we be able to specifl, for each 
sentence, conditions under which it is true. Thus Goldbach's conjecture should be put into the 
extension of "true" if every even number greater that 2 is the sum of two primes, whereas it 
should be lefi outside the extension of "true" if not every even number is the sum of two primes. 
Without knowing which of these two cases obtains, we can nonetheless be sure that: 
Goldbach's Conjecture is true if and only if every even number greater 
than two is the sum of two primes. 
This observation can be extended to a general criterion of correctness of proposed definition of 
truth: 
Convention T. A proposed definition of truth for the language of 
arithmetic is adequate if it implies all sentences of the form: 
(T) r@ is true if and only if 4, 
for 4 a sentence of the language of arithmetic and r@ is Godel number, 
and it also implies "@ir)(x is true - x is a sentence)." 
("Implies" here doesn't mean strictly logical implication. It's permissible to employ basic 
laws of syntax in deriving the (T)-sentences.)</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Tarski's Theory of Truth, p. 11 
"knows,,"and so on, is called "English,." Introduce predicates "true,," "false,," "satisfies,," 
"knows,," and so on applicable to the sentences of English,. "True," can be introduced simply by 
taking the (T)-sentences for English, as axioms. Call the language obtained fiom English, by 
introducing these new predicates "English," and introduce predicates "true,,""false,," "satisfies,," 
"knows,," and so on, applicable to the sentences of English,. This process generates a language 
English ,, which contains all the "true,"s, t false,"^, "satisfies,"~ and "knows,"~ as predicates. 
English, doesn't have global notions of truth and falsity, applicable to the whole language, but 
every sentence of English, is either true,, for sufficiently large n, or false,, for sufficiently large 
n. 
This construction doesn't give a very satisfactory semantic theory for English ,, because it 
leaves out something that's intuitively perfectly obvious, namely, that the true sentences of 
English, are those that are true, for large enough n. And it doesn't give us a theory of truth for 
English at all, because English contains the predicate "true"; it doesn't contain the predicates 
"true,," '?me,," "true,," '?me,," .... 
The liar paradox leaves us in a very unhappy position. As Tarski recognized, the paradox 
shows that one can't develop a semantic theory for a language within the language itself, but only 
within a richer metalanguage. But that means we lack the means to develop a semantic theory for 
a natural language. And without such a theory, how can we understand how human language is 
connected to the world around us?</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Tarski's Theory of Truth, p. 2 
We faced a similar problem when we tried to answer the question, "When is a partial 
function computable by an algorithm?" We don't already have a precise standard of calculability 
- that's what we're looking for - but our intuitive understanding of the notion is sharp enough to 
provide us a large supply of clear examples. However, the examples we have are all one-sided: 
There are plenty of examples of functions that are known to be calculable, and there are 
examples of functions that are not known to be calculable, but we don't have any clear examples 
of functions that are known not to be calculable. (The Halting Problem -- determining whether a 
given algorithm will yield an output for a given input -- is an example of a problem that isn't 
solvable by algorithm, but what we call the Halting Problem is really only the sketch of a 
problem that we can only make precise after we have a precise characterization of calculability.) 
Our proposed answer, that the calculable partial functions are the partial functions, met the 
following conditions: 
Every partial function that is calculable by known methods satisfies the criterion. 
Every partial function that satisfies the criterion is calculable by known methods. 
This leaves open the possibility of discovering some hitherto unsuspected computational 
techniques that will calculate some function that doesn't meet the criterion. One can amass a fair 
amount of evidence to give us confidence that this won't occur, but the evidence doesn't amount 
to anything like a proof. 
How does the situation look for trying to define truth? There are a lot of sentences that 
are known to be true, so that, for example, any proposed definition will have to put Fermat's Last 
Theorem into the extension of "true." There are other sentences that are known to like outside 
the extension of "true"; the negation of the Fermat theorem, for one. Also, we know that all</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Tarski's Theory of Truth, p. 8 
Similar paradoxes afflict other semantic notions, for example, the notion of denotation is 
troubled by Berry's paradox.2 There are only finitely many expressions of English of fewer than 
thirty syllables, so, in particular, there are only finitely many expressions of English of fewer 
than thirty syllables that happen to name natural numbers. Each expression names at most one 
number, so that are only finitely many natural numbers that are named by English expressions of 
fewer than thirty syllables. There are, however, infinitely many natural numbers, so there are 
natural numbers that aren't named by any English expression of fewer than thirty syllables. 
Because the natural numbers are well-ordered, we know that there has to be a least natural 
number not named by any English expression of fewer than thirty syllables. "The least natural 
number not named by any English expression of fewer than thirty syllables" names it is twenty- 
seven syllables. 
The simplest of the semantic paradoxes is Grelling 's paradox,3 which involves the notion 
of satisfaction. Some English phrases satisfl themselves and others do not. "Noun," for example, 
is a noun, so it satisfies itself. "Verb" isn't a verb, so it doesn't satisfl itself. "Polysyllabic," 
being polysyllabic, satisfies itself, whereas "monosyllabic," not being monosyllabic, doesn't 
satisfl itself. How about "does not satisfy itself '? Does it satisfl itself or not? Either answer 
leads to a contradiction. 
2 See Chapter I1 of Alfied North Whitehead and Bertrand Russell, Principia Mathematics, 
2nd ed. (Cambridge: Cambridge University Press, 1927). 
3 This is a slightly different version of the paradox than the one we discussed earlier, and 
it's closer to the original. See Kurt Grelling and Leonard Nelson, "Bemerkungen zu den 
Paradoxien von Russell und Burali-Forti," Abhandlungen der Fries 'schen Schule neue 
Folge 2 (1908): 301-34.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Tarski's Theory of Truth, p. 6 
for each sentence 4 fo the language of arithmetic. In particular, we can use the Godel self- 
referential lemma to find a sentence h of the language of arithmetic such that the biconditional 
(h - -T([ rhl]) 
is a theorem of Q. We have the (T)-sentence 
([rhl] is true - A), 
and the definition of "true" give us this: 
([ rhl] is true - 'G( rhl)). 
This gives us our contradiction. 
We've been working with the language of arithmetic, but the same considerations apply 
to other languages. The general version of Convention T requires that an adequate definition of 
truth for a given object language entail all biconditional obtained fiom the schema 
(TI is true if and only if , 
by filling in the blanks in appropriate ways. The first blank is completed with what Tarski calls a 
"structural-descriptive name" of a sentence of the object language. Structural-descriptive names 
have the property that, if you're given the name of the sentence, you can recover the sentence 
itself. Godel numbers count as structural-descriptive names, as do quotation names. "The first 
sentence below the fold on the left column on the fiont page of the Boston Globe for May 5, 
2002," does not. The second blank is filled in with the sentence's translation into the 
metalanguage. Tarski doesn't say anything about what makes an acceptable translation, which is 
a pity. 
Tarski's technique for constructing an explicit definition of truth can be adapted to a wide 
variety of formal language. The only thing special about the language of arithmetic is that, in it, 
each of the individuals we are talking about is names by some numeral. In situations in which</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Tarski's Theory of Truth, p. 5 
(V sentence y)(V sentence z)(Triple(l4,y,z) E S - ((y E S A z E S) V (y $ S A z $ S))) A 
(V formula y)(V number n)(Triple(l5,n,y) E S - (V number k)(y vn/[kl E S) A 
(V formula y)(V number n)(Triple(l6,nYy) E S - (3 number k)(y vn/[kl E S) A 
x E S]]. 
Showing that this definition is adequate, as prescribed by Convention T, is labor-intensive but 
straightforward. 
The language of arithmetic only talks about numbers, but the definition of truth for the 
language of arithmetic talks not only about numbers and also about sets. There is a sense in 
which truth is defined recursively: The truth conditions for a complex sentence are defined in 
terms of the truth conditions for simpler sentences. However, we cannot apply our usual 
technique for converting recursive definitions into explicit definitions. This technique depends 
on encoding finite sets of numbers by a single number, and the sets of numbers we have to talk 
about in defining truth are infinite. There is, in fact, no way to define the set of true sentences of 
the language of arithmetic within the language of arithmetic. Any definition of truth for the 
language of arithmetic that is adequate in the sense of Convention T must be formulated in a 
language richer in expressive power than the language of arithmetic. This is the third part of 
Tarski's theory of truth, the negative part. 
To prove Tarski's result, suppose, for reduction ad absurdurn, that there is a formula ~(x) 
of the language of arithmetic such that the definition 
(VX)(X is true - ~(x)) 
is adequate in the sense of Convention T. Because it's adequate in the sense of Convention T, 
this definition implies 
(['@I is true - a),</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Tarski's Theory of Truth, p. 10 
Now we reflect that we have reached this result by careful, explicit deduction from securely 
known premisses, and that things we can derive this way are known. That is, 
It is known that what the Unknown Sentence says is not known. 
In other words, 
What the Unknown Sentence says is known. 
Contradiction. This informal derivation can be formalized in much the way that Tarski formalized 
Eubulides' paradox.' A similar derivation can be carried out with necessity in place of 
kn~wledge.~ 
One possible response to these paradoxes, endorsed, in slightly different forms, both by 
Whitehead and Russell and by Tarski, is to divide us the ordinary notions of truth, satisfaction, 
knowledge, and so on, into infinitely many notions. Let English, be the fragment of English 
obtained by excising all semantic terms, together with such semi-semantic terms as "knows" and 
"necessary." (Exactly which terms these are isn't going to be obvious). Introduce notions of 
truth,, falsity,, satisfaction,, knowledge,, and so on, like the familiar notions of truth, falsity, 
satisfaction, and knowledge except that they're applicable only to English,. For truth,, this can be 
done simply by taking all the (T)-sentences for English, (with "true," in place of "true") as 
axioms. The language we get from English,, by adding the predicates "true,," "false,," "satisfies,," 
5 See Richard Montague and David Kaplan, "A Paradox Regained," Notre Dame Journal 
of Formal Logic 1 (1960): 79-90. Reprinted in Montague, Formal Philosophy (New 
Haven: Yale University Press, 1974), pp. 271-85. 
6 See Richard Montague, "Syntactic Treatments of Modality, with Corollaries on 
Reflexion Principles and Finite Axiomatizability," Act Philosophical Fennica 16 (1 963): 
153-67. Reprinted in Formal Philosophy, pp. 286-302</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Tarski's Theory of Truth, p. 7 
not every individual has a name, we can't define truth directly. We have to define truth in terms 
of satisfaction, in a way familiar from Logic I. 
Tarski's negative result also generalizes, leading us to the conclusion that a definition of 
truth for a given object language can never be given within the language itself, but only within a 
richer metalanguage. For formal languages, at least most of them, that's fine; we can give the 
definition in plain English. The problem comes when we try to provide a definition of truth for a 
natural language. How can we give a definition of truth for English, when we don't have nay 
metalanguage richer than English? 
A natural response would be to say that we don't need a definition of truth for English. 
We understand the notion of truth, as it applies to English, well enough without an explicit 
definition. Unfortunately, that reply doesn't shelter us for very long. We may not need an 
explicit definition of truth, but if we want to understand how language works, we at least need a 
theory of truth. If we look at the proof of Tarski's theory on the undefinability of truth, it doesn't 
show us merely that truth is undefinable. It shows us that no consistent theory of truth for a 
language that's formulable within that very language implies the (T)-sentences; indeed, no such 
theory is even consistent with the(T)-sentences. 
Tarski's undefinability theorem is really just the ancient paradox of the liar, dressed up in 
formal wear. The paradox first appeared when Epimenides the Cretan said that Cretans always 
lie. A more direct version is given by Eubulides, who said "This statement is false." There is an 
easy response to Eubulides' paradox: declare that Eubulides' statement is neither true nor false. 
Easy, but short lived, for the paradox reappears if Eubulides says, "This statement is not true."</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Provability Logic (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/provablity_logic/</lecture_pdf_url>
      <lectureno>23-24</lectureno>
      <slides>
        <slide>
          <slideno>7</slideno>
          <text>Provability Logic, p. 8 
By (Ll) and (L3), PA t(~ew([r(o~ V ok V...V a$]) - Bew([i($)]). Since, by (iv),6 PA t(aj 
1 2 
+ B~w([~(o~ V Ok2 V...V o~)'])), PA t(oj + i(n$)). 
1 
If, on the other hand, O$ is false in j, then there is a world k accessible from j in which $ 
is false. By inductive hypothesis, PA t(o, - - i($)). It follows by (Ll) and (L3) that I? 1 
(Bew([ $($)I]) - Bew([r-o,l])), and so PA I(- Be~([~-a~l]) - -i(O$)). It follows by (iii) that 
PA 1 (aj -- i(O$)). s 
Given the Claim, we know that PA t(ol - -i(x)). It follows by (Ll) and (L3) that PA 1 
(Bew([ri(x)']) - Bew([r-all])), and so, by (iii), PA t(a0 - - Bew([G(x)'])). Since, by (v), 0, is 
true, it follows that Bew([ $(x)l]) is false, so that i(x) isn't a consequence of r. 
It remains to find the ajs. Figuring out what formulas to write down took a lot of ingenuity 
of Solovay's part, and I won't attempt to motivate the construction. I'll just write the formulas 
down and verifl that they work. Define a formula f(x,y) as follows: 
If z isn't the Godel number of a formula whose only free variable is "x," f(y,z) = 0. 
Suppose that z is the Godel number of a formula $(x) with "x" as its only free variable We define 
f(y,z) by induction on x: 
f(0,z) = 0 
If f(m,z) = j and m is a proof in I? of $([k]) and Rjk, then f(m+l,z) = k 
Otherwise, f(m+l ,z) = f(m,z). 
If z = q(x)l, then in calculating the value of f(y,z) for different values of y, we start at f(0,z) = 0 
and make ow way down the tree. If, at a certain point, we're at node j and we find a proof of 
'This is where the proof gets stuck for j = 0, since (iv) only applies where 1 I j I n. 
When we turn to the logic of always true formulas, we'll develop a restricted version of the 
Claim that applies to world 0.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>The Logic of Provability 
We want to apply the methods of modal logic to get a better picture of provability. Until 
further notice, I? will be a recursively axiomatized arithmetical theory that includes PA and 
that doesn't imply any false sentences. "Provability" will mean provability in r, and 
"Bew" will abbreviate "BewP" If we understand ''0 4" to mean "Bew([r@])," things like 
Lob's Theorem and the Lob conditions (Ll) to (L3) will convert straightforwardly to principles 
of modal logic. The modal system we get won't be among the most common systems - the most 
common systems all include KT1 - but the methods of modal logic can be hitfully applied to it 
nonetheless. 
An arithmetical interpretation of our language for the modal sentential calculus is a 
function i that associates an arithmetical formula with each modal formula, subject to the 
following constraints: 
i (4 v = (i(4) v i(W) 
i (4 A *) = (i(4) A i(W) 
i (4 + = (i(4) + i(W) 
i (4 ++ *) = (i(4) ++ i(W) 
i(- 4) = - i(4) 
i(O 4) = Bew([ ri(4)'l) 
A modal formula 4 is always provable iff, for each arithmetical interpretation i, i(4) is provable. 
4 is always true iff, for each arithmetical interpretation i, i(4) is true. 
The prominent exceptions are systems of deontic logic, in which "04" is read "4 is 
morally obligatory," and "0~)" is read "4 is morally permissible. We don't live in a morally 
perfect world, so not everything that is true is morally permissible.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Provability Logic, p. 10 
PA tthe greatest element of {f(y,[q(x)l]): y E n} = Ij] - -Bew([q([k])l])), 
whenever Rjk. Putting in -o(x) in place of q(x) gives us (iii). 
Again, take $(x) to be a formula whose only free variable is "x." 
(1 PA 1 Ij] is the greatest element of {f(y,[rq(x)l]): y E N} - (3y)f(y,[rq(x)l]) = 
Ijl). 
All sentences of the form (0 - Bew([@l])), with 0 x, are provable in PA. In particular, 
PA t ((3~)f(~,[ q(x)li) = L~I - ~ew([ r(3~)f(~,[ w(x)li) = tiill)). 
Moreover, 
PA t((3y)f(y,[q(x)l]) = Li] - the greatest member of {f(y,[w(x)l]): y E N} 
is equal either to Ij] or to [k,] or to [k,] or to ... or to [k]), 
where k,, k,, ..., k, are the worlds accessible form j. Applying (Ll) and (L3), we get: 
(1 PA t(~ew([ r(3y)f(y,[rq(x)l]) = Ijll]) - Bew([ The greatest member of {f(y,[ rq(x)l]): 
y E N}is equal either to Ij] or to [Ik,] or to [k,] or to ... or to [k,])l])). 
Putting (), m, and () together, we get: 
PA 1 Ij] is the greatest element of {f(y,[w(x)l]): y E N - 
Bew([The greatest member of {f(y,[rq(x)l]):y E N}is equal either to Ij] 
or to [Ik,] or to [k,] or to ... or to [k,])l])). 
Putting -o(x) in place of q(x), we get: 
($1 PA I(o(til) - Bew([ '(o(ti1) V o([Ik,l) V o(F21) V...V o([k,I))ll))). 
Where 1 I j I n, we have: 
PA t(o(Ij]) -Ij] is the greatest element of {f(y,[r-o(x)l]: y E N}) 
PA t([j] is the greatest element of {f(y,[r-o(x)l]): y E N} - (3y)f(y,[r-o(x)l] = Ij]).</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Provability Logic, p. 1 I 
PA t ((3y)f(y,[ r-o(x)l) = Lil - Bew([ r-cJ(Lil)ll) 
($1 PA t(~(Lil) - Bew([ r-o(LilYl). 
Putting ($) and ($) together, using the fact that the set of provable sentences is closed under the form 
of inference: 
(a V P) 
-a 
:. p 
we get: 
PA t(o(ti1) - Bew([ To(@,]) V V...V a([kI))ll))). 
which is (iv). 
Finally, we want to prove (v): that is, we want to show that the greatest element of 
{f(y, r-o(xY): y E N) is 0. Suppose, on the contrary, that the greatest element is j &gt; 0, and let the 
worlds accessible from j be k,, k,, ..., k. We have, from (iv): 
PA t~(Lil) - Bew([lo([k,l) V o(F21 V -.- V (J([kl)Yl). 
For each i, we have 
PA t(o(k1) - (3y)f(y,[ r-o(xYl = &amp;I) 
Therefore, 
PA t((o([kll) V o(F21) V ... V (J([lml)) - ((~Y)~(Y,[~~(xYI) = [kll V 
(~YI~(Y,[ ro(~)l~) = [k21 v ... v (~YY(Y,[ ro(~)l~) = [LI)). 
If we were assuming that I? were true, instead of merely that it's consequences are all 
true, (v) would be a piece of cake. For j &gt; 0, o(n]) asserts its own refutability, so that, if it were 
true, it would be a true refutable sentences. However, we are not assuming that I? is true, so there 
may well be true sentences that are refutable in I?. So we have more work to do.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Provability Logic, p. 5 
O$ is a subsentence of x that isn't in w*, then there is a v* with R* w* v* that doesn't contain X. 
To do this, we need to show that {-$, O$) u {a: O@ E w*) u (04: O@ E w*) is GL- 
consistent. If we do this, we can take v* to be a member of W* that contains this set. If the set is 
GL-inconsistent, we can find a,, @,, ..., an, with each Oai in w* such that the following sentence 
is in GL: 
((n@l A 41) + (042 A421 +.-.+ (O@n A an) + (n$ + $)).-.)). 
Because GL is normal, the following sentence is in GL: 
(n(n@l A 41) + (00@2 A421 +.-.+ (u(n@n A an) + n(n$ + $)).-.)). 
Because GL includes K4, (El&amp; - El(O@i A @i)) is in GL, for each i, and also, because GL 
includes (L), (O(O$ - $) - O$) is in GL. Consequently, the following sentence is in GL: 
(n@l - (0412 -...- - O$) ...)). 
Because each of the Oais is in w*, Oq is in w*. Contradiction. 
We're still not done. &lt;W*,R*,a*&gt; will be finite, transitive, and antireflexive, but there's 
no reason to suppose that it's branch connected or that every member of W* other than a* is 
accessible fiom a*. We have to tinker with the model to make it a tree. We're going to let our 
"worlds" be finite R*-chains that begin with a*. More precisely, the members of W are nonempty 
finite sequences w of elements of W* that meet these conditions: 
(w), = a*. 
If j+l &lt; the length of w, then R* (w)~ (w)~+~. 
If w and v are in W, Rwv iff v is an extension of w. a is the sequence whose only element 
is a*. If j+l is the length of w, 1(@,w) = I*(@, (w)~). Then &lt;W,R,a&gt; is a tree, and if w is an</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Provability Logic, p. 6 
element of W of length j+l and 4 is a modal formula, 4 is true in w in the model &lt;W,R,I,a&gt; iff 4 
is true in (w)~ in the model &lt;W*,R*,I*,a*&gt;. So x is false in the finite tree model &lt;W,R,I,a&gt;.m 
This theorem gives us a decision procedure for GL. If a sentence is in GL, we can derive 
it, whereas if a sentence is outside GL we can construct a finite tree model in which it's false. 
Now we're ready for the big time. Given a sentence x that's not in GL, we want to find an 
arithmetical interpretation i such that i(x) isn't a consequence of I?. We can find a finite tree 
model &lt;W,R,I,a&gt; in which x is false. It will do no harm if we take W to consist of the numbers 1, 
2, ..., n, so arranged that i &lt; j whenever Rij. Thus a = 1. We expand the model by adding 0 as an 
extra world, stipulating that every other world is accessible from 0 and that I(@,o) = 1(@,1), for 4 
atomic. At the end of the day, when we get ow arithmetical interpretation, world 0 will play the 
role of the actual world, that is, the standard model. The sentences true in world 1 might or might 
not be true in the standard model; we don't want to presume. When we turn to the logic of almost- 
truth, world 0 will play a starring role. 
Our plan is looking for an arithmetical interpretation that reproduces the structure of the 
tree is reminiscent of the strategy we used in seeing how to find an SC sentence with a given truth 
table. What we did there was to find, for each line of a truth table, a sentence, the state 
description, that described that line, then to take our sentence to be the disjunction of the state 
descriptions of the lines at which the given truth table assigns the value "true." Pursuing the same 
plan here, we want to find, for each world j, a sentence oj that describes that world. Once we've 
done that, we can take our arithmetical interpretation to be the hction that assigns to each 
atomic formula the disjunction of the world-descriptions of the worlds in which the formula is 
true. Specifically, we find, for each j I n, a sentence oj meeting these conditions:</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Provability Logic, p. 4 
subsentences of x.~ Since x isn't an element of GL, we can find a set of sentences a* with the 
following properties: 
- x is an element of a*. 
Every member of a* is either a subsentence of x or the negation of a subsentence 
For each subsentence of X, either it or its negation is in a*. 
To form a*, we go through the subsentences of X. When we come to a sentence, we add either it 
or its negation to our set. 
Let W* be the set of all maximal GL-consistent sets of subsentences of x and negated 
subsentences of X. That is, a set of sentences is in W* iff it meets the last three of the four 
conditions above. If w* is an element of W* and 4 is an atomic sentence that occurs in X, we'll 
set I*(@,w*) = 1 iff 4 E w*. The tricky part is defining the accessibility relation R*. Here's the 
definition: R* w* v* iff the following two conditions are met: 
For any sentence 04 that's an element of w*, both 4 and 4 are elements of v*. 
There is a sentence 8 such that 08 is in v*, but 08 isn't in w*. 
The proof that, for any sentence $ that's a subsentence of X, $ is true in w* in the model 
&lt;W*,R*,I*,a*&gt; iff I) is an element of w* is routine, except for one part. We need to show that, if 
The construction we give here, where we hire a finite model to do the job of the 
canonical model, comes up routinely for modal logicians in giving proofs that modal systems are 
decidable. One shows, for example, that KT4 is decidable by showing that, is a sentence is not in 
KT4 then one can construct a finite, reflexive, transitive model in which it's false. An infinite 
model, which is what the canonical fiame provides, does us no good. Our completeness proof for 
GL has a rabbit-out-of-the-hat quality only because we're presenting it in isolation fiom its 
native enviroment in the theory of modal logics.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Provability Logic, p. 3 
Anti-reflection: We never have Rww. 
a is the trunk: If w E W, then either a = w or Raw. 
Branch-connection: If Ruw and Rvw, then either Ruv or u=v or Rvw. 
The paradigm case of a finite true is a nonempty, finite set of finite sequences, with the property 
that every initial segment of a member of the set is a member of the set. Ruv holds if and only if 
v extends u. 
Given an interpretation &lt;W,R,I,a&gt;, with &lt;W,R,a&gt; a finite true, we know from the fact 
that R is transitive that the set of formulas true in every world in the model is a normal modal 
system that includes (4). We want to see that it also includes (L). Let w E W, and suppose that 
04 is false in w. Then there is a world accessible from w in which 4 is false, and hence, 
because W is finite, there has to be a bottommost3 world v accessible from w in which 4 is false. 
q 4 is true in v, and so (0 4 - 4) is false in v, and q (0 4 - 4) is false in w. Hence (0(0 4 
- 4) - 4) is true in every world. We have thus proved the right-to-left direction of the 
following: 
Theorem. A sentence is true in every model &lt;W,R,I,a&gt;, with &lt;W,R,a&gt; a finite 
tree, if and only if it is an element of GL. 
Proof: Suppose that x isn't in GL. We want to construct a model &lt;W,R,I,a&gt;, with &lt;W,R,a&gt; a 
finite tree, in which x is false. The construction we've used in the past, with maximal consistent 
sets of sentences, won't give us a finite tree. To keep everything finite, we don't look at all the 
sentences, but only at the sentences that are either subsentences of x or negations of 
Following the custom of mathematicians, very few of whom were raised on the farm, I 
speak of trees as growing downward, with the trunk at the top and the leaves at the bottom.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Provability Logic, p. 9 
w[k])l, with Rjk, then we jump to node k. Because the tree in finite, the jumping will have to 
come to a halt eventually. 
f is a recursive total function. So we can find encode the recursive definition off as a 
explicit definition, and having done so, we can prove the basic features off in PA. For example, 
applying our skills at supplying numerical codes for finite sets, we can prove that, for each z, the 
function f(y,z), regarded as a function of y, is a nondecreasing total function whose range is a 
subset of {0,1,2, ..., n). The Self-Reference Lemma lets us find a formula o(x) such that 
PA t(b'z)(o(z) - the greatest element of {f(y,[r-~(x)']): y E N) is equal to z). 
PA proves that, for each z, the greatest element of {f(y,z): y E N) is a number between 0 
and n, inclusive. In particular, it proves that th greatest element of {f(y, r-o(xP): y E N) is 
between 0 and n, inclusive. This gives us (i). 
If j + k, PA proves that j and k aren't both equal to the greatest element of {f(y, r-o(xP): y 
E N); this gives us (ii). 
Take a formula q(x) with "x" as its only free variable. If the greatest element of 
{f(y, w(x)l: y E N) is equal to j, then there is an m such that If f(m, w(x)1 is equal to j. If some 
with Rjk were provable in r, then there would be a number p &gt; m that proved q([k]). 
(Note that if a sentence is provable at all, then it has infinitely many proofs, because we can take a 
given proof and pad it out by adding pointless digressions.) So there must be a least p &gt; m that 
proves a sentence $([k]), with Rjk. But then f(p+l, w(x)l) would be equal to k, contrary to 
hypothesis that j is the largest element of {f(y, rq(xP : y E N). SO if j is the greatest element of 
{f(y, w(x)l): y E N), then no $([k]) with Rjk is provable in I?. Formalizing this argument in PA 
gives us:</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Provability Logic, p. 7 
0) PA implies the disjunction of the ojs. 
(ii) PA 1- (aj A 03, for j + k. 
(iii) PA t(oj - - Bew ([ r - a?])), whenever Rjk. 
(iv) PA t(aj - Bew(['the disjunction of the 0,s with Rjkl])), for 1 r j r n.' 
(v) a, is true. 
Defining ow arithmetical interpretation i by stipulating that, for 4 atomic, i(4) is the disjunction 
of the ajs, for j a world in which 4 is true, gives us the following: 
Claim. For any j, 1 I j I n, and any modal formula 4, if 4 is true in j, then 
PA t(oj - i(4)). 
Proof: We prove by induction on the complexity of formulas that, for each formula 4, if 4 is true 
in j, then PA t(oj - i(@)), whereas is 4 is false in j, PA t(oj - - i(4)). If 4 is atomic, then if 4 
is true in j, oj is one of the disjuncts of i(@), whereas, if 4 is false in j, condition (ii) assures us 
that CJ, is provably incompatible with each of the disjuncts of o,. In case 4 is built up from 
simpler formulas by means of the SC connectives, the proof is easy and I won't go through it 
here. Here let's worry instead about showing that the claim holds when 4 has the form O$. 
Let's say the worlds accessible from j are k,, k,, ..., k. If O$ is true in j, then by inductive 
hypothesis, for each h, 1 i h r m, PA 1 (a - i($)). So PA t((akl V % V...V 4) - i($)). kh 
In case there aren't any worlds accessible from j, let me stipulate that I'll take the 
"disjunction" of the ojs with Rjk to be the logically inconsistent sentence "- 0 = 0." So (iv) tells 
us that, if there aren't any world accessible form j, PA t(oj - - Con@')).</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Provability Logic, p. 14 
We now want to show that, for each subsentence 8 of X, if 0 is true in 0, PA t(oo - i(0)), 
whereas if 0 is false in 0, PA t(q, - - i(0)). Since o0 is true, it will follow that i(x) is false, as 
required. 
The proof for 0 atomic is the same as the proof we gave earlier for worlds 1,2, ..., n. The proof 
for 8 a disjunction, conjunction, conditional, biconditional, or negation is routine. 
Suppose that Oqj is true in 0. For each k &gt; 0, k is accessible fiom 0, and so qj is true in k. We 
showed earlier that this shows that PA t(ok - i(qj)). Since qj is true in 1 and the same subsentences 
of x are true in 0 and in 1, qj is true in 0, and so, by inductive hypothesis, PA t(oo - i(qj)). It follows 
that PA t((oo V o1 V...V 03 - i(qj)). Since PA t(oo V 0, V...V 03, we have PA ti(qj). By (Ll), 
PA 1 Bew(['l(qjr]), that is, PA ti(01$), and so PA t(oo - i(Oqj)). 
Now suppose instead that Oqj is false in 0. Then there is a world k &gt; 0 in which qj is false. We 
showed earlier that this implies that PA t(o, - -i(qj)). Applying contraposition, (Ll), (L3), and 
contraposition again, we obtain PA t(-~ew([~-o,l]) - -i(Oq)). Since (iii) gives us PA t(oo - 
-Bew([ r-oc])), PA t(oo - -i(011)) fo1lows.H 
From the equivalence of @ and @ and the existence of a decision procedure for GL, we see 
that there is an algorithm of testing whether a modal formula is always true.</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Provability Logic, p. 12 
Applying (Ll) and (L3) yields: 
PA t pew([ r(o(~li) v ~(R~I) v ... v o([lmi)~i) - ~ew([ r((3~)f(~,[ ro(x~~) = [kll 
v (~YY(Y,[ ro(~)l~) = [k21 v ... v (~Y)KY,[ ro(~)li) = kni) ri)), 
and so 
PA t ~(tii) - ~ew([ r((3~)f(~,[ ro(x)l~) = [kll v (~YI~(Y,[ ro(x)li) = ~~1 v ... 
v (3y)f(y,[ 'o(xY1) = [kml) rl)) 
On the other hand, if j is the greatest element of {f(y, r-o(x)l): y E N), then for none of the &amp;s does 
there exist a y with f(y, r-o(xY) = k, for each of the ks is greater than j. This observation can be 
formalized in PA, yielding: 
PA t(o(tii) - - ((~YI~(Y,[ ro(x~i) = R,I v (~Y)~(Y,[~~(xYI) = [kZ1 v ... 
v (3y)f(y,[ ro(x)ll) = [LI)) 
Consequently, since o(u]) is true, the disjunction ((3y)f(y,[ro(xY]) = [kl] V (3y)f(y,[ru(xY]) = [k2] V 
... V (3y)f(y,[ro(x)l]) = [k])) is logically equivalent to a false sentence provable in I?, contrary to 
hypothesis. H 
We now turn out attention to problem of determining which modal formulas are always true. 
Assuming that r is true, every always-provable formula will be always true, but not every always-true 
formula will be always provable, for all the instances of schema (T) will be always-true, but only those 
with always-provable consequents will be always provable. It turns out that these two observations, 
together with the recognition that the always-true formulas are closed under rnodus ponens, is enough 
to give us a complete inventory of always-true formula. 
Further notice: From now on will the a true recursively axiomatized theory that 
includes PA.</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Provability Logic, p. 13 
Let GLS (for "Godel-Lob-Solovay") be the smallest collection of formulas that includes GL 
and all the instances of schema (T) and is closed under modus ponens. Since all the tautologies are in 
GL, we know that GLS is closed under (TC). 
Theorem (Solovay). Given a modal formula X, let the subformulas of x that begin with 
"0" be Oq,, Oq2, ..., Oqm. The following are equivalent: 
OX E GLS. 
@ (((Oql- ~1) A (0~2 - ~2) A...A (Oqm + qm)) + X) E GL. 
8 x is always true. 
Proof: That @ implies @ and that @I implies @ are obvious, so all we need to show @ implies @. 
Actually, we'll show that the negation of @ implies the negation of @. If the conditional (((Oq, - q,) 
A (Oq2 - q2) A...A (Oqm - qm)) - X) isn't in GL, we follow the same procedure as before to find a 
model &lt;{O,l, ..., n),R,I,O&gt; in which the conditional is false at world 1. We want to show that a 
subformula of x is true in world 0 if and only if it's true at world 1. For atomic formulas, this follows 
immediately from the way we, thinking ahead, stipulated truth values when extending the model to 
include world 0. For conjunctions, disjunctions, conditionals, biconditionals, and negations, the proof 
is easy. If Oqj is true in world 0, then q is true in every world accessible from 0. Since every world 
accessible from world 1 is accessible from world 0, it follows that qj is true in every world accessible 
from world 1, and so Oqj is true in world 1. If, on the other hand, Oq is true in world 1, then qj is 
true in every world accessible from world 1. The only world accessible from 0 that isn't accessible 
from 1 is 1 itself. Since (Oq - qj) is true in 1, qj is true in true in 1, and thus true in every world 
accessible from 0, so that Orlj is true in 0. 
In particular, since x is false in 1, x is false in 0.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Provability Logic, p. 2 
Lob's condition (Ll) tells us that the set of always-provable formulas is closed under 
Necessitation. It follows fiom this that the instances of schema (4) are always true. (L2) tells us 
that they are, in fact, always provable. (L3) tells us that the instances of schema (K) are always 
provable. Since the set of always-provable sentences is closed under (TC), we conclude that the 
set of always-provable sentences is a normal modal system that includes K4. 
Lob's Theorem tells us that all instances of the following schema are always true: 
(L) (n(n 4 + 4) + q 4) 
The proof of Lob's Theorem can be formalized in I?, with the consequence that the instances of 
schema (L) are always provable. If we let GL (for "Godel-LW) be the smallest normal modal 
system that includes both (4) and (L), we see that the set of always-provable sentences includes 
GL. Dick de Jongh has shown that including schema (4) is redundant, so that GL can 
alternatively be characterized as the smallest normal modal system that includes (L). 
The main theorem in provability logic, which was obtained by Robert Solovay: gives an 
exact characterization of the set of always-provable formulas: The class of always-provable 
formulas is GL. 
Before undertaking to prove Solovay's theorem, we need a better characterization of GL. 
Let's say a triple &lt;W,R,a&gt; (where a is an element of W and R is a binary relation on W) is a 
finite tree if it meets the following conditions: 
Finitude: W is finite. 
Transitivity: Whenever Ruv and Rvw, we have Ruw. 
"Provability Interpretations of Modal Logic," Israel Journal of Mathematics 25 (1976): 
287-304. The definitive exposition of provability logic is George Boolos, The Logic of 
Provability (Cambridge: Cambridge University Press, 1995).</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>G&#246;del Numbering (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/goedel_numbering/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>Godel Numbering, p. 4 
The complement of the set of codes of terms is x. It will be helpful to have the following 
definition on board: 
Definition. x ;-y = x - y if x 2 y; 
=Oifx&lt;y. 
Note that x ;-y = z iff ((z + y) = x V (x &lt; y A z = 0)); since this is a bounded formula, ;-is a A 
total function. 
If x isn't the code of a closed term, then, if we try to form the structure tree for x, there 
will a branch that doesn't terminate either in "0" or a variable. Thus, x is not a code of a term if 
and only if there is a finite sequence s with the following properties: 
(s)~ = X. 
If n &lt; length(s) and (s), = Pair(4,y), then n+l &lt; length(s) and (s),, = y. 
If n &lt; length(s) and (s), = Triple(S,y,z), then n+l &lt; length(s) and (s),, is equal to 
either y or z. 
If n &lt; length(s) and (s), = Triple(6,y,z), then n+l &lt; length(s) and (s),, is equal to 
either y or z. 
If n &lt; length(s) and (s), = Triple(7,y,z), then n+l &lt; length(s) and (s),, is equal to 
either y or z. 
If n+l &lt; length(s), then either (s), = Pair(4,(s),,) or (32 &lt; s)(s), is equal to 
either Triple(S,(s),,,z) or Triple(S,z,(s),,) or Triple(6,(s),,,z) or Triple(6,z,(s),,) 
or Triple(7,(s),+,,z) or Triple(7,z,(s),,). 
(s)lenpth(s) T 1 + Pair(1,O). 
-(In &lt; S)(S)~,,~~(~) = Pair(2,n). IXI 
The set of codes of closed formulas is A; just leave off the clause for variables. 
Theorem. The set of pairs &lt;x,y&gt; for which y is a term and x a subterm of y is A.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Godel Numbering, p. 3 
The code for (~+p) is the triple Triple(5, 91, rpl), which we abbreviate r(~ + p)l. 
The code for (TOP) is the triple Triple(6,91, rpl), which we abbreviate r(~ l p)l. 
The code for (T E p) is the triple Triple(7,91, rpl), which we abbreviate r(~ E p)l. 
A number is the code of a term if and only if it is an element of every set S of numbers 
that meets the following conditions: 
Pair(1,l) ES. 
Pair(2,i) E S. 
If x is in S, so is Pair(4,x). 
If x and y are in S, so are Triple(S,x,y), Triple(6,x,y), and Triple(7,x,y). 
Any set that meets these conditions will be infinite, and we can't talk about infinite sets within 
the language of arithmetic. If we want to talk about the set of codes within the language of 
arithmetic, we need to figure out ways to say the things we want to say using only finite sets, so 
that we can take advantage of the fact that finite sets have numerical codes. Such an effort yields 
the following theorem: 
Theorem. The set of codes of terms is a A set. 
Proof. The set of codes of terms in 2. x is the code of a term if and only if it's an element of a 
finite set s with the following properties: 
If Pair(4,y) E s, y E s. 
If Triple(S,y,z) E s, then y E s and z E s. 
If Triple(6,y,z) E s, then y E s and z E s. 
If Triple(7,y,z) E s, then y E s and z E s. 
If y E s, then either y = Pair(1,O) or (In &lt; y)y = Pair(2,n) or 
(In &lt; y)y = Pair(4,n) or (3m &lt; s)(3 n &lt; s)y = Triple(S,m,n) or 
(3m &lt; s)(3 n &lt; s)y = Triple(6,m,n) or (3m &lt; s)(3 n &lt; s)y = Triple(7,m,n). 
The properties the code number of s has to satisfy for these conditions to be met can be 
expressed by a bounded formula.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Godel Numbering, p. 8 
If 4 and q are formulas, the code for (4 - q) is Triple(l3, re, v), which we 
abbreviate r(@ - $)I. 
If 4 and q are formulas, the code for (4 - q) is Triple(l4, re, rql), which we 
abbreviate '(4 - qp. 
1f 4 is a formula, the code for (b'%)@ is Triple(lS,n, re), which we abbreviate 
Tb'rZ34'- 
If 4 is a formula, the code for (I%)$ is Triple(l6,n, r@), which we abbreviate 
'(3rZ3@ 
Theorem. The set of codes of formulas is A. 
The proof is so close to the proof of the analogous proof for codes of terms that there's no real 
point in going through it. Same for the proof that the set of pairs &lt;x,y&gt; with x the code of a 
subformula of the formula coded by y is A. We define structure trees for formulas the way we did 
for terms, and once again we have unique readability. 
Theorem. The function Sub that, for 8 a formula, T a term, and n a natural number, 
takes &lt; alp, to @%lTl is A. 
Proof: First note that the function that, given terms T and a natural number n, takes &lt; r p 1 , n , TI&gt; to 
rpX.1~1 is 2, and hence, as a 2 partial function with a A domain, A. That's so because the value 
the function takes with input &lt; 'pl,n, is equal to z if and only if there is a finite set s with the 
following properties: 
Pair( rp1,z) is in s. 
If y is in s, then lst(y) and 2nd(y) are both in s. 
If Pair(Pair(1 , l),y) is in s, then y = Pair(1,l ,). 
If Pair(Pair(2,i),y) is in s, with i + n, then y = Pair(2,i). 
If Pair(Pair(2,n),y) is in s, then y = 91. 
If Pair(Pair(4,u),y) is in s, then lst(y) = 4 and Pair(u,2nd(y)) is in s.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Godel Numbering, p. 5 
Proof: Where I say "y is a term and x is a subterm," what I really mean is that y is the code of a 
term and x the code of a subterm. Most of the time, I'll neglect this distinction. You'll get used 
to it. 
If y is a term, x is a subterm of y if and only if x is an element of every finite set that 
meets the following conditions: 
y is in the set. 
If Pair(4,z) is in the set, z is in the set. 
If Triple(S,z,w), Triple(6,z,w), or Triple(7,zkw) is in the set, z and w are in the 
set. 
This shows that the set of pairs &lt;x,y&gt; with y a term and x a subterm is n. To see that it's also x, 
note that, for y a term. x is a subtern of y if and only if there is a number s coding a finite set with 
with the following properties: 
y is in the set. 
If Pair(4,z) is in s, z is in the set. 
If Triple(S,z,w), Triple(6,z,w), or Triple(7,zkw) is in tbe set, z and w are in the 
set. 
If t &lt; s is the code of a set containing y with the properties that z is in the set 
coded by t whenever Pair(4,z) is in the set coded by t and that z and w are in the 
set coded by t whenever any of Triple(S,z,w), Triple(6,z,w), or Triple(7,z,w) in in 
the set coded by z, then x is an element of the set coded by t.M 
AJinite tree is a finite set of sequences with the property that any initial segment of a 
member of the set is a member of the set; the statement that s is the code of a fine tree can be 
formalized by a bounded formula. AJinite binary tree is a finite tree consisting entirely of 
sequences of 0s and 1s. Where x is a code of a term, a structure tree for x is a pair Pair(s,f), 
where s is a code of a finite binary true and f is a function with domain the set of elements of the 
set coded by s that satisfies the following properties:</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Godel Numbering, p. 7 
Proof: Den(x) = v iff there is a finite set s with the following properties: 
Pair(x,v) E s. 
If y E s, lst(y) is a closed term. 
If Pair(Pair(1 , 1,), u) is in s, then y = 0. 
If Pair(Pair(4,y),u) is in s, then u &gt; 0 and Pair(y,u 7 1) is in s. 
If Pair(Triple(S,y,z),u) is in s, there there are t and w with Pair(y,t) and Pair(z,w) in 
andwithu=t+w. 
If Pair(Triple(6,y,z),u) is in s, there there are t and w with Pair(y,t) and Pair(z,w) in 
andwithu=t*w. 
If Pair(Triple(7,y,z),u) is in s, there there are t and w with Pair(y,t) and Pair(z,w) in 
S 
and with u = tw. 
This can be formalized by a x formula. Since Den is a x partial function with a A domain, it's 
A.m 
We encode formulas the same way: 
If T and p are terms, the code for T = p is Triple(8, r~l, rpl), which we abbreviate 
rT = pl. 
If T and p are terms, the code for T &lt; p is Triple(9, r~l, rpl), which we abbreviate 
'T &lt; P1. 
If 4 is a formula, the code for -4 is Pair(l0, r@), which we abbreviate r- @. 
If 4 and q are formulas, the code for (4 V q) is Triple(l1, r@, v), which we 
abbreviate r(4 V $)I. 
If 4 and q are formulas, the code for (4 A q) is Triple(l2, re, rql), which we 
abbreviate '(4 A qp.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Godel Numbering, p. 9 
If Pair(Triple(S,u,v),y) is in s, then 1 st(y) = 5 and Pair(u,2ndin3(y)) and 
Pair(v,3rdin3(y)) are both in s. 
If Pair(Triple(6,u,v),y) is in s, then 1 st(y) = 6 and Pair(u,2ndin3(y)) and 
Pair(v,3rdin3(y)) are both in s. 
If Pair(Triple(7,u,v),y) is in s, then 1 st(y) = 7 and Pair(u,2ndin3(y)) and 
Pair(v,3rdin3(y)) are both in s. 
If 0 is an atomic formula, r a term, and n a number, @%/,1 is given by: 
rp = ox"/, 1 = Triple(8, rps/,l, Fox./,'). 
rp &lt; ox"/, 1 = Triple(9, rpX.1~1, ro~/,l). 
To complete the proof, we need to do the same thing with formulas that we just did with terms. I 
won't give the details, which are tedious and don't involve any new ideas.m</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Godel Numbering, p. 6 
f assigns x to the trunk of the tree, &lt; &gt;. 
If y E s and f(y) = Pair(4,z), then y A &lt;O&gt; E s and f(y A &lt;0&gt;) = z, and y A &lt;1&gt; C s. 
If y E s and f(y) = Triple(S,z,w), then y A &lt;0&gt; and y A &lt;1&gt; are both in s, and 
f(y A &lt;0&gt;) = z and f(y A &lt;I&gt;) = w. 
If y E s and f(y) = Triple(G,z,w), then y A &lt;0&gt; and y A &lt;1&gt; are both in s, and 
f(y A &lt;0&gt;) = z and f(y A &lt;I&gt;) = w. 
If y E s and f(y) = Triple(7,z,w), then y A &lt;0&gt; and y A &lt;1&gt; are both in s, and 
f(y A &lt;0&gt;) = z and f(y A &lt;I&gt;) = w. 
If y A &lt;O&gt; E s and f(y A &lt;0&gt;) = z, then either f(y) = Pair(4,z) or 
(3w &lt; s)(f(y A &lt;I&gt;) is defined and equal to w and f(y) = Triple(S,z,w)) or 
(3w &lt; s)(f(y A &lt;I&gt;) is defined and equal to w and f(y) = Triple(6,z,w)) or 
(3w &lt; s)(f(y A &lt;I&gt;) is defined and equal to w and f(y) = Triple(7,z,w)). 
If y A &lt;1&gt; E s and f(y A &lt;I&gt;) = w, then, for some z &lt; s, f(y A &lt;O&gt; is defined and 
equal to z and either f(y) = Triple(S,z,w) or f(y) = Triple(6,z,w) or f(y) = 
Triple(7,z,w). 
If y E s and neither y A &lt;0&gt; nor y A &lt;1&gt; is in s, then either f(y) = Pair(1,O) or 
(3n &lt; s)f(y) = Pair(2,n). 
Unique Readability Lemma. Every (code of a) term has a unique structure tree. 
The most straightforward way to prove this would be to show that the set of terms for 
which there is a unique structure tree contains Pair(1,l) and Pair(2,i), for each i, and that it 
contains Pair(4,y), Triple(S,y,z), Triple(6,y,z), and Triple(7,y,z) whenever it contains y and z. 
Such a proof talks about infinite set of numbers, so it can't be carried out within the language of 
arithmetic. To get a purely aritmetical version of the proof, we have to pick a particular number 
y that codes a term and show that every subterm of y has a unique structure tree, formulating the 
argument in such a way that it only talks about subterms ofl. I won't go through the details. 
Theorem. The function Den that takes a closed term to the number it denotes is A.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Godel Numbering, p. 2 
David Hilbert proposed an innovative solution to this problem. Ordinarily, 
mathematicians study things like points, lines, planes, functions, and numbers, and they use 
mathematical proofs as a means of learning about these things. Hilbert proposed to treat 
mathematical proofs as themselves the objects of mathematical investigation. A new branch of 
mathematics, metamathematics, would study proofs the way geometers study points, lines, and 
planes. The hope would be that an investigation of proofs would enable us to prove that the 
axioms of set theory wouldn't lead to a contradiction. Graph theorists investigate when it is 
possible to find a path fiom one location to another within a complex network of points 
connected by curves. Proof theorists do something similar, looking to see whether there is a path 
leading from the axioms to a contradiction. Russell's paradox has taught us to be wary of proofs 
in set theory. Hilbert thinks we needn't be similarly chary of the proofs produced by proof 
theorists. The difference is that sets are fiequently infinite, and so impossible to display 
concretely or survey fully. Proofs, on the other hand, are finite objects that we can actually write 
out on paper. 
Metamathematics, as Hilbert envisaged, is separate from the rest of mathematics, because 
it studies a different kind of thing fiom the things ordinary mathematicians study. Godel devised 
a method of assimilating proof theory into ordinary mathematics by assigning arithmetical codes 
to the different symbols, thereby turning the question whether a particular sentence is provable 
from a certain set of axioms into an arithmetical question. 
The details of the coding are fairly arbitrary. What we'll see here is one possibility 
among many. We'll begin by encoding terms by ordered pairs and ordered triples. For any x, y, 
and z, Triple(x,y,z) = Pair(x,Pair(y,z)). If w = Triple(x,y,z),then lstin3(w) = x, 2ndin3(w) = y, 
and 3rdin3(w) = z. 
The code for "0" is the pair Pair(1 ,O), which we abbreviate Ql. 
The code for "%" is the pair Pair(2,n), which we abbreviate rql. 
The code for ST is the pair Pair(4,91), which we abbreviate rs~l.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Godel Numbering 
{x: x is a horse) is a collection that has all the worlds horses as elements, and nothing 
else. Thus we have 
For any y, y E {x: x is a horse) if and only if y is a horse. 
Traveler, for example, is a horse, so Traveler E {x: x is a horse). We would expect this pattern to 
hold generally, so that we have: 
For any y, y E {x: x is ) if and only if y is , 
for any way of filling in the blank. 
That's what we'd expect. But now try filling in the blank with "not an element of itself '; 
we get: 
For any y, y E {x: x is not an element of itself) if and only if y is not an 
element of itself. 
Substitute "{x: x is not an element of itself)" for "y," and we get a contradiction: 
{x: x is not an element of itself) E {x: x is not an element of itself) if and 
only if {x: x is not an element of itself) is not an element of itself. 
This is Russell's paradox, one of several set-theoretic paradoxes that shook the 
foundations of mathematics around the beginning of the twentieth century. The reason these 
paradoxes were so disturbing is that, during the last few decades of the nineteenth century, the 
idea of a set had played an increasing role in clarifling and securing the foundations of 
mathematics, particularly the calculus. By making set theory insecure, the paradoxes threatened 
to undo all these gains. 
A strategy for responding to the paradoxes is to adopt, hopefully on a principled basis, 
axioms that restrict the way the blanks can be filled in enough to prevent contradictions but not 
so much as to prevent set theory from playing its useful mathematical roles. That's a good 
questions, but how do we know that our axioms still don't still produce contradictions? The 
axioms are chosen to block the path by which Russell obtained a contradiction, but how can we 
be sure we won't still arrive at a contradiction by some, more devious path?</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Coding Proofs (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/coding_proofs/</lecture_pdf_url>
      <lectureno>9-10</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>Modus Tollens: If you've derived 4 with premise set I? and (- @ - - 4) with 
premise set A, you may write @ with premise set r u A. 
DeJnitional Exchange: You may replace (4 V @) with (-4 - @) or vice versa, 
keeping the same premise set. Similarly for (4 A @) and -(a - -@); and for (4 
* $1 and ((4 - @I A (@ - 4))). 
For a proof that these new rules are a satisfactory replacement for TC, see Benson Mates, 
Elementary Logic (New York: Oxford University Press, 1972). It's not surprising that the Mates' 
system meshes nicely with the rules from Logic I, since the rules for Logic I were lifted fiom his 
book. 
Where 4 is a sentence of St! and I? is a A set of sentences1 of St!, a number s is said to be a 
proof of 4 from I? just in case s is a sequence of ordered pairs &lt;x,y&gt; with the following 
properties: 
x is a code of a finite set n of sentences of St!,. 
y is a code of a sentence @ of St!,. 
Either @ is an element of n (so that @ is derivable from n by rule 
PI) or @ is derivable with premiss set fiom one or more of the 
earlier members of s by one of the rules other than PI. 
The last member of s has r@ as its second component and the code of a subset of 
I? as its first. 
To spell this out in detail, we would have to specifl, rule by rule, what it takes for one line to be 
1 What this really means is that the set of code numbers of members of I? is A. In the 
future, we shall frequently efface the distinction between a sentence or set of sentences 
and its code number. I hope that no confusion results.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Coding Proofs 
What we'd like to do now is to see how to take proofs and code them arithmetically. The 
details are complicated, but the idea is simple. A proof is a sequence of expressions, and we 
know already how to code expressions as a numbers and how to code a sequence of numbers as a 
single number. 
A couple of technical points require attention. The logical system we learned in Logic I 
required an infinite reservoir of infinite constants. It's not hard to give a system of rules that 
doesn't need the constants, but it's even easier to expand our system of Godel numbering to 
accommodate the extra constants. Where 'Sf is the language of arithmetic, let 'Sf, be the language 
obtained from 'Sf by adding infinitely many new individual constants c,, c,, c,, c,,. . . . We can 
extend our system of Godel numbering by letting rc,l be Pair(3,n). That's why we skipped pairs 
and triples beginning with 3 when we gave our earlier Godel numbering for Sf; we were leaving 
room for the new constants. 
Our deductive calculus from Logic I included bunch of simple rules and one very 
complicated rule, Tautological Consequence (TC), which permits you to write down any 
sentence that is either a tautology or a tautological consequence, taking as premiss set the union 
of the premiss sets of those earlier lines. TC is complex enough that it would be a lot of work to 
describe its operation arithmetically. Rather than doing so, we can replace TC with a bunch of 
simpler rules. There are many ways to do this. One method, which is particularly simple and 
which fits seamlessly with the system of rules we learned in Logic I, is to replace the rule TC 
with three new rules: 
Modus Ponens: If you've derived 4 with premise set r and (4 - q) with premise 
set A, you may write $ with premiss set I? u A.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>derived from an earlier line by a rule. For example &lt;x,y&gt; is derived from &lt;z,w&gt; by rule CP iff 
there is a v &lt; y such that y = Triple(l3,v,w) and, for any u &lt; s, u E z iff (u E x or u = v). Going 
through the details helps inculcate the virtues of patience and endurance, but it doesn't inspire 
any intellectual virtues, so we won't do it here. 
What we get is a x formula Br that strongly represents the relation {&lt;s, re&gt;: s is the 
code of a proof of 4 from I')' in Q, and hence in any consistent theory that includes Q. If we 
define a x formula Bewr (from the German "Beweis," for "proof ') by: 
Bewr(x) =D,, (3s)~ Br x, 
we get a formula that weakly represents {x: x is the code of a consequence of I?) in Q and in any 
other o-consistent theory that includes Q. 
In defining "Bewr," we have supposed that I' is a A system of axioms. This looks 
unnecessarily restrictive. In order to have a proof procedure for the set of consequences of a set 
of axioms, it's enough to have a proof procedure for the set of axioms; we don't need a decision 
procedure. To generate the consequences, we need to be reliably able to recognize the axioms; 
we don't have to be able to recognize the nonaxioms. Thus it would appear that we would 
benefit from employing a more liberal notion of provability that allowed us to start with a 2 set 
of axioms, rather than a A set. It turns out that this appearance is illusory, because of the 
2 In writing out the formula that strongly represents proofs in I', we'll use some x formula 
y(x) to strongly represent to set of axioms of I'. There are lots of different x formulas we 
could use to strongly represent I', and the each choice would give us a different formula 
to represent the proof-in-I' relation. In some out-of-the-way comers of logic, this makes a 
difference, but it won't matter for us here. To be hlly explicit, we ought to write "By(X),'' 
rather than "Br," but the mildly ambiguous notation won't do us any harm.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>following theorem: 
Craig's Theorem. Let be a set of sentences. Then there is a A set of 
sentences that has the same consequences as r. 
Proof: If I? is the empty set, it's already A, and we're done. If I? is nonempty, it is the range of 
some A total function, call it f. Let n = {Triple(lS,n,f(n)): n a natural number}. 
n is A. It's obviously 2. To see that it's 11, note that its complement is {z: lstin3(z) + 15 
or 3rdin3 (z) + f(2ndin3(z))}. 
The members of n are all obtained from members of r by prefixing a vacuous universal 
quantifier. The members of are obtained from members of by deleting a vacuous initial 
universal quantifier. So r and n are logically equiva1ent.H</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Defining Exponentiation (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/exponentiation/</lecture_pdf_url>
      <lectureno>25</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Defining Exponentiation 
Here's a loose end that needs tying up. In proving the incompleteness theorems, we took 
the language of arithmetic to include exponentiation among its primitive symbols. This was 
convenient, because it made it easy to encode a finite set of numbers by an single number. It was 
a convenient extravagance, but an unnecessary one. We can prove all our results in a restricted 
version of the language of arithmetic that eliminates "E" from among its symbols and that 
removes (47) and (48) from the axioms of Robinson's arithmetic. 
The proof, which was part of Godel's original paper, makes use of the following 
venerable theorem of number theory: 
Chinese Remainder Theorem (Qin Jiushao). Givenp,, p,, ..., p, 
relatively prime integers &gt; 1 (that is, no two of the pis have a common 
divisor other than I), and given a sequence a,, a,, ..., a,, with each ai &lt;pi, 
we can find a number c such that, for each i, ai is the remainder on 
dividing c by p,. 
Proof: We first show that, whenever q andp are relatively prime, we can find c and d with qc = 
pd + 1. To do this, find the least positive integer r such that there exist c and d with qc = pd + r, 
and assume, for reductio ad absurdurn, that r &gt;1. There are two cases: 
Case 1. r doesn't divide q. Then we can find e &gt; 0 and s with 0 &lt; s &lt; r so that q + s = re . Then 
qce =pde + re, and so q(ce - 1) =pde + s. This contradicts the leastness of r. 
Case 2. r divides q. Then r doesn't dividep, and so we can find f &gt; 0 and t with 0 &lt; t &lt; r so thatp 
+ t = r- Then qcf =pdf + rf, and so qcf =p(df - 1) + t. This again contradicts the leastness of r. 
Now let Q be the product of the pis, and let qi be the quotient of Q divided by p,. Then qi 
and pi are relatively prime, so that we can find ci and di with qi *ci = p,di + 1. Thus the remainder</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Defining Exponentiation, p. 3 
multiplication, into an explicit definition, thereby eliminating multiplication as one of the 
primitive operations of the language. This follows fiom a 1929 theorem of Mojzesz Presburger, 
who showed that there is a decision procedure for the set of sentences of the language with 
nonlogical symbols "0", "s," "+," and "&lt;" that are true in the standard model. Adding "." gives 
us an undecidable theory, so "." must not be explicitly definable.' 
'It is perhaps worth pointing out that "0," "&lt;" and "s" can all be defined in terms of "+." 
"x = 0" can be defined as "(x + x) = x." "x &lt; y" is defined by "(- x = y A (3z)(x + z) = y)." For 
6L sx = y," we use "(Vz)(x &lt; z - ('y = z V y &lt; z))." Thus, for us, the import of Presburger's theorem 
is that you can't define multiplication in terms of addition.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Defining Exponentiation, p. 2 
on dividing qi .ci by pi is equal to 1, and so the remainder on dividing qi .ci.ai by pi is equal to ai. 
Let e be the sum E qj .cj a? pi divides each of the qjs other than q, and so the remainder on 
dividing e by pi is the same as the remainder on dividing qi.ci ai by pi, which is a,EI 
We now define Godel's P-function. Let P(u,v,w) to be the remainder obtained on 
dividing u by (v~w) + 1. P can be defined by a bounded formula in the language of arithmetic. 
For x &gt; 0, we have (xEy) = z if and only if the following formula is satisfied: 
(3u)(3v)((P(u,v,O) = 1 A (Yw &lt;y)P(u,v, sw) = (P(u,v,w) .x)) A P(u,v,y) = 2). 
The right-to-left direction of this characterization is obvious. What is hard is to find u and v that 
verify the left-to-right direction. Given x, y, and z with (xEy) = z, let v = z!, the product of the 
positive integers I z. If s &lt; t I z, then (s-v) + 1 and (t'v) + 1 are relatively prime, since ifp were 
a prime that divided both of them, p would divide (t - s)v, and so, since (t - s) is one of the factors 
of v, p would divide v. But this enables us to conclude that the remainder on dividing (t'v) + 1 by 
p is one, contrary to our assumption that p divides (t'v) + 1. Use the Chinese Remainder 
Theorem to find u so that, for each t I y, xEt is the remainder on dividing u by (t'v) + 1 .Ell 
As long as our sole interest is the language of arithmetic, the fact that exponentiation can 
be treated as defined rather than primitive is a mere technical curiosity. It's practical utility 
comes when we try to show that theories expressed in languages other than the language of 
arithmetic are undecidable by interpreting Robinson's arithmetic into those other theories. If, in 
doing this, we don't have to worry about exponentiation, it makes life a lot easier. 
(47) and (48) are the recursive definition of exponentiation, and we can use Godel's beta 
function to convert this recursive definition into an explicit definition. We cannot take the 
process a step further by converting (Q5) and (Q6), which are the recursive definition of</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>First Incompleteness Theorem (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/1st_incompletens/</lecture_pdf_url>
      <lectureno>15-16</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>Self-reference Lemma, p. 4 
Let's see what happens if we take I? to be the set of sentences of the language of 
arithmetic that we can recognize as true. By this, I don't mean merely the sentences we are able 
to prove in formal system. I mean the sentences we are capable of recognizing as true by any 
cognitive methods available to us. One of those cognitive methods is proof, and indeed we'll 
count a sentence as recognizably true if it is in principle derivable from other sentences that are 
recognizably true, even if the derivation is too complicated for us to carry it out in practice. 
Assuming that I? is x, we can form the Godel sentence for r. We can recognize that 4 is 
true, even though 4 isn't derivable from I?. But wait a minute. I? was supposed to include 
everything we could recognize as true, yet 4 is a sentence we can recognize as true, even though 
it's not a consequence of r. 
The conclusion J. R. Lucasl wants us to draw from this is that the set of arithmetical 
sentences we can recognize as true isn't x. This is a philosophically important conclusion. It's 
fatal for the computational model of mind, which has it that the way to understand the human 
mind is to regard it as a gigantic computing machine. But the consequences go farther than that. 
The workings of the human mind can't even be simulated by a Turing machine. Now the 
operation of any ordinary mechanical device that takes symbolic inputs and yields symbolic 
outputs can be simulated by a Turing machine. This includes mechanical devices made of flesh 
and blood, with a carbon-based central processing unit, as well as devices made of steel and 
1. "Minds, Machines, and Godel," Philosophy 36 (1961): 120-24. The argument is taken up 
by Roger Penrose, The Emperor's New Mind (New York and Oxford: Oxford University 
Press, 1989).</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Self-reference Lemma, p. 7 
Godel sentence is true because we can't be sure that our beliefs are consistent. What we get in 
the end is not a spark of divinity but a counsel to humility. 
Another place that Godel's theorem has caused philosophical consternation is more 
directly concerned with the foundations of mathematics. Before the nineteenth century, 
mathrnaticians weren't insecure about what they were doing. What geometers studied was the 
structure of space (although the extend to which that structure was independent of our ways of 
representing space was controversial). After the advent of non-Euclidean geometry, this way of 
thinking was no longer tenable. Geometers studies many different, mutually incompatible 
systems, and they can't all describe the structure of reality. 
The traditional attitude toward geometry was a version of Aristotelean, as opposed to 
Platonic, realism. According to Plato, mathematical entities exist eternally in a pure realm all to 
themselves, free of the vicissitudes of bodies and sensations. Before birth, our uncorrupted minds 
could perceive them directly, but, now that we are embodied, our mathematical understanding 
consists in recollecting what before we could plainly see. Modem thinkers find this account of 
how mathematical knowledge is acquired implausible, so a central difficulty for mathematical 
Platonists -people who believe that mathematicians study actually existing things that are 
beyond the reach of space and time - is, How can we know about such things, when they don't 
affect us? Also, why are they so usehl scientifically, when they are causally inert? 
Aristotle's version or realism avoided this difficulty. The sense in which Aristotle's 
mathematical objects were "abstract' was different from the sense in which Plato's were. 
According to Aristotle, geometers studied ordinary physical things, regarding them from a 
"abstract"point of view that pays attention to size, shape, and position, but ignores color, texture,</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Self-reference Lemma, p. 2 
Shortly after Godel's proof, Barclay Rosser recognized that the hypothesis of 0- 
consistency was stronger than needed. 
Stronger Corollary (Rosser). Any x set of axioms that includes Q and is 
consistent is incomplete. 
Rosser proved this by constructing a sentence o that is provably equivalent to: 
(~Y)(Y Br [ 'oll + (32 &lt; Y) z Br [" 0 '1). 
The proof looks a lot like the proof that every A set is strongly representable and the proof that 
every x total function is functionally representable. Indeed, the idea of these proofs originated 
with Rosser's proof. Since we have used Rosser's idea to prove the every A set is strongly 
representable, we can prove a 
Still Stronger Corollary (Tarski, Mostowski, and Robinson). There isn't any A 
set that includes the sentences provable in Q and excludes the sentences refutable. 
Note that this implies Rosser's result, since, if I? were complete, then the set of consequences of 
I? would be x, and the complement of the set of consequences of I?, which is {nonsentences) u 
{sentences 0: -0 is a consequence of I?), would also be x.. 
Proof: Suppose D were a A set that includes the sentences provable in Q and excludes the 
sentences refutable. Let 6(x) strongly represent D in Q, and use the Self-Referential Lemma to 
find a sentence q with 
Q tn - - rqll)). 
If is in D, then 6([ TI) is provable in Q, and so q is refutable in Q, contrary to the hypothesis 
that D excludes the sentences refutable in Q. So 'ql must not be in D. Then -6([ rql) is provable</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Self-reference Lemma, p. 8 
weight, smell, and taste. The attraction of such a viewpoint faded dramatically with the advent of 
non-Euclidean geometry. 
Toward the end of the nineteenth century, an alternative conception of what 
mathematicians were doing became prominent. Mathematics isn't "about" anything. What 
mathematicians do is develop the consequences of systems of axioms. Which of those axioms 
are actually useful in describing material reality isn't a question for the mathematician; it's a 
question for the physicist. If there are any ways of interpreting the mathematical language so as 
to make the axioms true, we can be assured that the same interpretation will also satisfy the 
theorems. But whether there are such interpretations is not the mathematician's concern. 
This "formalist" perspective accurately describes what algebraists do. A "group" is 
anything that satisfies the axioms of group theory, and what a group theorist does is to discover 
the properties true of everything that satisfies the axioms. The picture doesn't fit what number 
theorists do. Whatever we take the axioms of number theory to be, there will be further 
statements we can recognize as true - true, that is, in the "intended model" of the language - 
that aren't consequences of the axioms. By showing this is so, the First Incompleteness Theorem 
makes the formalist position difficult to maintain.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Self-reference Lemma, p. 3 
in Q, and so q is provable in Q, contrary to the hypothesis that D includes the sentences provable 
in Q. Contradiction. H 
A theory is said to be decidable iff the set of it's consequences is A. This usage is 
confbsing. If you say that Peano Arithmetic is decidable, you might be making the true statement 
that there is an algorithm for determining whether a sentence is an axiom of PA, or you might be 
making the false statement that there's an algorithm for determining whether a sentence is a 
consequence of the axioms of PA. The established practice is to accept the latter reading, but it's 
a practice that makes for easy mix-ups. It's the result of a common failure to make it clear 
whether by a "theory" one means a set of axioms or the set of consequences of a set of axioms. 
Indulging in the unfortunate usage, we have the following: 
Theorem. No decidable theory is consistent with Q. 
Proof: This is where we use the fact that Q, unlike PA, can be written down as a single sentence. 
If !a were a decidable theory consistent with Q, then {sentences 4: (Q - 4) is a consequence of 
!a) would be a A set that includes the consequences of Q and excludes the sentences refutable in 
Q.H 
Church's Theorem. The set of sentences valid in the predicate calculus 
isn't A. 
Proof: The set of valid sentences is consistent with Q, so it better not be a decidable the0ry.H 
If 4 is the Godel sentence for PA - the sentence that asserts, "I am not provable in PA" - 
then we can recognize 4 as true, even though 4 isn't provable in PA. Consequently, PA doesn't 
include everything we can recognize as true. There is nothing special about PA in this. Replace 
PA by your favorite true theory, and you'll get the same answer.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Self-reference Lemma, p. 5 
plastic with a silicon-based CPU. The human mind has within it some spark of divinity that 
cannot be mimicked by any merely mechanical system. 
Most philosophers have wanted to resist Lucas's conclusion, but there has been no 
consensus what part of the argument to reject. One countervailing idea is this: The mere 
existence of the Godel sentence has no surprising consequences. What makes the Lucas 
argument go is that we can explicitly write down the Godel sentence, and once we have written it 
down, we can recognize its truth. In order for us to write down such a Godel sentence, it is not 
enough that there exist a X set of sentences whose consequences are all the arithmetical 
sentences we can recognize as true. We have to be able to explicitly specify the set. The 
conclusion to be drawn fiom the Lucas argument isn't that there isn't a computer program that 
simulates the operation of the human mind (or, at least, that part of human mental activity that is 
concerned with arithmetic). It's that, if there is such a program, we can't say what it is, or can't 
say with enough precision to write down the program and its Godel sentence. 
While this response resists Lucas's conclusion, it nonetheless takes us some distance 
down the path Lucas has pointed us. If you take an ordinary mechanical device, like a clock or 
an adding machine, we see that it' possible to find out exactly how the de vice works. Simply 
unscrew the back and examine it closely. The practical difficulties that stand in the way of doing 
the same thing for a hum being are immense. But before Godel's theorem we wouldn't have 
thought that in principle it was impossible for a human being to know her own program. It turns 
out, however, that a human being is fundamentally different fiom a mere mechanical device in 
that it isn't possible even in theory for a human being to know her own program, whereas it is</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Self-reference Lemma, p. 6 
possible, at least in theory, to know in detail how a mechanical device works. The spark of 
divinity is still there, albeit in embers. 
One thing to say in response is that, to know what sentences an agent is able to recognize 
as true, it is not enough to know in detail how the agent's mind works. We also have to know 
which arithmetical sentences are true, since in order to recognize a sentence as true, it has to be 
true. The most we can hope to determine just by examining an agent's mental state is what 
sentences the agent regards as true, that is, which sentences she believes. To say which of these 
regardings of a sentence as true ought to count as recognitions of true, we have to know about 
the natural number system as well as about the agent's inner states. For the Lucas argument to 
even get started, we have to take I' be the set of sentences the agent's belief-forming processes 
permit her to regard as true, rather than those she is able to recognize as true. But with that 
emendation, does not the Lucas argument show that, even though it is in principle possible to 
specify the outputs of a purely mechanical system by examining it closely, it isn't possible to do 
the same for the outputs of the human mind? 
Perhaps not. What the First Incompleteness Theorem shows is that, if I? is consistent, 
then the Godel sentence for I? is true. But how do we know that the set of arithmetical sentences 
we regard as true is consistent? Of course, we'd like to hope it's consistent, but you can't expect 
to tell by examining the belief-forming mechanism whether it ever generates a contradiction, for 
the same reason that you can't tell by examining it's program whether a given Turing machine 
will halt. As we shall see in detail when we turn to the Second Incompleteness Theorem, 
consisntent arithmetical theories can't prove their own consistency. We can't be sure that our</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Godel's First Incompleteness Theorem 
First Incompleteness Theorem. If I? is a consistent x set of axioms that includes 
Q, then there is a true sentence that isn't provable in r. 
Proof: By Craig's Theorem, we may assume I? is A. Use the Self-referential Lemma to find a 
sentence @ such that 
Q I(@ - - Bewr([ r@l))- 
If @ were provable in r, then Bewr([r@]) would be a true x sentence, hence provable in Q, 
hence provable in r. But also, since @ and (@ - - Bewr([r@])) are both provable in r, - 
~ewr([r@]) is provable in r. This contradicts the consistency of r. 
Since @ isn't provable in r, Bewr(r@) is false. Hence - Bewr(r@) is true, and @ is 
true. !H 
Corollary. Any x set of axioms that includes Q and in a-consistent is 
incomplete, that is, there are sentences that are neither provable nor refutable in 
the theory. 
Proof: As before, we may take our set I? of axioms to be A. Let @ be the sentence constructed in 
the proof of the first incompleteness theorem. We saw already that @ isn't provable in r. Hence, 
for each m, m is not the code of a proof in I? of r@. Since the formula Br strongly represents 
{&lt;x,y&gt;: x is the code of a proof of y in r} in Q, - [m] Br [ r@] is provable in Q, hence provable 
in r. Since I? is a-consistent, (3y) y Br [ r@] isn't provable in r. That is, Bewr([r@]) isn't 
provable in r and so - @ isn't provable in r.!H 
Because @ isn't provable in r, - @ is consistent with r, and hence (3y)y Br [ r@] is 
consistent with r, even though, for each m, - [m] Br [ r@] is a consequence of r. Consequently, 
I? u {(3y)y Br [r@]} is an example of a consistent, a-inconsistent theory.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Robinson&#8217;s Arithmetic (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/robison_arthmetc/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>8</slideno>
          <text>Robinson's Arithmetic, p. 9 
(12) (Yy)([f(n)l &lt; Y - (32 &lt; y)0([nI,z)). 
(12) is logically equivalent to this: 
(13) (Yy)([f(n) &lt; Y - -W)- WnI,z)), 
which immediately implies this: 
(14) (Yy)([f(n) &lt; Y - -(0([nI,y) A W)- 0([nI,y))), 
that is, 
(15) (Yy)([f(n)l &lt; Y - - o([nI,y))- 
Also, because Q implies 
(16) - &lt; [f(n)l, 
Q implies this: 
(17) (Yy)([f(n)l &lt; Y - l Y = [f(n)l). 
(1 5) and (17) together imply this: 
(18) (Yy)([f(n)l &lt; Y - (o([nI,y) - Y = [f(n)l))- 
(lo), (1 I), (1 8), and (Q11) together imply: 
(19) (Yy)(o([nI,y) - Y = [f(n)l).N 
Robinson's Arithmetic has no intrinsic interrest for us. It's technically usefbl as a means 
of proving some theorems, but it's not independently important. In particular, proofs in Q 
scarcely resemble our intuitive ways of thinking about the natural numbers. We now turn our 
attention to a much stronger theory, Peano Arithmetic, that does a very good job of reflecting the 
ways we reason when we prove things informally about the natural numbers.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Robinson's Arithmetic, p. 3 
and, for each n, 
Q ('v'x)(x &lt; [n+ I] - (X = [0] V x = [I] V . . . V x = [n])), 
every bounded formula is provably equivalent to an quantifier-fiee formula. We eliminate 
bounded quantifiers fiom he outside in, just as before. 
We now see that every bounded sentence is decidable in Q, and so, since Q is true, every 
true bounded sentence is provable in Q. Consequently, every true E sentence can be proven by 
providing a witness. EI 
Corollary. Let r' be a true theory that includes4 Q. Then for each 2 set5 S, 
there is a E formula that weakly represents S in I?. 
Proof: Let S be the extension of the E formula @. If n is in S, @([n]) is a consequence of Q, and 
so a consequence of r. If n @ S, @([n]) isn't true, and so it isn't a consequence of r.EI 
We can strengthen this corollary by employing a new notion: 
Definition. A theory is a-inconsistent iff, for some formula $(x), proves 
(3x)$(x), but it also proves -$([n]), for each n. 
Since an inconsistent theory proves every sentence, every inconsistent theory is a-inconsistent, 
but, as we shall see later, not every a-inconsistent theory is inconsistent. Every true theory is 0- 
consistent, but not every a-consistent theory is true. 
4 To say that I? includes Q, in standard usage, it's not literally required that Q be an 
element of r'. It's enough that Q is a consequence of r. The trouble is that, in standard 
usage, "theory" is ambiguous between a set of axioms and the set of consequences of the 
set of axioms. The ambiguous usage is thoroughly entrenched, so we have to live with it. 
5 As usual, what we say about sets goes for relations too.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Robinson's Arithmetic, p. 5 
Theorem (Rosser). For any A set S, there is a formula that strongly represents 
S in any consistent theory that includes Q. 
Proof: If S is A, then there are bounded formulas @(x,y) and $(x,y) such that (3y)@(x,y) 
weakly represents S in Q and (3y)$(x,y) weakly represents the complement of S. We want to 
put these formulas together to construct a single formula such that the formula weakly represents 
S in Q and its negation weakly represents the complement of S. If we were working with true 
arithmetic rather than Q, we could just take our formula to be (3y)@(x,y), taking advantage of 
the fact that (VX)(-(~~)@(X,~) - (3y)$(x,y)) is true. However, we are working with Q, and 
(VX)(-(~~)@(X,~) - (3y)$(x,y)), though true, might not be provable in Q. So we have to be 
more devious. 
The way our formula 8(x) is constructed is reminiscent of the way we proved the 
Reduction Theorem for effectively enumerable sets. There we had effectively enumerable sets A 
and B, and we wanted to find nonoverlapping effectively enumerable sets C c A and D c B with 
C u D = A u B. The idea was to simultaneously list A and B. If n first turns up in the list for A, 
put n into C, whereas if n first turns up in the list for B, put it in D; ties go to C. The formula 
8(x) that we're trying to produce describes an analogous construction in which, given n, we 
simultaneously try to construct a witness to (3y)@([n],y) and to construct a witness to 
(3y)$([n],y). If our first witness is a witness to (3y)@([n],y), make 8([n]) true, whereas if our 
first witness is a witness to (3y)$([n],y), make 8([n]) false; ties go to truth. 
The little parable I just told isn't part of the proof. The proof consists in writing down a 
formula and verifling that its works. The parable was intended to motivate the choice of 
formula. Here is the formula 8(x):</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Robinson's Arithmetic, p. 2 
This theorem is why Q is worth looking at. Q is of no interest in itself. Our reason for bringing it 
up is that it's a single-axiom theory within which every true E sentence is provable. 
Proof: First, note that, for each m and n, 
0 = [O] 
s[m] = [sm] 
([ml+ [nl) = [m+nl 
([ml l [nl) = [man] 
([mlE[nl) = [mEnl 
are all consequences of Q. An easy induction on the complexity of terms then enables us to 
prove that, for each closed term T, there is a number n such the sentence 
T = [n] 
is a consequence of Q. An induction shows that each number m has this property:' 
(b'n)(m + n - Q 1- [m] = [n] 
A similar induction shows that, for each number n, we have: 
For every m, if m &lt; n, then [m] &lt; [n] is provable in Q, whereas, if m 2 n, 
then [m] &lt; [n] is refutable2 in Q. 
Thus we see that every atomic sentence is decidable3 in Q. It follows immediately that every 
quantifier-fiee sentence is decidable in Q. Because 
Q t(b'X)lX &lt; 0 
1 "I? 14" means that 4 is a consequence of I?. 
2 A sentence is refutable in Q iff its negation is provable in Q. 
3 A sentence is decidable in Q iff it is either provable or refutable in Q.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Robinson's Arithmetic 
We're developing the idea that a set S is 2 iff it's effectively enumerable iff there is a 
proof procedure for S. We now want to see that we can we can take the notion of "proof 
procedure" literally, by treating a proof procedure as a derivation within a certain system of 
axioms. So we now need to look at systems of axioms. 
Definition. Q, also known as Robinson's arithmetic, is the conjunction of the 
following axioms: 
(Ql) (Vx)-x=O 
(42) (VX)@'Y)(SX = SY - x = Y) 
(43) (Vx)((x + 0) = x 
(44) (VX)@'Y)(X + SY) = s(x + Y) 
(Q5) (Vx)(x.O) = 0 
(46) (Vx)(Vy)(x0sy) = ((X~Y) + x) 
(47) (Vx)(xEO) = SO 
(Qg) (Vx)(Vy)(xEsy) = ((XEY).~) 
(Q9) (Vx)- x &lt; 0 
(QlO) (VX)@'Y)(X&lt;SY - (X&lt;Y Vx= Y)) 
(Qll) (VX)(VY)(X&lt;Y V (x= Y V Y &lt;XI) 
As an account of the natural numbers, Q is pitihlly weak. Even the very simplest 
generalizations, like the commutation laws of addition and multiplication, are underivable in Q. 
Nevertheless, we have the following: 
Theorem. Every true sentence is derivable in Q.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Robinson's Arithmetic, p. 7 
(Ql 1) gives us this: 
(7) (Yy)([mI&lt; Y V ([ml= Y V Y &lt; [ml)) 
Combining (3), (4), (6), and (7), we see that 
(8) (Yy)-(@([nI,y) A wz &lt; Y)- *([nI,z)), 
which is equivalent to 
(9) -8([nl), 
is a the consequence of Q, and hence a consequence of I?. 
Proof of (e): If n is in S, then, by (a), I? t8([n]). It follows by consistency that r' $-~([n]). 
Proof of (d): If n isn't in S, then by (b), r' 1- 8([n]). It follows by consistency that r' $ 
8([nI).H 
Definition. A formula o(x,y)finctionally represents a total function fin a 
theory I? iff, for each n, the sentence (Vy)o([n],y) - y = [f(n)]) is a conse- 
quence of I?. 
Notice that, if our theory I? (which includes Q) is consistent, any formula that function- 
ally represents fin I? also strongly represents fin I?. The converse doesn't hold, in general. If 8 
strongly represents fin I?, then, for each m and n, 
(8([nl,[ml) - [ml = [f(n)l 
is a consequence of I?. So we can prove each instance of the generalization: 
(YY)(~([~],Y) - Y = [f(n-l), 
but there isn't any way to put the proofs of the infinitely many instances together to get a proof 
of the generalization. So, whereas Rosser's result gives us, for each A total function f, a formula</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Robinson's Arithmetic, p. 8 
that strongly represents f, that formula does not, as a rule, also functionally represent f. However, 
we can find another formula that does functionally represents f, as we shall now see: 
Theorem (Tarski, Mostowski, and Robinson). For any x total function f, 
there is a x formula that functionally represents S in any theory that 
includes Q. 
Proof: Since any x total function is A, Rosser's result tells us that there is a x formula 0 (x,y) 
that strongly represents fin Q. Let o(x,y) be the following formula: 
(O(x,y) A (Vz &lt; Y)- O(x,z)). 
The proof that o functionally represents fin Q (and hence in any theory that includes Q) is a lot 
like the last proof. Take any n. 
If k &lt; f(n), Q 1- O([n],[k]), and hence Q 1- o([n],[k]). Also, Q 1- [k] = [f(n)], and so 
Q ~((J([~I,FI) - [kl = [f(n)l). Since (VY)(Y &lt; [f(n)l - ((~([nl,~) - Y = [f(n)l)) is provably (in Q) 
equivalent to the conjunction of all the sentences of the form (o([n],[k]) - [Ik] = [f(n)]) with k &lt; 
f(n), we see that 
(10) (VY)(Y &lt; [f(n)l - (o([nI,y) - Y = [f(n)l)) 
is a theorem of Q. 
Since (Vz &lt; [f(m)]) - e([n],z) is provably (in Q) equivalent to the conjunction of all the 
sentences of the form - O([n],[k]), with k &lt; f(n), and since, for each k &lt; f(n), - O([n],[k]) is a 
consequence of Q, (Vz &lt; [f(m)])- e([n],z) is a consequence of Q. O([n],[f(n]) is likewise a 
consequence of Q, so that Q implies o([n],[f(n)]), which is logically equivalent to this: 
(11) (VY)(Y = [f(n)l - (o([nI,y) - Y = [f(n)l))- 
Since Q implies O([n],[f(n)], it also implies</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Robinson's Arithmetic, p. 4 
Corollary. Let I? be an o-consistent theory that includes6 Q. Then for each x set S, 
there is a x formula that weakly represents S in I?. 
Proof: Let S be the extension of (3y)q(x,y), where q is bounded. The argument that, if n is in 
S, then I? t(3y)q([n],y), is the same as above. If n isn't in S, then, for each m, q([n],[m]) is 
false, and so -$([n],[m]) is a consequence of Q, and hence a consequence of I?. It follows by o- 
consistency that (3y)$([n],y) isn't a consequence of I?.H 
We cannot strengthen the corollary still further by replacing "a-consistent" by "consis- 
tent," for it is possible to find a consistent theory that includes Q in which not every x set is 
weakly representable. The proof proceeds by starting with a set K that is x but not A, and by 
enumerating all the formulas with one free variable. We build up our theory I? in stages, starting 
with Q, and at the nth stage adding a sentence to the theory that kills off the possibility that the 
nth formula weakly represents K, maintaining consistency all the while. I won't go into  detail^.^ 
One can, however, show that, if I? is a consistent, x set of sentences that implies Q, then 
every x set is weakly representable in I?. The proof requires machinery we haven't developed 
yet.* 
6 To say that I? includes Q, in standard usage, it's not literally required that Q be an 
element of I?. It's enough that Q is a consequence of I?. The trouble is that, in standard 
usage, "theory" is ambiguous between a set of axioms and the set of consequences of the 
set of axioms. The ambiguous usage is thoroughly entrenched, so we have to live with it. 
7 You can see the details in a very useful little book by Per Lindstrom entitled Aspects of 
Incompleteness (Springer Verlag Lecture Notes in Logic, vol. 10). 
8 Again, see Lindstrom's book.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Robinson's Arithmetic, p. 6 
(3y)(@(x,y) A wz &lt; y)- $(x,y)). 
Let I? be a consistent theory that includes Q. We need to verify the following four 
statements: 
(a) If n is in S, then I? e([n]). 
(b) If n isn't in S, then I? 1-~([n]). 
(c) If n is in S, then I? $-~([n]). 
(d) If n isn't in S, then I? $~([n]). 
Proof of (a): In n is in S, then e([n]) is a true 2 sentence, provable in Q and hence in I?. 
Proof of (b): If n isn't in S, then, for some natural number m, $([n],[m]) is a true bounded 
sentence, and so a theorem of Q. Consequently, 
(1) (Vy)([mI&lt; Y - (32 &lt; y)$([nI,z)) 
is a consequence of Q. So are 
(2) (Vy)([mI&lt; Y - -wz &lt; Y)- $([nl,z)) 
and 
(3) (Vy)([mI &lt; Y - -(@([nI,y) A (Vz &lt; Y)- $([nl,z))). 
Because n isn't in S, for each k, @([n],[k]) is false. Consequently, for each k, -(@([n],[k]) 
A (VZ &lt; @I)- $([n],z)) is true. Therefore, 
(4) (VY)(Y &lt; [ml - -(@([nI,y) A wz &lt; Y)- $([nI,z))) 
is a true bounded sentence, and so a consequence of Q. Also, 
(5) -(@([nI,[ml) A wz &lt; Y)- $([nI,z)) 
is a true bounded sentence, and so a consequence of Q. (5) is equivalent to 
(6) (Vy)([mI = Y - -(@([nI,y) A (Vz &lt; Y)- $([nl,z))).</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Interpretations (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/interpretations/</lecture_pdf_url>
      <lectureno>17</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>Interpretations, p. 6 
from formulas of P. For now, let me ignore this complication and pretend that the formulas of 5l! 
are represented by code numbers that are denoted by numerals in P, just the way we have it in 
the language of arithmetic. 
Let $(x) be a formula of P. The self-reference lemma, applied within the language of 
arithmetic, gives us an arithmetical sentence 4 such that 
Q I($ - (3y)y)(v is the translation into P of [r@] A $(v)). 
Here I am taking advantage of the fact that the function that takes the code number of an 
arithmetical formula to the code number of its translation can be functionally represented by a Z 
formula. Let 0 be the translation into 5l! of 4. Then 
Q t('dy)(y is the translation into P of [r@] - y = [@I). 
Because A interprets Q, 
A t (0 - $( el)). 
Thus the self-reference lemma applies not only to the language of arithmetic but to languages 
into which we can translate the language of arithmetic. 
I have been taking it for granted that the "=" sign of the language of arithmetic is 
translated as the "=" sign of P. This isn't obligatory. We can pick a formula I(x,y) of P to 
translate "x = y," as long as we make sure that our interpreting theory A proves statements that 
correspond to the facts about identity that are used in proving the theorems of r. Specifically, A 
should prove that "I" designates an equivalence relation: 
(W(N(x) - I(x*x)) 
(W@jl)((N(x) A Ny)(v)) - (I(x9y) - IOl,x))) 
(W@ly)(W((N(x) A NOI) A N(z)) - ((I(~*Y) A I(%+) - I(x*z)))</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Interpretations, p. 4 
(~~O)@;C~)(~~~)@;C~)(~X~~WX~)(((X~ = =I A x3 = (xo + ~2)) A 
(x4 = (xo + xl) A X5 = SX~)) - X3 = x5). 
Making the substitutions, we get: 
(~xO)(N(XO) - (vxl)(N(xl) - (vx2)(N(x2) - (vx3)(N(x3) - (vx4)(N(x4) - (~xS)(N(XS) 
-(((S(x1~2) A A(xO~2~ ~3)) A (A(x0~1~4) A S(x4~5))) - x3 = ~5)))))). 
Given an arithmetical theory r and a theory A expressed in $f, we say that A interprets I? 
if A entails each of the following: 
The translation of each of the axioms of I?. 
(3x)@jl)((Nb) A Zb)) - Y = x). 
(Vx)(N(x) - (3y)@i)((N(z) A S(x*z)) - z = Y)) 
O'x)@jl)((N(x) A Nb)) - (3z)@iv)((N(w) A A(X)Y)~)) - w = 2)) 
O'x)@jr)((N(x) A Nb)) - (3z)@iv)((N(w) A M(x,y*w)) - w = 4) 
O'x)@jl)((N(x) A Nb)) - (3z)@iv)((N(w) A E(X)Y)~)) - w = 2)) 
These sentences express the constraints about what's related to what that are built into the 
function-sign notation. 
The following, very weak theory of sets is able to interpret Q: 
(vx)@jl)((vz)(z E x - z E Y) - x = Y) 
(~x)-(~Y)Y E x 
(VX)(V~)(~Z)(~W)(W E z - (w E x V w = y)) 
Let A be a recursively axiomatized theory into which Q can be interpreted. In talking 
about a theory in being "recursively axiomatized," I am presuming that a system of code 
numbers has been assigned to the expressions of Sf is a reasonable way. What will be required of</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Interpretations, p. 3 
It is easy to prove that, for any a, b, c, and d, we have &lt;a.B.&gt; = &lt;c,&amp; if and only if a = c and b = 
d. Once we have the pairing hction, we can get ow formulas "A(x,y,z)," "M(x,y,z)," and 
"E(x,y,z)" by applying our usual method for converting recursive definitions into explicit 
definitions. "L(x,y)" is just "x E y." 
Once we have our translation scheme we translate arithmetical formulas into 9 by the 
following procedure: Given a sentence 4, we eliminate the nesting of hction signs. rewriting 4 
as a logically equivalent formula in which the atomic formulas take one of the following seven 
forms: 
We leave the first of these alone, and we replace the others by "L(x, xj)," "Z(xi)," "S(xi,xj)," 
"A(x3xj,xb)," "M(xi,xj,xb)," and "E(x3xj,xb)," respectively, changing bound variables as needed to 
avoid collisions. Finally, we replace "(Vxi)" and "(3~~)" by "(Vxi)(N(xi) - ...)" and "(3xi)(N(xi) A 
To take an example, let's translate (Q4), "(Vx)(Vy)(x + sy) = s(x + y)." We first find an 
equivalent sentence in which the atomic formulas all have the prescribed form. There are a 
number of ways to do this, but they're all logically equivalent. This is one:</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Interpretations, p. 2 
the numbers less than n. One way to think of it is that we reduce number theory to set theory by 
taking numerals to refer to certain sets. In terms of the reduction, we can say that a number is 
equal to the set of its predecessors. 
"Z(x)" will just be "- (3y)y E x"; this identifies the zero element with the empty set. The 
successor function is represented by the operation that takes x to x u {x), so we set "S(x,y)" 
equal to "@i)(z E y - (z E x V z = x))." "N(x)" will say that x has four properties: 
x is transitive: (Vy)@i)((y E x A z E y) - z E x). 
xis connected: ('dy)@i)((y EXAZ EX) - (y ~zVy=zVz ~y)). 
x is well-founded: (Vy)((3z)(z E y A z E x) - (3z)((z E x A z E y) A 
-(~w)(w~x~w~y~w~z))). 
x contains no limits: (Vy)((y E x A (3z)z E y) - (3z)(z E x A 
(VW)(W E y - (w E z V w = z)))). 
The third conditions is what gives us the principle of mathematical induction. The most 
common formalization of the axioms of set theory has an axiom that says every set is well- 
founded. In the presence of such an axiom, the third clause is superfluous. The fourth clause tells 
us that every number is either 0 or a successor. 
In order express addition, multiplication, and exponentiation set-theoretically, we first 
need a set-theoretic analogue of Pair, a function that encodes an ordered pair of sets as a single 
set.3 For that purpose, we define, for any sets a and b, 
&lt;a.b.&gt;=,,, {{a}, {a.b)). 
The specific function we use was devised by Kazimierz Kuratowski, although the basic 
idea was due to Norbert Weiner. Both their papers are in the van Heijenoort volume.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Interpretations, p. 7 
and it should prove that 'T' is a congruence: 
(vx)Wu)((N(x) A N(u)) - ((Z(x) A Z(u)) - I(x, u))) 
(vx)@jl)(vu)(vv)((N(x) A NOI) A Nu) A N(v)) - (((S(x9y) A S(u9v)) A I(x9u)) 
- IOIA)) 
(~x)W)(~~)(~~)(~V)WW)((N(X) A NO.) A N(z) A N(u) A N(v) A N(w)) 
- (((A (x, y,z) A A (u, v, w)) A (I(&amp; u) A I(y, v))) - I(z, w))) 
(~x)W)(~~)(~~)(~V)WW)((N(X) A NOI) A N(z) A N(u) A N(v) A N(w)) 
- (((M(x, y, z) A M(u, v, w)) A (I(&amp; u) A IO, v))) - I(z, w))) 
(~x)W)(~~)(~~)(~V)WW)((N(X) A NOI) A N(z) A N(u) A N(v) A N(w)) 
- (((E(x, y,z) A E(u, v, w)) A (I(&amp; u) A I(y, v))) - I(z, w))) 
(vx)@jl)(vu)(vv)((N(x) A Nb) A N(u) A N(v)) - ((('(x9u) A IbJv)) A L(xj~)) - 
L(u,v)))</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Interpretations 
The first incompleteness theorem applies not only to the language of arithmetic but to 
other languages into which one can translate the language of arithmetic. The notion of 
"translation" we'll be using comes from Tarski, Mostowski, and Robinson's book Undecidable 
Theories.' Let Ee be a language that includes the first-order predicate calculus and might or might 
not include other logical apparatus as well. We translate the language of arithmetic into St! by 
picking a formula N(x,) of Ee to represent "x, is a natural number," picking a formula "Z(x,)" to 
represent "x, = 0," and picking formulas "S(x,,x,)," "A(xo,xl,x2)," "M(xo,xl,x2)," "E(xo,xl,x2)," and 
"L(x,,x,)," to represent "x, is the successor of x,," "x2 = (x, + x,)," "x2 = (x, *x,)," "x2 = (x, E x,)," 
and "x, &lt; x,," respectively. 
As an example, let us take Ee to be the language of set theory, which is the language 
whose only non-logical symbol is the binary predicate "E" ("is an element of '). Our technique 
for formulating arithmetical statements within the language of arithmetic is due to John von 
Ne~ann.~ We use the empty set, 0, to represent 0, we use {a) to represent 1, we use {a, (0)) 
to represent 2, and so on, representing a number n as the set of the sets that we use to represent 
Amsterdam: North-Holland, 1953. The notion we are developing here is what they call 
relative interpretation. 
An earlier proposal for reducing number theory to set theory, put forward by Ernst 
Zermelo, was to identify0 with the empty set and to identify a successor with the unit set of its 
immediate predecessor, so that we associate 1 with {0],2 with { (0) ), 3 with (((0) ) ), and so 
on. If we're only interested in arithmetic, one suggestion is as good as the other. The reason von 
Neumann's technique has generally been preferred is that it extends seamlessly into the 
transfinite. You can read the papers by Zermelo and von Neumann in Jean van Heijenoort's 
From Frege to Godel (Cambridge, Mass.: Harvard University Press, 1965). The fact that there 
are multiple equally effective reductions of number theory to set theory has been thought to have 
profound and disturbing implications for the philosophy of mathematics. See Paul Benacerraf, 
"What Numbers Could Not Be," in Benacerraf and Hilary Putnams, eds. Philosophy of 
Mathematics, 2nd ed. (Cambridge: Cambridge University Press, 1984).</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Interpretations, p. 5 
this coding, for our purposes here, is that the function that takes an arithmetical sentence to its 
translation be recursive. Another way to express the thesis that A is recursively axiomatized is to 
say that the set of consequences of A is effectively enumerable; this way of putting things 
depends on the Church-Turing thesis. Another way of saying it is that A can be axiomatized by a 
single axiom schema. Here we use a theorem of Robert Vaught4 that a theory in a language built 
from a finite vocabulary into which we can interpret Q is recursively axiomatizable if and only if 
it is axiomatizable by a single axiom schema. 
Given A a recursively axiomatized theory into which we can interpret Q, there can't be 
any recursive set D that includes the theorems of A and excludes all the sentences refutable in A, 
since if there were such a set, the set of arithmetical sentences whose translations are elements of 
D would be a recursive set of arithmetical sentences that included the theorems of Q and 
excluded the sentences refutable in Q. It follows that, if A is consistent, it is incomplete. 
Virtually every known example of an undecidable theory has been obtained this way. 
Our notion of interpretation requires that a formula of the language of arithmetic be 
translated as a formula of 9. It does not require that an arithmetical term be translated as a term 
of 9, since Sf might be a language like the language of set theory, which has no terms other than 
variables. What we can do, however, is to translate arithmetical terms into definite descriptions 
in Sf. For example the numeral "[2]" is translated "(1~)(3y)(3z)((N(x) A NO) A N(z)) A (Z(z) A 
S(z,y) A S(y,x))." We can then use Russell's technique5 to eliminate the definite descriptions 
"Axiomatizability by a Schema," Journal of Symbolic Logic 32 (1967): 473-479. 
"On Denoting," Mind n.s. 14 (1905): 479-493. We talked about Russell's account in 
Logic I.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Second Incompleteness Theorem (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/2nd_incompletens/</lecture_pdf_url>
      <lectureno>20-21</lectureno>
      <slides>
        <slide>
          <slideno>8</slideno>
          <text>Second Incompleteness Theorem, p. 9 
which will appear on a LED display. Using the number k as a code for the state in which the 
numeral for k appears on the LED display, we can treat your transition function as having 
numerical inputs. As you enter the sensory deprivation chamber, a snapshot of your brain is 
taken and fed into a computer, which determines the Godel code of your transition function. The 
Arabic numeral for this code is then flashed on the LED display. Let's say the number is k. Then, 
after you see the display, you'll know the Godel number of the set of arithmetical sentences you 
are willing to accept. It's the output of the function with Godel code k - call it "f' - on input k. 
You'll know your own Godel number. 
Now that you know that you are willing to accept all the members of the set coded by 
f(k), should you also be willing to accept that all the members of the set are true? For each 
sentence in the set, you have good enough reason to accept the sentence, so you have good 
enough reason to accept that the sentence is true. But this doesn't show that you have reason to 
accept that all the sentences in the set are true, since we sometimes find ourselves in a position to 
accept each instance of a generalization without being in a position to accept the generalization. 
If you are in a position to accept the thesis that all the members of f(k) are true, the evidence that 
leads you to accept it will be psychological, not mathematical. Observing the LED didn't give 
you any new mathematical insights. What it told you, assuming you trust the instruments, is 
something about your psychological states. The question is, now that you know the 
psychological fact that you are willing to accept all the outputs of f(k), does this give you good 
reason to accept that all the outputs of f(k) are true? 
I can imagine you reasoning like this, "I know that I am careful, methodical, and clever, 
and that I don't accept things without good reason. I'm not the sort of person who makes</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Second Incompleteness Theorem, p. 10 
mathematical mistakes. So I can be confident that the things I am willing to accept are true." I 
hope you don't reason this way, because to me it sounds terribly arrogant. And, indeed, such 
arrogance is promptly punished. If you accept that a the things you are willing to accept are true, 
you'll be willing to accept that the things you are willing to accept are consistent, and this 
means, by the Second Incompleteness Theorem, that the things you are willing to accept are 
inconsistent. 
You might try to overcome the accusation of arrogance by adopting higher standards of 
acceptance, taking advantage of the fact that "willing to accept" is a vague term. "Most of the 
time," you will admit, "I am as error prone as the next fellow. But right now, when I talk about 
'accepting' an arithmetical statement, I mean that I am willing to embrace the statement under 
the very highest standards of meticulous mathematical rigor. That's how I'm using the word 
'accept' here, and I have programmed the transition-function-recognition program to reflect this 
high standard of rigor. Surely, if I have such elevated epistemic criteria, I can be confident that 
the things I am willing to accept are true." The trouble is that, while adopting these very high 
standards does indeed make it more reasonable to believe that they things you are willing to 
accept are true, this belief in your own veracity, while reasonable, isn't secure enough to pass 
your very high standards. Raising standards makes it harder for your beliefs to count as 
"accepted," including your belief that the things you accept are true. 
In the end, I think the moral to be drawn fiom the Lucas-Penrose argument is a lesson in 
humility. We human beings are highly fallible, and we can't be sure, even when we're reasoning 
carehlly, that the things we accept are true, or even consistent.</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Second Incompleteness Theorem, p. 13 
Leon Henkin was curious what would happen if, instead, you constructed a sentence that 
asserted its own provability in PA. Would such a sentence be provable? Would it be true? Lob 
answered Henkin's question by showing that, if 4 is a sentence that asserts its own provability in 
PA, so that 
PA Be~r([~@l)), 
then 4 is provable in PA (and so true). Lob sent his paper to the Journal of Symbolic Logic, 
which sent it to Henkin to referee. Henkin noticed that Lob's proof only used the right-to-left 
direction of the hypothesis. Thus Lob's Theorem, as we have it today, was born. Here is Lob's 
proof: 
Proof (Lob): Given 4, use the Self-Referential Lemma to construct a sentence 6 such that: 
(9 I' t(6 - (Bewrt[ r6a - 4)). 
(i) yields this, by sentential calculus: 
(ii) I' I@ + (Bewrtr r611) + 4))- 
(Ll) gives us this: 
(iii) I' t~ewr([ r(6 + (Bewr([ r6'1) + 4)YI). 
Two applications of (L3) give us this: 
(iv) I' t(~ewr([~6'1) + (~ewr([~ewr([~6'lYl) + Bewr(['@l))). 
(L2) yields this: 
(v) I' t(~ewr([~6'1) + Be~r([Bewr([~6'lYl)). 
By a truth-functional inference of the form</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Second Incompleteness Theorem, p. 14 
(a - (P - Y)) 
(a - P) 
:. (a - y) 
we derive: 
(vi) I' t(~ewr([ '&amp;I) - ~ewr([ '@'I))- 
Assume, as the hypothesis of Lob's Theorem: 
(vii) I' t(Bewr(['@'l) - 0). 
(vi) and (vii) give us this: 
(viii) I' t(Bewr(['6'1) + 9) 
(i) and (viii) give us: 
0x1 r 1s. 
Using (Ll), we derive: 
(XI r Isewr([ r611). 
(viii) and (x) give us: 
(xi) I? 10, 
as required.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Godel's Second Incompleteness Theorem 
Let r be a recursively axiomatized theory that includes Q. The proof of Godel's first 
incompleteness theorem proceeded by constructing a sentence o such that 
(1) (0 Bewr([ro I])) 
is a theorem. Having this, it was straightforward to prove the following: 
(2) If r is consistent, then o isn't provable in r. 
We can formulate this result withing the language of arithmetic. Using "Con(r)" to abbreviate 
"- Bewr([r- 0 - 0 I])," we formalize (2) as: 
(3) (Con(r) - - Bewr([r I])). 
(1) and (3) together give us: 
(4) (Con(r) - o). 
Provided that r includes PA, we can formalize the derivation of (4) within r. Hence we have: 
(5) Bewr([ r(Con(r) - ~)l]). 
Because the set of theorems of r is closed under modus ponens, (5) gives us: 
(6) {Bewr([rCon(r)l] - Bewr([rol])) 
(3) and (6) together tautologically imply: 
(7) (Con(r) - - Bewr([rCon(r)l])). 
Thus we have: 
Second Incompleteness Theorem. No consistent, recursively 
axiomatized theory that includes PA can prove its own consistency. 
Proof: I don't really want give a proof of (9, which would be unbearably long and boring. I'll 
be content with a sketch. The proof depends on three principles, which were first singled out by 
M. H. Lob:</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Second Incompleteness Theorem, p. 7 
Theorem, that I? is inconsistent. This puts a limitation on our capacity for self-knowledge. 
Assuming the set of arithmetical sentences we accept is consistent, we can't consciously accept 
the set of arithmetical sentences we accept. Perhaps we consciously accept each finite subset of 
the set of arithmetical sentences we accept, but we won't consciously accept the whole thing. 
There are a couple of ways this could happen. The most likely scenario is that we aren't 
sufficiently aware of our own mental state to be able to identifl the set of arithmetical sentences 
we accept. This is, it seems to me, the normal human condition. 
We can, however, imagine science-fiction cases in which a futuristic brain scan reveals to 
us exactly which sentences we accept by, as it were, discovering our brain's wiring diagram. 
Arranging it that, at a particular time, we know a Godel code1 of the set of arithmetical sentences 
we are willing to accept at that time is not entirely straightforward, even if the have the full 
medical resources of the starship Enterprise at our disposal. The trouble is that our arithmetical 
beliefs aren't entire the product of apriori cogitation. Some of our arithmetical beliefs we have 
because of sensory experiences we've had, for example, hearing a lecture or reading a book, and 
we may expect that our beliefs will change in the future on the basis of new sensory experiences. 
In particular, if a computer analysis of a brain snapshot taken at time t,, tells me that the set of my 
arithmetical sentences I accept has Godel code k, I might respond to this knowledge by accepting 
that the set of sentences with Godel code k is consistent. But this won't mean that I believe a set 
of sentences that implies its own consistency. Instead, the set of my arithmetical beliefs at a later 
time t,, after I've seen the computer printout, includes the statement that the set of sentence I 
1 We may that the Godel code of a recursively enumerable set to be the Godel number of a 
E formula that has the set as its extension.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Second Incompleteness Theorem, p. 11 
Let us return our attention to the case in which our theory I? is something like Peano 
arithmetic, that we consciously accept. That means that we not only suppose that the members of 
I? are consistent; we believe that they're true. Of course, the statement that the members of I? are 
true, unlike the statement that I? is consistent, isn't something that we are able to express within 
the language of arithmetic. But our belief that I? is true will have repercussions for what purely 
arithmetical sentences we are willing to accept. For a given arithmetical sentence 4, we might or 
might not know whether 4 is true, but we will know, because we regard all the members of I? as 
true and we recognize that all the consequences of a true theory are true, that, if 4 is a 
consequence of I?, 4 is true. That is, we are willing to accept all of the so-called Reflection 
Axioms: 
(Bewr([ r@l) - 4)- 
The Reflection Axioms are called that because we get them, not directly from I?, but by 
reflecting on the fact that I? is a theory that we are willing to acknowledge as true. 
The Reflection Axioms are statements we are willing to accept in virtue of our conscious 
willingness to accept I?. Which of them are actually consequences of I?? Well, of course, if 4 is 
a consequence of I?, then the conditional (Bewr([r@]) - 4) is a consequence of I?, since you 
can prove a conditional by proving its consequent. It turns out that these are the only Reflection 
Axioms that are provable in I?: 
Lob's Theorem. If is a recursive set of sentences that includes PA, 
the Reflection Axiom (Bewr([r@]) - 4) is a consequence of I? only if 
4 is a consequence of I?.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Second Incompleteness Theorem, p. 4 
We want to show that, if is consistent, Con(r) isn't provable in r. Equivalently, we want to 
show that, if Con(r) is provable in I?, then I? is inconsistent. Toward this end, suppose that 
0 r 1 con(r). 
(j) and (k) yield: 
(1) r 10. 
By (Ll), we get: 
(m) t~ew~([r~l]). 
(a) and (m) give us: 
(n) r 1- O. 
(1) and (n) show us that I? is inconsistent, as requiredB 
The First Incompleteness Theorem was a little disappointing. Sure, it did what it was 
advertised as doing, giving us a true, unprovable sentence. But the sentence it gave us was an 
out-of-the-way statement that, apart from its appearance in the First Incompleteness Theorem, no 
one would ever have been interested in. The theorem left open the possibility that there aren't 
any interesting statements that aren't provable in PA. 
With the Second Incompleteness Theorem, our disappointment dissipates, for we 
certainly are interested in knowing whether our theories are consistent. Thus Con(PA) is an 
important truth that isn't provable in PA. 
We've proved the Second Incompleteness Theorem for the language of arithmetic, but 
the same proof will work for any language into which we can translate the language of 
arithmetic. In particular, we can prove that, if axiomatic set theory is consistent, then it cannot 
prove its own consistency. This discovery stopped Hilbert's program dead in its tracks. Hilbert</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Second Incompleteness Theorem, p. 8 
believed at an earlier time to is consistent. To arrange things so that, at a particular time, we have 
a code of the set of arithmetical sentences we are willing to accept at that time, we have to be 
more devious. 
A complete circuit analysis of your brain ought to tell you, not only what sentences you 
accept, but what sentences you would accept in response to various sensory inputs you might 
have in the future, in the same way that a complete circuit analysis of an adding machine would 
tell you how the machine would respond to various possible combinations of keystrokes. It will 
provide you with a detailed description of a hction f, such that, for any possible sensory input i, 
f(i) is a Godel code of the set of arithmetical sentences you will accept after experiencing i. Call 
this hction f your transition f~nction.~ 
There's no telling how new sensory inputs will affect your mental states. Perhaps the 
song of a mockingbird will awaken an erstwhile dozing corner of your brain an enable you to 
enjoy a mathematical insight that would otherwise have been unavailable. We are trying to show 
that, if the clockwork model of the mind is correct, it is theoretically possible, with enough 
effort, resourcefulness, and technical firepower, for you to put yourself in a position in which 
you know a Godel code for the set of arithmetical sentences you are willing to accept. To that 
end, let's try to minimize the effects of random disturbances like mockingbird calls, and focus 
our attention on the question how to accommodate the fact that, typically, learning your mental 
state is going to change your mental state. So suppose that you are put into a sensory deprivation 
chamber, where the only sensory stimulation you are in a position to enjoy is an Arabic numeral, 
2 To keep things tolerably simple, I am supposing that your brain is deterministic. In real 
life, the jury is still out on this, or so I understand.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Second Incompleteness Theorem, p. 5 
hoped to prove the consistency of the axioms of set theory in a system much weaker than 
axiomatic set theory. It turns out that (assuming axiomatic set theory is consistent) proving its 
consistency will require a theory stronger than axiomatic set theory. So if you're worried about 
the consistency of set theory, you won't get a consistency proof that helps. 
By using interpretations, we can extend the proof of the Second Incompleteness Theorem 
to theories like the Zermelo-Fraenkel axioms for set theory, theories that are substantially richer 
than PA. We can use the same technique to extend the proof to theories that are substantially 
weaker than PA, like Q. We cannot prove the Second Incompleteness Theorem for Q directly, by 
proving analogues to (L1)-(L3), with "BewQ" in place of Bew,,." To prove (L2), we need 
induction, and in Q we don't have induction. To obtain the Second Incompleteness Theorem for 
Q, and for other theories that include Q, one has to be more devious. We first produce a theory I? 
that, although weaker that PA - it's obtained from PA by restricting the induction axiom schema 
- is nonetheless strong enough to prove Second Incompleteness Theorem. Next, we interpret I? 
into Q by giving a translation that leaves the nonlogical terms alone but suitably restricts the 
quantifiers. If we had a proof of CON(Q) in Q, we could get a proof of CON(I?) in r. The details 
of the proof, which is mainly due to Alex Wilkie, are delicate, and all I can do here is give you 
the URL for Sam Buss's web site, where you can find the proof written out; it's 
http://www.math.ucsd.edu/-sbussResearchWeb/handbooldI/index.html. 
Refocusing our attention on PA, if we think a sentence 0 is true, we'll think it's 
consistent; that is, we would expect to have the following: 
(Y ' Con({y 1)-</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Second Incompleteness Theorem, p. 12 
We can derive the Second Incompleteness Theorem as a special case of Lob's Theorem 
by setting 4 equal to " - 0 = 0." Conversely, we can derive Lob's Theorem from the Second 
Incompleteness Theorem. That wasn't the way Lob proved the theorem initially; it's a later 
proof, due to Saul Kripke. 
Proof (Kripke): The key fact we use is that, for any Jr and 8, Bewr([qJr - 8)1]) is provably 
equivalent to Be~~~{~,([@l]). This is easy to see. If we have a derivation of (Jr - 8) from I?, we 
can get a derivation of 8 from I? u {Jr) by adding Jr as a line by Premise Introduction, then 
adding 8 by Modus Ponens. If, conversely, we have a proof of 8 from I? u {Jr), we get a 
derivation of (Jr - 8) from I' by Conditional Proof. 
We prove Lob's theorem by proving its contrapositive, that is, by assuming that 4 isn't a 
consequence of I? and deriving that consequence that (Bewr([r@]) - 4) isn't a consequence of 
I?. Since 4 isn't a consequence of I?, I? u {- 4) is consistent. It follows from the Second 
Incompleteness theorem that I' u {- 4) doesn't prove its own consistency, so that we have: 
r u 1- 4) $con(r u 1- $1). 
I? u {- 4) $- ~ewr,,{-~,([~ - 0 = 0'1). 
I? u {- 4) $- Bewr([r(- 4 - - 0 = 0)ll). 
I' u {- 41 $-~ewr([ '@I) 
(because (- 4 - - 0 = 0) and 4 are provably equivalent). 
I?$(- 4 + -Be~r([~@l))- 
$(~ewr([ '@I) - $)-m 
The way Lob's Theorem came about was this: Godel constructed a sentence that asserted 
its own unprovability in PA, and he showed that that sentence was true but unprovable in PA.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Second Incompleteness Theorem, p. 3 
Now that we have (L1)-(L3), we want to see how to utilize them to get the Second 
Incompleteness Theorem. The Self-Referential Lemma gives us a sentence o such that 
(a) I? 1 (0 - - Bewr([r~l])). 
We have, 
(b) I? 1 (0 - - Bewr([r~l]))). 
(Ll) lets us derive: 
(c) I? t~ew~([r(o - - Bewr([r~1]))1]). 
Applying (L3), we get: 
(dl I? t(~ew~([r~l]) - Bewr([r- Bewr(['ol])l])). 
(L2) gives us this: 
(el t(~ewr([~oll) - Bewr([Bewr([ roll)ll)) 
(- Bewr([r~l]) - (Bewr([r~l]) - - 0 = 0)) is a tautology, hence a theorem of I?, so that by (Ll) 
we have: 
( f) I? t~ew~([r(- Bewr([rW]) + (Bewr([rW]) - - 0 = O))7]). 
Two applications of (L3) give us: 
(g) I? t(~ew~([r-~ew~([r~])7]) + (Be~~([Bew~([~0~])7]) + 
Bewr([r- 0 = 011))). 
(d), (e), and (g) yield, by truth-functional logic: 
(h) I? t(~ew~([r~l]) - Bewr([r- 0 = 011)). 
(9 I? t(Con(I?) - - Bewr([ roll)), 
using the definition of "Con." This and (a) give us: 
(i I? t(~on(I?) - o).</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Second Incompleteness Theorem, p. 6 
All instances of this schema are, in fact, provable in PA. The proof isn't easy, and I won't 
attempt it here. It follows that, if the theory I? is finitely axiomatized, it proves its own 
consistency. Consequently, by the Second Incompleteness Theorem, if I? is finitely axiomatized 
and it includes PA, then I? is inconsistent. Thus we have the following: 
Theorem (Ryll-Nardzewski). No consistent theory in the language of 
arithmetic that includes PA can be finitely axiomatized. 
This theorem is not as resilient as most of the results we have been studying, which generalize 
from the language of arithmetic to other languages into which you can translate the language of 
arithmetic. Ryll-Nardzewski's theorem, and the schema (y - Con({y))) that backs it up, are 
brittle. They hold for the language of arithmetic, but they don't necessarily hold for other 
languages that include the language of arithmetic. 
Let us say - this is a little vague, but bear with me- that we consciously accept an 
arithmetical theory I? if, upon reflection, we are willing to agree that all the members of I' are 
true. (Keep in mind what we learned from Tarski, that, whereas the general notion of truth is 
philosophically suspicious, truth in the language of arithmetic is unexceptionable.) If we think 
that all the members of I? are true, then we must surely think that I? is consistent, since we know 
the Soundness Theorem, which tells us that the members of an inconsistent set of sentences can't 
all be true. Thus if I? is a recursively axiomatized set of sentences that includes PA, then if we 
consciously accept I?, we'll accept Con(I?). 
Let I? be the set of arithmetical sentences that we are, upon careful reflection, willing to 
accept. Assuming, pace Lucas and Penrose, that we I? is effectively enumerable, that if we 
consciously accept I?, then we'll accept Con(I?), which means, by the Second Incompleteness</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Second Incompleteness Theorem, p. 2 
(L1) If I? 14, then I? tBewr([r@]). 
(L2) t(~ewr([~@l) + Bewr([Bewr([ r@l)'l)). 
(L3) t(~ewr([ '(4 - $)'I) - (Bewr([ '@I) - Bewr([ W'l))). 
(Ll) we proved earlier, when we showed that "Bewr(x)" weakly represents { r@ : 4 is a 
consequence of I?) in Q. This tells us that, if I? 14, then Q t~ew~([r@]), and so, since I? 
includes Q, I? t~ew~([~@]). 
(L2) is the formalized statement of (Ll). To prove it, we formalize our proof that every 
true x sentence is provable in I?. First we show, by induction on the complexity of terms, that, 
for each term T(x1 ,. . .,%), 
I? t(vzl)...(vG)w%+l)(~(zl,...,4 = G+l - 
Bewr([T(xl, ...%) = %+,I 1 %+I/ /[Zl1~~~~~~%1 [%+ill)). 
Next show, by induction on the complexity of bounded formulas, that for each bounded formula 
$(~1,...,%), 
t(v~l)...(v~)($(zl,... ,GI - ~ewr([ r$(~~~~~~~~xl~[Zll~~~x"~~~ll~~~ 
Next, prove the same thing for $ a x formula, by induction on the length of the initial existential 
quantifier prefix. The key fact we need is that our rules of proof include Existential 
Generalization. Because Bewr(x1) is a formula, a special case of this principle will be: 
(vzl)(~ewr(zl) - Bewr([ ~ewr(xl)'X1/[zllI)). 
We get (L2) by instantiating with [r@]. A detailed proof would be quite laborious. 
To prove (L3), simply note that, if we have proofs of (4 - $) and 4, we get a proof of $ 
by taking the two proofs together, then adding $ at the end by the rule Modus Ponens. All we 
need to know is that the arithmetical concatenation operation works properly.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Peano Arithmetic (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/peano_arithmetic/</lecture_pdf_url>
      <lectureno>11-12</lectureno>
      <slides>
        <slide>
          <slideno>9</slideno>
          <text>Peano Arithmetic, p. 10 
(TI 
We have 
((Vy)(y &lt; sz - Ry) - (z &lt; sz - Rz)). 
Since "z &lt; sz" is a consequence of (Q1 I), (T) follows immediately. 
Plug in "- Qx" in place of "Sx" in the strong induction schema, and you get a schema 
logically equivalent to the following: 
((3x)Qx - (3x)(Qx A (VY &lt; - QY)). 
This schema is a formalized version of the well-orderingprinciple: Every nonempty collection 
of natural numbers has a least element. 
The induction axiom schema is a formalized version of the 
Principle of Mathematical Induction. Any collection that contains 0 and 
contains the successor of any natural number it contains contains every 
natural number. 
This principle is central to out reasoning about the natural numbers. A reason for this 
centrality is singled out in the following: 
Theorem (Richard Dedekind). Any two models of Q that both satisfl the 
principle of mathematical induction are is om or phi^.^ 
2 An isomorphism fiom a model U to a model 23 of the language of arithmetic is a bijection 
f fiom IUI to 1231 that satisfies the following conditions: 
f(03) = oB. 
f(ser(x)) = sB(f(x)). 
f(x y) = f(x) +% f(y).</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Peano Arithmetic, p. 5 
= ((x*~) + (x + SY)) [by (4411 
= (((xmy) + x) +sy) [by Proposition 51 
= ((x*sY) + SY) [by (4611-rn 
Proposition 8 (Commutative Law of Multiplication). PA t(x*y) = (y*x). 
Proof: The base clause, "(x*O) = (O*x)," uses (Q5) and Proposition 6. As inductive hypothesis, 
assume: 
(x*Y) = (Y*x). 
We compute: 
(X*SY) = ((x*~) + x) [by 4611 
= ((y*x) + x) [by IHI 
= (sy*x) [by Proposition 71. rn 
Proposition 9 (Distributive law). PA t(b'x)(Vy)(Vz)(x*(y + z)) = ((x*y) + (xmz)). 
Proof: We prove this equivalent formula: 
(b'y)(~z)Wx)(x*(y + 4) = ((x*y) + (xaz)), 
by using this induction axiom: 
(b'Y)(W [[(Om (Y + 4) = ((O*Y)+ (0.~1) A Wx)((x* (Y + 4) = ((x*y) + (x*z)) - 
(sx*(y + z)) = ((sx*y) + (sxez)))l - (b'x)(x*(y + z)) = ((x*y) + (x*z))l 
To get the base clause, we compute: 
(O*(y + z)) = 0 [by Proposition 61 
= (0 + 0) [by (4311 
= ((0.y) + (0.z)) [by Proposition 6 again]. 
In proving the induction step, we assume the IH:</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Peano Arithmetic, p. 6 
(x*(Y + z)) = ((x*Y) + (xaz)). 
Now we calculate: 
(SX*(Y + z)) = ((x*(Y + z)) + (Y + z)) [by Proposition 71 
= (((x0y) + (xaz)) + (Y + 4) [by IHI 
= ((x*y) + ((x*z) + (y + z))) [by Proposition 51 
= ((x*y) + (((xoz) + y) + z)) [by Proposition 51 
= ((x*y) + ((y + (x*z)) + z)) [by Proposition 41 
= ((x*y) + (y + ((x*z) + z))) [by Proposition 51 
= (((x*y) + y) + ((x*z) + z)) [by Proposition 51 
= ((sxoy) + (sx*z)) [by Proposition 71. H 
Proposition 10 (Associative law of multiplication). PA t(~x)(b'~)(Vz)((x~~)*z) 
= (x* (y*z)). 
Proof: The induction axiom we intend to employ is this: 
(V~)(VY)[[((~*Y)~~) = (x0(y*O)) A (Vz)(((x0y).z) = (x*(y0z)) - ((xay)*sz) = 
(x*(yasz)))l - (Vz)((xay)*z) = (xa(y*z))l. 
We get the base clause thus: 
((x* y)*~) = o [by (4611 
= (x*O) [by (4611 
= (x*(yaO)) [by (4611. 
To get the induction step, we assume this IH: 
((xay)*z) = (xa(y*z)). 
We compute:</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Peano Arithmetic, p. 13 
23 23 = f(x) + S (f(~)) [because U satisfies (Q4)] 
= f(x) +23 f(syY)) [because f respects "s"]. 
Therefore, s'(~) is in E.H 
Now we have a puzzle. Dedekind's theorem tells us that any model of Q that satisfies the 
principle of mathematical induction is isomorphic to the standard model. In particular, since true 
arithmetic includes Q and it also includes all the instances of the induction axiom schema, all 
models of true arithmetic ought to be isomorphic to the standard model. But they aren't. The 
Compactness Theorem tells us that there are nonstandard models of true arithmetic, that is, 
models of true arithmetic that aren't isomorphic to the standard model. 
The solution to this puzzle is to realize that the induction axiom schema doesn't hlly 
succeed in expressing the content of the principle of mathematical induction. What the induction 
axiom schema tells us is that the principle of mathematical induction is satisfied by every 
collection that is named by some predicate of the lang~age.~ There's no way the schema could 
tell us about collections that aren't named by predicates of the language. The collections that 
appear in the proof of Dedekind's theorem - the domain of the function f, and so on - aren't 
named by predicates of the language. 
3 To put the matter a little more precisely, let U be a model of the language of arithmetic. 
Extend the language of arithemetic by adding a new constant to serve as a standard name 
of each element of the universe of U. If U satisfies all the induction axioms, we are 
assured that the priniciple of mathematical induction holds for every subcollection of IUI t 
hat is the extension of some predicate of the extended language. The slogan is that the 
priniciple holds for collections that are named by some "predicate with parameters" in U.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Peano Arithmetic, p. 4 
= (x + s(y + z)) [by (4411 
= (X + (y + sz)) [by (4411- 
Proposition 6. PA t('dx)(o.x) = 0. 
Proof: The base clause, "(0.0) = 0," comes from (Q5). To get the induction, assume as IH: 
(0.x) = 0. 
We have: 
(0.s~) = ((0.x) + 0) [by (4611 
= (0.x) [by (4411 
=O [by IH] . q 
Proposition 7. PA t(~x)(b'~)(sx.~) = ((xmy) + y). 
Proof: We derive the base clause as follows: 
(sx.0) = o [by (Q5) 
= (x.0) [by (Q5) again1 
= ((x0y) + 0) [by (Q3)I. 
Assuming, as IH, 
(sx0y) = ((x0y) + Y), 
we compute: 
(sxosy) = ((sxoy) + sx) [by (4611 
= (((X~Y) + Y) + sx) [by IHI 
=((x.y) + (y + sx)) [by Proposition 51 
= ((X~Y) + S(Y + x)) [by (4411 
=((x.y) + s(x + y)) [by Proposition 41</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Peano Arithmetic 
Peano Arithmetic1 or PA is the system we get from Robinson's Arithmetic by adding the 
induction axiom schema: 
((R(0) A (Yx)(R(x) - R(sx))) - (Yx)R(x)). 
What this means is that any sentence of the language of arithmetic that you get from the schema 
by replacing the schematic letter "R" with a formula, then prefixing universal quantifiers to bind 
all the free variables is an axiom of PA. Thus PA consist of the axioms (Ql) through (Q1 I), 
together with infinitely many induction axioms. 
The induction axiom schema formalizes a familiar method of reasoning about the natural 
numbers. To show that every natural number has the property expressed by the formula we 
substitute for "R," we begin by showing that 0 has the property; this is the base case. Next we 
derive, by conditional proof, the conditional 
Wx)(R(x) - R(sx)); 
we assume R(x) as inductive hypothesis, then derive R(sx). The rule of mathematical induction 
permits us to infer (Vx)R(x). 
Virtually all of our ordinary mathematical reasoning about the natural numbers can be 
formalized in PA. Indeed, after some initial awkwardness, in which we produce proofs of facts 
of elementary arithmetic that we've taken for granted since childhood, reasoning in PA is nearly 
indistinguishable from ordinary arithmetical thinking. 
1'11 do a couple of these early proofs informally here, just to get an idea of what's going 
on. 
1 The so-called Peano axioms were first formulated by Richard Dedekind. Peano said as 
much in a footnote, but somehow "Peano Arithmetic" was the name that stuck.</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Peano Arithmetic, p. 12 
Let C be the set of elements of IUI that are paired by f with exactly one element of 131. We 
see that 0% is in C and that, whenever x is in C, sU(x) is in C. Because U satisfies the principle of 
mathematical induction, C must be equal to IUI, which means that f is a function fiom IUI to 1231. 
A similar argument, this time using the fact that 23 satisfies the principle of mathematical 
induction, shows that f is a bijection. 
To complete the proof that f is an isomorphism, we have to show several things. We have 
to show that f(oU) = oB; this follows immediately fiom the way f was defined. For each of the 
function signs of the language, we have to show that f respects the operation of the function sign; 
for example, we have to show that f(x +' y) = f(x) +' f(y). Finally, we have to show that f 
preserves the "&lt;" relation, that is, that x 3 y iff f(x) &lt;' f(y). Of these, we'll only write out the 
proofs for "s" and "+" here. 
(Dl) tells us that, if &lt;x,y&gt; E f, &lt;sU(x), s~(~)&gt; E f. Consequently, for x E IUI, since 
&lt;s,f(x)&gt; E f, &lt;sU(x), sB(f(x))&gt; E f, that is, f(s3(x)) = sB(f(x)). 
To get the clause for "+," pick x E 1'311. Let E = {y E IUI: f(x +' y) = f(x) +' f(y)). We 
want to show that 0' is in E, and also to show that, if y is in E, so is s'(~). Because U satisfies the 
principle of mathematical induction, this will suffice to show that every member of IUI is in E. 
Because U satisfies (Q3), x +' 0' = X. Because 23 satisfies (Q3), f(x) +' 0% = f(x). 
Consequently, f(x +' 0%) = f(x) = f(x) +% oB = f(x) +B f(oQL), and 0' is in E. 
Suppose that y is in E. We compute 
f(x +U syY)) = f(sU(x y)) [because U satisfies (Q4)] 
= sB(f(x y)) [because f respects "s"] 
= sB(f(x) +% f(y)) [because y E El</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Peano Arithmetic, p. 7 
((xay)*sz) = (((xay)*z) + (x*~)) [by (4611 
= ((xa(y*z)) + (x0y)) [by IHI 
= (x*((yaz) + Y)) [by Proposition 91 
= (x*(yosz)) [by (4611-rn 
We could keep going like this for a very long time. 
The induction axiom schema we have been using is sometimes called the "weak 
induction schema," to distinguish it form the following strong induction schema: 
(WX)(WY &lt; X)SY - Sx) - 0'~)s~)- 
In applying this schema, we assume as inductive hypothesis that every number less than x has 
the property represented by Sx, then try to show that x has the property. If we succeed, we 
conclude that every number has the property. We don't need to assume the instances of the 
strong induction schema as additional axioms, because we can derive them using the regular 
induction schema. Specifically, the induction axiom we use is this: 
[[(VY &lt; 0)SY A (Vx)((Vy &lt; x)Sy - (VY &lt; sx)Sy)l - Wx)(Vy &lt; x)Syl. 
The inductive hypothesis, "(Vy &lt; O)Sy," is a consequence of (Q9). (Q10) tells us that the 
induction clause, "(Vx)((Vy &lt; x)Sy - (Vy &lt; sx)Sy)," is equivalent to this: 
WX)((VY &lt; X)SY - (VY)((Y &lt; x v Y = x) - SY)), 
which, in turn is equivalent to this: 
(Vx)((Vy &lt; x)Sy - ((VY &lt; x)Sy A Sx)), 
which is equivalent to 
(Vx)((Vy &lt;x)Sy - Sx). 
Thus we have this:</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Peano Arithmetic, p. 8 
((VX)((~Y &lt; X)SY - Sx) - (VX)(VY &lt; x)SY). 
We also have this: 
((VX)(VY &lt; X)SY - Wx)Sx), 
which we obtain by the following derivation: 
1 1 - (VX)(VY)(Y &lt; x - SY) 
1 2- (VY)(Y &lt; sa - SY) 
1 3. (a &lt; sa - Sa) 
(Ql 0) 4. (Vx)(Vy)(x &lt; sy - (x &lt; y V x = y)) 
(Ql 0) 5. (Vy)(a &lt; sy - (a &lt; y V a = y)) 
(Ql 0) 6. (a &lt; sa - (a &lt; a V a= a)) 
7.a=a 
(Ql 0) 8. a&lt; sa 
1, (QlO) 9. Sa 
1, (QlO) 10. (VX)SX 
(Ql 0) 1 1. ((Vx)(Vy &lt; x)sy - (VX)SX) PI 
us, 1 
us, 2 
us, 4 
us, 5 
RI 
TC, 6,7 
TC, 3,8 
UG, 9 
CP, 1, 10 
Combining results, we obtain: 
((Vx)((Vy &lt; x)Sy - Sx) - (Vx)Sx). 
What we'd like to do now is reverse the process, showing how we could, if we had 
chosen, have taken the strong induction schema as axiomatic, and derived the weak induction 
schema. However, our attempt to do so runs into a glitch. We used weak induction to derive 
Proposition 1, the statement that every number is either 0 or a successor. If we replace weak by 
strong induction, we can't derive Proposition 1. Indeed, it's possible to put together a model of Q</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Peano Arithmetic, p. 9 
+ the strong induction schema in which Proposition 1 is false (though we won't do so here). 
What we can show, however, is that Q + Proposition 1 + the strong induction schema entails the 
weak induction schema. Thus, what we want to show is this: 
((RO A Wx)(Rx - Rsx)) - Wx)Rx). 
Strong induction gives us this: 
(Wx)(Wy &lt; ~)RY - Rx) - (Vx)Rx). 
So what we need to show is this: 
((RO A Wx)(Rx - Rsx)) - Wx)(Wy &lt; ~)RY - 
Assume 
RO 
and 
(Vx)(Rx - Rsx) 
Take any y. What we want to show is this: 
(WY &lt; ~)RY - Rx). 
If x = 0, this follows immediately from our assumption that RO. So we may assume (using 
Proposition 1) that x is a successor; say x = sz. So what we have to show is this: 
((Vy &lt; sz)Ry - RSZ. 
We assumed (Vx)(Rx - Rsx), which gives us this: 
(Rz - Rsz). 
So what we need is this: 
((Vy &lt; sz)Ry - Rz). 
In other words,</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Peano Arithmetic, p. 14 
To realize the full strength of the principle of mathematical induction, we have to go 
beyond the familiar language of arithmetic to the language of second-order arithmetic. In 
addition to the familiar symbols of the language of arithmetic, this new language includes the 
second-order variables, "X,," "X,," "X,," "X,," and so on.4 The definition of "formula" is 
changed in two ways: For any term T, KT is an atomic formula. Also, if 4 is a formula, so are 
(3XJ4 and @'&amp;)a. The distinction of "free" and "bound" occurrences of second-order 
variables, and the distinction between sentences and other formulas, works exactly the way it did 
for the first-order language. 
The definition of "model" is unchanged, but there are small changes in the semantics. A 
variable assignment for a model U assigns an element of IUI to each ordinary variable (or each 
individual variable, as they're called in this context), and it assigns a subset of IUI to each 
second-order variable. a satisfies &amp;T iff the individual T denotes with respect to a is an element 
of o(X,,,). An &amp;-variant of a variable assignment a agrees with a except perhaps in what it 
assigns to K. a satisfies (3X,,,)4 in U iff some &amp;-variant of a satisfies 4 in U. a satisfies 
(VX,,,)$ in U iff every &amp;-variant of a satisfies 4 in U. 
4 We are allowing second-order variables to take the place of unary predicates. We could 
also, if we wanted, allow second-order variables that take the place of predicates of more 
than one arguments. As far as what what we're doing here goes, this wouldn't make any 
differencebecause we can use the hction Pair to translate things we want to say about 
binary relations on the natural numbers into statements about properties of natural 
numbers.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Peano Arithmetic, p. 1 1 
Proof: Let f be the smallest subcollection of IUI x 1231 that meets these conditions: 
(Dl) &lt;OU,OB&gt; is in the collection. 
(D2) If &lt;x,y&gt; is in the collection, so is &lt;sU(x), s'(~)&gt;. 
That is, f is the intersection of all subcollections of IUI x 1231 that satisfl (Dl) and (D2). 
f is a function from 131 to 1231. To see this, note, first, that f pairs 0' with one and only one 
U B element of 1231: &lt;O , 0 &gt; E f by (Dl). If y + oB, f - {&lt;o',~&gt;) satisfies (Dl) and (D2), which 
implies, since f is smallest, that f - {&lt;o',~&gt;) = f and &lt;o',~&gt; C f. 
Next, assume that f pairs x with one and only one element y of 1931. Because f satisfies 
(D2), the pair &lt;sU(x), is in f. Suppose that z + s~(~). Let g = f - {&lt;sU(x),*). Because U 
satisfies (Ql), sU(x) + o', and so g satisfies (Dl). To see that g also satisfies (D2), take &lt;a,b&gt; E 
g. If sU(a) + sU(x), &lt;sU(a), sB(b)&gt; will be in g because it's in f. If sU(a) = sU(x), then, because U 
satisfies (Q2), a = x. Because f pairs x with only one element of 131, b must be equal to y, and so 
sB(b) + Z; hence, again, &lt;sU(a), sB(b)&gt; is in g. Thus g satisfies (Dl) and (D2). Because f is the 
smallest class that satisfies (Dl) and (D2), g must be equal to f, which means that &lt;sU(x), z&gt; isn't 
in f. Consequently, f pairs sU(x) with s~(~), and with nothing else. 
f(x 0% y) = f(x) 0% f(y). 
f(x E' y) = f(x) E~ f(y). 
x 3 y iff f(x) &lt;' f(y). 
If o is a variable assignment for U, then, for any formula 4, o satisfies 4 in U iff foo 
satisfies 4 in 23. (foo is defined by setting foo(v) equal to f(o(v)).) It follows that the 
same sentences are true in U and in 23.</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Peano Arithmetic, p. 15 
Second-order PA consists of axioms (Q 1) through (Q 1 I), together with the following 
second-order induction axiom: 
(vxo)((xoo A WY)(XOY - Xosy)) - (~Y)XOY). 
Thus we can write down second-order PA as a single sentence of the second-order language of 
arithmetic. 
Because the second-order variables range over all subcollections of the universe of 
discourse, not just those subcollections that happen to be named by some formula or other, the 
second-order induction axiom expresses the full strength of the principle of mathematical 
induction. Dedekind's theorem amounts to the following: 
Corollary. Second-order PA is categorical; that is, any two models of the 
theory are isomorphic.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Peano Arithmetic, p. 2 
Proposition 1. PA t(Vx)(x = 0 V (3y)x = sy). 
Proof: Use the following induction axiom: 
[[(0 = 0 V (3y)O = sy) A (Vx)((x = 0 V (3y)x = sy) - (sx = 0 V (3y)sx = sy))] 
- ('V'x)(x = 0 v (3y)x = sy)] 
The antecedent is a theorem of pure 1ogic.m 
Proposition 2. PA ~(VX)(O + x) = x. 
Proof: Use the following induction axiom: 
[[(0 + 0) = 0 A (Vx)((O + x) = x + (0 + sx) = sx)] - (Vx)(O + x) = x] 
The base clause, "(0 + 0) = 0," follows from (43). To get the induction step, assume, as 
inductive hypothesis (M) that (0 + x) = x. We have 
(0 + sx) = s(0 + x) [by (44)] 
= sx [by IH] . q 
Proposition 3. PA t(Vx)(Vy)(sx + y) = s(x + y). 
Proof: We use the following induction axiom: 
(Vx)[[(sx + 0) = s(x + 0) A (Vy)((sx + y) = s(x + y) - (sx + sy) = s(x + sy))] 
- ('V'Y)(SX + Y) = s(x + Y)I. 
The base clause is easy. Two applications of (43) yield 
(sx + 0) = sx 
= s(x + 0) 
To get the induction step, assume, as IH, 
(SX + y) = s(x + y). 
We have:</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Peano Arithmetic, p. 3 
(SX + SY) = s(sx + Y) [by (4411 
= ss(x + y) [by IH] 
= S(X + sy) [by (44) again]. H 
Proposition 4 (Commutative law of addition). PA t(b'x)(Vy)(x + y) = (y + x). 
Proof: We use this induction axiom: 
(b'x)[[(x + 0) = (0 + x) WY)((X + Y) = (Y + x) + (x + SY) = (SY + x))l 
- (b'y)(x + Y) = (Y + x)l. 
(43) gives us "(x + 0) = x," and Proposition 2 gives us "(0 + x) = x"; these together yield the 
base clause, "(x + 0) = (0 + x)." To get the induction step, assume as IH: 
(x + Y) = (Y + XI- 
We have: 
(X + SY) = s(x + Y) [by (4411 
= s(y + x) [by IH] 
= (sy + x) [by Proposition 31 H 
Proposition 5 (Associative law of addition). PA t(b'x)(Vy)(b'z)((x + y) + z) 
= (x + (y + z)). 
Proof: Two applications of (43) give us the basis clause, "((x + y) + 0) = (x + (y + O))." To get 
the induction step, assume as IH: 
((x + Y) + z) = (x + (Y + z)). 
We have: 
((x + y) + sz) = s((x + y) + z) [by (4411 
= s(x + (y + z)) [by IHI</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Key Computability Concepts (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/key_coptbty_cons/</lecture_pdf_url>
      <lectureno>2-3</lectureno>
      <slides>
        <slide>
          <slideno>10</slideno>
          <text>Key Computability Concepts, p. 1 1 
Proof: (-) If A is effectively enumerable, then it's the range of the partial function that takes n 
to the nth number on the list. 
(*) Iff is calculable, then, regarded as a binary relation, it's effectively enumerable. A algorithm 
for listing the range off is the following: 
List f. Whenever an ordered pair appears, give it's second member as an 
output. rn 
Theorem. A set is effectively enumerable iff it's either the empty set or 
the range of a calculable total function. 
Proof: (*) Suppose that A is effectively enumerable and nonempty. If A is infinite, then the 
function that takes n to the nth element on the list is a calculable total function whose range is A. 
If A is finite, then it has the form A = {a,, a,, q, ..., a,). Then A is the range of the function f, 
defined as follows: 
If i = 0, f(i) = a,,. 
If i = 1, f(i) = a,. 
Ifi = 2, f(i) = q. 
......................... 
If i = k, f(i) = a,. 
If i &gt; k, f(i) = a,. 
(*) If A is the empty set, it's enumerated by the lazy algorithm that never gives any output. If A 
is the range of a calculable total function, then it's the range of a calculable partial function.H 
Theorem. A set is effectively enumerable iff it's either finite or the range 
of a one-one calculable total function.</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Kcy Computability Concepts, p. 18</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Key Computability Concepts, p. 15 
Theorem. There is a calculable partial function that can't be extended to a 
calculable total function. 
Proof: Using A and B fiom the last theorem, define a calculable partial function g by: 
g(n) = 1 ifn E A 
=OinnB 
Suppose, for reductio ad absurdurn, that there were a calculable total function h that extended g. 
Then the function that takes an input n to the maximum of h(n) and 1 would be the characteristic 
function of a decidable set that included A and was disjoint from B.H 
Something important to remember is that effective enumerability and decidability are 
properties of sets. Whether a set is decidable doesn't depend on how the set is named, and it 
doesn't depend on our epistemic state. Often, a set can be named in many different ways. S 
might be {n: n has property P} and it might also be {n: n has property Q}, and it might turn out 
that we have an algorithm for answering all question of form "Does have property P?" 
(where the blank if filled in with an Arabic numeral2) but no algorithm for answering all 
questions of the form "Does have property Q?" In such a case, S would count as 
decidable. A set S is decidable iff there is some property3 P such that S is the set of numbers that 
2 S to be decidable, we don't have to be able to answer questions like, "Does the number of 
fish in Lake Anza have property P?" 
3 Here I am using the notion of property "pleonastically," so that to say that Traveler has 
the property of horseness is just another way of saying that Traveler is a horse. We could 
express the same idea without getting tangled in the metaphysics by talking about 
predicates. S is decidable iff there is some predicate 4 such that S = {n: @(n)} and such</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Key Computability Concepts, p. 3 
natural numbers. There is an mechanical procedure that, given F, will calculate Code(F). 
Moreover, there is a algorithm in the opposite direction, that, given a number n, computes the 
unique set F with Code(F) = n: write n in binary notation, and take F to be the set of places 
where 1 s appear. 
Coding a finite sequence. Given a finite sequence &lt;so, s,, s,, ..., sp, let its code be 
Code( {pair(O,s,), pair(1 ,s,), pair(2,s2),. . ., pair(n,s$)). 
Example: We can form two infinite lists, one of which lists all the expressions of English in 
alphabetical order, and the other of which lists all the expressions of Russian in alphabetical 
order. There is a mechanical procedure by which, given an English expression, we can find the 
position of the expression on the list, and also a procedure by which, given a number n, we can 
find the nth expression on the list. Then the problem of determining, given an English expression 
and an Russian expression whether the latter is an acceptable translation of the former, is 
equivalent to the arithmetical problem of determining, for given m and n, whether pair(m,n) is an 
element of {pair(i j): the ith English expression is an acceptable translation of the4 jth Russian 
expression. 
Example: The core of the Star Wars nuclear defense system is envisaged to be a gigantic 
supercomputer that takes radar traces of attacking missiles as inputs and yields instructions to US 
missiles that will shoot the attacking missiles down as outputs. Now it isn't possible to assign a 
distinct numerical code to each possible trajectory of an incoming missile, because there are 
more possible trajectories than there are natural numbers. However, the apparatus we use to 
sense the incoming missiles has limited sensitivity, so that it will be unable to distinguish among 
trajectories that are very close together. If we group together trajectories that the instruments are</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Key Computability Concepts, p. 5 
Aproofprocedure for S is an algorithm that calculates a partial function 
whose domain includes S that assigns the value 1 to an input if and only if 
the input is an element of S. 
An enumeration procedure for S is an algorithm that lists the elements of 
S. The function that takes a number n to the nth element on the list is a 
calculable partial function whose domain is an initial segment of the 
natural numbers and whose range is S. 
S is eflectively enumerable iff there is an enumeration procedure for S. 
Theorem. There is an proof procedure for S if and only if S is effectively 
enumerable. 
Proof: (*) A proof procedure for S calculates a partial function f with Dom(f) 2 S and f(n) = 1 
iff n E S, for n E Dom(f). We want to find an enumeration procedure for f. Here's a proposal that 
doesn't work: 
First, calculate f(0). If f(0) = 1, put 0 on the list. 
Second, calculate f(1). If f(1) = 1, put 1 on the list. 
Third, calculate f(2). If f(2) = 1, put 2 on the list. 
Fourth, calculate f(3). If f(3) = 1, put 3 on the list. 
And so on. 
The trouble is that, when the algorithm gets to something that's not in the domain off, it gets 
stuck. We want to modify the algorithm so that meeting up with a number that's not in the 
domain won't prevent it form going on to consider greater numbers. We might try this:</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Computability Theory: Key Concepts 
The general problem we want to confront is this: given a set or relation, when is there an 
algorithm for testing membership in that set? We can reduce this problem to another problem 
that, at first, appears to be much more restricted, namely, given a set of natural numbers, when is 
there an algorithm for testing membership in that set? We can effect this reduction by coding the 
given problem as a problem about numbers. A few examples will illustrate how this is done: 
Example: We already know that there is an algorithm for testing whether an SC sentence is 
valid. Let us see how this problem can be coded as a problem about numbers. We first associate, 
with each simple symbol of our SC language, a numerical code, as follows: 
1 is the code for "(" 
2 is the code for ")" 
3 is the code for "V" 
4 is the code for "A" 
5 is the code for "-" 
6 is the code for "-" 
7 is the code for "1" 
8 is the code for "A" 
9 is the code for "B" 
10 is the code for "C" 
1 1 is the code for "D" 
And so on. We can think of a sentence of the SC language as a finite sequence of symbols, so we 
can encode a sentence as a finite sequence of numbers. Moreover, as we shall see in a moment, it 
is possible to code a finite sequence of natural numbers as a single natural numbers. Putting</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Key Computability Concepts, p. 8 
Step 12. Perform another step in the attempt to calculate f(3) (if you 
didn't already succeed in calculating it). If you succeed in calculating f(3) 
and it's equal to 1, put 3 on the list. 
Step 13. Perform another step in the attempt to calculate f(2) (if you 
haven't already calculated it successfblly). If you succeed in calculating 
f(2) and it's equal to 1, put 2 on the list. 
Step 14. Perform another step in the attempt to calculate f(1) (if you 
haven't calculated it already). If you succeed in calculating f(1) and it's 
equal to 1, put 1 on the list. 
Step 15. Perform another step in the attempt to calculate f(0) (if you 
haven't calculated it already). If you succeed in calculating f(0) and it's 
equal to 1, put 0 on the list. 
And so on. 
(*) If we have an enumeration procedure for S, our proof procedure for S will e this: 
Given n. Begin listing S. If and when n appears on the list, give the output 
1.m 
Theorem. A set is decidable if and only if it and its complement are both 
effectively enumerable. 
Proof: (-) If S is decidable, then there is an algorithm for computing the characteristic function, 
x,, of S. This algorithm will also be a proof procedure for S. The algorithm that takes n to 1 - 
x,(n) will be a proof procedure for the complement of S.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Key Computability Concepts, p. 9 
(*) Given n, begin listing both S and its complement simultaneously. If n appears on the list for 
S, give the output 1. If n appears on the list for the complement, give the output 0.H 
We've spoken about decidable and effectively enumerable sets, but we can also talk 
about decidable and effectively enumerable relations, and the same theorems will hold, with the 
same proofs. Similarly, we described "calculable partial function" for 1-place functions, but we 
can also talk about functions of more than one argument. We have: 
Theorem. A partial function of one argument is calculable if and only if, 
regarded as a binary relation, it is effectively enumerable. 
Proof: (-) Suppose that f is a calculable partial function. Here is a proof procedure for f, 
thought of as a binary relation: given m and n, attempt to calculate f(m). If you get an output, 
check whether it's equal to n. If it is, give the output 1. 
(*) Given an enumeration procedure for f, here is an algorithm for calculating f: given m, begin 
enumerating f. As a pair appears on the list, check whether its first component is equal to m. If it 
is, give the second component as output.8 
Theorem. A total function of one argument is calculable if and only if, regarded 
as a binary relation, it's decidable. 
Proof: (*) Given that f is a calculable total function, here is a decision procedure. Given m and 
n, begin calculating f(m). If f(m) is equal to n, given the output 1. If f(m) is different from n, give 
the output 0. 
(*) Any decidable total function will be an effectively enumerable partial function, and so 
calculable. H</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Key Computability Concepts, p. 12 
Proof: (-) If A is infrnitc and cffcctivcly cnumcrablc, it can bc listcd without rcpciitions. 
Simply modify the lisling procedure so that a number can only be added to the list if it hasn't 
been listed already. Then the fbction ht takes n to the nth item on the list is a onwne 
calculable total function whose range is f. 
(-) If A is finite, it's effectively enumerable. If A is the range of a one-one calculable total 
function, it's the range of a calculable partial functionJ 
Theorem. If A and B are effectively enumerable sets, them there are 
effectively enumerable sets C and D with 
CrA 
DrB 
CnD=a 
CuD=AuB 
Proof: Here arc enumeration procedures for C 
atld D: bcgin sirnultancously to list A and B. Lf a 
number n appears on the list for A at a stage at 
which it has not yct appcarcd on thc list for B, put n on thc list for C, If n appcars on thc list for 
B at a stage at which it has not yet appeared on the list for A, put n on the list for D. If n appears 
on boh lists at he same stage, put n on the list for A. 
Theorem. Tf R is an effectively enumerable relation such that 
Vx)(3y)R(x,y), then there is a calculable total fimction f such that R(xJrx)), 
for every x.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Key Computability Concepts, p. 4 
unable to distinguish, we find that there are only finitely many discernibility classes of 
trajectories, and these can be assigned numerical codes. The instructions the computer sends to 
the defensive missiles can likewise be given numerical codes, so that the computer's problem 
can be coded as a numerical problem. 
We now present some key definitions. The definitions utilize colloquial notions that 
haven't been made mathematical precise, but they will nonetheless be precise enough to permit 
us to prove some theorems: 
Definitions. Apartial function from the natural numbers to the natural 
numbers is a subset f of N x N that meets the following condition: 
(Vx)(Vy)(vz)((&lt;x,z&gt; E f A &lt;y,* E f) - x = y) 
In other word, f is a function from a subset of N onto a subset of N. 
A partial function f is total iff its domain is all off. Thus, in our usage, 
total functions are a kind of partial function. 
A partial function f is calculable iff there is an algorithm such that, given 
n as input, the algorithm gives f(n) as output if n is in the domain off; iff 
isn't in the domain off, the algorithm gives no output. 
A decision procedure for S is an algorithm that calculates the 
characteristic function of S; that is, if the input is a member of S, the 
output is 1, whereas if the input is a nonmember, the output is 0. 
S is decidable iff there is a decision procedure for S.</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Key Computability Concepts, p. 16 
have property P and such that there is an algorithm for answering questions of the form "Does 
have property P?' The fact that there is some other property Q such that S is the set of 
numbers that have property Q and such that there is no known algorithm for answering questions 
of the form "Does have property Q?" doesn't spoil the decidability of S. 
To take an example, let D = {numbers n: there is a string of n or more successive 7s in 
the decimal expansion of IT). D is clearly effectively enumerable. The enumeration procedure is 
simply to start grinding out the decimal expansion of IT and to add n to the list when you come 
across a string of n 7s. Is D also decidable? No one knows how to answer questions of the form 
"If is D?' No one knows whether 1000 is in D, or whether 1,000,000 is in D. As far as 
anyone knows, every number could be in D. Nonetheless, D is decidable. If it happens to be the 
case that every number is in D, the a decision proacedure for D is the following: 
No matter what the input, give the output 1. 
If not every number is in D, then there is a number k such that D = {n: n I k). In that case, a 
decision procedure for D is this: 
Give the output 1 is the input is I k. If the input is &gt; k, give the output 0. 
One way or another, there is a decision procedure for D. 
The same goes for functions: a partial function is a set of ordered pairs, and whether it's 
calculable doesn't depend on how the function is names. To take an example, the Continuum 
that there is an algorithm for determining the truth values of sentences obtained from the 
open sentence @(x) by replacing free occurrences of "x" by a numeral. It doesn't matter 
if there is another predicate $ such that S = (n:$(n)) for which there is no such 
algorithm.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Key Computability Concepts, p. 10 
Theorem. The union of two effectively enumerable sets is effectively 
enumerable. 
Proof: Given enumeration procedures for A and B, here is a proof procedure for A u B: given n, 
begin simultaneously listing A and B. If n appears on either list, give the output 1 .B 
Theorem. The intersection of two effectively enumerable sets is 
effectively enumerable. 
Proof: Given enumeration procedures for A and B, here is a proof procedure for there 
intersection: given n, begin enumerating A If n appears on the list, then stop worrying about A 
and start listing B. If n appears, give the output 1 EI 
Theorem. A set is effectively enumerable iff it's the domain of a 
calculable partial function. 
Proof: (-) If A is effectively enumerable, then there is a proof procedure for A. By definition, 
that means that there is a calculable partial function f such that, for any n, n is in A if and only n 
is in the domain off and f(n) = 1. Define a calculable function g by the following algorithm: 
Being calculating f(n). If you get a value, check whether it's equal to 1. If 
it is, give the output 1 
Then A is the domain of g. 
(*) Iff is a calculable total function, a proof procedure for the domain off is the following: 
Begin calculating f(n). If you get an output, give the output 1 .B 
Theorem. A set is effectively enumerable iff it's the range of a calculable 
partial function.</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Key Computability Concepts, p. 17 
Hypothesis is the most famous unproved conjecture in set the~ry.~ Not only hasn't anyone ever 
been able either to prove or to refbte the Continuum Hypothesis, but it's known that the 
hypothesis can't be either proven or refuted on the basis of the currently accepted axioms of set 
theory. Now consider the function c, defined as follows: 
f(n) = n+l if the Continuum Hypothesis is true 
= n it the Continuum Hypothesis is not true 
It is not possible, on the basis of the currently accepted of set theory, to determine any of 
the values of the function c. Nonetheless c is calculable. Either c is the successor function, which 
is calculable, or c is the identity map, which is calculable. 
We've managed to identify some general structural properties of the set of effectively 
enumerable sets, but we haven't yet attempted to say precisely which the effectively enumerable 
sets are. We are going to wind up identifying the effectively enumerable sets as those that are 
named by especially simple formulas of the language of arithmetic. So what we need to do now 
is to introduce the language of arithmetic. 
4 To make the point we're making here, it doesn't matter what the hypothesis says.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Key Computability Concepts, p. 2 
these two encodings together, we associate a code number with each sentence. What I have in 
mind by talking about coding is this: there is an algorithm which, given a an SC sentence as 
input, gives the code number of that sentence as output. Furthermore, there is an algorithm that, 
given a number as input, first determines whether the number is the code of an SC sentence; if it 
is, the algorithm gives you the sentence. Once we have such a coding, we see that the problem of 
determining whether a given SC sentence is valid reduces to the problem of testing whether a 
given natural number is the code of a valid SC sentence. 
Coding a pair of natural numbers. Given natural numbers x and y, let pair(x,y) = %(x2 + 2xy + 
y2 + x + 3y). pair is a bijection1 from the set of ordered pairs of natural numbers to the set of 
natural numbers. There is an algorithm that, given x and y, givens you pair(x,y), and another 
algorithm that, given z, gives you the unique numbers x and y with pair(x,y) = z. Let's write x = 
1 st(z) and y = 2nd(z). 
Coding a finite set of natural numbers. Where F is a finite set of natural numbers, let Code(F) 
= C {2": n E F). Code is a bijection from the set of finite sets of natural numbers to the set of 
1 Recall that a function from a set A to a set B is a set f c A x B with the property that, for 
each element a of A, there is one and only one element b of B with &lt;a,b&gt; E f. If &lt;a,b&gt; E 
f, we write f(a) = b. A is the domain of the function, and the set of all elements b of B 
such that, for some a E A, f(a) = bI is the range. If the range off is all of B, f is said to be 
surjective or onto. If, for each a and a* in A, if f(a) = f(a*), then a = a, f is said to be 
injective or one-one. Iff is both surjective and injective, f is said to be bijective or a one- 
one correspondence. Iff is a bijection form A to B, the inverse off, fml, {&lt;b,a&gt;: &lt;a,b&gt;  
f), is bijection from B to A.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Key Computability Concepts, p. 6 
First, attempt to calculate f(0). If 0 @ Dom(f), skip to step 2. if 0 E Dom(f) 
and f(0) = 1, put 0 on the list. 
Second, attempt to calculate f(1). If 1 @ Dom(f), skip to step 3. If 1 E 
Dom(f) and f(1) = 1, put 1 on the list. 
Third, attempt to calculate f(2). If 2 @ Dom(f), skip to step 4. If 2 E 
Dom(f) and f(2) = 1, put 2 on the list. 
Fourth, attempt to calculate f(3). If 3 CE Dom(f), skip to step 5. If 3 E 
Dom(f) and f(3) = 1, put 3 on the list. 
And so on. 
The trouble is that, in general, we won't have any test to tell us whether a number is in the 
domain off. If n is in the domain off, our algorithm for f will compute f(n), but iff isn't in the 
domain, the algorithm will typically keep running forever without giving an output. We want to 
arrange our procedure so that we never give up on trying to calculate f(n), but doing this won't 
prevent us fiom considering numbers greater than n. We accomplish this by a technique called 
dovetailing that weaves different computations together: 
Step 1. Take one step in the attempt to compute f(0). If you succeed, see 
whether f(0) = 1. If it is, put 0 on the list. 
Step 2. Take one step in the attempt to compute f(1). If you succeed, see 
whether f(1) = 1. If it is, put 1 on the list. 
Step 3. Take another step in the attempt to compute f(0) (if you didn't 
already succeed in calculating f(0) at step 1). If you succeed in calculating 
f(O), see whether it's equal to 1. If it is, put 0 on the list.</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Key Computability Concepts, p. 13 
Proof: Here is an algorithm fbr calculating f: given n, 
begin mumerating the ordered pairs in R until you 
come to one whose kt component is equal to n. The 
first time you encounter such a pair, give its second 
component as output. H 
Iff ia a calculable partial functim (of me 
vent, say), then there is a computer program that 
calculates f. That is, there is a program that, given a number n as an input, will calculate far a 
while, then give the output qn), then Mt, if n is in the domain off. Ifn isn't in the domain off, 
the program will keep runnjng fomver, without giving any output. (We'll look at this a little later 
on in more detail.) We can write arrange all the possible program in alphabetical order (or 
something like it), so that, for each calculable partial function f, there is a number m such that 
the mth machine calculates f. Given m and n, we can write out the mth program, then calculate 
what output, if any, the program gives on the output n. The haltingproblem is this: given m and 
n, to detemk whether the 111th program halts when it's given the input n. There is a proof 
procedure for the halting problem, consisting in just carrying out the computation. Them is, 
however, no decision procedure. 
Theorem. There is no decision procedure for the halting problem, 
Proof: If there were such a decision procedure, then the following recipe would compute a 
calculable total hctim - call it f: 
Given m. If the mth machine yields the output k on input m, give the output 
k+1. If the mth machine doesn't halt on in@ m, give the output 0.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Key Computability Concepts, p. 7 
Step 4. Perform one step in the attempt to calculate f(2). If you succeed 
and f(2) = 1, put 2 on the list. 
Step 5. Take another step in the attempt to compute f(1) (if you didn't 
already succeed in calculating f(1) at step 2). If you succeed in calculating 
f(1) and it's equal to 1, put 1 on the list. 
Step 6. Take another step in the attempt to compute f(0) (if you didn't 
already calculate f(0) at step 1 or step 3). If you succeed in calculating f(0) 
and it's equal to 1, put 0 on the list. 
Step 7. Perform one step in the attempt to calculate f(3). If you succeed 
and f(3) = 1, put 3 on the list. 
Step 8. Perform another step in the attempt to calculate f(2) (if you didn't 
already succeed in calculating f(2) at step 4). If you succeed in calculating 
f(2) and it's equal to 1, put 2 on the list. 
Step 9. Perform another step in the attempt to calculate f(1) (if you didn't 
already succeed in calculating f(1) at step 2 or step 5). If you succeed in 
calculating f(1) and it's equal to 1, put 1 on the list. 
Step 10. Perform another step in the attempt to calculate f(0) (if you 
haven't succeeded in calculating f(0)). If you succeed in calculating f(0) 
and it's equal to 1, put 0 on the list. 
Step 11. Carry out one step in the attempt to calculate f(4). If you succeed 
and f(4) = 1, put 4 on the list.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Key Computability Concepts, p. 14 
Because f is calculable, there is a machine that calculates f; let's say it's the jth machine. 
Because f is total, the jth machine yields an output on every input. In particular, the jth machine 
yields an output on the input j, and we have: 
1 + the output of the jth machine on input j 
= f(j) [by the way f was defined] 
= the output of the jth machine on input j [by the way j was chozen] 
Contradiction. H 
Theorem. There are disjoint, effectively enumerable sets A and B such that there 
isn't any decidable set that includes A and in disjoint fiom B. 
Proof: Let A = {m: the mth machine gives output 0 on 
input m). Let B = {m: the mth machine 
gives output 1 on input m). Then A and B are disjoint ~L 2l\ &lt;~ 
and effectively enumerable. Pretend there were a 
decidable set C that included A and was disjoint fiom B. 
Since C is decidable, its characteristic function is 
calculable. Let's say the kth machine calculates the 
characteristic function of the complement of C. 
If k is in C, then x,(k) = 1, and so the kth machine yields output 1 on input k, which 
means that k is in B. But that's impossible, since B is disjoint from C. 
So k isn't in C, and so x,(k) = 0, that is, the kth machine gives output 0 on input k. But 
that means that k is in A, which is a subset of C. Contradicti0n.H</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Introduction to Modal Logic (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/24-242-logic-ii-spring-2004/resources/modal_logic/</lecture_pdf_url>
      <lectureno>22</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>An Introduction to Modal Logic 
Ordinary logic studies the partition of sentences1 into two categories, true and false. 
Modal logic investigates a finer classification. A sentence can be either necessary (true, and it 
couldn't have been otherwise), contingently true (true, but it might have been false), contingently 
false (false, but it might have been true). or impossible (couldn't have been true). The informal 
study of the logical properties of modality goes back at least to Aristotle, but the advent of 
formal systems of symbolic modal logic dates from the publication of C. I. Lewis's Survey of 
Symbolic Logic2 in 19 18. Lewis started with the sentential calculus, and added symbols to 
represent "it is necessary that," "it is possible that," and   imp lie^."^ He then developed deductive 
calculi by adopting various appealing axioms and deriving their conseqeunces. 
What redeemed formal modal logic fiom empty symbol pushing was the development of 
possible-world semantics. The idea comes fiom Leibniz, who thought of God as surveying all 
possible worlds, selecting the one that was best, and making it actual. The idea that this is the 
best of all possible worlds is a nutty idea, even by philosophers' standards - see Voltaire's 
Candide - but it proved fruitful. Possible-world semantics for modal sentential calculus were 
developed by J.C.C. MacKensie and Alfied Tarski in the 1940s; and they were extended to 
I am restricting attention to sentences used to make assertion, setting aside sentences 
used to ask questions or make requests or issue promises. A general theory that encompasses 
these other ways of employing language is developed by John Searle in Speech Acts (Cambridge: 
Cambridge University Press, 1969). 
Berkeley, Calif.: University of California Press. 
Recall my polemics in Logic I against reading "-" as "implies." The confusion of 
"implies," which is a transitive verb, with a sentential connective originates with Alfied North 
Whitehead and Bertrand Russell's Principia Mathematica (Cambridge: Cambridge University 
Press, 1910). See W. V. Quine, "Reply to Professor Marcus," Synthese 20 (196 I), reprinted in 
Quine, The Ways of Paradox (Cambridge, Mass.: Harvard University Press, 1966). 
"On Closed Elements in Closure Algebra," Annals of Mathematics 47 (1 946): 122- 162.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Modal Logic, p. 7 
KT, then the canonical frame for KT will be a transitive frame in which there is a world in which 
4 is false. 
KB is the smallest normal system that contains (B). A sentence is in KB iff it's valid for 
the class of symmetric frames. 
K5 is the smallest normal modal system that includes (5). A sentence is in K5 iff it's 
valid for the class of Euclidean frames. 
KT4, which Lewis called 34," is the smallest normal modal system that includes both 
(T) and (4). A sentence is is KT4 iff it's valid for the class of reflexive, transitive frames. 
KTB is the smallest normal modal system that includes both (T) and (B) A sentence is in 
KTB iff it's valid for the class of reflexive, symmetric frames. 
KT5, which Lewis called (SS), is the smallest normal modal system that includes both 
(T) and (5). A sentence is in KT5 iff it's valid for the class of reflexive, Euclidean frames. Since 
a binary relation that is reflexive and Euclidean will also be transitive and symmetric, KT5 is the 
same as KT4B5. 
I could keep doing this for a long time, but you get the point. 
The mystery component of the story is the accessibility relation. I have never heard a 
remotely satisfling explanation of why one possible world should or should not be accessible</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Modal Logic, p. 5 
w and such that (0, - (0, - ... - (0, - q) ...)) is a tautology. It follows by Tautological 
Consequence and Necessitation that O(0, - (0, - ... - (0, - q) ...)) is a member of r, and 
hence, by multiple applications of Tautological Consequence and Schema (K), that (00, - (08, 
- ... - (00, - Oq) ...)) isn in r, and hence in w. Because w is closed under modusponens, it 
follows that O* is in w, contrary to our assumption. 
The fi-ame &lt;W,R,I &gt; that we just constructed is called the canonicalfiame for I?. The 
principal moral of the theorem is that, if a sentence is outside I?, then there is a world in the 
canonical fi-ame in which it is fa1se.W 
Let me write down some axioms schemata; the schemata were named by different people 
at different times, so the nomenclature is annoyingly haphazard: 
(TI (04 - 4) 
(4) (04 - 004) 
(B) (4 - 004) 
(5) (04 - 004) 
Let me also write down some notable properties of binary relations: 
R is a reflexive relation on W iff, for each w in W, we have Rww. 
R is transitive iff, for each u, v, and w, if Ruv and Rvw, then Ruw. 
R is symmetric iff, for each u and v, if Ruv, then Rvu. 
R is Euclidean iff, for each u, v, and w, if Ruv and Ruw, then Rvw. 
K is defined to be the smallest normal modal system (that is, every other normal modal 
system includes K), so that a sentence is an element of K iff it is derivable fi-om instances of 
schema (K) by the rules TC and Necessitation. A sentence is in K iff it is true in every world in</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Modal Logic, p. 8 
from an~ther.~ As far as I can tell, the accessibility relation is something we tack on ad hoc so as 
to get the pretty relations between frames and axiom systems. 
We sometimes think if the march of history as following a forked path through a 
continually unfolding array of branching possibilities, so that what happens now can constrain 
what will be possible tomorrow. It could happen that, as of now, it's possible that I should fly to 
Jamaica tomorrow, but that some untoward event could happen tonight that would render it 
impossible for me to fly to Jamaica tomorrow; I might, for example, be eaten by a tiger escaped 
from a circus. So, even though it's not possible for me to fly to Jamaica tomorrow, it might 
become impossible for it to be possible for me to fly to Jamaica tomorrow, so that some 
instances of schema (5) can fail. To represent this conception formally, we take a "possible 
world" to be, not (as we would have expected) a possible complete course of history, but rather 
an ordered pair consisting of a complete course of history and a time. A statement will be 
possible at &lt;h,t&gt; if its truth is compatible with the course of history according to h as it has 
unfolded up to time t. A statement not involving modality will be true in &lt;h,t&gt; iff it's true in h. A 
pair &lt;h',t'&gt; will be accessible from &lt;h,t&gt; if t' is later than or equal to t and if h and h' agree in 
their depiction of the history of the world up to time t. The appropriate modal logic will be KT4.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Modal Logic, p. 3 
A normal modal system is a set of sentences I? with the following properties: 
Tautological consequence: Every tautological consequence of is in r. 
Necessitation: If 4 is in r, so is 04. 
Schema (K): Each instance of the axiom schema 
(K) (U4 + $1 + (04 + $1) 
is in I?. 
Theorem. For a set of sentences, the following are equivalent: 
(i) I? is a normal model system. 
(ii) There is a class of frames such that I? is the set of sentences valid for 
every member of the class 
(iii) Either I? is the set of all sentences or there is a frame &lt;W,R,I&gt; such that I? 
is the set of sentences valid for &lt;W,R,I&gt;. . 
Proof: That (ii) implies (i) is easy to check. That (iii) implies (ii) is immediate; if r is the set of 
all sentences, our class of frames will be the empty class. So we only need to worry about 
showing that (i) implies (iii). Given a normal modal system, let's say a set of sentences is r- 
consistent iff it contains all the members of I? and it is consistent by the sentential calculus. A 
maximal r-consistent set is a r-consistent set such that, for every sentence, either the sentence 
of its negation is in the set. Let W be the class of all maximal r-consistent sets of sentences; 
unless is the set of all sentences, W will be nonempty. For u and v elements of W, define Ruv 
iff 4 is in v whenever 04 is in W. Define I(@,w) = 1 iff 4 E w, for 4 atomic. We want to show 
that, for any sentence 4, 4 is true in w in the frame &lt;W,R,I&gt; iff 4 E w. This will tell us that the 
folowing are equivalent:</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Modal Logic, p. 4 
4~r 
4 is an element of every maximal r-consistent set 
4 is an element of every world w in W 
4 is true in every world w in W 
4 is valid for the frame &lt;W,R,I&gt; 
The proof that, for any sentence @,a is true in w if and only if 4 E w proceeds by 
induction on the complexity of 4. The only part of this that isn't entirely routine is to show that 
O$ is true in w iff its a element of w. Here's the proof of the right-to-left direction: If O$ is an 
element of w, then, by definition of R, $ is an element of every world accessible from w. It 
follows by inductive hypothesis that $ is true in every world accessible from w, that is, that O$ 
is true in w. 
For the other direction, suppose that 01) isn't an element of w. We want to see that there 
is a world accessible from w in which $ isn't true. This means, according to the inductive 
hypothesis, that we want a world accessible from w that contains $. That is, given the definition 
of R, we want a maximal r-consistent set of sentences that includes all the sentences 8 with 08 
in w but that doesn't include $. To get this, it will suffice to show that I' u {sentences 8: q 8 E 
w) u {- $1 is tautologically consistent. If it is, we can expand I? u (8: 8 E w) u {-$1 to a 
maximal r-consistent set by the familiar technique of marching through the sentences one by 
one, for each sentence when we come to it adding either it or its negation to the set, preserving 
r-consistency at every stage. Because of Necessitation, if y is in r, Oy is in I', and so Oy is in 
w and y is in (8: 08 E w). So it will be enough to show that (8: 08 E w) u z{-$1 is 
tautologically consistent. If not, then there exist sentences 8,, 8,, ..., 8, such that each O8i is in</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Modal Logic, p. 6 
every frame. Why? The set of sentences valid for every frame is a normal modal system, so it 
includes K. If 4 isn't in K, then there is a frame in which there is a world in which 4 is false, 
namely, the canonical model for K. 
KT is defined to be the smallest normal modal system that includes (T), so that a sentence 
is an element of KT iff it is derivable from (K) and (T) by the rules TC and Necessitation. A 
sentence is a element of KT iff it is true in every world in every reflexive frame. Why? Given a 
model &lt;W,R,I,a&gt;, with R reflexive, if 04 is true in a, then 4 is true in every world accessible 
from a; in particular, 4 is true in a itself; so all instances of schema (T) are true in the model. 
Consequently, the set of sentences valid for every reflexive frame is a normal modal system that 
includes (T). Moreover, the canonical frame for KT is reflexive; for any world w in the canonical 
frame, if 04 is in w, 4 is in w, so we have Rww. Thus, if 4 isn't in KT, then there is a reflexive 
frame in which there is a world in which 4 is false, namely, the canonical frame for KT. 
K4 is defined to be the smallest normal modal system that includes (4). A sentence is an 
element of K4 iff it's true in every world in every transitive frame. Why? Given a model 
&lt;W,R,I,a&gt; with R transitive, if q 4 is true in a and w is a world accessible from a, then every 
world accessible from w is accessible from a.. Since 4 is true in every world accessible from a, 
4 must be true in every world accessible from w, so that q 4 is true in w. We have shown that 
q 4 is true in every world accessible from a, so that 4 is true in a. Thus we see that all 
instances of schema (4) are true in the model, so that the set of sentences true in every transitive 
model will be a normal modal system that includes (4). Moreover, the canonical frame for K4 is 
transitive. If u, v, and w are worlds in the canonical frame for K4 with Ruv and Rvw, then if 04 
is in u, q 4 is in u, so that 04 is in v and 4 is in w. Consequently, Ruw. Thus, if $ is not in</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Modal Logic, p. 2 
modal predicate calculus by Saul Kripke in the 1960~~ We'll only talk about modal sentential 
calculus here, and that only s~perficially.~ 
We start with a version of the sentential calculus with infinitely many atomic sentences 
and add an operator "0," read "it is necessary that"; if 4 is a sentence, so is 04. We treat 
Lewis's symbol for possibility, "0," as defined: 04 =,,, - - 4. We'll have no need for 
Lewis's symbol for implication. 
Our interest here is in the interpretation of the modal sentential calculus in which "0" 
means "It is provable that," so that "0" means "It is consistent that." 
A Kripke model is an ordered quadruple &lt;W,R,I,a&gt;, where W, the set of worlds, is a 
nonempty set; R, the accessibility relation is a binary relation on W; I, the interpretation 
function, is a function that assigns to each pair &lt;@,w&gt; with 4 a sentence and w a world either 
the value 0 or the value 1; and a E W is the actual world. The triple &lt;W,R,I&gt; is afiame. For 4 
and atomic sentence and w a world, 4 is true in w if and only if I(@,w) = 1. A conjunction is true 
in w iff both conjuncts are true in w, a disjunction is true in w if and only if one or both disjuncts 
are true in w, and so on. 04 is true in w iff 4 is true in every world v with Rwv. A sentence is 
true in the model iff it's true in a. 
A sentence is valid for a frame or set of frames iff it's true at every world in every 
member of the set. 
"Semantical Considerations on Modal Logic," Acta Philosophica Fennica 16 (1 963): 
83-94. 
For a fuller treatment, see Brian Chellas, Modal Logic (Cambridge: Cambridge 
University Press, 1980), G. E. Hughes and Max Cresswell, A New Introduction to Modal Logic 
(Routledge, 1996), or J. C. Beall and Bas van Fraassen, Possibilities and Paradox (Oxford: 
Oxford University Press, 2003).</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
