<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/</course_url>
    <course_title>Introduction to Representation Theory</course_title>
    <course_tags>
      <list>Mathematics </list>
      <list>Algebra and Number Theory </list>
      <list>Linear Algebra</list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch1</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch1/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>1 Basic notions of representation theory 
1.1 What is representation theory? 
In technical terms, representation theory studies representations of associative algebras. Its general 
content can be very briey summarized as follows. 
An associative algebra over a eld k is a vector space A over k equipped with an associative 
bilinear multiplication a,b  ab, a,b  A. We will always consider associative algebras with unit, 
i.e., with an element 1 such that 1 a = a  1 = a for all a  A. A basic example of an associative 
algebra is the algebra EndV of linear operators from a vector space V to itself. Other important 
examples include algebras dened by generators and relations, such as group algebras and universal 
enveloping algebras of Lie algebras. 
A representation of an associative algebra A (also called a left A-module) is a vector space 
V equipped with a homomorphism  : A  EndV , i.e., a linear map preserving the multiplication 
and unit. 
A subrepresentation of a representation V is a subspace U V which is invariant under all 
operators (a), a  A. Also, if V1,V2 are two representations of A then the direct sum V1  V2 
has an obvious structure of a representation of A. 
A nonzero representation V of A is said to be irreducible if its only subrepresentations are 
0 and V itself, and indecomposable if it cannot be written as a direct sum of two nonzero 
subrepresentations. Obviously, irreducible implies indecomposable, but not vice versa. 
Typical problems of representation theory are as follows: 
1. Classify irreducible representations of a given algebra A. 
2. Classify indecomposable representations of A. 
3. Do 1 and 2 restricting to nite dimensional representations. 
As mentioned above, the algebra A is often given to us by generators and relations. For 
example, the universal enveloping algebra U of the Lie algebra sl(2) is generated by h,e,f with 
dening relations 
he  eh = 2e, hf  fh = 2f, ef  fe = h. (1) 
This means that the problem of nding, say, N-dimensional representations of A reduces to solving 
a bunch of nonlinear algebraic equations with respect to a bunch of unknown N by N matrices, 
for example system (1) with respect to unknown matrices h,e,f . 
It is really striking that such, at rst glance hopelessly complicated, systems of equations can 
in fact be solved completely by methods of representation theory! For example, we will prove the 
following theorem. 
Theorem 1.1. Let k = C be the eld of complex numbers. Then: 
(i) The algebra U has exactly one irreducible representation Vd of each dimension, up to equiv
alence; this representation is realized in the space of homogeneous polynomials of two variables x,y 
of degree d  1, and dened by the formulas 
    (h) = x y , (e) = x , (f) = y . x y y x 
(ii) Any indecomposable nite dimensional representation of U is irreducible. That is, any nite</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>1. p2
i = pi, pipj = 0 for i =  j
2. ahph = ah, ahpj = 0 for j  = h
3. ph ah = ah, piah = 0 for i  = h
We now justify our statement that a representation of a quiver is the same thing as a represen
tation of the path algebra of a quiver. 
Let V be a representation of the path algebra PQ. From this representation, we can construct a 
representation of Q as follows: let Vi = piV, and for any edge h, let xh = ah|pVh  : ph V  ph V 
be the operator corresponding to the one-edge path h. 
Similarly, let (Vi,xh) be a representation of a quiver Q. From this representation, we can 
construct a representation of the path algebra PQ: let V = i Vi, let pi : V  Vi  V be the 
projection onto Vi, and for any path p = h1...hm let ap = xh1 ...x
hm : Vh m  V  hbe the composition 
1 of the operators corresponding to the edges occurring in p (and the action of this operator on the 
other Vi is zero). 
It is clear that the above assignments V  (piV) and (Vi)  i Vi are inverses of each other. 
Thus, we have a bijection between isomorphism classes of represen
tations of the algebra PQ and of 
the quiver Q. 
Remark 1.34. In practice, it is generally easier to consider a representation of a quiver as in 
Denition 1.30. 
We lastly dene several previous concepts in the context of quivers representations. 
Denition 1.35. A subrepresentation of a representation (Vi,xh) of a quiver Q is a representation 
(Wi,x
h) where Wi  Vi for all i  I and where xh(Wh )  Wh and xh = xh|Wh : Wh  Wh for 
all h  E. 
Denition 1.36. The direct sum of two representations (Vi,xh) and (Wi,yh) is the representation 
(Vi  Wi,xh  yh). 
As with representations of algebras, a nonzero representation (Vi) of a quiver Q is said to be 
irreducible if its only subrepresentations are (0) and (Vi) itself, and indecomposable if it is not 
isomorphic to a direct sum of two nonzero representations. 
Denition 1.37. Let (Vi,xh) and (Wi,yh) be representations of the quiver Q. A homomorphism 
 : (Vi)  (Wi) of quiver representations is a collection of maps i : Vi   Wi such that 
yh  h = h  xh for all h  E. 
Problem 1.38. Let A be a Z+-graded algebra, i.e., A = n0A[n], and A[n]  A[m] A[n + m].             IfA[n]is nite dimensional, it is useful to consider the Hilbert series hA(t) = dimA[n]tn(the 
generating function of dimensions of A[n]). Often this series converges to a rational
 function, and 
the answer is written in the form of such function. For example, if A = k[x] and deg(xn) = n then 
h2 n 1 
A(t) = 1 + t + t+ ... + t+ ... =1  t 
Find the Hilbert series of: 
(a) A = k[x1,...,x m] (where the grading is by degree of polynomials);</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>The most important properties of tensor products are summarized in the following problem. 
Problem 1.49. (a) Let U be any k-vector space. Construct a natural bijection between bilinear 
maps V  W  U and linear maps V  W  U. 
(b) Show that if {vi} is a basis of V and {wj } is a basis of W then {vi  wj } is a basis of 
V  W . 
(c) Construct a natural isomorphism V   W  Hom(V,W ) in the case when V is nite 
dimensional (natural means that the isomorphism is dened without choosing bases). 
(d)  Let V be a vector space over a eld k. Let SnV be the quotient of V n(n-fold tensor product 
of V ) by the subspace spanned by the tensors T  s(T ) where T  V n, and s is some transposition. 
Also let nV be the quotient of V n by the subspace spanned by the tensors T such that s(T ) = T 
for some transposition s. These spaces are called the n-th symmetric, respectively exterior, power 
of V . If {vi} is a basis of V , can you construct a basis of SnV, nV ? If dimV = m, what are their 
dimensions? 
(e) If k has characteristic zero, nd  a natural identication of SnV with the space of T  V n
such that T = sT for all transpositions s, and  of nV with the space of T  V nsuch that T = sT 
for all transpositions s. 
(f) Let A : V  W be a linear operator. Then we have  an operator An: V n  W n, and 
its symmetric and exterior powers SnA : SnV  SnW , nA : nV  nW which are dened in 
an obvious way. Suppose V = W and has dimension N, and assume that the eigenvalues of A are 
1,..., N . Find Tr(SnA),Tr (nA). 
(g) Show that N A = det(A)Id , and use this equality to give a one-line proof of the fact that 
det(AB ) = det(A)det(B ). 
Remark. Note that a similar denition to the above can be used to dene the tensor product 
V A W , where A is any ring, V is a right A-module, and W is a left A-module. Namely, V A W 
is the abelian group which is the quotient of the group V W freely generated by formal symbols 
v  w, v  V , w  W , modulo the relations 
(v1 + v2)  w  v1  w  v2  w,v  (w1 + w2)  v  w1  v  w2,va  w  v  aw,a  A. 
Exercise. Throughout this exercise, we let k be an arbitrary eld (not necessarily of charac
teristic zero, and not necessarily algebraically closed). 
If A and B are two k-algebras, then an (A,B)-bimodule will mean a k-vector space V with 
both a left A-module structure and a right B-module structure which satisfy (av) b = a (vb) for 
any v  V , a  A and b  B. Note that both the notions of left A-module and right A-
module are particular cases of the notion of bimodules; namely, a left A-module is the same as an 
(A,k)-bimodule, and a right A-module is the same as a (k,A)-bimodule. 
Let B be a k-algebra, W a left B-module and V a right B-module. We denote by V B W the 
k-vector space (V k W ) / vb  w  v  bw | v  V, w  W, b  B. We denote the projection of 
a pure tensor v  w (with v  V and w  W ) onto the space V B W by v B w. (Note that this 
tensor product V B W is the one dened in the Remark after Problem1.49.) 
If, additionally, A is another k-algebra, and if the right B-module structure on V is part of an 
(A,B)-bimodule structure, then V B W becomes a left A-module by a (v B w) = av B w for 
any a  A, v  V and w  W .</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Hint. Prove the result by induction in dimension. By the induction assumption, K(g) has a 
common eigenvector v in V , that is there is a linear function  : K(g)  C such that av = (a)v 
for any a  K(g). Show that g preserves common eigenspaces of K(g) (for this you will need to 
show that ([x,a]) = 0 for x  g and a  K(g). To prove this, consider the smallest vector subspace 
U containing v and invariant under x. This subspace is invariant under K(g) and any a  K(g) 
acts with trace dim(U )(a) in this subspace. In particular 0 = Tr([x,a]) = dim(U )([x,a]).). 
Problem 1.57. Classify irreducible nite dimensional representations of the two dimensional Lie 
algebra with basis X,Y and commutation relation [X,Y ] = Y . Consider the cases of zero and 
positive characteristic. Is the Lie theorem true in positive characteristic? 
Problem 1.58. (hard!) For any element x of a Lie algebra g let ad(x) denote the operator g  
g,y  [x,y]. Consider the Lie algebra gn generated by two elements x,y with the dening relations 
ad(x)2(y) = ad(y)n+1(x) = 0. 
(a) Show that the Lie algebras g1, g2, g3 are nite dimensional and nd their dimensions. 
(b) (harder!) Show that the Lie algebra g4 has innite dimension. Construct explicitly a basis 
of this algebra.</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Similarly, if C is another k-algebra, and if the left B-module structure on W is part of a (B,C)
bimodule structure, then V B W becomes a right C-module by (v B w) c = v B wc for any 
c  C, v  V and w  W . 
If V is an (A,B)-bimodule and W is a (B,C)-bimodule, then these two structures on V B W 
can be combined into one (A,C)-bimodule structure on V B W . 
(a) Let A, B, C, D be four algebras. Let V be an (A,B)-bimodule, W be a (B,C)-bimodule, 
and X a (C,D )-bimodule. Prove that (V B W ) C X = V B (W C X) as (A,D)-bimodules. 
The isomorphism (from left to right) is given by (v B w) C x  v B (w C x) for all v  V , 
w  W and x  X. 
(b) If A, B, C are three algebras, and if V is an (A,B)-bimodule and W an (A,C)-bimodule, 
then the vector space Hom A (V,W ) (the space of all left A-linear homomorphisms from V to W ) 
canonically becomes a (B,C)-bimodule by setting (bf)(v) = f (vb) for all b  B, f  Hom A (V,W ) 
and v  V and (fc)(v ) = f (v) c for all c  C, f  Hom A (V,W ) and v  V . 
Let A, B, C, D be four algebras. Let V be a (B,A)-bimodule, W be a (C,B)-bimodule, and X a 
(C,D)-bimodule. Prove that Hom B (V, Hom C (W,X )) = HomC (W B V,X) as (A,D )-bimodules. 
The isomorphism (from left to right) is given by f  (w B v  f (v) w) for all v  V , w  W 
and f  Hom B (V, Hom C (W,X )). 
1.11 The tensor algebra 
The notion of tensor product allows us to give more conceptual (i.e., coordinate free) denitions 
of the free algebra, polynomial algebra, exterior algebra, and universal enveloping algebra of a Lie 
algebra. 
Namely, given a vector space V , dene  its tensor algebra TV over a eld k to be TV = nn0V , 
with multiplication dened by a   b := a  b, a  V n, b  V m. Observe that a choice of a basis 
x1,...,x N in V denes an isomorphism of TV with the free algebra k&lt;x 1,...,x n &gt;. 
Also, one can make the following denition. 
Denition 1.50. (i) The symmetric algebra SV of V is the quotient of TV by the ideal generated 
by v  w  w  v, v,w  V . 
(ii) The exterior algebra V of V is the quotient of TV by the ideal generated by v  v, v  V . 
(iii) If V is a Lie algebra, the universal enveloping algebra U(V ) of V is the quotient of TV by 
the ideal generated by v  w  w  v  [v,w], v,w  V . 
It is easy to see that a choice of a basis x1,...,x N in V identies SV with the polynomial algebra 
k[x1,...,x N ], V with the exterior algebra k(x1,...,x N ), and the universal enveloping algebra U(V ) 
with one dened previously. 
Also, it is   easy to see that we have decompositions SV = n0SnV , V = nn0 V . 
1.12 Hilberts third problem 
Problem 1.51. It is known that if A and B are two polygons of the same area then A can be cut 
by nitely many straight cuts into pieces from which one can make B. David Hilbert asked in 1900 
whether it is true for polyhedra in 3 dimensions. In particular, is it true for a cube and a regular 
tetrahedron of the same volume?</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>This example shows that an indecomposable representation of an algebra need not be irreducible. 
3. The group algebra A = k[G], where G is a group. A representation of A is the same thing as 
a representation of G, i.e., a vector space V together with a group homomorphism  : G  Aut(V ), 
whre Aut(V ) = GL(V ) denotes the group of invertible linear maps from the space V to itself. 
Problem 1.20. Let V be a nonzero nite dimensional representation of an algebra A. Show that 
it has an irreducible subrepresentation. Then show by example that this does not always hold for 
innite dimensional representations. 
Problem 1.21. Let A be an algebra over a eld k. The center Z(A) of A is the set of all elements 
z  A which commute with all elements of A. For example, if A is commutative then Z(A) = A. 
(a) Show that if V is an irreducible nite dimensional representation of A then any element 
z  Z(A) acts in V by multiplication by some scalar V (z). Show that V : Z(A)  k is a 
homomorphism. It is called the central character of V . 
(b) Show that if V is an indecomposable nite dimensional representation of A then for any 
z  Z(A), the operator (z) by which z acts in V has only one eigenvalue V (z), equal to the 
scalar by which z acts on some irreducible subrepresentation of V . Thus V : Z(A)  k is a 
homomorphism, which is again called the central character of V . 
(c) Does (z) in (b) have to be a scalar operator? 
Problem 1.22. Let A be an associative algebra, and V a representation of A. By End A(V ) one 
denotes the algebra of all homomorphisms of representations V  V . Show that EndopA(A) = A, 
the algebra A with opposite multiplication. 
Problem 1.23. Prove the following Innite dimensional Schurs lemma (due to Dixmier): Let 
A be an algebra over C and V be an irreducible representation of A with at most countable basis. 
Then any homomorphism of representations  : V  V is a scalar operator. 
Hint. By the usual Schurs lemma, the algebra D := EndA(V ) is an algebra with division. 
Show that D is at most countably dimensional. Suppose  is not a scalar, and consider the subeld 
C() D. Show that C() is a transcendental extension of C. Derive from this that C() is
uncountably dimensional and obtain a contradiction. 
1.4 Ideals 
A left ideal of an algebra A is a subspace I  A such that aI  I for all a  A. Similarly, a right 
ideal of an algebra A is a subspace I  A such that Ia  I for all a  A. A two-sided ideal is a 
subspace that is both a left and a right ideal. 
Left ideals are the same as subrepresentations of the regular representation A. Right ideals are 
the same as subrepresentations of the regular representation of the opposite algebra Aop. 
Below are some examples of ideals: 
	If A is any algebra, 0 and A are two-sided ideals. An algebra A is called simple if 0 and A 
are its only two-sided ideals. 
	If  : A  B is a homomorphism of algebras, then ker  is a two-sided ideal of A. 
	If S is any subset of an algebra A, then the two-sided ideal generated by S is denoted S and 
is the span of elements of the form asb, where a,b  A and s  S. Similarly we can dene 
S = span{as} and Sr = span{sb}, the left, respectively right, ideal generated by S.</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>The answer is no, as was found by Dehn in 1901. The proof is very beautiful. Namely, to 
any polyhedron A let us attach its Dehn invariant D(A) in V = R  (R/Q) (the tensor product 
of Q-vector spaces). Namely, 
 (a) D(A) = 
l(a)  , a 
where a runs over edges of A, and l(a),(a) are the length of a and the angle at a. 
(a) Show that if you cut A into B and C by a straight cut, then D(A) = D(B) + D(C). 
(b) Show that  = arccos(1/3)/ is not a rational number. 
Hint. Assume that  = 2m/n, for integers m,n. Deduce that  roots of the equation x+x1= 2/3 
are roots of unity of degree n. Conclude  that xk+ xk has denominator 3k and get a contradiction. 
(c) Using (a) and (b), show that the answer to Hilberts question is negative. (Compute the 
Dehn invariant of the regular tetrahedron and the cube). 
1.13 Tensor products and duals of representations of Lie algebras 
Denition 1.52. The tensor product of two representations V,W of a Lie algebra g is the space 
V  W with V W (x) = V (x)   Id + Id  W (x). 
Denition  1.53. The dual representation V to a representation V of a Lie algebra g is the dual 
   spaceVto V with V  (x) = V (x). 
It is easy to check that these are indeed representations. 
Problem 1.54. Let V,W,U be nite dimensional representations of a Lie algebra g. Show that 
the space Hom g(V  W,U) is isomorphic to Hom g(V,U  W ). (Here Hom g := Hom U(g)). 
1.14 Representations of sl(2) 
This subsection is devoted to the representation theory of sl(2), which is of central importance in 
many areas of mathematics. It is useful to study this topic by solving the following sequence of 
exercises, which every mathematician should do, in one form or another. 
Problem 1.55. According to the above, a representation of sl(2) is just a vector space V with a 
triple of operators E,F,H such that HE  EH = 2E,HF  FH = 2F,EF  FE = H (the 
corresponding map  is given by (e) = E,(f ) = F , (h) = H). 
Let V be a nite dimensional representation of sl(2) (the ground eld in this problem is C). 
 (a) Take eigenvalues of H and pick one with the biggest real part. Call it . Let V () be the 
generalized eigenspace corresponding to . Show that E|V() = 0. 
(b) Let W be any representation of sl(2) and w  W be a nonzero vector such that Ew = 0. 
For any k &gt; 0 nd a polynomial Pk(x) of degree k such that EkF kw = Pk(H)w. (First compute 
EF kw, then use induction in k). 
     (c) Letv V () be a generalized eigenvector of H with eigenvalue . Show that there exists 
 N &gt; 0 such that F Nv = 0. 
(d) Show  that H is diagonalizable on V(). (Take  N to be such that F N  = 0 on V(), and 
compute EN F N v, v  V(), by (b). Use the fact that Pk(x) does not have multiple roots).</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>1.5 Quotients 
Let A be an algebra and I a two-sided ideal in A. Then A/I is the set of (additive) cosets of I. 
Let  : A  A/I be the quotient map. We can dene multiplication in A/I by (a)  (b) := (ab).
This is well dened because if (a) = (a) then 
(a+  b) = (ab  (a a)b) = (ab) + ((a a)b) = (ab) 
because (a  a)b  Ib  I = ker , as I is a right ideal; similarly, if (b) = (b) then 
         (ab) =(ab+a(b b)) = (ab) +(a(b b)) = (ab) 
because a(b  b)  aI  I = ker , as I is also a left ideal. Thus, A/I is an algebra. 
Similarly, if V is a representation of A, and WV is a subrepresentation, then V/W is also a 
representation. Indeed, let  : V  V/W be the quotient map, and set V/W (a)(x) := (V (a)x). 
Above we noted that left ideals of A are subrepresentations of the regular representation of A, 
and vice versa. Thus, if I is a left ideal in A, then A/I is a representation of A. 
Problem 1.24. Let A = k[x1,...,x n] and I = A be any ideal in A containing all homogeneous 
polynomials of degree  N. Show that A/I is an indecomposable representation of A. 
Problem 1.25. Let V = 0 be a representation of A. We say that a vector v  V is cyclic if it 
generates V , i.e., Av = V . A representation admitting a cyclic vector is said to be cyclic. Show 
that 
(a) V is irreducible if and only if all nonzero vectors of V are cyclic. 
(b) V is cyclic if and only if it is isomorphic to A/I, where I is a left ideal in A. 
(c) Give an example of an indecomposable representation which is not cyclic. 
Hint. Let A = C[x,y ]/I2, where I2 is the ideal spanned by homogeneous polynomials of degree 
            2(soAhas a basis 1,x,y). LetV=Abe the space of linear functionals on A, with the action 
of A given by ((a)f )(b) = f(ba). Show that V provides such an example. 
1.6 Algebras dened by generators and relations 
If f1,...,f m are elements of the free algebra kx1,...,x n, we say that the algebra
A := kx1,...,x n/{f 1,...,f m} is generated by x1,...,x n with dening relations f1 = 0, ..., fm = 
0. 
1.7 Examples of algebras 
1. The Weyl algebra, kx,y/yx  xy  1.
2. The q-Weyl algebra, generated by x,x1,y,y1 with dening relations yx = qxy and xx1 = 
x1x = yy1 = y1y = 1. 
Proposition. (i) A basis for the  Weyl algebra A is {xiyj,i,j  0}. 
(ii) A basis for the q-Weyl algebra i j Aq is {xy ,i,j  Z}.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>1.2 Algebras 
Let us now begin a systematic discussion of representation theory. 
Let k be a eld. Unless stated otherwise, we will always assume that k is algebraically closed, 
i.e., any nonconstant polynomial with coecients in k has a root in k. The main example is the 
eld of complex numbers C, but we will also consider elds of characteristic p, such as the algebraic 
closure Fp of the nite eld Fp of p elements. 
Denition 1.3. An associative algebra over k is a vector space A over k together with a bilinear 
map A  A  A, (a,b)  ab, such that (ab)c = a(bc). 
Denition 1.4. A unit in an associative algebra A is an element 1  A such that 1a = a1 = a. 
Proposition 1.5. If a unit exists, it is unique. 
Proof. Let 1,   1be two units. Then 1 = 11= 1. 
From now on, by an algebra A we will mean an associative algebra with a unit. We will also 
assume that A = 0. 
Example 1.6. Here are some examples of algebras over k: 
1. A = k. 
2. A = k[x1,...,x n]  the algebra of polynomials in variables x1,...,x n. 
3. A = EndV  the algebra of endomorphisms of a vector space V over k (i.e., linear maps, or 
operators, from V to itself). The multiplication is given by composition of operators. 
4. The free algebra A = kx1,...,x n. A basis of this algebra consists of words in letters 
x1,...,x n, and multiplication in this basis is simply concatenation of words. 
5. The group algebra A = k[G] of a group G. Its basis is {ag,g  G}, with multiplication law 
agah = agh. 
Denition 1.7. An algebra A is commutative if ab = ba for all a,b  A. 
For instance, in the above examples, A is commutative in cases 1 and 2, but not commutative in 
cases 3 (if dim V &gt; 1), and 4 (if n&gt; 1). In case 5, A is commutative if and only if G is commutative. 
Denition 1.8. A homomorphism of algebras f : A  B is a linear map such that f(xy) = 
f(x)f(y) for all x,y  A, and f(1) = 1. 
1.3 Representations 
Denition 1.9. A representation of an algebra A (also called a left A-module) is a vector space 
V together with a homomorphism of algebras  : A  EndV . 
Similarly, a right A-module is a space V equipped with an antihomomorphism  : A  EndV ; 
i.e.,  satises (ab) = (b)(a) and (1) = 1. 
The usual abbreviated notation for (a)v is av for a left module and va for the right module. 
Then the property that  is an (anti)homomorphism can be written as a kind of associativity law: 
(ab)v = a(bv) for left modules, and (va)b = v(ab) for right modules. 
Here are some examples of representations.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>dimensional representation of U is a direct sum of irreducible representations. 
As another example consider the representation theory of quivers. 
A quiver is a nite oriented graph Q. A representation of Q over a eld k is an assignment 
of a k-vector space Vi to every vertex i of Q, and of a linear operator Ah : Vi  Vj to every directed 
edge h going from i to j (loops and multiple edges are allowed). We will show that a representation 
of a quiver Q is the same thing as a representation of a certain algebra PQ called the path algebra 
of Q. Thus one may ask: what are the indecomposable nite dimensional representations of Q? 
More specically, let us say that Q is of nite type if it has nitely many indecomposable 
representations. 
We will prove the following striking theorem, proved by P. Gabriel about 35 years ago: 
Theorem 1.2. The nite type property of Q does not depend on the orientation of edges. The 
connected graphs that yield quivers of nite type are given by the following list: 
 An :         
  
 Dn:        | 
 E6 :        
     
|
 E7 :           
    
| 
                 
 E8 : |
The graphs listed in the theorem are called (simply laced) Dynkin diagrams. These graphs 
arise in a multitude of classication problems in mathematics, such as classication of simple Lie 
algebras, singularities, platonic solids, reection groups, etc. In fact, if we needed to make contact 
with an alien civilization and show them how sophisticated our civilization is, perhaps showing 
them Dynkin diagrams would be the best choice! 
As a nal example consider the representation theory of nite groups, which is one of the most 
fascinating chapters of representation theory. In this theory, one considers representations of the 
group algebra A = C[G] of a nite group G  the algebra with basis ag,g  G and multiplication 
law agah = agh. We will show that any nite dimensional representation of A is a direct sum of 
irreducible representations, i.e., the notions of an irreducible and indecomposable representation 
are the same for A (Maschkes theorem). Another striking result discussed below is the Frobenius 
divisibility theorem: the dimension of any irreducible representation of A divides the order of G. 
Finally, we will show how to use representation theory of nite groups to prove Burnsides theorem: 
any nite group of order paqb, where p,q are primes, is solvable. Note that this theorem does not 
mention representations, which are used only in its proof; a purely group-theoretical proof of this 
theorem (not using representations) exists but is much more dicult!</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>3. The Heisenberg Lie algebra H of  0matrices 0 0
 
0 0 0
 
It has the basis  
0 0 0
 0 1 0
 0 0 1
x =


0 0 1

 y =

0 0 0


 c =


0 0 0


0 0 0 
0 0 0  
0 0 0 
with relations [y,x] = cand [y,c] = [x,c] = 0. 
4. The algebra a(1) of matrices ( 

0 0
 )
Its basis consists of X = ( 1 0 ) and Y = ( 0 1 
0 0 0 0 ), with [X,Y ] = Y .
5. so(n), the space of skew-symmetric n  n matrices, with [a,b] = ab  ba. 
Exercise. Show that Example 1 is a special case of Example 5 (for n = 3). 
Denition 1.42. Let g1, g2 be Lie algebras. A homomorphism  : g1   g2 of Lie algebras is a 
linear map such that ([a,b]) = [(a),(b)]. 
Denition 1.43. A representation of a Lie algebra g is a vector space V with a homomorphism 
of Lie algebras  : g   End V . 
Example 1.44. Some examples of representations of Lie algebras are: 
1. V = 0. 
2. Any vector space V with  = 0 (the trivial representation). 
3. The adjoint representation V = g with (a)(b) := [a,b]. That this is a representation follows 
from Equation (2). Thus, the meaning of the Jacobi identity is that it is equivalent to the 
existence of the adjoint representation. 
It turns out that a representation of a Lie algebra g is the same thing as a representation of a 
certain associative algebra U(g). Thus, as with quivers, we can view the theory of representations 
of Lie algebras as a part of the theory of representations of associative algebras. 
Denition 1.45. Let g be a Lie algebra with basis xi and [ , ] dened by [xi,xj ] = k c xk. The 
universal enveloping algebra U(g) is the associative algebra generated by the 
xis with the 
dening relations xixj =k  xjxi  k cij xk. 
Remark. This is not a very good denition since it depends on the choice of a basis. Later we 
will give an equivalent denition which will be basis-independent. 
Exercise. Explain why a representation of a Lie algebra is the same thing as a representation 
of its universal enveloping algebra. 
Example 1.46. The associative algebra U(sl(2)) is the algebra generated by e, f, h with relations 
he  eh = 2e hf  fh = 2f ef  fe = h. 
Example 1.47. The algebra U(H), where H is the Heisenberg Lie algebra, is the algebra generated 
by x, y, c with the relations 
yx  xy = c yc  cy = 0 xc  cx = 0. 
Note that the Weyl algebra is the quotient of U(H) by the relation c = 1.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Showxpand yp Hint.  that are central elements. 
(c) Find all irreducible nite dimensional representations of A. 
Hint. Let V be an irreducible nite dimensional representation of A, and v be an eigenvector 
of y in V . Show that {v,xv,x2v,...,xp1v} is a basis of V . 
Problem 1.27. Let q be a nonzero complex number, and A be the q-Weyl algebra over C generated 
     1 by x1 and y1with dening relations xx= x1x =1 1,yy= y1y = 1, and xy = qyx. 
(a) What is the center of A for dierent q? If q is not a root of unity, what are the two-sided 
ideals in A? 
(b) For which q does this algebra have nite dimensional representations?
Hint. Use determinants.
(c) Find all nite dimensional irreducible representations of A for such q.
Hint. This is similar to part (c) of the previous problem.
1.8 Quivers 
Denition 1.28. A quiver Q is a directed graph, possibly with self-loops and/or multiple edges 
between two vertices. 
Example 1.29. 
      
 
We denote the set of vertices of the quiver Q as I, and the set of edges as E. For an edge h  E, 
 let h, hdenote the source and target of h, respectively: 
   h  h h
Denition 1.30. A representation of a quiver Q is an assignment to each vertex i  I of a vector 
space Vi and to each edge h  E of a linear map xh : Vh  Vh . 
It turns out that the theory of representations of quivers is a part of the theory of representations 
of algebras in the sense that for each quiver Q, there exists a certain algebra PQ, called the path 
algebra of Q, such that a representation of the quiver Q is the same as a representation of the 
algebra PQ. We shall rst dene the path algebra of a quiver and then justify our claim that 
representations of these two objects are the same. 
Denition 1.31. The path algebra PQ of a quiver Q is the algebra whose basis is formed by 
oriented paths in Q, including the trivial paths pi, i  I, corresponding to the vertices of Q, and 
multiplication is concatenation of paths: ab is the path obtained by rst tracing b and then a. If 
two paths cannot be concatenated, the product is dened to be zero. 
 Remark 1.32. It is easy to see that for a nite quiver pi = 1, so PQ is an algebra with unit. 
iI 
Problem 1.33. Show that the algebra PQ is generated by pi for i  I and ah for h  E with the 
dening relations:</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>1.10 Tensor products 
In this subsection we recall the notion of tensor product of vector spaces, which will be extensively 
used below. 
Denition 1.48. The tensor product V W of vector spaces V and W over a eld k is the quotient 
of the space V  W whose basis is given by formal symbols v  w, v  V , w  W , by the subspace 
spanned by the elements 
(v1 + v2)  w  v1  w  v2  w,v  (w1 + w2)  v  w1  v  w2,av  w  a(v  w),v  aw  a(v  w), 
where v  V,w  W,a  k. 
Exercise. Show that V  W can be equivalently dened as the quotient of the free abelian 
group V W generated by v  w, v  V,w  W by the subgroup generated by 
(v1 + v2)  w  v1  w  v2  w,v  (w1 + w2)  v  w1  v  w2,av  w  v  aw, 
where v  V,w  W,a  k. 
The elements v  w  V  W , for v  V,w  W are called pure tensors. Note that in general, 
there are elements of V  W which are not pure tensors. 
This allows one to dene the tensor product of any number of vector spaces, V1  ...  Vn. Note 
that this tensor product is associative, in the sense that (V1  V2)  V3 can be naturally identied 
with V1  (V2  V3). 
 In particular, people often consider tensor products of the form V n= V  ...  V (n times) for 
a   given vector space V , and, more generally, E := V n (V )m. This space is called the space of 
tensors of type (m,n) on V . For instance, tensors of type (0, 1) are vectors, of type (1, 0) - linear 
functionals (covectors), of type (1, 1) - linear operators, of type (2, 0) - bilinear forms, of type (2, 1) 
- algebra structures, etc. 
If V i  is nite dimensional with basis e,i = 1,...,N , and eiis the dual basis of V , then a basis 
of E is the set of vectors 
ej1 jm i1  ...  ein  e ...  e , 
and a typical element of E is 
N 
T i1...in 
j 1 ...  ej1 
...jei in  e  ...  ejm ,1m 
i1,...,in,j1,...,j  
m=1   
where T is a multidimensional table of numbers. 
Physicists dene a tensor as a collection of such multidimensional tables TB attached to every 
basis B in V , which change according to a certain rule when the basis B is changed. Here it is 
important to distinguish upper and lower indices, since lower indices of T correspond to V and 
upper ones to V . The physicists dont write the sum sign, but remember that one should sum 
over indices that repeat twice - once as an upper index and once as lower. This convention is 
called the Einstein summation, and it also stipulates that if an index appears once, then there is 
no summation over it, while no index is supposed to appear more than once as an upper index or 
more than once as a lower index. 
               One can also dene the tensor product of linear maps. Namely, if A: V  V and B : W  W 
are linear maps, then   one can dene the linear map A  B : V  W  V  W given by the formula 
(A  B)(v  w) = Av  Bw (check that this is well dened!)</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Example 1.10. 1. V = 0. 
2. V = A, and  : A  EndA is dened as follows: (a) is the operator of left multiplication by 
a, so that (a)b = ab (the usual product). This representation is called the regular representation 
of A. Similarly, one can equip A with a structure of a right A-module by setting (a)b := ba. 
3. A = k. Then a representation of A is simply a vector space over k. 
4. A = kx1,...,x n. Then a representation of A is just a vector space V over k with a collection 
of arbitrary linear operators (x1),...,(x n) : V  V (explain why!). 
Denition 1.11. A subrepresentation of a representation V of an algebra A is a subspace W V 
which is invariant under all the operators (a) : V  V , a  A. 
For instance, 0 and V are always subrepresentations. 
Denition 1.12. A representation V = 0 of A is irreducible (or simple) if the only subrepresenta
tions of V are 0 and V . 
Denition 1.13. Let V1,V2 be two representations of an algebra A. A homomorphism (or in
tertwining operator)  : V1  V2 is a linear operator which commutes with the action of A, i.e., 
(av) = a(v) for any v  V1. A homomorphism  is said to be an isomorphism of representations 
if it is an isomorphism of vector spaces. The set (space) of all homomorphisms of representations 
V1  V2 is denoted by Hom A(V1,V2). 
Note that if a linear operator  : V1  V2 is an isomorphism of representations then so is the 
 linear operator 1: V2  V1 (check it!). 
Two representations between which there exists an isomorphism are said to be isomorphic. For 
practical purposes, two isomorphic representations may be regarded as the same, although there 
could be subtleties related to the fact that an isomorphism between two representations, when it 
exists, is not unique. 
Denition 1.14. Let V1,V2 be representations of an algebra A. Then the space V1  V2 has an 
obvious structure of a representation of A, given by a(v1  v2) = av1  av2. 
Denition 1.15. A nonzero representation V of an algebra A is said to be indecomposable if it is 
not isomorphic to a direct sum of two nonzero representations. 
It is obvious that an irreducible representation is indecomposable. On the other hand, we will 
see below that the converse statement is false in general. 
One of the main problems of representation theory is to classify irreducible and indecomposable 
representations of a given algebra up to isomorphism. This problem is usually hard and often can 
be solved only partially (say, for nite dimensional representations). Below we will see a number 
of examples in which this problem is partially or fully solved for specic algebras. 
We will now prove our rst result  Schurs lemma. Although it is very easy to prove, it is 
fundamental in the whole subject of representation theory. 
Proposition 1.16. (Schurs lemma) Let V1,V2 be representations of an algebra A over any eld 
F (which need not be algebraically closed). Let  : V1  V2 be a nonzero homomorphism of 
representations. Then: 
(i) If V1 is irreducible,  is injective;</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>(e) Let Nv be the smallest N satisfying (c). Show that  = Nv  1. 
(f) Show that for each N &gt; 0, there exists a unique up to isomorphism irreducible representation 
of sl(2) of dimension N. Compute the matrices E,F,H in this representation using a convenient 
basis. (For V nite dimensional irreducible take  as in (a) and v  V () an eigenvector of H. 
Show that v,Fv,...,F v is a basis of V , and compute the matrices of the operators E,F,H in this 
basis.) 
Denote the  + 1-dimensional irreducible representation from (f) by V. Below you will show 
that any nite dimensional representation is a direct sum of V. 
(g) Show that the operator C = EF + FE + H2/2 (the so-called Casimir operator) commutes 
    (+2) withE,F,H and equals Id on V. 2
Now it will be easy to prove the direct sum decomposition. Namely, assume the contrary, and 
let V be a reducible representation of the smallest dimension, which is not a direct sum of smaller 
representations. 
(h) Show that  on +2)C has only one eigenvalue V , (  namely for some nonnegative integer . 2
(use that the generalized eigenspace decomposition of C must be a decomposition of representations). 
(i) Show that V has a subrepresentation W = V such that V/W = nV for some n (use (h) 
and the fact that V is the smallest which cannot be decomposed). 
(j) Deduce from (i) that the eigenspace V () of H is n + 1-dimensional. If v1,...,v n+1 is its 
basis, show that F j vi, 1  i  n + 1, 0  j   are linearly independent and therefore form a basis 
of V  (establish that if ( 2) Fx = 0 and Hx = x then Cx = x and hence  = ).2 
(k) Dene W= span(v,Fv,...,F i i i vi). Show that Vi are subrepresentations of V and derive a 
contradiction with the fact that V cannot be decomposed. 
(l) (Jacobson-Morozov Lemma) Let V be a nite dimensional complex vector space and A : V 
V a nilpotent operator. Show that there exists a unique, up to an isomorphism, representation of 
sl(2) on V such that E = A. (Use the classication of the representations and the Jordan normal 
form theorem) 
(m) (Clebsch-Gordan decomposition) Find the decomposition into irreducibles of the represen
tation V  V of sl(2). 
Hint. For a nite dimensional representation V of sl(2) it is useful to introduce the character 
xH V (x) = Tr(e), x  C. Show that V W (x) = V (x) + W (x) and V W (x) = V (x) W (x).  
Then compute the character of V and of V V and derive the decomposition. This decomposition 
is of fundamental importance in quantum mechanics. 
(n) Let V = CM  CN , and A = JM (0)  IdN + IdM  JN (0), where Jn(0) is the Jordan block 
of size n with eigenvalue zero (i.e., Jn(0)ei = ei1, i = 2,...,n, and J   n(0)e1 = 0). Find the Jordan 
normal form of A using (l),(m). 
1.15 Problems on Lie algebras 
Problem 1.56. (Lies Theorem) The commutant K(g) of a Lie algebra g is the linear span 
of elements [x,y], x,y  g. This is an ideal in g (i.e., it is a subrepresentation of the adjoint 
representation). A nite dimensional Lie algebra g over a eld k is said to be solvable if there 
exists n such that Kn(g) = 0. Prove the Lie theorem: if k = C and V is a nite dimensional 
irreducible representation of a solvable Lie algebra g then V is 1-dimensional.</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
18.712  Introduction to Representation Theory 
Fall 2010 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>(b) A = k&lt;x 1,...,x m &gt; (the grading is by length of words); 
(c) A is the exterior (=Grassmann) algebra k[x1,...,x m], generated over some eld k by 
     2 x1,...,x m with the dening relations xixj +xj xi = 0 and xi = 0 for all i,j (the grading is by 
degree). 
(d) A is the path algebra PQ of a quiver Q (the grading is dened by deg(p i) = 0, deg(a h) = 1). 
Hint. The closed answer is written in terms of the adjacency matrix MQ of Q. 
1.9 Lie algebras 
Let g be a vector space over a eld k, and let [ , ] : g  g   g be a skew-symmetric bilinear map. 
(That is, [a,a] = 0, and hence [a,b] = [b,a]). 
Denition 1.39. (g, [ , ]) is a Lie algebra if [ , ] satises the Jacobi identity 

[a,b] ,c 
+    
[b,c] ,a
+ 
[c,a] ,b
= 0.	 (2) 
Example 1.40. Some examples of Lie algebras are: 
1. Any space g with [ , ] = 0 (abelian Lie algebra). 
2. Any associative algebra A with [a,b] = ab  ba . 
3. Any subspace U of an associative algebra A such that [a,b]  U for all a,b  U. 
4. The space Der(A) of derivations of an algebra A, i.e. linear maps D : A  A which satisfy 
the Leibniz rule:
D(ab) = D(a)b + aD(b).
Remark 1.41. Derivations are important because they are the innitesimal version of automor
phisms (i.e., isomorphisms onto itself). For example, assume that g(t) is a dierentiable family of 
automorphisms of a nite dimensional algebra A over R or C parametrized by t  (,) such that 
g(0) = Id. Then D := g(0) : A  A is a derivation (check it!). Conversely, if D : A  A is a 
derivation, then  etDis a 1-parameter family of automorphisms (give a proof!). 
This provides a motivation for the notion of a Lie algebra. Namely, we see that Lie algebras 
arise as spaces of innitesimal automorphisms (=derivations) of associative algebras. In fact, they 
similarly arise as spaces of derivations of any kind of linear algebraic structures, such as Lie algebras, 
Hopf algebras, etc., and for this reason play a very important role in algebra. 
Here are a few more concrete examples of Lie algebras: 
1.	R3 with [u,v] = u  v, the cross-product of u and v. 
2.	sl(n), the set of n  n matrices with trace 0.
For example, sl(2) has the basis
 	  0 1 0 0 1 0 e =	 f = h = 0	0 1 0 0 1 
with relations
[h,e] = 2e, [h,f] = 2f, [e,f] = h.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Proof. (i) First let us show that  the elements xiyjare a spanning set for A. To do this, n
ny word in x,y can be ordered to have all the x on the left of the y, at the cost of interc
ome x and y. Since yx  xy = 1, this will lead to error terms, but these terms will be 
onomials that have a smaller number of letters x,y than the original word. Therefore, co
his process, we can order everything and represent any word as a linear combination of x
The  proof that xiyjare linearly independent is based on representation theory. Namely,
   variable, and E = tak[a][t,t1] (here tais just a formal symbol, so really E = k[a][t,t1]). 
s a representation of A with action given by xf  +tfd f d(ta n)=  and yf = (where := (a + n) dt dt 
uppose now that we have a nontrivial j linear relation ciij xy= 0. Then the operator 
  d j 
L = 
cij ti
dt 
cts by zero in E. Let us write L as 
r   j d L = 
Qj(t) 
dt 
, 
j=0 
here Qr = 0. Then we have 
r 
Lta = Qj (t)a(a  1)...(a 
j j + 1)taj . 
=0 
his must be zero, so r  we have 
j=0 Qj (t)a(a  1)...(a  j + 1)tj= 0 in k[a][t,t1]. Ta
eading term in a, we get Qr(t) = 0, a contradiction. 
(ii) Any word in x,y,x1  ,y1can be ordered at the cost of multiplying it by a power of
asily implies both the spanning property and the linear independence. 
Remark. The proof of (i) shows that the Weyl algebra A can be viewed as the al
olynomial dierential operators in one variable t. 
The proof of (i) also brings up the notion of a faithful representation.
Denition. A representation  : A  End V is faithful if  is injective.
For example, k[t] is a faithful representation of the Weyl algebra, if k has characteris
check it!), but not in characteristic p, where (d/dt)pQ = 0 for any polynomial Q. Howe
epresentation E = tak[a][t,t1], as weve seen, is faithful in any characteristic. 
roblem 1.26. Let A be the Weyl algebra, generated by two elements x,y with the relati
yx  xy  1 = 0. 
(a) If chark = 0, what are the nite dimensional representations of A? What are the t
deals in A? 
Hint. For the rst question, use the fact that for two square matrices B,C, Tr(BC) = 
or the second question, show that any nonzero two-sided ideal in A contains a nonzero pol
n x, and use this to characterize this ideal. 
Suppose for the rest of the problem that chark = p. 
(b) What is the center of A? ote  that 
a hanging 
s sums of 
m ntinuing 
tiyj. 
  let a be 
a Then E 
i ta+n1). 
S
a
w 
T king the 
l
  q. This 
e
gebra of 
p
tic zero
( ver, the 
r 
P on 
wo-sided 
i
Tr(CB ). 
F ynomial 
i</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>(ii) If V2 is irreducible,  is surjective. 
Thus, if both V1 and V2 are irreducible,  is an isomorphism. 
Proof. (i) The kernel K of  is a subrepresentation of V1. Since  = 0, this subrepresentation 
cannot be V1. So by irreducibility of V1 we have K = 0. 
(ii) The image I of  is a subrepresentation of V2. Since  = 0, this subrepresentation cannot 
be 0. So by irreducibility of V2 we have I = V2. 
Corollary 1.17. (Schurs lemma for algebraically closed elds) Let V be a nite dimensional 
irreducible representation of an algebra A over an algebraically closed eld k, and  : V  V is an 
intertwining operator. Then  =   Id for some   k (a scalar operator). 
Remark. Note that this Corollary is false over the eld of real numbers: it suces to take 
A = C (regarded as an R-algebra), and V = A. 
Proof. Let  be an eigenvalue of  (a root of the characteristic polynomial of ). It exists since k is 
an algebraically closed eld. Then the operator   Id is an intertwining operator V  V , which 
is not an isomorphism (since its determinant is zero). Thus by Proposition 1.16 this operator is 
zero, hence the result. 
Corollary 1.18. Let A be a commutative algebra. Then every irreducible nite dimensional rep
resentation V of A is 1-dimensional. 
Remark. Note that a 1-dimensional representation of any algebra is automatically irreducible. 
Proof. Let V be irreducible. For any element a  A, the operator (a) : V  V is an intertwining 
operator. Indeed, 
(a)(b)v = (ab)v = (ba)v = (b)(a)v 
(the second equality is true since the algebra is commutative). Thus, by Schurs lemma, (a) is 
a scalar operator for any a  A. Hence every subspace of V is a subrepresentation. But V is 
irreducible, so 0 and V are the only subspaces of V . This means that dim V = 1 (since V = 0). 
Example 1.19. 1. A = k. Since representations of A are simply vector spaces, V = A is the only 
irreducible and the only indecomposable representation. 
2. A = k[x]. Since this algebra is commutative, the irreducible representations of A are its 
1-dimensional representations. As we discussed above, they are dened by a single operator (x). 
In the 1-dimensional case, this is just a number from k. So all the irreducible representations of A 
are V = k,   k, in which the action of A dened by (x) = . Clearly, these representations are 
pairwise non-isomorphic. 
The classication of indecomposable representations of k[x] is more interesting. To obtain it, 
recall that any linear operator on a nite dimensional vector space V can be brought to Jordan 
normal form. More specically, recall J   that the Jordan block ,n is the operator on knwhich in 
the standard basis is given by the formulas J,nei = ei + ei1 for i&gt; 1, and J,ne1 = e1. Then 
for any linear operator B : V  V there exists a basis of V such that the matrix of B in this basis 
is a direct sum of Jordan blocks. This implies that all the indecomposable representations of A are 
 Vn,n = k,   k, with (x) = J,n. The fact that these representations are indecomposable and 
pairwise non-isomorphic follows from the Jordan normal form theorem (which in particular says 
that the Jordan normal form of an operator is unique up to permutation of blocks).</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch5</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch5/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>11</slideno>
          <text>on ZNrestricts to the inner product B given by  on L, since it takes the same values on the 
basis vectors: 
(
i,i) = 2 
 1 i,j adjacent (i,j ) = 0 otherwise 
This means that vectors of the form 
(0,..., 0, 1, 0,..., 0, 1, 0,..., 0) = i + i+1 + + j1
and 
(0,..., 0, 1, 0,..., 0, 1, 0,..., 0) = ( i + i+1 + + j)1
are the roots of L. Therefore the number of positive roots in L equals 
N(N  1) . 2 
2. As a fact we also state the number of positive roots in the other Dynkin diagrams: 
DN N(N  1) 
E6 36 roots 
E7 63 roots 
E8 120 roots 
Denition 5.20.  Let   Znbe a positive root. The reection s is dened by the formula 
s(v) = v  B(v,). 
We denote si by si and call these simple reections. 
Remark 5.21. As a linear operator of Rn , s xes any vector orthogonal to  and 
s() =  
Therefore s is the reection at the hyperplane orthogonal to , and in particular xes B. The 
si generate a subgroup W  O(Rn), which is called the Weyl group of . Since for every w  W , 
w(i) is a root, and since there are only nitely many roots, W has to be nite. 
5.5 Gabriels theorem 
Denition 5.22. Let Q be a quiver with any labeling 1,...,n of the vertices. Let V = (V 1,...,V n) 
be a representation of Q. We then call 
d(V ) = (dim V1,..., dim Vn) 
the dimension vector of this representation. 
We are now able to formulate Gabriels theorem using roots. 
Theorem 5.23 (Gabriels theorem). Let Q be a quiver of type An,Dn,E6,E7,E8. Then Q has 
nitely many indecomposable representations. Namely, the dimension vector of any indecomposable 
representation is a positive root (with respect to B) and for any positive root  there is exactly 
one indecomposable representation with dimension vector .</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Proposition 5.31. Let Q be a quiver and V a representation of Q. 
1. Let i  Q be a sink and let V be surjective at i. Then
d(F+
i V ) = si(d(V )).
2. Let i  Q be a source and let V be injective at i. Then
d(FiV ) = si(d(V )).
Proof. We only prove the rst statement, the second one follows similarly. Let i  Q be a sink and 
let  
 : Vj  Vi 
ji 
be surjective. Let K = ker . Then 
 
dim K = 
dim Vj  dim Vi. 
ji 
Therefore we get 

d(F +
iV )  d(V )  
= 
dim Vj  2dim Vi = B (d(V ),i)i
ji
 
and   
d(F+
i V )  d(V )
= 0, j =  i.j 
This implies 
d(F+
i V )  d(V ) = B (d(V ),i) i 
 d(F +
i V ) = d(V )  B (d(V ),i) i = si (d(V )) .
5.7 Coxeter elements 
Denition 5.32. Let Q be a quiver and let  be the underlying graph. Fix any labeling 1,...,n 
of the vertices of . Then the Coxeter element c of Q corresponding to this labeling is dened as 
c = s1s2 ...sn. 
Lemma 5.33. Let  
 = 
kii 
i 
with ki  0 for all i but not all ki = 0. Then there is N  N, such that 
 c N
has at least one strictly negative coecient.</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>3) Hn: V = Cn with  basis vi, W = Cn1with basis wi, Avi = wi, Bwi = vi+1 for i &lt;n, and 
Avn = 0. 
4) Kn is obtained from Hn by exchanging V with W and A with B. 
Show that these are indecomposable and pairwise nonisomorphic. 
(b) Show that if E is a representation of Q2 such that  AB is not nilpotent, then E = E E, 
where E = En, for some  = 0.
(c) Consider the case when AB is nilpotent, and consider the operator X on V  W given 
by X(v,w) = (Bw,Av ). Show that X is nilpotent, and admits a basis consisting of chains (i.e., 
sequences u,Xu,X2u,...Xl1u where Xlu = 0) which are compatible with the direct sum decompo
sition (i.e., for every chain u  V or u  W ). Deduce that (1)-(4) are the only indecomposable 
representations of Q2. 
(d)(harder!) generalize this classication to the Kronecker quiver, which has two vertices 1 and 
2 and two edges both going from 1 to 2. 
(e)(still harder!) can you generalize this classication to Qn, n&gt; 2, with any orientation? 
Problem 5.40. Let L 1  Z8 be the lattice of vectors where the coordinates are either all integers 2 
or all half-integers (but not integers), and the sum of all coordinates is an even integer. 
      8 (a) Leti =ei ei+1,i= 1,..., 6, 7 = e6 + e7, 8 = 1/2 
i=1 ei. Show that i are a basis 
of L (over Z). 
(b) Show that roots in L (under the usual inner product) form a root system of type E8 (compute 
the inner products of i). 
(c) Show that the E7 and E6 lattices can be obtained as the sets of vectors in the E8 lattice L 
where the rst two, respectively three, coordinates (in the basis ei) are equal. 
(d) Show that E6,E7,E8 have 72,126,240 roots, respectively (enumerate types of roots in terms 
of the presentations in the basis ei, and count the roots of each type). 
Problem 5.41. Let V be the indecomposable representation of a Dynkin quiver Q which corre
sponds to a positive root . For instance, if i is a simple root, then Vi has a 1-dimensional space 
at i and 0 everywhere else. 
(a) Show that if i is a source then Ext1(V,V i ) = 0 for any representation V of Q, and if i is 
a sink, then Ext1(Vi ,V ) = 0. 
(b) Given an orientation of the quiver, nd a Jordan-H older series of V for that orientation.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>By identifying V and Y as subspaces of W , this leads to the problem of classifying pairs of 
subspaces of a given space W up to isomorphism (the pair of subspaces problem). To do 
so, we      rst choose a complement Wof V   in W , and set V  = W     Y V , Y = W  Y . 
Then we can decompose the representation as follows: 

 
  
  
 
  =
 
 
V W   
  
   
Y V
W  
Y
V  Y V    .
  Y V  Y
The second summand is a multiple of the object 1  1 1 . We go on decomposing the 
rst summand. Again, to simplify notation, we let 
V = V , W = W , Y = Y . 
We can now    0. Next, let   assume that V  Y= Wbe a complement of V  Y in W . Then 
we get 
    
 
 =
V WY  
V VYY0 W 
 0
The second of these summands is a multiple of the indecomposable object 0 1 0 . 
The rst summand can be further decomposed as follows: 


      =
 
  
VV Y Y V 0 
   
0   
V YY
These summands are multiples of 
1 1 0 , 0 1 1 
So - like in the other orientation - we get 6 indecomposable representations of A3: 
  1 0 0 , 0 0 1 , 1 1 1 , 
0 1 0 , 1 1 0 , 0 1 1 
5.3 Indecomposable representations of the quiver D4 
As a last - slightly more complicated - example we consider the quiver D4. 
Example 5.10 (D4). We restrict ourselves to the orientation 

    
.

So a representation of this quiver looks like 
A1 V 
    A3 
 
V1 V
3 
A2 

V
2</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>3
1 2 3 4 5 6 4 2 
(f) Deduce from (a)-(e) the classication theorem for Dynkin diagrams. 
(g) A (simply laced) ane Dynkin diagram is a connected graph without self-loops such that the 
quadratic form dened by A is positive semidenite. Classify ane Dynkin diagrams. (Show that 
they are exactly the forbidden diagrams from (c)-(e)). 
Problem 5.4. Let Q be a quiver with set of vertices D. We say that Q is of nite type if it 
has nitely many indecomposable representations. Let bij be the number of edges from i to j in Q 
(i,j  D). 
There is the following remarkable theorem, proved by P. Gabriel in early seventies. 
Theorem. A connected quiver Q is of nite type if and only if the corresponding unoriented 
graph (i.e., with directions of arrows forgotten) is a Dynkin diagram. 
In this problem you will prove the only if direction of this theorem (i.e., why other quivers 
are NOT of nite type). 
(a) Show that if Q is of nite type then for any rational numbers xi  0 which are not simul
taneously zero, one has q(x1,...,x N ) &gt; 0, where 
 q(x1,...,x N ) :=  
 x2 1
i  2 
bij xixj. 
i D i,jD 
Hint. It suces to check the result for integers: xi = ni. First assume that ni  0, and consider 
the space W of representations V of Q such that dimVi = ni. Show that the group i GLni (k) acts 
with nitely many orbits on W  k, and use Problem 5.2 to derive the inequality. Then
 deduce the 
result in the case when ni are arbitrary integers. 
(b) Deduce that q is a positive denite quadratic form. 
Hint. Use the fact that Q is dense in R. 
(c) Show that a quiver of nite type can have no self-loops. Then, using Problem 5.3, deduce 
the theorem. 
Problem 5.5. Let G = 1 be a nite subgroup of SU(2), and V be the 2-dimensional representation 
of G coming from its embedding into SU(2). Let Vi, i  I, be all the irreducible representations of 
G. Let rij be the multiplicity of Vi in V  Vj. 
(a) Show that rij = rji. 
(b) The McKay graph of G, M(G), is the graph whose vertices are labeled by i  I, and i is 
connected to j by rij edges. Show that M(G) is connected. (Use Problem 3.26) 
(c) Show that M(G) is an ane Dynkin graph (one of the forbidden graphs in Problem 5.3). 
For this, show that the matrix aij = 2 ij  rij is positive semidenite but not denite, and use 
Problem 5.3. 
Hint. Let f =  xiVi , where Vi be the characters of Vi. Show directly that ((2V )f,f)  0. 
When is it equal to 0? Next, show that M(G) has no self-loops, by using that if G is not cyclic 
then G contains the central element Id  SU(2).</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>E7 :           |
     
                  
 E8 : |
(a) Compute the determinant of A where  = AN ,DN . (Use the row decomposition rule, and 
write down a recursive equation for it). Deduce by Sylvester criterion7 that AN ,DN are Dynkin 
diagrams.8 
(b) Compute the determinants of A for E6,E7,E8 (use row decomposition and reduce to (a)). 
Show they are Dynkin diagrams. 
(c) Show that if  is a Dynkin diagram, it cannot have cycles. For this, show that det(A ) = 0 
for a  graph  below 9
1 
1 1 1 1 
(show that the sum of rows is 0). Thus  has to be a tree. 
(d) Show that if  is a Dynkin diagram, it cannot have vertices with 4 or more incoming edges, 
and that  can have no more than one vertex with 3 incoming edges. For this, show that det(A ) = 0 
for a graph  below: 
1 1 
2 2 
1 1 
(e) Show that det(A ) = 0 for all graphs  below: 
1 
2 
1 2 3 2 1
2
1 2 3 4 3 2 1 
7Recall the Sylvester criterion: a symmetric real matrix is positive denite if and only if all its upper left corner 
principal minors are positive. 
8The Sylvester  criterion says that a symmetric bilinear form (, ) on RNis positive denite if and only if for any 
k  N, det1i,jk (ei, ej ) &gt; 0. 
9Please ignore the numerical labels; they will be relevant for Problem 5.5 below.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>The rst thing we can do is - as usual - split away the kernels of the maps A1,A2,A3. More 
precisely, we split away the representations 
00 0 0   
 
ker  
0
 A1 0 0   
    
 
0
0 
ker
 A3 
0 
 
0
 ker
 A2 0
 
These representations are multiples of the indecomposable objects 
00 0 0  
 
  
  0
  
1 0 0 0 0
 1
0 
 
0
1
0 
So we get to a situation where all of the maps A1,A2,A3 are injective. 
  
A1 V   A3  

V  
1 V3 
A2 



V
2 
As in 2, we can then identify the spaces V1,V2,V3 with subspaces of V . So we get to the triple of 
subspaces problem of classifying a triple of subspaces of a given space V . 
The next step is to split away a multiple of 
1 
    
0 
0 
0
 
to reach a situation where 
V1 + V2 + V3 = V. 
By letting Y =   V1  V2  V3, choosing a complement V of Y in V , and setting Vi= V  Vi, 
i = 1, 2, 3, we can decompose this representation into 
 V   Y  
   
 
  
V
1V
3Y 
Y


 



 
V
2Y

The last summand is a multiple of the indecomposable representation 
 1  
   
1
1
 

1</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Then a representation of this quiver looks like 
A  
V WB  .
Y 
Like in Example 5.8 we rst split away 
0 0  
ker A 00.
  This object is a multiple of 1 0 0 . Next, let Y be a complement of ImB in Y . 
Then we can also split away 
0   
000
 Y 
which is a multiple of the object 0 0 1 . This results in a situation where the map 
A is injective and the map B is surjective (we rename the spaces to simplify notation): 
 A  B  .
V W
 Y
Next, let X = ker(B  A) and let X be a        complement of XinV. Let W be a complement 
of A(X) in W such that A(X)
W . Then we get
  A B   A B  =
  

A B   
V W Y X A(X)
 0 
 W  X Y
 The rst of these summands is a multiple of 1 1 0 . Looking at the second summand, 
we now have a situation where A is injective, B is surjective and furthermore ker(B  A) = 0.
To simplify notation, we redene 
V = X, W = W . 
Next we let X = Im(B A) and let Xbe a complement of X in Y . Furthermore, let
W=B1(X). Then W is a complement of A(V ) in W . This yields the decomposition 
 A B A B    B   
   =V W Y V X 0 W  X
  A(V )
Here, the rst summand is a  multiple of 1 1  1 . By splitting away the kernel of B, 
the e  second summand can b decomposed into multiples of 0 1 1 and 0 1 0 . 
So, on the whole, this quiver has six indecomposable representations: 
1 0 0 , 0 0  1 , 1 1 0 , 
   1 1 1 , 0 1 1 , 0 1 0 
2. Now we look at the orientation 

 
 
.
Very similarly to the other orientation, we can split away objects of the type 
1 0 0 , 0 0 1 
which results in a situation where both A and B are injective: 
 A  
V WB 
Y.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Next, let  be the edge connecting i with the  next vertex towards j and ibe the vertex on the other 
end of . We then let 1, 2 be the graphs obtained from  by removing . Since  is supposed 
to be a Dynkin diagram - and therefore has no cycles or loops - both 1 and 2 will be connected 
graphs, which are not connected to each other. 
  
i 1   j   
 
2 
Then we have i  1, j  2. We dene 
 
 =   
 k mm,  = 
kmm. 
m1 m2 
With this choice we get 
 =  + . 
Since ki &gt; 0,kj &lt; 0 we know that  = 0, = 0 and therefore 
B(,)  2, B (,)  2. 
Furthermore, 
B(,) = kiki , 
since 1, 2 are only connected at . But this has to be a nonnegative number, since ki &gt; 0 and 
ki  0. This yields 
B(,) = B( + , + ) = B(,) +2 B(,) +  B(,)  4.   
2  

0  

2 
But this is a contradiction, since  was assumed to be a root.
Denition 5.17. We call a root  = 
i kii a positive root if all ki  0. A root for which ki  0
for all i is called a negative root. 
Remark 5.18. Lemma 5.16 states that every root is either positive or negative. 
Example 5.19. 1. Let Then   be of the type AN1. the lattice L = ZN1can be realized as 
a subgroup   the lattice ZN of by letting L  ZNbe the subgroup of all vectors (x1,...,x N ) 
such that  
xi = 0. 
i 
The vectors 
1 = (1, 1, 0,..., 0) 
2 = (0, 1, 1, 0,..., 0) 
. . . 
N1 = (0,..., 0, 1, 1)   
naturally form a basis of L. Furthermore, the standard inner product 
 
(x,y) = 
xiyi</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>5.4 Roots 
From now on, let  be a xed graph of type An,Dn,E6,E7,E8. We denote the adjacency matrix 
of  by R. 
Denition 5.11 (Cartan Matrix). We dene the Cartan matrix as 
A = 2Id  R. 
On  the lattice Zn(or the space Rn) we then dene an inner product 
 B(x,y) = x TAy 
corresponding to the graph . 
Lemma 5.12. 1. B is positive denite. 
2. B(x,x) takes only even values  for x  Zn. 
Proof. 1. This follows by denition, since  is a Dynkin diagram. 
2. By the denition of the Cartan matrix we get 
      B(x,x) = x TAx = 
xi aij xj = 2 
x2
i + 
xi aij xj = 2 
x2
i + 2  
i,j
aij xixj
 i i,j, i=j i i&lt;j
which is even.
Denition 5.13. A root with respect to a certain positive inner product is a shortest (with respect 
  to this inner product), nonzero vector in Zn. 
So for the inner product B, a root  is a nonzero vector x  Znsuch that 
B(x,x) = 2. 
Remark 5.14. There can be only nitely many roots, since all of them have to lie in some ball. 
Denition 5.15. We call vectors of the form 
ith 
i = (0,..., 1 ,..., 0) 
simple roots. 
The  i naturally form a basis of the lattice Zn. 
Lemma 5.16. Let   be a root,  = n
i=1 kii. Then either ki  0 for all i or ki  0 for all i.
Proof. Assume the contrary, i.e., ki &gt; 0, kj &lt; 0. Without loss of generality, we can also assume 
that ks = 0 for all s between i and j. We can identify the indices i,j with vertices of the graph . 
 i 
  
i   j</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 18.712 Introduction to Representation Theory
Fall 2010</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>be surjective and let 
K = ker . 
When applying F
+
i , the space Vi gets replaced by K. Furthermore, let 

 : K 

Vj . 
ji 
After applying Fi, K gets replaced by 
K =

 
V
j 
ji 
/(Im ).
But 
Im = K 
and therefore 
 
K =

Vj  
 
 

/

ker( :

Vj Vi) 
 
= Im( :

Vj  Vi)
ji ji ji 
by the homomorphism theorem. Since  was assumed to be surjective, we get 
K = Vi. 
Proposition 5.30. Let Q be a quiver, and V be an indecomposable representation of Q. Then 
F
+
i V
and FiV (whenever dened) are either indecomposable or 0.
Proof. We prove the proposition for F
+
i V - the case FiV follows similarly. By Proposition 5.28 it
follows that either 
 :
Vj 
j i  Vi 

is surjective or dim Vi = 1, dim Vj = 0, j =  i. In the last case 
F
+
i V = 0.
So we can assume that  is surjective. In this case, assume that F
+
i V is decomposable as
F
+
i V = X  Y
with X,Y = 0. But F+
i V is injective at i, since the maps are canonical projections, whose direct
sum is the tautological embedding. Therefore X and Y also have to be injective at i and hence (by 
5.29) 
F
+F+
i iX = X, F
i FiY = Y
In particular 
FiX = 0, FiY = 0. 
Therefore 
V
= FiF
+
i V
= FiX  FiY
which is a contradiction, since V was assumed to be indecomposable. So we can infer that
F
+
i V
is indecomposable.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>1. Let i  Q be a sink. Then either dim Vi = 1, dim Vj = 0 for j =  i or
 :  
Vj  Vi 
ji 
is surjective. 
2. Let i  Q be a source. Then either dim Vi = 1, dim Vj = 0 for j =  i or
 
 : Vi  
Vj 
ij 
is injective. 
Proof. 1. Choose a complement W of Im. Then we get 
W 
       
0 0    V=  V
 
0 
Since V is indecomposable, one of these summands has to be zero. If the rst summand is 
zero, then  has to be surjective. If the second summand is zero, then the rst one has to be 
of the desired form, because else we could write it as a direct sum of several objects of the 
type 
1       
0 
0 
 0 
which is impossible, since V was supposed to be indecomposable. 
2. Follows similarly by splitting away the kernel of . 
Proposition 5.29. Let Q be a quiver, V be a representation of Q. 
1. If 
 :  
V
j  Vi 
ji 
is surjective, then 
FiF+
i V = V.
2. If 
 : Vi   
Vj 
ij 
is injective, then 
F
+
i FiV = V.
Proof. In the following proof, we will always mean by i  j that i points into j in the original
quiver Q. We only establish the rst statement and we also restrict ourselves to showing that the
spaces of V and FiF+
i V are the same. It is enough to do so for the i-th space. Let
 
 : 
Vj  Vi 
ji</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>These two corollaries show that there are only nitely many indecomposable representations 
(since there are only nitely many roots) and that the dimension vector of each of them is a positive 
root. The last statement of Gabriels theorem follows from 
Corollary 5.37. For every positive root , there is an indecomposable representation V with 
d(V ) = . 
Proof. Consider the sequence 
sn,sn1sn,... 
Consider the rst element of this sequence which is a negative root (this has to happen by Lemma 
5.33) and look at one step before that, calling this element . So  is a positive root and si is a 
negative root for some i. But since the si only change one coordinate, we get 
 = i 
and 
(sq ...sn1sn) = i. 
We let C(i) be the representation having dimension vector i. Then we dene 
V = FnF n
1 ...FqC(i). 
This is an indecomposable representation and 
d(V ) = . 
Example 5.38. Let us demonstrate by example how reection functors work. Consider the quiver 
D4 with the orientation of all arrows towards the node (which is labeled by 4). Start with the 
1-dimensional representation V4 sitting at the 4-th vertex. Apply to V4 the functor F3F2F1. 
This yields 
F1F2F3V4 = V1+2+3+4 . 
Now applying F4we get 
F4F1F2F3V4 = V1+2+3+24 . 
Note that this is exactly the inclusion of 3 lines into the plane, which is the most complicated 
indecomposable representation of the D4 quiver. 
5.9 Problems 
Problem 5.39. Let Qn be the cyclic quiver of length n, i.e., n vertices connected by n oriented edges 
forming a cycle. Obviously, the classication of indecomposable representations of Q1 is given by 
the Jordan normal form theorem. Obtain a similar classication of indecomposable representations 
of Q2. In other words, classify pairs of linear operators A : V  W and B : W  V up to 
isomorphism. Namely: 
(a) Consider the following pairs (for n  1): 
1) En,: V =  W = Cn, A is the Jordan block of size n with eigenvalue , B = 1 (  C). 
2) En,: is obtained from E  n,0 by exchanging V with W and A with B.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>So - considering the rst summand and renaming the spaces to simplify notation - we are in a 
situation where 
V = V1 + V2 + V3, V 1  V2  V3 = 0. 
As a next step, we let Y = V1  V2 and we choose a complement V  of Y in V such that V3
  
V ,
and set V
1= V  V1,V2= V  V2. This yields the decomposition
 V   V   Y 
 
V
1 
V
3 V

1  
  
 
 
V
3Y 0

=
 
  
 


 
 
V2 V
2Y
The second summand is a multiple of the indecomposable object 
 1 
  .
1 0


1
In the resulting situation we have V1  V2 = 0. Similarly we can split away multiples of 
 1  1  
1
     
1 0 1 
and  
 0 1
 
to reach a situation where the spaces V
1,V2,V3 do not intersect pairwise 
V1  V2 = V1  V3 = V2  V3 = 0. 
If V1  V2  V3 we let Y = V1  (V2  V3). We let V1be a complement of Y in V1. Since then 
 V1 (V2  V3) = 0, we can select a complement V of V 1
 in V which contains V2  V3. This gives
us the decomposition 
 V     V  
 
 
 
V1 VV
3 V

11
  
  0
Y


V
3
= 


 

 
V2 
0
 V
2
The rst of these summands is a multiple of 
 1   
1
0
 

0
 
By splitting these away we get to a situation where V1  V2  V3. Similarly, we can split away 
objects of the type 
1 1      
       
0 0 0 1 
 and 
 
10 
to reach a situation in which the following conditions hold</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Theorem 5.34. There is m  N, such that 
d 
V (m) 
= p 
for some p. 
Proof. If V (i) is surjective at the appropriate vertex k, then 
d 
V (i+1)
= d 
F +
 V (i)
= s
V (i)
k kd
. 
 This implies, that if V (0),...,V (i1)are surjective at the appropriate vertices, then 
d 
V (i) 
= ...sn1snd(V ). 
 
By Lemma 5.33 this cannot continue indenitely - since d 
V (i)
may not have any negative entries. 
 Let i be smallest number such that V (i)is not surjective at the appropriate vertex. By Proposition 
5.30 it is indecomposable. So, by Proposition 5.28, we get 
d(V (i)) = p 
for some p. 
We are now able to prove Gabriels theorem. Namely, we get the following corollaries. 
Corollary 5.35. Let Q be a quiver, V be any indecomposable representation. Then d(V ) is a 
positive root. 
Proof. By Theorem 5.34 
si1 ...sim (d(V )) = p. 
Since the si preserve B, we get 
B(d(V ),d(V )) = B(p,p) = 2. 
Corollary 5.36. Let V,V  be indecomposable representations of Q such that d(V ) = d(V ). Then 
V and V  are isomorphic. 
Proof. Let i be such that 
d 
 (i)  
V (i)
= p. 
Then we also get d 
V 
= p. So 
V (i) = V (i) =:  V i. 
Furthermore we have 
V (i) = F + ...F + F +V (0) 
k n1 n 
 (i)  V   =F+
k ...F +
n1F+
n V (0). 
But  both V (i1),...,V (0)and V (i1)  ,...,V (0)have to be surjective at the appropriate vertices. 
This implies 
 + + + (0) (0) 
F F ...F V i FnF n
1 ...F F  ...F n1Fn V = V = V =  k knn
1 k      F  +
nF
1 ...F kF+
k ...F +(0) (0)
n n1F  
n V = V = V</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Proof. c belongs to a nite group W . So there is M  N, such that 
c M = 1. 
We claim that 
1 + c + c 2 +  c M1 + = 0 
as operators on Rn . This implies what we need, since  has at least one strictly positive coecient, 
so one of the elements 
c,c2,...,cM1 
must have at least one strictly negative one. Furthermore, it is enough to show that 1 is not an 
eigenvalue for c, since 
(1 + c + c 2 + + c M1)v = w = 0 
 
 cw = c 1 + c  2 +c +  + c M1v =2 3 (c + c + c +  + c M1 + 1)v = w. 
Assume the contrary, i.e.,
 1 is a eigenvalue of c
 and let v be a corresponding eigenvector. 
cv = v s1 ...snv = v
 s2 ...snv = s1v. 
But since si only changes the i-th coordinate of v, we get 
s1v = v and s2 ...snv = v. 
Repeating the same procedure, we get 
siv = v 
for all i. But this means 
B(v, i) = 0. 
for all i, and since B is nondegenerate, we get v = 0. But this is a contradiction, since v is an 
eigenvector. 
5.8 Proof of Gabriels theorem 
Let V be an indecomposable representation of Q. We introduce a xed labeling 1,...n on Q, such 
that i&lt;j if one can reach j from i. This is possible, since we can assign the highest label to any 
sink, remove this sink from the quiver, assign the next highest label to a sink of the remaining 
quiver and so on. This way we create a labeling of the desired kind. 
We now consider the sequence 
 (0)    (1)   +   (2)   +  + V=V, V =Fn V, V =FnF1n V,... 
This sequence is well dened because of the selected labeling: n has to be a sink of Q, n  1 has 
to be a sink of Qn (where Qn is obtained from Q by reversing all the arrows at the vertex r) and 
so on. Furthermore, we note that V (n) is a representation of Q again, since every arrow has been 
reversed twice (since we applied a reection functor to every vertex). This implies that we can 
dene 
V (n+1) = F+
n V (n),... 
and continue the sequence to innity.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>5 Quiver Representations 
5.1 Problems 
Problem 5.1. Field embeddings. Recall that k(y1,...,y m) denotes the eld of rational functions 
of y1,...,y m over a eld k. Let f : k[x1,...,x n]  k(y1,...,y m) be an injective k-algebra homomor
phism. Show that m  n. (Look at the growth of dimensions of the spaces WN of polynomials of 
degree N in xi and their images under f as N  ). Deduce that if f : k(x1,...,x n)  k(y1,...,y m) 
is a eld embedding, then m  n. 
Problem 5.2. Some algebraic geometry. 
Let k be an algebraically closed eld, and G = GLn(k). Let V be a polynomial representation 
of G. Show that if   Ghas nitely many orbits on V then dim(V )  n2. Namely: 
(a) Let x1,...,x N be linear coordinates on V . Let us say that a subset X of V is Zariski dense 
if any polynomial f(x1,...,x N ) which vanishes on X is zero (coecientwise). Show that if G has 
nitely many orbits on V then G has at least one Zariski dense orbit on V . 
(b) Use (a) to construct a eld embedding k(x1,...,x N )  k(gpq), then use Problem 5.1. 
(c) generalize the result of this problem to the case when G = GLn1 (k)  ...  GLnm (k). 
Problem 5.3. Dynkin diagrams. 
Let  be a graph, i.e., a nite set of points (vertices) connected with a certain number of edges 
(we allow multiple edges). We assume that  is connected (any vertex can be connected to any 
other by a path of edges) and has no self-loops (edges from a vertex to itself). Suppose the vertices 
of  are labeled by integers 1,...,N . Then one can assign to  an N  N matrix R = (r ij ), where 
rij is the number of edges connecting vertices i and j. This matrix is obviously symmetric, and is 
called the adjacency matrix. Dene the matrix A = 2I  R, where I is the identity matrix. 
Main denition:  is said to be a Dynkin diagram if the quadratic from on RN with matrix 
A is positive denite. 
Dynkin diagrams appear in many areas of mathematics (singularity theory, Lie algebras, rep
resentation theory, algebraic geometry, mathematical physics, etc.) In this problem you will get a 
complete classication of Dynkin diagrams. Namely, you will prove 
Theorem.  is a Dynkin diagram if and only if it is one on the following graphs: 
 An :         
     
 D:     
 n|
 E6 :             
|</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>5.6 Reection Functors 
Denition 5.24. Let Q be any quiver. We call a vertex i  Q a sink if all edges connected to i 
point towards i. 
i     
We call a vertex i  Q a source if all edges connected to i point away from i. 
i    
 
Denition 5.25. Let Q be any quiver and i  Q be a sink (a source). Then we let Qi be the 
quiver obtained from Q by reversing all arrows pointing into (pointing out of) i. 
We are now able to dene the reection functors (also called Coxeter functors ). 
Denition 5.26. Let Q be a quiver, i  Q be a sink. Let V be a representation of Q. Then we 
dene the reection functor 
F
+
i : RepQ  RepQ i
by the rule 
F+
i (V )k = Vk if k = i

F
+
i (V )i = ker 

 :

Vj  Vi
.
ji 
Also, all maps stay the same but those now pointing out of i; these are replaced by compositions 
of the inclusion of ker  into Vj with the projections Vj  Vk. 
Denition 5.27. Let Q be a quiver, i  Q be a source. Let V be a representation of Q. Let  be 
the canonical map 
 : Vi Vj . 
ij
Then we dene the reection functor 
Fi : RepQ  RepQ i 
by the rule 
Fi(V )k = Vk if k = i
 
Fi(V )i = Coker () = 
V
j
 /Im.
ij 
Again, all maps stay the same but those now pointing into i; these are replaced by the compositions 
of the inclusions Vk   i jVj with the natural map  Vj  V j/Im. 
Proposition 5.28. Let Q be a quiver, V an indecomposable representation of Q.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>1. V1 + V2 + V3 = V. 
2. V1  V2 = 0, V 1  V3 = 0, V 2  V3 = 0. 
3. V1  V2  V3, V 2  V1  V3, V 3  V1  V2. 
But this implies that 
V1  V2 = V1  V3 = V2  V3 = V. 
So we get 
dim V1 = dim V2 = dim V3 = n 
and 
dim V = 2n. 
Since V3  V1  V2 we can write every element of V3 in the form 
x  V3, x = (x 1,x2), x1  V1, x2  V2. 
We then can dene the projections 
B1 : V3  V1, (x1,x2)  x1, 
B2 : V3  V2, (x1,x2)  x2. 
Since V3  V1 = 0,V 3  V2 = 0, these maps have to be injective and therefore are isomorphisms. We 
then dene the isomorphism 
 1 A = B2 B1 : V1  V2.
Let e1,...,e n be a basis for V1. Then we get 
V1 = C e1  C e2    C en 
V2 = C Ae1  C Ae2    C Aen
V3 = C (e1 + Ae1)  C (e2 + Ae2)    C (en + Aen).
So we can think of V3 as the graph of an isomorphism A : V1  V2. From this we obtain the 
decomposition 
  V    C2    
V 
3 n1 
V  C(1
, 0) 
C(1
, 1) 
= 
    j=1
V2 C(0 
, 1) 
These correspond to the indecomposable object 
2     
1 
1
 
 
1 
Thus the quiver D4 with the selected orientation has 12 indecomposable objects. If one were to 
explicitly decompose representations for the other possible orientations, one would also nd 12 
indecomposable objects. 
It appears as if the number of indecomposable representations does not depend on the orienta
tion of the edges, and indeed - Gabriels theorem will generalize this observation.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>(d) Which groups from Problem 3.24 correspond to which diagrams? 
(e) Using the McKay graph, nd the dimensions of irreducible representations of all nite 
G SU(2) (namely, show that they are the numbers labeling the vertices of the ane Dynkin
diagrams on our pictures). Compare with the results on subgroups of SO(3) we obtained in 
Problem 3.24. 
5.2 Indecomposable representations of the quivers A1, A2, A3 
We have seen that a central question about representations of quivers is whether a certain connected 
quiver has only nitely many indecomposable representations. In the previous subsection it is shown 
that only those quivers whose underlying undirected graph is a Dynkin diagram may have this 
property. To see if they actually do have this property, we rst explicitly decompose representations 
of certain easy quivers. 
Remark 5.6. By an object of the type 1 0 we mean a map from a one-dimensional vector 
space to the zero space. Similarly, an object of the type 0 1 is a map from the zero space into 
a one-dimensional space. The object 1 1 means an isomorphism from a one-dimensional to 
another one-dimensional space. The numbers in such diagrams always mean the dimension of the 
attached spaces and the maps are the canonical maps (unless specied otherwise) 
Example 5.7 (A1). The quiver A1 consists of a single vertex and has no edges. Since a repre
sentation of this quiver is just a single vector space, the only indecomposable representation is the 
ground eld (=a one-dimensional space). 
Example 5.8 (A2). The quiver A2 consists of two vertices connected by a single edge. 
 
A representation of this quiver consists of two vector spaces V,W and an operator A : V  W . 
A  
V W
   To decompose this representation, we rst let V be a complement to the kernel of A in V and 
let W  be a complement to the image of A in W . Then we can decompose the representation as 
follows 
A 
VA 
W0 0=   ker  A 0  V ImA 0 W
 
The rst summand is a multiple of the object 1 0 , the second a multiple of 1 1 , the 
third of 0 1 . We see that the quiver A2 has three indecomposable representations, namely 
1 0 , 1 1 and 0 1 . 
Example 5.9 (A3). The quiver A3 consists of three vertices and two connections between them. 
So we have to choose between two possible orientations. 
    or 
1. We rst look at the orientation 
   .</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>http://www-math.mit.edu/~etingof/repb.pdf</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/http://www-math.mit.edu/~etingof/repb.pdf</lecture_pdf_url>
      <lectureno>0</lectureno>
      <slides/>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch3</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch3/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>7</slideno>
          <text>wi: wi
(u) = (u,w i). Then for x  G we have (xwi,wj) = (xw i,wj ). Therefore, putting P =  1 
xG x, we have |G| 
V W | |1 = (tij ,tij )G (xvi,v1j )(xw i ,wj ) = |G|
(xvi,vj )(xwi
 ,wj
 ) = (P (vi  wi
 ),vj  wj
 ) 
xG xG 
If V = W, this is zero, since P projects to the trivial representation, which does not occur in 
V  W . If V = W, we need to consider (P (vi  vi
 ),vj  vj
 ). We have a G-invariant decomposition 
V  V  =C  L 
C = span( 
vk  vk) 
 
L = spana:Pakk =0(
aklvk k  vl), 
k,l 
and P projects to the rst summand along the second one. The projection of vi  vi
 to CC  L
is thus ii
  
v  
vdim V 
kk
This shows that       iijj (P(vi vi ),vj vj ) =dim V 
which nishes the proof of (i) and (ii). The last statement follows immediately from the sum of 
squares formula. 
3.8 Character tables, examples 
The characters of all the irreducible representations of a nite group can be arranged into a char
acter table, with conjugacy classes of elements as the columns, and characters as the rows. More 
specically, the rst row in a character table lists representatives of conjugacy classes, the second 
one the numbers of elements in the conjugacy classes, and the other rows list the values of the 
characters on the conjugacy classes. Due to Theorems 3.8 and 3.9 the rows and columns of a 
character table are orthonormal with respect to the appropriate inner products. 
Note that in any character table, the row corresponding to the trivial representation consists 
of ones, and the column corresponding to the neutral element consists of the dimensions of the 
representations. 
S3 Id (12) (123) 
# 1 3 2 
Here is, for example, the character table of S3 : C+ 1 1 1 
C 1 -1 1 
C2 2 0 -1 
It is obtained by explicitly computing traces in the irreducible representations. 
For another example consider A4, the group of even permutations of 4 items. There are three 
one-dimensional representations (as A4 has a normal subgroup Z2  Z2, and A4/Z2  Z2 = Z3). 
Since there are four conjugacy classes in total, there is one more irreducible representation of 
dimension 3. Finally, the character table is</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>The 5 conjugacy classes are {1}, {1}, {i}, {j}, {k}, so there are 5 dierent irreducible 
representations, the sum of the squares of whose dimensions is 8, so their dimensions must 
be 1, 1, 1, 1, and 2. 
The center Z(Q8) is {1}, and Q8/Z(Q8) = Z2  Z2. The four 1-dimensional irreducible 
representations of Z2  Z2 can be pulled back to Q8. That is, if q : Q8  Q8/Z(Q8) is the 
quotient map, and  any representation of Q8/Z(Q8), then   q gives a representation of Q8. 
The 2-dimensional representation is V = C2, given by (1) = Id and 
 0 1(i) = 1 0   1 0 0    1, (j ) = , (k ) =	 . (3)0	 1  
 1 0 
These are the Pauli matrices, which arise in quantum mechanics. 
Exercise. Show that the 2-dimensional irreducible representation of Q8 can be realized in 
the space of functions f : Q8  C such that f(gi) = 1f(g) (the action of G is by right 
multiplication, g  f(x) = f(xg)). 
4. The	symmetric group S4. The order of S4 is 24, and there are 5 conjugacy classes: 
e, (12), (123), (1234), (12)(34). Thus the sum of the squares of the dimensions of 5 irreducible 
representations is 24. As with S3, there are two of dimension 1: the trivial and sign repre
sentations, C+ and C. The other three must then have dimensions 2, 3, and 3. Because 
S3 = S4/Z2  Z2, where Z2  Z2 is {e, (12)(34), (13)(24), (14)(23) }, the 2-dimensional repre
sentation of S3 can be pulled back to the 2-dimensional representation of S4, which we will 
call C2 . 
We can consider S4 as the group of rotations of a cube acting by permuting the interior 
diagonals (or, equivalently, on a regular octahedron permuting pairs of opposite faces); this 
gives the 3-dimensional representation C3 
+. 
The  last 3-dimensional representation is C3, the product of C3 with the sign representation.  +
C3 
+ and C3 are dierent, 
 for if g is a transposition, det g|
C3= 1 while det g|
= ( 1)3
C3= 1.+ 
 
Note that another realization of C3 
 is by action of S4 by symmetries (not necessarily rotations) 
of the regular tetrahedron. Yet another realization of this representation is the space of 
functions on the set of 4 elements (on which S4 acts by permutations) with zero sum of 
values. 
.4 Duals and tensor products of representations 
f V is a  representation of a group G, then V is also a representation, via 
  V  (g) = ( V (g))1= ( V (g)1)= V (g1). 
he character is 1V  (g) = V (g). 
 We have V (g) = i, where the i are the eigenvalues of g in V . These eigenvalues must be 
oots of unity because  (g)|G|= (g|G|) = (e) = Id. Thus for complex representations 
    V  (g) = 1 (g) = 
1V i
 = 
i = 
i = V (g). 
n particular, V = V  as representations (not just as vector spaces) if and only if V (g)  R for all 
  G. 3
I
T
r
I 
g</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>A4 Id (123) (132) (12)(34)
#
1 4 4 3 
C 1 1 1 1 
C 1  2 1
C 1 22  1
C3 3 0 0 1 
where  = exp( 2i ). 3 
The last row can be computed using the orthogonality of rows. Another way to compute the 
 last row is to note that C3is the representation of A4 by rotations of the regular tetrahedron: in 
this case (123), (132) are the  rotations by 1200and 2400 around a perpendicular to a face of the 
tetrahedron, while (12)(34) is the rotation by 1800 around an axis perpendicular to two opposite 
edges. 
Example 3.15. The following three character tables are of Q8, S4, and A5 respectively. 
1 
(123) C+
C
+ 
 
 -1 Q8 i j k
# 1 1 2 2 2 
C++ 1 1 1 1 1
1
1 1 -1 -1 
1 1 -1 1 -1 
C 1 1 -1 -1 1 
C2 2 -2 0 0 0 
Id (12) S4 (12)(34) (1234)
#
1 6 3 8 6 
C+ 1 1 1 1 1
C 1 -1 1 1 -1 
C2 2 0 2 -1 0 
C3 
+
3 -1 -1 0 1
C3
3 1 -1 0 -1 
1 A5 Id (123) (12)(34) (12345) (13245)
# 1 20 15 12 12 
C 1 1 1 1 
C3 3 0 -1 1+
5 
+ 2
C3 3 0  1
5 -1 2 
C4 4 1 0 -1 1
5 
C5 5 -1 1 0 0 2
1+
5 
2 
-1 
Indeed, the computation of the characters of the 1-dimensional representations is straightfor
ward. 
The character of the 2-dimensional representation of Q8 is obtained from the explicit formula 
(3) for this representation, or by using the orthogonality. 
For S4, the 2-dimensional irreducible representation is obtained from the 2-dimensional irre
ducible representation of S3 via the surjective homomorphism S4  S3, which allows to obtain its 
character from the character table of S3. 
The character of the  3-dimensional representation C3+ is computed from its geometric realization 
by rotations of the cube. Namely, by rotating the cube, S4 permutes the main diagonals. Thus 
(12) is the  rotation by 1800around an axis that is perpendicular to two opposite edges, (12)(34)</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Problem 3.21. Let I be the set of vertices of a regular icosahedron (|I|= 12). Let Fun(I ) be the 
space of complex functions on I. Recall that the group G = A5 of even permutations of 5 items 
acts on the icosahedron, so we have a 12-dimensional representation of G on Fun(I ). 
(a) Decompose this representation in a direct sum of irreducible representations (i.e., nd the 
multiplicities of occurrence of all irreducible representations). 
(b) Do the same for the representation of G on the space of functions on the set of faces and 
the set of edges of the icosahedron. 
Problem 3.22. Let Fq be a nite eld with q elements, and G be the group of nonconstant inho
mogeneous linear transformations, x  ax + b, over Fq (i.e., a  F
q ,b  Fq). Find all irreducible 
complex representations of G, and compute their characters. Compute the tensor products of irre
ducible representations. 
Hint. Let V be the representation of G on the space of functions on Fq with sum of all values 
equal to zero. Show that V is an irreducible representation of G. 
Problem 3.23. Let G = SU(2) (unitary 2 by 2 matrices with determinant 1), and V = Cthe 
standard 2-dimensional representation of SU(2). We consider V as a real representation, so it is 
4-dimensional. 
(a) Show that V is irreducible (as a real representation). 
(b) Let H be the subspace of End R(V ) consisting of endomorphisms of V as a real representation. 
Show that H is 4-dimensional and closed under multiplication. Show that every nonzero element in 
H is invertible, i.e., H is an algebra with division. 
(c) Find a basis 1,i,j,k of H such that 1 is the unit and i2 = j2 = k2 = 1, ij = ji = k,jk = 
kj = i,ki = ik =  j. Thus we have that Q8 is a subgroup of the group Hof invertible elements 
of H under multiplication. 
The algebra H is called the quaternion algebra. 
(d) For q = a+bi+cj+dk, a,b,c,d  R, let q = abicjdk, and ||q||2 = qq = a2 +b2 +c2 . 
Show that q1q2 = q2q1, and ||q1q2|| = ||q1||  ||q2||. 
(e) Let G be the group of quaternions of norm 1. Show that this group is isomorphic to SU(2). 
(Thus geometrically SU(2) is the 3-dimensional sphere). 
(f) Consider the action of G on the space V  H spanned  by i,j,k, by x  qxq1, q G, 
x  V . Since this action preserves the norm on V , we have a homomorphism h : SU(2)  SO(3), 
where SO(3) is the group of rotations of the three-dimensional Euclidean space. Show that this 
homomorphism is surjective and that its kernel is {1, 1}. 
Problem 3.24. It is known that the classication of nite subgroups of SO(3) is as follows: 
1) the cyclic group Z/nZ, n  1, generated by a rotation by 2/n around an axis; 
2) the dihedral group Dn of order 2n, n  2 (the group of rotational symmetries in 3-space of 
a plane containing a regular n-gon5; 
3) the group of rotations of the regular tetrahedron (A4). 
4) the group of rotations of the cube or regular octahedron (S4). 
5) the group of rotations of a regular dodecahedron or icosahedron (A5). 
5A regular 2-gon is just a line segment.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>A5 
C
C3 
+ 
C3 

C4
C5 C
C 
C  3 C+
C+
3 
C5  3 C+
C C3 

C3

C4   C5
   C5 C3
+ 
C3 
+ C4 
C4 
C3   C4 C5

C3  
 C4 C5
+ 
 
  C3 C  C4 C5 
C C5 
C5
C3     C3 C4 C5
+ 
C3  
 
 C3 C4 C5
+ 
 
C3  
   C3 2C5 C4
+ 
  
  C32C42C5
+C3   
3.10 Problems 
Problem 3.17. Let G be the group of symmetries of a regular N-gon (it has 2N elements). 
(a) Describe all irreducible complex representations of this group (consider the cases of odd and 
even N) 
(b) Let V be the 2-dimensional complex representation of G obtained by complexication of the 
standard representation on the real plane (the plane of the polygon). Find the decomposition of 
V  V in a direct sum of irreducible representations. 
Problem 3.18. Let G be the group of 3 by 3 matrices over Fp which are upper triangular and have 
ones on the diagonal, under multiplication (its order is p3). It is called the Heisenberg group. For 
      p any complex number zsuch thatz= 1 we dene a representation of G on the space V of complex 
functions on Fp, by 

1 1 0
(
0 1 0

0 0 1

f)(x) = f(x  1),
1 0 0
(

0 1 1


f)(x) = z
xf(x).
0 0 1 
(note that zx makes  sense since zp= 1). 
(a) Show that such a representation exists and is unique, and compute (g) for all g  G. 
(b) Denote this representation by Rz. Show that Rz is irreducible if and only if z = 1.
(c) Classify all 1-dimensional representations of G. Show that R1 decomposes into a direct sum 
of 1-dimensional representations, where each of them occurs exactly once. 
(d) Use (a)-(c) and the sum of squares formula to classify all irreducible representations of 
G. 
Problem 3.19. Let V be a nite dimensional complex vector space, and GL(V ) be the group of 
invertible linear transformations of V . Then SnV and mV (m  dim(V )) are representations of 
GL(V ) in a natural way. Show that they are irreducible representations. 
Hint: Choose a basis {ei} in V . Find a diagonal element H of GL(V ) such that (H) has 
distinct eigenvalues. (where  is one of the above representations). This shows that if W is a 
subrepresentation, then it is spanned by a subset S of a basis of eigenvectors of (H). Use the 
invariance of W under the operators (1+ Eij ) (where Eij is dened by Eij ek = jkei) for all i = j
to show that if the subset S is nonempty, it is necessarily the entire basis. 
Problem 3.20. Recall that the adjacency matrix of a graph  (without multiple edges) is the matrix 
in which the ij-th entry is 1 if the vertices i and j are connected with an edge, and zero otherwise. 
Let  be a nite graph whose automorphism group is nonabelian. Show that the adjacency matrix 
of  must have repeated eigenvalues.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Recall that the group SO(3) of rotations acts on V , so S2V , End(V ) are representations of this 
group. The laws of physics must be invariant under this group (Galileo transformations), so f must 
be a homomorphism of representations. 
(a) Show that End(V ) admits a decomposition RV W , where R is the trivial representation, 
V is the standard 3-dimensional representation, and W is a 5-dimensional representation of SO(3). 
Show that S2V = R  W 
(b) Show that V and W are irreducible, even after complexication. Deduce using Schurs 
lemma that SP is always symmetric, and for x  R,y  W one has f(x + y) = Kx + y for some 
real numbers K,. 
In fact, it is clear from physics that K, are positive. Physically, the compression modulus K 
characterises resistance of the material to compression or dilation, while the shearing modulus  
characterizes its resistance to changing the shape of the object without changing its volume. For 
instance, clay (used for sculpting) has a large compression modulus but a small shearing modulus.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Exercise. Show that if |G	|= 0 in k then the number of isomorphism classes of irreducible 
representations of G over k is strictly less than the number of conjugacy classes in G. 
 Hint. Let P =  
g G g  k[G]. Then P 2= 0. So P has zero trace in every nite dimensional 
representation of G over k. 
Corollary 3.7. Any representation of G is determined by its character if k has characteristic 0; 
namely, V = W implies V = W . 
3.3 Examples 
The following are examples of representations of nite groups over C. 
1. Finite  abelian groups G = Zn1    Znk . Let Gbe the set of irreducible representations 
of G. Every element of G forms a conjugacy class, so |G| = |G|. Recall that all irreducible 
representations over C (and algebraically closed elds in general) of commutative algebras and 
groups are one-dimensional. Thus, G is an abelian group: if 1,2 : G 
  C are irreducible 
representations then so are 1(g)2(g) and 1(g)1. G is called the dual or character group 
of G. 
For given n  1, dene  : Zn  C by (m) = e2im/n. Then Z
n = {k : k = 0,...,n  1}, 
so Z
n = Zn. In general, 
     (G1 G2 Gn) = G1
  G
2    Gn , 
so G = G for any nite abelian group G. This isomorphism is, however, noncanonical: 
the particular decomposition of G as Zn1    Znk is not unique as far as which elements 
of	G correspond to Zn1 , etc. is concerned. On =  the other hand, G 
(G)is a canonical 
isomorphism, given by  : G  (G), where (g)() = (g).
2. The symmetric group	S3. In Sn, conjugacy classes are determined by cycle decomposition 
sizes: two permutations are conjugate if and only if they have the same number of cycles 
of each length. For S3, there are 3 conjugacy classes, so there are 3 dierent irreducible 
  representations over C. If their dimensions are d1,d2,d2223, then d1+d2 +d3= 6, so S3 must have 
two 1-dimensional and one 2-dimensional representations. The 1-dimensional representations 
are the trivial representation C+ given by () = 1 and the sign representation C given by 
() ( 
= 1). 
The 2-dimensional representation can be visualized as representing the symmetries of the 
equilateral triangle with vertices 1, 2, 3 at the points (cos 120, sin120), (cos 240, sin240), 
(1, 0) of the coordinate plane, respectively. Thus, for example, 
 	   1 0 cos 120 sin120
((12)) = 
, ((123)) =	

. 0	1 
sin 120 cos 120 
To show that this representation is irreducible, consider any subrepresentation V . V must be 
the span of a subset of the eigenvectors of ((12)), which are the nonzero multiples of (1, 0) 
and (0, 1). V must also be the span of a subset of the eigenvectors of ((123)), which are 
dierent vectors. Thus,  V must be either C2or 0. 
3. The quaternion group Q8 = {1, i, j, k}, with dening relations 
i = jk = kj, j  = ki = ik, k = ij =   ji, 1 = i2= j2= k2.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Theorem 3.8 gives a powerful method of checking if a given complex representation V of a nite 
group G is irreducible. Indeed, it implies that V is irreducible if and only if (V ,V ) = 1. 
Exercise. Let G be a nite group. Let Vi be the irreducible complex representations of G. 
For every i, let 
dim V i  
  1 i = |V(g)g  C [G] . G | i
gG 
(i) Prove that i acts on Vj as the identity if j = i, and as the null map if j =  i.
 (ii) Prove that i are idempotents, i.e., 2
i = i for any i, and ij = 0 for any i =  j.
Hint: In (i), notice that i commutes with any element of k [G], and thus acts on Vj as an 
intertwining operator. Corollary 1.17 thus yields that i acts on Vj as a scalar. Compute this 
scalar by taking its trace in Vj . 
Here is another orthogonality formula for characters, in which summation is taken over irre
ducible representations rather than group elements. 
Theorem 3.9. Let g,h  G, and let Zg denote the centralizer of g in G. Then 
  |Zg| if g is conjugate to h V (g)V (h) = 0, otherwise 
V 
where the summation is taken over all irreducible representations of G. 
Proof. As noted above, V (h) = V  (h), so the left hand side equals (using Maschkes theorem): 
 
V (g)V  (h) = Tr|V V V  (g  (h)1) =  
V 
Tr|V EndV (x  gxh1) = Tr|C[G](x  gxh1). 
  Ifg and h are not conjugate, this trace is clearly zero, since the matrix of the operator x  gxh1
in the basis of group elements has zero diagonal entries. On the other hand, if g and h are in the 
same conjugacy class, the trace is equal to the number of elements x such that x = gxh1, i.e., the 
order of the centralizer Zg of g. We are done. 
Remark. Another proof of this result is as follows. Consider the matrix U whose rows are 
labeled by irreducible representations of G and columns by conjugacy classes, with entries UV,g = 
V (g)/|Zg|. Note that the conjugacy class of g is G/Z g, thus |G|/|Z g| is the number of elements 
conjugate to G. Thus, by Theorem 3.8, the rows of the matrix U are orthonormal. This means 
that U is unitary and hence its columns are also orthonormal, which implies the statement. 
3.6	Unitary representations. Another proof of Maschkes theorem for complex 
representations 
Denition 3.10. A unitary nite dimensional representation of a group G is a representation of G 
on a complex nite dimensional vector space V over C equipped with a G-invariant positive denite 
Hermitian form4 (, ), i.e., such that V (g) are unitary operators: (V (g)v, V (g)w) = (v,w ). 
4We agree that Hermitian forms are linear in the rst argument and antilinear in the second one.</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>(a) Derive this classication. 
Hint. Let G be a nite subgroup of SO(3). Consider the action of G on the unit sphere. A 
point of the sphere preserved by some nontrivial element of G is called a pole. Show that every 
nontrivial element of G xes a unique pair of opposite poles, and that the subgroup of G xing a 
particular pole P is cyclic, of some order m (called the order of P). Thus the orbit of P has n/m 
elements, where n = |G|. Now let P1,...,P k be the poles representing all the orbits of G on the set 
of poles, and m1,...,m k be their orders. By counting nontrivial elements of G, show that 
1 12(1  ) = (1  ). n mii 
Then nd all possible mi and n that can satisfy this equation and classify the corresponding groups. 
(b) Using this classication, classify nite subgroups of SU(2) (use the homomorphism SU(2) 
SO(3)). 
Problem 3.25. Find the characters and tensor products of irreducible complex representations of 
the Heisenberg group from Problem 3.18. 
Problem 3.26. Let G be a nite group, and V a complex representation of G which is faithful, 
i.e., the corresponding map G  GL(V ) is injective. Show that any irreducible representation of 
G occurs inside SnV (and hence inside V n) for some n. 
Hint. Show that there exists a vector  u  V whose stabilizer in G is 1. Now dene the map 
SV  Fun(G, C) sending a polynomial  f on V to the function fu on G given by fu(g) = f(gu). 
Show that this map is surjective and use this to deduce the desired result. 
Problem 3.27. This problem is about an application of representation theory to physics (elasticity 
theory). We rst describe the physical motivation and then state the mathematical problem. 
Imagine a material which occupies a certain region U in the physical space V = R3 (a space 
with a positive denite inner product). Suppose the material is deformed. This means, we have 
applied a dieomorphism (=change of coordinates) g : U  U . The question in elasticity theory 
is how much stress in the material this deformation will cause. 
For every point P  U, let AP : V  V be dened by AP = dg(P ). AP is nondegenerate, 
so it has a polar decomposition AP = DP OP , where OP is orthogonal and DP is symmetric. The 
matrix OP characterizes the rotation part of AP (which clearly produces no stress), and DP is 
the distortion part, which actually causes stress. If the deformation is small, DP is close to 1, so 
DP = 1+ dP , where dP is a small symmetric matrix, i.e., an element of S2V . This matrix is called 
the deformation tensor at P . 
Now we dene the stress tensor, which characterizes stress. Let v be a small nonzero vector in 
V , and  a small disk perpendicular to v centered at P of area ||v||. Let Fv be the force with which 
the part of the material on the v-side of  acts on the part on the opposite side. It is easy to deduce 
from Newtons laws that Fv is linear in v, so there exists a linear operator SP : V  V such that 
Fv = SP v. It is called the stress tensor. 
An elasticity law is an equation SP = f(dP ), where f is a function. The simplest such law is a 
linear law (Hookes law): f : S2V  End(V ) is a linear function. In general, such a function is 
dened by 9  6 = 54 parameters, but we will show there are actually only two essential ones  the
compression modulus K and the shearing modulus . For this purpose we will use representation 
theory.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>rProof. Write k[G] = 
i=1 End Vi, where the Vi are irreducible representations and V1 = k is the 
trivial one-dimensional representation. Then 
k[G] = k  r r
End Vi = k   
diVi, 
i=2 i=2 
where di = dim Vi. By Schurs Lemma, 
Hom k[G](k,k[G]) = k
Hom k[G](k[G],k) = k,
for nonzero homomorphisms of representations  : k[G]  k and  : k  k[G] unique up to scaling.  We can take  such that (g) = 1 for all g  G, and  such that (1) = 
gG g. Then 
  (1) =    
g 
=  
1 = |G|. 
gG g G 
If |G| = 0, then  has no left inverse, as (a)  (1) = 0 for any a  k. This is a contradiction. 
Example 3.3. If G = Z/pZ and k has characteristic p, then every irreducible representation of G 
over k is trivial (so k[Z/pZ] indeed is not semisimple). Indeed, an irreducible representation of this 
group is a 1-dimensional space, on which the generator acts by a p-th root of unity, and every p-th 
root of   unity in k equals 1, as xp 1 = (x  1)pover k. 
Problem 3.4.  Let G be a group of order pn. Show that every irreducible representation of G over 
a eld k of characteristic p is trivial. 
3.2 Characters 
If V is a nite-dimensional representation of a nite group G, then its character V : G  k 
is dened by the formula V (g) = tr|V ((g)). Obviously, V (g) is simply the restriction of the 
character V (a) of V as a representation of the algebra A = k[G] to the basis GA, so it carries 
exactly the same information. The character is a central or class function : V (g) depends only on 
the conjugacy class of g; i.e., 1V (hgh) = V (g). 
Theorem 3.5. If the characteristic of k does not divide |G|, characters of irreducible representa
tions of G form a basis in the space Fc(G,k) of class functions on G. 
Proof. By the Maschke theorem, k[G] is semisimple, so by Theorem 2.17, the characters are linearly 
independent and are a basis of (A/[A,A]), where A = k[G]. It suces to note that, as vector 
spaces over k, 
 (A/[A,A])= {  Hom k(k[G],k)
| gh  hg  ker  g,h  G}
= {f  Fun(G,k ) | f(gh) = f(hg) g,h  G},
which is precisely Fc(G,k). 
Corollary 3.6. The number of isomorphism classes of irreducible representations of G equals the 
number of conjugacy classes of G (if |G|= 0 in k).</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
18.712  Introduction to Representation Theory 
Fall 2010 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Theorem 3.11. If G is nite, then any nite dimensional representation of G has a unitary 
structure. If the representation is irreducible, this structure is unique up to scaling by a positive 
real number. 
Proof. Take any positive denite form B on V and dene another form B as follows: 
B(v,w) =  
B(V (g)v, V (g)w) 
gG 
Then B is a positive denite Hermitian form on V, and V (g) are unitary operators. If V is 
an irreducible representation and B1,B2 are two positive denite Hermitian forms on V, then 
B1(v,w) = B2(Av,w ) for some homomorphism A : V  V (since any positive denite Hermitian 
form is nondegenerate). By Schurs lemma, A = Id, and clearly &gt; 0. 
Theorem 3.11 implies that if V is a nite dimensional representation of a nite group G, then 
the complex conjugate representation V (i.e., the same space V with the same addition and the same 
action of G, but complex conjugate action of scalars) is isomorphic to the dual representation V . 
Indeed, a homomorphism of representations V  V  is obviously the same thing as an invariant 
sesquilinear form on V (i.e. a form additive on both arguments which is linear on the rst one and 
antilinear on the second one), and an isomorphism is the same thing as a nondegenerate invariant 
sesquilinear form. So one can use a unitary structure on V to dene an isomorphism V  V . 
Theorem 3.12. A nite dimensional unitary representation V of any group G is completely re
ducible. 
Proof. Let W be a subrepresentation of V  . Let W be the orthogonal complement of W in V 
under the Hermitian inner product. Then  W is a subrepresentation of W , and V = W  W . 
This implies that V is completely reducible. 
Theorems 3.11 and 3.12 imply Maschkes theorem for complex representations (Theorem 3.1). 
Thus, we have obtained a new proof of this theorem over the eld of complex numbers. 
Remark 3.13. Theorem 3.12 shows that for innite groups G, a nite dimensional representation 
may fail to admit a unitary structure (as there exist nite dimensional representations, e.g. for 
G = Z, which are indecomposable but not irreducible). 
3.7 Orthogonality of matrix elements 
Let V be an irreducible representation of a nite group G, and v1,v2,...,v n be an orthonormal 
basis  of V under the invariant Hermitian form. The matrix elements of V are tV
ij (x) = ( V (x)v i,vj ).
Proposition 3.14. (i) Matrix elements of nonisomorphic irreducible representations are orthog onal in Fun(G, C) under the form (f,g) = 1
x G f(x)g(x). |G| 
(ii) (tV  
ij ,tV
  ) =   1jj ij ii  dim V 
Thus, matrix elements of irreducible representations of G form an orthogonal basis of Fun(G, C). 
Proof. Let V and W be two irreducible representations of G. Take {vi} to be an orthonormal basis 
of V and {wi} to be an orthonormal basis of W under their positive denite invariant Hermitian 
forms. Let  wi W be the linear function on W dened by taking the inner product with</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Example 3.16. The following tables represent computed tensor product multiplicities of irre
C2 
C2 S3 C+ C

C+ C+	Cducible representations of S3,S4, and A5 respectively. C+ 
C2 C2C
3C C+  C  C2 
C3 C2	C3 
+ S4 C+ C
C2	C3 + C+ C+	C
C+ 
C3 
+ C2 
3C+ 2 3 3C C C   + 3C
 C3 C

C2
C3
+ 
C3 3C+ 
 3C+  C3 
 C3 
+  C3 C+  C
C+  C2   C2 
C+  C2 C
 C3  is the rotation by 1800around an axis that is perpendicular to two opposite faces, (123) is the 
rotation around a main diagonal by 1200, and  (1234) is the rotation by 900around an axis that is 
perpendicular to two opposite faces; this allows us to compute the traces easily, using the fact that 
the trace of a rotation by the   angle  in R3is 1 + 2cos .
Now the character of C3is found by
multiplying the character of C3
+ by the character of the sign representation. 
Finally, we explain how to obtain the character table of A5 (even permutations of 5 items). The 
group A5 is the group of rotations of the regular icosahedron. Thus it has a 3-dimensional rotation 
 C3  representation , in which (12)(34) is the rotation by 1800
+ around an axis perpendicular to two 
opposite edges, (123) is the  rotation by 1200around an axis perpendicular to two opposite faces, 
and (12345), (13254) are the rotations by 720, respectively 1440, around axes going through two 
opposite vertices. The character of this representation is computed from this description in a 
straightforward way. 
Another representation of A5, which is also 3-dimensional, is C3 
+ twisted by the automorphism 
of A5 given by conjugation by (12) inside S5. This representation is denoted by C3. It has the

same character as C3 
+, except that the conjugacy classes (12345) and (13245) are interchanged. 
There are two remaining irreducible representations, and by the sum of squares formula their 
dimensions are 4 and   5. So we  them C4 call and C5. 
The representation C4 is realized on the space of functions on the set {1, 2, 3, 4, 5} with zero 
sum of values, where A5 acts by permutations (check that it is irreducible!). The character of 
this representation is equal to the character of the 5-dimensional permutation representation minus 
the character of the 1-dimensional trivial representation (constant functions). The former at an 
element g equals to the number of items among 1,2,3,4,5 which are xed by g. 
The representation C5 is realized on the space of functions on pairs of opposite vertices of the 
icosahedron which has zero sum of values (check that it is irreducible!). The character of this 
representation is computed similarly to the character of C4, or from the orthogonality formula. 
3.9 Computing tensor product multiplicities using character tables 
          k Character tables allow us to compute the tensor product multiplicities Nijusing 
 
Vi   Vj = 
Nk
ijVk, Nk 
ij= ( ij ,k)</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>3 Representations of nite groups: basic results 
Recall that a representation of a group G over a eld k is a k-vector space V together with a 
group homomorphism  : G  GL(V ). As we have explained above, a representation of a group G 
over k is the same thing as a representation of its group algebra k[G]. 
In this section, we begin a systematic development of representation theory of nite groups. 
3.1 Maschkes Theorem 
Theorem 3.1. (Maschke) Let G be a nite group and k a eld whose characteristic does not divide 
|G|. Then: 
(i) The algebra k[G] is semisimple. 
(ii) There is an isomorphism of algebras  : k[G]   iEndVi dened by g  ig|Vi , where Vi
are the irreducible representations of G. In particular, this is an isomorphism of representations 
of G (where G acts on both sides by left multiplication). Hence, the regular representation k[G] 
decomposes into irreducibles as i dim(V i)Vi, and one has 
G=  
| |  dim(V i)2.
i 
(the sum of squares formula). 
Proof. By Proposition 2.16, (i) implies (ii), and to prove (i), it is sucient to show that if V is 
a nite-dimensional representation of G and WV is any subrepresentation, then there exists a 
subrepresentation W   V such that V = W  W  as representations. 
Choose any complement Wof W in  V . (Thus V = W  Was vector spaces, but not necessarily 
 as representations.) Let P be the projection along Wonto W , i.e., the operator on V dened by 
P |W = Id and P |= 0. Let W1 P :=  
(g)P(g1), |G| gG 
where (g) is the action of g on V , and let 
W  = ker P. 
 Now P |W = Id and P (V )  W , so  2P= P , so P is a projection along W . Thus, V =  W  W as 
vector spaces. 
Moreover, for any h  G and any y  W , 
    1P(h y =(g)(g1 1) P h)y =(h)P(1)y = (h)Py = 0, |G| gG |G| 
G 
so (h)y  ker P  = W . Thus, W is invariant under the action of G and is therefore a subrepre
sentation of V . Thus, V = W  W  is the desired decomposition into subrepresentations. 
The converse to Theorem 3.1(i) also holds. 
Proposition 3.2. If k[G] is semisimple, then the characteristic of k does not divide |G|.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>If V,W are representations of G, then V  W is also a representation, via 
V W (g) = V (g)    W (g). 
Therefore, V W (g) = V (g)W (g). 
An interesting problem discussed below is to decompose V  W (for irreducible V,W ) into the 
direct sum of irreducible representations. 
3.5 Orthogonality of characters 
We dene a positive denite Hermitian inner product on Fc(G, C) (the space of central functions) 
by 
1  
(f1,f2) = f(g)f(g). |G| g
1 2
G 
The following theorem says that characters of irreducible representations of G form an orthonormal 
basis of Fc(G, C) under this inner product. 
Theorem 3.8. For any representations V,W 
(V ,W ) = dim Hom G(W,V ), 
and  1, if V = W, (V ,W ) = 0, if V  W 
if V,W are irreducible. 
Proof. By the denition 
1  1  
(V ,W ) =  (g)  (g) =  (g)   (g) |G| 
V W V W
gG |G|g
G 
1  
= V W  (g) = Tr  |V W  (P ), |G| g
G 
 where P = 1
g G g  Z(C[G]). (Here Z(C[G]) denotes the center of ]).G| C[G  If X is an irreducible | 
representation of G then  Id, if X = C,P |X =
0, X =  C.
Therefore, for any representation X the operator P |X is the G-invariant projector onto the subspace 
XG of G-invariants in X. Thus, 
Tr |V W  (P )	= dim Hom G(C,V  W ) 
= dim(V  W   )G= dim Hom G(W,V ).</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch4</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch4/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>4 Representations of nite groups: further results 
4.1 Frobenius-Schur indicator 
Suppose that G is a nite group and V is an irreducible representation of G over C. We say that 
V is 
- of complex type, if V  V , 
- of real type, if V has a nondegenerate symmetric form invariant under G, 
- of quaternionic type, if V has a nondegenerate skew form invariant under G. 
Problem 4.1. (a) Show that End R[G] V is C for V of complex type, Mat2(R) for V of real type, 
and H for V of quaternionic type, which motivates the names above. 
Hint. Show that the complexication VC of V decomposes as V  V . Use this to compute the 
dimension of End R[G] V in all three cases. Using the fact that C End R[G] V , prove the result 
in the complex case. In the remaining two cases, let B be the invariant bilinear form on V , and 
(, ) the invariant positive Hermitian form (they are dened up to a nonzero complex scalar and a 
positive real scalar, respectively), and dene the operator j : V  V such that B(v,w) = (v,jw ). 
           2 
Show thatjis complex antilinear (ji =ij), andj=   Id, where  is a real number, positive in 
the real case and negative in the quaternionic case (if B is renormalized, j multiplies by a nonzero 
  complex number z and j2by zz, as j is antilinear). Thus j can be normalized so that j2= 1 for 
the real case, and j2 = 1 in the quaternionic case. Deduce the claim from this. 
(b) Show that V is of real type if and only if V is the complexication of a representation VR 
over the eld of real numbers. 
Example 4.2. For Z/nZ all irreducible representations are of complex type, except the trivial one 
and, if n is even, the sign representation, m  (1)m, which are of real type. For S3 all three 
irreducible representations C+, C, C2 are of real type. For S  4 there are ve irreducible representa
tions C+, C, C2 , C3
+, C3 , which are all of real type. Similarly, all ve irreducible representations  
of A5  C, C3 +, C3 , C4 , C5 are of real type. As for Q8, its one-dimensional representations are of 
real type, and the two-dimensional one is of quaternionic type. 
Denition 4.3. The Frobenius-Schur indicator FS(V ) of an irreducible representation V is 0 if it 
is of complex type, 1 if it is of real type, and 1 if it is of quaternionic type. 
Theorem 4.4. (Frobenius-Schur) The number of involutions (=elements of order  2) in G is 
equal to V dim(V )FS(V ), i.e., the sum of dimensions of all representations of G of real type 
minus the sum of dimensions of its representations of quaternionic type. 
Proof. Let A : V  V have eigenvalues 1,2,..., n. We have 
 
Tr|S2V (A  A) = 
ij
|ij 
Tr2V (A  A) = ij
i&lt;j 
Thus,  
Tr|S2V (A  A)  Tr|2V (A  A) = 
12 = Tr(A2
i ).
in</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>For the partition  = (1,..., 1), Q = Sn, P = {1}, so c is the antisymmetrizer, and hence V is 
the sign representation. 
n = 3. For   = (2, 1), V = C2. 
n = 4. For  = (2, 2), V = C2; for   = (3, 1), V = C3;   for = (2, 1, 1), V = C3
 +. 
Corollary 4.38. All irreducible representations of Sn can be given by matrices with rational entries. 
Problem 4.39. Find the sum of dimensions of all irreducible representations of the symmetric 
group Sn. 
Hint. Show that all irreducible representations of Sn are real, i.e., admit a nondegenerate 
invariant symmetric form. Then use the Frobenius-Schur theorem. 
4.13 Proof of Theorem 4.36 
Lemma 4.40. Let x  C[Sn]. Then axb = (x)c, where  is a linear function. 
Proof. If g  PQ, then g has a unique representation as pq, p  P,q  Q, so agbq = (1)c. 
Thus, to prove the required statement, we need to show that if g is a permutation which is not in 
PQ then agb = 0. 
To show this, it is sucient to nd a transposition t such that t  P and g1tg  Q; then 
agb1 = atgb = ag(gtg)b = agb, 
so agb = 0. In other words, we have to nd two elements i,j standing in the same row in the 
tableau T =  T, and in the same column in the tableau T = gT (where gT is the tableau of the 
same shape as T obtained by permuting the entries of T by the permutation g). Thus, it suces to 
show that if   such a pair does not exist, then g  PQ, i.e., there exists p  P, q Q:= gQg1
such that pT = qT  (so that g = pq1,q = g1qg  Q). 
Any two elements in the rst row of T must be in dierent columns of T , so there exists q1 Q
which moves all these  elements to the rst row. So there is p1  P such that p1T and q1T have 
the same rst row. Now do the same procedure with the second row, nding elements p2,q2such 
  thatp2p1T and q2q1T have the same rst two rows. Continuing so, we will construct the desired 
elements p,q. The lemma is proved. 
Let us introduce the lexicographic ordering on partitions:  &gt;  if the rst nonvanishing 
i  i is positive. 
Lemma 4.41. If &gt; then aC[Sn]b = 0. 
Proof. Similarly to the previous lemma, it suces to show that for any g  Sn there exists a 
transposition t  P such that g1tg  Q. Let T = T and  T = gT. We claim that there are 
two integers which are in the same row of T and the same column of T . Indeed, if 1 &gt;1, this is 
clear by the pigeonhole principle (already for the rst row). Otherwise, if 1 = 1, like in the proof 
of the previous lemma, we can nd elements p1  P,q1  gQ g1 such that p1T and q1T have the 
same rst row, and repeat the argument for the second row, and so on. Eventually, having done 
i  1 such steps, well have i &gt;i, which means that some two elements of the i-th row of the rst 
tableau are in the same column of the second tableau, completing the proof.</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>If 1   = 2, let z = xy1, then the last term of the summation is 
 
 2   
 2   1  2     1 (q+q)1(z)2(z) = (q +q) (z ) = (q +q)(q1) (z ). 2 2 x=y x;z=1 z=1
Since  1 (z) = 0,
 2zFq 
because the sum of all roots of unity of a given order m&gt; 1 is zero, the last term becomes 
 
 2     1 (q+q)(q1) (1) = (q 2+ q)(q  1). 2 z=1
The dierence between this case and the case of 1 = 2 is equal to 
(q 2 + q)[(q  2)(q  1) + (q  1)] = |G|, 
so this is an irreducible representation by Lemma 4.27. 
To prove the third assertion of the theorem, we look at the characters on hyperbolic elements 
and note that the function 
1(x)2(y) + 1(y)2(x) 
determines 1,2 up to permutation. 
4.24.4 Complementary series representations 
Let Fq2  Fq be a quadratic  extension Fq(),  Fq \ F2
q. We regard this as a 2-dimensional vector 
space over Fq; then G is the group of linear transformations of Fq2 over Fq. Let KG be the cyclic 
group of multiplications by elements of F
q2 , 
  x yK = { 
} | , K   | = q 21y x. 
For  : K  C a homomorphism, let 
Y = IndG 
K C. 
This representation, of course, is very reducible. Let us compute its character, using the Mackey 
formula. We get x 0 
 = q(q  1)(x);0 x 
(A) = 0 for A parabolic or hyperbolic; 
x y x y x q y =  + y
. 
 y x x y x 
The last assertion holds because if we regard the matrix as an element of Fq2 , conjugation is an 
 automorphism of Fq2 over Fq, but the only nontrivial automorphism of Fq2 over Fq is the qthpower 
map.</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>(where N  p). 
In this formula, there are many cancelations. After making some of these cancelations, we 
obtain the hook length formula. Namely, for a square (i,j) in a Young diagram  (i,j  1,i  j), 
                         
 dene the hook of (i,j ) to be the set of all squares (i,j ) inwithi i,j=jori= i, j j. 
Let h(i,j) be the length of the hook of i,j, i.e., the number of squares in it. 
Theorem 4.53. (The hook length formula) One has 
n! dim V =  . 
i h(i,j) j
Proof. The formula follows from formula (5). Namely, note that 
 
l1!= 
k. 
1&lt;j N (l1  lj ) 1kl1,k=l1lj
It is easy to see that the factors in this product are exactly the hooklengths h(i, 1). Now delete the 
rst row of the diagram and proceed by induction. 
4.18 Schur-Weyl duality for gl(V ) 
We start with a simple result which is called the Double Centralizer Theorem. 
Theorem 4.54. Let A, B be two subalgebras of the algebra End E of endomorphisms of a nite 
dimensional vector space E, such that A is semisimple, and B = End A E. Then: 
(i) A = EndB E (i.e., the centralizer of the centralizer of A is A); 
(ii) B is semisimple; 
(iii) as a representation of A  B, E decomposes as E = i I Vi  Wi, where V  i are all the 
irreducible representations of A, and Wi are all the irreducible representations of B. In particular, 
we have a natural bijection between irreducible representations of A and B. 
Proof. Since A is semisimple, we have a natural decomposition E = i I Vi  Wi, where W  i := 
Hom A(Vi,E), and A = i End Vi. Therefore, by Schurs lemma, B = EndA(E) is naturally identi
ed with i End(W i). This implies all the statements of the theorem. 
We will now apply Theorem 4.54 to the following situation: E =  V n, where V is a nite 
dimensional vector space over a eld of characteristic zero, and A is the image of C[Sn] in End E. 
Let us now characterize the algebra B. Let gl(V ) be End V regarded as a Lie algebra with operation 
ab  ba. 
Theorem 4.55. The algebra B = EndA E is the image of the universal enveloping algebra U(gl(V )) 
under its natural action on E. In other words, B is generated by elements of the form 
n(b) := b  1  ...  1 + 1  b  ...  1 + ... + 1  1  ...  b, 
b  gl(V ). 
Proof. Clearly, the image of U(gl(V )) is contained in B, so we just need to show that any element 
of B is contained in the image of U(gl(V )). By denition,  B = SnEnd V , so the result follows from 
part (ii) of the following lemma.</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>The goal of this section is to describe the irreducible representations of G.
To begin, let us nd the conjugacy classes in GL2(Fq). 
Number of elements in a conjugacy Representatives Number of classes class 
  x 0 q 1 (one for every nonScalar 0 x 1 (this is a central element) 
zero x) 
 2    q1 (elements that commute   with 
x 1  q 1 (one for every nonParabolic  this one are  formt u0 x   of the  0 t , t = zero x) 0) 
 2 q+ q (elements that commute with   1   (q  1)(q  2) (x,y = 0 Hyperbolic x0, y  = x this one are of the form t0 20 y 0 u , t,u =   
and x  = y)0) 
 
Elliptic x y 
y x ,x  Fq, y
F
q ,   
F
 q \ F2 q (characteris q2 1 q (the reason will be described q(q 1) (matrices with 2 
tic polynomial over Fq is irre below) y and y are conjugate) 
ducible) 
More on the conjugacy class of elliptic matrices: these are the matrices whose characteristic 
polynomial is irreducible over Fq and which therefore dont have eigenvalues in Fq. Let A be such 
a matrix, and consider a quadratic extension of Fq, 
Fq(),  Fq \ F2 
q.
Over this eld, A will have eigenvalues 
 = 1 + 2 
and 
 = 1 2, 
with corresponding eigenvectors 
v, v (Av = v, Av = v). 
Choose a basis 
{e1 = v + v, e2 = (v  v)}. 
In this basis, the matrix A will have the form 
  1 2
2 1 
, 
justifying the description of representative elements of this conjugacy class. 
In the basis {v, v}, matrices that commute with A will have the form 
 0
0  
, 
for all 
  F
q2 , 
so the  number of such matrices is q2 1.</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>the expression evaluates to
(g) 1,
since here 
aga1  B  a  B. 
If x 0g = 0 y  
, 
the expression evaluates to   
1(x)2(y) + 1(y)2(x)
 1,
since here 
aga1  B  a  B or a is an element of B multiplied by the transposition matrix. 
If   x yg = , x  = yy x 
the expression on the right evaluates to 0 because matrices of this type dont have eigenvalues over 
Fq (and thus cannot be conjugated into B). From the denition, i(x)(i = 1, 2) is a root of unity, 
so 
|G| 2 2V ,,V  , = (q + 1) (q  1) + (q  
1 2 1 2 1)(q  1) 
2 (q  1)(q   2) + 2(q + q) + (q 2+ q) 
1(x)2(y)1(y)2(x). 2 x=y
The last two summands come from the expansion 
|a + b| 2 = | | 2  a+ |b| 2+ ab + ab. 
If 
1 = 2 = , 
the last term is equal to 
 (q 2+ q)(q  2)(q  1), 
and the total in this case is 
(q + 1)(q  1)[(q + 1) + (q  1) + 2q(q  2)] = (q + 1)(q  1)2q(q  1) = 2|G|, 
so 
V ,,V , = 2. 
1 2 1 2 
Clearly, 
C  IndG 
B C,, 
since 
Hom G(C, IndGBC,) = Hom B(C, C) = C (Theorem 4.33). 
Therefore, IndG 
BC, = C  W; W is irreducible; and the character of W is dierent for distinct 
values of , proving that W are distinct.</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>4.20 Schur polynomials 
Let  = ( 1,..., p) be a partition of n, and N  p. Let 
  N 
s 
 j +Nj  j +N jD(x) = ( 1) x = det(x
i ). s(j) 
sSN j=1 
Dene the polynomials 
D(x)S(x) := D0(x) 
(clearly D0(x) is just (x)). It is easy to see that these are indeed polynomials, as D is an
tisymmetric and therefore must be divisible by . The polynomials S are called the Schur 
polynomials. 
Proposition 4.61.   
(xm
1 + ... + xm
N )im = 
(Ci)S(x). 
m :pN
Proof. The identity follows from the Frobenius character formula and the antisymmetry of 
(x) 
(xm+m m1  ... + x N )i. 
m 
Certain special values of Schur polynomials are of importance. Namely, we have 
Proposition 4.62. 
 zii  
2 N1  zj j
S(1,z,z ,...,z ) = 
 zi  zj 
1i&lt;j N
Therefore,  i  j + j  i S(1,..., 1) = j  i 1i&lt;j N
Proof. The rst identity is obtained from the denition using the Vandermonde determinant. The 
second identity follows from the rst one by setting z = 1. 
4.21 The characters of L 
Proposition 4.61 allows us to calculate the characters of the representations L. 
Namely, let dim V = N, g  GL(V ), and x1,...,x N be the eigenvalues of g on V . To compute 
the character L (g), let us calculate TrV n (gns), where s  Sn. If s  Ci, we easily get that this 
trace equals   
Tr(g m)im = 
Hm(x)im . 
m m 
On the other hand, by the Schur-Weyl duality 
 
Trn 
V n (gs) = 
(Ci)TrL (g). 
Comparing this to Proposition 4.61 and using linear independence of columns of the character table 
of Sn, we obtain</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>4.24.3 Principal series representations 
Let  
B  G, B =  { 
0 
} 
(the set of upper triangular matrices); then 
|B| = (q  1)2 q, 
1[B,B] = U = {  
0 1  
},
and 
B/[B,B ] = Fq
  F
q 
(the isomorphism maps an element of B to its two diagonal entries). 
Let 
 :  B  C
be a homomorphism dened by 
   a b
= 1(a)2(c),for some pair of homomorphisms 1, 2 : F
 0 cq C. 
Dene 
V1,2 = IndG B C, 
where C is the 1-dimensional representation of B in which B acts by . We have 
G dim(V 1,2 ) = | |= q + 1. |B| 
Theorem 4.71. 1. 1 = 2  V1,2 is irreducible.  
2. 1 = 2 =   V1,2 = C  W, where W is a q-dimensional irreducible representation of 
G. 
3. W = W if and only if         { }  {   =;V  V, 1,2=if and only if 1,2=
1 2 1, 2} (in the 
second case,   
1 = 2, 1  = 2).
Proof. From the Mackey formula, we have 
  1trV ,(g) = (aga
1 2 1). |B| 
aG,
aga1 B 
If  x 0g =  
,0 x 
the expression on the right evaluates to 
(g) |G| = 1(x)2(x)
q + 1
. |B| 
If x 1 
g = ,0 x</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Corollary 4.49 easily implies that the coecient of x+y+is 1. Indeed, if  = 1 is a permu
tation   inSN , the coecient of this monomial in 1is obviously zero. Q(1x j y(j)) 
Remark. For partitions  and  of n, let us say that    or  if    is a sum of 
vectors of the form ei  ej , i&lt;j (called positive roots). This is a partial order, and   implies
  . It follows from Theorem 4.47 and its proof that 
 = KU . 
This implies that the Kostka numbers K vanish unless
  .
4.16 Problems 
In the following problems, we do not make a distinction between Young diagrams and partitions. 
Problem 4.50. For a Young diagram , let A() be the set of Young diagrams obtained by adding 
a square to , and R() be the set of Young diagrams obtained by removing a square from . 
(a) Show that ResSn V = Sn1 R()V.
(b) Show that IndSn 
SV =  A()V.n1   
Problem 4.51. The content 
c() of a Young diagram  is the sum  j 
j i=1 (i  j). Let C = 
i&lt;j (ij)  C[Sn] be the sum of all transpositions. Show that C acts on the Specht module V by 
multiplication by c(). 
Problem 4.52. (a) Let V be any nite dimensional representation of Sn. Show that the element 
E := (12) + ... + (1n) is diagonalizable and has integer eigenvalues on V , which are between 1  n 
and n  1. 
Hint. Represent E as Cn  Cn1, where C= C is the element from Problem 4.51.  n 
(b) Show that the element (12)+...+(1n) acts on V by a scalar if and only if  is a rectangular 
Young diagram, and compute this scalar. 
4.17 The hook length formula 
Let us use the Frobenius character formula to compute the dimension of V. According to the 
character formula, dim V+ n  is the coecient of xin (x)(x 1 + ... + xN ) . Let lj = j + N  j. 
Then, using the determinant formula for (x) and expanding the determinant as a sum over 
permutations, we get 
 s n! n!   
dim  = (1) = ( V 1)slj (lj 1)...(l j N+s(j)+1) = 
j(lj  N + s(j))! l1!...lN ! s SN :l
j Ns(j)  
sSN j 
n!  det(l j (lj  1)...(l j  N + i + 1)). 
j lj! 
Using column reduction and the Vandermonde determinant formula, we see from this expression 
that n! dim VN in!  
 =  det(lj
) = (li  lj ) (5)
j lj ! 
j lj ! 

1i&lt;j N</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>where (g) is the trace of the diagonal block of (g) corresponding to V. 
Since g() = g is a right H-coset for any right H-coset , (g) = 0 if  =  g.
Now assume that  =  g. Then xg = hx where h = xgx1
  H. Consider the vector space 
homomorphism  : V  V with (f) = f(x). Since f  V is uniquely determined by f(x),  
is an isomorphism. We have 
(gf) = g(f)(x ) = f(xg) = f(hx) = V (h)f(x) = h(f), 
and gf = 1h(f). This means that (g) = V (h). Therefore 
(g) =  
V (x1gx
 ). 
H\G,g = 
4.10 Frobenius reciprocity 
A very important result about induced representations is the Frobenius Reciprocity Theorem which 
connects the operations Ind and Res. 
Theorem 4.33. (Frobenius Reciprocity) 
Let HG be groups, V be a representation of G and W a representation of H. Then 
Hom G(V, WG IndG
H  ) is naturally isomorphic to Hom H (ResH V,W ).
Proof. Let E = Hom G(V,    IndGW ) and E= Hom H (ResG
H H V,W ). Dene F : E  Eand F : E
E as follows: F ()v = (v )(e) for any   E and (F ()v)(x) = (xv) for any   E. 
  In order to check that F and F are well dened and inverse to each other, we need to check 
the following ve statements. 
Let   E,   E, v  V , and x,g  G. 
(a) F () is an H-homomorphism, i.e., F ()hv = hF ()v.
Indeed, F ()hv = (hv )(e) = (hv )(e) = (v )(he) = (v )(eh) = h  (v)(e) = hF ()v.
(b) F ()v  IndG 
H W , i.e.,  
(F()v)(hx) = h(F ()v)(x).
Indeed, (F ()v)(hx) = (hxv) = h(xv) = h(F ()v)(x).
(c) F () is a G-homomorphism, i.e. F ()gv = g(F ()v).
Indeed, (F ()gv)(x) = (xgv) = (F ()v)(xg) = (g (F ()v))(x).
 (d) F  F = IdE .
This holds since F (F ())v = (F ()v)(e) = (v).
(e) F   F = IdE , i.e., (F (F ())v)(x) = (v )(x).
Indeed, (F (F ())v)(x) = F (xv) = (xv )(e) = (xv )(e) = (v )(x), and we are done.
Exercise. The purpose of this exercise is to understand the notions of restricted and induced 
representations as part of a more advanced framework. This framework is the notion of tensor 
products over k-algebras (which generalizes the tensor product over k which we dened in Denition</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>4.24.2 1-dimensional representations 
First, we describe the 1-dimensional representations of G. 
Proposition 4.70. [G,G] = SL2(Fq). 
Proof. Clearly, 
 det(xyx1y1) = 1, 
so 
[G,G]  SL2(Fq). 
To show the converse, it suces to show that the matrices 
  1 1 a 0  1 0, 0 1 0 a1 , 1 1 
are commutators (as such matrices generate SL2(Fq).) Clearly, by using transposition, it suces 
to show that only the rst two matrices are commutators. But it is easy to see that the matrix 
  1 1
0 1 
is the commutator of the matrices 
  1 1/2A = 0 1 
,1 0 B = 
,0 1 
while the matrix   a 0 
0 a1 
is the commutator of the matrices 
a 0   0 1A = , B = 
,0 1 1 0 
This completes the proof. 
Therefore,
G/[G,G] = F
q via g  det(g).
The one-dimensional representations of G thus have the form 
(g) = 
det(g)
, 
where  is a homomorphism 
 : Fq  C; 
so there are q  1 such representations, denoted C.</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Because  is also a root of unity, the last term of the expression evaluates to
 
(2 + q1() + 1q()). 
 elliptic 
Lets evaluate the last summand. 
Since F
q2 is cyclic and q =  ,
  
q1() = 
1q() = 0. 
 Fq2  Fq2 
Therefore, 
  
(q1() + 1q()) =  (q1() + 1q()) = 2(q  1) = 
 elliptic 
 
 Fq 
since F
q is cyclic of order q  1. Therefore,
1  q(q  1)  
, =
(q 1) (q 1)21+(q 1) 1 (q 21)+ (2(q 2q)2(q (q  2q(q + 1) 2 1))1)
= 1.      
We have now shown that for any   with q =  the representation Y with the same character 
as 
W1  VG ,1  V,1  IndK C 
exists and is irreducible. These characters are distinct for distinct pairs (, ) (up to switch 
  q), so there are q(q1) such representations, each of dimension q  1.2 
We have thus found q  1 q(q1) 1-dimensional representations of G, principal series repre2 
sentations, and q(q1) complementary series representations, for a total of q2 1 representations, 2 
i.e., the number of conjugacy classes in G. This implies that we have in fact found all irreducible 
representations of GL2(Fq). 
4.25 Artins theorem 
Theorem 4.73. Let X be a conjugation-invariant system of subgroups of a nite group G. Then 
two conditions are equivalent: 
(i) Any element of G belongs to a subgroup H  X. 
(ii) The character of any irreducible representation of G belongs to the Q-span of characters of 
 induced representations IndG
H V , where H  X and V is an irreducible representation of H.
Remark. Statement (ii) of Theorem 4.73 is equivalent to the same statement with Q-span 
replaced by C-span. Indeed, consider the matrix whose columns consist of the coecients of the 
decomposition of IndG H V (for various H,V ) with respect to the irreducible representations of G.
Then both statements are equivalent to the condition that the rows of this matrix are linearly 
independent.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Proof. Let V = C[G] be the regular representation of G. Consider the operator-valued polynomial
 
L(x) = 
xg(g), 
gG 
where (g)  EndV is induced by g. The action of L(x) on an element h  G is 
  
L(x)h = xg(g)h = 
xggh =  
xzh1 z 
gG gG z G 
So the matrix of the linear operator L(x) in the basis g1,g2,...,g n is XG with permuted columns 
and hence has the same determinant up to sign. 
Further, by Maschkes theorem, we have 
r
detV L(x) =  (detVi L(x))dimVi , 
i=1 
where Vi are the irreducible representations of G. We set Pi = detVi L(x). Let {eim} be bases of Vi 
and Ei,jk  End Vi be the matrix units in these bases. Then {Ei,jk} is a basis of C[G] and 
 
L(x)| Vi = 
yi,jkEi,jk,
j,k 
where yi,jk are new coordinates on C[G] related to xg by a linear transformation. Then 
Pi(x) = det |Vi L(x) = det(y i,jk)
Hence, Pi are irreducible (by Lemma 4.8) and not proportional to each other (as they depend on 
dierent collections of variables yi,jk). The theorem is proved. 
4.3 Algebraic numbers and algebraic integers 
We are now passing to deeper results in representation theory of nite groups. These results require 
the theory of algebraic numbers, which we will now briey review. 
Denition 4.9. z  C is an algebraic number (respectively, an algebraic integer), if z is a 
root of a monic polynomial with rational (respectively, integer) coecients. 
Denition 4.10. z  C is an algebraic number, (respectively, an algebraic integer), if z is an 
eigenvalue of a matrix with rational (respectively, integer) entries. 
Proposition 4.11. Denitions (4.9) and (4.10) are equivalent. 
Proof. To show (4.10)  (4.9), notice that z is a root of the characteristic polynomial of the matrix 
(a monic polynomial with rational, respectively integer, coecients). 
To show (4.9)  (4.10), suppose z is a root of 
 p(x) = x n+ a1x n1 + ... + an1x + an. 
Then the characteristic polynomial of the following matrix (called the companion matrix) is 
p(x):</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>with Y . Taking into account the proof of (i), we deduce that R has the required decomposition, 
which is compatible with the second action of GL(V ) (by left multiplications). This implies the 
statement. 
Note that the Peter-Weyl theorem generalizes Maschkes theorem for nite group, one of whose 
forms states that the space of complex functions Fun(G, C) on a nite group G as a representation 
of G  G decomposes  as V Irrep(G)V  V . 
Remark 4.67. Since the Lie algebra sl(V ) of traceless operators on V is a quotient of gl(V ) by 
scalars, the above results extend in a straightforward manner to representations of the Lie algebra 
sl(V ). Similarly, the results for GL(V ) extend to the case of the group SL(V ) of operators with 
determinant 1. The only dierence is that in this case the representations L and L+1m are 
isomorphic, so the irreducible representations are parametrized by integer sequences 1  ...  N 
up to a simultaneous shift by a constant. 
In particular, one can show that any nite dimensional representation of sl(V ) is completely 
reducible, and any irreducible one is of the form L (we will not do this here). For dim V = 2 one 
then recovers the representation theory of sl(2) studied in Problem 1.55. 
4.23 Problems 
Problem 4.68. (a) Show that the Sn-representation V:= C[Sn]ba is isomorphic to V. 
Hint. Dene Sn-homomorphisms f : V  Vand g : V V by the formulas f(x) = xa and 
g(y) = yb, and show that they are inverse to each other up to a nonzero scalar. 
(b) Let  : C[Sn]  C[Sn] be the automorphism sending s to (1)ss for any permutation s. 
Show that  maps any representation V of Sn to V  C. Show also that (C[S   n]a) = C[Sn](a), 
for a  C[Sn]. Use (a) to deduce  that V  C = V , where is the conjugate partition to , 
obtained by reecting the Young diagram of . 
Problem 4.69. Let Rk,N be the algebra of polynomials on the space of k-tuples of complex N by N 
matrices X1,...,X k, invariant under simultaneous conjugation. An example of an element of Rk,N 
is the function Tw := Tr(w(X1,...,X k )), where w is any nite word on a k-letter alphabet. Show 
that Rk,N is generated by the elements Tw. 
Hint. Consider invariant functions that are of degree di in each Xi, and realize this space as 
a tensor   product diSi (V  V ). Then embed this tensor product into (V  V )N= End(V )n, 
and use the Schur-Weyl duality to get the result. 
4.24 Representations of GL2(Fq) 
4.24.1 Conjugacy classes in GL2(Fq) 
Let Fq be a nite eld of size q of characteristic other than 2, and G = GL2(Fq). Then 
|G| = (q 2   1)(q 2 q), 
since the rst column of an invertible 2 by 2 matrix must be non-zero and the second column may 
not be a multiple of the rst one. Factoring, 
|GL2(Fq)| = q(q + 1)(q  1)2 .</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 18.712 Introduction to Representation Theory
Fall 2010</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>We thus have
 IndGC= G 
K q IndK C 
because  they have the same character. Therefore, for q=    we get 1q(q 2 1) representations. 
Next, we look at the following tensor product: 
W1  V,1, 
where 1 is the trivial character and W1 is dened as in the previous section. The character of this 
representation is x 0 
 = q(q + 1)(x);0 x 
(A) = 0 for A parabolic or elliptic; 
x 0 
 = (x) + (y). 0 y 
Thus the virtual representation 
WG 1  V,1  V,1  IndK C , 
where  is the restriction of  to scalars, has character 
  x 0 = (q  1)(x);0 x 

x 1 
 = (x);0 x 
   x 0
= 0; 0 y 
x y   x y   x y =   q
. y x y x y x 
In all that follows, we will  have q=  . 
The following two lemmas will establish that the inner product of this character with itself is 
equal to 1, that its value at 1 is positive. As we know from Lemma 4.27, these two properties imply 
that it is the character of an irreducible representation of G. 
Lemma 4.72. Let  be the character of the virtual representation dened above. Then 
, = 1 
and 
(1) &gt; 0. 
Proof. 
(1) = q(q + 1)  (q + 1)  q(q  1) = q  1 &gt; 0. 
We now compute the inner product ,. Since  is a root of unity, this will be equal to 
1   q( 1)   q (q1) (q1)21+(q1) 1 (q 21)+  
(()+q())(() + q())
 (q  1)2q(q + 1)    2 
 elliptic</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>(a) Z2 
(b) Z3 
(c) Z5 
(d) A4 
(e) Z2  Z2 
4.12 Representations of Sn 
In this subsection we give a description of the representations of the symmetric group Sn for any 
n. 
Denition 4.35. A partition  of n is a representation of n in the form n = 1 + 2 + ... + p, 
where i are positive integers, and i  i+1. 
To such  we will attach a Young diagram Y, which is the union of rectangles i  y  i+1, 
0  x  i in the coordinate plane, for i = 1,...,p. Clearly, Y is a collection of n unit squares. A 
Young tableau corresponding to Y is the result of lling the numbers 1,...,n into the squares of 
Y in some way (without repetitions). For example, we will consider the Young tableau T obtained 
by lling in the numbers in the increasing order, left to right, top to bottom. 
We can dene two subgroups of Sn corresponding to T: 
1. The row subgroup P: the subgroup which maps every element of {1,...,n} into an element 
standing in the same row in T. 
2. The column subgroup Q: the subgroup which maps every element of {1,...,n} into an 
element standing in the same column in T. 
Clearly, P  Q = {1}. 
Dene the Young projectors: 
| 1 a := g, |P gP 
1  
b := 
(1)gg,
|Q| gQ
where (1)g denotes the sign of the permutation g. Set c = ab. Since P  Q = {1}, this
element is nonzero. 
The irreducible representations of Sn are described by the following theorem. 
Theorem 4.36. The subspace V := C[Sn]c of C[Sn] is an irreducible representation of Sn under 
left multiplication. Every irreducible representation of Sn is isomorphic to V for a unique . 
The modules V are called the Specht modules. 
The proof of this theorem is given in the next subsection. 
Example 4.37. 
For the partition  = (n), P = Sn, Q = {1}, so c is the symmetrizer, and hence V is the trivial 
representation.</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Proof. (i) Let us decompose V = V(O,U) as an A-module. Then we get 
V = yOVy, 
where Vy = {v  V(O,U)|av = (y,a)v,a  A}. (Equivalently, Vy = {v  V(O,U)|v(g) = 0 unless gy = 
x}). So if W  V is a subrepresentation, then W = y OWy, where W  y  Vy. Now, Vy is a 
representation of Gy, which goes to U under any isomorphism Gy  Gx determined by g  G 
mapping x to y. Hence, Vy is irreducible over Gy, so Wy = 0 or Wy = Vy for each y. Also, if hy = z 
then hWy = Wz, so either Wy = 0 for all y or Wy = Vy for all y, as desired. 
(ii) The orbit O is determined by the A-module structure of V , and the representation U by 
the structure of Vx as a Gx-module. 
(iii) We have   
 2  dimV(U,O) = 
|O| 2(dim U)2= 
U,O U,O 
 
|O|2|Gx| =   
|O||G/G x||Gx| = |G| 
 
|O| = G||A
 | | = |G  A|. 
O O O
(iv) The proof is essentially the same as that of the Mackey formula. 
Exercise. Redo Problems 3.17(a), 3.18, 3.22 using Theorem 4.75. 
Exercise. Deduce parts (i)-(iii) of Theorem 4.75 from part (iv).</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Proof. Proof that (ii) implies (i). Assume that g  G does not belong to any of the subgroups 
H  X. Then, since X is conjugation invariant, it cannot be conjugated into such a subgroup. 
Hence by the Mackey formula, IndG (V )(g) = 0 for all H  X and V . So by (ii), for any irreducible 
H 
representation W of G, W (g) = 0. But irreducible characters span the space of class functions, so 
any class function vanishes on g, which is a contradiction. 
Proof that (i) implies (ii). Let U be a virtual representation of G over C (i.e., a linear combina
tion of irreducible representations with nonzero integer coecients) such that (U ,IndG V ) = 0 for 
H 
all H,V . So by Frobenius reciprocity, (U|H ,V ) = 0. This means that U vanishes on H for any 
H  X. Hence by (i), U is identically zero. This implies (ii) (because of the above remark). 
Corollary 4.74. Any irreducible character of a nite group is a rational linear combination of 
induced characters from its cyclic subgroups. 
4.26 Representations of semidirect products 
Let G,A be groups and  : G  Aut(A) be a homomorphism. For a  A, denote (g)a by g(a). 
The semidirect product G  A is dened to be the product A  G with multiplication law 
(a1,g1)(a2,g2) = (a 1g1(a2),g1g2). 
Clearly, G and A are subgroups of G  A in a natural way. 
We would like to study irreducible complex representations of G  A. For simplicity, let us do 
it when A is abelian. 
In this case, irreducible representations of A are 1-dimensional and form the character group 
A, which carries an action of G. Let O be an orbit of this action, x  O a chosen element, 
and Gx the stabilizer of x in G. Let U be an irreducible representation of Gx. Then we dene a 
representation V(O,U) of G  A as follows. 
As a representation of G, we set 
 V(O,x,U ) = IndG
Gx U = {f : G  U|f(hg) = hf(g),h  Gx}.
Next, we introduce an additional action of A on this space by (af)(g) = x(g(a))f(g). Then its 
easy to check that these two actions combine into an action of G  A. Also, it is clear that this 
representation does not really depend on the choice of x, in the following sense. Let x,y  O, 
and g  G be such that gx = y, and let g(U) be the representation of Gy obtained from the 
representation U of Gx by the action of g. Then V(O,x,U ) is (naturally) isomorphic to V(O,y,g (U)). 
Thus we will denote V(O,x,U ) by V(O,U) (remembering, however, that x has been xed). 
Theorem 4.75. (i) The representations V(O,U) are irreducible. 
(ii) They are pairwise nonisomorphic. 
(iii) They form a complete set of irreducible representations of G  A. 
(iv) The character of V = V(O,U) is given by the Mackey-type formula 
 1 V (a,g) = 
x(h(a)) U (hgh1). |Gx| 
hG:hgh1Gx</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Proof. Denote V shortly by . Let us denote the class function dened in the theorem by . We  
claim that this function has the property  = 
  L, where L are integers and L = 1. 
Indeed, from Theorem 4.46 we have 
 =  
(1)U+ () , 
SN 
where if the vector  +   () has a negative entry, the corresponding term is dropped, and if 
it has nonnegative entries which fail to be nonincreasing, then the entries should be reordered in 
the nonincreasing order, making a partition that well denote  +   () (i.e., we agree that 
U+  () := U +  ()). Now note that  =  +   ()      is obtained from  by adding vectors 
of the form ei  ej, i &lt; j, which implies that  &gt;  or  = , and the case  =  arises only if 
 = 1, as desired. 
Therefore, to show that  = , by Lemma 4.27, it suces to show that (,) = 1. 
We have
 1 (,) = Cn! 
|i|(Ci)2.
i 
Using that 
 |Ci| = 
we conclude that (,) is the coecient of n! , 
m mim im! 
x+y+ in the series R(x,y) = (x)(y )S(x,y), 
where 
  (m x)im i  (mk ym   m m im 
 j j k ) (j,k xj y /m)
S(x,y) = = k. mim i
m!  
im! i m i m 
Summing over i and m, we get 
S x,y ) =   exp(  
( x mm
j yk/m) = exp( 
log(1  xj y1k)) = 
(1  xjyk)
m j,k j,k j,k 
Thus, 
i&lt;j(xi  xj )(yi  yj ) 
R(x,y) =  . 
i,j(1  xiyj) 
Now we need the following lemma. 
Lemma 4.48. 
i&lt;j(zj  zi)(yi  y  j ) 1= det( ). 
i,j(zi  yj) zi  yj 
Proof. Multiply both sides by i,j(ziyj). Then the right hand side must vanish on the hyperplanes 
zi = zj and yi = yj (i.e., be divisible
 by (z)(y)), and is a homogeneous polynomial of degree 
N(N  1). This implies that the right hand side and the left hand side are proportional. The 
proportionality coecient (which is equal to 1) is found by induction by multiplying both sides by 
zN  yN and then setting zN = yN . 
Now setting in the lemma zi = 1/x i, we get 
Corollary 4.49. (Cauchy identity) 
 1 1 R(x,y) = det( ) = 
. 1  xiyNj 
j=1(1  xjy (j))SN</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Thus for g  G we have 
V (g 2) = S2V (g)  2V (g) 
Therefore, 
  1  is of real  , if V type
|
1 2  G|V (g) = S2V (P ) 2V (P ) = dim(S2V )Gdim( 2V )G=


1, if V is of quaternionic type 
g G 0, if V is of complex  type
Finally, the number of involutions in G equals

 
   
 1dim V2 (g ) = dim V 
|G
 dim V.| 
V
V g
G real
 V quat
 V 
Corollary 4.5. Assume that all representations of a nite group G are dened over real numbers 
(i.e., all complex representations of G are obtained by complexifying real representations). Then 
the sum of dimensions of irreducible representations of G equals the number of involutions in G. 
Exercise. Show that any nontrivial nite group of odd order has an irreducible representation 
which is not dened over R (i.e., not realizable by real matrices). 
4.2 Frobenius determinant 
Enumerate the elements of a nite group G as follows: g1,g2,...,g n. Introduce n variables indexed 
with the elements of G : 
xg1 ,xg2 ,...,x gn . 
Denition 4.6. Consider the matrix XG with entries aij = xgigj . The determinant of XG is some 
polynomial of degree n of xg1 ,xg2 ,...,x gn that is called the Frobenius determinant. 
The following theorem, discovered by Dedekind and proved by Frobenius, became the starting 
point for creation of representation theory (see [Cu]). 
Theorem 4.7. 
r 
Pj (x)deg det XPjG = 
j=1 
for some pairwise non-proportional irreducible polynomials Pj (x), where r is the number of conju
gacy classes of G. 
We will need the following simple lemma. 
Lemma 4.8. Let Y be an n  n matrix with entries yij. Then det Y is an irreducible polynomial 
of {yij }. 
n Proof. Let Y = tId+
i=1 xiEi,i+1, where i+1 is computed modulo n, and Ei,j are the elementary 
matrices. Then  det(Y ) = tn (1)nx1...xn, which is obviously irreducible. Hence det(Y ) is 
irreducible (since factors of a homogeneous polynomial are homogeneous). 
Now we are ready to proceed to the proof of Theorem 4.7.</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Theorem 4.63. (Weyl character formula) The representation L is zero if and only if N &lt; p, 
where p is the number of parts of . If N  p, the character of L is the Schur polynomial S(x). 
Therefore, the dimension of L is given by the formula 
 i  dim L = j + j  i 
j  i 1i&lt;j N
This shows that irreducible representations of  GL(V ) which occur in V nfor some n are labeled 
by Young diagrams with any number of squares but at most N = dim V rows. 
Proposition 4.64. The representation  L+1N (where 1N= (1, 1,...,  1)  ZN) is isomorphic to 
L  N V . 
   N    n  Proof. Indeed,L V V  NV  V n+N , and the only component of V n+N  that has 
the same character as  LN  V is L+1N . This implies the statement. 
4.22 Polynomial representations of GL(V ) 
Denition 4.65. We say that a nite dimensional representation Y of GL(V ) is polynomial (or 
algebraic, or rational) if its matrix elements are polynomial functions of the entries of g,g1 , 
g  GL(V ) (i.e., belong to k[gij ][1/ det(g)]). 
For example, V n and hence all L are polynomial. Also dene  LN
 r1N := L (V )r (this 
denition makes sense by Proposition 4.64). This is also a polynomial representation. Thus we 
have attached a unique irreducible polynomial representation L of GL(V ) = GLN to any sequence 
(1,..., N ) of integers (not necessarily positive) such that 1  ...  N . This sequence is called 
the highest weight of L. 
Theorem 4.66. (i) Every nite dimensional polynomial representation of GL(V ) is completely 
reducible, and decomposes into summands of the form L (which are pairwise non-isomorphic). 
(ii) (the Peter-Weyl theorem for GL(V )). Let R be the algebra of polynomial functions on 
GL(V ). Then as a representation of GL(V )  GL(V ) (with action ((g,h))(x) = (g1xh), 
g,h,x  GL(V ),   R), R decomposes as 
R = L
  L, 
where the summation runs over all . 
Proof. (i) Let Y be a polynomial representation of GL(V ). We have an embedding  : Y  Y  R 
given by (u,(v))(g) := u(gv), u  V . It is easy to see that  is a homomorphism of representations 
(where the action of GL(V ) on the rst component of Y  R is trivial). Thus, it suces to prove 
the theorem for  a subrepresentation Y Rm. Now, every element of R is a polynomial of gij
times a nonpositive power of det(g). Thus, R is a quotient of a direct sum of representations of the 
 r     N  formS(V V ) (V )s. So we may assume that Y is contained in a quotient of a (nite) 
 direct sum of such representations. As V = N1V  N V , Y is contained in a direct sum of 
representations of the form V n  (N V )s, and we are done. 
(ii) Let Y be a polynomial representation of GL(V ), and let us regard R as a representation 
of GL(V ) via ((h))(x) = (xh). Then Hom GL(V )(Y,R) is the space of polynomial functions 
on GL(V ) with values in Y , which are GL(V )-equivariant. This space is naturally identied</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Now, consider  
iV (gCi ). 
i 
This is an algebraic integer, since: 
(i) i are algebraic integers by Proposition 4.17, 
(ii) V (gCi ) is a sum of roots of unity (it is the sum of eigenvalues of the matrix of (gCi ), and 
since g|G | 
C= e in G, the eigenvalues of (gCi ) are roots of unity), and i 
(iii) A is a ring (Proposition 4.12). 
On the other hand, from the denition of i, 
  CiV (gC)V (gCii i ) 
V (gCi ) = | |. dim V Ci i 
Recalling that V is a class function, this is equal to 
 V (g)V (g) |G|( V ,V ) = . dim V dim V gG 
Since V is an irreducible representation, (V ,V ) = 1, so 
 
iV (gCi ) = |G| . dim V Ci 
 |G| Q    A    |GSince andCV (g ), i C i by Proposition 4.13| dimV i dimV Z. 
4.5 Burnsides Theorem 
Denition 4.18. A group G is called solvable if there exists a series of nested normal subgroups 
{e} = G1  G2  ...  Gn = G 
where Gi+1/Gi is abelian for all 1  i  n  1. 
Remark 4.19. Such groups are called solvable because they rst arose as Galois groups of poly
nomial equations which are solvable in radicals. 
Theorem 4.20 (Burnside). Any group G of order paqb, where p and q are prime and a,b  0, is 
solvable. 
This famous result in group theory was proved by the British mathematician William Burnside 
in the early 20-th century, using representation theory (see [Cu]). Here is this proof, presented in 
modern language. 
Before proving Burnsides theorem we will prove several other results which are of independent 
interest. 
Theorem 4.21. Let V be an irreducible representation of a nite group G and let C be a conjugacy 
class of G with gcd(|C |, dim(V )) = 1. Then for any g  C, either V (g) = 0 or g acts as a scalar 
on V .</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>0 0 0 ... 0 an 
1 0 0 ... 0 a
n1
0 1 0 ... 0 an2
.
 .  . .  
0 0 0 ... 1 a1 
Since z is a root of the characteristic polynomial of this matrix, it is an eigenvalue of this matrix. 
The set of algebraic numbers is denoted by Q, and the set of algebraic integers by A. 
Proposition 4.12. (i) A is a ring. 
(ii) Q is a eld. Namely, it is an algebraic closure of the eld of rational numbers. 
Proof. We will be using denition (4.10). Let  be an eigenvalue of 
A  Matn(C) 
with eigenvector v, let  be an eigenvalue of 
B  Matm(C) 
with eigenvector w. Then    is an eigenvalue of 
A  Idm  Idn  B, 
and  is an eigenvalue of 
A  B. 
The corresponding eigenvector is in both cases v  w. This shows that both A and Q are rings. 
To show that the latter is a eld, it suces to note that if  = 0 is a root of a polynomial p(x) of 
degree d, then 1 is a root of xdp(1/x). The last statement is easy, since a number  is algebraic 
if and only if it denes a nite extension of Q. 
Proposition 4.13. A  Q = Z. 
Proof. We will be using denition (4.9). Let z be a root of 
n p(x) = x +  a1x n1+ ... + an1x + an, 
and suppose pz = =q Q, gcd(p,q ) 1.  
Notice that the  leading term of p(x) will have qnin the denominator, whereas all the other terms 
will have a lower power of q there. Thus, if q =  1, then p(z) /Z, a contradiction. Thus, 
z  A  Q  z  Z. The reverse inclusion follows because n  Z is a root of x  n. 
Every algebraic number  has a minimal polynomial p(x), which is the monic polynomial 
with rational coecients of the smallest degree such that p() = 0. Any other polynomial q(x) with 
rational coecients such that q() = 0 is divisible by p(x). Roots of p(x) are called the algebraic 
conjugates of ; they are roots of any polynomial q with rational coecients such that q() = 0.</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Proof. The proof is obtained easily from the Mackey formula. Namely, U (Ci) is the number of 
 elements x  Sn such that xgx1 P (for a representative g  Ci), divided by |P|. The order of 
P is  i!, and the num er of  
i b elements x such that xgx1 P is the number of elements in P
conjugate to g (i.e. |Ci  P|) times the order of the centralizer Zg of g (which is n!/|C i|). Thus, 
Zg U i  (Ci) = | |
jj! |C  P|. 
 Now, it is easy to see that the centralizer Zg of g is isomorphic to 
m Sim  (Z/mZ)im , so 
|Zg| =  
m im im!, 
m 
and we get  mim im! mU (Ci) = 
Now, since P = j S , we have   P
j|C .
 j! i  |  

j
  ! |Ci  P   j
| =  ,r
r m1 mjm rjm!j1 

where r = (r jm) runs over all collections of nonnegative integers such that 
  
mrjm = j , 
rjm = im. 
m j 
Indeed, an element of Ci that is in P would dene an ordered partition of each j into parts 
(namely, cycle lengths), with m occuring rjm times, such that the total (over all j) number of times 
each part m occurs is im. Thus we get 
 im! U (Ci) =  

j rjm! r m 
But this is  exactly the coecient of xin 
 
(xm m i m 1 + ... + xN )
m1 
(rjm is the number of times we take xm
j ). 
4.15 The Frobenius character formula 
Let (x) =  
1i&lt;j N (xi  xj ). Let  = (N  1,N  2,..., 0)  CN. The following theorem, due  
to Frobenius, gives a character formula for the Specht modules V. 
  +N j Theorem 4.47. Let N  p. Then V (Ci) is the coecient of x+:= xj 
j in the polyno
mial 
(x)  
H(x)im m. 
m1 
Remark. Here is an equivalent formulation  of Theorem 4.47: V (Ci) is the coecient of x
in the (Laurent) polynomial 
  x1 
i&lt;j j)
i 
Hm(xim . x m1</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Now pick V  N such that V (g) = 0; it exists by Lemma 4.24. Theorem 4.21 implies that g
(and hence any element of C) acts by a scalar in V . Now let H be the subgroup of G generated 
 by elements ab1, a,b  C. It is normal and acts trivially in V , so H =  G, as V is nontrivial. Also 
H = 1, since |C| &gt; 1.
Proof of Burnsides theorem. 
Assume Burnsides theorem is false. Then there  exists a nonsolvable group G of order paqb. Let 
G be the smallest such group. Then G is simple, and by Theorem 4.23, it cannot have a conjugacy 
class of order pk or qk , k  1. So the order of any conjugacy class in G is either 1 or is divisible 
by pq. Adding the orders of conjugacy classes and equating the sum to paqb, we see that there has 
to be more than one conjugacy class consisting just of one element. So G has a nontrivial center, 
which gives a contradiction. 
4.6 Representations of products 
Theorem 4.25. Let G,H be nite groups, {Vi} be the irreducible representations of G over a 
eld k (of any characteristic), and {Wj } be the irreducible representations of H over k. Then the 
irreducible representations of G  H over k are {Vi  Wj}. 
Proof. This follows from Theorem 2.26. 
4.7 Virtual representations 
Denition 4.26. A virtual representation of a nite group G is an integer linear combination of  irreducible representations of G, V = niVi, ni  Z (i.e., ni are not assumed to be nonnegative).  The character of V is V := niVi . 
The following lemma is often very useful (and will be used several times below). 
Lemma 4.27. Let V be a virtual representation with character V . If (V ,V ) = 1 and V (1) &gt; 0 
then V is a character of an irreducible representation of G. 
 Proof. Let V1,V2,...,V m be the irreducible representations of G, and V = niVi. Then by 
orthonormality of characters, ( , ) = n2V  2 V i i . Soi ni = 1, meaning that n
i = 1 for exactly 
one i, and nj = 0 for j =  i. But V (1) &gt; 0, so ni = +1
 and we are done. 
4.8 Induced Representations 
Given a representation V of a group G and a subgroup HG, there is a natural way to construct 
a representation   ofH. The restricted representation of V to H, ResG
H V is the representation given 
by the vector space V and the action ResG V = V|H . 
H 
There is also a natural, but more complicated way to construct a representation of a group G 
given a representation V of its subgroup H. 
Denition 4.28. If G is a group, HG, and V is a representation of H, then the induced 
representation IndG H V is the representation of G with
IndG H V = {f : G  V |f(hx) = V (h)f(x)x  G,h  H}</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Lemma 4.56. Let k be a eld of characteristic zero. 
(i) For any nite dimensional vector space U over k, the space SnU is spanned by elements of 
the form u  ...  u, u  U. 
(ii) For any algebra A over k, the algebra SnA is generated by elements n(a), a  A. 
Proof. (i) The space SnU is an irreducible representation of GL(U ) (Problem 3.19). The subspace 
spanned by u  ...  u is a nonzero subrepresentation, so it must be everything. 
(ii) By the fundamental theorem on symmetric functions, there exists a polynomial P with 
rational coecients such that P (H1(x),...,H n(x)) = x1...xn (where x = (x 1,...,x n)). Then 
P (n(a), n(a 2),..., n(a n)) = a  ...  a. 
The rest follows from (i). 
Now, the algebra A is semisimple by Maschkes theorem, so the double centralizer theorem 
applies, and we get the following result, which goes under the name Schur-Weyl duality. 
Theorem 4.57. (i) The image A of C[S] and the image B of U(gl(V )) in End(V nn ) are central
izers of each other. 
         (ii) BothAandBare semisimple. In particular, V nis a semisimple gl(V )-module. 
(iii) We have a decomposition of  A  B-modules V n= V  L, where the summation 
is taken over partitions of n, V are Specht modules for Sn, and L are some distinct irreducible 
representations of gl(V ) or zero. 
4.19 Schur-Weyl duality for GL(V ) 
The Schur-Weyl duality for the Lie algebra gl(V ) implies a similar statement for the group GL(V ). 
Proposition 4.58. The image of GL(V ) in End(V n) spans B. 
 Proof. Denote the span of gn, g  GL(V ), by B. Let b  End V be any element. 
  We claim that Bcontains bn. Indeed, for all values of t but nitely many, tId+b is invertible, 
so  (t  Id + b)nbelongs to B. This implies that this is true for all t, in particular for t = 0, since 
(t  Id + b)n is a polynomial in t.
The rest follows from Lemma 4.56. 
Corollary 4.59.  As a representation of Sn  GL(V ), V ndecomposes as V  L, where 
L = Hom Sn (V,V n) are distinct irreducible representations of GL(V ) or zero. 
Example 4.60. If  = (n) then L = SnV , and if  = (1n) (n copies of 1) then L = nV . It was 
shown in Problem 3.19 that these representations are indeed irreducible (except that nV is zero 
if n&gt; dim V ).</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>and the action g(f)(x) = f(xg) g  G. 
Remark 4.29. In fact,  IndG
H V is naturally isomorphic to Hom H (k[G],V ).
Let us check that  IndG
H V is indeed a representation: 
g(f)(hx) = f(hxg) = V (h)f(xg) = V (h)g(f)(x), and g(g(f))(x) = g(f)(xg) = f(xgg) = 
(gg)(f)(x) for any g,g,x  G and h  H. 
Remark 4.30. Notice that if we choose a representative x from every right H-coset  of G, then 
any f  IndG 
H V is uniquely determined by {f(x)}.
Because of this,
dim(IndG |G| .
H V ) = dim V  |H| 
Problem 4.31. Check that if KH  G are groups and V a representation of K then IndG H
H IndK V 
is isomorphic to  IndGK V . 
Exercise. Let KG be nite groups, and  : K  C be a homomorphism. Let C be the 
corresponding 1-dimensional representation of K. Let 
1 e = 
(g)1 g  C[K] |K| gK 
be the idempotent corresponding to  . Show that the G-representation IndG
K C is naturally iso-
morphic to C[G]e  (with G acting by left multiplication). 
4.9 The Mackey formula 
Let us now compute the  character  of IndGH V . In each right coset   H\G, choose a representative 
x. 
Theorem 4.32. (The Mackey formula) One has 
 
(g) = 1V (xgx
 ). 
1H\G
:x gx  H 
Remark. If the characteristic of the ground eld k is relatively prime to |H|, then this formula 
can be written as 1  
(g) = 
V (xgx1). |H| 
xG:xgx1H 
Proof. For a right H-coset  of G, let us dene 
 {  G V=fIndH V |f(g) = 0 g }. 
Then one has  
IndG 
H V= 
V, 
 
and so 
(g) =  
(g),</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Note that any algebraic conjugate of an algebraic integer is obviously also an algebraic inte
ger. Therefore, by the Vieta theorem, the minimal polynomial of an algebraic integer has integer 
coecients. 
Below we will need the following lemma: 
Lemma 4.14. If 1,..., m are algebraic numbers, then all algebraic conjugates to 1 + ... + m 
are of the form 1+ ... + 
m, where 
i are some algebraic conjugates of i.
Proof. It suces to prove this for two summands. If i are eigenvalues of rational matrices Ai of 
smallest size (i.e., their characteristic polynomials are the minimal polynomials of i), then 1 + 2 
is an eigenvalue of A := A1  Id + Id  A2. Therefore, so is any algebraic conjugate to 1 + 2. 
But all eigenvalues of A are of the form 1+ 2, so we are done. 
Problem 4.15. (a) Show that for any nite group G there exists a nite Galois extension K C
of Q such that any nite dimensional complex representation of G has a basis in which the matrices 
of the group elements have entries in K. 
Hint. Consider the representations of G over the eld Q of algebraic numbers. 
(b) Show that if V is an irreducible complex representation of a nite group G of dimension 
&gt; 1 then there exists g  G such that V (g) = 0. 
Hint: Assume the contrary. Use orthonormality of characters to show that the arithmetic mean 
of the numbers | V (g)|2for g =  1 is &lt; 1. Deduce that their product  satises 0 &lt;  &lt; 1. 
Show that all conjugates of  satisfy the same inequalities (consider the Galois conjugates of the 
representation V , i.e. representations obtained from V by the action of the Galois group of K over 
Q on the matrices of group elements in the basis from part (a)). Then derive a contradiction. 
Remark. Here is a modication of this argument, which does not use (a). Let N = G
 | |. For 
any 0 &lt; j &lt; N coprime to N, show that the map g  gjis a bijection G  G. Deduce that  |j |2      
g=1V (g) =. Then show that   K := Q(),  = e2i/N, and does not change under the 
automorphism of K given by   j. Deduce that  is an integer, and derive a contradiction. 
4.4 Frobenius divisibility 
Theorem 4.16. Let G be a nite group, and let V be an irreducible representation of G over C. 
Then 
dim V divides |G|.
Proof. Let C1,C2,...,C n be the conjugacy classes of G. Set 
C i = iV (gCi ) | |,dim V 
where gCi is a representative of Ci. 
Proposition 4.17. The numbers i are algebraic integers for all i. 
Proof. Let C be a conjugacy class in G, and P = h C h. Then P is a central element of Z[G], so it 
acts on V by some scalar , which is an algebraic
 integer (indeed, since Z[G] is a nitely generated 
Z-module, any element of Z[G] is integral over Z, i.e., satises a monic polynomial equation with 
integer coecients). On the other hand, taking the trace of P in V , we get |C|V (g) =  dim V , 
|C|V (g) g  C, so  = .dim V</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>1.48). In particular, this understanding will lead us to a new proof of the Frobenius reciprocity 
and to some analogies between induction and restriction. 
Throughout this exercise, we will use the notation and results of the Exercise in Section 1.10. 
Let G be a nite group and HG a subgroup. We consider k [G] as a (k [H] ,k [G])-bimodule 
(both module structures are given by multiplication inside k [G]). We denote this bimodule by 
k [G]1. On the other hand, we can also consider k [G] as a (k [G] ,k [H])-bimodule (again, both 
module structures are given by multiplication). We denote this bimodule by k [G]2. 
(a) Let V be a representation of G. Then, V is a left k [G]-module, thus a (k [G] ,k)-bimodule. 
Thus, the tensor product k [G]1 k[G] V is a (k [H] ,k)-bimodule, i. e., a left k [H]-module. Prove 
that this tensor product is isomorphic to  ResG
H V as a left k [H]-module. The isomorphism ResG
H V 
G
k [G]1 k[G] V is given by v  1 k[G] v for every v  ResH V . 
(b) Let W be a representation of H. Then, W is a left k [H]-module, thus a (k [H] ,k)
bimodule. Then, IndG 
H W = k [G] ,W ), according to Remark 4.30. In   Hom H ( other words, IndG
H W = 
Hom k[H] (k [G]1 ,W ). Now, use part (b) of the Exercise in Section 1.10 to conclude Theorem 4.33. 
(c) Let V be a representation of G. Then, V is a left k [G]-module, thus a (k [G] ,k)-bimodule. 
Prove that not only k [G]V , but also Hom (k [G],V ) is isomorphic to ResG 
1 k[G] k[G] 2 H V as a left 
k [H]-module. The isomorphism Hom k[G] (k [G]2 ,V )  ResG 
H V is given by f  f (1) for every 
f  Hom k[G] (k [G]2 ,V ). 
(d) Let W be a representation of H. Then, W is a left k [H]-module, thus a (k [H] ,k)
bimodule.  Show that IndG
H W is not only isomorphic to Hom k[H] (k [G]1 ,W ), but also isomorphic to  k [G]2k[H]W . The isomorphism Hom k[H] (k [G]1 ,W )  k [G]2k[H]W is given by f  
gg1
P k[H] 
f (g) for every f  Hom k[H] (k [G]1 ,W ), where P is a set of distinct representatives for the right 
H-cosets in G. (This isomorphism is independent of the choice of representatives.) 
(e) Let V be a representation of G and W a representation of H. Use (b) to prove that  
HomG G G IndH W,V is naturally isomorphic to Hom H
W, ResH V 
. 
           G    G (f) LetVbe a representation of H. Prove that Ind = H V 
H (V) Ind as representations of 
  G. [Hint: Write IndGH V as k [G]2 k[H] V and write IndGH (V ) as Hom k[H] (k [G]1 ,V ). Prove   
that the map Hom k[H] (k [G]1 ,V  G ) IndH (V ) k given by f, x k[H] v (f (Sx))(v) is 
a nondegenerate G-invariant bilinear 
form, where
 S : k [G]  k 
[G]
 is the linear
 map dened by 
Sg = g1 for every g  G.] 
4.11 Examples 
Here are some examples of induced representations (we use the notation for representations from 
the character tables). 
1. Let G = S3, H   = Z2. Using the Frobenius reciprocity, we obtain: IndG= C2
H C+  C+, 
IndG C= C2 
H  C.  
2. Let G = S3, H = Z3. Then we  obtain IndGH C+ = C+  C, IndGC= IndG  H C = C2
H  2 . 
3. Let G = S, H = S. Then IndG 4 3 H C+ = C+C3  G C  C C3  G C2  C2C3 C3 , Ind = = . H  , Ind + H +
Problem 4.34. Compute the decomposition into irreducibles of all the representations of A5 in
duced from all the irreducible representations of</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>The proof will be based on the following lemma.
1
Lemma 4.22. If 1,2 ...n are roots of unity such that (1 + 2 + ... + n) is an algebraic n integer, then either 1 = ... = n or 1 + ... + n = 0. 
Proof. Let a = 1 (1 + ... + n). If not all i are equal, then an | |&lt; 1. Moreover, since any algebraic 
conjugate of a root | of unity is also a root of unity, a|  1 for any algebraic conjugate aof a. But
the product of all algebraic conjugates of a is an integer. Since it has absolute value &lt; 1, it must 
equal zero. Therefore, a = 0. 
Proof of theorem 4.21. 
Let dim V = n. Let 1,2,... n be the eigenvalues of V (g). They are roots of unity, so 
         1 V (g) is an algebraic integer. Also, by Proposition 4.17, |C|V (g) is an algebraic integer. Since n 
gcd(n, |C|) = 1, there exist integers a,b such that a|C| + bn = 1. This implies that 
V (g) 1 = ( 1 + ... + n). n n 
is an algebraic integer. Thus, by Lemma 4.22, we get that either 1 = ... = n or 1 + ... + n = 
V (g) = 0. In the rst case, since V (g) is diagonalizable, it must be scalar. In the second case, 
V (g) = 0. The theorem is proved. 
Theorem 4.23. Let G be a nite  group, and let C be a conjugacy class in G of order pkwhere p 
is prime and k&gt; 0. Then G has a proper nontrivial normal subgroup (i.e., G is not simple). 
Proof. Choose an element g  C. Since g =  e, by orthogonality of columns of the character table, 
 
dim VV (g) = 0. (4) 
V IrrG 
We can divide IrrG into three parts: 
1. the trivial representation, 
2. D, the set of irreducible representations whose dimension is divisible by p, and 
3. N, the set of non-trivial irreducible representations whose dimension is not divisible by p. 
Lemma 4.24. There exists V  N such that V (g) = 0.
Proof. If V  D, the number 1 dim(V )V (g) is an algebraic integer, so p 
 1 a = dim(V )V (g) pV D 
is an algebraic integer. 
Now, by (4), we have 
 
0 = (g) +   
C dim VV (g) + 
dim VV (g) = 1 + pa + 
dim VV (g). 
V D V N V N 
This means that the last summand is nonzero.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Lemma 4.42. c is proportional to an  idempotent. Namely, c2
 = n!c. dim V 
Proof. Lemma 4.40 implies that c2  is proportional to c. Also, it is easy to see that the trace of 
c in the regular representation is n! (as the coecient of the identity element in c is 1). This 
implies the statement. 
Lemma 4.43. Let A be an algebra and e be an idempotent in A. Then for any left A-module M, 
one has Hom A(Ae,M ) = eM (namely, x  eM corresponds to fx : Ae  M given by fx(a) = ax, 
a  Ae). 
Proof. Note that 1  e is also an idempotent in A. Thus the statement immediately follows from 
the fact that Hom A(A,M ) = M and the decomposition A = Ae  A(1  e). 
Now we are ready to prove Theorem 4.36. Let   . Then by Lemmas 4.42, 4.43 
Hom Sn (V,V) = Hom Sn (C[S n]c, C[Sn]c) = cC[Sn]c. 
The latter space is zero for  &gt;  by Lemma 4.41, and 1-dimensional if  =  by Lemmas 4.40 
and 4.42. Therefore, V are irreducible, and V is not isomorphic to V if  = . Since the number 
of partitions equals the number of conjugacy classes in Sn, the representations V exhaust all the 
irreducible representations of Sn. The theorem is proved. 
4.14 Induced representations for Sn 
Denote by U the representation IndSn C. It is easy to see that U can be alternatively dened as P U = C[Sn]a. 
Proposition 4.44. Hom(U ,V) = 0 for  &lt; , and dim Hom(U ,V) = 1. Thus, U = 
 KV, where K are nonnegative integers and K=   1. 
Denition 4.45. The integers K are called the Kostka numbers. 
Proof. By Lemmas 4.42 and 4.43, 
Hom(U ,V) = Hom(C[S n]a, C[Sn]ab) = aC[Sn]ab, 
and the result follows from Lemmas 4.40 and 4.41. 
Now let us compute the character of U. Let Ci be the conjugacy class in Sn having il cycles 
of length l for all l  1 (here i is a shorthand notation for (i1,...,i l,...)). Also let x1,...,x N be 
variables, and let  
Hmm(x) = xi 
i 
be the power sum polynomials. 
Theorem 4.46. Let N   p   (where p is the number of parts of ). Then 6U (Ci ) is the coecient
 x of := xj 
jin the polynomial  
Hm(x)im . 
m1 
6If j &gt; p, we dene j to be zero.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_replect</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_replect/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>93</slideno>
          <text>Proof. c belongs to a nite group W . So there is M  N, such that 
c M =1. 
We claim that 
1+ c + c 2 ++ c M1 =0  
as operators on Rn . This implies what we need, since  has at least one strictly positive coecien t, 
so one of the elemen ts 
c,c2,...,cM1 
must have at least one strictly negativ e one. Furthermore, it is enough to show that 1 is not an 
eigenvalue for c, since 
(1 + c + c 2 ++ c M1)v = w =0  
2 2 3  cw = c 
1+ c + c +  + c M1 
v =(c + c + c +  + c M1 + 1)v = w. 
Assume the contrary, i.e., 1 is a eigenvalue of c and let v be a corresp onding eigenvector. 
cv = vs1 ...snv = v  
 s2 ...snv = s1v. 
But since si only changes the i-th coordinate of v, we get 
s1v = v and s2 ...snv = v. 
Repeating the same procedure, we get 
siv = v 
for all i. But this means 
B(v,i)=0. 
for all i, and since B is nondegenerate, we get v = 0. But this is a contradiction, since v is an 
eigenvector. 
5.8 Proof of Gabriels theorem 
Let V be an indecomp osable represen tation of Q. We introduce a xed labeling 1,...n on Q, such 
that i&lt;j if one can reach j from i. This is possible, since we can assign the highest label to any 
sink, remove this sink from the quiver, assign the next highest label to a sink of the remaining 
quiver and so on. This way we create a labeling of the desired kind. 
We now consider the sequence 
V (0) = F + = F + F + = V, V (1) 
n V, V (2) 
n1n V,... 
This sequence is well dened because of the selected labeling: n has to be a sink of Q, n  1 has 
to be a sink of Qn (where Qn is obtained from Q by reversing all the arrows at the vertex r) and 
so on. Furthermore, we note that V (n) is a represen tation of Q again, since every arrow has been 
reversed twice (since we applied a reection functor to every vertex). This implies that we can 
dene 
V (n+1) = Fn +V (n),... 
and continue the sequence to innit y. 
94</text>
        </slide>
        <slide>
          <slideno>63</slideno>
          <text>(where N  p). 
In this formula, there are many cancelations. After making some of these cancelations, we 
obtain the hook length formula. Namely , for a square (i,j) in a Young diagram  (i,j  1,i  j), 
dene the hook of (i,j) to be the set of all squares (i,j) in  with i  i, j = j or i = i, j  j. 
Let h(i,j) be the length of the hook of i,j, i.e., the number of squares in it. 
Theorem 4.53. (The hook length formula) One has 
n! dim V = h(i,j) . 
ij
Proof. The formula follows from formula (5). Namely , note that 
l1!=  
k. 
1&lt;j N(l1  lj ) 1kl1,k=l1lj
It is easy to see that the factors in this product are exactly the hooklengths h(i, 1). Now delete the 
rst row of the diagram and proceed by induction. 
4.18 Schur-Weyl dualit y for gl(V ) 
We start with a simple result which is called the Double Centralizer Theorem. 
Theorem 4.54. Let A, B be two subalgebras of the algebra End E of endomorphisms of a nite 
dimensional vector space E, such that A is semisimple, and B = End A E. Then: 
(i) A = EndB E (i.e., the centralizer of the centralizer of A is A); 
(ii) B is semisimple; 
(iii) as a representation of A  B, E decomposes as E = iI Vi  Wi, where Vi are all the 
irreducible representations of A, and Wi are all the irreducible representations of B. In particular, 
we have a natural bijection between irreducible representations of A and B. 
Proof. Since A is semisimple, we have a natural decomp osition E = iI Vi  Wi, where Wi := 
Hom A(Vi,E), and A = i End Vi. Therefore, by Schurs lemma, B = EndA(E) is naturally identi
ed with i End(Wi). This implies all the statemen ts of the theorem. 
We will now apply Theorem 4.54 to the following situation: E = V n , where V is a nite 
dimensional vector space over a eld of characteristic zero, and A is the image of C[Sn] in End E. 
Let us now characterize the algebra B. Let gl(V ) be End V regarded as a Lie algebra with operation 
ab  ba. 
Theorem 4.55. The algebra B = EndA E is the image of the universal enveloping algebra U(gl(V )) 
under its natural action on E. In other words, B is generated by elements of the form 
n(b) := b  1  ...  1+1  b  ...  1+ ... +1  1  ...  b, 
b  gl(V ). 
Proof. Clearly , the image of U(gl(V )) is contained in B, so we just need to show that any elemen t 
of B is contained in the image of U(gl(V )). By denition, B = Sn End V , so the result follows from 
part (ii) of the following lemma. 
64</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Example 2.14. 1. Let A = k[x]/(xn). This algebra has a unique irreducible represen tation, which 
is a 1-dimensional space k, in which x acts by zero. So the radical Rad(A) is the ideal (x). 
2. Let A be the algebra of upper triangular n by n matrices. It is easy to check that the 
irreducible represen tations of A are Vi, i =1,...,n, which are 1-dimensional, and any matrix x acts 
by xii. So the radical Rad(A) is the ideal of strictly upper triangular matrices (as it is a nilpotent 
ideal and contains the radical). A similar result holds for block-triangular matrices. 
Denition 2.15. A nite dimensional algebra A is said to be semisimple if Rad(A) = 0. 
Proposition 2.16. For a nite dimensional algebra A, the following are equivalent: 
1.	A is semisimple. 
2.	
i (dim Vi)2 = dim A, where the Vis are the irreducible representations of A. 
3.	A = Matdi (k) for some di.i 
4. Any nite dimensional representation of	A is completely reducible (that is, isomorphic to a 
direct sum of irreducible representations). 
5.	A is a completely reducible representation of A. 
Proof. As dim AdimRad(A) = (dim Vi)2, clearly dim A = (dim Vi)2 if and only if Rad(A) = i	 i 
0. Thus, (1)  (2). 
Next, by Theorem 2.12, if Rad(A) =	 = i Matdi (k) for di = dim Vi. Thus, 0, then clearly A 
(1)  (3). Conversely, if A = Matdi (k), then by Theorem 2.6, Rad(A) =0, so A is semisimple. i 
Thus (3)  (1). 
Next, (3)  (4) by Theorem 2.6. Clearly (4)  (5). To see that (5)  (3), let A = 
i niVi. 
Consider EndA(A) (endomorphisms of A as a represen tation of A). As the Vis are pairwise non-
isomorphic, by Schurs lemma, no copy of Vi in A can be mapped to a distinct Vj . Also, again by 
Schurs lemma, EndA (Vi)= k. Thus, EndA(A)  Matni = Aop by Problem = (k). But EndA(A) 
= (k). Thus, A  Matni i 
Matni 1.22, so Aop  Matni =((k))op = (k), as desired. i	 i i 
2.6 Characters of represen tations 
Let A be an algebra and V a nite-dimensional represen tation of A with action . Then the 
character of V is the linear function V : A  k given by 
V (a) = trV ((a)).|
If [A,A] is the span of comm utators [x,y] := xy  yx over all x,y  A, then [A,A]  ker V . Thus, 
we may view the character as a mapping V : A/[A,A]  k. 
Exercise. Show that if WV are nite dimensional represen tations of A, then V = W + 
V/W . 
Theorem 2.17. (i) Characters of (distinct) irreducible nite-dimensional representations of A are 
linearly independent. 
(ii) If A is a nite-dimensional semisimple algebra, then these characters form a basis of 
(A/[A,A]). 
27</text>
        </slide>
        <slide>
          <slideno>69</slideno>
          <text>4.24.2 1-dimensional represen tations 
First, we describ e the 1-dimensional represen tations of G. 
Proposition 4.70. [G,G]= SL2(Fq). 
Proof. Clearly , 
det(xyx1 y1)=1, 
so 
[G,G]  SL2(Fq). 
To show the converse, it suces to show that the matrices 
11a 0 10 
01 , 0 a1 , 11 
are comm utators (as such matrices generate SL2(Fq).) Clearly , by using transp osition, it suces 
to show that only the rst two matrices are comm utators. But it is easy to see that the matrix 
11 
01 
is the comm utator of the matrices 
11/2 10  
A = ,B = ,01 0 1 
while the matrix a 0  
0 a1 
is the comm utator of the matrices 
a 0 01 
A = ,B = ,01 10 
This completes the proof. 
Therefore,
G/[G,G]  via g  det(g).
 = F
q 
The one-dimensional represen tations of G thus have the form 
(g)= 
det(g)
, 
where  is a homomorphism 
 : Fq  C; 
so there are q  1 such represen tations, denoted C. 
70</text>
        </slide>
        <slide>
          <slideno>50</slideno>
          <text>Note that any algebraic conjugate of an algebraic integer is obviously also an algebraic inte
ger. Therefore, by the Vieta theorem, the minimal polynomial of an algebraic integer has integer 
coecien ts. 
Below we will need the following lemma: 
Lemma 4.14. If 1,...,m are algebraic numbers, then all algebraic conjugates to 1 + ... + m 
are of the form 1+ ... + , where are some algebraic conjugates of i.m i 
Proof. It suces to prove this for two summands. If i are eigenvalues of rational matrices Ai of 
smallest size (i.e., their characteristic polynomials are the minimal polynomials of i), then 1 + 2 
is an eigenvalue of A := A1  Id +Id  A2. Therefore, so is any algebraic conjugate to 1 + 2. 
But all eigenvalues of A are of the form 1+ 2, so we are done. 
Problem 4.15. (a) Show that for any nite group G there exists a nite Galois extension K C
of Q such that any nite dimensional complex representation of G has a basis in which the matric es 
of the group elements have entries in K. 
Hint. Consider the representations of G over the eld Q of algebraic numbers. 
(b) Show that if V is an irreducible complex representation of a nite group G of dimension 
&gt; 1 then there exists g  G such that V (g)=0. 
Hint: Assume the contrary. Use orthonormality of characters to show that the arithmetic mean 
of the numbers |V (g)|2 for g =  1 is &lt; 1. Deduce that their product  satises 0 &lt;&lt; 1. 
Show that all conjugates of  satisfy the same inequalities (consider the Galois conjugates of the 
representation V , i.e. representations obtaine d from V by the action of the Galois group of K over 
Q on the matric es of group elements in the basis from part (a)). Then derive a contradiction. 
Remark. Here is a modication of this argument, which does not use (a). Let N = G. For 
j ||
any 0 &lt;j &lt;N coprime to N, show that the map g  gis a bijection G  G. Deduce that 
2 
g=1|V (gj )|= . Then show that   K := Q(),  = e2i/N , and does not change under the 
automorphism of K given by   j. Deduce that  is an integer, and derive a contradiction. 
4.4 Frobenius divisibilit y 
Theorem 4.16. Let G be a nite group, and let V be an irreducible representation of G over C. 
Then 
dim V divides G.||
Proof. Let C1,C2,...,Cn be the conjugacy classes of G. Set 
i = V (gCi ) |Ci| ,dim V 
where gCi is a represen tative of Ci. 
Proposition 4.17. The numbers i are algebraic integers for all i. 
Proof. Let C be a conjugacy class in G, and P = 
hC h. Then P is a central elemen t of Z[G], so it 
acts on V by some scalar , which is an algebraic integer (indeed, since Z[G] is a nitely generated 
Z-module, any elemen t of Z[G] is integral over Z, i.e., satises a monic polynomial equation with 
integer coecien ts). On the other hand, taking the trace of P in V , we get CV (g)=  dim V , 
|C|V (g) ||
g  C, so  = .dim V 
51</text>
        </slide>
        <slide>
          <slideno>59</slideno>
          <text>Lemma 4.42. c is proportional to an idempotent. Namely, c 2 = dim n! 
V c. 
Proof. Lemma 4.40 implies that c2 
 is proportional to c. Also, it is easy to see that the trace of 
c in the regular represen tation is n! (as the coecien t of the identity elemen t in c is 1). This 
implies the statemen t. 
Lemma 4.43. Let A be an algebra and e be an idempotent in A. Then for any left A-module M, 
one has Hom A(Ae,M) = eM (namely, x  eM corresponds to fx : Ae  M given by fx(a)= ax, 
a  Ae). 
Proof. Note that 1  e is also an idemp otent in A. Thus the statemen t immediately follows from 
the fact that Hom A(A,M) = M and the decomp osition A = Ae  A(1  e). 
Now we are ready to prove Theorem 4.36. Let   . Then by Lemmas 4.42, 4.43 
Hom Sn (V,V) = Hom Sn (C[S n]c, C[Sn]c)= cC[Sn]c. 
The latter space is zero for &gt; by Lemma 4.41, and 1-dimensional if  =  by Lemmas 4.40 
and 4.42. Therefore, V are irreducible, and V is not isomorphic to V if  = . Since the number 
of partitions equals the number of conjugacy classes in Sn, the represen tations V exhaust all the 
irreducible represen tations of Sn. The theorem is proved. 
4.14 Induced represen tations for Sn 
Denote by U the represen tation IndSn C. It is easy to see that U can be alternativ ely dened as P U = C[Sn]a. 
Proposition 4.44. Hom(U ,V)=0 for &lt;, and dim Hom(U ,V)=1. Thus, U = 
KV, where K are nonnegative integers and K =1. 
Denition 4.45. The integers K are called the Kostk a numbers. 
Proof. By Lemmas 4.42 and 4.43, 
Hom(U,V) = Hom(C[S n]a, C[Sn]ab)= aC[Sn]ab, 
and the result follows from Lemmas 4.40 and 4.41. 
Now let us compute the character of U. Let Ci be the conjugacy class in Sn having il cycles 
of length l for all l  1 (here i is a shorthand notation for (i1,...,il,...)). Also let x1,...,xN be 
variables, and let 
mHm(x)=  
xi 
i 
be the power sum polynomials. 
Theorem 4.46. Let N  p (where p is the number of parts of ). Then U (Ci) is the coecient6 
of x :=  xjj in the polynomial  
Hm(x)im . 
m1 
If j&gt;p, we dene j to be zero. 
60
6</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>Theorem 3.8 gives a powerful metho d of checking if a given complex represen tation V of a nite 
group G is irreducible. Indeed, it implies that V is irreducible if and only if (V ,V ) = 1. 
Exercise. Let G be a nite group. Let Vi be the irreducible complex represen tations of G. 
For every i, let 
i = dim Vi  
Vi (g) g1  C [G] . |G| gG  
(i) Prove that i acts on Vj as the identity if j = i, and as the null map if j = i. 
(ii) Prove that i are idemp otents, i.e., i 2 = i for any i, and ij = 0 for any i = j. 
Hint: In (i), notice that i comm utes with any elemen t of k [G], and thus acts on Vj as an 
intertwining operator. Corollary 1.17 thus yields that i acts on Vj as a scalar. Compute this 
scalar by taking its trace in Vj . 
Here is another orthogonalit y formula for characters, in which summation is taken over irre
ducible represen tations rather than group elemen ts. 
Theorem 3.9. Let g,h  G, and let Zg denote the centralizer of g in G. Then 
 
V (g)V (h)=  |Zg| if g is conjugate to h 
0, otherwise 
V 
where the summation is taken over all irreducible representations of G. 
Proof. As noted above, V (h)= V  (h), so the left hand side equals (using Maschkes theorem): 
 
V (g)V  (h) = Tr|V V V  (g  (h)1)= 
V 
Tr|V EndV (x  gxh1) = Tr|C[G](x  gxh1). 
If g and h are not conjugate, this trace is clearly zero, since the matrix of the operator x  gxh1 
in the basis of group elemen ts has zero diagonal entries. On the other hand, if g and h are in the 
same conjugacy class, the trace is equal to the number of elemen ts x such that x = gxh1, i.e., the 
order of the centralizer Zg of g. We are done. 
Remark. Another proof of this result is as follows. Consider the matrix U whose rows are 
labeled by irreducible represen tations of G and columns by conjugacy classes, with entries UV,g = 
V (g)/
|Zg|. Note that the conjugacy class of g is G/Zg, thus |G|/|Zg| is the number of elemen ts 
conjugate to G. Thus, by Theorem 3.8, the rows of the matrix U are orthonormal. This means 
that U is unitary and hence its columns are also orthonormal, which implies the statemen t. 
3.6	Unitary represen tations. Another proof of Maschkes theorem for complex 
represen tations 
Denition 3.10. A unitary nite dimensional represen tation of a group G is a represen tation of G 
on a complex nite dimensional vector space V over C equipp ed with a G-invariant positive denite 
Hermitian form4 (, ), i.e., such that V (g) are unitary operators: (V (g)v,V (g)w)=(v,w). 
4We agree that Hermitian forms are linear in the rst argumen t and antilinear in the second one. 
38</text>
        </slide>
        <slide>
          <slideno>94</slideno>
          <text>Theorem 5.34. There is m  N, such that 
d 
V (m) 
= p 
for some p. 
Proof. If V (i) is surjectiv e at the appropriate vertex k, then 

V (i+1) 
F +V (i) 
V (i)
d = d k = skd. 
This implies, that if V (0),...,V (i1) are surjectiv e at the appropriate vertices, then 
d 
V (i) 
= ...sn1snd(V ). 
By Lemma 5.33 this cannot continue indenitely -since d 
V (i) 
may not have any negativ e entries. 
Let i be smallest number such that V (i) is not surjectiv e at the appropriate vertex. By Proposition 
5.30 it is indecomp osable. So, by Proposition 5.28, we get 
d(V (i))= p 
for some p. 
We are now able to prove Gabriels theorem. Namely , we get the following corollaries. 
Corollary 5.35. Let Q be a quiver, V be any indecomposable representation. Then d(V ) is a 
positive root. 
Proof. By Theorem 5.34 
si1 ...sim (d(V )) = p. 
Since the si preserv e B, we get 
B(d(V ),d(V )) = B(p,p)=2. 
Corollary 5.36. Let V,V  be indecomposable representations of Q such that d(V )= d(V ). Then 
V and V  are isomorphic. 
Proof. Let i be such that 
d 
V (i) 
= p. 
Then we also get d 
V (i) 
= p. So 
V (i) = V (i) =: V i . 
Furthermore we have 
V (i) = F + ...F + F +V (0) 
k n1n 
V (i) = Fk + ...F n+ 
1Fn +V (0). 
But both V (i1),...,V (0) and V (i1),...,V (0) have to be surjectiv e at the appropriate vertices. 
This implies 
 FnF ...F F + ...F + Fn + = V F F ...F V i = n1 kk n1V (0) = V (0) 
nn1 k FnF n
1 ...F kFk + ...F n+ 
1Fn +V (0) = V (0) = V  
95</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>V Example 1.10. 1. V = 0. 
2. V = A, and  : A  EndA is dened as follows: (a) is the operator of left multiplication by 
a, so that (a)b = ab (the usual product). This represen tation is called the regular represen tation 
of A. Similarly , one can equip A with a structure of a right A-module by setting (a)b := ba. 
3. A = k. Then a represen tation of A is simply a vector space over k. 
4. A = kx1,...,xn. Then a represen tation of A is just a vector space V over k with a collection 
of arbitrary linear operators (x1),...,(xn): V  V (explain why!). 
Denition 1.11. A subrepresen tation of a represen tation V of an algebra A is a subspace W 
which is invariant under all the operators (a): V  V , a  A. 
For instance, 0 and V are always subrepresen tations. 
Denition 1.12. A represen tation V = 0 of A is irreducible (or simple) if the only subrepresen ta 
tions of V are 0 and V . 
Denition 1.13. Let V1,V2 be two represen tations of an algebra A. A homomorphism (or in
tertwining operator)  : V1  V2 is a linear operator which comm utes with the action of A, i.e., 
(av)= a(v) for any v  V1. A homomorphism  is said to be an isomorphism of represen tations 
if it is an isomorphism of vector spaces. The set (space) of all homomorphisms of represen tations 
V1  V2 is denoted by Hom A(V1,V2). 
Note that if a linear operator  : V1  V2 is an isomorphism of represen tations then so is the 
linear operator 1 : V2  V1 (check it!). 
Two represen tations between which there exists an isomorphism are said to be isomorphic. For 
practical purposes, two isomorphic represen tations may be regarded as the same, although there 
could be subtleties related to the fact that an isomorphism between two represen tations, when it 
exists, is not unique. 
Denition 1.14. Let V1,V2 be represen tations of an algebra A. Then the space V1  V2 has an 
obvious structure of a represen tation of A, given by a(v1  v2)= av1  av2. 
Denition 1.15. A nonzero represen tation V of an algebra A is said to be indecomp osable if it is 
not isomorphic to a direct sum of two nonzero represen tations. 
It is obvious that an irreducible represen tation is indecomp osable. On the other hand, we will 
see below that the converse statemen t is false in general. 
One of the main problems of represen tation theory is to classify irreducible and indecomp osable 
represen tations of a given algebra up to isomorphism. This problem is usually hard and often can 
be solved only partially (say, for nite dimensional represen tations). Below we will see a number 
of examples in which this problem is partially or fully solved for specic algebras. 
We will now prove our rst result  Schurs lemma. Although it is very easy to prove, it is 
fundamen tal in the whole subject of represen tation theory . 
Proposition 1.16. (Schurs lemma) Let V1,V2 be representations of an algebra A over any eld 
F (which need not be algebraically closed). Let  : V1  V2 be a nonzer o homomorphism of 
representations. Then: 
(i) If V1 is irreducible,  is injective; 
8</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>|
 |
 |
dimensional representation of U is a direct sum of irreducible representations. 
As another example consider the represen tation theory of quivers. 
A quiver is a nite oriented graph Q.A represen tation of Q over a eld k is an assignmen t 
of a k-vector space Vi to every vertex i of Q, and of a linear operator Ah : Vi  Vj to every directed 
edge h going from i to j (loops and multiple edges are allowed). We will show that a represen tation 
of a quiver Q is the same thing as a represen tation of a certain algebra PQ called the path algebra 
of Q. Thus one may ask: what are the indecomp osable nite dimensional represen tations of Q? 
More specically , let us say that Q is of nite type if it has nitely many indecomp osable 
represen tations. 
We will prove the following striking theorem, proved by P. Gabriel about 35 years ago: 
Theorem 1.2. The nite type property of Q does not depend on the orientation of edges. The 
connected graphs that yield quivers of nite type are given by the following list: 
 An :    
  
Dn: 
 E6 : 
 E7 : 

E8 : |
 
The graphs listed in the theorem are called (simply laced) Dynkin diagrams. These graphs 
arise in a multitude of classication problems in mathematics, such as classication of simple Lie 
algebras, singularities, platonic solids, reection groups, etc. In fact, if we needed to make contact 
with an alien civilization and show them how sophisticated our civilization is, perhaps showing 
them Dynkin diagrams would be the best choice! 
As a nal example consider the represen tation theory of nite groups, which is one of the most 
fascinating chapters of represen tation theory . In this theory , one considers represen tations of the 
group algebra A = C[G] of a nite group G  the algebra with basis ag,g  G and multiplication 
law agah = agh. We will show that any nite dimensional represen tation of A is a direct sum of 
irreducible represen tations, i.e., the notions of an irreducible and indecomp osable represen tation 
are the same for A (Masc hkes theorem). Another striking result discussed below is the Frobenius 
divisibilit y theorem: the dimension of any irreducible represen tation of A divides the order of G. 
Finally , we will show how to use represen tation theory of nite groups to prove Burnsides theorem: 
aany nite group of order pqb, where p,q are primes, is solvable. Note that this theorem does not 
mention represen tations, which are used only in its proof; a purely group-theoretical proof of this 
theorem (not using represen tations) exists but is much more dicult! 
6</text>
        </slide>
        <slide>
          <slideno>107</slideno>
          <text>[Cu]	 C. Curtis, Pioneers of Represen tation Theory: Frobenius, Burnside, Schur, and Brauer, AMS, 
1999. 
[CR] C. Curtis and I. Reiner, Represen tation Theory of Finite Groups and Associative Algebras, 
AMS, 2006. 
[FH]	 W. Fulton and J. Harris, Represen tation Theory , A rst course, Springer, New York, 1991. 
[Fr]	Peter J. Freyd, Abelian Categories, an Introduction to the Theory of Functors. Harper and 
Row (1964). 
[McL] S. MacLane, Categories for a working Mathematician: 2nd Ed., Graduate Texts in Mathe
matics 5, Springer, 1998. 
108</text>
        </slide>
        <slide>
          <slideno>61</slideno>
          <text>Proof. Denote V shortly by . Let us denote the class function dened in the theorem by . We 
claim that this function has the property  =  
 L, where L are integers and L = 1. 
Indeed, from Theorem 4.46 we have 
 =  
(1)U+ () , 
SN 
where if the vector  +   () has a negativ e entry, the corresp onding term is dropp ed, and if 
it has nonnegativ e entries which fail to be nonincreasing, then the entries should be reordered in 
the nonincreasing order, making a partition that well denote  +   () (i.e., we agree that 
U+() := U +()). Now note that  =  +   () is obtained from  by adding vectors 
of the form ei  ej, i&lt;j, which implies that &gt; or  = , and the case  =  arises only if 
 = 1, as desired. 
Therefore, to show that  = , by Lemma 4.27, it suces to show that (,) = 1. 
We have
(,)= n1
!  
|Ci|(Ci)2 .
i 
Using that 
n! |Ci| =  
m mim im! , 
we conclude that (,) is the coecien t of x+y+ in the series R(x,y) = (x)(y )S(x,y), 
where 
 (
j xj )im (
k yk  (
j,k xj yk /m)im 
S(x,y)=  m 
mim im! m)im 
= m 
im! m 
. 
i m i m 
Summing over i and m, we get 
S(x,y)=  
exp( 
x m
j ykm/m) = exp(  
log(1  xj yk)) = 
(1  xjyk)1 
m j,k j,k j,k 
Thus, (xi  xj )(yi  yj ) 
R(x,y)= i&lt;j(1  xiyj) . 
i,j
Now we need the following lemma. 
Lemma 4.48. (zj  zi)(yi  yj )i&lt;j
i,j(zi  yj) = det( zi  1 
yj ). 
Proof. Multiply both sides by (ziyj). Then the right hand side must vanish on the hyperplanes i,j
zi = zj and yi = yj (i.e., be divisible by (z)(y)), and is a homogeneous polynomial of degree 
N(N  1). This implies that the right hand side and the left hand side are proportional. The 
proportionalit y coecien t (which is equal to 1) is found by induction by multiplying both sides by 
zN  yN and then setting zN = yN . 
Now setting in the lemma zi =1/xi, we get 
Corollary 4.49. (Cauchy identity) 
R(x,y)=det( 1 )=  1 . 1  xiyjSN N (1  xjy(j))j=1
62</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>Id (123) (132) (12)(34)
#
A4 
1 4 4 3 
C 1 1 1 1 
21  1 C 
21  1 C2 
C3 3 0 0 1 
where  = exp( 2
3 i ). 
The last row can be computed using the orthogonalit y of rows. Another way to compute the 
last row is to note that C3 is the represen tation of A4 by rotations of the regular tetrahedron: in 
this case (123), (132) are the rotations by 1200 and 2400 around a perpendicular to a face of the 
tetrahedron, while (12)(34) is the rotation by 1800 around an axis perpendicular to two opposite 
edges. 
Example 3.15. The following three character tables are of Q8,S4, and A5 respectively. 
1 
(123) 
  + C+
C
-1 i j k Q8 
# 1 1 2 2 2 
1 1 1 1 1
1
C++ 
1 1 -1 -1 
1 1 -1 1 -1 
C 1 1 -1 -1 1 
C2 2 -2 0 0 0 
Id (12) (12)(34) (1234)
#
S4 
1 6 3 8 6 
1 1 1 1 1 C+ 
C 1 -1 1 1 -1 
C2 2 0 2 -1 0 
C3 3 -1 -1 0 1+
C3
3 1 -1 0 -1 
1 Id (123) (12)(34) (12345) (13245) A5 
# 1 20 15 12 12 
C 1 1 1 1 
C3 3 0 -1 1+
5 
+ 
C3 3 0 -1 12
5 
 2 
C4 4 1 0 -1 
C5 5 -1 1 0 0 1
5 
1+2
5 
2 
-1 
Indeed, the computation of the characters of the 1-dimensional represen tations is straigh tfor
ward. 
The character of the 2-dimensional represen tation of Q8 is obtained from the explicit formula 
(3) for this represen tation, or by using the orthogonalit y. 
For S4, the 2-dimensional irreducible represen tation is obtained from the 2-dimensional irre
ducible represen tation of S3 via the surjectiv e homomorphism S4  S3, which allows to obtain its 
character from the character table of S3. 
The character of the 3-dimensional represen tation C3 is computed from its geometric realization + 
by rotations of the cube. Namely , by rotating the cube, S4 permutes the main diagonals. Thus 
(12) is the rotation by 1800 around an axis that is perpendicular to two opposite edges, (12)(34) 
41</text>
        </slide>
        <slide>
          <slideno>56</slideno>
          <text>1.48). In particular, this understanding will lead us to a new proof of the Frobenius recipro city 
and to some analogies between induction and restriction. 
Throughout this exercise, we will use the notation and results of the Exercise in Section 1.10. 
Let G be a nite group and HG a subgroup. We consider k [G] as a (k [H] ,k [G])-bimo dule 
(both module structures are given by multiplication inside k [G]). We denote this bimodule by 
k [G]1. On the other hand, we can also consider k [G] as a (k [G] ,k [H])-bimo dule (again, both 
module structures are given by multiplication). We denote this bimodule by k [G]2. 
(a) Let V be a represen tation of G. Then, V is a left k [G]-module, thus a (k [G] ,k)-bimo dule. 
Thus, the tensor product k [G]1 k[G] V is a (k [H] ,k)-bimo dule, i. e., a left k [H]-module. Prove 
that this tensor product is isomorphic to ResG
H V H V as a left k [H]-module. The isomorphism ResG 
is given by v  1 k[G] v for every v  ResGk [G]1 k[G] V H V . 
(b) Let W be a represen tation of H. Then, W is a left k [H]-module, thus a (k [H] ,k)
bimodule. Then, IndG = Hom H (k [G] ,W ), according to Remark 4.30. In other words, IndG = H W H W 
Hom k[H] (k [G]1 ,W ). Now, use part (b) of the Exercise in Section 1.10 to conclude Theorem 4.33. 
(c) Let V be a represen tation of G. Then, V is a left k [G]-module, thus a (k [G] ,k)-bimo dule. 
Prove that not only k [G]1 k[G] V , but also Hom k[G] (k [G]2 ,V ) is isomorphic to ResG as a left H V 
k [H]-module. The isomorphism Hom k[G] (k [G]2 ,V )  ResG is given by f  f (1) for every H V 
f  Hom k[G] (k [G]2 ,V ). 
(d) Let W be a represen tation of H. Then, W is a left k [H]-module, thus a (k [H] ,k)
bimodule. Show that IndG ,W ), but also isomorphic to H W is not only isomorphic to Hom k[H] (k [G]1 
k [G]2k[H]W . The isomorphism Hom k[H] (k [G]1 ,W )  k [G]2k[H]W is given by f   
gP g1k[H] 
f (g) for every f  Hom k[H] (k [G]1 ,W ), where P is a set of distinct represen tatives for the right 
H-cosets in G. (This isomorphism is independen t of the choice of represen tatives.) 
(e) Let V be a represen tation of G and W a represen tation of H. Use (b) to prove that 
Hom G 
IndG 
W, ResG 
H W,V  
is naturally isomorphic to Hom H H V 
. 
(f) Let V be a represen tation of H. Prove that IndG = H V  as represen tations of H (V ) 
IndG 
G. [Hint: Write IndG as k [G]2 k[H] V H (V ) as Hom k[H] (k [G]1 ,V ). Prove H V and write IndG 
that the map Hom k[H] (k [G]1 ,V ) H (V ) 
 k given by 
f, 
x k[H] v 
 (f (Sx))(v) is 
IndG 
a nondegenerate G-invariant bilinear form, where S : k [G]  k [G] is the linear map dened by 
Sg = g1 for every g  G.] 
4.11 Examples 
Here are some examples of induced represen tations (we use the notation for represen tations from 
the character tables). 
1. Let G = = Using the Frobenius recipro city, we obtain: IndG = C2S3, H Z2. H C+  C+, 
IndG  = C2  C.H C
2. Let G = S3, H = Z3. H C+ , IndG
H C2 = C2Then we obtain IndG = C+  C H C = IndG . 
3. Let G = S4, H = S3. H C+ , IndG  = CC3 
H C2 = C2
C+3 . Then IndG = C+C3 
H C , IndG C3 
+
Problem 4.34. Compute the decomposition into irreducibles of all the representations of A5 in
duced from all the irreducible representations of 
57</text>
        </slide>
        <slide>
          <slideno>74</slideno>
          <text>Because  is also a root of unity, the last term of the expression evaluates to
 
(2 + q1()+ 1q()). 
 elliptic 
Lets evaluate the last summand. 
Since F
q2 is cyclic and q = , 
 
q1()=  
1q()=0. 
F 
q2 F 
q2 
Therefore, 
 
(q1()+ 1q()) =   
(q1()+ 1q()) = 2(q  1) = 
 elliptic F 
q 
since Fis cyclic of order q  1. Therefore,q 
2 2, =(q  1)21 
q(q + 1) 
(q 1)(q 1)2 1+(q 1)1(q 1)+ q(q 
2  1) (2(q q)2(q 1)) 
=1.     
We have now shown that for any  with q =  the represen tation Y with the same character  
as 
W1  V,1  V,1  IndG 
K C 
exists and is irreducible. These characters are distinct for distinct pairs (, ) (up to switch 
  q), so there are q(q1) such represen tations, each of dimension q  1.2 
We have thus found q  1 1-dimensional represen tations of G, q(q1) principal series repre2 
2sentations, and q(q1) complemen tary series represen tations, for a total of q 1 represen tations, 2 
i.e., the number of conjugacy classes in G. This implies that we have in fact found all irreducible 
represen tations of GL2(Fq). 
4.25 Artins theorem 
Theorem 4.73. Let X be a conjugation-invariant system of subgroups of a nite group G. Then 
two conditions are equivalent: 
(i) Any element of G belongs to a subgroup H  X. 
(ii) The character of any irreducible representation of G belongs to the Q-span of characters of 
induced representations IndG is an irreducible representation of H.H V , where H  X and V 
Remark. Statemen t (ii) of Theorem 4.73 is equivalent to the same statemen t with Q-span 
replaced by C-span. Indeed, consider the matrix whose columns consist of the coecien ts of the 
decomp osition of IndG (for various H,V ) with respect to the irreducible represen tations of G.H V 
Then both statemen ts are equivalent to the condition that the rows of this matrix are linearly 
independen t. 
75</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>wi: wi(u)=(u,wi). Then for x  G we have (xwi,wj)=(xwi,wj ). Therefore, putting P = 
1  
xG x, we have |G| 
VW(tij ,tij )= |G|1 
(xvi,vj )(xw i ,wj )= |G|1 
(xvi,vj )(xwi
 ,wj
 )=(P (vi  wi
 ),vj  wj
 ) 
xG xG 
If V = W, this is zero, since P projects to the trivial represen tation, which does not occur in 
V  W . If V = W, we need to consider (P (vi  vi
 ),vj  vj
 ). We have a G-invariant decomp osition 
=V  V  C  L 
C = span( 
vk  vk) 
PL = spana:k akk =0( 
aklvk  vl), 
k,l 
and P projects to the rst summand along the second one. The projection of vi  vi
 to CC  L 
is thus ii
 
vk  vk
dim V 
This shows that 
(P (vi  vi
 ),vj  vj
 )= ii jj 
dim V 
which nishes the proof of (i) and (ii). The last statemen t follows immediately from the sum of 
squares formula. 
3.8 Character tables, examples 
The characters of all the irreducible represen tations of a nite group can be arranged into a char
acter table, with conjugacy classes of elemen ts as the columns, and characters as the rows. More 
specically , the rst row in a character table lists represen tatives of conjugacy classes, the second 
one the numbers of elemen ts in the conjugacy classes, and the other rows list the values of the 
characters on the conjugacy classes. Due to Theorems 3.8 and 3.9 the rows and columns of a 
character table are orthonormal with respect to the appropriate inner products. 
Note that in any character table, the row corresp onding to the trivial represen tation consists 
of ones, and the column corresp onding to the neutral elemen t consists of the dimensions of the 
represen tations. 
S3 Id (12) (123) 
#13 2 
Here is, for example, the character table of S3 : C+ 11 1 
C 1-1 1 
C2 20 -1 
It is obtained by explicitly computing traces in the irreducible represen tations. 
For another example consider A4, the group of even permutations of 4 items. There are three 
one-dimensional represen tations (as A4 has a normal subgroup Z2  Z2, and A4/Z2  Z2 = Z3). 
Since there are four conjugacy classes in total, there is one more irreducible represen tation of 
dimension 3. Finally , the character table is 
40</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>1 Basic notions of represen tation theory 
1.1 What is represen tation theory? 
In technical terms, represen tation theory studies represen tations of associative algebras. Its general 
content can be very briey summarized as follows. 
An associative algebra over a eld k is a vector space A over k equipp ed with an associative 
bilinear multiplication a,b  ab, a,b  A. We will always consider associative algebras with unit, 
i.e., with an elemen t 1 such that 1 a = a 1= a for all a  A. A basic example of an associative   
algebra is the algebra EndV of linear operators from a vector space V to itself. Other important 
examples include algebras dened by generators and relations, such as group algebras and universal 
enveloping algebras of Lie algebras. 
A represen tation of an associative algebra A (also called a left A-module) is a vector space 
V equipp ed with a homomorphism  : A  EndV , i.e., a linear map preserving the multiplication 
and unit. 
A subrepresen tation of a represen tation V is a subspace UV which is invariant under all  
operators (a), a  A. Also, if V1,V2 are two represen tations of A then the direct sum V1  V2 
has an obvious structure of a represen tation of A. 
A nonzero represen tation V of A is said to be irreducible if its only subrepresen tations are 
0 and V itself, and indecomp osable if it cannot be written as a direct sum of two nonzero 
subrepresen tations. Obviously , irreducible implies indecomp osable, but not vice versa. 
Typical problems of represen tation theory are as follows: 
1. Classify irreducible represen tations of a given algebra A. 
2. Classify indecomp osable represen tations of A. 
3. Do 1 and 2 restricting to nite dimensional represen tations. 
As mentioned above, the algebra A is often given to us by generators and relations. For 
example, the universal enveloping algebra U of the Lie algebra sl(2) is generated by h,e,f with 
dening relations 
he  eh =2e, hf  fh = 2f, ef  fe = h. (1) 
This means that the problem of nding, say, N-dimensional represen tations of A reduces to solving 
a bunch of nonlinear algebraic equations with respect to a bunch of unkno wn N by N matrices, 
for example system (1) with respect to unkno wn matrices h,e,f. 
It is really striking that such, at rst glance hopelessly complicated, systems of equations can 
in fact be solved completely by metho ds of represen tation theory! For example, we will prove the 
following theorem. 
Theorem 1.1. Let k = C be the eld of complex numbers. Then: 
(i) The algebra U has exactly one irreducible representation Vd of each dimension, up to equiv
alence; this representation is realized in the space of homogeneous polynomials of two variables x,y 
of degree d  1, and dened by the formulas 
(h)= xx  yy , (e)= xy , (f)= yx . 
(ii) Any indecomposable nite dimensional representation of U is irreducible. That is, any nite
5</text>
        </slide>
        <slide>
          <slideno>92</slideno>
          <text>Proposition 5.31. Let Q be a quiver and V a representation of Q. 
1. Let i  Q be a sink and let V be surjective at i. Then
d(Fi +V )= si(d(V )).
2. Let i  Q be a source and let V be injective at i. Then
d(FiV )= si(d(V )).
Proof. We only prove the rst statemen t, the second one follows similarly . Let i  Q be a sink and 
let 
 :  
Vj  Vi 
ji 
be surjectiv e. Let K = ker . Then 
dim K =  
dim Vj  dim Vi. 
ji 
Therefore we get 

d(F +V )  d(V ) 
=  
dim Vj  2dim Vi = B (d(V ),i)i i
ji
and 
d(Fi +V )  d(V ) 
j =0,j = i. 
This implies 
d(Fi +V )  d(V )= B (d(V ),i) i 
 d(F +V )= d(V )  B (d(V ),i) i = si (d(V )) .i 
5.7 Coxeter elemen ts 
Denition 5.32. Let Q be a quiver and let  be the underlying graph. Fix any labeling 1,...,n 
of the vertices of . Then the Coxeter elemen t c of Q corresp onding to this labeling is dened as 
c = s1s2 ...sn. 
Lemma 5.33. Let 
 =  
kii 
i 
with ki  0 for all i but not all ki =0. Then there is N  N, such that 
N c 
has at least one strictly negative coecient. 
93</text>
        </slide>
        <slide>
          <slideno>62</slideno>
          <text>Corollary 4.49 easily implies that the coecien t of x+y+ is 1. Indeed, if  = 1 is a permu
tation in SN , the coecien t of this monomial in (1x1 
j y(j)) is obviously zero. 
Q
Remark. For partitions  and  of n, let us say that    or  if    is a sum of 
vectors of the form ei  ej , i&lt;j (called positive roots). This is a partial order, and  implies 
  . It follows from Theorem 4.47 and its proof that 
 = KU . 
This implies that the Kostk a numbers K vanish unless . 
4.16 Problems 
In the following problems, we do not make a distinction between Young diagrams and partitions. 
Problem 4.50. For a Young diagram , let A() be the set of Young diagrams obtaine d by adding 
a square to , and R() be the set of Young diagrams obtaine d by removing a square from . 
(a) Show that ResSn V = R()V.Sn1 
(b) Show that IndSn 
Sn1 V = A()V. 
Problem 4.51. The content c() of a Young diagram  is the sum j Let C = ji=1(i  j). 
i&lt;j (ij)  C[Sn] be the sum of all transpositions. Show that C acts on the Specht module V by 
multiplic ation by c(). 
Problem 4.52. (a) Let V be any nite dimensional representation of Sn. Show that the element 
E := (12) + ... + (1n) is diagonalizable and has integer eigenvalues on V , which are between 1  n 
and n  1. 
Hint. Represent E as Cn  Cn1, where Cn = C is the element from Problem 4.51. 
(b) Show that the element (12)+...+(1n) acts on V by a scalar if and only if  is a rectangular 
Young diagram, and compute this scalar. 
4.17 The hook length formula 
Let us use the Frobenius character formula to compute the dimension of V. According to the 
character formula, dim V is the coecien t of x+ in (x)(x 1 + ... + xN )n . Let lj = j + N  j. 
Then, using the determinan t formula for (x) and expanding the determinan t as a sum over 
permutations, we get 
dim V =  
(1)s n!= n!  
(1)s  
lj (lj 1)...(l j N+s(j)+1) = (lj  N + s(j))! l1!...lN ! sSN :lj Ns(j) jsSN j 
n! 
j lj! det(l j (lj  1)...(l j  N + i + 1)). 
Using column reduction and the Vandermonde determinan t formula, we see from this expression 
that 
dim V = n! det(lNi)= n!  
(li  lj ) (5)j

j lj ! 
j lj ! 1i&lt;j N
 
63</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>1.10 Tensor products 
In this subsection we recall the notion of tensor product of vector spaces, which will be extensiv ely 
used below. 
Denition 1.48. The tensor product V W of vector spaces V and W over a eld k is the quotien t 
of the space V  W whose basis is given by formal symbols v  w, v  V , w  W , by the subspace 
spanned by the elemen ts 
(v1 + v2)  w  v1  w  v2  w,v  (w1 + w2)  v  w1  v  w2,av  w  a(v  w),v  aw  a(v  w), 
where v  V,w  W,a  k. 
Exercise. Show that V  W can be equivalently dened as the quotien t of the free abelian 
group VW generated by v  w, v  V,w  W by the subgroup generated by  
(v1 + v2)  w  v1  w  v2  w,v  (w1 + w2)  v  w1  v  w2,av  w  v  aw, 
where v  V,w  W,a  k. 
The elemen ts v  w  V  W , for v  V,w  W are called pure tensors. Note that in general, 
there are elemen ts of V  W which are not pure tensors. 
This allows one to dene the tensor product of any number of vector spaces, V1  ...  Vn. Note 
that this tensor product is associative, in the sense that (V1  V2)  V3 can be naturally identied 
with V1  (V2  V3). 
In particular, people often consider tensor products of the form V n = V  ...  V (n times) for 
a given vector space V , and, more generally , E := V n  (V )m . This space is called the space of 
tensors of type (m,n) on V . For instance, tensors of type (0, 1) are vectors, of type (1, 0) -linear 
functionals (covectors), of type (1, 1) -linear operators, of type (2, 0) -bilinear forms, of type (2, 1) 
-algebra structures, etc. 
If V is nite dimensional with basis ei, i =1,...,N, and ei is the dual basis of V , then a basis 
of E is the set of vectors 
ei1  ...  ein  ej1  ...  ejm , 
and a typical elemen t of E is 
N 
T i1...in  ...  ein j1  ...  ejm ,j1...jm ei1  e
i1,...,in,j1,...,j m=1 
where T is a multidimensional table of numbers. 
Physicists dene a tensor as a collection of such multidimensional tables TB attached to every 
basis B in V , which change according to a certain rule when the basis B is changed. Here it is 
important to distinguish upper and lower indices, since lower indices of T corresp ond to V and 
upper ones to V . The physicists dont write the sum sign, but remem ber that one should sum 
over indices that repeat twice -once as an upper index and once as lower. This convention is 
called the Einstein summation, and it also stipulates that if an index appears once, then there is 
no summation over it, while no index is supposed to appear more than once as an upper index or 
more than once as a lower index. 
One can also dene the tensor product of linear maps. Namely , if A : V  V  and B : W  W  
are linear maps, then one can dene the linear map A  B : V  W  V   W  given by the formula 
(A  B)(v  w)= Av  Bw (check that this is well dened!) 
17</text>
        </slide>
        <slide>
          <slideno>102</slideno>
          <text>Dictionary between category theory and linear algebra
Category C Vector space V with a nondegenerate inner product 
The set of morphisms Hom(X,Y ) Inner product (x,y) on V (maybe nonsymmetric) 
Opposite category Cop Same space V with reversed inner product 
The category Sets The ground eld k 
Full subcategory in C Nondegenerate subspace in V 
Functor F : CD Linear operator f : V  W 
Functor F : C Sets Linear functional f  V  = Hom(V,k) 
Represen table functor Linear functional f  V  given by f(v)=(u,v), u  V 
Yoneda lemma Nondegeneracy of the inner product (on both sides) 
Not all functors are represen table If dim V = , not f  V , f(v)=(u,v) 
Left and right adjoin t functors Left and right adjoin t operators 
Adjoin t functors dont always exist Adjoin t operators may not exist if dim V = 
If they do, they are unique If they do, they are unique 
Left and right adjoin ts may not coincide The inner product may be nonsymmetric 
Example 6.13. 1. Let V be a nite dimensional represen tation of a group G or a Lie algebra g. 
Then the left and right adjoin t to the functor V  on the category of represen tations of G is the 
functor V . 
2. The functor ResG
K . This is nothing but the statemen t of the Frobenius K is left adjoin t to IndG 
recipro city. 
3. Let Assock be the category of associative unital algebras, and Liek the category of Lie 
algebras over some eld k. We have a functor L : Assock  Liek, which attaches to an associative 
algebra the same space regarded as a Lie algebra, with bracket [a,b]= ab  ba. Then the functor L 
has a left adjoin t, which is the functor U of taking the universal enveloping algebra of a Lie algebra. 
4. We have the functor GL1 : Assock  Groups , given by A  GL1(A)= A. This functor 
has a left adjoin t, which is the functor G  k[G], the group algebra of G. 
5. The left adjoin t to the forgetful functor Assock  Vectk is the functor of tensor algebra: 
V  TV . Also, if we denote by Comm k the category of comm utativ e algebras, then the left adjoin t 
to the forgetful functor Comm k  Vectk is the functor of the symmetric algebra: V  SV . 
One can give many more examples, spanning many elds. These examples show that adjoin t 
functors are ubiquitous in mathematics. 
6.7 Abelian categories 
The type of categories that most often appears in represen tation theory is abelian categories. 
The standard denition of an abelian category is rather long, so we will not give it here, referring 
the reader to the textbook [Fr]; rather, we will use as the denition what is really the statemen t of 
the Freyd-Mitc hell theorem: 
Denition 6.14. An abelian category is a category (enriched over the category of abelian groups), 
which is equivalent to a full subcategory C of the category A-mod of left modules over a ring A, 
closed under taking nite direct sums, as well as kernels, cokernels, and images of morphisms. 
We see from this denition that in an abelian category , Hom(X,Y ) is an abelian group for each 
X,Y , compositions are group homomorphisms with respect to each argumen t, there is the zero ob
ject, the notion of an injectiv e morphism (monomorphism) and surjectiv e morphism (epimorphism), 
and every morphism has a kernel, a cokernel, and an image. 
103</text>
        </slide>
        <slide>
          <slideno>67</slideno>
          <text>with Y . Taking into accoun t the proof of (i), we deduce that R has the required decomp osition, 
which is compatible with the second action of GL(V ) (by left multiplications). This implies the 
statemen t. 
Note that the Peter-W eyl theorem generalizes Maschkes theorem for nite group, one of whose 
forms states that the space of complex functions Fun(G, C) on a nite group G as a represen tation 
of G  G decomp oses as V Irrep(G)V   V . 
Remark 4.67. Since the Lie algebra sl(V ) of traceless operators on V is a quotien t of gl(V ) by 
scalars, the above results extend in a straigh tforward manner to represen tations of the Lie algebra 
sl(V ). Similarly , the results for GL(V ) extend to the case of the group SL(V ) of operators with 
determinan t 1. The only dierence is that in this case the represen tations L and L+1m are 
isomorphic, so the irreducible represen tations are parametrized by integer sequences 1  ...  N 
up to a simultaneous shift by a constan t. 
In particular, one can show that any nite dimensional represen tation of sl(V ) is completely 
reducible, and any irreducible one is of the form L (we will not do this here). For dim V = 2 one 
then recovers the represen tation theory of sl(2) studied in Problem 1.55. 
4.23 Problems 
Problem 4.68. (a) Show that the Sn-representation V:= C[Sn]ba is isomorphic to V. 
Hint. Dene Sn-homomorphisms f : V  Vand g : V V by the formulas f(x)= xa and 
g(y)= yb, and show that they are inverse to each other up to a nonzer o scalar. 
(b) Let  : C[Sn]  C[Sn] be the automorphism sending s to (1)ss for any permutation s. 
Show that  maps any representation V of Sn to V  C. Show also that (C[S n]a)= C[Sn](a), 
for a  C[Sn]. Use (a) to deduce that V  C = V , where  is the conjugate partition to , 
obtaine d by reecting the Young diagram of . 
Problem 4.69. Let Rk,N be the algebra of polynomials on the space of k-tuples of complex N by N 
matric es X1,...,Xk, invariant under simultane ous conjugation. An example of an element of Rk,N 
is the function Tw := Tr(w(X1,...,Xk )), where w is any nite word on a k-letter alphab et. Show 
that Rk,N is generated by the elements Tw. 
Hint. Consider invariant functions that are of degree di in each Xi, and realize this space as 
a tensor product iSdi (V  V ). Then embed this tensor product into (V  V )N = End(V )n , 
and use the Schur-Weyl duality to get the result. 
4.24 Represen tations of GL2(Fq) 
4.24.1 Conjugacy classes in GL2(Fq) 
Let Fq be a nite eld of size q of characteristic other than 2, and G = GL2(Fq). Then 
|G| =(q 2  1)(q 2  q), 
since the rst column of an invertible 2 by 2 matrix must be non-zero and the second column may 
not be a multiple of the rst one. Factoring, 
|GL2(Fq)| = q(q + 1)(q  1)2 . 
68</text>
        </slide>
        <slide>
          <slideno>85</slideno>
          <text>1. V1 + V2 + V3 = V. 
2. V1  V2 =0,V1  V3 =0,V2  V3 =0. 
3. V1  V2  V3,V2  V1  V3,V3  V1  V2. 
But this implies that 
V1  V2 = V1  V3 = V2  V3 = V. 
So we get 
dim V1 = dim V2 = dim V3 = n 
and 
dim V =2n. 
Since V3  V1  V2 we can write every elemen t of V3 in the form 
x  V3,x =(x1,x2),x1  V1,x2  V2. 
We then can dene the projections 
B1 : V3  V1, (x1,x2)  x1, 
B2 : V3  V2, (x1,x2)  x2. 
Since V3  V1 =0,V3  V2 = 0, these maps have to be injectiv e and therefore are isomorphisms. We 
then dene the isomorphism 
A = B2  B1 : V1  V2.1 
Let e1,...,en be a basis for V1. Then we get 
V1 = C e1  C e2  C en 
V2 = C Ae1  C Ae2  C Aen
V3 ).
 = C (e1 + Ae1)  C (e2 + Ae2)  C (en + Aen
So we can think of V3 as the graph of an isomorphism A : V1  V2. From this we obtain the 
decomp osition 
 V  C2     
n V 
1 V 
3 C(1
, 0) C(1
, 1) 
= 
 j=1  
V 
2 C(0 
, 1) 
These corresp ond to the indecomp osable object 
2 
1 1 
 
1 
Thus the quiver D4 with the selected orientation has 12 indecomp osable objects. If one were to 
explicitly decomp ose represen tations for the other possible orientations, one would also nd 12 
indecomp osable objects. 
It appears as if the number of indecomp osable represen tations does not depend on the orienta
tion of the edges, and indeed -Gabriels theorem will generalize this observ ation. 
86</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>2.5 Finite dimensional algebras 
Denition 2.9. The radical of a nite dimensional algebra A is the set of all elemen ts of A which 
act by 0 in all irreducible represen tations of A. It is denoted Rad(A). 
Proposition 2.10. Rad(A) is a two-side d ideal. 
Proof. Easy. 
Proposition 2.11. Let A be a nite dimensional algebra. 
(i) Let I be a nilpotent two-side d ideal in A, i.e., I n =0 for some n. Then I Rad(A).  
(ii) Rad(A) is a nilpotent ideal. Thus, Rad(A) is the largest nilpotent two-side d ideal in A. 
Proof. (i) Let V be an irreducible represen tation of A. Let v  V . Then Iv V is a subrepresen
n
tation. If Iv = 0 then Iv = V so there is x  I such that xv = v. Then x= 0, a contradiction.  
Thus Iv = 0, so I acts by 0 in V and hence I Rad(A). 
(ii) Let 0 = A0 A1 ... An = A be a ltration of the regular represen tation of A by  
subrepresen tations such that Ai+1/Ai are irreducible. It exists by Lemma 2.8. Let x  Rad(A). 
Then x acts on Ai+1/Ai by zero, so x maps Ai+1 to Ai. This implies that Rad(A)n = 0, as 
desired. 
Theorem 2.12. A nite dimensional algebra A has only nitely many irreducible representations 
Vi up to isomorphism, these representations are nite dimensional, and 
A/Rad(A)  
End Vi. = 
i 
Proof. First, for any irreducible represen tation V of A, and for any nonzero v  V , Av  V is a 
nite dimensional subrepresen tation of V . (It is nite dimensional as A is nite dimensional.) As 
V is irreducible and Av = 0, V = Av and V is nite dimensional. 
Next, suppose we have non-isomorphic irreducible represen tations V1,V2,...,Vr. By Theorem 
2.5, the homomorphism  
i : A   
End Vi 
i i 
is surjectiv e. So r  
i dimEnd Vi  dim A. Thus, A has only nitely many non-isomorphic 
irreducible represen tations (at most dim A). 
Now, let V1,V2,...,Vr be all non-isomorphic irreducible nite dimensional represen tations of 
A. By Theorem 2.5, the homomorphism 
 
i : A   
End Vi 
i i 
is surjectiv e. The kernel of this map, by denition, is exactly Rad(A). 
Corollary 2.13. 
i (dim Vi)2  dim A, where the Vis are the irreducible representations of A. 
Proof. As dim End Vi = (dim Vi)2, Theorem 2.12 implies that dim AdimRad(A) = dimEnd Vi = (dim Vi)2 . As dim Rad(A)  0, (dim Vi)2  dim A. i 
i i 
26</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Problem 2.24. Let A be an algebra, and V a representation of A. Let  : A  EndV . A formal 
deformation of V is a formal series 
= 0 + t1 + ... + tnn + ..., 
where i : A  End(V ) are linear maps, 0 = , and (ab)= (a)(b). 
If b(t) = 1+ b1t + b2t2 + ..., where bi  End(V ), and  b1 is a formal deformation of , then b
is also a deformation of , which is said to be isomorphic to . 
(a) Show that if Ext1(V,V )=0, then any deformation of  is trivial, i.e., isomorphic to . 
(b) Is the converse to (a) true? (consider the algebra of dual numbers A = k[x]/x2). 
Problem 2.25. The Cliord algebra. Let V be a nite dimensional complex vector space 
equipped with a symmetric bilinear form (, ). The Clior d algebra Cl(V ) is the quotient of the 
tensor algebra TV by the ideal generated by the elements v  v  (v,v)1, v  V . More explicitly, if 
xi, 1  i  N is a basis of V and (xi,xj )= aij then Cl(V ) is generated by xi with dening relations 
xixj + xjxi =2aij ,x i 2 = aii. 
Thus, if (, )=0, Cl(V )= V . 
(i) Show that if (, ) is nondegenerate then Cl(V ) is semisimple, and has one irreducible repre
sentation of dimension 2n if dim V =2n (so in this case Cl(V ) is a matrix algebra), and two such 
representations if dim(V )=2n +1 (i.e., in this case Cl(V ) is a direct sum of two matrix algebras). 
Hint. In the even case, pick a basis a1,...,an,b1,...,bn of V in which (ai,aj )=(bi,bj )=0, 
(ai,bj )= ij /2, and construct a representation of Cl(V ) on S := (a1,...,an) in which bi acts as 
dier entiation  with respect to ai. Show that S is irreducible. In the odd case the situation is 
similar, except there should be an additional basis vector c such that (c,ai)=(c,bi)=0, (c,c)= 
1, and the action of c on S may be dened either by (1)degree or by (1)degree+1, giving two 
representations S+,S(why are they non-isomorphic?). Show that there is no other irreducible 
representations by nding a spanning set of Cl(V ) with 2dim V elements. 
(ii) Show that Cl(V ) is semisimple if and only if (, ) is nondegenerate. If (, ) is degenerate, what 
is Cl(V )/Rad(Cl(V ))? 
2.10 Represen tations of tensor products 
Let A,B be algebras. Then A  B is also an algebra, with multiplication (a1  b1)(a2  b2)= 
a1a2  b1b2. 
Exercise. Show that Matm(k)  Matn= Matmn(k). (k) 
The following theorem describ es irreducible nite dimensional represen tations of AB in terms 
of irreducible nite dimensional represen tations of A and those of B. 
Theorem 2.26. (i) Let V be an irreducible nite dimensional representation of A and W an 
irreducible nite dimensional representation of B. Then V  W is an irreducible representation of 
A  B. 
(ii) Any irreducible nite dimensional representation M of A  B has the form (i) for unique 
V and W . 
Remark 2.27. Part (ii) of the theorem typically fails for innite dimensional represen tations; 
e.g. it fails when A is the Weyl algebra in characteristic zero. Part (i) also may fail. E.g. let 
A = B = V = W = C(x). Then (i) fails, as A  B is not a eld. 
31</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Remark. Thus, we see that in general, the Krull-Sc hmidt theorem fails for innite dimensional 
modules. However, it still holds for modules of nite length, i.e., modules M such that any ltration 
of M has length bounded above by a certain constan t l = l(M). 
2.9 Problems 
Problem 2.21. Extensions of represen tations. Let A be an algebra, and V,W be a pair of 
representations of A. We would like to classify representations U of A such that V is a subrepre
sentation of U, and U/V = W . Of course, there is an obvious example U = V  W , but are there 
any others? 
Suppose we have a representation U as above. As a vector space, it can be (non-uniquely) 
identie d with V  W , so that for any a  A the corresponding operator U (a) has block triangular 
form V (a) f(a)  
U (a)= ,0 W (a) 
where f : A  Hom k(W,V ) is a linear map. 
(a) What is the necessary and sucient condition on f(a) under which U (a) is a repre
sentation? Maps f satisfying this condition are called (1-)cocycles (of A with coecients in 
Hom k(W,V )). They form a vector space denote d Z1(W,V ). 
(b) Let X : W  V be a linear map. The coboundary of X, dX, is dened to be the function A 
Hom k(W,V ) given by dX(a)= V (a)X XW (a). Show that dX is a cocycle, which vanishes if and 
only if X is a homomorphism of representations. Thus coboundaries form a subspace B 1(W,V ) 
Z1(W,V ), which is isomorphic to Hom k(W,V )/Hom A(W,V ). The quotient Z1(W,V )/B1(W,V ) 
is 
denote d Ext1(W,V ). 
(c) Show that if f,f   Z1(W,V ) and f  f   B1(W,V ) then the corresponding extensions 
U,U are isomorphic representations of A. Conversely, if  : U  U  is an isomorphism such that 
(a)= 1V   
01W 
then f  f   B1(V,W ). Thus, the space Ext1(W,V ) classies extensions of W by V . 
(d) Assume that W,V are nite dimensional irreducible representations of A. For any f 
Ext1(W,V ), let Uf be the corresponding extension. Show that Uf is isomorphic to Uf as repre
sentations if and only if f and f  are proportional. Thus isomorphism classes (as representations) 
of nontrivial extensions of W by V (i.e., those not isomorphic to W  V ) are parametrize d by the 
projective space PExt1(W,V ). In particular, every extension is trivial if and only if Ext1(W,V )=0. 
Problem 2.22. (a) Let A = C[x1,...,xn], and Va,Vb be one-dimensional representations in which 
xi act by ai and bi, respectively (ai,bi  C). Find Ext1(Va,Vb) and classify 2-dimensional repre
sentations of A. 
(b) Let B be the algebra over C generated by x1,...,xn with the dening relations xixj =0 for 
all i,j. Show that for n&gt; 1 the algebra B has innitely many non-isomorphic indecomposable 
representations. 
Problem 2.23. Let Q be a quiver without oriente d cycles, and PQ the path algebra of Q. Find 
irreducible representations of PQ and compute Ext1 between them. Classify 2-dimensional repre
sentations of PQ. 
30</text>
        </slide>
        <slide>
          <slideno>97</slideno>
          <text>6 Introduction to categories 
6.1 The denition of a category 
We have now seen many examples of represen tation theories and of operations with represen tations 
(direct sum, tensor product, induction, restriction, reection functors, etc.) A context in which one 
can systematically talk about this is provided by Category Theory. 
Category theory was founded by Saunders MacLane and Samuel Eilenberg around 1940. It is a 
fairly abstract theory which seemingly has no content, for which reason it was christened abstract 
nonsense. Nevertheless, it is a very exible and powerful language, which has become totally 
indisp ensable in many areas of mathematics, such as algebraic geometry , topology, represen tation 
theory , and many others. 
We will now give a very short introduction to Category theory , highligh ting its relevance to the 
topics in represen tation theory we have discussed. For a serious acquain tance with category theory , 
the reader should use the classical book [McL]. 
Denition 6.1. A category C is the following data: 
(i) a class of objects Ob(C); 
(ii) for every objects X,Y  Ob(C), the class Hom C (X,Y ) = Hom(X,Y ) of morphisms (or 
arrows) from X,Y (for f  Hom(X,Y ), one may write f : X  Y ); 
(iii) For any objects X,Y,Z  Ob(C), a composition map Hom(Y,Z)Hom(X,Y )  Hom(X,Z), 
(f,g)  f  g, 
which satisfy the following axioms: 
1. The composition is associative, i.e., (f  g)  h = f  (g  h); 
2. For each X  Ob(C), there is a morphism 1X  Hom(X,X), called the unit morphism, such 
that 1X  f = f and g  1X = g for any f,g for which compositions make sense. 
Remark. We will write X C instead of X  Ob(C). 
Example 6.2. 1. The category Sets of sets (morphisms are arbitrary maps). 
2. The categories Groups , Rings (morphisms are homomorphisms). 
3. The category Vectk of vector spaces over a eld k (morphisms are linear maps). 
4. The category Rep(A) of represen tations of an algebra A (morphisms are homomorphisms of 
represen tations). 
5. The category of topological spaces (morphisms are continuous maps). 
6. The homotop y category of topological spaces (morphisms are homotop y classes of continuous 
maps). 
Important remark. Unfortunately , one cannot simplify this denition by replacing the word 
class by the much more familiar word set. Indeed, this would rule out the important Example 1, 
as it is well known that there is no set of all sets, and working with such a set leads to contradictions. 
The precise denition of a class and the precise distinction between a class and a set is the subject 
of set theory , and cannot be discussed here. Luckily, for most practical purposes (in particular, in 
these notes), this distinction is not essential. 
98</text>
        </slide>
        <slide>
          <slideno>103</slideno>
          <text>Example 6.15. The category of modules over an algebra A and the category of nite dimensional 
modules over A are abelian categories. 
Remark 6.16. The good thing about Denition 6.14 is that it allows us to visualize objects, 
morphisms, kernels, and cokernels in terms of classical algebra. But the denition also has a big 
drawback, which is that even if C is the whole category A-mod, the ring A is not determined by C. 
In particular, two dieren t rings can have equivalent categories of modules (such rings are called 
Morita equivalent). Actually , it is worse than that: for many important abelian categories there 
is no natural (or even manageable) ring A at all. This is why people prefer to use the standard 
denition, which is free from this drawback, even though it is more abstract. 
We say that an abelian category C is k-linear if the groups Hom C (X,Y ) are equipp ed with 
a structure of a vector space over k, and composition maps are k-linear in each argumen t. In 
particular, the categories in Example 6.15 are k-linear. 
6.8 Exact functors 
Denition 6.17. A sequence of objects and morphisms 
X0  X1  ...  Xn+1 
in an abelian category is said to be a complex if the composition of any two consecutiv e arrows 
is zero. The cohomology of this complex is Hi = Ker (di)/Im(di1), where di : Xi  Xi+1 (thus 
the cohomology is dened for 1  i  n). The complex is said to be exact in the i-th term if 
Hi = 0, and is said to be an exact sequence if it is exact in all terms. A short exact sequence 
is an exact sequence of the form 
0  X  Y  Z  0. 
Clearly , 0  X  Y  Z  0 is a short exact sequence if and only if X  Y is injectiv e, 
Y  Z is surjectiv e, and the induced map Y/X  Z is an isomorphism. 
Denition 6.18. A functor F between two abelian categories is additiv e if it induces homomor
phisms on Hom groups. Also, for k-linear categories one says that F is k-linear if it induces k-linear 
maps between Hom spaces. 
It is easy to show that if F is an additiv e functor, then F (X  Y ) is canonically isomorphic to 
F (X)  F (Y ). 
Example 6.19. The functors IndG
K , Hom G(V, ?) in the theory of group represen tations over K , ResG 
a eld k are additiv e and k-linear. 
Denition 6.20. An additiv e functor F : CD between abelian categories is left exact if for 
any exact sequence 
0  X  Y  Z, 
the sequence 
0  F (X)  F (Y )  F (Z) 
is exact. F is right exact if for any exact sequence 
X  Y  Z  0, 
the sequence 
F (X)  F (Y )  F (Z)  0 
is exact. F is exact if it is both left and right exact. 
104</text>
        </slide>
        <slide>
          <slideno>91</slideno>
          <text>:
be surjectiv e and let 
K = ker . 
+When applying F
, the space Vi gets replaced by K. Furthermore, let i 
 : K 
Vj . 
ji 
After applying Fi, K gets replaced by 
ji 
But 
Im = K 
and therefore 

K Vj /(Im ).
 =
ji ji ji 
by the homomorphism theorem. Since  was assumed to be surjectiv e, we get 
K = Vi. 
Proposition 5.30. Let Q be a quiver, and V be an indecomposable representation of Q. Then  

 
K Vj /
ker( :
Vj  Vi) = Im( :
Vj  Vi) =
+V
and FiF
 V (whenever dened) are either indecomposable or 0.
i 
+V -the case FiProof. We prove the proposition for F
 V follows similarly . By Proposition 5.28 it
i 
follows that either 
Vj  Vi 
ji 
is surjectiv e or dim Vi =1, dim Vj =0,j = i. In the last case  
+F
V =0.
i 
+So we can assume that  is surjectiv e. In this case, assume that F
V is decomp osable as
i 
+F
V = X  Y
i 
+with X,Y = 0. But F  V is injectiv e at i, since the maps are canonical projections, whose direct
i 
sum is the tautological embedding. Therefore X and Y also have to be injectiv e at i and hence (by 
5.29) 
+ +FiX = X, F
FiY = Y
 F
i i 
In particular 
FiX = 0, FiY = 0. 
Therefore 
V
= FiF
+V
= FiX  FiY
i 
which is a contradiction, since V was assumed to be indecomp osable. So we can infer that
+F
V
i 
is indecomp osable. 
92</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>1.5 Quotien ts 
Let A be an algebra and I a two-sided ideal in A. Then A/I is the set of (additiv e) cosets of I. 
Let  : A  A/I be the quotien t map. We can dene multiplication in A/I by (a) (b) := (ab).  
This is well dened because if (a)= (a) then 
(ab)= (ab +(a  a)b)= (ab)+ ((a  a)b)= (ab) 
because (a  a)b  Ib  I = ker , as I is a right ideal; similarly , if (b)= (b) then 
(ab)= (ab + a(b  b)) = (ab)+ (a(b  b)) = (ab) 
because a(b  b)  aI  I = ker , as I is also a left ideal. Thus, A/I is an algebra. 
Similarly , if V is a represen tation of A, and WV is a subrepresen tation, then V/W is also a 
represen tation. Indeed, let  : V  V/W be the quotien t map, and set V/W (a)(x) := (V (a)x). 
Above we noted that left ideals of A are subrepresen tations of the regular represen tation of A, 
and vice versa. Thus, if I is a left ideal in A, then A/I is a represen tation of A. 
Problem 1.24. Let A = k[x1,...,xn] and I = A be any ideal in A containing all homogeneous 
polynomials of degree  N. Show that A/I is an indecomposable representation of A. 
Problem 1.25. Let V =0 be a representation of A. We say that a vector v  V is cyclic if it  
generates V , i.e., Av = V . A representation admitting a cyclic vector is said to be cyclic. Show 
that 
(a) V is irreducible if and only if all nonzer o vectors of V are cyclic. 
(b) V is cyclic if and only if it is isomorphic to A/I, where I is a left ideal in A. 
(c) Give an example of an indecomposable representation which is not cyclic. 
Hint. Let A = C[x,y]/I2, where I2 is the ideal spanned by homogeneous polynomials of degree 
 2 (so A has a basis 1,x,y). Let V = A be the space of linear functionals on A, with the action 
of A given by ((a)f )(b)= f(ba). Show that V provides such an example. 
1.6 Algebras dened by generators and relations 
If f1,...,fm are elemen ts of the free algebra kx1,...,xn, we say that the algebra 
A := kx1,...,xn/{f1,...,fm} is generated by x1,...,xn with dening relations f1 =0, ..., fm = 
0. 
1.7 Examples of algebras 
1. The Weyl algebra, kx,y/yx  xy  1.  
2. The q-Weyl algebra, generated by x,x1,y,y1 with dening relations yx = qxy and xx1 = 
x1x = yy1 = y1y = 1. 
Proposition. (i) A basis for the Weyl algebra A is {xiyj ,i,j  0}. 
(ii) A basis for the q-Weyl algebra Aq is {xiyj ,i,j  Z}. 
11</text>
        </slide>
        <slide>
          <slideno>51</slideno>
          <text>Now, consider  
iV (gCi ). 
i 
This is an algebraic integer, since: 
(i) i are algebraic integers by Proposition 4.17, 
(ii) V (gCi ) is a sum of roots of unity (it is the sum of eigenvalues of the matrix of (gCi ), and 
since gC|G 
i | = e in G, the eigenvalues of (gCi ) are roots of unity), and 
(iii) A is a ring (Prop osition 4.12). 
On the other hand, from the denition of i, 
 
iV (gCi )=  |Ci|V (gCi )V (gCi ) . dim V Ci i 
Recalling that V is a class function, this is equal to 
 V (g)V (g)= |G|(V ,V ) . dim V dim V gG 
Since V is an irreducible represen tation, (V ,V )=1, so 
 
iV (gCi )= |G| . dim V Ci 
Since dim|G|
V  Q and 
Ci iV (gCi )  A, by Proposition 4.13 dim|G|
V  Z. 
4.5 Burnsides Theorem 
Denition 4.18. A group G is called solvable if there exists a series of nested normal subgroups 
{e} = G1 G2  ...  Gn = G 
where Gi+1/Gi is abelian for all 1  i  n  1. 
Remark 4.19. Such groups are called solvable because they rst arose as Galois groups of poly
nomial equations which are solvable in radicals. 
aTheorem 4.20 (Burnside). Any group G of order pqb, where p and q are prime and a,b  0, is 
solvable. 
This famous result in group theory was proved by the British mathematician William Burnside 
in the early 20-th century, using represen tation theory (see [Cu]). Here is this proof, presen ted in 
modern language. 
Before proving Burnsides theorem we will prove several other results which are of independen t 
interest. 
Theorem 4.21. Let V be an irreducible representation of a nite group G and let C be a conjugacy 
class of G with gcd(|C|, dim(V )) = 1. Then for any g  C, either V (g)=0 or g acts as a scalar 
on V . 
52</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>(e) Let Nv be the smallest N satisfying (c). Show that  = Nv  1. 
(f) Show that for each N&gt; 0, there exists a unique up to isomorphism irreducible representation 
of sl(2) of dimension N. Compute the matric es E,F,H in this representation using a convenient 
basis. (For V nite dimensional irreducible take  as in (a) and v  V () an eigenve ctor of H. 
Show that v,Fv,...,F v is a basis of V , and compute the matric es of the operators E,F,H in this 
basis.) 
Denote the  +1-dimensional irreducible representation from (f) by V. Below you will show 
that any nite dimensional representation is a direct sum of V. 
(g) Show that the operator C = EF + FE + H2/2 (the so-called Casimir operator) commutes 
with E,F,H and equals (
2+2) Id on V. 
Now it will be easy to prove the direct sum decomposition. Namely, assume the contrary, and 
let V be a reducible representation of the smallest dimension, which is not a direct sum of smaller 
representations. 
(h) Show that C has only one eigenvalue on V , namely (
2+2) for some nonnegative integer . 
(use that the generalized eigensp ace decomposition of C must be a decomposition of representations). 
(i) Show that V has a subrepresentation W = V such that V/W = nV for some n (use (h) 
and the fact that V is the smallest which cannot be decomposed). 
(j) Deduce from (i) that the eigensp ace V () of H is n +1-dimensional. If v1,...,vn+1 is its 
basis, show that F j vi, 1  i  n +1, 0  j   are linearly independent and therefore form a basis 
of V (establish that if Fx =0 and Hx = x then Cx = (2) x and hence  = ).2 
(k) Dene Wi = span(vi,Fvi,...,F vi). Show that Vi are subrepresentations of V and derive a 
contradiction with the fact that V cannot be decomposed. 
(l) (Jacobson-Mor ozov Lemma) Let V be a nite dimensional complex vector space and A : V 
V a nilpotent operator. Show that there exists a unique, up to an isomorphism, representation of 
sl(2) on V such that E = A. (Use the classic ation of the representations and the Jordan normal 
form theorem) 
(m) (Clebsch-Gor dan decomposition) Find the decomposition into irreducibles of the represen
tation V  V of sl(2). 
Hint. For a nite dimensional representation V of sl(2) it is useful to introduce the character 
V (x)= Tr(exH ), x  C. Show that V W (x)= V (x)+ W (x) and V W (x)= V (x) W (x). 
Then compute the character of V and of V V and derive the decomposition. This decomposition 
is of fundamental importanc e in quantum mechanics. 
(n) Let V = CM  CN , and A = JM (0)  IdN + IdM  JN (0), where Jn(0) is the Jordan block 
of size n with eigenvalue zero (i.e., Jn(0)ei = ei1, i =2,...,n, and Jn(0)e1 =0). Find the Jordan 
normal form of A using (l),(m). 
1.15 Problems on Lie algebras 
Problem 1.56. (Lies Theorem) The commutant K(g) of a Lie algebra g is the linear span 
of elements [x,y], x,y  g. This is an ideal in g (i.e., it is a subrepresentation of the adjoint 
representation). A nite dimensional Lie algebra g over a eld k is said to be solvable if there 
exists n such that Kn(g)=0. Prove the Lie theorem: if k = C and V is a nite dimensional 
irreducible representation of a solvable Lie algebra g then V is 1-dimensional. 
21</text>
        </slide>
        <slide>
          <slideno>90</slideno>
          <text>1. Let i  Q be a sink. Then either dim Vi =1, dim Vj =0 for j = i or 
 :  
Vj  Vi 
ji 
is surjective. 
2. Let i  Q be a source. Then either dim Vi =1, dim Vj =0 for j = i or 
 : Vi   
Vj 
ij 
is injective. 
Proof. 1. Choose a complemen t W of Im. Then we get 
W 
V =0 0 V  
 
0 
Since V is indecomp osable, one of these summands has to be zero. If the rst summand is 
zero, then  has to be surjectiv e. If the second summand is zero, then the rst one has to be 
of the desired form, because else we could write it as a direct sum of several objects of the 
type 
1 
0 0 
 
0 
which is impossible, since V was supposed to be indecomp osable. 
2. Follows similarly by splitting away the kernel of . 
Proposition 5.29. Let Q be a quiver, V be a representation of Q. 
1. If 
 :  
Vj  Vi 
ji 
is surjective, then 
FiF+V = V.
i 
2. If 
 : Vi   
Vj 
ij 
is injective, then 
+FiV = V.
 F
i 
Proof. In the following proof, we will always mean by i  j that i points into j in the original
quiver Q. We only establish the rst statemen t and we also restrict ourselv es to showing that the
spaces of V and FiF+V are the same. It is enough to do so for the i-th space. Let
i 
 :  
Vj  Vi 
ji 
91</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>C3 
C3 C4 
+ C  C5  C+3 
C3 
3C

4CA5 C C+3 C4 C5 
C4 C5CC C+
3 
C3 C3 C4  C5
+  C3 
+  C4  C5
+  C3 
3C+ 

 +  C3 
3C C4  C5 
 C4  C5C3 C5 
C  C5  C3 
+ 
C3 
+  C3 
 C  C4  C5 C3 
C  C3  2C5  C4 
 2C4  2C5C5 
3.10 Problems 
Problem 3.17. Let G be the group of symmetries of a regular N-gon (it has 2N elements). 
(a) Describ e all irreducible complex representations of this group (consider the cases of odd and 
even N) 
(b) Let V be the 2-dimensional complex representation of G obtaine d by complexic ation of the 
standar d representation on the real plane (the plane of the polygon). Find the decomposition of 
V  V in a direct sum of irreducible representations. 
Problem 3.18. Let G be the group of 3 by 3 matric es over Fp which are upper triangular and have 
ones on the diagonal, under multiplic ation (its order is p3). It is called the Heisenb erg group. For 
any complex number z such that zp =1 we dene a representation of G on the space V of complex 
functions on Fp, by 

110
010

f)(x)= f(x  1),
 (
001

100
011

f)(x)= z
xf(x). (
001 
(note that zx makes sense since zp =1). 
(a) Show that such a representation exists and is unique, and compute (g) for all g  G. 
(b) Denote this representation by Rz. Show that Rz is irreducible if and only if z =1.
(c) Classify all 1-dimensional representations of G. Show that R1 decomposes into a direct sum 
of 1-dimensional representations, where each of them occurs exactly once. 
(d) Use (a)-(c) and the sum of squares formula to classify all irreducible representations of 
G. 
Problem 3.19. Let V be a nite dimensional complex vector space, and GL(V ) be the group of 
invertible linear transformations of V . Then SnV and mV (m  dim(V )) are representations of 
GL(V ) in a natural way. Show that they are irreducible representations. 
Hint: Choose a basis {ei} in V . Find a diagonal element H of GL(V ) such that (H) has 
distinct eigenvalues. (where  is one of the above representations). This shows that if W is a 
subrepresentation, then it is spanned by a subset S of a basis of eigenve ctors of (H). Use the 
invarianc e of W under the operators (1+ Eij ) (where Eij is dened by Eij ek = jkei) for all i = j
to show that if the subset S is nonempty, it is necessarily the entire basis. 
Problem 3.20. Recall that the adjacency matrix of a graph  (without multiple edges) is the matrix 
in which the ij-th entry is 1 if the vertices i and j are connected with an edge, and zero otherwise. 
Let  be a nite graph whose automorphism group is nonabelian. Show that the adjacency matrix 
of  must have repeated eigenvalues. 
43</text>
        </slide>
        <slide>
          <slideno>83</slideno>
          <text>The rst thing we can do is -as usual -split away the kernels of the maps A1,A2,A3. More 
precisely , we split away the represen tations 
0 0 0 0 0 
 
 
 
 
 0 
to reach a situation where 
V1 + V2 + V3 = V. 
By letting Y = V1  V2  V3, choosing a complemen t V  of Y in V , and setting Vi= V   Vi, 
i =1, 2, 3, we can decomp ose this represen tation into 
 V 
   Y  ker A1 0 0 0 0 ker A3 
0     
   

1
0 ker A2 0 
These represen tations aremultiples oftheindecomp osable objects 
0 0 0 0 0   
0 
   

Y Y

0
 0 0    
1 0 
V1 V3 
A2 
0 0 

Y




3
V

 


2
V

1V
0 1 0 
So we get to a situation where all of the maps A1,A2,A3 are injectiv e. 
 A1 V A3 
V2 
As in 2, we can then identify the spaces V1,V2,V3 with subspaces of V . So we get to the triple of 
subspaces problem of classifying a triple of subspaces of a given space V . 
The next step is to split away a multiple of 
1 
The last summand is a multiple of the indecomp osable represen tation 
 1  
1 1 

1
84</text>
        </slide>
        <slide>
          <slideno>82</slideno>
          <text>By identifying V and Y as subspaces of W , this leads to the problem of classifying pairs of 
subspaces of a given space W up to isomorphism (the pair of subspaces problem). Todo 
 so, we rst choose a complemen t W  of V  Y in W , and set V  = W   V , Y  = W   Y . 
Then we can decomp ose the represen tation as follows: 
VW Y W V  YV  YV  Y     =
 .
 
V
 Y
      The second summand is a multiple of the object 1  1 1 . We go on decomp osing the 
rst summand. Again, to simplify notation, we let 
V = V ,W = W ,Y = Y . 
We can now assume that V  Y = 0. Next, let W  be a complemen t of V  Y in W . Then 
we get 
VW YV Y 0 W 0    =
 VY
   Thesecond ofthese summands isamultiple oftheindecomp osable object 0 1 0. 
Therstsummand canbefurther decomp osedasfollows: 
VY 0 0 V YVV YY       =
These summands are multiples of 
1 10 , 0 11 
So -like in the other orientation -we get 6 indecomp osable represen tations of A3: 
1 00 , 0 01 , 1 11 , 
0 10 , 1 10 , 0 11 
5.3 Indecomp osable represen tations of the quiver D4 
As a last -slightly more complicated -example we consider the quiver D4. 
Example 5.10 (D4). We restrict ourselv es to the orientation 
.
 

So a represen tation of this quiver looks like 
A1 V A3 


V1 V3 
A2 

V2 
83</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>V . This number is called the length of V . It is easy to see that n is also the maximal length of a 
ltration of V in which all the inclusions are strict. 
The sequence of the irreducible represen tations W1,...,Wn enumerated in the order they appear 
from some ltration of V as successiv e quotein ts is called a Jordan-H older series of V . 
2.8 The Krull-Sc hmidt theorem 
Theorem 2.19. (Krull-Schmidt theorem) Any nite dimensional representation of A can be uniquely 
(up to an isomorphism and order of summands) decomposed into a direct sum of indecomposable 
representations. 
Proof. It is clear that a decomp osition of V into a direct sum of indecomp osable represen tations 
exists, so we just need to prove uniqueness. We will prove it by induction on dim V . Let V = 
V1  ...  Vm = V1 ...  V . Let is : Vs  V , i: V  V , ps : V  Vs, p: V  V be the natural n s s s s 
maps associated to these decomp ositions. Let s = p1ipi1 : V1  V1. We have n s = 1. Now ss s=1 
we need the following lemma. 
Lemma 2.20. Let W be a nite dimensional indecomposable representation of A. Then 
(i) Any homomorphism  : W  W is either an isomorphism or nilpotent; 
(ii) If s : W  W , s =1,...,n are nilpotent homomorphisms, then so is  := 1 + ... + n. 
Proof. (i) Generalized eigenspaces of  are subrepresen tations of W , and W is their direct sum. 
Thus,  can have only one eigenvalue . If  is zero,  is nilpotent, otherwise it is an isomorphism. 
(ii) The proof is by induction in n. The base is clear. To make the induction step (n  1 to n), 
assume that  is not nilpotent. Then by (i)  is an isomorphism, so n
i=1 1i = 1. The morphisms 
1i are not isomorphisms, so they are nilpotent. Thus 1  1n = 11 + ... + 1n1 is an 
isomorphism, which is a contradiction with the induction assumption. 
By the lemma, we nd that for some s, s must be an isomorphism; we may assume that 
s = 1. In this case, V1= Im(p1i1)  Ker(p1i1), so since V1is indecomp osable, we get that 
f := p
1i1 : V1  V1and g := p1i1: V1 V1 are isomorphisms. 
Let B = j&gt;1Vj , B = j&gt;1Vj; then we have V = V1  B = V1 B. Consider the map 
h : B  B dened as a composition of the natural maps B  V  B attached to these 
decomp ositions. We claim that h is an isomorphism. To show this, it suces to show that Kerh =0 
(as h is a map between spaces of the same dimension). Assume that v  KerhB. Then v  V1. 
On the other hand, the projection of v to V1 is zero, so gv = 0. Since g is an isomorphism, we get 
v = 0, as desired. 
Now by the induction assumption, m = n, and Vj = V
(j) for some permutation  of 2,...,n. 
The theorem is proved. 
Exercise. Let A be the algebra of real-valued continuous functions on R which are periodic 
with period 1. Let M be the A-module of continuous functions f on R which are antiperiodic with 
period 1, i.e., f(x +1) = f(x). 
(i) Show that A and M are indecomp osable A-modules. 
(ii) Show that A is not isomorphic to M but A  A is isomorphic to M  M. 
29</text>
        </slide>
        <slide>
          <slideno>73</slideno>
          <text>We thus have
IndG = IndG 
K Cq K C 
because they have the same character. Therefore, for q =   we get 21 q(q  1) represen tations. 
Next, we look at the following tensor product: 
W1  V,1, 
where 1 is the trivial character and W1 is dened as in the previous section. The character of this 
represen tation is x 0 
 = q(q + 1)(x);0 x 
(A)=0 for A parab olic or elliptic; 
x 0 
 = (x)+ (y). 0 y 
Thus the virtual represen tation 
W1  V,1  V,1  IndG 
K C , 
where  is the restriction of  to scalars, has character 
x 0 
 =(q  1)(x);0 x 
x 1 
 = (x);0 x 
x 0 
 = 0; 0 y 
x y x y x y 
 =   q . yx yxyx 
In all that follows, we will have q = .  
The following two lemmas will establish that the inner product of this character with itself is 
equal to 1, that its value at 1 is positive. As we know from Lemma 4.27, these two properties imply 
that it is the character of an irreducible represen tation of G. 
Lemma 4.72. Let  be the character of the virtual representation dened above. Then 
, =1 
and 
(1) &gt; 0. 
Proof. 
(1) = q(q + 1)  (q + 1)  q(q  1) = q  1 &gt; 0. 
We now compute the inner product ,. Since  is a root of unity, this will be equal to 
1 2
(q1)(q1)2 1+(q1)1(q 1)+ q(q  1)  
(()+q())(()+ q()) 
(q  1)2q(q + 1)   2  
 elliptic 
74</text>
        </slide>
        <slide>
          <slideno>99</slideno>
          <text>8. We have an obvious notion of the Cartesian product of categories (obtained by taking the 
Cartesian products of the classes of objects and morphisms of the factors). The functors of direct 
sum and tensor product are then functors Vectk Vectk  Vectk. Also the operations V  V n , 
V  SnV , V  nV are functors on Vectk. More generally , if  is a represen tation of Sn, we 
have functors V  Hom Sn (,V n). Such functors (for irreducible ) are called the Schur functors. 
They are labeled by Young diagrams. 
9. The reection functors Fi : Rep(Q)  Rep( Qi) are functors between represen tation cate
gories of quivers. 
6.3 Morphisms of functors 
One of the important features of functors between categories which distinguishes them from usual 
maps or functions is that the functors between two given categories themselv es form a category , 
i.e., one can dene a nontrivial notion of a morphism between two functors. 
Denition 6.6. Let C, D be categories and F,G : CD be functors between them. A morphism 
a : F  G (also called a natural transformation or a functorial morphism) is a collection of 
morphisms aX : F (X)  G(X) labeled by the objects X of C, which is functorial in X, i.e., for 
any morphism f : X  Y (for X,Y C) one has aY  F (f)= G(f)  aX . 
A morphism a : F  G is an isomorphism if there is another morphism a1 : G  F such that 
a  a1 and a1  a are the identities. The set of morphisms from F to G is denoted by Hom(F,G). 
Example 6.7. 1. Let FVectk be the category of nite dimensional vector spaces over k. Then the 
functors id and  on this category are isomorphic. The isomorphism is dened by the standard 
maps aV : V  V  given by aV (u)(f)= f(u), u  V , f  V . But these two functors are not 
isomorphic on the category of all vector spaces Vectk, since for an innite dimensional vector space 
V , V is not isomorphic to V . 
2. Let FVect
k be the category of nite dimensional k-vector spaces, where the morphisms 
are the isomorphisms. We have a functor F from this category to itself sending any space V to 
V  and any morphism a to (a)1 . This functor satises the property that V is isomorphic to 
F (V ) for any V , but it is not isomorphic to the identity functor. This is because the isomorphism 
V  F (V )= V  cannot be chosen to be compatible with the action of GL(V ), as V is not 
isomorphic to V  as a represen tation of GL(V ). 
3. Let A be an algebra over a eld k, and F : A  mod  Vectk be the forgetful functor. 
Then as follows from Problem 1.22, EndF = Hom(F,F )= A. 
4. The set of endomorphisms of the identity functor on the category A  mod is the center of 
A (check it!). 
6.4 Equivalence of categories 
When two algebraic or geometric objects are isomorphic, it is usually not a good idea to say that 
they are equal (i.e., literally the same). The reason is that such objects are usually equal in many 
dieren t ways, i.e., there are many ways to pick an isomorphism, but by saying that the objects are 
equal we are misleading the reader or listener into thinking that we are providing a certain choice 
of the identication, which we actually do not do. A vivid example of this is a nite dimensional 
vector space V and its dual space V . 
100</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>Exercise. Show that if G= 0 in k then the number of isomorphism classes of irreducible |	|
represen tations of G over k is strictly less than the number of conjugacy classes in G. 
Hint. Let P =  
gG g  k[G]. Then P 2 = 0. So P has zero trace in every nite dimensional 
represen tation of G over k. 
Corollary 3.7. Any representation of G is determine d by its character if k has characteristic 0; 
namely, V = W implies V = W . 
3.3 Examples 
The following are examples of represen tations of nite groups over C. 
1. Finite abelian groups G = Zn1  Znk . Let G be the set of irreducible represen tations 
of G. Every elemen t of G forms a conjugacy class, so G= G. Recall that all irreducible || ||
represen tations over C (and algebraically closed elds in general) of comm utativ e algebras and 
groups are one-dimensional. Thus, G is an abelian group: if 1,2 : G  C are irreducible 
represen tations then so are 1(g)2(g) and 1(g)1 . G is called the dual or character group 
of G. 
For given n  1, dene  : Zn  C by (m)= e2im/n. Then Z
n = {k : k =0,...,n  1}, 
so Z= Zn. In general, n 
(G1  G2  Gn) = G1  G
2  G
n , 
so G = G for any nite abelian group G. This isomorphism is, however, noncanonical: 
the particular decomp osition of G as Zn1 is not unique as far as which elemen ts  Znk 
of	G corresp ond to Zn1 , etc. is concerned. On the other hand, G (G) is a canonical =
isomorphism, given by  : G  (G), where (g)()= (g).
2. The symmetric group	S3. In Sn, conjugacy classes are determined by cycle decomp osition 
sizes: two permutations are conjugate if and only if they have the same number of cycles 
of each length. For S3, there are 3 conjugacy classes, so there are 3 dieren t irreducible 
represen tations over C. If their dimensions are d1,d2,d3, then d12 +d2
2 +d32 = 6, so S3 must have 
two 1-dimensional and one 2-dimensional represen tations. The 1-dimensional represen tations 
are the trivial represen tation C+ given by () = 1 and the sign represen tation Cgiven by 
()=(1) .  
The 2-dimensional represen tation can be visualized as represen ting the symmetries of the 
equilateral triangle with vertices 1, 2, 3 at the points (cos 120, sin120), (cos 240, sin240), 
(1, 0) of the coordinate plane, respectively. Thus, for example, 
10 	 cos120  sin120 
((12)) = , ((123)) =	 . 0	1 sin 120 cos120 
To show that this represen tation is irreducible, consider any subrepresen tation V . V must be 
the span of a subset of the eigenvectors of ((12)), which are the nonzero multiples of (1, 0) 
and (0, 1). V must also be the span of a subset of the eigenvectors of ((123)), which are 
dieren t vectors. Thus, V must be either C2 or 0. 
3. The quaternion group Q8 = {1, i, j, k}, with dening relations 
i = jk = kj, j = ki = ik, k = ij = ji, 1= i2 = j2 = k2 . 
35</text>
        </slide>
        <slide>
          <slideno>52</slideno>
          <text>The proof will be based on the following lemma.
1
Lemma 4.22. If 1,2 ...n are roots of unity such that (1 + 2 + ... + n) is an algebraic n integer, then either 1 = ... = n or 1 + ... + n =0. 
Proof. Let a = 1 (1 + ... + n). If not all i are equal, then a&lt; 1. Moreo ver, since any algebraic n ||
conjugate of a root of unity is also a root of unity, a 1 for any algebraic conjugate a of a. But ||
the product of all algebraic conjugates of a is an integer. Since it has absolute value &lt; 1, it must 
equal zero. Therefore, a = 0. 
Proof of theorem 4.21. 
Let dim V = n. Let 1,2,...n be the eigenvalues of V (g). They are roots of unity, so 
V (g) is an algebraic integer. Also, by Proposition 4.17, n |C|V (g) is an algebraic integer. Since 
gcd(n, C) = 1, there exist integers a,b such that aC+ bn = 1. This implies that || || 1 
V (g)1 =(1 + ... + n). nn 
is an algebraic integer. Thus, by Lemma 4.22, we get that either 1 = ... = n or 1 + ... + n = 
V (g) = 0. In the rst case, since V (g) is diagonalizable, it must be scalar. In the second case, 
V (g) = 0. The theorem is proved. 
Theorem 4.23. Let G be a nite group, and let C be a conjugacy class in G of order pk where p 
is prime and k&gt; 0. Then G has a proper nontrivial normal subgroup (i.e., G is not simple). 
Proof. Choose an elemen t g  C. Since g = e, by orthogonalit y of columns of the character table,  
 
dim VV (g)=0. (4) 
V IrrG 
We can divide IrrG into three parts: 
1. the trivial represen tation, 
2. D, the set of irreducible represen tations whose dimension is divisible by p, and 
3. N, the set of non-trivial irreducible represen tations whose dimension is not divisible by p. 
Lemma 4.24. There exists V  N such that V (g)=0.
Proof. If V  D, the number 1 dim(V )V (g) is an algebraic integer, so p 
 1 a = dim(V )V (g) pV D 
is an algebraic integer. 
Now, by (4), we have 
0= C(g)+  
dim VV (g)+  
dim VV (g)=1+ pa +  
dim VV (g). 
V D V N V N 
This means that the last summand is nonzero. 
53</text>
        </slide>
        <slide>
          <slideno>84</slideno>
          <text>V So -considering the rst summand and renaming the spaces to simplify notation -we are in a 
situation where 
V = V1 + V2 + V3,V1  V2  V3 =0. 
of Y in V such that V3 ,
 As a next step, we let Y = V1  V2 and we choose a complemen t V 
= V   V2. This yields the decomp osition
1= V   V1,V2and set V
 V    V 
   Y   
V1 V3   
 
 
 
 
1V
 V3 Y 0
=

 
 
Y
 2V
 V2 
The second summand is a multiple of the indecomp osable object 
 1 .
 
1  
0

1
In the resulting situation we have V1  V2 = 0. Similarly we can split away multiples of 
 1  1  
  
1 1 0 1 
and   
   
  
  0 1 
to reach a situation where the spaces V1,V2,V3 do not intersect pairwise 
V1  V2 = V1  V3 = V2  V3 =0. 
If V1  V2  V3 we let Y = V1  (V2  V3). We let V1be a complemen t of Y in V1. Since then 
V1 (V2  V3) = 0, we can select a complemen t V  of V in V which contains V2  V3. This gives1 
us the decomp osition 
 V    V 1
 V 
  
V1 V3 
 
 
 
 
V3 1Y
 V
 0
= 
   
V2 V2 0
The rst of these summands is a multiple of 
 1 
1 0 
 

0 
By splitting these away we get to a situation where V1  V2  V3. Similarly , we can split away 
objects of the type 
1 1   
0 0 0 1 
 and 
   
  
1 0 
to reach a situation in which the following conditions hold 
85</text>
        </slide>
        <slide>
          <slideno>106</slideno>
          <text>Now, in the general case, we prove by induction in k that there exists a lift ek of e0 to A/Ik+1 , 
and it is unique up to conjugation by an elemen t of 1 + I k (this is sucien t as I is nilpotent). 
Assume it is true for k = m  1, and let us prove it for k = m. So we have an idemp otent 
em1  A/Im, and we have to lift it to A/Im+1 . But (Im)2 =0 in A/Im+1, so we are done. 
Denition 7.4. A complete system of orthogonal idemp otents in a unital algebra B is a collection 
of elemen ts e1,...,en  B such that eiej = ijei, and 
in 
=1 ei = 1. 
Corollary 7.5. Let e01,...,e0m be a complete system of orthogonal idempotents in A/I. Then there 
exists a complete system of orthogonal idempotents e1,...,em (eiej = ijei,  ei =1) in A which 
lifts e01,...,e0m. 
Proof. The proof is by induction in m. For m = 2 this follows from Proposition 7.3. For m&gt; 2, 
we lift e01 to e1 using Proposition 7.3, and then apply the induction assumption to the algebra 
(1  e1)A(1  e1). 
7.3 Projective covers 
Obviously , every nitely generated projective module over a nite dimensional algebra A is a direct 
sum of indecomp osable projective modules, so to understand nitely generated projective modules 
over A, it suces to classify indecomp osable ones. 
Let A be a nite dimensional algebra, with simple modules M1,...,Mn. 
Theorem 7.6. (i) For each i =1,...,n there exists a unique indecomposable nitely generated 
projective module Pi such that dim Hom(Pi,Mj )= ij . 
(ii) A = in 
=1(dim Mi)Pi. 
(iii) any indecomposable nitely generated projective module over A is isomorphic to Pi for 
some i. 
Proof. Recall that A/Rad(A) = in 
=1 End(Mi), and Rad(A) is a nilpotent ideal. Pick a basis of 
0 Ei 
Mi, and let eij = jj, the rank 1 projectors projecting to the basis vectors of this basis (j = 
1,..., dim Mi). Then eij 0 are orthogonal idemp otents in A/Rad (A). So by Corollary 7.5 we can lift 
them to orthogonal idemp otents eij in A. Now dene Pij = Aeij . Then A = i  dim Mi Pij , so Pij j=1 
are projective. Also, we have Hom(P ij ,Mk)= eij Mk, so dim Hom(Pij ,Mk)= ik. Finally , Pij is 
independen t of j up to an isomorphism, as eij for xed i are conjugate under A by Proposition 
7.3; thus we will denote Pij by Pi. 
We claim that Pi is indecomp osable. Indeed, if Pi = Q1  Q2, then Hom(Q l,Mj )=0 for all j 
either for l = 1 or for l = 2, so either Q1 =0 or Q2 = 0. 
Also, there can be no other indecomp osable nitely generated projective modules, since any 
such module has to occur in the decomp osition of A. The theorem is proved. 
References 
[BGP] J. Bernstein, I. Gelfand, V. Ponomarev, Coxeter functors and Gabriels theorem, Russian 
Math. Surveys 28 (1973), no. 2, 1732. 
107</text>
        </slide>
        <slide>
          <slideno>45</slideno>
          <text>Recall that the group SO(3) of rotations acts on V , so S2V , End(V ) are representations of this 
group. The laws of physics must be invariant under this group (Galile o transformations), so f must 
be a homomorphism of representations. 
(a) Show that End(V ) admits a decomposition RV W , where R is the trivial representation, 
V is the standar d 3-dimensional representation, and W is a 5-dimensional representation of SO(3). 
Show that S2V = R  W 
(b) Show that V and W are irreducible, even after complexic ation. Deduce using Schurs 
lemma that SP is always symmetric, and for x  R,y  W one has f(x + y)= Kx + y for some 
real numbers K,. 
In fact, it is clear from physics that K, are positive. Physic ally, the compression modulus K 
characterises resistanc e of the material to compression or dilation, while the shearing modulus  
characterizes its resistanc e to changing the shape of the object without changing its volume. For 
instanc e, clay (used for sculpting) has a large compression modulus but a small shearing modulus. 
46</text>
        </slide>
        <slide>
          <slideno>105</slideno>
          <text>7 Structure of nite dimensional algebras 
In this section we return to studying the structure of nite dimensional algebras. Throughout the 
section, we work over an algebraically closed eld k (of any characteristic). 
7.1 Projective modules 
Let A be an algebra, and P be a left A-module. 
Theorem 7.1. The following properties of P are equivalent: 
(i) If  : M  N is a surjective morphism, and  : P  N any morphism, then there exists a 
morphism  : P  M such that    = . 
(ii) Any surjective morphism  : M  P splits, i.e., there exists  : P  M such that  = id. 
(iii) There exists another A-module Q such that P  Q is a free A-module, i.e., a direct sum of 
copies of A. 
(iv) The functor Hom A(P, ?) on the category of A-modules is exact. 
Proof. To prove that (i) implies (ii), take N = P . To prove that (ii) implies (iii), take M to be free 
(this can always be done since any module is a quotien t of a free module). To prove that (iii) implies 
(iv), note that the functor Hom A(P, ?) is exact if P is free (as Hom A(A,N)= N), so the statemen t 
follows, as if the direct sum of two complexes is exact, then each of them is exact. To prove that 
(iv) implies (i), let K be the kernel of the map , and apply the exact functor Hom A(P, ?) to the 
exact sequence 
0  K  M  N  0. 
Denition 7.2. A module satisfying any of the conditions (i)-(iv) of Theorem 7.1 is said to be 
projective. 
7.2 Lifting of idemp otents 
Let A be a ring, and IA a nilpotent ideal.  
Proposition 7.3. Let e0  A/I be an idempotent, i.e., e2 = e0. There exists an idempotent e  A0 
which is a lift of e0 (i.e., it projects to e0 under the reduction modulo I). This idempotent is unique 
up to conjugation by an element of 1+ I. 
Proof. Let us rst establish the statemen t in the case when I 2 = 0. Note that in this case I is a 
left and right module over A/I. Let e be any lift of e0 to A. Then e 2  e = a  I, and e0a = ae0. 
We look for e in the form e = e + b, b  I. The equation for b is e0b + be0  b = a. 
Set b = (2e0  1)a. Then 
e0b + be0  b =2e0a  (2e0  1)a = a, 
so e is an idemp otent. To classify other solutions, set e = e + c. For e to be an idemp otent, we 
must have ec + ce  c = 0. This is equivalent to saying that ece = 0 and (1  e)c(1  e)=0, so 
c = ec(1  e) + (1  e)ce =[e, [e,c]]. Hence e = (1+[c,e])e(1 +[c,e])1 . 
106</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>The 5 conjugacy classes are {1}, {1}, {i}, {j}, {k}, so there are 5 dieren t irreducible 
represen tations, the sum of the squares of whose dimensions is 8, so their dimensions must 
be 1, 1, 1, 1, and 2. 
The center Z(Q8) is {1}, and Q8/Z(Q8) Z2  Z2. The four 1-dimensional irreducible = 
represen tations of Z2  Z2 can be pulled back to Q8. That is, if q : Q8  Q8/Z(Q8) is the 
quotien t map, and  any represen tation of Q8/Z(Q8), then   q gives a represen tation of Q8. 
The 2-dimensional represen tation is V = C2, given by (1) = Id and 
 
0
1 1 1 
0 
1   
0 
1 1 
(i)= ,(j)= ,(k)=	 . (3)0 0	 0 
These are the Pauli matrices, which arise in quantum mechanics. 
Exercise. Show that the 2-dimensional irreducible represen tation of Q8 can be realized in 
the space of functions f : Q8  C such that f(gi)= 1f(g) (the action of G is by right 
multiplication, g  f(x)= f(xg)). 
4. The	symmetric group S4. The order of S4 is 24, and there are 5 conjugacy classes: 
e, (12), (123), (1234), (12)(34). Thus the sum of the squares of the dimensions of 5 irreducible 
represen tations is 24. As with S3, there are two of dimension 1: the trivial and sign repre
sentations, C+ and C. The other three must then have dimensions 2, 3, and 3. Because 
= S4/Z2  Z2, where Z2  Z2 is {e, (12)(34), (13)(24), (14)(23)}, the 2-dimensional repre S3 
sentation of S3 can be pulled back to the 2-dimensional represen tation of S4, which we will 
call C2 . 
We can consider S4 as the group of rotations of a cube acting by permuting the interior 
diagonals (or, equivalently, on a regular octahedron permuting pairs of opposite faces); this 
gives the 3-dimensional represen tation C3 
+. 
The last 3-dimensional represen tation is C3 , the product of C3 with the sign represen tation.  +
C3 and C3 are dieren t, for if g is a transp osition, det g= 1 while det g=(1)3
+  = 1.
 |
 |
 3
+ 3C C 
Note that another realization of C3 
 is by action of S4 by symmetries (not necessarily rotations) 
of the regular tetrahedron. Yet another realization of this represen tation is the space of 
functions on the set of 4 elemen ts (on which S4 acts by permutations) with zero sum of 
values. 
3.4 Duals and tensor products of represen tations 
If V is a represen tation of a group G, then V  is also a represen tation, via 
V  (g)=(V (g))1 =(V (g)1) = V (g1). 
The character is V  (g)= V (g1). 
We have V (g)=  i, where the i are the eigenvalues of g in V . These eigenvalues must be 
roots of unity because (g)|G| = (g|G|)= (e) = Id. Thus for complex represen tations 
V  (g)= V (g1)=  

i 1 =  
i =  
i = V (g). 
In particular, V = V  as representations (not just as vector spaces) if and only if V (g)  R for all 
g  G. 
36</text>
        </slide>
        <slide>
          <slideno>54</slideno>
          <text>and the action g(f)(x)= f(xg) g  G. 
Remark 4.29. In fact, IndG is naturally isomorphic to Hom H (k[G],V ).H V 
Let us check that IndG is indeed a represen tation: H V 
g(f)(hx) = f(hxg)= V (h)f(xg)= V (h)g(f)(x), and g(g(f))(x) = g(f)(xg)= f(xgg)= 
(gg)(f)(x) for any g,g,x  G and h  H. 
Remark 4.30. Notice that if we choose a represen tative x from every right H-coset  of G, then 
any f  IndG is uniquely determined by {f(x)}.H V 
Because of this,
dim(IndG |G| .
H V ) = dim V  H|| 
Problem 4.31. Check that if KH H IndHG are groups and V a representation of K then IndG
K V 
is isomorphic to IndG  
K V . 
Exercise. Let KG be nite groups, and  : K  C be a homomorphism. Let C be the 
corresp onding 1-dimensional represen tation of K. Let 
e =1  
(g)1 g  C[K] |K| gK 
be the idemp otent corresp onding to . Show that the G-represen tation IndG is naturally iso-K C 
morphic to C[G]e  (with G acting by left multiplication). 
4.9 The Mackey formula 
Let us now compute the character  of IndG In each right coset   H\G, choose a represen tative H V . 
x. 
Theorem 4.32. (The Mackey formula) One has 
(g)=  
V (xgx
 1). 
1H\G:x gx  H 
Remark. If the characteristic of the ground eld k is relativ ely prime to H, then this formula ||
can be written as 
(g)= 1  
V (xgx1). |H| 
xG:xgx1H 
Proof. For a right H-coset  of G, let us dene 
= {f  IndG f(g)=0 g V H V |  }. 
Then one has 
IndG =  
H VV, 
 
and so 
(g)=  
(g), 
 
55</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>is the rotation by 1800 around an axis that is perpendicular to two opposite faces, (123) is the 
rotation around a main diagonal by 1200, and (1234) is the rotation by 900 around an axis that is 
perpendicular to two opposite faces; this allows us to compute the traces easily, using the fact that 
the trace of a rotation by the angle  in R3 is 1+2cos .
 is found by
 Now the character of C3 

3C multiplying thecharacter of bythecharacter ofthesignrepresen tation. + 
3C Thisrepresen tation isdenoted by Finally , we explain how to obtain the character table of A5 (even permutations of 5 items). The 
group A5 is the group of rotations of the regular icosahedron. Thus it has a 3-dimensional rotation 
represen tation C3 , in which (12)(34) is the rotation by 1800 around an axis perpendicular to two +
opposite edges, (123) is the rotation by 1200 around an axis perpendicular to two opposite faces, 
and (12345), (13254) are the rotations by 720, respectively 1440, around axes going through two 
opposite vertices. The character of this represen tation is computed from this description in a 
straigh tforward way. 
Another represen tation of A5, which is also 3-dimensional, is C3 twisted by the automorphism + 
, except that the conjugacy classes (12345) and (13245) are interchanged. of A5 given by conjugation by (12) inside S5. . It has the
same character as C3 
+
There are two remaining irreducible represen tations, and by the sum of squares formula their 
dimensions are 4 and 5. So we call them C4 and C5 . 
The represen tation C4 is realized on the space of functions on the set {1, 2, 3, 4, 5} with zero 
sum of values, where A5 acts by permutations (check that it is irreducible!). The character of 
this represen tation is equal to the character of the 5-dimensional permutation represen tation minus 
the character of the 1-dimensional trivial represen tation (constan t functions). The former at an 
elemen t g equals to the number of items among 1,2,3,4,5 which are xed by g. 
The represen tation C5 is realized on the space of functions on pairs of opposite vertices of the 
icosahedron which has zero sum of values (check that it is irreducible!). The character of this 
represen tation is computed similarly to the character of C4, or from the orthogonalit y formula. 
3.9 Computing tensor product multiplicities using character tables 
Character tables allow us to compute the tensor product multiplicities Nijk using 
Vi  Vj =  
Nijk Vk,Nijk =(ij ,k) 
Example 3.16. The following tables represen t computed tensor product multiplicities of irre
C2 
C2 S3 C+ C

C+ C+	Cducible represen tations of S3,S4, and A5 respectively. C+ 
C2 C2C
3C C+  C  C2 
C3 C2	C3 
+ S4 C+ C
C2	C3 
+  C+ C+	C
C+ 
C3 
+ C2 
3C+ 2 3 3C C C    + 3C
 C3 C

C2
C3
+ 
C3 3C+ 
 3C+  C3 
 C3 
+  C3 C+  C
C+  C2   C2 
C+  C2 C
 C3 
42</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>6.6 Adjoin tfunctors ...................................... 102
6.7 Abeliancategories ..................................... 103
6.8 Exact functors ....................................... 104
7 Structure of nite dimensional algebras 106 
7.1 Projectivemodules ..................................... 106
7.2 Lifting ofidemp otents ................................... 106
7.3 Projectivecovers ...................................... 107
INTR ODUCTION 
Very roughly speaking, represen tation theory studies symmetry in linear spaces. It is a beautiful 
mathematical subject which has many applications, ranging from number theory and combinatorics 
to geometry , probabilit y theory , quantum mechanics and quantum eld theory . 
Represen tation theory was born in 1896 in the work of the German mathematician F. G. 
Frobenius. This work was triggered by a letter to Frobenius by R. Dedekind. In this letter Dedekind 
made the following observ ation: take the multiplication table of a nite group G and turn it into a 
matrix XG by replacing every entry g of this table by a variable xg. Then the determinan t of XG 
factors into a product of irreducible polynomials in {xg}, each of which occurs with multiplicit y 
equal to its degree. Dedekind checked this surprising fact in a few special cases, but could not prove 
it in general. So he gave this problem to Frobenius. In order to nd a solution of this problem 
(which we will explain below), Frobenius created represen tation theory of nite groups. 1 
The presen t lecture notes arose from a represen tation theory course given by the rst author to 
the remaining six authors in March 2004 within the framew ork of the Clay Mathematics Institute 
Researc h Academ y for high school studen ts, and its extended version given by the rst author to 
MIT undergraduate math studen ts in the Fall of 2008. The lectures are supplemen ted by many 
problems and exercises, which contain a lot of additional material; the more dicult exercises are 
provided with hints. 
The notes cover a number of standard topics in represen tation theory of groups, Lie algebras, and 
quivers. We mostly follow [FH], with the exception of the sections discussing quivers, which follow 
[BGP]. We also recommend the comprehensiv e textbook [CR]. The notes should be accessible to 
studen ts with a strong background in linear algebra and a basic knowledge of abstract algebra. 
Acknowledgemen ts. The authors are grateful to the Clay Mathematics Institute for hosting 
the rst version of this course. The rst author is very indebted to Victor Ostrik for helping him 
prepare this course, and thanks Josh Nichols-Barrer and Thomas Lam for helping run the course 
in 2004 and for useful commen ts. He is also very grateful to Darij Grinberg for very careful reading 
of the text, for many useful commen ts and corrections, and for suggesting the Exercises in Sections 
1.10, 2.3, 3.5, 4.9, 4.26, and 6.8. 
For more on the history of represen tation theory , see [Cu]. 
4 1</text>
        </slide>
        <slide>
          <slideno>70</slideno>
          <text>4.24.3 Principal series represen tations 
Let 
B  G, B = { 
0  
} 
(the set of upper triangular matrices); then 
|B| =(q  1)2 q, 
[B,B]= U = { 1  
},01 
and 
B/[B,B] q  F
q = F
(the isomorphism maps an elemen t of B to its two diagonal entries). 
Let 
 : B  C 
be a homomorphism dened by 
ab 
 = 1(a)2(c),for some pair of homomorphisms 1,2 : F
q  C. 0 c 
Dene 
V1,2 = IndG 
B C, 
where C is the 1-dimensional represen tation of B in which B acts by . We have 
dim(V1,2 )= |G| = q +1. |B| 
Theorem 4.71. 1. 1 = 2  V1,2 is irreducible.  
2. 1 = 2 =   V1,2 = C  W, where W is a q-dimensional irreducible representation of 
G. 
 
1,2  {  3. W = W if and only if  = ; V1,2 = V if and only if {1,2} = 1, 2} (in the 
  second case, 1 = 2, = 2).  1  
Proof. From the Mackey formula, we have 
trV1,2 (g)= 1  
(aga1). |B| 
aG,aga1 B 
If x 0 
g = ,0 x 
the expression on the right evaluates to 
(g) |G| = 1(x)2(x)
q +1
. |B| 
If x 1 
g = ,0 x 
71</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Proof. (i) If V1,...,Vr are nonisomorphic irreducible nite-dimensional represen tations of A, then 
V1  Vr : A  End V1  End Vr is surjectiv e by the densit y theorem, so V1 ,...,Vr are 
linearly independen t. (Indeed, if  iVi (a) =0 for all a  A, then  iTr(Mi) =0 for all Mi 
EndkVi. But each tr(M i) can range independen tly over k, so it must be that 1 = = r = 0.)  
(ii) First we prove that [Mat d(k), Matd(k)] = sld(k), the set of all matrices with trace 0. It is 
clear that [Mat d(k), Matd(k)]  sld(k). If we denote by Eij the matrix with 1 in the ith row of the 
jth column and 0s everywhere else, we have [Eij ,Ejm]= Eim for i = m, and [Ei,i+1,Ei+1,i]= Eii  
Ei+1,i+1. Now {Eim}{EiiEi+1,i+1 } forms a basis in sld(k), so indeed [Mat d(k), Mat d(k)] = sld(k), 
as claimed. 
By semisimplicit y, we can write A = Mat d1 (k). Then [A,A]= sld1 (k)  Matdr (k)  
sldr (k), and A/[A,A] kr .= By Theorem 2.6, there are exactly r irreducible represen tations of A 
(isomorphic to kd1 ,...,kdr , respectively), and therefore r linearly independen t characters on the 
r-dimensional vector space A/[A,A]. Thus, the characters form a basis. 
2.7 The Jordan-H older theorem 
We will now state and prove two important theorems about represen tations of nite dimensional 
algebras -the Jordan-H older theorem and the Krull-Sc hmidt theorem. 
Theorem 2.18. (Jordan-H older theorem). Let V be a nite dimensional representation of A, 
and 0= V0 V1 ... Vn = V , 0= V0... Vm= V be ltrations of V , such that the   
representations Wi := Vi/Vi1 and W := Vi/Vi
1 are irreducible for all i. Then n = m, and there i 
exists a permutation  of 1,...,n such that W(i) is isomorphic to Wi. 
Proof. First proof (for k of characteristic zero). The character of V obviously equals the sum 
of characters of Wi, and also the sum of characters of Wi. But by Theorem 2.17, the charac
ters of irreducible represen tations are linearly independen t, so the multiplicit y of every irreducible 
represen tation W of A among Wi and among Wiare the same. This implies the theorem. 3 
Second proof (general). The proof is by induction on dim V . The base of induction is clear, 
so let us prove the induction step. If W1 = W1(as subspaces), we are done, since by the induction 
assumption the theorem holds for V/W1. So assume W1 = W1. In this case W1  W1= 0 (as 
W1,W 1are irreducible), so we have an embedding f : W1  W1 V . Let U = V/(W1  W1), and 
0= U0 U1 ... Up = U be a ltration of U with simple quotien ts Zi = Ui/Ui1 (it exists by  
Lemma 2.8). Then we see that: 
1) V/W1 has a ltration with successiv e quotien ts W1,Z1,...,Zp, and another ltration with 
successiv e quotien ts W2,....,Wn. 
2) V/W 1has a ltration with successiv e quotien ts W1,Z1,...,Zp, and another ltration with 
successiv e quotien ts W2,....,W n. 
By the induction assumption, this means that the collection of irreducible represen tations with 
multiplicities W1,W 1,Z1,...,Zp coincides on one hand with W1,...,Wn, and on the other hand, with 
W1,...,W . We are done. m
The Jordan-H older theorem shows that the number n of terms in a ltration of V with irre
ducible successiv e quotien ts does not depend on the choice of a ltration, and depends only on 
3This proof does not work in characteristic p because it only implies that the multiplicities of Wi and Wi  are the 
same modulo p, which is not sucien t. In fact, the character of the represen tation pV , where V is any represen tation, 
is zero. 
28</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>3. The Heisen berg Lie algebra H of matrices  
0 0 0  

000 
It has the basis 
000
 0
 001
 01 
00 
000 000 000 
4. The algebra a(1) of matrices ( 
00 )
Its basis consists of X =( 10 ) and Y =( 01 ), with [X,Y ]= Y .
00 00 
5. so(n), the space of skew-symmetric n  n matrices, with [a,b]= ab  ba. 
Exercise. Show that Example 1 is a special case of Example 5 (for n = 3). 
Denition 1.42. Let g1, g2 be Lie algebras. A homomorphism  : g1  g2 of Lie algebras is a 
linear map such that ([a,b]) = [(a),(b)]. 
 
withrelations []= and[]=[]=0. y,xcy,cx,c
Denition 1.43. Arepresen tation ofaLiealgebra isavector space V withahomomorphism g 
of Lie algebras  : g  End V . 
Example 1.44. Some examples of represen tations of Lie algebras are: 
1. V = 0. 
2. Any vector space V with  = 0 (the trivial represen tation). 
3. The adjoin t represen tation V = g with (a)(b) := [a,b]. That this is a represen tation follows 
from Equation (2). Thus, the meaning of the Jacobi identity is that it is equivalent to the 
existence of the adjoin t represen tation. 
It turns out that a represen tation of a Lie algebra g is the same thing as a represen tation of a 
certain associative algebra U(g). Thus, as with quivers, we can view the theory of represen tations 
of Lie algebras as a part of the theory of represen tations of associative algebras. 
kDenition 1.45. Let g be a Lie algebra with basis xi and [ , ] dened by [xi,xj ]= 
k cij xk. The 
universal enveloping algebra U(g) is the associative algebra generated by the xis with the 
kdening relations xixj  xjxi = 
k cij xk. 
Remark. This is not a very good denition since it depends on the choice of a basis. Later we 
will give an equivalent denition which will be basis-indep enden t. 
Exercise. Explain why a represen tation of a Lie algebra is the same thing as a represen tation 
of its universal enveloping algebra. 
Example 1.46. The associative algebra U(sl(2)) is the algebra generated by e, f, h with relations 
he  eh =2e hf  fh = 2f ef  fe = h. 
 
 
 
 
001
 0
 000
 x =
 y =
 c =
Example 1.47. The algebra U(H), where H is the Heisen berg Lie algebra, is the algebra generated 
by x, y, c with the relations 
yx  xy = c yc  cy =0 xc  cx =0. 
Note that the Weyl algebra is the quotien t of U(H) by the relation c = 1. 
16</text>
        </slide>
        <slide>
          <slideno>66</slideno>
          <text>Theorem 4.63. (Weyl character formula) The representation L is zero if and only if N &lt;p, 
where p is the number of parts of . If N  p, the character of L is the Schur polynomial S(x). 
Therefore, the dimension of L is given by the formula 
dim L =  i  j + j  i 
j  i 1i&lt;j N 
This shows that irreducible represen tations of GL(V ) which occur in V n for some n are labeled 
by Young diagrams with any number of squares but at most N = dim V rows. 
Proposition 4.64. The representation L+1N (where 1N = (1, 1,..., 1)  ZN ) is isomorphic to 
L N V . 
Proof. Indeed, L N V  V n N V  V n+N , and the only component of V n+N that has 
the same character as L N V is L+1N . This implies the statemen t. 
4.22 Polynomial represen tations of GL(V ) 
Denition 4.65. We say that a nite dimensional represen tation Y of GL(V ) is polynomial (or 
algebraic, or rational) if its matrix elemen ts are polynomial functions of the entries of g,g1 , 
g  GL(V ) (i.e., belong to k[gij ][1/ det(g)]). 
For example, V n and hence all L are polynomial. Also dene Lr1N := L (N V )r (this
denition makes sense by Proposition 4.64). This is also a polynomial represen tation. Thus we 
have attached a unique irreducible polynomial represen tation L of GL(V )= GLN to any sequence 
(1,...,N ) of integers (not necessarily positive) such that 1  ...  N . This sequence is called 
the highest weight of L. 
Theorem 4.66. (i) Every nite dimensional polynomial representation of GL(V ) is completely 
reducible, and decomposes into summands of the form L (which are pairwise non-isomorphic). 
(ii) (the Peter-Weyl theorem for GL(V )). Let R be the algebra of polynomial functions on 
GL(V ). Then as a representation of GL(V )  GL(V ) (with action ((g,h))(x) = (g1xh), 
g,h,x  GL(V ),   R), R decomposes as 
R = L
  L, 
where the summation runs over all . 
Proof. (i) Let Y be a polynomial represen tation of GL(V ). We have an embedding  : Y  Y  R 
given by (u,(v))(g) := u(gv), u  V . It is easy to see that  is a homomorphism of represen tations 
(where the action of GL(V ) on the rst component of Y  R is trivial). Thus, it suces to prove 
the theorem for a subrepresen tation YRm . Now, every elemen t of R is a polynomial of gij 
times a nonpositive power of det(g). Thus, R is a quotien t of a direct sum of represen tations of the 
form Sr(V  V )  (N V )s . So we may assume that Y is contained in a quotien t of a (nite) 
direct sum of such represen tations. As V  = N1V N V , Y is contained in a direct sum of 
represen tations of the form V n  (N V )s, and we are done. 
(ii) Let Y be a polynomial represen tation of GL(V ), and let us regard R as a represen tation 
of GL(V ) via ((h))(x) = (xh). Then Hom GL(V )(Y,R) is the space of polynomial functions 
on GL(V ) with values in Y , which are GL(V )-equiv ariant. This space is naturally identied 
67</text>
        </slide>
        <slide>
          <slideno>60</slideno>
          <text>Proof. The proof is obtained easily from the Mackey formula. Namely , U (Ci) is the number of 
elemen ts x  Sn such that xgx1  P (for a represen tative g  Ci), divided by |P|. The order of 
P is i!, and the number of elemen ts x such that xgx1  P is the number of elemen ts in P i 
conjugate to g (i.e. |Ci  P|) times the order of the centralizer Zg of g (which is n!/|Ci|). Thus, 
U (Ci)= |Z
jg
| 
j! |Ci  P|. 
Now, it is easy to see that the centralizer Zg of g is isomorphic to  
m Sim  (Z/mZ)im , so 
|Zg| =  
m im im!, 
m 
and we get  mim im! U (Ci)= m
j j! |Ci  P|. 
Now, since P = 
j Sj , we have 
 j ! = , |Ci  P| 
r  
m1 mrjm rjm!j1 
where r =(rjm) runs over all collections of nonnegativ e integers such that 
 
mrjm = j ,  
rjm = im. 
m j 
Indeed, an elemen t of Ci that is in P would dene an ordered partition of each j into parts 
(namely , cycle lengths), with m occuring rjm times, such that the total (over all j) number of times 
each part m occurs is im. Thus we get 
! U (Ci)=  

j im
rjm! rm 
But this is exactly the coecien t of x in 
m m 
(x1 + ... + xN )im 
m1 
m(rjm is the number of times we take xj ). 
4.15 The Frobenius character formula 
Let (x) = 
i&lt;j (xi  xj ). Let  =(N  1,N  2,..., 0)  CN . The following theorem, due 1 N 
to Frobenius, gives a character formula for the Specht modules V. 
Theorem 4.47. Let N  p. Then V (Ci) is the coecient of x+ :=  xjj +Nj in the polyno
mial 
(x)  
Hm(x)im . 
m1 
Remark. Here is an equivalent formulation of Theorem 4.47: V (Ci) is the coecien t of x 
in the (Lauren t) polynomial 
 
1  x
xj
i  
Hm(x)im . 
i&lt;j m1 
61</text>
        </slide>
        <slide>
          <slideno>65</slideno>
          <text>4.20 Schur polynomials 
Let  =(1,...,p) be a partition of n, and N  p. Let 
N
j +Nj j +NjD(x)=  
(1)s  
x = det(x ). s(j) i 
sSN j=1 
Dene the polynomials 
D(x)S(x) := D0(x) 
(clearly D0(x) is just (x)). It is easy to see that these are indeed polynomials, as D is an
tisymmetric and therefore must be divisible by . The polynomials S are called the Schur 
polynomials. 
Proposition 4.61. 
m m
(x1 + ... + xN )im =  
(Ci)S(x). 
m :pN
Proof. The identity follows from the Frobenius character formula and the antisymmetry of 
m m(x) 
(x1 + ... + xN )im . 
m 
Certain special values of Schur polynomials are of importance. Namely , we have 
Proposition 4.62. 
S(1,z,z 2 ,...,z N1)=  zii  zj j 
zi  zj 
1i&lt;j N 
Therefore, 
S(1,..., 1) =  i  j + j  i 
j  i 1i&lt;j N 
Proof. The rst identity is obtained from the denition using the Vandermonde determinan t. The 
second identity follows from the rst one by setting z = 1. 
4.21 The characters of L 
Proposition 4.61 allows us to calculate the characters of the represen tations L. 
Namely , let dim V = N, g  GL(V ), and x1,...,xN be the eigenvalues of g on V . To compute 
the character L (g), let us calculate TrV n (gns), where s  Sn. If s  Ci, we easily get that this 
trace equals  
Tr(g m)im =  
Hm(x)im . 
m m 
On the other hand, by the Schur-Weyl dualit y 
TrV n (gn s)=  
(Ci)TrL (g). 
Comparing this to Proposition 4.61 and using linear independence of columns of the character table 
of Sn, we obtain 
66</text>
        </slide>
        <slide>
          <slideno>86</slideno>
          <text>5.4 Roots 
From now on, let  be a xed graph of type An,Dn,E6,E7,E8. We denote the adjacency matrix 
of  by R. 
Denition 5.11 (Cartan Matrix). We dene the Cartan matrix as 
A = 2Id  R. 
On the lattice Zn (or the space Rn) we then dene an inner product 
B(x,y)= x T Ay 
corresp onding to the graph . 
Lemma 5.12. 1. B is positive denite. 
2. B(x,x) takes only even values for x  Zn . 
Proof. 1. This follows by denition, since  is a Dynkin diagram. 
2. By the denition of the Cartan matrix we get 
2 2B(x,x)= x T Ax =  
xi aij xj =2  
xi +  
xi aij xj =2  
xi +2  
aij xixj  
i,j i i,j,i=j i i&lt;j 
which is even.
Denition 5.13. A root with respect to a certain positive inner product is a shortest (with respect 
to this inner product), nonzero vector in Zn . 
So for the inner product B, a root is a nonzero vector x  Zn such that 
B(x,x)=2. 
Remark 5.14. There can be only nitely many roots, since all of them have to lie in some ball. 
Denition 5.15. We call vectors of the form 
ith 
i = (0,..., 1 ,..., 0) 
simple roots. 
The i naturally form a basis of the lattice Zn . 
Lemma 5.16. Let  be a root,  = n kii. Then either ki  0 for all i or ki  0 for all i.i=1 
Proof. Assume the contrary, i.e., ki &gt; 0, kj &lt; 0. Without loss of generalit y, we can also assume 
that ks = 0 for all s between i and j. We can identify the indices i,j with vertices of the graph . 
 i 
  
i   j  

87</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>The most important properties of tensor products are summarized in the following problem. 
Problem 1.49. (a) Let U be any k-vector space. Construct a natural bijection between bilinear 
maps V  W  U and linear maps V  W  U. 
(b) Show that if {vi} is a basis of V and {wj } is a basis of W then {vi  wj } is a basis of 
V  W . 
(c) Construct a natural isomorphism V   W  Hom(V,W ) in the case when V is nite 
dimensional (natur al means that the isomorphism is dened without choosing bases). 
(d) Let V be a vector space over a eld k. Let SnV be the quotient of V n (n-fold tensor product 
of V ) by the subspace spanned by the tensors T  s(T ) where T  V n, and s is some transposition. 
Also let nV be the quotient of V n by the subspace spanned by the tensors T such that s(T )= T 
for some transposition s. These spaces are called the n-th symmetric, respectively exterior, power 
of V . If {vi} is a basis of V , can you construct a basis of SnV, nV ? If dimV = m, what are their 
dimensions? 
(e) If k has characteristic zero, nd a natural identic ation of SnV with the space of T  V n 
such that T = sT for all transpositions s, and of nV with the space of T  V n such that T = sT 
for all transpositions s. 
(f) Let A : V  W be a linear operator. Then we have an operator An : V n  W n, and 
its symmetric and exterior powers SnA : SnV  SnW , nA : nV nW which are dened in 
an obvious way. Suppose V = W and has dimension N, and assume that the eigenvalues of A are 
1,...,N . Find Tr(SnA),Tr(nA). 
(g) Show that N A = det(A)Id , and use this equality to give a one-line proof of the fact that 
det(AB ) = det(A) det(B). 
Remark. Note that a similar denition to the above can be used to dene the tensor product 
V A W , where A is any ring, V is a right A-module, and W is a left A-module. Namely , V A W 
is the abelian group which is the quotien t of the group VW freely generated by formal symbols  
v  w, v  V , w  W , modulo the relations 
(v1 + v2)  w  v1  w  v2  w,v  (w1 + w2)  v  w1  v  w2,va  w  v  aw,a  A. 
Exercise. Throughout this exercise, we let k be an arbitrary eld (not necessarily of charac
teristic zero, and not necessarily algebraically closed). 
If A and B are two k-algebras, then an (A,B)-bimo dule will mean a k-vector space V with 
both a left A-module structure and a right B-module structure which satisfy (av) b = a (vb) for 
any v  V , a  A and b  B. Note that both the notions of left A-module and right A-
module are particular cases of the notion of bimodules; namely , a left A-module is the same as an 
(A,k)-bimo dule, and a right A-module is the same as a (k,A)-bimo dule. 
Let B be a k-algebra, W a left B-module and V a right B-module. We denote by V B W the 
k-vector space (V k W ) / vb  w  v  bw | v  V, w  W, b  B. We denote the projection of 
a pure tensor v  w (with v  V and w  W ) onto the space V B W by v B w. (Note that this 
tensor product V B W is the one dened in the Remark after Problem1.49.) 
If, additionally , A is another k-algebra, and if the right B-module structure on V is part of an 
(A,B)-bimo dule structure, then V B W becomes a left A-module by a (v B w)= av B w for 
any a  A, v  V and w  W . 
18</text>
        </slide>
        <slide>
          <slideno>75</slideno>
          <text>Proof. Proof that (ii) implies (i). Assume that g  G does not belong to any of the subgroups 
H  X. Then, since X is conjugation invariant, it cannot be conjugated into such a subgroup. 
Hence by the Mackey formula, IndG (V )(g) = 0 for all H  X and V . So by (ii), for any irreducible 
H 
represen tation W of G, W (g) = 0. But irreducible characters span the space of class functions, so 
any class function vanishes on g, which is a contradiction. 
Proof that (i) implies (ii). Let U be a virtual represen tation of G over C (i.e., a linear combina
tion of irreducible represen tations with nonzero integer coecien ts) such that (U ,IndG V ) = 0 for 
H 
all H,V . So by Frobenius recipro city, (U|H ,V ) = 0. This means that U vanishes on H for any 
H  X. Hence by (i), U is identically zero. This implies (ii) (because of the above remark). 
Corollary 4.74. Any irreducible character of a nite group is a rational linear combination of 
induced characters from its cyclic subgroups. 
4.26 Represen tations of semidirect products 
Let G,A be groups and  : G  Aut(A) be a homomorphism. For a  A, denote (g)a by g(a). 
The semidirect product G  A is dened to be the product A  G with multiplication law 
(a1,g1)(a2,g2)=(a1g1(a2),g1g2). 
Clearly , G and A are subgroups of G  A in a natural way. 
We would like to study irreducible complex represen tations of G  A. For simplicit y, let us do 
it when A is abelian. 
In this case, irreducible represen tations of A are 1-dimensional and form the character group 
A, which carries an action of G. Let O be an orbit of this action, x  O a chosen elemen t, 
and Gx the stabilizer of x in G. Let U be an irreducible represen tation of Gx. Then we dene a 
represen tation V(O,U) of G  A as follows. 
As a represen tation of G, we set 
V(O,x,U) = IndG U = {f : G  U|f(hg)= hf(g),h  Gx}.Gx 
Next, we introduce an additional action of A on this space by (af)(g)= x(g(a))f(g). Then its 
easy to check that these two actions combine into an action of G  A. Also, it is clear that this 
represen tation does not really depend on the choice of x, in the following sense. Let x,y  O, 
and g  G be such that gx = y, and let g(U) be the represen tation of Gy obtained from the 
represen tation U of Gx by the action of g. Then V(O,x,U) is (naturally) isomorphic to V(O,y,g(U)). 
Thus we will denote V(O,x,U) by V(O,U) (remem bering, however, that x has been xed). 
Theorem 4.75. (i) The representations V(O,U) are irreducible. 
(ii) They are pairwise nonisomorphic. 
(iii) They form a complete set of irreducible representations of G  A. 
(iv) The character of V = V(O,U) is given by the Mackey-typ e formula 
V (a,g)= 1  
x(h(a)) U (hgh1). |Gx| 
hG:hgh1Gx 
76</text>
        </slide>
        <slide>
          <slideno>71</slideno>
          <text>the expression evaluates to
(g)1, 
since here 
aga1  B  a  B. 
If x 0 
g = 0 y , 
the expression evaluates to 
1(x)2(y)+ 1(y)2(x) 
1, 
since here 
aga1  B  a  B or a is an elemen t of B multiplied by the transp osition matrix. 
If x y 
g = ,x = yyx  
the expression on the right evaluates to 0 because matrices of this type dont have eigenvalues over 
Fq (and thus cannot be conjugated into B). From the denition, i(x)(i =1, 2) is a root of unity, 
so 
|G|V1 ,2 ,V1,2  =(q + 1)2(q  1) + (q 2  1)(q  1) 
2 2+ 2(q + q)(q  1)(q  2) +(q + q)  
1(x)2(y)1(y)2(x). 2 x=y
The last two summands come from the expansion 
|a + b| 2 = |a| 2 + |b| 2 + ab + ab. 
If 
1 = 2 = , 
the last term is equal to 
(q 2 + q)(q  2)(q  1), 
and the total in this case is 
(q + 1)(q  1)[(q + 1) + (q  1) + 2q(q  2)] = (q + 1)(q  1)2q(q  1) = 2|G|, 
so 
V1,2 ,V1,2  =2. 
Clearly , 
C  IndG 
B C,, 
since 
Hom G(C, IndG
BC,) = Hom B(C, C)= C (Theorem 4.33). 
Therefore, IndG is irreducible; and the character of W is dieren t for distinct BC, = C  W; W 
values of , proving that W are distinct. 
72</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>(b) A = k&lt;x1,...,xm &gt; (the grading is by length of words); 
(c) A is the exterior (=Grassmann) algebra k[x1,...,xm], generated over some eld k by 
x1,...,xm with the dening relations xixj + xj xi =0 and xi 2 =0 for all i,j (the grading is by 
degree). 
(d) A is the path algebra PQ of a quiver Q (the grading is dened by deg(pi)=0, deg(ah)=1). 
Hint. The closed answer is written in terms of the adjacency matrix MQ of Q. 
1.9 Lie algebras 
Let g be a vector space over a eld k, and let [ , ]: g  g  g be a skew-symmetric bilinear map. 
(That is, [a,a] = 0, and hence [a,b]= [b,a]). 
Denition 1.39. (g, [ , ]) is a Lie algebra if [ , ] satises the Jacobi identity 

[a,b] ,c 
+ 
[b,c] ,a 
+ 
[c,a] ,b 
=0.	 (2) 
Example 1.40. Some examples of Lie algebras are: 
1. Any space g with [ , ] = 0 (abelian Lie algebra). 
2. Any associative algebra A with [a,b]= ab  ba . 
3. Any subspace U of an associative algebra A such that [a,b]  U for all a,b  U. 
4. The space Der(A) of derivations of an algebra A, i.e. linear maps D : A  A which satisfy 
the Leibniz rule:
D(ab)= D(a)b + aD(b).
Remark 1.41. Derivations are important because they are the innitesimal version of automor
phisms (i.e., isomorphisms onto itself). For example, assume that g(t) is a dieren tiable family of 
automorphisms of a nite dimensional algebra A over R or C parametrized by t  (,) such that 
g(0) = Id. Then D := g(0) : A  A is a derivation (check it!). Conversely, if D : A  A is a 
derivation, then etD is a 1-parameter family of automorphisms (give a proof!). 
This provides a motivation for the notion of a Lie algebra. Namely , we see that Lie algebras 
arise as spaces of innitesimal automorphisms (=deriv ations) of associative algebras. In fact, they 
similarly arise as spaces of derivations of any kind of linear algebraic structures, such as Lie algebras, 
Hopf algebras, etc., and for this reason play a very important role in algebra. 
Here are a few more concrete examples of Lie algebras: 
1.	R3 with [u,v]= u  v, the cross-pro duct of u and v. 
2.	sl(n), the set of n  n matrices with trace 0.
For example, sl(2) has the basis
01	 00 10  
e =	 f = h = 0	0 10 0 1 
with relations
[h,e]=2e, [h,f]= 2f, [e,f]= h.
15</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>(ii) If V2 is irreducible,  is surjective. 
Thus, if both V1 and V2 are irreducible,  is an isomorphism. 
Proof. (i) The kernel K of  is a subrepresen tation of V1. Since  = 0, this subrepresen tation 
cannot be V1. So by irreducibilit y of V1 we have K = 0. 
(ii) The image I of  is a subrepresen tation of V2. Since  = 0, this subrepresen tation cannot 
be 0. So by irreducibilit y of V2 we have I = V2. 
Corollary 1.17. (Schurs lemma for algebraically closed elds) Let V be a nite dimensional 
irreducible representation of an algebra A over an algebraically closed eld k, and  : V  V is an 
intertwining operator. Then  =  Id for some   k (a scalar operator).  
Remark. Note that this Corollary is false over the eld of real numbers: it suces to take 
A = C (regarded as an R-algebra), and V = A. 
Proof. Let  be an eigenvalue of  (a root of the characteristic polynomial of ). It exists since k is 
an algebraically closed eld. Then the operator   Id is an intertwining operator V  V , which 
is not an isomorphism (since its determinan t is zero). Thus by Proposition 1.16 this operator is 
zero, hence the result. 
Corollary 1.18. Let A be a commutative algebra. Then every irreducible nite dimensional rep
resentation V of A is 1-dimensional. 
Remark. Note that a 1-dimensional represen tation of any algebra is automatically irreducible. 
Proof. Let V be irreducible. For any elemen t a  A, the operator (a): V  V is an intertwining 
operator. Indeed, 
(a)(b)v = (ab)v = (ba)v = (b)(a)v 
(the second equalit y is true since the algebra is comm utativ e). Thus, by Schurs lemma, (a) is 
a scalar operator for any a  A. Hence every subspace of V is a subrepresen tation. But V is 
irreducible, so 0 and V are the only subspaces of V . This means that dim V = 1 (since V = 0). 
Example 1.19. 1. A = k. Since represen tations of A are simply vector spaces, V = A is the only 
irreducible and the only indecomp osable represen tation. 
2. A = k[x]. Since this algebra is comm utativ e, the irreducible represen tations of A are its 
1-dimensional represen tations. As we discussed above, they are dened by a single operator (x). 
In the 1-dimensional case, this is just a number from k. So all the irreducible represen tations of A 
are V = k,   k, in which the action of A dened by (x)= . Clearly , these represen tations are 
pairwise non-isomorphic. 
The classication of indecomp osable represen tations of k[x] is more interesting. To obtain it, 
recall that any linear operator on a nite dimensional vector space V can be brough t to Jordan 
normal form. More specically , recall that the Jordan block J,n is the operator on kn which in 
the standard basis is given by the formulas J,nei = ei + ei1 for i&gt; 1, and J,ne1 = e1. Then 
for any linear operator B : V  V there exists a basis of V such that the matrix of B in this basis 
is a direct sum of Jordan blocks. This implies that all the indecomp osable represen tations of A are 
V,n = kn ,   k, with (x)= J,n. The fact that these represen tations are indecomp osable and 
pairwise non-isomorphic follows from the Jordan normal form theorem (which in particular says 
that the Jordan normal form of an operator is unique up to permutation of blocks). 
9</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>If V,W are represen tations of G, then V  W is also a represen tation, via 
V W (g)= V (g)  W (g). 
Therefore, V W (g)= V (g)W (g). 
An interesting problem discussed below is to decomp ose V  W (for irreducible V,W ) into the 
direct sum of irreducible represen tations. 
3.5 Orthogonalit y of characters 
We dene a positive denite Hermitian inner product on Fc(G, C) (the space of central functions) 
by 
(f1,f2)= 1  
f1(g)f2(g). |G| gG 
The following theorem says that characters of irreducible represen tations of G form an orthonormal 
basis of Fc(G, C) under this inner product. 
Theorem 3.8. For any representations V,W 
(V ,W ) = dim Hom G(W,V ), 
and  1, if V = W, (V ,W )= 0, if V  W 
if V,W are irreducible. 
Proof. By the denition 
(V ,W )= 1  
V (g)W (g)= 1  
V (g)W  (g) |G| gG |G| gG 
=1  
V W  (g) = Tr V W  (P ), |G| gG |
1where P = |G|  
gG g  Z(C[G]). (Here Z(C[G]) denotes the center of C[G]). If X is an irreducible 
represen tation of G then  Id, if X = C,P X =|0,X = C. 
Therefore, for any represen tation X the operator P X is the G-invariant projector onto the subspace |
XG of G-invariants in X. Thus, 
Tr |V W  (P )	= dim Hom G(C,V  W ) 
= dim(V  W )G = dim Hom G(W,V ). 
37</text>
        </slide>
        <slide>
          <slideno>101</slideno>
          <text>Lemma 6.9. (The Yoneda Lemma) If a functor F is represented by an object X, then X is unique 
up to a unique isomorphism. I.e., if X,Y are two objects in C, then for any isomorphism of functors 
 : Hom(X, ?)  Hom(Y, ?) there is a unique isomorphism a : X  Y inducing . 
Proof. (Sketch) One sets a = 
Y 1(1Y ), and shows that it is invertible by constructing the inverse, 
which is a
 1 = X (1X ). It remains to show that the composition both ways is the identity, which 
we will omit here. This establishes the existence of a. Its uniqueness is veried in a straigh tforward 
manner. 
Remark. In a similar way, if a category C is enriched over another category D (say, the category 
of abelian groups or vector spaces), one can dene the notion of a represen table functor from C to 
D. 
Example 6.10. Let A be an algebra. Then the forgetful functor to vector spaces on the category 
of left A-modules is represen table, and the represen ting object is the free rank 1 module (=the 
regular represen tation) M = A. But if A is innite dimensional, and we restrict attention to the 
category of nite dimensional modules, then the forgetful functor, in general, is not represen table 
(this is so, for example, if A is the algebra of complex functions on Z which are zero at all points 
but nitely many). 
6.6 Adjoin t functors 
Another fundamen tal notion in category theory is the notion of adjoin t functors. 
Denition 6.11. Functors F : CD and G : DC are said to be a pair of adjoin t functors if for 
any X C, Y D we are given an isomorphism XY : Hom C (F (X),Y )  Hom D(X,G(Y )) which is 
functorial in X and Y ; in other words, if we are given an isomorphism of functors Hom(F (?), ?) 
Hom(?,G(?)) (CD  Sets). In this situation, we say that F is left adjoin t to G and G is right 
adjoin t to F . 
Not every functor has a left or right adjoin t, but if it does, it is unique and can be constructed 
canonically (i.e., if we someho w found two such functors, then there is a canonical isomorphism 
between them). This follows easily from the Yoneda lemma, as if F,G are a pair of adjoin t functors 
then F (X) represen ts the functor Y  Hom(X,G(Y )), and G(Y ) represen ts the functor X 
Hom(F (X),Y ). 
Remark 6.12. The terminology left and right adjoin t functors is motivated by the analogy 
between categories and inner product spaces. More specically , we have the following useful dic
tionary between category theory and linear algebra, which helps understand better many notions 
of category theory . 
102</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>3 Represen tations of nite groups: basic results 
Recall that a represen tation of a group G over a eld k is a k-vector space V together with a 
group homomorphism  : G  GL(V ). As we have explained above, a represen tation of a group G 
over k is the same thing as a represen tation of its group algebra k[G]. 
In this section, we begin a systematic developmen t of represen tation theory of nite groups. 
3.1 Maschkes Theorem 
Theorem 3.1. (Maschke) Let G be a nite group and k a eld whose characteristic does not divide 
|G|. Then: 
(i) The algebra k[G] is semisimple. 
(ii) There is an isomorphism of algebras  : k[G] iEndVi dened by g  ig|, where Vi Vi 
are the irreducible representations of G. In particular, this is an isomorphism of representations 
of G (where G acts on both sides by left multiplic ation). Hence, the regular representation k[G] 
decomposes into irreducibles as i dim(Vi)Vi, and one has 
G=  
dim(Vi)2 . || 
i 
(the sum of squares formula). 
Proof. By Proposition 2.16, (i) implies (ii), and to prove (i), it is sucien t to show that if V is 
a nite-dimensional represen tation of G and WV is any subrepresen tation, then there exists a 
subrepresen tation W  V such that V = W  W  as represen tations.  
Choose any complemen t Wof W in V . (Thus V = W  Was vector spaces, but not necessarily 
as representations.) Let P be the projection along Wonto W , i.e., the operator on V dened by 
P |W = Id and P |W= 0. Let 
1 P :=  
(g)P(g1), |G| gG 
where (g) is the action of g on V , and let 
W  = ker P. 
2 Now P |W = Id and P (V )  W , so P = P , so P is a projection along W . Thus, V = W  W  as 
vector spaces. 
Moreo ver, for any h  G and any y  W , 
P(h)y =1  
(g)P(g1h)y =1  
(h)P(1)y = (h)Py =0, |G| gG |G| G 
so (h)y  ker P = W . Thus, W  is invariant under the action of G and is therefore a subrepre
sentation of V . Thus, V = W  W  is the desired decomp osition into subrepresen tations. 
The converse to Theorem 3.1(i) also holds. 
Proposition 3.2. If k[G] is semisimple, then the characteristic of k does not divide G.||
33</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2.6 Characters ofrepresen tations ............................... 27
2.7 TheJordan-H older theorem ................................ 28
2.8 TheKrull-Sc hmidt theorem ................................ 29
2.9 Problems .......................................... 30
2.10Represen tations oftensor products ............................ 31
3 Represen tations of nite groups: basic results	 33
3.1 MaschkesTheorem ..................................... 33
3.2 Characters .......................................... 34
3.3 Examples .......................................... 35
3.4	Duals andtensor products ofrepresen tations . . . . . . . . . . . . . . . . . . . . . . 36
3.5	Orthogonalit yofcharacters ................................ 37
3.6	Unitary represen tations. Another proof of Maschkes theorem for complex represen
tations ............................................ 38
3.7	Orthogonalit yofmatrix elemen ts ............................. 39
3.8	Character tables, examples ................................ 40
3.9	Computing tensor product multiplicities using character tables . . . . . . . . . . . . 42
3.10	Problems .......................................... 43
4 Represen tations of nite groups: further results	 47
4.1 Frobenius-Sc hurindicator ................................. 47
4.2 Frobenius determinan t ................................... 48
4.3 Algebraic numbersandalgebraic integers ........................ 49
4.4 Frobenius divisibilit y .................................... 51
4.5 Burnsides Theorem .................................... 52
4.6 Represen tations ofproducts ................................ 54
4.7 Virtual represen tations ................................... 54
4.8 Induced Represen tations .................................. 54
4.9 TheMackeyformula .................................... 55
4.10Frobenius recipro city .................................... 56
4.11Examples .......................................... 57
4.12 Represen tations of Sn ................................... 58
4.13ProofofTheorem 4.36 ................................... 59
4.14 Induced represen tations for Sn .............................. 60
2</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Hint. Show that xp and yp are central elements. 
(c) Find all irreducible nite dimensional representations of A. 
Hint. Let V be an irreducible nite dimensional representation of A, and v be an eigenve ctor 
of y in V . Show that {v,xv,x2v,...,xp1v} is a basis of V . 
Problem 1.27. Let q be a nonzer o complex number, and A be the q-Weyl algebra over C generated 
by x1 and y1 with dening relations xx1 = x1x =1,yy1 = y1y =1, and xy = qyx. 
(a) What is the center of A for dierent q? If q is not a root of unity, what are the two-side d 
ideals in A? 
(b) For which q does this algebra have nite dimensional representations?
Hint. Use determinants.
(c) Find all nite dimensional irreducible representations of A for such q.
Hint. This is similar to part (c) of the previous problem.
1.8 Quivers 
Denition 1.28. A quiver Q is a directed graph, possibly with self-lo ops and/or multiple edges 
between two vertices. 
Example 1.29. 
 
We denote the set of vertices of the quiver Q as I, and the set of edges as E. For an edge h  E, 
let h, h denote the source and target of h, respectively: 
h h h 
Denition 1.30. A represen tation of a quiver Q is an assignmen t to each vertex i  I of a vector 
space Vi and to each edge h  E of a linear map xh : Vh  Vh . 
It turns out that the theory of represen tations of quivers is a part of the theory of represen tations 
of algebras in the sense that for each quiver Q, there exists a certain algebra PQ, called the path 
algebra of Q, such that a represen tation of the quiver Q is the same as a represen tation of the 
algebra PQ. We shall rst dene the path algebra of a quiver and then justify our claim that 
represen tations of these two objects are the same. 
Denition 1.31. The path algebra PQ of a quiver Q is the algebra whose basis is formed by 
oriented paths in Q, including the trivial paths pi, i  I, corresp onding to the vertices of Q, and 
multiplication is concatenation of paths: ab is the path obtained by rst tracing b and then a. If 
two paths cannot be concatenated, the product is dened to be zero. 
Remark 1.32. It is easy to see that for a nite quiver  pi = 1, so PQ is an algebra with unit. 
iI 
Problem 1.33. Show that the algebra PQ is generated by pi for i  I and ah for h  E with the 
dening relations: 
13</text>
        </slide>
        <slide>
          <slideno>49</slideno>
          <text>000 ... 0 an  
100 ... 0 an1
010 ... 0  an2. . 
.  .  
000 ... 1 a1 
Since z is a root of the characteristic polynomial of this matrix, it is an eigenvalue of this matrix. 
The set of algebraic numbers is denoted by Q, and the set of algebraic integers by A. 
Proposition 4.12. (i) A is a ring. 
(ii) Q is a eld. Namely, it is an algebraic closure of the eld of rational numbers. 
Proof. We will be using denition (4.10). Let  be an eigenvalue of 
A Matn(C) 
with eigenvector v, let  be an eigenvalue of 
B Matm(C) 
with eigenvector w. Then    is an eigenvalue of 
A Idm  Idn B, 
and  is an eigenvalue of 
AB. 
The corresp onding eigenvector is in both cases v  w. This shows that both A and Q are rings. 
To show that the latter is a eld, it suces to note that if  = 0 is a root of a polynomial p(x) of 
d
degree d, then 1 is a root of xp(1/x). The last statemen t is easy, since a number  is algebraic 
if and only if it denes a nite extension of Q. 
Proposition 4.13. A  Q = Z. 
Proof. We will be using denition (4.9). Let z be a root of 
n p(x)= x + a1x n1 + ... + an1x + an, 
and suppose 
z = p
q  Q, gcd(p,q)=1. 
Notice that the leading term of p(x) will have qn in the denominator, whereas all the other terms 
will have a lower power of q there. Thus, if q = 1, then p(z) /Z, a contradiction. Thus,  
z  A  Q  z  Z. The reverse inclusion follows because n  Z is a root of x  n. 
Every algebraic number  has a minimal polynomial p(x), which is the monic polynomial 
with rational coecien ts of the smallest degree such that p() = 0. Any other polynomial q(x) with 
rational coecien ts such that q() = 0 is divisible by p(x). Roots of p(x) are called the algebraic 
conjugates of ; they are roots of any polynomial q with rational coecien ts such that q() = 0. 
50</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>(a) Derive this classic ation. 
Hint. Let G be a nite subgroup of SO(3). Consider the action of G on the unit sphere. A 
point of the sphere preserved by some nontrivial element of G is called a pole. Show that every 
nontrivial element of G xes a unique pair of opposite poles, and that the subgroup of G xing a 
particular pole P is cyclic, of some order m (called the order of P). Thus the orbit of P has n/m 
elements, where n = G. Now let P1,...,Pk be the poles representing all the orbits of G on the set ||
of poles, and m1,...,mk be their orders. By counting nontrivial elements of G, show that 
2(1  1) = 
(1  1). n mii 
Then nd all possible mi and n that can satisfy this equation and classify the corresponding groups. 
(b) Using this classic ation, classify nite subgroups of SU(2) (use the homomorphism SU(2) 
SO(3)). 
Problem 3.25. Find the characters and tensor products of irreducible complex representations of 
the Heisenb erg group from Problem 3.18. 
Problem 3.26. Let G be a nite group, and V a complex representation of G which is faithful, 
i.e., the corresponding map G  GL(V ) is injective. Show that any irreducible representation of 
G occurs inside SnV (and hence inside V n) for some n. 
Hint. Show that there exists a vector u  V  whose stabilizer in G is 1. Now dene the map 
SV  Fun(G, C) sending a polynomial f on V  to the function fu on G given by fu(g)= f(gu). 
Show that this map is surjectiv e and use this to deduce the desired result. 
Problem 3.27. This problem is about an application of representation theory to physics (elasticity 
theory). We rst describ e the physical motivation and then state the mathematic al problem. 
Imagine a material which occupies a certain region U in the physical space V = R3 (a space 
with a positive denite inner product). Suppose the material is deforme d. This means, we have 
applied a dieomorphism (=change of coordinates) g : U  U . The question in elasticity theory 
is how much stress in the material this deformation will cause. 
For every point P  U, let AP : V  V be dened by AP = dg(P ). AP is nondegenerate, 
so it has a polar decomposition AP = DP OP , where OP is orthogonal and DP is symmetric. The 
matrix OP characterizes the rotation part of AP (which clearly produces no stress), and DP is 
the distortion part, which actually causes stress. If the deformation is small, DP is close to 1, so 
DP = 1+ dP , where dP is a small symmetric matrix, i.e., an element of S2V . This matrix is called 
the deformation tensor at P . 
Now we dene the stress tensor, which characterizes stress. Let v be a small nonzer o vector in 
V , and  a small disk perpendicular to v centered at P of area ||v||. Let Fv be the force with which 
the part of the material on the v-side of  acts on the part on the opposite side. It is easy to deduce 
from Newton s laws that Fv is linear in v, so there exists a linear operator SP : V  V such that 
Fv = SP v. It is called the stress tensor. 
An elasticity law is an equation SP = f(dP ), where f is a function. The simplest such law is a 
linear law (Hookes law): f : S2V  End(V ) is a linear function. In general, such a function is 
dened by 9 6=54 parameters, but we will show there are actually only two essential ones  the  
compression modulus K and the shearing modulus . For this purpose we will use representation 
theory. 
45</text>
        </slide>
        <slide>
          <slideno>68</slideno>
          <text>The goal of this section is to describ e the irreducible represen tations of G.
To begin, let us nd the conjugacy classes in GL2(Fq). 
Represen tatives 
Scalar  x 
0 x 0  
Parabolic  x 
0 x 1  
Hyperbolic  x 
0 y 0 
,y = x 
Elliptic  x y 
,x y yx  Fq, 
F
q ,  Fq \ F2 
q (characteris
tic polynomial over Fq is irre
ducible) Number of elemen ts in a conjugacy 
class 
1 (this is a central elemen t) 
q2  1 (elemen ts that comm ute with 
this one are of the form  
0 t u 
t 
,t = 
0) 
q2 + q (elemen ts that comm ute with 
this one are of the form  
0 t
u 0 
, t,u = 
0) 
q2  q (the reason will be describ ed 
below) Number of classes 
q 1 (one for every non
zero x) 
q 1 (one for every non
zero x) 
1 (q  1)(q  2) (x,y =0 2 
and x = y) 
1 q(q 1) (matrices with 2 
y and y are conjugate) 
More on the conjugacy class of elliptic matrices: these are the matrices whose characteristic 
polynomial is irreducible over Fq and which therefore dont have eigenvalues in Fq. Let A be such 
a matrix, and consider a quadratic extension of Fq, 
Fq(),  Fq \ F2 .q
Over this eld, A will have eigenvalues 
 = 1 + 2 
and 
 = 1 2, 
with corresp onding eigenvectors 
v, v (Av = v, Av = v). 
Choose a basis 
{e1 = v + v, e2 = (v  v)}. 
In this basis, the matrix A will have the form 
1 2 
2 1 , 
justifying the description of represen tative elemen ts of this conjugacy class. 
In the basis {v, v}, matrices that comm ute with A will have the form 
 0 
0 , 
for all 
  F
q2 , 
so the number of such matrices is q2  1. 
69</text>
        </slide>
        <slide>
          <slideno>77</slideno>
          <text>|
5 Quiver Represen tations 
5.1 Problems 
Problem 5.1. Field embeddings. Recall that k(y1,...,ym) denotes the eld of rational functions 
of y1,...,ym over a eld k. Let f : k[x1,...,xn]  k(y1,...,ym) be an injective k-algebr a homomor
phism. Show that m  n. (Look at the growth of dimensions of the spaces WN of polynomials of 
degree N in xi and their images under f as N ). Deduce that if f : k(x1,...,xn)  k(y1,...,ym) 
is a eld embedding, then m  n. 
Problem 5.2. Some algebraic geometry . 
Let k be an algebraically closed eld, and G = GLn(k). Let V be a polynomial representation 
of G. Show that if G has nitely many orbits on V then dim(V )  n2 . Namely: 
(a) Let x1,...,xN be linear coordinates on V . Let us say that a subset X of V is Zariski dense 
if any polynomial f(x1,...,xN ) which vanishes on X is zero (coecientwise). Show that if G has 
nitely many orbits on V then G has at least one Zariski dense orbit on V . 
(b) Use (a) to construct a eld embedding k(x1,...,xN )  k(gpq), then use Problem 5.1. 
(c) generalize the result of this problem to the case when G = GLn1 (k)  ...  GLnm (k). 
Problem 5.3. Dynkin diagrams. 
Let  be a graph, i.e., a nite set of points (vertic es) connected with a certain number of edges 
(we allow multiple edges). We assume that  is connected (any vertex can be connected to any 
other by a path of edges) and has no self-loops (edges from a vertex to itself). Suppose the vertices 
of  are labeled by integers 1,...,N. Then one can assign to  an N  N matrix R =(rij ), where 
rij is the number of edges connecting vertices i and j. This matrix is obviously symmetric, and is 
called the adjacency matrix. Dene the matrix A =2I  R, where I is the identity matrix. 
Main denition:  is said to be a Dynkin diagram if the quadratic from on RN with matrix 
A is positive denite. 
Dynkin diagrams appear in many areas of mathematics (singularity theory, Lie algebras, rep
resentation theory, algebraic geometry, mathematic al physics, etc.) In this problem you will get a 
complete classic ation of Dynkin diagrams. Namely, you will prove 
Theorem.  is a Dynkin diagram if and only if it is one on the following graphs: 
 An :    
  
 Dn: |
 E6 : 
78</text>
        </slide>
        <slide>
          <slideno>104</slideno>
          <text>Denition 6.21. An abelian category C is semisimple if any short exact sequence in this category 
splits, i.e., is isomorphic to a sequence 
0  X  X  Y  Y  0 
(where the maps are obvious). 
Example 6.22. The category of represen tations of a nite group G over a eld of characteristic 
not dividing G(or 0) is semisimple. || 
Note that in a semisimple category , any additiv e functor is automatically exact on both sides. 
Example 6.23. (i) The functors IndG
K are exact. K , ResG 
(ii) The functor Hom(X, ?) is left exact, but not necessarily right exact. To see that it need not 
be right exact, it suces to consider the exact sequence 
0  Z  Z  Z/2Z  0, 
and apply the functor Hom(Z/2Z, ?). 
(iii) The functor XA for a right A-module X (on the category of left A-modules) is right exact, 
but not necessarily left exact. To see this, it suces to tensor multiply the above exact sequence 
by Z/2Z. 
Exercise. Show that if (F,G) is a pair of adjoin t additiv e functors between abelian categories, 
then F is right exact and G is left exact. 
Exercise. (a) Let Q be a quiver and i  Q a source. Let V be a represen tation of Q, and W a 
represen tation of Qi (the quiver obtained from Q by reversing arrows at the vertex i). Prove that 
there is a natural isomorphism between Hom 
FiV,W  
and Hom 
V,FW 
. +In other words, the
i 
functor F
+is right adjoin t to Fi
i .
(b) Deduce that the functor F
+is left exact, and Fi is right exact.
i 
105</text>
        </slide>
        <slide>
          <slideno>95</slideno>
          <text>These two corollaries show that there are only nitely many indecomp osable represen tations 
(since there are only nitely many roots) and that the dimension vector of each of them is a positive 
root. The last statemen t of Gabriels theorem follows from 
Corollary 5.37. For every positive root , there is an indecomposable representation V with 
d(V )= . 
Proof. Consider the sequence 
sn,sn1sn,... 
Consider the rst elemen t of this sequence which is a negativ e root (this has to happen by Lemma 
5.33) and look at one step before that, calling this elemen t . So  is a positive root and si is a 
negativ e root for some i. But since the si only change one coordinate, we get 
 = i 
and 
(sq ...sn1sn) = i. 
We let C(i) be the represen tation having dimension vector i. Then we dene 
V = FnF n
1 ...FqC(i). 
This is an indecomp osable represen tation and 
d(V )= . 
Example 5.38. Let us demonstrate by example how reection functors work. Consider the quiver 
D4 with the orientation of all arrows towards the node (which is labeled by 4). Start with the 
1-dimensional represen tation V4 sitting at the 4-th vertex. Apply to V4 the functor F3F2F1. 
This yields 
F1F2F3V4 = V1+2+3+4 . 
Now applying F4we get 
F4F1F2F3V4 = V1+2+3+24 . 
Note that this is exactly the inclusion of 3 lines into the plane, which is the most complicated 
indecomp osable represen tation of the D4 quiver. 
5.9 Problems 
Problem 5.39. Let Qn be the cyclic quiver of length n, i.e., n vertices connected by n oriente d edges 
forming a cycle. Obviously, the classic ation of indecomposable representations of Q1 is given by 
the Jordan normal form theorem. Obtain a similar classic ation of indecomposable representations 
of Q2. In other words, classify pairs of linear operators A : V  W and B : W  V up to 
isomorphism. Namely: 
(a) Consider the following pairs (for n  1): 
1) En,: V = W = Cn , A is the Jordan block of size n with eigenvalue , B =1 (  C). 
2) En,: is obtaine d from En,0 by exchanging V with W and A with B. 
96</text>
        </slide>
        <slide>
          <slideno>81</slideno>
          <text>Then a represen tation of this quiver looks like 
A B VW .
Y 
Like in Example 5.8 we rst split away 
0 0 
0 0 ker A  .
This object is a multiple of 1 0 0 . Next, let Y  be a complemen t of ImB in Y . 
Then we can also split away 
0 0 0 0 Y 
which is a multiple of the object 0 0 1 . This results in a situation where the map 
A is injectiv e and the map B is surjectiv e (we rename the spaces to simplify notation): 
 A B 
V Y .
 W
Next, let X = ker(B  A) and let X be a complemen t of X in V . Let W  be a complemen t 
of A(X) in W such that A(X)W . Then we get
 
 A B A B  A B =
To simplify notation, we redene 
V = X,W = W . 0 VWYX YW 
   Therstofthesesummands isamultiple of1 1 0. Looking atthesecond summand, 
wenowhaveasituation where A isinjectiv e, B issurjectiv eandfurthermore ker(BA)=0.  
Next let X Im(BA)andlet Xbe complemen tof X in Y Furthermore, let  we = a . 
1    WB(X).Then W isacomplemen tof A(V )in W Thisyields thedecomp osition = . 
 A B A B B 
V WYV X 0 WX
A(X)
 X
=   
A(V )
Here, the rst summand is a multiple of 1  1  1 . By splitting away the kernel of B, 
the second summand can be decomp osed into multiples of 0 1  1 and 0 1 0 . 
So, on the whole, this quiver has six indecomp osable represen tations: 
1 0 0 , 0 0 1 , 1  1 0 , 
1  1  1 , 0 1  1 , 0 1 0 
2. Now we look at the orientation 
.

 
 
  Very similarly to the other orientation, we can split away objects of the type 
1 00 , 0 01 
which results in a situation where both A and B are injectiv e: 
 A B  
VW Y .
82</text>
        </slide>
        <slide>
          <slideno>88</slideno>
          <text>on ZN restricts to the inner product B given by  on L, since it takes the same values on the 
basis vectors: 
(i,i)=2 
i,j adjacen t  1 (i,j )= 0 otherwise 
This means that vectors of the form 
(0,..., 0, 1, 0,..., 0, 1, 0,..., 0) = i + i+1 ++ j1  
and 
(0,..., 0, 1, 0,..., 0, 1, 0,..., 0) = (i + i+1 ++ j1)  
are the roots of L. Therefore the number of positive roots in L equals 
N(N  1) . 2 
2. As a fact we also state the number of positive roots in the other Dynkin diagrams: 
DN 
E6 N(N  1) 
36 roots 
E7 63 roots 
E8 120 roots 
Denition 5.20. Let   Zn be a positive root. The reection s is dened by the formula 
s(v)= v  B(v,). 
We denote si by si and call these simple reections. 
Remark 5.21. As a linear operator of Rn , s xes any vector orthogonal to  and 
s()=  
Therefore s is the reection at the hyperplane orthogonal to , and in particular xes B. The 
si generate a subgroup W  O(Rn), which is called the Weyl group of . Since for every w  W , 
w(i) is a root, and since there are only nitely many roots, W has to be nite. 
5.5 Gabriels theorem 
Denition 5.22. Let Q be a quiver with any labeling 1,...,n of the vertices. Let V =(V1,...,Vn) 
be a represen tation of Q. We then call 
d(V ) = (dim V1,..., dim Vn) 
the dimension vector of this represen tation. 
We are now able to formulate Gabriels theorem using roots. 
Theorem 5.23 (Gabriels theorem). Let Q be a quiver of type An,Dn,E6,E7,E8. Then Q has 
nitely many indecomposable representations. Namely, the dimension vector of any indecomposable 
representation is a positive root (with respect to B) and for any positive root  there is exactly 
one indecomposable representation with dimension vector . 
89</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>This example shows that an indecomp osable represen tation of an algebra need not be irreducible. 
3. The group algebra A = k[G], where G is a group. A represen tation of A is the same thing as 
a represen tation of G, i.e., a vector space V together with a group homomorphism  : G  Aut(V ), 
whre Aut(V )= GL(V ) denotes the group of invertible linear maps from the space V to itself. 
Problem 1.20. Let V be a nonzer o nite dimensional representation of an algebra A. Show that 
it has an irreducible subrepresentation. Then show by example that this does not always hold for 
innite dimensional representations. 
Problem 1.21. Let A be an algebra over a eld k. The center Z(A) of A is the set of all elements 
z  A which commute with all elements of A. For example, if A is commutative then Z(A)= A. 
(a) Show that if V is an irreducible nite dimensional representation of A then any element 
z  Z(A) acts in V by multiplic ation by some scalar V (z). Show that V : Z(A)  k is a 
homomorphism. It is called the central character of V . 
(b) Show that if V is an indecomposable nite dimensional representation of A then for any 
z  Z(A), the operator (z) by which z acts in V has only one eigenvalue V (z), equal to the 
scalar by which z acts on some irreducible subrepresentation of V . Thus V : Z(A)  k is a 
homomorphism, which is again called the central character of V . 
(c) Does (z) in (b) have to be a scalar operator? 
Problem 1.22. Let A be an associative algebra, and V a representation of A. By End A(V ) one 
denotes the algebra of all homomorphisms of representations V  V . Show that End A(A)= Aop, 
the algebra A with opposite multiplic ation. 
Problem 1.23. Prove the following Innite dimensional Schurs lemma (due to Dixmier): Let 
A be an algebra over C and V be an irreducible representation of A with at most countable basis. 
Then any homomorphism of representations  : V  V is a scalar operator. 
Hint. By the usual Schurs lemma, the algebra D := EndA(V ) is an algebra with division. 
Show that D is at most countably dimensional. Suppose  is not a scalar, and consider the subeld 
C() D. Show that C() is a transcendental extension of C. Derive from this that C() is 
uncountably dimensional and obtain a contradiction. 
1.4 Ideals 
A left ideal of an algebra A is a subspace I  A such that aI  I for all a  A. Similarly , a right 
ideal of an algebra A is a subspace I  A such that Ia  I for all a  A.A two-side d ideal is a 
subspace that is both a left and a right ideal. 
Left ideals are the same as subrepresen tations of the regular represen tation A. Right ideals are 
the same as subrepresen tations of the regular represen tation of the opposite algebra Aop. 
Below are some examples of ideals: 
	If A is any algebra, 0 and A are two-sided ideals. An algebra A is called simple if 0 and A 
are its only two-sided ideals. 
	If  : A  B is a homomorphism of algebras, then ker  is a two-sided ideal of A. 
	If S is any subset of an algebra A, then the two-sided ideal generated by S is denoted S and 
is the span of elemen ts of the form asb, where a,b  A and s  S. Similarly we can dene 
S = span{as} and Sr = span{sb}, the left, respectively right, ideal generated by S. 
10</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>2 General results of represen tation theory 
2.1 Subrepresen tations in semisimple represen tations 
Let A be an algebra. 
Denition 2.1. A semisimple (or completely reducible) represen tation of A is a direct sum of 
irreducible represen tations. 
Example. Let V be an irreducible represen tation of A of dimension n. Then Y = End(V ), 
with action of A by left multiplication, is a semisimple represen tation of A, isomorphic to nV (the 
direct sum of n copies of V ). Indeed, any basis v1,...,vn of V gives rise to an isomorphism of 
represen tations End(V )  nV , given by x  (xv1,...,xvn). 
Remark. Note that by Schurs lemma, any semisimple represen tation V of A is canonically 
identied with X Hom A(X,V )X, where X runs over all irreducible represen tations of A. Indeed, 
we have a natural map f : X Hom(X,V )X  V , given by g x  g(x), x  X, g  Hom(X,V ), 
and it is easy to verify that this map is an isomorphism. 
Well see now how Schurs lemma allows us to classify subrepresen tations in nite dimensional 
semisimple represen tations. 
Proposition 2.2. Let Vi, 1  i  m be irreducible nite dimensional pairwise nonisomorphic 
mrepresentations of A, and W be a subrepresentation of V = i=1niVi. Then W is isomorphic to 
m 
i=1riVi, ri  ni, and the inclusion  : W  V is a direct sum of inclusions i : riVi  niVi given 
by multiplic ation of a row vector of elements of Vi (of length ri) by a certain ri-by-n i matrix Xi 
with linearly independent rows: (v1,...,vri )=(v1,...,vri )Xi. 
Proof. The proof is by induction in n := m
i=1 ni. The base of induction (n = 1) is clear. To perform 
the induction step, let us assume that W is nonzero, and x an irreducible subrepresen tation 
PW . Such P exists (Problem 1.20). 2 Now, by Schurs lemma, P is isomorphic to Vi for some i, 
and the inclusion |P : P  V factors through niVi, and upon identication of P with Vi is given 
by the formula v  (vq1,...,vqni ), where ql  k are not all zero. 
Now note that the group Gi = GLni (k) of invertible ni-by-ni matrices over k acts on niVi 
by (v1,...,vni )  (v1,...,vni )gi (and by the identity on njVj , j = i), and therefore acts on the 
set of subrepresen tations of V , preserving the property we need to establish: namely , under the 
action of gi, the matrix Xi goes to Xigi, while Xj ,j = i dont change. Take gi  Gi such that 
(q1,...,qni )gi = (1, 0,..., 0). Then Wgi contains the rst summand Vi of niVi (namely , it is Pgi), 
hence Wgi = Vi  W , where W  n1V1  ...  (ni  1)Vi  ...  nmVm is the kernel of the projection 
of Wgi to the rst summand Vi along the other summands. Thus the required statemen t follows 
from the induction assumption. 
Remark 2.3. In Proposition 2.2, it is not important that k is algebraically closed, nor it matters 
that V is nite dimensional. If these assumptions are dropp ed, the only change needed is that the 
entries of the matrix Xi are no longer in k but in Di = EndA(Vi), which is, as we know, a division 
algebra. The proof of this generalized version of Proposition 2.2 is the same as before (check it!). 
Another proof of the existence of P , which does not use the nite dimensionalit y of V , is by induction in n. 
Namely , if W itself is not irreducible, let K be the kernel of the projection of W to the rst summand V1. Then 
K is a subrepresen tation of (n1  1)V1  ...  nmVm, which is nonzero since W is not irreducible, so K contains an 
irreducible subrepresen tation by the induction assumption. 
23 2</text>
        </slide>
        <slide>
          <slideno>89</slideno>
          <text>:


 5.6 Reection Functors 
Denition 5.24. Let Q be any quiver. We call a vertex i  Q a sink if all edges connected to i 
point towards i. 
i 
We call a vertex i  Q a source if all edges connected to i point away from i. 
i  
Denition 5.25. Let Q be any quiver and i  Q be a sink (a source). Then we let Qi be the 
quiver obtained from Q by reversing all arrows pointing into (pointing out of) i. 
We are now able to dene the reection functors (also called Coxeter functors ). 
Denition 5.26. Let Q be a quiver, i  Q be a sink. Let V be a represen tation of Q. Then we 
dene the reection functor 
+F
: RepQ  RepQ i i 
by the rule 
F+(V )k = Vk if k = ii 


.
+F
(V )i = ker Vj  Vi i 
ji 
Also, all maps stay the same but those now pointing out of i; these are replaced by compositions 
of the inclusion of ker  into Vj with the projections Vj  Vk. 
Denition 5.27. Let Q be a quiver, i  Q be a source. Let V be a represen tation of Q. Let  be 
the canonical map 
 : Vi Vj . 
ij
Then we dene the reection functor 
Fi : RepQ  RepQ i 
by the rule 
Fi(V )k = Vk if k = i

/Im.
 Fi(V )i = Coker ()= Vj 
ij 
Again, all maps stay the same but those now pointing into i; these are replaced by the compositions 
of the inclusions Vk ijVj with the natural map Vj Vj/Im. 
Proposition 5.28. Let Q be a quiver, V an indecomposable representation of Q. 
90</text>
        </slide>
        <slide>
          <slideno>78</slideno>
          <text>|
 E7 : 

 E8 : |
(a) Compute the determinant of A where = AN ,DN . (Use the row decomposition rule, and 
write down a recursive equation for it). Deduce by Sylvester criterion7 that AN ,DN are Dynkin 
diagrams.8 
(b) Compute the determinants of A for E6,E7,E8 (use row decomposition and reduce to (a)). 
Show they are Dynkin diagrams. 
(c) Show that if  is a Dynkin diagram, it cannot have cycles. For this, show that det(A )=0 
for a graph  below 9 
1 1 1 1 
1 
(show that the sum of rows is 0). Thus  has to be a tree. 
(d) Show that if  is a Dynkin diagram, it cannot have vertices with 4 or more incoming edges, 
and that  can have no more than one vertex with 3 incoming edges. For this, show that det(A )=0 
for a graph  below: 
1 1 
2 2 
1 1 
(e) Show that det(A )=0 for all graphs  below: 
1 
2 
1 2 3 2 1
2
1 2 3 4 3 2 1 
7Recall the Sylvester criterion: a symmetric real matrix is positive denite if and only if all its upper left corner 
principal minors are positive. 
8The Sylvester criterion says that a symmetric bilinear form (, ) on RN is positive denite if and only if for any 
k  N, det1i,jk (ei,ej ) &gt; 0. 
9Please ignore the numerical labels; they will be relevant for Problem 5.5 below. 
79</text>
        </slide>
        <slide>
          <slideno>58</slideno>
          <text>For the partition  = (1,..., 1), Q = Sn, P = {1}, so c is the antisymmetrizer, and hence V is 
the sign represen tation. 
n = 3. For  = (2, 1), V = C2 . 
n = 4. For  = (2, 2), V = C2; for  = (3, 1), V = C3 ; for  = (2, 1, 1), V = C3 
 +. 
Corollary 4.38. All irreducible representations of Sn can be given by matric es with rational entries. 
Problem 4.39. Find the sum of dimensions of all irreducible representations of the symmetric 
group Sn. 
Hint. Show that all irreducible representations of Sn are real, i.e., admit a nondegenerate 
invariant symmetric form. Then use the Frobenius-Schur theorem. 
4.13 Proof of Theorem 4.36 
Lemma 4.40. Let x  C[Sn]. Then axb = (x)c, where  is a linear function. 
Proof. If g  PQ, then g has a unique represen tation as pq, p  P,q  Q, so agb =(1)qc. 
Thus, to prove the required statemen t, we need to show that if g is a permutation which is not in 
PQ then agb = 0. 
To show this, it is sucien t to nd a transp osition t such that t  P and g1tg  Q; then 
agb = atgb = ag(g1tg)b = agb, 
so agb = 0. In other words, we have to nd two elemen ts i,j standing in the same row in the 
tableau T = T, and in the same column in the tableau T  = gT (where gT is the tableau of the 
same shape as T obtained by permuting the entries of T by the permutation g). Thus, it suces to 
show that if such a pair does not exist, then g  PQ, i.e., there exists p  P, q  Q:= gQg1 
such that pT = qT  (so that g = pq1,q = g1qg  Q). 
Any two elemen ts in the rst row of T must be in dieren t columns of T , so there exists q1 Q
which moves all these elemen ts to the rst row. So there is p1  P such that p1T and q1T  have 
the same rst row. Now do the same procedure with the second row, nding elemen ts p2,q2such 
that p2p1T and q2q1T  have the same rst two rows. Continuing so, we will construct the desired 
elemen ts p,q. The lemma is proved. 
Let us introduce the lexicographic ordering on partitions: &gt; if the rst nonvanishing 
i  i is positive. 
Lemma 4.41. If &gt; then aC[Sn]b =0. 
Proof. Similarly to the previous lemma, it suces to show that for any g  Sn there exists a 
transp osition t  P such that g1tg  Q. Let T = T and T  = gT. We claim that there are 
two integers which are in the same row of T and the same column of T . Indeed, if 1 &gt;1, this is 
clear by the pigeonhole principle (already for the rst row). Otherwise, if 1 = 1, like in the proof 
of the previous lemma, we can nd elemen ts p1  P,q1 gQg1 such that p1T and q1T  have the 
same rst row, and repeat the argumen t for the second row, and so on. Eventually, having done 
i  1 such steps, well have i &gt;i, which means that some two elemen ts of the i-th row of the rst 
tableau are in the same column of the second tableau, completing the proof. 
59</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>Thus for g  G we have 
V (g 2)= S2V (g)  2V (g) 
Therefore, 

 

1, if V is of real type
2V )GG|1V ( 
g 2)= S2V (P )2V (P ) = dim(S2V )G dim( 1, if V is of quaternionic type 
0, |
 =
if V is of complex type
 gG 
Finally , the number of involutions in G equals
1
V|G| dim VV ( 
g 2)=  
dim V 
 dim V.
gG real V quat V 
Corollary 4.5. Assume that all representations of a nite group G are dened over real numbers 
(i.e., all complex representations of G are obtaine d by complexifying real representations). Then 
the sum of dimensions of irreducible representations of G equals the number of involutions in G. 
Exercise. Show that any nontrivial nite group of odd order has an irreducible represen tation 
which is not dened over R (i.e., not realizable by real matrices). 
4.2 Frobenius determinan t 
Enumerate the elemen ts of a nite group G as follows: g1,g2,...,gn. Introduce n variables indexed 
with the elemen ts of G : 
xg1 ,xg2 ,...,xgn . 
Denition 4.6. Consider the matrix XG with entries aij = xgigj . The determinan t of XG is some 
polynomial of degree n of xg1 ,xg2 ,...,xgn that is called the Frobenius determinant. 
The following theorem, discovered by Dedekind and proved by Frobenius, became the starting 
point for creation of represen tation theory (see [Cu]). 
Theorem 4.7. r
Pj (x)deg Pjdet XG = 
j=1 
for some pairwise non-pr oportional irreducible polynomials Pj (x), where r is the number of conju
gacy classes of G. 
We will need the following simple lemma. 
Lemma 4.8. Let Y be an n  n matrix with entries yij. Then det Y is an irreducible polynomial 
of {yij }. 
Proof. Let Y = tId+
in 
=1 xiEi,i+1, where i+1 is computed modulo n, and Ei,j are the elemen tary 
matrices. Then det(Y )= tn  (1)nx1...xn, which is obviously irreducible. Hence det(Y ) is 
irreducible (since factors of a homogeneous polynomial are homogeneous). 
Now we are ready to proceed to the proof of Theorem 4.7. 
48</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>1. p2 
i = pi, pipj =0 for i = j 
2. ahph = ah, ahpj =0 for j = h 
3. ph ah = ah, piah =0 for i = h 
We now justify our statemen t that a represen tation of a quiver is the same thing as a represen
tation of the path algebra of a quiver. 
Let V be a represen tation of the path algebra PQ. From this represen tation, we can construct a 
represen tation of Q as follows: let Vi = piV, and for any edge h, let xh = ah|ph V : ph V  ph V 
be the operator corresp onding to the one-edge path h. 
Similarly , let (Vi,xh) be a represen tation of a quiver Q. From this represen tation, we can 
construct a represen tation of the path algebra PQ: let V = 
i Vi, let pi : V  Vi  V be the 
projection onto Vi, and for any path p = h1...hm let ap = xh1 ...xhm : Vh  Vh be the composition m 1 of the operators corresp onding to the edges occurring in p (and the action of this operator on the 
other Vi is zero). 
It is clear that the above assignmen ts V  (piV) and (Vi)  Vi are inverses of each other. i 
Thus, we have a bijection between isomorphism classes of represen tations of the algebra PQ and of 
the quiver Q. 
Remark 1.34. In practice, it is generally easier to consider a represen tation of a quiver as in 
Denition 1.30. 
We lastly dene several previous concepts in the context of quivers represen tations. 
Denition 1.35. A subrepresen tation of a represen tation (Vi,xh) of a quiver Q is a represen tation 
(Wi,x
h) where Wi  Vi for all i  I and where xh(Wh )  Wh and x
h = xh|Wh : Wh  Wh for 
all h  E. 
Denition 1.36. The direct sum of two represen tations (Vi,xh) and (Wi,yh) is the represen tation 
(Vi  Wi,xh  yh). 
As with represen tations of algebras, a nonzero represen tation (Vi) of a quiver Q is said to be 
irreducible if its only subrepresen tations are (0) and (Vi) itself, and indecomp osable if it is not 
isomorphic to a direct sum of two nonzero represen tations. 
Denition 1.37. Let (Vi,xh) and (Wi,yh) be represen tations of the quiver Q. A homomorphism 
 :(Vi)  (Wi) of quiver represen tations is a collection of maps i : Vi  Wi such that 
yh  h = h  xh for all h  E. 
Problem 1.38. Let A be a Z+-graded algebra, i.e., A = n0A[n], and A[n] A[m] A[n + m]. 
If A[n] is nite dimensional, it is useful to consider the Hilbert series hA(t)=   dim
A[n]tn (the 
generating function of dimensions of A[n]). Often this series converges to a rational function, and 
the answer is written in the form of such function. For example, if A = k[x] and deg(xn)= n then 
hA(t)=1+ t + t2 + ... + tn + ... =1 
1  t 
Find the Hilbert series of: 
(a) A = k[x1,...,xm] (where the grading is by degree of polynomials); 
14</text>
        </slide>
        <slide>
          <slideno>96</slideno>
          <text>3) Hn: V = Cn with basis vi, W = Cn1 with basis wi, Avi = wi, Bwi = vi+1 for i&lt;n, and 
Avn =0. 
4) Kn is obtaine d from Hn by exchanging V with W and A with B. 
Show that these are indecomposable and pairwise nonisomorphic. 
(b) Show that if E is a representation of Q2 such that AB is not nilpotent, then E = E  E, 
where E = En, for some  =0.
(c) Consider the case when AB is nilpotent, and consider the operator X on V  W given 
by X(v,w)=(Bw,Av). Show that X is nilpotent, and admits a basis consisting of chains (i.e., 
sequences u,Xu,X2u,...Xl1u where Xlu =0) which are compatible with the direct sum decompo
sition (i.e., for every chain u  V or u  W ). Deduce that (1)-(4) are the only indecomposable 
representations of Q2. 
(d)(har der!) generalize this classic ation to the Kronecker quiver, which has two vertices 1 and 
2 and two edges both going from 1 to 2. 
(e)(stil l harder!) can you generalize this classic ation to Qn, n&gt; 2, with any orientation? 
Problem 5.40. Let L 1 Z8 be the lattice of vectors where the coordinates are either all integers  2 
or all half-inte gers (but not integers), and the sum of all coordinates is an even integer. 
(a) Let i = ei  ei+1, i =1,..., 6, 7 = e6 + e7, 8 = 1/2 8 Show that i are a basis i=1 ei. 
of L (over Z). 
(b) Show that roots in L (under the usual inner product) form a root system of type E8 (compute 
the inner products of i). 
(c) Show that the E7 and E6 lattices can be obtaine d as the sets of vectors in the E8 lattice L 
where the rst two, respectively three, coordinates (in the basis ei) are equal. 
(d) Show that E6,E7,E8 have 72,126,240 roots, respectively (enumer ate types of roots in terms 
of the presentations in the basis ei, and count the roots of each type). 
Problem 5.41. Let V be the indecomposable representation of a Dynkin quiver Q which corre
sponds to a positive root . For instanc e, if i is a simple root, then Vi has a 1-dimensional space 
at i and 0 everywher e else. 
(a) Show that if i is a source then Ext1(V,Vi )=0 for any representation V of Q, and if i is 
a sink, then Ext1(Vi ,V )=0. 
(b) Given an orientation of the quiver, nd a Jordan-H older series of V for that orientation. 
97</text>
        </slide>
        <slide>
          <slideno>72</slideno>
          <text>If 1 = 2, let z = xy1 , then the last term of the summation is  
2 2 2(q + q)  
1(z)2(z)=(q + q)  1 (z)=(q + q)(q  1)  1 (z). 2 2 x=y x;z=1 z=1   
Since  1 (z)=0,2 zFq 
because the sum of all roots of unity of a given order m&gt; 1 is zero, the last term becomes 
2 2(q + q)(q  1)  1 (1) = (q + q)(q  1). 2 z=1
The dierence between this case and the case of 1 = 2 is equal to 
(q 2 + q)[(q  2)(q  1) + (q  1)] = |G|, 
so this is an irreducible represen tation by Lemma 4.27. 
To prove the third assertion of the theorem, we look at the characters on hyperbolic elemen ts 
and note that the function 
1(x)2(y)+ 1(y)2(x) 
determines 1,2 up to permutation. 
4.24.4 Complemen tary series represen tations 
Let Fq2  Fq be a quadratic extension Fq(),  Fq \ F2 
q. We regard this as a 2-dimensional vector 
space over Fq; then G is the group of linear transformations of Fq2 over Fq. Let KG be the cyclic 
group of multiplications by elemen ts of F
q2 , 
x y 
K = { yx }, |K| = q 2  1. 
For  : K  C a homomorphism, let 
Y = IndG 
K C. 
This represen tation, of course, is very reducible. Let us compute its character, using the Mackey 
formula. We get x 0 
 = q(q  1)(x);0 x 
(A)=0 for A parab olic or hyperbolic; 
x y x y x yq 
 =  +  . yx yxyx 
The last assertion holds because if we regard the matrix as an elemen t of Fq2 , conjugation is an 
automorphism of Fq2 over Fq, but the only nontrivial automorphism of Fq2 over Fq is the qth power 
map. 
73</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Proof. (i) By the densit y theorem, the maps A  End V and B  End W are surjectiv e. Therefore, 
the map A  B  End V  End W = End(V  W ) is surjectiv e. Thus, V  W is irreducible. 
(ii) First we show the existence of V and W . Let A,B be the images of A,B in End M. Then 
A,B are nite dimensional algebras, and M is a represen tation of A  B, so we may assume 
without loss of generalit y that A and B are nite dimensional. 
In this case, we claim that Rad(A  B) = Rad(A)  B + A  Rad(B). Indeed, denote the latter 
by J. Then J is a nilpotent ideal in A  B, as Rad(A) and Rad(B ) are nilpotent. On the other 
hand, (A  B)/J =(A/Rad (A))  (B/Rad(B )), which is a product of two semisimple algebras, 
hence semisimple. This implies J  Rad(A  B). Altogether, by Proposition 2.11, we see that 
J = Rad(A  B), proving the claim. 
Thus, we see that 
(A  B)/Rad (A  B)= A/Rad (A)  B/Rad(B ). 
Now, M is an irreducible represen tation of (A  B)/Rad(A  B), so it is clearly of the form 
M = V  W , where V is an irreducible represen tation of A/Rad(A) and W is an irreducible 
represen tation of B/Rad(B ), and V,W are uniquely determined by M (as all of the algebras 
involved are direct sums of matrix algebras). 
32</text>
        </slide>
        <slide>
          <slideno>55</slideno>
          <text>where (g) is the trace of the diagonal block of (g) corresp onding to V. 
Since g()= g is a right H-coset for any right H-coset , (g)=0 if  = g. 
Now assume that  = g. Then xg = hx where h = xgx
 1  H. Consider the vector space 
homomorphism  : V  V with (f)= f(x). Since f  V is uniquely determined by f(x),  
is an isomorphism. We have 
(gf)= g(f)(x )= f(xg)= f(hx)= V (h)f(x)= h(f), 
and gf = 1h(f). This means that (g)= V (h). Therefore 
(g)=  
V (xgx
 1). 
H\G,g= 
4.10 Frobenius recipro city 
A very important result about induced represen tations is the Frobenius Recipro city Theorem which 
connects the operations Ind and Res. 
Theorem 4.33. (Frobenius Recipro city) 
Let HG be groups, V be a represen tation of G and W a represen tation of H. Then 
Hom G(V, Ind
G
H V,W ).H W ) is naturally isomorphic to Hom H (ResG 
Proof. Let E = Hom G(V, IndG
H W ) and E = Hom H (ResG  and F 
H V,W ). Dene F : E  E : E
E as follows: F ()v =(v)(e) for any   E and (F ()v)(x)= (xv) for any   E. 
In order to check that F and F  are well dened and inverse to each other, we need to check 
the following ve statemen ts. 
Let   E,   E, v  V , and x,g  G. 
(a) F () is an H-homomorphism, i.e., F ()hv = hF ()v.
Indeed, F ()hv =(hv)(e)=(hv)(e)=(v)(he) =(v)(eh)= h (v)(e)= hF ()v.
  
(b) F 
H W , i.e., (F ()v)(hx) = h(F ()v)(x). ()v  IndG 
Indeed, (F ()v)(hx) = (hxv)= h(xv)= h(F ()v)(x).
(c) F () is a G-homomorphism, i.e. F ()gv = g(F ()v).
Indeed, (F ()gv)(x)= (xgv)=(F ()v)(xg)=(g(F ()v))(x).
(d) F  F  = IdE .
This holds since F (F ())v =(F ()v)(e)= (v).
(e) F   F = IdE , i.e., (F (F ())v)(x)=(v)(x).
Indeed, (F (F ())v)(x)= F (xv)=(xv)(e)=(xv)(e)=(v)(x), and we are done.
Exercise. The purpose of this exercise is to understand the notions of restricted and induced 
represen tations as part of a more advanced framew ork. This framew ork is the notion of tensor 
products over k-algebras (which generalizes the tensor product over k which we dened in Denition 
56</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Hint. Prove the result by induction in dimension. By the induction assumption, K(g) has a 
common eigenve ctor v in V , that is there is a linear function  : K(g)  C such that av = (a)v 
for any a  K(g). Show that g preserves common eigensp aces of K(g) (for this you will need to 
show that ([x,a]) = 0 for x  g and a  K(g). To prove this, consider the smallest vector subspace 
U containing v and invariant under x. This subspace is invariant under K(g) and any a  K(g) 
acts with trace dim(U)(a) in this subspace. In particular 0 = Tr([x,a]) = dim(U )([x,a]).). 
Problem 1.57. Classify irreducible nite dimensional representations of the two dimensional Lie 
algebra with basis X,Y and commutation relation [X,Y ]= Y . Consider the cases of zero and 
positive characteristic. Is the Lie theorem true in positive characteristic? 
Problem 1.58. (hard!) For any element x of a Lie algebra g let ad(x) denote the operator g  
g,y  [x,y]. Consider the Lie algebra gn generated by two elements x,y with the dening relations 
ad(x)2(y)= ad(y)n+1(x)=0. 
(a) Show that the Lie algebras g1, g2, g3 are nite dimensional and nd their dimensions. 
(b) (harder!) Show that the Lie algebra g4 has innite dimension. Construct explicitly a basis 
of this algebra. 
22</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Proof. (i) First let us show that the elemen ts xiyj are a spanning set for A. To do this, note that 
any word in x,y can be ordered to have all the x on the left of the y, at the cost of interchanging 
some x and y. Since yx  xy = 1, this will lead to error terms, but these terms will be sums of 
monomials that have a smaller number of letters x,y than the original word. Therefore, continuing 
this process, we can order everything and represen t any word as a linear combination of xiyj. 
The proof that xiyj are linearly independen t is based on represen tation theory . Namely , let a be 
a variable, and E = tak[a][t,t1] (here ta is just a formal symbol, so really E = k[a][t,t1]). Then E 
df d(ta+n)is a represen tation of A with action given by xf = tf and yf = dt (where dt := (a + n)ta+n1). 
iSuppose now that we have a nontrivial linear relation  cij xyj = 0. Then the operator 
iL =  
cij t d j 
dt 
acts by zero in E. Let us write L as 
r  d j 
L =  
Qj(t) dt , 
j=0 
where Qr = 0. Then we have 
r
Lta = Qj (t)a(a  1)...(a  j + 1)taj . 
j=0 
This must be zero, so we have r Qj (t)a(a  1)...(a  j + 1)tj = 0 in k[a][t,t1]. Taking the j=0 
leading term in a, we get Qr(t) = 0, a contradiction. 
(ii) Any word in x,y,x1,y1 can be ordered at the cost of multiplying it by a power of q. This 
easily implies both the spanning property and the linear independence. 
Remark. The proof of (i) shows that the Weyl algebra A can be viewed as the algebra of 
polynomial dieren tial operators in one variable t. 
The proof of (i) also brings up the notion of a faithful represen tation.
Denition. A represen tation  : A  End V is faithful if  is injectiv e.
For example, k[t] is a faithful represen tation of the Weyl algebra, if k has characteristic zero
(check it!), but not in characteristic p, where (d/dt)pQ = 0 for any polynomial Q. However, the 
represen tation E = tak[a][t,t1], as weve seen, is faithful in any characteristic. 
Problem 1.26. Let A be the Weyl algebra, generated by two elements x,y with the relation 
yx  xy  1=0. 
(a) If chark =0, what are the nite dimensional representations of A? What are the two-side d 
ideals in A? 
Hint. For the rst question, use the fact that for two square matric es B,C, Tr(BC)= Tr(CB). 
For the second question, show that any nonzer o two-side d ideal in A contains a nonzer o polynomial 
in x, and use this to characterize this ideal. 
Suppose for the rest of the problem that chark = p. 
(b) What is the center of A? 
12</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>2.2 The densit y theorem 
Let A be an algebra over an algebraically closed eld k. 
Corollary 2.4. Let V be an irreducible nite dimensional representation of A, and v1,...,vn  V 
be any linearly independent vectors. Then for any w1,...,wn  V there exists an element a  A 
such that avi = wi. 
Proof. Assume the contrary. Then the image of the map A  nV given by a  (av1,...,avn) is a 
proper subrepresen tation, so by Proposition 2.2 it corresp onds to an r-by-n matrix X, r&lt;n. Thus, 
taking a = 1, we see that there exist vectors u1,...,ur  V such that (u1,...,ur)X =(v1,...,vn). Let 
(q1,...,qn) be a nonzero vector such that X(q1,...,qn)T = 0 (it exists because r&lt;n). Then  qivi = 
(u1,...,ur )X(q1,...,qn)T = 0, i.e.  qivi = 0 -a contradiction with the linear independence of 
vi. 
Theorem 2.5. (the Density Theorem). (i) Let V be an irreducible nite dimensional representation 
of A. Then the map  : A  EndV is surjective. 
(ii) Let V = V1  ...  Vr, where Vi are irreducible pairwise nonisomorphic nite dimensional 
representations of A. Then the map r i : A r End(Vi) is surjective. i=1 i=1 
Proof. (i) Let B be the image of A in End(V ). We want to show that B = End(V ). Let c  End(V ), 
v1,...,vn be a basis of V , and wi = cvi. By Corollary 2.4, there exists a  A such that avi = wi. 
Then a maps to c, so c  B, and we are done. 
(ii) Let Bi be the image of A in End(Vi), and B be the image of A in r End(Vi). Recall that as i=1 
a represen tation of A, r End(Vi) is semisimple: it is isomorphic to r diVi, where di = dim Vi.i=1 i=1
Then by Proposition 2.2, B = iBi. On the other hand, (i) implies that Bi = End(Vi). Thus (ii) 
follows. 
2.3 Represen tations of direct sums of matrix algebras 
In this section we consider represen tations of algebras A = 
i Matdi (k) for any eld k. 
Theorem 2.6. Let A = r
i=1 Matdi (k). Then the irreducible representations of A are V1 = 
kd1 ,...,Vr = kdr , and any nite dimensional representation of A is a direct sum of copies of 
V1,...,Vr. 
In order to prove Theorem 2.6, we shall need the notion of a dual represen tation. 
Denition 2.7. (Dual represen tation) Let V be a represen tation of any algebra A. Then the 
dual represen tation V  is the represen tation of the opposite algebra Aop (or, equivalently, right 
A-module) with the action 
(fa)(v) := f(av).  
Proof of Theorem 2.6. First, the given represen tations are clearly irreducible, as for any v =0,w  
Vi, there exists a  A such that av = w. Next, let X be an n-dimensional represen tation of 
A. Then, X is an n-dimensional represen tation of Aop. But (Mat di (k))op = Matdi (k) with 
isomorphism (X)= XT , as(BC)T = CT BT . = AopThus, A  and X may be viewed as an 
n-dimensional represen tation of A. Dene 
 : A  A  X 
n copies 
24</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Proof. Write k[G]= r
i=1 End Vi, where the Vi are irreducible represen tations and V1 = k is the 
trivial one-dimensional represen tation. Then 
r r
k[G]= k   
End Vi = k   
diVi, 
i=2 i=2 
where di = dim Vi. By Schurs Lemma, 
Hom k[G](k,k[G]) = k
Hom k[G](k[G],k)= k,
for nonzero homomorphisms of represen tations  : k[G]  k and  : k  k[G] unique up to scaling. 
We can take  such that (g)=1 for all g  G, and  such that (1) =  
gG g. Then 
  (1) =   
g  
=  
1= |G|. 
gG gG 
If |G| = 0, then  has no left inverse, as (a)  (1) = 0 for any a  k. This is a contradiction. 
Example 3.3. If G = Z/pZ and k has characteristic p, then every irreducible represen tation of G 
over k is trivial (so k[Z/pZ] indeed is not semisimple). Indeed, an irreducible represen tation of this 
group is a 1-dimensional space, on which the generator acts by a p-th root of unity, and every p-th 
root of unity in k equals 1, as xp  1=(x  1)p over k. 
Problem 3.4. Let G be a group of order pn . Show that every irreducible representation of G over 
a eld k of characteristic p is trivial. 
3.2 Characters 
If V is a nite-dimensional represen tation of a nite group G, then its character V : G  k 
is dened by the formula V (g) = trV ((g)). Obviously , V (g) is simply the restriction of the |
character V (a) of V as a represen tation of the algebra A = k[G] to the basis GA, so it carries 
exactly the same information. The character is a central or class function : V (g) depends only on 
the conjugacy class of g; i.e., V (hgh1)= V (g). 
Theorem 3.5. If the characteristic of k does not divide G, characters of irreducible representa ||
tions of G form a basis in the space Fc(G,k) of class functions on G. 
Proof. By the Maschke theorem, k[G] is semisimple, so by Theorem 2.17, the characters are linearly 
independen t and are a basis of (A/[A,A]), where A = k[G]. It suces to note that, as vector 
spaces over k, 
(A/[A,A])  | gh  hg  ker  g,h  G} = {  Hom k(k[G],k)
= {f  Fun(G,k) f(gh)= f(hg) g,h  G},
  | 
which is precisely Fc(G,k). 
Corollary 3.6. The number of isomorphism classes of irreducible representations of G equals the 
number of conjugacy classes of G (if G=0 in k). ||
34</text>
        </slide>
        <slide>
          <slideno>53</slideno>
          <text>Now pick V  N such that V (g) = 0; it exists by Lemma 4.24. Theorem 4.21 implies that g 
(and hence any elemen t of C) acts by a scalar in V . Now let H be the subgroup of G generated 
by elemen ts ab1 , a,b  C. It is normal and acts trivially in V , so H =  G, as V is nontrivial. Also 
H = 1, since C&gt; 1.  || 
Proof of Burnsides theorem. 
Assume Burnsides theorem is false. Then there exists a nonsolv able group G of order paqb . Let 
G be the smallest such group. Then G is simple, and by Theorem 4.23, it cannot have a conjugacy 
class of order pk or qk , k  1. So the order of any conjugacy class in G is either 1 or is divisible 
aby pq. Adding the orders of conjugacy classes and equating the sum to pqb, we see that there has 
to be more than one conjugacy class consisting just of one elemen t. So G has a nontrivial center, 
which gives a contradiction. 
4.6 Represen tations of products 
Theorem 4.25. Let G,H be nite groups, {Vi} be the irreducible representations of G over a 
eld k (of any characteristic), and {Wj } be the irreducible representations of H over k. Then the 
irreducible representations of G  H over k are {Vi  Wj}. 
Proof. This follows from Theorem 2.26. 
4.7 Virtual represen tations 
Denition 4.26. A virtual representation of a nite group G is an integer linear combination of 
irreducible represen tations of G, V =  niVi, ni  Z (i.e., ni are not assumed to be nonnegativ e). 
The character of V is V :=  niVi . 
The following lemma is often very useful (and will be used several times below). 
Lemma 4.27. Let V be a virtual representation with character V . If (V ,V )=1 and V (1) &gt; 0 
then V is a character of an irreducible representation of G. 
Proof. Let V1,V2,...,Vm be the irreducible represen tations of G, and V =  niVi. Then by 
2 2orthonormalit y of characters, (V ,V )= 
i . So = 1, meaning that ni = 1 for exactly i ni ni 
one i, and nj = 0 for j = i. But V (1) &gt; 0, so ni = +1 and we are done.  
4.8 Induced Represen tations 
Given a represen tation V of a group G and a subgroup HG, there is a natural way to construct 
a represen tation of H. The restricted represen tation of V H V is the represen tation given to H, ResG 
by the vector space V and the action ResG V = VH . 
H |
There is also a natural, but more complicated way to construct a represen tation of a group G 
given a represen tation V of its subgroup H. 
Denition 4.28. If G is a group, HG, and V is a represen tation of H, then the induced 
representation IndG V is the represen tation of G withH 
IndG f(hx)= V (h)f(x)x  G,h  H}H V = {f : G  V |
54</text>
        </slide>
        <slide>
          <slideno>100</slideno>
          <text>For this reason in category theory , one most of the time tries to avoid saying that two objects 
or two functors are equal. In particular, this applies to the denition of isomorphism of categories. 
Namely , the naive notion of isomorphism of categories is dened in the obvious way: a functor 
F : CD is an isomorphism if there exists F 1 : DC such that F  F 1 and F 1  F are equal 
to the identity functors. But this denition is not very useful. We might suspect so since we have 
used the word equal for objects of a category (namely , functors) which we are not supposed to 
do. And in fact here is an example of two categories which are the same for all practical purposes 
but are not isomorphic; it demonstrates the deciency of our denition. 
Namely , let C1 be the simplest possible category: Ob(C1) consists of one object X, with 
Hom(X,X)= {1X }. Also, let C2 have two objects X,Y and 4 morphisms: 1X , 1Y ,a : X  Y 
and b : Y  X. So we must have a  b =1Y , b  a =1X . 
It is easy to check that for any category D, there is a natural bijection between the collections 
of isomorphism classes of functors C1 D and C2 D (both are identied with the collection of 
isomorphism classes of objects of D). This is what we mean by saying that C1 and C2 are the same 
for all practical purposes. Nevertheless they are not isomorphic, since C1 has one object, and C2 
has two objects (even though these two objects are isomorphic to each other). 
This shows that we should adopt a more exible and less restrictiv e notion of isomorphism of 
categories. This is accomplished by the denition of an equivalence of categories. 
Denition 6.8. A functor F : CD is an equivalence of categories if there exists F  : DC 
such that F  F  and F   F are isomorphic to the identity functors. 
In this situation, F  is said to be a quasi-inverse to F . 
In particular, the above categories C1 and C2 are equivalent (check it!). 
Also, the category FSet of nite sets is equivalent to the category whose objects are nonneg
ative integers, and morphisms are given by Hom(m,n) = Maps( {1,...,m}, {1,...,n}). Are these 
categories isomorphic? The answer to this question depends on whether you believe that there 
is only one nite set with a given number of elemen ts, or that there are many of those. It seems 
better to think that there are many (without asking how many), so that isomorphic sets need not 
be literally equal, but this is really a matter of choice. In any case, this is not really a reasonable 
question; the answer to this question is irrelev ant for any practical purpose, and thinking about it 
will give you nothing but a headac he. 
6.5 Represen table functors 
A fundamen tal notion in category theory is that of a represen table functor. Namely , let C be a 
(locally small) category , and F : C Sets be a functor. We say that F is represen table if there 
exists an object X C such that F is isomorphic to the functor Hom(X, ?). More precisely , if we 
are given such an object X, together with an isomorphism  : F = Hom(X, ?), we say that the 
functor F is represen ted by X (using ). 
In a similar way, one can talk about represen table functors from Cop to Sets. Namely , one 
calls such a functor represen table if it is of the form Hom(?,X) for some object X C, up to an 
isomorphism. 
Not every functor is represen table, but if a represen ting object X exists, then it is unique. 
Namely , we have the following lemma. 
101</text>
        </slide>
        <slide>
          <slideno>76</slideno>
          <text>Proof. (i) Let us decomp ose V = V(O,U) as an A-module. Then we get 
V = yOVy, 
where Vy = {v  V(O,U)|av =(y,a)v,a  A}. (Equiv alently, Vy = {v  V(O,U)|v(g) = 0 unless gy = 
x}). Soif W  V is a subrepresen tation, then W = yOWy, where Wy  Vy. Now, Vy is a 
represen tation of Gy, which goes to U under any isomorphism Gy  Gx determined by g  G 
mapping x to y. Hence, Vy is irreducible over Gy, so Wy = 0 or Wy = Vy for each y. Also, if hy = z 
then hWy = Wz, so either Wy = 0 for all y or Wy = Vy for all y, as desired. 
(ii) The orbit O is determined by the A-module structure of V , and the represen tation U by 
the structure of Vx as a Gx-module. 
(iii) We have  
dim V(2 
U,O) =  
|O| 2(dim U)2 = 
U,O U,O 
2 
|O||Gx| =  
|O||G/G x||Gx| = |G|  
|O| = |G||A| = |G  A|. 
O O O 
(iv) The proof is essentially the same as that of the Mackey formula. 
Exercise. Redo Problems 3.17(a), 3.18, 3.22 using Theorem 4.75. 
Exercise. Deduce parts (i)-(iii) of Theorem 4.75 from part (iv). 
77</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>The answer is no, as was found by Dehn in 1901. The proof is very beautiful. Namely, to 
any polyhedron A let us attach its Dehn invariant D(A) in V = R  (R/Q) (the tensor product 
of Q-vector spaces). Namely, 
D(A)=  
l(a)  (a) , a 
where a runs over edges of A, and l(a),(a) are the length of a and the angle at a. 
(a) Show that if you cut A into B and C by a straight cut, then D(A)= D(B)+ D(C). 
(b) Show that  = arccos (1/3)/ is not a rational number. 
Hint. Assume that  =2m/n, for integers m,n. Deduce that roots of the equation x+x1 =2/3 
are roots of unity of degree n. Conclude that xk + xk has denominator 3k and get a contradiction. 
(c) Using (a) and (b), show that the answer to Hilberts question is negative. (Compute the 
Dehn invariant of the regular tetrahedron and the cube). 
1.13 Tensor products and duals of represen tations of Lie algebras 
Denition 1.52. The tensor product of two represen tations V,W of a Lie algebra g is the space 
V  W with V W (x)= V (x)  Id + Id  W (x). 
Denition 1.53. The dual represen tation V  to a represen tation V of a Lie algebra g is the dual 
space V  to V with V  (x)= V (x). 
It is easy to check that these are indeed represen tations. 
Problem 1.54. Let V,W,U be nite dimensional representations of a Lie algebra g. Show that 
the space Hom g(V  W,U) is isomorphic to Hom g(V,U  W ). (Here Hom g := Hom U(g)). 
1.14 Represen tations of sl(2) 
This subsection is devoted to the represen tation theory of sl(2), which is of central importance in 
many areas of mathematics. It is useful to study this topic by solving the following sequence of 
exercises, which every mathematician should do, in one form or another. 
Problem 1.55. According to the above, a representation of sl(2) is just a vector space V with a 
triple of operators E,F,H such that HE  EH =2E,HF  FH = 2F,EF  FE = H (the 
corresponding map  is given by (e)= E,(f)= F , (h)= H). 
Let V be a nite dimensional representation of sl(2) (the ground eld in this problem is C). 
 (a) Take eigenvalues of H and pick one with the biggest real part. Call it . Let V () be the 
generalized eigensp ace corresponding to . Show that E|V() =0. 
(b) Let W be any representation of sl(2) and w  W be a nonzer o vector such that Ew =0. 
For any k&gt; 0 nd a polynomial Pk(x) of degree k such that EkF kw = Pk(H)w. (First compute 
EF kw, then use induction in k). 
 (c) Let v  V () be a generalized eigenve ctor of H with eigenvalue . Show that there exists 
N&gt; 0 such that F N v =0. 
(d) Show that H is diagonalizable on V(). (Take N to be such that F N =0 on V(), and 
compute EN F N v, v  V(), by (b). Use the fact that Pk(x) does not have multiple roots). 
20</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>4.15TheFrobenius character formula ............................. 61
4.16Problems .......................................... 63
4.17Thehooklength formula.................................. 63
4.18 Schur-Weyl dualit y for gl(V ) ............................... 64
4.19 Schur-Weyl dualit y for GL(V )............................... 65
4.20Schurpolynomials ..................................... 66
4.21 The characters of L .................................... 66
4.22 Polynomial represen tations of GL(V )........................... 67
4.23Problems .......................................... 68
4.24 Represen tations of GL2(Fq) ................................ 68
4.24.1 Conjugacy classes in GL2(Fq)........................... 68
4.24.2 1-dimensional represen tations ........................... 70
4.24.3 Principal series represen tations .......................... 71
4.24.4 Complemen taryseries represen tations . . . . . . . . . . . . . . . . . . . . . . 73
4.25Artins theorem ....................................... 75
4.26Represen tations ofsemidirect products .......................... 76
5 Quiver Represen tations 78
5.1 Problems .......................................... 78
5.2 Indecomp osable represen tations of the quivers A1,A2,A3 ................ 81
5.3 Indecomp osable represen tations of the quiver D4 .................... 83
5.4 Roots ............................................ 87
5.5 Gabriels theorem ...................................... 89
5.6 Reection Functors ..................................... 90
5.7 Coxeter elemen ts ...................................... 93
5.8 ProofofGabriels theorem ................................. 94
5.9 Problems .......................................... 96
6 Introduction to categories 98
6.1 Thedenition ofacategory ................................ 98
6.2 Functors ........................................... 99
6.3 Morphisms offunctors ................................... 100
6.4 Equiv alence ofcategories .................................. 100
6.5 Represen tablefunctors ................................... 101
3</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Similarly , if C is another k-algebra, and if the left B-module structure on W is part of a (B,C)
bimodule structure, then V B W becomes a right C-module by (v B w) c = v B wc for any 
c  C, v  V and w  W . 
If V is an (A,B)-bimo dule and W is a (B,C)-bimo dule, then these two structures on V B W 
can be combined into one (A,C)-bimo dule structure on V B W . 
(a) Let A, B, C, D be four algebras. Let V be an (A,B)-bimo dule, W be a (B,C)-bimo dule, 
and X a(C,D)-bimo dule. Prove that (V B W ) C X V B (W C X) as (A,D)-bimo dules. = 
The isomorphism (from left to right) is given by (v B w) C x  v B (w C x) for all v  V , 
w  W and x  X. 
(b) If A, B, C are three algebras, and if V is an (A,B)-bimo dule and W an (A,C)-bimo dule, 
then the vector space Hom A (V,W ) (the space of all left A-linear homomorphisms from V to W ) 
canonically becomes a (B,C)-bimo dule by setting (bf)(v)= f (vb) for all b  B, f  Hom A (V,W ) 
and v  V and (fc)(v)= f (v) c for all c  C, f  Hom A (V,W ) and v  V . 
Let A, B, C, D be four algebras. Let V bea (B,A)-bimo dule, W bea (C,B)-bimo dule, and X a 
(C,D)-bimo dule. Prove that Hom B (V, Hom C (W,X)) = Hom C (W B V,X) as(A,D)-bimo dules. 
The isomorphism (from left to right) is given by f  (w B v  f (v) w) for all v  V , w  W 
and f  Hom B (V, Hom C (W,X)). 
1.11 The tensor algebra 
The notion of tensor product allows us to give more conceptual (i.e., coordinate free) denitions 
of the free algebra, polynomial algebra, exterior algebra, and universal enveloping algebra of a Lie 
algebra. 
Namely , given a vector space V , dene its tensor algebra TV over a eld k to be TV = n0V n , 
with multiplication dened by ab := a  b, a  V n , b  V m . Observ e that a choice of a basis  
x1,...,xN in V denes an isomorphism of TV with the free algebra k&lt;x1,...,xn &gt;. 
Also, one can make the following denition. 
Denition 1.50. (i) The symmetric algebra SV of V is the quotien t of TV by the ideal generated 
by v  w  w  v, v,w  V . 
(ii) The exterior algebra V of V is the quotien t of TV by the ideal generated by v  v, v  V . 
(iii) If V is a Lie algebra, the universal enveloping algebra U(V ) of V is the quotien t of TV by 
the ideal generated by v  w  w  v  [v,w], v,w  V . 
It is easy to see that a choice of a basis x1,...,xN in V identies SV with the polynomial algebra 
k[x1,...,xN ], V with the exterior algebra k(x1,...,xN ), and the universal enveloping algebra U(V ) 
with one dened previously . 
Also, it is easy to see that we have decomp ositions SV = n0SnV , V = n0 n V . 
1.12 Hilberts third problem 
Problem 1.51. It is known that if A and B are two polygons of the same area then A can be cut 
by nitely many straight cuts into pieces from which one can make B. David Hilbert asked in 1900 
whether it is true for polyhedra in 3 dimensions. In particular, is it true for a cube and a regular 
tetrahedron of the same volume? 
19</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>by 
(a1,...,an)= a1y1 ++ anyn  
where {yi} is a basis of X.  is clearly surjectiv e, as kA. Thus, the dual map  : X  An
is injectiv e. But An = An as represen tations of A (check it!). Hence, Im  = X is a subrepresen
tation of An . Next, Matdi (k)= diVi, so A = r
i=1diVi, An = r
i=1ndiVi, as a represen tation of A. 
Hence by Proposition 2.2, X = ir 
=1miVi, as desired. 
Exercise. The goal of this exercise is to give an alternativ e proof of Theorem 2.6, not using 
any of the previous results of Chapter 2. 
Let A1, A2, ..., An be n algebras with units 11,12, ...,1n, respectively. Let A = A1 A2 ...An. 
Clearly , 1i1j = ij1i, and the unit of A is 1=11 +12 + ... +1n. 
For every represen tation V of A, it is easy to see that 1iV is a represen tation of Ai for every 
i {1, 2,...,n}. Conversely, if V1, V2, ..., Vn are represen tations of A1, A2, ..., An, respectively, 
then V1  V2  ...  Vn canonically becomes a represen tation of A (with (a1,a2,...,an)  A acting 
on V1  V2  ...  Vn as (v1,v2,...,vn)  (a1v1,a2v2,...,anvn)). 
(a) Show that a represen tation V of A is irreducible if and only if 1iV is an irreducible repre
sentation of Ai for exactly one i {1, 2,...,n}, while 1iV = 0 for all the other i. Thus, classify the 
irreducible represen tations of A in terms of those of A1, A2, ..., An. 
(b) Let d  N. Show that the only irreducible represen tation of Mat d(k) is kd, and every nite 
dimensional represen tation of Mat d(k) is a direct sum of copies of kd . 
Hint: For every (i,j) {1, 2,...,d} 2, let Eij  Matd(k) be the matrix with 1 in the ith row of the 
jth column and 0s everywhere else. Let V be a nite dimensional represen tation of Mat d(k). Show 
that V = E11V  E22V  ...  EddV , and that i : E11V  EiiV , v  Ei1v is an isomorphism for 
every i {1, 2,...,d}. For every v  E11V , denote S (v)= E11v,E21v,...,Ed1v. Prove that S (v) 
is a subrepresen tation of V isomorphic to kd (as a represen tation of Matd(k)), and that v  S (v). 
Conclude that V = S (v1)  S (v2)  ...  S (vk), where {v1,v2,...,vk} is a basis of E11V . 
(c) Conclude Theorem 2.6. 
2.4 Filtrations 
Let A be an algebra. Let V be a represen tation of A. A (nite) ltration of V is a sequence of 
subrepresen tations 0 = V0 V1 ... Vn = V .   
Lemma 2.8. Any nite dimensional representation V of an algebra A admits a nite ltration 
0= V0 V1 ... Vn = V such that the successive quotients Vi/Vi1 are irreducible.   
Proof. The proof is by induction in dim(V ). The base is clear, and only the induction step needs 
to be justied. Pick an irreducible subrepresen tation V1 V , and consider the represen tation 
U = V/V1. Then by the induction assumption U has a ltration 0 = U0 U1 ... Un1 = U  
such that Ui/Ui1 are irreducible. Dene Vi for i  2 to be the preimages of Ui1 under the 
tautological projection V  V/V1 = U. Then 0 = V0 V1 V2 ... Vn = V is a ltration of V  
with the desired property. 
25</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>4 Represen tations of nite groups: further results 
4.1 Frobenius-Sc hur indicator 
Suppose that G is a nite group and V is an irreducible represen tation of G over C. We say that 
V is 
-of complex type, if V  V , 
-of real type, if V has a nondegenerate symmetric form invariant under G, 
-of quaternionic type, if V has a nondegenerate skew form invariant under G. 
Problem 4.1. (a) Show that End R[G] V is C for V of complex type, Mat2(R) for V of real type, 
and H for V of quaternionic type, which motivates the names above. 
Hint. Show that the complexic ation VC of V decomposes as V  V . Use this to compute the 
dimension of End R[G] V in all three cases. Using the fact that C End R[G] V , prove the result 
in the complex case. In the remaining two cases, let B be the invariant bilinear form on V , and 
(, ) the invariant positive Hermitian form (they are dened up to a nonzer o complex scalar and a 
positive real scalar, respectively), and dene the operator j : V  V such that B(v,w)=(v,jw). 
Show that j is complex antiline ar (ji = ij), and j2 =  Id, where  is a real number, positive in  
the real case and negative in the quaternionic case (if B is renormalize d, j multiplies by a nonzer o 
complex number z and j2 by zz, as j is antiline ar). Thus j can be normalize d so that j2 =1 for 
the real case, and j2 = 1 in the quaternionic case. Deduce the claim from this. 
(b) Show that V is of real type if and only if V is the complexic ation of a representation VR 
over the eld of real numbers. 
Example 4.2. For Z/nZ all irreducible represen tations are of complex type, except the trivial one 
and, if n is even, the sign represen tation, m  (1)m, which are of real type. For S3 all three 
irreducible represen tations C+, C, C2 are of real type. For S4 there are ve irreducible represen ta
tions C+, C, C2 , C3
+, C3 , which are all of real type. Similarly , all ve irreducible represen tations 
of A5  C, C+3 , C3 , C4 , C
5 are of real type. As for Q8, its one-dimensional represen tations are of 
real type, and the two-dimensional one is of quaternionic type. 
Denition 4.3. The Frobenius-Sc hur indicator FS(V ) of an irreducible represen tation V is 0 if it 
is of complex type, 1 if it is of real type, and 1 if it is of quaternionic type. 
Theorem 4.4. (Frobenius-Schur) The number of involutions (=elements of order  2) in G is 
equal to 
V dim(V )FS(V ), i.e., the sum of dimensions of all representations of G of real type 
minus the sum of dimensions of its representations of quaternionic type. 
Proof. Let A : V  V have eigenvalues 1,2,...,n. We have 
TrS2V (A  A)=  
ij |
ij
Tr2V (A  A)=  
ij |
i&lt;j 
Thus, 
Tr|S2V (A  A)  Tr|2V (A  A)=  
2 = Tr(A2).i 
1in
47</text>
        </slide>
        <slide>
          <slideno>98</slideno>
          <text>We also mention that in many examples, including examples 1-6, the word class in (ii) can 
be replaced by set. Categories with this property (that Hom(X,Y ) is a set for any X,Y ) are 
called locally small; many categories that we encoun ter are of this kind. 
Sometimes the collection Hom(X,Y ) of morphisms from X to Y in a given locally small category 
C is not just a set but has some additional structure (say, the structure of an abelian group, or a 
vector space over some eld). In this case one says that C is enriched over another category D
(which is a monoidal category , i.e., has a product operation and a unit object under this product, e.g. 
the category of abelian groups or vector spaces with the tensor product operation). This means that 
for each X,Y C, Hom(X,Y ) is an object of D, and the composition Hom(Y,Z)  Hom(X,Y ) 
Hom(X,Z) is a morphism in D. E.g., if D is the category of vector spaces, this means that the 
composition is bilinear, i.e. gives rise to a linear map Hom(Y,Z)  Hom(X,Y )  Hom(X,Z). For 
a more detailed discussion of this, we refer the reader to [McL]. 
Example. The category Rep(A) of represen tations of a k-algebra A is enriched over the 
category of k-vector spaces. 
Denition 6.3. A full subcategory of a category C is a category C whose objects are a subclass 
of objects of C, and Hom C (X,Y ) = Hom C (X,Y ). 
Example. The category AbelianGroups is a full subcategory of the category Groups. 
6.2 Functors 
We would like to dene arrows between categories. Such arrows are called functors. 
Denition 6.4. A functor F : CD between categories C and D is 
(i) a map F : Ob(C)  Ob(D); 
(ii) for each X,Y C, a map F = FX,Y : Hom(X,Y )  Hom(F (X),F (Y )) which preserv es 
compositions and identity morphisms. 
Note that functors can be composed in an obvious way. Also, any category has the identity 
functor. 
Example 6.5. 1. A (locally small) category C with one object X is the same thing as a monoid. 
A functor between such categories is a homomorphism of monoids. 
2. Forgetful functors Groups  Sets, Rings  AbelianGroups . 
3. The opposite category of a given category is the same category with the order of arrows and 
compositions reversed. Then V  V  is a functor Vectk  Vectop .k 
4. The Hom functors: If C is a locally small category then we have the functor C Sets given 
by Y  Hom(X,Y ) and Cop  Sets given by Y  Hom(Y,X). 
5. The assignmen t X  Fun(X, Z) is a functor Sets  Ringsop. 
6. Let Q be a quiver. Consider the category C(Q) whose objects are the vertices and morphisms 
are oriented paths between them. Then functors from C(Q) to Vectk are represen tations of Q over 
k. 
7. Let KG be groups. Then we have the induction functor IndG 
ResG  K : Rep(K )  Rep(G), and 
K : Rep(G)  Rep(K ). 
99</text>
        </slide>
        <slide>
          <slideno>64</slideno>
          <text>Lemma 4.56. Let k be a eld of characteristic zero. 
(i) For any nite dimensional vector space U over k, the space SnU is spanned by elements of 
the form u  ...  u, u  U. 
(ii) For any algebra A over k, the algebra SnA is generated by elements n(a), a  A. 
Proof. (i) The space SnU is an irreducible represen tation of GL(U ) (Problem 3.19). The subspace 
spanned by u  ...  u is a nonzero subrepresen tation, so it must be everything. 
(ii) By the fundamen tal theorem on symmetric functions, there exists a polynomial P with 
rational coecien ts such that P (H1(x),...,Hn(x)) = x1...xn (where x =(x1,...,xn)). Then 
P (n(a), n(a 2),..., n(a n)) = a  ...  a. 
The rest follows from (i). 
Now, the algebra A is semisimple by Maschkes theorem, so the double centralizer theorem 
applies, and we get the following result, which goes under the name Schur-Weyl dualit y. 
Theorem 4.57. (i) The image A of C[Sn] and the image B of U(gl(V )) in End(V n) are central
izers of each other. 
(ii) Both A and B are semisimple. In particular, V n is a semisimple gl(V )-module. 
(iii) We have a decomposition of A  B-modules V n = V  L, where the summation 
is taken over partitions of n, V are Specht modules for Sn, and L are some distinct irreducible 
representations of gl(V ) or zero. 
4.19 Schur-Weyl dualit y for GL(V ) 
The Schur-Weyl dualit y for the Lie algebra gl(V ) implies a similar statemen t for the group GL(V ). 
Proposition 4.58. The image of GL(V ) in End(V n) spans B. 
Proof. Denote the span of gn , g  GL(V ), by B. Let b  End V be any elemen t. 
We claim that B contains bn . Indeed, for all values of t but nitely many, tId+b is invertible, 
so (t Id + b)n belongs to B. This implies that this is true for all t, in particular for t = 0, since  
(t Id + b)n is a polynomial in t.  
The rest follows from Lemma 4.56. 
Corollary 4.59. As a representation of Sn  GL(V ), V n decomposes as V  L, where 
L = Hom Sn (V,V n) are distinct irreducible representations of GL(V ) or zero. 
Example 4.60. If  =(n) then L = SnV , and if  = (1n)(n copies of 1) then L = nV . It was 
shown in Problem 3.19 that these represen tations are indeed irreducible (except that nV is zero 
if n&gt; dim V ). 
65</text>
        </slide>
        <slide>
          <slideno>87</slideno>
          <text>Next, let  be the edge connecting i with the next vertex towards j and i be the vertex on the other 
end of . We then let 1, 2 be the graphs obtained from  by removing . Since  is supposed 
to be a Dynkin diagram -and therefore has no cycles or loops -both 1 and 2 will be connected 
graphs, which are not connected to each other. 
  
i 1   j   
 
2 
Then we have i  1,j  2. We dene 
 =  
kmm,  =  
kmm. 
m1 m2 
With this choice we get 
 =  + . 
Since ki &gt; 0,kj &lt; 0 we know that  =0, = 0 and therefore  
B(,)  2,B(,)  2. 
Furthermore, 
B(,)= kiki , 
since 1, 2 are only connected at . But this has to be a nonnegativ e number, since ki &gt; 0 and 
ki  0. This yields 
B(,)= B( + , + )= B(,) +2 B(,)+ B(,)  4.   
2 0 2 
But this is a contradiction, since  was assumed to be a root.
Denition 5.17. We call a root  = kii a positive root if all ki  0. A root for which ki  0
i 
for all i is called a negativ e root. 
Remark 5.18. Lemma 5.16 states that every root is either positive or negativ e. 
Example 5.19. 1. Let  be of the type AN1. Then the lattice L = ZN1 can be realized as 
a subgroup of the lattice ZN by letting L  ZN be the subgroup of all vectors (x1,...,xN ) 
such that  
xi =0. 
i 
The vectors 
1 = (1, 1, 0,..., 0) 
2 = (0, 1, 1, 0,..., 0) 
. . . 
N1 = (0,..., 0, 1, 1) 
naturally form a basis of L. Furthermore, the standard inner product 
(x,y)=  
xiyi 
88</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>Theorem 3.11. If G is nite, then any nite dimensional representation of G has a unitary 
structur e. If the representation is irreducible, this structur e is unique up to scaling by a positive 
real number. 
Proof. Take any positive denite form B on V and dene another form B as follows: 
B(v,w)=  
B(V (g)v,V (g)w) 
gG 
Then B is a positive denite Hermitian form on V, and V (g) are unitary operators. If V is 
an irreducible represen tation and B1,B2 are two positive denite Hermitian forms on V, then 
B1(v,w)= B2(Av,w) for some homomorphism A : V  V (since any positive denite Hermitian 
form is nondegenerate). By Schurs lemma, A = Id, and clearly &gt; 0. 
Theorem 3.11 implies that if V is a nite dimensional represen tation of a nite group G, then 
the complex conjugate representation V (i.e., the same space V with the same addition and the same 
action of G, but complex conjugate action of scalars) is isomorphic to the dual represen tation V . 
Indeed, a homomorphism of represen tations V  V  is obviously the same thing as an invariant 
sesquilinear form on V (i.e. a form additiv e on both argumen ts which is linear on the rst one and 
antilinear on the second one), and an isomorphism is the same thing as a nondegenerate invariant 
sesquilinear form. So one can use a unitary structure on V to dene an isomorphism V  V . 
Theorem 3.12. A nite dimensional unitary representation V of any group G is completely re
ducible. 
Proof. Let W be a subrepresen tation of V . Let W  be the orthogonal complemen t of W in V 
under the Hermitian inner product. Then W  is a subrepresen tation of W , and V = W  W . 
This implies that V is completely reducible. 
Theorems 3.11 and 3.12 imply Maschkes theorem for complex represen tations (Theorem 3.1). 
Thus, we have obtained a new proof of this theorem over the eld of complex numbers. 
Remark 3.13. Theorem 3.12 shows that for innite groups G, a nite dimensional represen tation 
may fail to admit a unitary structure (as there exist nite dimensional represen tations, e.g. for 
G = Z, which are indecomp osable but not irreducible). 
3.7 Orthogonalit y of matrix elemen ts 
Let V be an irreducible represen tation of a nite group G, and v1,v2,...,vn be an orthonormal 
basis of V under the invariant Hermitian form. The matrix elemen ts of V are tV (x)=(V (x)v i,vj ).ij 
Proposition 3.14. (i) Matrix elements of nonisomorphic irreducible representations are orthog
1onal in Fun(G, C) under the form (f,g)= |G|  
xG f(x)g(x). 
(ii) (tV
ij )= ii jj 1 
ij ,tV  dim V 
Thus, matrix elements of irreducible representations of G form an orthogonal basis of Fun(G, C). 
Proof. Let V and W be two irreducible represen tations of G. Take {vi} to be an orthonormal basis 
of V and {wi} to be an orthonormal basis of W under their positive denite invariant Hermitian 
forms. Let wi W  be the linear function on W dened by taking the inner product with 
39</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>Problem 3.21. Let I be the set of vertices of a regular icosahedron (I= 12). Let Fun(I) be the ||
space of complex functions on I. Recall that the group G = A5 of even permutations of 5 items 
acts on the icosahedron, so we have a 12-dimensional representation of G on Fun(I). 
(a) Decompose this representation in a direct sum of irreducible representations (i.e., nd the 
multiplicities of occurrence of all irreducible representations). 
(b) Do the same for the representation of G on the space of functions on the set of faces and 
the set of edges of the icosahedron. 
Problem 3.22. Let Fq be a nite eld with q elements, and G be the group of nonconstant inho
mogeneous linear transformations, x  ax + b, over Fq (i.e., a  F,b  Fq). Find all irreducible q 
complex representations of G, and compute their characters. Compute the tensor products of irre
ducible representations. 
Hint. Let V be the representation of G on the space of functions on Fq with sum of all values 
equal to zero. Show that V is an irreducible representation of G. 
Problem 3.23. Let G = SU(2) (unitary 2 by 2 matric es with determinant 1), and V = C2 the 
standar d 2-dimensional representation of SU(2). We consider V as a real representation, so it is 
4-dimensional. 
(a) Show that V is irreducible (as a real representation). 
(b) Let H be the subspace of End R(V ) consisting of endomorphisms of V as a real representation. 
Show that H is 4-dimensional and closed under multiplic ation. Show that every nonzer o element in 
H is invertible, i.e., H is an algebra with division. 
(c) Find a basis 1,i,j,k of H such that 1 is the unit and i2 = j2 = k2 = 1, ij = ji = k,jk = 
kj = i,ki = ik = j. Thus we have that Q8 is a subgroup of the group H of invertible elements 
of H under multiplic ation. 
The algebra H is called the quaternion algebra. 
(d) For q = a+bi+cj+dk, a,b,c,d  R, let q= abicjdk, and ||q||2 = qq= a2 +b2 +c2 +d2 . 
Show that q1q2 = q2q1, and ||q1q2|| = ||q1||  ||q2||. 
(e) Let G be the group of quaternions of norm 1. Show that this group is isomorphic to SU(2). 
(Thus geometric ally SU(2) is the 3-dimensional sphere). 
(f) Consider the action of G on the space V  H spanned by i,j,k, by x  qxq1 , q  G, 
x  V . Since this action preserves the norm on V , we have a homomorphism h : SU(2)  SO(3), 
where SO(3) is the group of rotations of the three-dimensional Euclide an space. Show that this 
homomorphism is surjective and that its kernel is {1, 1}. 
Problem 3.24. It is known that the classic ation of nite subgroups of SO(3) is as follows: 
1) the cyclic group Z/nZ, n  1, generated by a rotation by 2/n around an axis; 
2) the dihedral group Dn of order 2n, n  2 (the group of rotational symmetries in 3-space of 
a plane containing a regular n-gon5; 
3) the group of rotations of the regular tetrahedron (A4). 
4) the group of rotations of the cube or regular octahedron (S4). 
5) the group of rotations of a regular dodecahedron or icosahedron (A5). 
5A regular 2-gon is just a line segmen t. 
44</text>
        </slide>
        <slide>
          <slideno>79</slideno>
          <text>3
1 2 3 4 5 6 4 2 
(f) Deduce from (a)-(e) the classic ation theorem for Dynkin diagrams. 
(g) A (simply laced) ane Dynkin diagram is a connected graph without self-loops such that the 
quadratic form dened by A is positive semidenite. Classify ane Dynkin diagrams. (Show that 
they are exactly the forbidden diagrams from (c)-(e)). 
Problem 5.4. Let Q be a quiver with set of vertices D. We say that Q is of nite type if it 
has nitely many indecomposable representations. Let bij be the number of edges from i to j in Q 
(i,j  D). 
There is the following remarkable theorem, proved by P. Gabriel in early seventies. 
Theorem. A connected quiver Q is of nite type if and only if the corresponding unoriente d 
graph (i.e., with directions of arrows forgotten) is a Dynkin diagram. 
In this problem you will prove the only if direction of this theorem (i.e., why other quivers 
are NOT of nite type). 
(a) Show that if Q is of nite type then for any rational numbers xi  0 which are not simul
taneously zero, one has q(x1,...,xN ) &gt; 0, where 
q(x1,...,xN ) :=  
xi 2  21  
bij xixj. 
iD i,jD 
Hint. It suces to check the result for integers: xi = ni. First assume that ni  0, and consider 
the space W of representations V of Q such that dimVi = ni. Show that the group 
i GLni (k) acts 
with nitely many orbits on W  k, and use Problem 5.2 to derive the inequality. Then deduce the 
result in the case when ni are arbitrary integers. 
(b) Deduce that q is a positive denite quadratic form. 
Hint. Use the fact that Q is dense in R. 
(c) Show that a quiver of nite type can have no self-loops. Then, using Problem 5.3, deduce 
the theorem. 
Problem 5.5. Let G =1 be a nite subgroup of SU(2), and V be the 2-dimensional representation 
of G coming from its embedding into SU(2). Let Vi, i  I, be all the irreducible representations of 
G. Let rij be the multiplicity of Vi in V  Vj. 
(a) Show that rij = rji. 
(b) The McKa y graph of G, M(G), is the graph whose vertices are labeled by i  I, and i is 
connected to j by rij edges. Show that M(G) is connected. (Use Problem 3.26) 
(c) Show that M(G) is an ane Dynkin graph (one of the forbidden graphs in Problem 5.3). 
For this, show that the matrix aij =2ij  rij is positive semidenite but not denite, and use 
Problem 5.3. 
Hint. Let f =  xiVi , where Vi be the characters of Vi. Show directly that ((2V )f,f)  0. 
When is it equal to 0? Next, show that M(G) has no self-lo ops, by using that if G is not cyclic 
then G contains the central elemen t Id  SU(2). 
80</text>
        </slide>
        <slide>
          <slideno>108</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
18.712 Introduction to Representation Theory 
Fall 2010 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>1.2 Algebras 
Let us now begin a systematic discussion of represen tation theory . 
Let k be a eld. Unless stated otherwise, we will always assume that k is algebraically closed, 
i.e., any nonconstan t polynomial with coecien ts in k has a root in k. The main example is the 
eld of complex numbers C, but we will also consider elds of characteristic p, such as the algebraic 
closure Fp of the nite eld Fp of p elemen ts. 
Denition 1.3. An associative algebra over k is a vector space A over k together with a bilinear 
map A  A  A,(a,b)  ab, such that (ab)c = a(bc). 
Denition 1.4. A unit in an associative algebra A is an elemen t 1  A such that 1a = a1= a. 
Proposition 1.5. If a unit exists, it is unique. 
Proof. Let 1, 1 be two units. Then 1 = 11 =1. 
From now on, by an algebra A we will mean an associative algebra with a unit. We will also 
assume that A = 0. 
Example 1.6. Here are some examples of algebras over k: 
1. A = k. 
2. A = k[x1,...,xn]  the algebra of polynomials in variables x1,...,xn. 
3. A = EndV  the algebra of endomorphisms of a vector space V over k (i.e., linear maps, or 
operators, from V to itself). The multiplication is given by composition of operators. 
4. The free algebra A = kx1,...,xn. A basis of this algebra consists of words in letters 
x1,...,xn, and multiplication in this basis is simply concatenation of words. 
5. The group algebra A = k[G] of a group G. Its basis is {ag,g  G}, with multiplication law 
agah = agh. 
Denition 1.7. An algebra A is comm utativ e if ab = ba for all a,b  A. 
For instance, in the above examples, A is comm utativ e in cases 1 and 2, but not comm utativ e in 
cases 3 (if dim V&gt; 1), and 4 (if n&gt; 1). In case 5, A is comm utativ e if and only if G is comm utativ e. 
Denition 1.8. A homomorphism of algebras f : A  B is a linear map such that f(xy)= 
f(x)f(y) for all x,y  A, and f(1) = 1. 
1.3 Represen tations 
Denition 1.9. A represen tation of an algebra A (also called a left A-module) is a vector space 
V together with a homomorphism of algebras  : A  EndV . 
Similarly , a right A-module is a space V equipp ed with an antihomomorphism  : A  EndV ; 
i.e.,  satises (ab) = (b)(a) and (1) = 1. 
The usual abbreviated notation for (a)v is av for a left module and va for the right module. 
Then the property that  is an (anti)homomorphism can be written as a kind of associativit y law: 
(ab)v = a(bv) for left modules, and (va)b = v(ab) for right modules. 
Here are some examples of represen tations. 
7</text>
        </slide>
        <slide>
          <slideno>80</slideno>
          <text>(d) Which groups from Problem 3.24 corresp ond to which diagrams? 
(e) Using the McKa y graph, nd the dimensions of irreducible represen tations of all nite 
G SU(2) (namely , show that they are the numbers labeling the vertices of the ane Dynkin 
diagrams on our pictures). Compare with the results on subgroups of SO(3) we obtained in 
Problem 3.24. 
5.2 Indecomp osable represen tations of the quivers A1,A2,A3 
We have seen that a central question about represen tations of quivers is whether a certain connected 
quiver has only nitely many indecomp osable represen tations. In the previous subsection it is shown 
that only those quivers whose underlying undirected graph is a Dynkin diagram may have this 
property. To see if they actually do have this property, we rst explicitly decomp ose represen tations 
of certain easy quivers. 
Remark 5.6. By an object of the type 1 0 we mean a map from a one-dimensional vector 
space to the zero space. Similarly , an object of the type 0 1 is a map from the zero space into 
a one-dimensional space. The object 1 1 means an isomorphism from a one-dimensional to 
another one-dimensional space. The numbers in such diagrams always mean the dimension of the 
attached spaces and the maps are the canonical maps (unless specied otherwise) 
Example 5.7 (A1). The quiver A1 consists of a single vertex and has no edges. Since a repre
sentation of this quiver is just a single vector space, the only indecomp osable represen tation is the 
ground eld (=a one-dimensional space). 
Example 5.8 (A2). The quiver A2 consists of two vertices connected by a single edge. 
A represen tation of this quiver consists of two vector spaces V,W and an operator A : V  W . 
A 
VW
To decomp ose this represen tation, we rst let V  be a complemen t to the kernel of A in V and 
let W  be a complemen t to the image of A in W . Then we can decomp ose the represen tation as 
follows 
AA 0   0 
VW= kerA 0  V ImA 0 W 
 
The rst summand is a multiple of the object 1 0 , the second a multiple of 1 1 , the 
third of 0 1 . We see that the quiver A2 has three indecomp osable represen tations, namely 
1 0 , 1 1 and 0 1 . 
Example 5.9 (A3). The quiver A3 consists of three vertices and two connections between them. 
So we have to choose between two possible orientations. 
or 
1. We rst look at the orientation 
. 
81</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Introduction to represen tation theory 
Pavel Etingof, Oleg Golberg, Sebastian Hensel,
Tiank ai Liu, Alex Schwendner, Dmitry Vaintrob, and Elena Yudovina
February 1, 2011
Contents 
1 Basic notions of represen tation theory 5
1.1 What isrepresen tation theory? .............................. 5
1.2 Algebras ........................................... 7
1.3 Represen tations ....................................... 7
1.4 Ideals ............................................ 10
1.5 Quotien ts .......................................... 11
1.6 Algebras dened bygenerators andrelations . . . . . . . . . . . . . . . . . . . . . . . 11
1.7 Examples ofalgebras .................................... 11
1.8 Quivers ........................................... 13
1.9 Liealgebras ......................................... 15
1.10Tensor products ....................................... 17
1.11Thetensor algebra ..................................... 19
1.12Hilbertsthird problem ................................... 19
1.13 Tensor products and duals of represen tations of Lie algebras . . . . . . . . . . . . . . 20
1.14 Represen tations of sl(2) .................................. 20
1.15Problems onLiealgebras ................................. 21
2 General results of represen tation theory 23
2.1 Subrepresen tations in semisimple represen tations . . . . . . . . . . . . . . . . . . . . 23
2.2 Thedensit ytheorem .................................... 24
2.3 Represen tations ofdirect sums ofmatrix algebras .................... 24
2.4 Filtrations .......................................... 25
2.5 Finite dimensional algebras ................................ 26
1</text>
        </slide>
        <slide>
          <slideno>48</slideno>
          <text>Proof. Let V = C[G] be the regular represen tation of G. Consider the operator-v alued polynomial
L(x)=  
xg(g), 
gG 
where (g)  EndV is induced by g. The action of L(x) on an elemen t h  G is 
L(x)h =  
xg(g)h =  
xggh =  
xzh1 z 
gG gG zG 
So the matrix of the linear operator L(x) in the basis g1,g2,...,gn is XG with permuted columns 
and hence has the same determinan t up to sign. 
Further, by Maschkes theorem, we have 
r
detV L(x)= 
(detVi L(x))dim Vi , 
i=1 
where Vi are the irreducible represen tations of G. We set Pi = detVi L(x). Let {eim} be bases of Vi 
and Ei,jk  End Vi be the matrix units in these bases. Then {Ei,jk} is a basis of C[G] and 
L(x) Vi =  
yi,jkEi,jk, |
j,k 
where yi,jk are new coordinates on C[G] related to xg by a linear transformation. Then 
Pi(x) = det |L(x) = det(yi,jk) Vi 
Hence, Pi are irreducible (by Lemma 4.8) and not proportional to each other (as they depend on 
dieren t collections of variables yi,jk). The theorem is proved. 
4.3 Algebraic numbers and algebraic integers 
We are now passing to deeper results in represen tation theory of nite groups. These results require 
the theory of algebraic numbers, which we will now briey review. 
Denition 4.9. z  C is an algebraic number (respectively, an algebraic integer), if z is a 
root of a monic polynomial with rational (respectively, integer) coecien ts. 
Denition 4.10. z  C is an algebraic number, (respectively, an algebraic integer), if z is an 
eigenvalue of a matrix with rational (respectively, integer) entries. 
Proposition 4.11. Denitions (4.9) and (4.10) are equivalent. 
Proof. To show (4.10)  (4.9), notice that z is a root of the characteristic polynomial of the matrix 
(a monic polynomial with rational, respectively integer, coecien ts). 
To show (4.9)  (4.10), suppose z is a root of 
p(x)= x n + a1x n1 + ... + an1x + an. 
Then the characteristic polynomial of the following matrix (called the companion matrix) is 
p(x): 
49</text>
        </slide>
        <slide>
          <slideno>57</slideno>
          <text>(a) Z2 
(b) Z3 
(c) Z5 
(d) A4 
(e) Z2  Z2 
4.12 Represen tations of Sn 
In this subsection we give a description of the represen tations of the symmetric group Sn for any 
n. 
Denition 4.35. A partition  of n is a represen tation of n in the form n = 1 + 2 + ... + p, 
where i are positive integers, and i  i+1. 
To such  we will attach a Young diagram Y, which is the union of rectangles i  y i+1, 
0  x  i in the coordinate plane, for i =1,...,p. Clearly , Y is a collection of n unit squares. A 
Young tableau corresp onding to Y is the result of lling the numbers 1,...,n into the squares of 
Y in some way (without repetitions). For example, we will consider the Young tableau T obtained 
by lling in the numbers in the increasing order, left to right, top to bottom. 
We can dene two subgroups of Sn corresp onding to T: 
1. The row subgroup P: the subgroup which maps every elemen t of {1,...,n} into an elemen t 
standing in the same row in T. 
2. The column subgroup Q: the subgroup which maps every elemen t of {1,...,n} into an 
elemen t standing in the same column in T. 
Clearly , P  Q = {1}. 
Dene the Young projectors: 
a := 1  
g, |P| gP 
b := 1  
(1)gg,
|Q| gQ
where (1)g denotes the sign of the permutation g. Set c = ab. Since P  Q = {1}, this
elemen t is nonzero. 
The irreducible represen tations of Sn are describ ed by the following theorem. 
Theorem 4.36. The subspace V := C[Sn]c of C[Sn] is an irreducible representation of Sn under 
left multiplic ation. Every irreducible representation of Sn is isomorphic to V for a unique . 
The modules V are called the Specht modules. 
The proof of this theorem is given in the next subsection. 
Example 4.37. 
For the partition  =(n), P = Sn, Q = {1}, so c is the symmetrizer, and hence V is the trivial 
represen tation. 
58</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch6</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch6/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>For this reason in category theory, one most of the time tries to avoid saying that two objects 
or two functors are equal. In particular, this applies to the denition of isomorphism of categories. 
Namely, the naive notion of isomorphism of categories is dened in the obvious way: a functor 
F : C  D is an isomorphism if there exists F 1 : D  C such that F  F 1 and F 1  F are equal 
to the identity functors. But this denition is not very useful. We might suspect so since we have 
used the word equal for objects of a category (namely, functors) which we are not supposed to 
do. And in fact here is an example of two categories which are the same for all practical purposes 
but are not isomorphic; it demonstrates the deciency of our denition. 
Namely, let C1 be the simplest possible category: Ob(C 1) consists of one object X, with 
Hom(X,X ) = {1X }. Also, let C2 have two objects X,Y and 4 morphisms: 1X , 1Y ,a : X  Y 
and b : Y  X. So we must have a  b = 1Y , b  a = 1X . 
It is easy to check that for any category D, there is a natural bijection between the collections 
of isomorphism classes of functors C1  D and C2  D (both are identied with the collection of 
isomorphism classes of objects of D). This is what we mean by saying that C1 and C2 are the same 
for all practical purposes. Nevertheless they are not isomorphic, since C1 has one object, and C2 
has two objects (even though these two objects are isomorphic to each other). 
This shows that we should adopt a more exible and less restrictive notion of isomorphism of 
categories. This is accomplished by the denition of an equivalence of categories. 
 Denition 6.8. A functor F : C  D is an equivalence of categories if there exists F : D  C 
such that   F  F and F  F are isomorphic to the identity functors. 
In this situation, F  is said to be a quasi-inverse to F . 
In particular, the above categories C1 and C2 are equivalent (check it!). 
Also, the category FSet of nite sets is equivalent to the category whose objects are nonneg
ative integers, and morphisms are given by Hom(m,n) = Maps({1,...,m} , {1,...,n} ). Are these 
categories isomorphic? The answer to this question depends on whether you believe that there 
is only one nite set with a given number of elements, or that there are many of those. It seems 
better to think that there are many (without asking how many), so that isomorphic sets need not 
be literally equal, but this is really a matter of choice. In any case, this is not really a reasonable 
question; the answer to this question is irrelevant for any practical purpose, and thinking about it 
will give you nothing but a headache. 
6.5 Representable functors 
A fundamental notion in category theory is that of a representable functor. Namely, let C be a 
(locally small) category, and F : C  Sets be a functor. We say that F is representable if there 
exists an object X  C such that F is isomorphic to the functor Hom(X, ?). More precisely, if we 
are given such an object X, together with an isomorphism  : F = Hom(X, ?), we say that the 
functor F is represented by X (using ). 
In  a similar way, one can talk about representable functors from Copto Sets. Namely, one 
calls such a functor representable if it is of the form Hom(?,X ) for some object X  C, up to an 
isomorphism. 
Not every functor is representable, but if a representing object X exists, then it is unique. 
Namely, we have the following lemma.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>8. We have an obvious notion of the Cartesian product of categories (obtained by taking the 
Cartesian products of the classes of objects and morphisms of the factors). The functors of direct 
then  sum and tensor product are functors Vect k Vect k  Vect k. Also the operations V  V n, 
V  SnV , V  nV are functors on Vect k. More generally, if  is a representation of Sn, we 
have functors V  HomnSn (,V ). Such functors (for irreducible ) are called the Schur functors. 
They are labeled by Young diagrams. 
9. The reection functors Fi : Rep(Q)  Rep( Qi) are functors between representation cate
gories of quivers. 
6.3 Morphisms of functors 
One of the important features of functors between categories which distinguishes them from usual 
maps or functions is that the functors between two given categories themselves form a category, 
i.e., one can dene a nontrivial notion of a morphism between two functors. 
Denition 6.6. Let C, D be categories and F,G : C  D be functors between them. A morphism 
a : F  G (also called a natural transformation or a functorial morphism) is a collection of 
morphisms aX : F (X)  G(X) labeled by the objects X of C, which is functorial in X, i.e., for 
any morphism f : X  Y (for X,Y  C) one has aY  F (f) = G(f)  aX . 
               1 A morphism a:F G is an isomorphism if there is another morphism a: G  F such that 
a  a1 and a1  a are the identities. The set of morphisms from F to G is denoted by Hom(F,G). 
Example 6.7. 1. Let FVect k be the category of nite dimensional vector spaces over k. Then the 
functors id and  on this category are isomorphic. The isomorphism is dened by the standard 
maps aV : V   V given by aV (u)(f) = f(u), u  V , f  V . But these two functors are not 
isomorphic on the category of all vector spaces Vect k, since for an innite dimensional vector space 
V , V is not isomorphic to V . 
2. Let FVect
k be the category of nite dimensional k-vector spaces, where the morphisms 
are the isomorphisms. We have a functor F from this category to itself sending any space V to 
  V and any morphism a to (a)1. This functor satises the property that V is isomorphic to 
F (V ) for any V , but it is not isomorphic to the identity functor. This is because the isomorphism 
 V  F (V ) = V cannot be chosen to be compatible with the action of GL(V ), as V is not 
isomorphic to V  as a representation of GL(V ). 
3. Let A be an algebra over a eld k, and F : A  mod  Vect k be the forgetful functor. 
Then as follows from Problem 1.22, EndF = Hom(F,F ) = A. 
4. The set of endomorphisms of the identity functor on the category A  mod is the center of 
A (check it!). 
6.4 Equivalence of categories 
When two algebraic or geometric objects are isomorphic, it is usually not a good idea to say that 
they are equal (i.e., literally the same). The reason is that such objects are usually equal in many 
dierent ways, i.e., there are many ways to pick an isomorphism, but by saying that the objects are 
equal we are misleading the reader or listener into thinking that we are providing a certain choice 
of the identication, which we actually do not do. A vivid example of this is a nite dimensional 
vector space V and its dual space V .</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 18.712 Introduction to Representation Theory
Fall 2010</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Lemma 6.9. (The Yoneda Lemma) If a functor F is represented by an object X, then X is unique 
up to a unique isomorphism. I.e., if X,Y are two objects in C, then for any isomorphism of functors 
 : Hom(X, ?)  Hom(Y, ?) there is a unique isomorphism a : X  Y inducing . 
Proof. (Sketch) One sets a= 1
 Y (1Y ), and shows that it is invertible by constructing the inverse, 
which  is a1
 = X (1X ). It remains to show that the composition both ways is the identity, which 
we will omit here. This establishes the existence of a. Its uniqueness is veried in a straightforward 
manner. 
Remark. In a similar way, if a category C is enriched over another category D (say, the category 
of abelian groups or vector spaces), one can dene the notion of a representable functor from C to 
D. 
Example 6.10. Let A be an algebra. Then the forgetful functor to vector spaces on the category 
of left A-modules is representable, and the representing object is the free rank 1 module (=the 
regular representation) M = A. But if A is innite dimensional, and we restrict attention to the 
category of nite dimensional modules, then the forgetful functor, in general, is not representable 
(this is so, for example, if A is the algebra of complex functions on Z which are zero at all points 
but nitely many). 
6.6 Adjoint functors 
Another fundamental notion in category theory is the notion of adjoint functors. 
Denition 6.11. Functors F : C  D and G : D  C are said to be a pair of adjoint functors if for 
any X  C, Y  D we are given an isomorphism XY : Hom C (F (X),Y )  Hom (X,G(Y )) which is D
functorial in X and Y ; in other words, if we are given an isomorphism of functors Hom(F (?), ?) 
Hom(?,G(?)) (C  D  Sets). In this situation, we say that F is left adjoint to G and G is right 
adjoint to F . 
Not every functor has a left or right adjoint, but if it does, it is unique and can be constructed 
canonically (i.e., if we somehow found two such functors, then there is a canonical isomorphism 
between them). This follows easily from the Yoneda lemma, as if F,G are a pair of adjoint functors 
then F (X) represents the functor Y  Hom(X,G(Y )), and G(Y ) represents the functor X 
Hom(F (X),Y ). 
Remark 6.12. The terminology left and right adjoint functors is motivated by the analogy 
between categories and inner product spaces. More specically, we have the following useful dic
tionary between category theory and linear algebra, which helps understand better many notions 
of category theory.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>6 Introduction to categories 
6.1 The denition of a category 
We have now seen many examples of representation theories and of operations with representations 
(direct sum, tensor product, induction, restriction, reection functors, etc.) A context in which one 
can systematically talk about this is provided by Category Theory. 
Category theory was founded by Saunders MacLane and Samuel Eilenberg around 1940. It is a 
fairly abstract theory which seemingly has no content, for which reason it was christened abstract 
nonsense. Nevertheless, it is a very exible and powerful language, which has become totally 
indispensable in many areas of mathematics, such as algebraic geometry, topology, representation 
theory, and many others. 
We will now give a very short introduction to Category theory, highlighting its relevance to the 
topics in representation theory we have discussed. For a serious acquaintance with category theory, 
the reader should use the classical book [McL]. 
Denition 6.1. A category C is the following data: 
(i) a class of objects Ob(C); 
(ii) for every objects X,Y  Ob(C), the class Hom  (X,Y ) = Hom(X,Y ) of morphisms (or C
arrows) from X,Y (for f  Hom(X,Y ), one may write f : X  Y ); 
(iii) For any objects X,Y,Z  Ob(C), a composition map Hom(Y,Z )Hom(X,Y )  Hom(X,Z ), 
(f,g)  f  g, 
which satisfy the following axioms: 
1. The composition is associative, i.e., (f  g)  h = f  (g  h); 
2. For each X  Ob(C), there is a morphism 1X  Hom(X,X ), called the unit morphism, such 
that 1X  f = f and g  1X = g for any f,g for which compositions make sense. 
Remark. We will write X  C instead of X  Ob(C). 
Example 6.2. 1. The category Sets of sets (morphisms are arbitrary maps). 
2. The categories Groups , Rings (morphisms are homomorphisms). 
3. The category Vect k of vector spaces over a eld k (morphisms are linear maps). 
4. The category Rep(A) of representations of an algebra A (morphisms are homomorphisms of 
representations). 
5. The category of topological spaces (morphisms are continuous maps). 
6. The homotopy category of topological spaces (morphisms are homotopy classes of continuous 
maps). 
Important remark. Unfortunately, one cannot simplify this denition by replacing the word 
class by the much more familiar word set. Indeed, this would rule out the important Example 1, 
as it is well known that there is no set of all sets, and working with such a set leads to contradictions. 
The precise denition of a class and the precise distinction between a class and a set is the subject 
of set theory, and cannot be discussed here. Luckily, for most practical purposes (in particular, in 
these notes), this distinction is not essential.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Dictionary between category theory and linear algebra
Category C Vector space V with a nondegenerate inner product 
The set of morphisms Hom(X,Y ) Inner product (x,y) on V (maybe nonsymmetric) 
Opposite category Cop Same space V with reversed inner product 
The category Sets The ground eld k 
Full subcategory in C Nondegenerate subspace in V 
Functor F : C  D Linear operator f : V  W 
Functor F : C  Sets Linear functional f  V  = Hom(V,k ) 
 Representable functor Linear functional f  V given by f(v) = (u,v ), u  V 
Yoneda lemma Nondegeneracy of the inner product (on both sides) 
Not all functors are representable If dim V = , not f  V , f(v) = (u,v ) 
Left and right adjoint functors Left and right adjoint operators 
Adjoint functors dont always exist Adjoint operators may not exist if dim V = 
If they do, they are unique If they do, they are unique 
Left and right adjoints may not coincide The inner product may be nonsymmetric 
Example 6.13. 1. Let V be a nite dimensional representation of a group G or a Lie algebra g. 
Then the left and right adjoint to the functor V  on the category of representations of G is the 
functor V . 
 2. The functor ResGis left adjoint to IndG
K K . This is nothing but the statement of the Frobenius 
reciprocity. 
3. Let Assoc k be the category of associative unital algebras, and Liek the category of Lie 
algebras over some eld k. We have a functor L : Assoc k  Liek, which attaches to an associative 
algebra the same space regarded as a Lie algebra, with bracket [a,b] = ab  ba. Then the functor L 
has a left adjoint, which is the functor U of taking the universal enveloping algebra of a Lie algebra. 
4. We have the functor GL1 : Assoc k  Groups , given by A  GL1(A) = A. This functor 
has a left adjoint, which is the functor G  k[G], the group algebra of G. 
5. The left adjoint to the forgetful functor Assoc k  Vect k is the functor of tensor algebra: 
V  TV . Also, if we denote by Comm k the category of commutative algebras, then the left adjoint 
to the forgetful functor Comm k  Vect k is the functor of the symmetric algebra: V  SV . 
One can give many more examples, spanning many elds. These examples show that adjoint 
functors are ubiquitous in mathematics. 
6.7 Abelian categories 
The type of categories that most often appears in representation theory is abelian categories. 
The standard denition of an abelian category is rather long, so we will not give it here, referring 
the reader to the textbook [Fr]; rather, we will use as the denition what is really the statement of 
the Freyd-Mitchell theorem: 
Denition 6.14. An abelian category is a category (enriched over the category of abelian groups), 
which is equivalent to a full subcategory C of the category A-mod of left modules over a ring A, 
closed under taking nite direct sums, as well as kernels, cokernels, and images of morphisms. 
We see from this denition that in an abelian category, Hom(X,Y ) is an abelian group for each 
X,Y , compositions are group homomorphisms with respect to each argument, there is the zero ob
ject, the notion of an injective morphism (monomorphism) and surjective morphism (epimorphism), 
and every morphism has a kernel, a cokernel, and an image.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Denition 6.21. An abelian category C is semisimple if any short exact sequence in this category 
splits, i.e., is isomorphic to a sequence 
0  X  X  Y  Y  0 
(where the maps are obvious). 
Example 6.22. The category of representations of a nite group G over a eld of characteristic 
not dividing |G| (or 0) is semisimple. 
Note that in a semisimple category, any additive functor is automatically exact on both sides. 
Example 6.23. (i) The functors IndG
K , ResG 
K are exact. 
(ii) The functor Hom(X, ?) is left exact, but not necessarily right exact. To see that it need not 
be right exact, it suces to consider the exact sequence 
0  Z  Z  Z/2Z  0, 
and apply the functor Hom(Z/2Z, ?). 
(iii) The functor XA for a right A-module X (on the category of left A-modules) is right exact, 
but not necessarily left exact. To see this, it suces to tensor multiply the above exact sequence 
by Z/2Z. 
Exercise. Show that if (F,G) is a pair of adjoint additive functors between abelian categories, 
then F is right exact and G is left exact. 
Exercise. (a) Let Q be a quiver and i  Q a source. Let V be a representation of Q, and W a 
representation of Qi (the quiver obtained from Q by reversing arrows at the vertex i). Prove that  
there is a natural isomorphism between Hom FiV,W and Hom V,F+
i W . In other words, the
functor F
+
i is right adjoint to Fi.
 
(b) Deduce that the functor F
+
i is   left exact, and Fiis right exact.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>We also mention that in many examples, including examples 1-6, the word class in (ii) can 
be replaced by set. Categories with this property (that Hom(X,Y ) is a set for any X,Y ) are 
called locally small; many categories that we encounter are of this kind. 
Sometimes the collection Hom(X,Y ) of morphisms from X to Y in a given locally small category 
C is not just a set but has some additional structure (say, the structure of an abelian group, or a 
vector space over some eld). In this case one says that C is enriched over another category D
(which is a monoidal category, i.e., has a product operation and a unit object under this product, e.g. 
the category of abelian groups or vector spaces with the tensor product operation). This means that 
for each X,Y  C, Hom(X,Y ) is an object of D, and the composition Hom(Y,Z )  Hom(X,Y ) 
Hom(X,Z ) is a morphism in D. E.g., if D is the category of vector spaces, this means that the 
composition is bilinear, i.e. gives rise to a linear map Hom(Y,Z )  Hom(X,Y )  Hom(X,Z ). For 
a more detailed discussion of this, we refer the reader to [McL]. 
Example. The category Rep(A) of representations of a k-algebra A is enriched over the 
category of k-vector spaces. 
Denition 6.3. A full subcategory of a category C is a category C whose objects are a subclass 
of objects of C, and Hom  (X,Y ) = Hom C C (X,Y ). 
Example. The category AbelianGroups is a full subcategory of the category Groups. 
6.2 Functors 
We would like to dene arrows between categories. Such arrows are called functors. 
Denition 6.4. A functor F : C  D between categories C and D is 
(i) a map F : Ob(C)  Ob(D); 
(ii) for each X,Y  C, a map F = FX,Y : Hom(X,Y )  Hom(F (X),F (Y )) which preserves 
compositions and identity morphisms. 
Note that functors can be composed in an obvious way. Also, any category has the identity 
functor. 
Example 6.5. 1. A (locally small) category C with one object X is the same thing as a monoid. 
A functor between such categories is a homomorphism of monoids. 
2. Forgetful functors Groups  Sets, Rings  AbelianGroups . 
3. The opposite category of a given category is the same category with the order of arrows and 
compositions reversed.  Then V  V is a functor Vect k  op Vect .k 
4. The Hom functors: If C is a locally small category then we have the functor C  Sets given 
by Y   Hom(X,Y ) and Cop Sets given by Y  Hom(Y,X ). 
5. The assignment X  Fun(X, Z) is a functor Sets  Ringsop. 
6. Let Q be a quiver. Consider the category C(Q) whose objects are the vertices and morphisms 
are oriented paths between them. Then functors from C(Q) to Vect k are representations of Q over 
k. 
7. Let K G be groups. Then we have the induction functor G IndK : Rep(K )  Rep(G), and 
 ResG
K : Rep(G)  Rep(K ).</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Example 6.15. The category of modules over an algebra A and the category of nite dimensional 
modules over A are abelian categories. 
Remark 6.16. The good thing about Denition 6.14 is that it allows us to visualize objects, 
morphisms, kernels, and cokernels in terms of classical algebra. But the denition also has a big 
drawback, which is that even if C is the whole category A-mod, the ring A is not determined by C. 
In particular, two dierent rings can have equivalent categories of modules (such rings are called 
Morita equivalent). Actually, it is worse than that: for many important abelian categories there 
is no natural (or even manageable) ring A at all. This is why people prefer to use the standard 
denition, which is free from this drawback, even though it is more abstract. 
We say that an abelian category C is k-linear if the groups Hom C (X,Y ) are equipped with 
a structure of a vector space over k, and composition maps are k-linear in each argument. In 
particular, the categories in Example 6.15 are k-linear. 
6.8 Exact functors 
Denition 6.17. A sequence of objects and morphisms 
X0  X1  ...  Xn+1 
in an abelian category is said to be a complex if the composition of any two consecutive arrows 
is zero. The  cohomology of this complex is Hi= Ker (di)/Im(d i1), where di : X  i  Xi+1 (thus 
the cohomology is dened for 1  i  n). The complex is said to be exact in the i-th term if 
Hi = 0, and is said to be an exact sequence if it is exact in all terms. A short exact sequence 
is an exact sequence of the form 
0  X  Y  Z  0. 
Clearly, 0  X  Y  Z  0 is a short exact sequence if and only if X  Y is injective, 
Y  Z is surjective, and the induced map Y/X  Z is an isomorphism. 
Denition 6.18. A functor F between two abelian categories is additive if it induces homomor
phisms on Hom groups. Also, for k-linear categories one says that F is k-linear if it induces k-linear 
maps between Hom spaces. 
It is easy to show that if F is an additive functor, then F (X  Y ) is canonically isomorphic to 
F (X)  F (Y ). 
 Example 6.19. The functors IndG
K , ResG
K , Hom G(V, ?) in the theory of group representations over 
a eld k are additive and k-linear. 
Denition 6.20. An additive functor F : C  D between abelian categories is left exact if for 
any exact sequence 
0  X  Y  Z, 
the sequence 
0  F (X)  F (Y )  F (Z) 
is exact. F is right exact if for any exact sequence 
X  Y  Z  0, 
the sequence 
F (X)  F (Y )  F (Z)  0 
is exact. F is exact if it is both left and right exact.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch7</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch7/</lecture_pdf_url>
      <lectureno>9</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>Now, in the general case, we prove by induction in k that there exists a lift ek of  e0 to A/Ik+1, 
and it is unique up  to conjugation by an element of 1 + I k(this is sucient as I is nilpotent). 
Assume it is true for k = m  1, and let us prove it for k = m. So we have an idempotent 
em1  A/Im, and we have to lift it  to A/Im+1. But (Im)2 = 0 in A/Im+1, so we are done. 
Denition 7.4. A complete system of orthogonal idempotents in a unital algebra B is a collection 
of elements e1,...,e n  B such that eiej = ijei, and n 
i=1 ei = 1. 
Corollary 7.5. Let e01,...,e 0m be a complete system of orthogonal idempotents in A/I. Then there  exists a complete system of orthogonal idempotents e1,...,e m (eiej = ijei, ei = 1) in A which 
lifts e01,...,e 0m. 
Proof. The proof is by induction in m. For m = 2 this follows from Proposition 7.3. For m &gt; 2, 
we lift e01 to e1 using Proposition 7.3, and then apply the induction assumption to the algebra 
(1  e1)A(1  e1). 
7.3 Projective covers 
Obviously, every nitely generated projective module over a nite dimensional algebra A is a direct 
sum of indecomposable projective modules, so to understand nitely generated projective modules 
over A, it suces to classify indecomposable ones. 
Let A be a nite dimensional algebra, with simple modules M1,...,M n. 
Theorem 7.6. (i) For each i = 1,...,n there exists a unique indecomposable nitely generated 
projective module Pi such that dim Hom(Pi,Mj ) = ij . 
(ii) A = n 
i=1(dim Mi)Pi. 
(iii) any indecomposable nitely generated projective module over A is isomorphic to Pi for 
some i. 
Proof.  Recall that A/Rad(A) = n
i=1 End(M i), and Rad(A) is a nilpotent ideal. Pick a basis of 
   Mi, and let e0Ei
ij = jj, the rank 1 projectors projecting to the basis vectors of this basis (j = 
 1,..., dim Mi). Then e0
ij are orthogonal idempotents in A/Rad(A). So by Corollary 7.5 we can lift 
them to orthogonal idempotents  edim  ij in A. Now dene Pij = AeMiij . Then A = i  j=1 Pij , so Pij
are projective. Also, we have Hom(P ij ,Mk) = eij Mk, so dim Hom(P ij ,Mk) = ik. Finally, Pij is 
               independent of jup to an isomorphism, as eij for xediare conjugate under Aby Proposition 
7.3; thus we will denote Pij by Pi. 
We claim that Pi is indecomposable. Indeed, if Pi = Q1  Q2, then Hom(Q l,Mj ) = 0 for all j 
either for l = 1 or for l = 2, so either Q1 = 0 or Q2 = 0. 
Also, there can be no other indecomposable nitely generated projective modules, since any 
such module has to occur in the decomposition of A. The theorem is proved. 
References 
[BGP] J. Bernstein, I. Gelfand, V. Ponomarev, Coxeter functors and Gabriels theorem, Russian 
Math. Surveys 28 (1973), no. 2, 1732.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>7 Structure of nite dimensional algebras 
In this section we return to studying the structure of nite dimensional algebras. Throughout the 
section, we work over an algebraically closed eld k (of any characteristic). 
7.1 Projective modules 
Let A be an algebra, and P be a left A-module. 
Theorem 7.1. The following properties of P are equivalent: 
(i) If  : M  N is a surjective morphism, and  : P  N any morphism, then there exists a 
morphism  : P  M such that    = . 
(ii) Any surjective morphism  : M  P splits, i.e., there exists  : P  M such that  = id. 
(iii) There exists another A-module Q such that P  Q is a free A-module, i.e., a direct sum of 
copies of A. 
(iv) The functor Hom A(P, ?) on the category of A-modules is exact. 
Proof. To prove that (i) implies (ii), take N = P . To prove that (ii) implies (iii), take M to be free 
(this can always be done since any module is a quotient of a free module). To prove that (iii) implies 
(iv), note that the functor Hom A(P, ?) is exact if P is free (as Hom A(A,N) = N), so the statement 
follows, as if the direct sum of two complexes is exact, then each of them is exact. To prove that 
(iv) implies (i), let K be the kernel of the map , and apply the exact functor Hom A(P, ?) to the 
exact sequence 
0  K  M  N  0. 
Denition 7.2. A module satisfying any of the conditions (i)-(iv) of Theorem 7.1 is said to be 
projective. 
7.2 Lifting of idempotents 
Let A be a ring, and I A a nilpotent ideal. 
Proposition 7.3. Let e0  A/I  be an idempotent, i.e., e2
0 = e0. There exists an idempotent e  A
which is a lift of e0 (i.e., it projects to e0 under the reduction modulo I). This idempotent is unique 
up to conjugation by an element of 1 + I. 
Proof. Let us rst establish the statement in the case when  I 2= 0. Note that in this case I is a 
left and right module over   A/I. Let e be any lift of e20 to A. Then e  e = a  I, and e a = ae.     0 0
We look for e in the form e = e + b, b  I. The equation for b is e0b + be0  b = a. 
Set b = (2e0  1)a. Then 
e0b + be0  b = 2e 0a  (2e0  1)a = a, 
so  e is an idempotent. To classify other  solutions, set e= e + c. For eto be an idempotent, we 
must have ec + ce  c = 0. This is equivalent to saying that ece = 0 and (1  e)c(1  e) = 0, so 
c  = ec(1  e) + (1   e)ce = [e, [e,c]]. Hence e= (1 + [c,e])e(1 + [c,e])1.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>[Cu]	 C. Curtis, Pioneers of Representation Theory: Frobenius, Burnside, Schur, and Brauer, AMS, 
1999. 
[CR] C. Curtis and I. Reiner, Representation Theory of Finite Groups and Associative Algebras, 
AMS, 2006. 
[FH]	 W. Fulton and J. Harris, Representation Theory, A rst course, Springer, New York, 1991. 
[Fr]	 Peter J. Freyd, Abelian Categories, an Introduction to the Theory of Functors. Harper and 
Row (1964). 
[McL] S. MacLane, Categories for a working Mathematician: 2nd Ed., Graduate Texts in Mathe
matics 5, Springer, 1998.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 18.712 Introduction to Representation Theory
Fall 2010</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch2</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_ch2/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>9</slideno>
          <text>Proof. (i) By the density theorem, the maps A  End V and B  End W are surjective. Therefore, 
the map A  B  End V  End W = End(V  W ) is surjective. Thus, V  W is irreducible. 
(ii)  First we show the existence of V and W . Let A,Bbe the images of A,B in End M. Then 
A   ,Bare nite dimensional algebras, and M is a representation of A B, so we may assume 
without loss of generality that A and B are nite dimensional. 
In this case, we claim that Rad(A  B) = Rad(A)  B + A  Rad(B ). Indeed, denote the latter 
by J. Then J is a nilpotent ideal in A  B, as Rad(A) and Rad(B ) are nilpotent. On the other 
hand, (A  B)/J = (A/Rad(A))  (B/Rad(B )), which is a product of two semisimple algebras, 
hence semisimple. This implies J  Rad(A  B). Altogether, by Proposition 2.11, we see that 
J = Rad(A  B), proving the claim. 
Thus, we see that 
(A  B)/Rad(A  B) = A/Rad(A)  B/Rad(B ). 
Now, M is an irreducible representation of (A  B)/Rad(A  B), so it is clearly of the form 
M = V  W , where V is an irreducible representation of A/Rad(A) and W is an irreducible 
representation of B/Rad(B ), and V,W are uniquely determined by M (as all of the algebras 
involved are direct sums of matrix algebras).</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>2.5 Finite dimensional algebras 
Denition 2.9. The radical of a nite dimensional algebra A is the set of all elements of A which 
act by 0 in all irreducible representations of A. It is denoted Rad(A). 
Proposition 2.10. Rad(A) is a two-sided ideal. 
Proof. Easy. 
Proposition 2.11. Let A be a nite dimensional algebra. 
(i) Let  I be a nilpotent two-sided ideal in A, i.e., I n= 0 for some n. Then I  Rad(A).
(ii) Rad(A) is a nilpotent ideal. Thus, Rad(A) is the largest nilpotent two-sided ideal in A. 
Proof. (i) Let V be an irreducible representation of A. Let v  V . Then Iv V is a subrepresen
tation. If Iv = 0 then Iv = V so there is x  I such that xv = v. Then xn= 0, a contradiction. 
Thus Iv = 0, so I acts by 0 in V and hence I  Rad(A).
(ii) Let 0 = A0  A1 ... An = A be a ltration of the regular representation of A by 
subrepresentations such that Ai+1/Ai are irreducible. It exists by Lemma 2.8. Let x  Rad(A). 
Then   xacts on Ani+1/Ai by zero, so x maps Ai+1 to Ai. This implies that Rad(A) = 0, as 
desired. 
Theorem 2.12. A nite dimensional algebra A has only nitely many irreducible representations 
Vi up to isomorphism, these representations are nite dimensional, and 
A/Rad (A)  
= End Vi.
i 
Proof. First, for any irreducible representation V of A, and for any nonzero v  V , Av  V is a 
nite dimensional subrepresentation of V . (It is nite dimensional as A is nite dimensional.) As 
V is irreducible and Av = 0, V = Av and V is nite dimensional. 
Next, suppose we have non-isomorphic irreducible representations V1,V2,...,V r. By Theorem 
2.5, the homomorphism   
i : A   
End Vi 
i i 
is surjective. So r  
i dimEnd Vi  dim A. Thus, A has only nitely many non-isomorphic 
irreducible representations (at most dim A). 
Now, let V1,V2,...,V r be all non-isomorphic irreducible nite dimensional representations of 
A. By Theorem 2.5, the homomorphism 
  
i : A   
End Vi 
i i 
is surjective. The kernel of this map, by denition, is exactly Rad(A). 
Corollary 2.13. 
i (dim 2 Vi) dim A, where the Vis are the irreducible representations of A. 
Proof. As dim End Vi = 2
(dim Vi) , Theorem 2.12 implies that dim AdimRad(A) = i dimEnd Vi = 
2 2 
i(dim Vi) . As dim Rad(A)  0, i (dim Vi) dim A.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2.2 The density theorem 
Let A be an algebra over an algebraically closed eld k. 
Corollary 2.4. Let V be an irreducible nite dimensional representation of A, and v1,...,v n  V 
be any linearly independent vectors. Then for any w1,...,w n  V there exists an element a  A 
such that avi = wi. 
Proof. Assume the contrary. Then the image of the map A  nV given by a  (av1,...,av n) is a 
proper subrepresentation, so by Proposition 2.2 it corresponds to an r-by-n matrix X, r&lt;n. Thus, 
taking a = 1, we see that there exist vectors u1,...,u r  V such that (u1,...,u r)X = (v1,...,vn). Let  (q1,...,q n) be a nonzero  vector such that X(q1,...,q n)T= 0 (it exists because r&lt;n). Then q ivi = 
 (uT1,...,u r )X(q1,...,q n) = 0, i.e. qivi = 0 - a contradiction with the linear independence of 
vi. 
Theorem 2.5. (the Density Theorem). (i) Let V be an irreducible nite dimensional representation 
of A. Then the map  : A  EndV is surjective. 
(ii) Let V = V1  ...  Vr, where Vi are irreducible pairwise nonisomorphic nite dimensional 
r representations of A. Then   the map r
i=1i : A  i=1 End(V i) is surjective. 
Proof. (i) Let B be the image of A in End(V ). We want to show that B = End(V ). Let c  End(V ), 
v1,...,v n be a basis of V , and wi = cvi. By Corollary 2.4, there exists a  A such that avi = wi. 
Then a maps to c, so c  B, and we are done. 
(ii) Let   B End(Vri be the image of A in i), and B be the image of A in i=1 End(V i). Recall that as 
 of   a representation A, ri=1 End(V i) is semisimple: it is isomorphic to r
i=1diVi, where di = dim Vi.
Then by Proposition 2.2, B = iBi. On the other hand, (i) implies that Bi = End(V i). Thus (ii) 
follows. 
2.3 Representations of direct sums of matrix algebras 
In this section we consider representations of algebras A = i Matdi (k) for any eld k. 
 = rTheorem 2.6. Let Ai=1 Matdi (k). Then the irreducible
 representations of A are V1 = 
kd1 ,...,Vdr = kr , and any nite dimensional representation of A is a direct sum of copies of 
V1,...,V r. 
In order to prove Theorem 2.6, we shall need the notion of a dual representation. 
Denition 2.7. (Dual representation) Let V be a representation of any algebra A. Then the 
  dual representation V is the representation of the opposite algebra Aop(or, equivalently, right 
A-module) with the action 
(f a)(v) := f(av).
Proof of Theorem 2.6. First, the given representations are clearly irreducible, as for any v = 0,w 
Vi, there exists a  A such that av = w. Next, let X be an n-dimensional representation of 
A. Then, X is an n-dimensional oprepresentation of Aop. But  (Mat di (k))= Matdi (k) with 
      isomorphism (X) = XT, as (BC )T= CTBT. Thus, A = Aopand Xmay be viewed as an 
n-dimensional representation of A. Dene 
 : A      A  X
 
n copies</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>by 
(a1,...,a n) = a1y1 + + anyn
where {yi} is a basis  of X.  is clearly surjective, as k A. Thus, the dual map : X  An
   n  
   
is injective. But A= Anas representations of A (check it!). Hence, Im = X is a subrepresen
tation of An  . Next, Matdi (k) = diVi, so A = r n r
i=1diVi, A= i=1ndiVi, as a representation of A. 
Hence by Proposition 2.2, X   =r
i=1miVi, as desired. 
Exercise. The goal of this exercise is to give an alternative proof of Theorem 2.6, not using 
any of the previous results of Chapter 2. 
Let A1, A2, ..., An be n algebras with units 11, 12, ..., 1 n, respectively. Let A = A1 A2 ...An. 
Clearly, 1i1j = ij1i, and the unit of A is 1 = 1 1 + 12 + ... + 1n. 
For every representation V of A, it is easy to see that 1iV is a representation of Ai for every 
i  {1, 2,...,n} . Conversely, if V1, V2, ..., Vn are representations of A1, A2, ..., An, respectively, 
then V1  V2  ...  Vn canonically becomes a representation of A (with (a1,a2,...,a n)  A acting 
on V1  V2  ...  Vn as (v1,v2,...,v n)  (a1v1,a2v2,...,a nvn)). 
(a) Show that a representation V of A is irreducible if and only if 1iV is an irreducible repre
sentation of Ai for exactly one i  {1, 2,...,n} , while 1iV = 0 for all the other i. Thus, classify the 
irreducible representations of A in terms of those of A1, A2, ..., An. 
(b) Let d  N. Show that the only irreducible representation of Mat d(k) is kd, and every nite 
dimensional representation of  Mat d(k) is a direct sum of copies of kd. 
Hint: For every (i,j)  {1, 2,...,d} 2, let Eij  Matd(k) be the matrix with 1 in the ith row of the 
jth column and 0s everywhere else. Let V be a nite dimensional representation of Mat d(k). Show 
that V = E11V  E22V  ...  EddV , and that i : E11V  EiiV , v  Ei1v is an isomorphism for 
every i  {1, 2,...,d} . For every v  E11V , denote S (v) = E11v,E21v,...,E d1v. Prove that S (v) 
is a  subrepresentation of V isomorphic to kd(as a representation of Matd(k)), and that v  S (v). 
Conclude that V = S (v1)  S (v2)  ...  S (vk), where {v1,v2,...,v k} is a basis of E11V . 
(c) Conclude Theorem 2.6. 
2.4 Filtrations 
Let A be an algebra. Let V be a representation of A. A (nite) ltration of V is a sequence of 
subrepresentations 0 = V0  V1 ...  Vn = V .
Lemma 2.8. Any nite dimensional representation V of an algebra A admits a nite ltration 
0 = V0  V1 ...  Vn = V such that the successive quotients Vi/Vi educible. 1 are irr  
Proof. The proof is by induction in dim(V ). The base is clear, and only the induction step needs 
to be justied. Pick an irreducible subrepresentation V1 V , and consider the representation 
U = V/V1. Then by the induction assumption U has a ltration 0 = U0  U1 ... Un  = U 1
such that Ui/Ui1 are irreducible. Dene Vi for i  2 to be the preimages of U  iunder1  the 
tautological projection V  V/V1 = U. Then 0 = V0  V1 V2 ... Vn = V is a ltration of V
with the desired property.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Remark. Thus, we see that in general, the Krull-Schmidt theorem fails for innite dimensional 
modules. However, it still holds for modules of nite length, i.e., modules M such that any ltration 
of M has length bounded above by a certain constant l = l(M). 
2.9 Problems 
Problem 2.21. Extensions of representations. Let A be an algebra, and V,W be a pair of 
representations of A. We would like to classify representations U of A such that V is a subrepre
sentation of U, and U/V = W . Of course, there is an obvious example U = V  W , but are there 
any others? 
Suppose we have a representation U as above. As a vector space, it can be (non-uniquely) 
identied with V  W , so that for any a  A the corresponding operator U (a) has block triangular 
form   V (a) f(a) U (a) = 
,0 W (a) 
where f : A  Hom k(W,V ) is a linear map. 
(a) What is the necessary and sucient condition on f(a) under which U (a) is a repre
sentation? Maps f satisfying this condition are called (1-)cocycles (of A with coecients in 
Hom k(W,V )). They form a vector space denoted Z1(W,V ). 
(b) Let X : W  V be a linear map. The coboundary of X, dX, is dened to be the function A 
Hom k(W,V ) given by dX(a) = V (a)X XW (a). Show that dX is a cocycle, which vanishes if and 
only if X is a homomorphism of representations. Thus coboundaries form a subspace B 1(W,V ) 
Z1(W,V ), which is isomorphic to Hom k(W,V )/Hom A(W,V ). The quotient Z1(W,V )/B1(W,V ) is 
denoted Ext1(W,V ). 
(c)  Show that if f,f  Z1(W,V  ) and f  f  B1(W,V ) then the corresponding extensions 
U,U are isomorphic representations   of A. Conversely, if : U  U is an isomorphism such that 
(a) =   1V  
0 1 W 
then f  f   B1(V,W ). Thus, the space Ext1(W,V ) classies extensions of W by V . 
(d) Assume that W,V are nite dimensional irreducible representations of A. For any f  
Ext1(W,V ), let Uf be the corresponding extension. Show that Uf is isomorphic to Uf as repre
sentations if and only if f and  f are proportional. Thus isomorphism classes (as representations) 
of nontrivial extensions of W by V (i.e., those not isomorphic to W  V ) are parametrized by the 
projective space PExt1(W,V ). In particular, every extension is trivial if and only if Ext1(W,V ) = 0. 
Problem 2.22. (a) Let A = C[x1,...,x n], and Va,Vb be one-dimensional representations in which 
xi act by ai and bi, respectively (ai,bi  C). Find Ext1(Va,Vb) and classify 2-dimensional repre
sentations of A. 
(b) Let B be the algebra over C generated by x1,...,x n with the dening relations xixj = 0 for 
all i,j. Show that for n &gt; 1 the algebra B has innitely many non-isomorphic indecomposable 
representations. 
Problem 2.23. Let Q be a quiver without oriented cycles, and PQ the path algebra of Q. Find 
irreducible representations of PQ and  compute Ext1between them. Classify 2-dimensional repre
sentations of PQ.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Example 2.14. 1. Let A = k[x]/(xn). This algebra has a unique irreducible representation, which 
is a 1-dimensional space k, in which x acts by zero. So the radical Rad(A) is the ideal (x). 
2. Let A be the algebra of upper triangular n by n matrices. It is easy to check that the 
irreducible representations of A are Vi, i = 1,...,n, which are 1-dimensional, and any matrix x acts 
by xii. So the radical Rad(A) is the ideal of strictly upper triangular matrices (as it is a nilpotent 
ideal and contains the radical). A similar result holds for block-triangular matrices. 
Denition 2.15. A nite dimensional algebra A is said to be semisimple if Rad(A) = 0. 
Proposition 2.16. For a nite dimensional algebra A, the following are equivalent: 
1.	A is semisimple. 
2.	
i (dim 2 Vi) = dim A, where the Vis are the irreducible representations of A. 
3.	A = 
i Matdi (k) for some di.
4. Any nite dimensional representation of	A is completely reducible (that is, isomorphic to a 
direct sum of irreducible representations). 
5.	A is a completely reducible representation of A. 
Proof. As dim AdimRad(A) = 
i	(dim 2) , clearly dim  2A=  Vi i (dim Vi) if and only if Rad(A) = 
0. Thus, (1)  (2). 
Next, by Theorem 2.12, if Rad(A) =	 0, then clearly A = i Matdi (k) for di = dim Vi. Thus, 
(1)  (3). Conversely, if A = i Matdi (k), then by Theorem 2.6,
 Rad(A) = 0, so A is semisimple. 
Thus (3)  (1). 
Next, (3)  (4) by Theorem 2.6. Clearly (4)  (5). To see that (5)  (3), let A = i niVi. 
Consider EndA(A) (endomorphisms of A as a representation of A). As the Vis are pairwise
 non-
isomorphic, by Schurs lemma, no copy of Vi in A can be mapped to a distinct Vj . Also, again by 
Schurs lemma, EndA (Vi) = k.   Thus, EndA(A) =i Matni (k). But EndA(A) = Aopby Problem 
  op      op 
1.22, soA=i	Matni (k). Thus,A=(iMatni (k)) = i Matni(k), as desired. 
2.6 Characters of representations 
Let A be an algebra and V a nite-dimensional representation of A with action . Then the 
character of V is the linear function V : A  k given by 
V (a) = tr|V ((a)).
If [A,A] is the span of commutators [x,y] := xy  yx over all x,y  A, then [A,A]  ker V . Thus, 
we may view the character as a mapping V : A/[A,A]  k. 
Exercise. Show that if WV are nite dimensional representations of A, then V = W +
V/W . 
Theorem 2.17. (i) Characters of (distinct) irreducible nite-dimensional representations of A are 
linearly independent. 
(ii) If A is a nite-dimensional semisimple algebra, then these characters form a basis of 
(A/[A,A]).</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>2 General results of representation theory 
2.1 Subrepresentations in semisimple representations 
Let A be an algebra. 
Denition 2.1. A semisimple (or completely reducible) representation of A is a direct sum of 
irreducible representations. 
Example. Let V be an irreducible representation of A of dimension n. Then Y = End(V ), 
with action of A by left multiplication, is a semisimple representation of A, isomorphic to nV (the 
direct sum of n copies of V ). Indeed, any basis v1,...,v n of V gives rise to an isomorphism of 
representations End(V )  nV , given by x  (xv1,...,xv n). 
Remark. Note that by Schurs lemma, any semisimple representation V of A is canonically 
identied with X Hom A(X,V )X, where X runs over all irreducible representations of A. Indeed, 
we have a natural map f : X Hom(X,V )X  V , given by g x  g(x), x  X, g  Hom(X,V ), 
and it is easy to verify that this map is an isomorphism. 
Well see now how Schurs lemma allows us to classify subrepresentations in nite dimensional 
semisimple representations. 
Proposition 2.2. Let Vi, 1  i  m be irreducible nite dimensional pairwise nonisomorphic 
representations of A, and W be a subrepresentation of V = m
i=1niVi. Then W is isomorphic to 
m i=1riVi, ri  ni, and the inclusion  : W  V is a direct sum of inclusions i : riVi  niVi given 
by multiplication of a row vector of elements of Vi (of length ri) by a certain ri-by-n i matrix Xi 
with linearly independent rows: (v1,...,v ri ) = (v 1,...,v ri )Xi. 
Proof. The proof is mby induction in n := 
i=1 ni. The base of induction (n = 1) is clear. To perform 
the induction step, let us assume that W is nonzero, and x an irreducible subrepresentation 
PW . Such P exists (Problem 1.20). 2 Now, by Schurs lemma, P is isomorphic to Vi for some i,
and the inclusion |P : P  V factors through niVi, and upon identication of P with Vi is given 
by the formula v  (vq1,...,vq ni ), where ql  k are not all zero. 
Now note that the group Gi = GLni (k) of invertible ni-by-n i matrices over k acts on niVi 
by (v1,...,v ni )  (v1,...,v ni )gi (and by the identity on njVj , j = i), and therefore acts on the 
set of subrepresentations of V , preserving the property we need to establish: namely, under the 
action of gi, the matrix Xi goes to Xigi, while Xj ,j = i dont change. Take gi  Gi such that 
(q1,...,q ni )gi = (1, 0,..., 0). Then Wgi contains the rst summand Vi of niVi (namely, it is Pgi), 
 hence Wgi = Vi  W , where W n1V1  ...  (ni  1)Vi  ...  nmVm is the kernel of the projection 
of Wgi to the rst summand Vi along the other summands. Thus the required statement follows 
from the induction assumption. 
Remark 2.3. In Proposition 2.2, it is not important that k is algebraically closed, nor it matters 
that V is nite dimensional. If these assumptions are dropped, the only change needed is that the 
entries of the matrix Xi are no longer in k but in Di = EndA(Vi), which is, as we know, a division 
algebra. The proof of this generalized version of Proposition 2.2 is the same as before (check it!). 
2Another proof of the existence of P , which does not use the nite dimensionality of V , is by induction in n. 
Namely, if W itself is not irreducible, let K be the kernel of the projection of W to the rst summand V1. Then 
K is a subrepresentation of (n1  1)V1  ...  nmVm, which is nonzero since W is not irreducible, so K contains an 
irreducible subrepresentation by the induction assumption.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Proof. (i) If V1,...,V r are nonisomorphic irreducible nite-dimensional representations of A, then 
V1  Vr : A  End V1  End Vr is surjective by the density theorem, so V1 ,..., Vr are   linearly independent. (Indeed, if iVi (a) = 0 for all a  A, then iTr(M i) = 0 for all Mi 
EndkVi. But each tr(M i) can range
 independently over k, so it must 
be that 1 = = r = 0.) 
(ii) First we prove that [Mat d(k), Matd(k)] = sld(k), the set of all matrices with trace 0. It is 
clear that [Mat d(k), Matd(k)]  sld(k). If we denote by Eij the matrix with 1 in the ith row of the 
jth column and 0s everywhere else, we have [Eij ,Ejm] = Eim for i = m, and [Ei,i+1,Ei+1,i] = Eii 
Ei+1,i+1. Now {Eim}{E iiEi+1,i+1 } forms a basis in sld(k), so indeed [Mat d(k), Mat d(k)] = sld(k), 
as claimed. 
By semisimplicity, we can write A = Mat d1 (k)    Matdr (k). Then [A,A] = sld1(k) 
    
sldr (k), and A/[A,A] = kr. By Theorem 2.6, there are exactly r irreducible representations of A 
(isomorphic to kd1 ,...,kdr , respectively), and therefore r linearly independent characters on the 
r-dimensional vector space A/[A,A]. Thus, the characters form a basis. 
2.7 The Jordan-H older theorem 
We will now state and prove two important theorems about representations of nite dimensional 
algebras - the Jordan-H older theorem and the Krull-Schmidt theorem. 
Theorem 2.18. (Jordan-H older theorem). Let V be a nite dimensional representation of A, 
and 0 = V0  V1 ...  Vn = V , 0 = V0... Vm= V be ltrations of V , such that the 
representations Wi := Vi/Vi1 and W i
 := Vi/Vi
1 are irreducible for all i. Then n = m, and there  
exists a permutation  of 1,...,n such that W(i) is isomorphic to Wi. 
Proof. First proof (for k of characteristic zero). The character of V obviously equals the sum 
of characters of Wi, and also the sum of characters of Wi. But by Theorem 2.17, the charac
ters of irreducible representations are linearly independent, so the multiplicity of every irreducible 
representation W of A among Wi and among Wiare the same.  This implies the theorem. 3
Second proof (general). The proof is by induction on dim V . The base of induction is clear, 
so let us prove the induction step. If W1 = W1(as subspaces), we are done, since by the induction 
assumption the theorem holds for V/W 1. So assume W1 = W1. In this case W1  W1= 0 (as 
W1,W 1are irreducible), so we have an embedding f : W1  W1 V . Let U = V/(W 1  W1), and 
0 = U0  U1 ... Up = U be a ltration of U with simple quotients Zi = Ui/Ui1 (it exists by 
Lemma 2.8). Then we see that: 
1) V/W 1 has a ltration with successive quotients W1,Z1,...,Z p, and another ltration with 
successive quotients W2,....,W n. 
2) V/W 1has a ltration with successive quotients W1,Z1,...,Z p, and another ltration with 
successive quotients W2,....,W n. 
By the induction assumption, this means that the collection of irreducible representations with 
multiplicities W1,W 1,Z1,...,Z p coincides on one hand with W1,...,W n, and on the other hand, with 
W1,...,W m. We are done. 
The Jordan-H older theorem shows that the number n of terms in a ltration of V with irre
ducible successive quotients does not depend on the choice of a ltration, and depends only on 
3  This proof does not work in characteristic p because it only implies that the multiplicities of Wi and W
i are the 
same modulo p, which is not sucient. In fact, the character of the representation pV , where V is any representation, 
is zero.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Problem 2.24. Let A be an algebra, and V a representation of A. Let  : A  EndV . A formal 
deformation of V is a formal series 
 = n0 + t1 + ... + t n + ..., 
where i : A  End(V ) are linear maps, 0 = , and (ab) = (a)(b). 
If b(t) = 1 + b1t + b2 2t+ ..., where bi  End(V ), and  is a formal deformation of , then bb1
is also a deformation of , which is said to be isomorphic to . 
(a) Show that if Ext1(V,V ) = 0, then any deformation of  is trivial, i.e., isomorphic to . 
(b) Is the converse to (a) true? (consider the algebra of dual numbers A = k[x]/x2). 
Problem 2.25. The Cliord algebra. Let V be a nite dimensional complex vector space 
equipped with a symmetric bilinear form (, ). The Cliord algebra Cl(V ) is the quotient of the 
tensor algebra TV by the ideal generated by the elements v  v  (v,v)1, v  V . More explicitly, if 
xi, 1  i  N is a basis of V and (xi,xj ) = aij then Cl(V ) is generated by xi with dening relations 
xixj +  xjxi = 2a ij ,x 2
i = aii. 
Thus, if (, ) = 0, Cl(V ) = V . 
(i) Show that if (, ) is nondegenerate then Cl(V ) is semisimple, and has one irreducible repre
sentation of dimension 2n if dim V = 2n (so in this case Cl(V ) is a matrix algebra), and two such 
representations if dim(V ) = 2n +1 (i.e., in this case Cl(V ) is a direct sum of two matrix algebras). 
Hint. In the even case, pick a basis a1,...,a n,b1,...,b n of V in which (ai,aj ) = (b i,bj ) = 0, 
(ai,bj ) = ij /2, and construct a representation of Cl(V ) on S := (a1,...,a n) in which bi acts as 
dierentiation with respect to ai. Show that S is irreducible. In the odd case the situation is 
similar, except there should be an additional basis vector c such that (c,a i) = (c,b i) = 0, (c,c) = 
1, and the action  of c on S may be dened either by (1)degreeor by (1)degree+1, giving two 
representations S+,S(why are they non-isomorphic?). Show that there is no other irreducible 
  representations by nding a spanning set of Cl(V ) with 2dimVelements. 
(ii) Show that Cl(V ) is semisimple if and only if (, ) is nondegenerate. If (, ) is degenerate, what 
is Cl(V )/Rad (Cl(V ))? 
2.10 Representations of tensor products 
Let A,B be algebras. Then A  B is also an algebra, with multiplication (a1  b1)(a2  b2) = 
a1a2  b1b2. 
Exercise. Show that Matm(k)  Matn(k) = Matmn(k).
The following theorem describes irreducible nite dimensional representations of AB in terms 
of irreducible nite dimensional representations of A and those of B. 
Theorem 2.26. (i) Let V be an irreducible nite dimensional representation of A and W an 
irreducible nite dimensional representation of B. Then V  W is an irreducible representation of 
A  B. 
(ii) Any irreducible nite dimensional representation M of A  B has the form (i) for unique 
V and W . 
Remark 2.27. Part (ii) of the theorem typically fails for innite dimensional representations; 
e.g. it fails when A is the Weyl algebra in characteristic zero. Part (i) also may fail. E.g. let 
A = B = V = W = C(x). Then (i) fails, as A  B is not a eld.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 18.712 Introduction to Representation Theory
Fall 2010</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>V . This number is called the length of V . It is easy to see that n is also the maximal length of a 
ltration of V in which all the inclusions are strict. 
The sequence of the irreducible representations W1,...,W n enumerated in the order they appear 
from some ltration of V as successive quoteints is called a Jordan-H older series of V . 
2.8 The Krull-Schmidt theorem 
Theorem 2.19. (Krull-Schmidt theorem) Any nite dimensional representation of A can be uniquely 
(up to an isomorphism and order of summands) decomposed into a direct sum of indecomposable 
representations. 
Proof. It is clear that a decomposition of V into a direct sum of indecomposable representations 
exists, so we just need to prove uniqueness. We will prove it by induction on dim V . Let V = 
V1  ...  Vm = V1 ...  V n. Let is : Vs  V , is: V s
  V , ps : V  Vs, ps: V  V s
 be the natural 
maps associated to these decompositions. Let s = p1i
s np i1 : V1  V1. We  
s have s=1 s = 1. Now 
we need the following lemma. 
Lemma 2.20. Let W be a nite dimensional indecomposable representation of A. Then 
(i) Any homomorphism  : W  W is either an isomorphism or nilpotent; 
(ii) If s : W  W , s = 1,...,n are nilpotent homomorphisms, then so is  := 1 + ... + n. 
Proof. (i) Generalized eigenspaces of  are subrepresentations of W , and W is their direct sum. 
Thus,  can have only one eigenvalue . If  is zero,  is nilpotent, otherwise it is an isomorphism. 
(ii) The proof is by induction in n. The base is clear. To make the induction step (n  1 to n), 
assume that  is not nilpotent. nThen by (i)  is an isomorphism, so i=1 1i = 1. The morphisms 
1i are not isomorphisms, so they are nilpotent. Thus 1  1
= 1+ ... + 1n 1 n1 is an 
isomorphism, which is a contradiction with the induction assumption. 
By the lemma, we nd that for some s, s must be an isomorphism; we may assume that 
s = 1. In this case, V1= Im(p1i1)  Ker(p 1i1), so since V1is indecomposable, we get that 
f := p
1i1 : V1  V1and g := p1i1: V1 V1 are isomorphisms. 
 Let B = j&gt;1Vj , B= j&gt;1Vj; then we have V = V1  B = V1 B. Consider the map 
h :   B  Bdened as a composition of the natural maps B  V  Battached to these 
decompositions. We claim that h is an isomorphism. To show this, it suces to show that Kerh = 0 
(as h is a map between spaces of the same dimension). Assume that v  KerhB. Then v  V1.
On the other hand, the projection of v to V1 is zero, so gv = 0. Since g is an isomorphism, we get 
v = 0, as desired. 
Now by the induction assumption, m = n, and Vj = Vfor some permutation  of 2,...,n. (j) 
The theorem is proved. 
Exercise. Let A be the algebra of real-valued continuous functions on R which are periodic 
with period 1. Let M be the A-module of continuous functions f on R which are antiperiodic with 
period 1, i.e., f(x + 1) = f(x). 
(i) Show that A and M are indecomposable A-modules. 
(ii) Show that A is not isomorphic to M but A  A is isomorphic to M  M.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_intro</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-712-introduction-to-representation-theory-fall-2010/resources/mit18_712f10_intro/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
18.712  Introduction to Representation Theory 
Fall 2010 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>INTRODUCTION 
Very roughly speaking, representation theory studies symmetry in linear spaces. It is a beautiful 
mathematical subject which has many applications, ranging from number theory and combinatorics 
to geometry, probability theory, quantum mechanics and quantum eld theory. 
Representation theory was born in 1896 in the work of the German mathematician F. G. 
Frobenius. This work was triggered by a letter to Frobenius by R. Dedekind. In this letter Dedekind 
made the following observation: take the multiplication table of a nite group G and turn it into a 
matrix XG by replacing every entry g of this table by a variable xg. Then the determinant of XG 
factors into a product of irreducible polynomials in {xg}, each of which occurs with multiplicity 
equal to its degree. Dedekind checked this surprising fact in a few special cases, but could not prove 
it in general. So he gave this problem to Frobenius. In order to nd a solution of this problem 
(which  we will explain below), Frobenius created representation theory of nite groups. 1
The present lecture notes arose from a representation theory course given by the rst author to 
the remaining six authors in March 2004 within the framework of the Clay Mathematics Institute 
Research Academy for high school students, and its extended version given by the rst author to 
MIT undergraduate math students in the Fall of 2008. The lectures are supplemented by many 
problems and exercises, which contain a lot of additional material; the more dicult exercises are 
provided with hints. 
The notes cover a number of standard topics in representation theory of groups, Lie algebras, and 
quivers. We mostly follow [FH], with the exception of the sections discussing quivers, which follow 
[BGP]. We also recommend the comprehensive textbook [CR]. The notes should be accessible to 
students with a strong background in linear algebra and a basic knowledge of abstract algebra. 
Acknowledgements. The authors are grateful to the Clay Mathematics Institute for hosting 
the rst version of this course. The rst author is very indebted to Victor Ostrik for helping him 
prepare this course, and thanks Josh Nichols-Barrer and Thomas Lam for helping run the course 
in 2004 and for useful comments. He is also very grateful to Darij Grinberg for very careful reading 
of the text, for many useful comments and corrections, and for suggesting the Exercises in Sections 
1.10, 2.3, 3.5, 4.9, 4.26, and 6.8. 
1For more on the history of representation theory, see [Cu].</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
