<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/</course_url>
    <course_title>Computation Structures</course_title>
    <course_tags>
      <list>Engineering </list>
      <list>Computer Science </list>
      <list>Mathematics </list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>Virtual machines: timesharing, OS kernels, supervisor calls</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec18/</lecture_pdf_url>
      <lectureno>18</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>L18  Virtual Machines   17  6.004  Spring 2009 4/14/09Communicating with the OS 
User-mode programs need to communicate with OS code: 
      Access virtual I/O devices 
      Communicate with other processes 
       
Solution: 
    Abstraction:         a supervisor call (SVC) with args in registers                                             result in R0 or maybe user-mode memory    Implementation: use illegal instructions to cause an exception --   
                               OS code will recognize these particular illegal                                instructions as a user-mode SVCs But if OS Kernel is in another 
context (ie, not in user-mode address space) how do we get to it? 
Okay
show me how it 
works! 
L18  Virtual Machines   18  6.004  Spring 2009 4/14/09Exception Hardware 
PC+4+4*SXT(C)
ASEL 0 1
Data Memory 
RDWD
AdrR/W
WDSEL 012WA Rc: &lt;25:21&gt;01XPPCJT
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt; Ra: &lt;20:16&gt;
RA2SELRc: &lt;25:21&gt;
+
Register
FileRA1 RA2
RD1 RD2
BSEL 0 1C: SXT(&lt;15:0&gt;)Z
ALUABJTWAWD
WE
ALUFNControl LogicZ
ASEL
BSELPCSEL
RA2SEL
WDSEL
ALUFN
Wr
PC+401
Wr0 1 2 3 4XAdrILL 
OP 
WASEL
WASELIRQWERF
WERF00If (bad opcode) { 
     // Reg[XP] /.notdef.g0001 PC+4;  PC /.notdef.g0001Illop
PCSEL = 3, 
   WASEL = 1, WDSEL = 0, WERF = 1, 
   WR = 0 
}PCSEL0x8000004
Look!  The supervisor bit is on! 
So the 
processor enters kernel mode before rst 
instruction 
of handler is fetched. 
L18  Virtual Machines   19  6.004  Spring 2009 4/14/09Exception Handling 
. = 0x00000004 
BR(I_IllOp) | on Illegal Instruction (eg SVC) 
| Here's the SAVED STATE of the interrupted process, while we're 
| processing an interrupt. UserMState: STORAGE(32) | R0-R31... (PC is in XP!) 
| Here are macros to SAVE and RESTORE state -- 31 registers -- from 
|   the above storage. 
.macro SS(R) ST(R, UserMState+(4*R)) | (Auxiliary macro) 
.macro SAVESTATE() { 
SS(0)  SS(1)  SS(2)  SS(3)  SS(4)  SS(5)  SS(6)  SS(7) SS(8)  SS(9)  SS(10) SS(11) SS(12) SS(13) SS(14) SS(15) 
SS(16) SS(17) SS(18) SS(19) SS(20) SS(21) SS(22) SS(23) SS(24) SS(25) SS(26) SS(27) SS(28) SS(29) SS(30) } 
.macro RS(R) LD(UserMState+(4*R), R) | (Auxiliary macro) 
.macro RESTORESTATE() { RS(0)  RS(1)  RS(2)  RS(3)  RS(4)  RS(5)  RS(6) RS(7) RS(8)  RS(9)  RS(10) RS(11) RS(12) RS(13) RS(14) RS(15) 
RS(16) RS(17) RS(18) RS(19) RS(20) RS(21) RS(22) RS(23) 
RS(24) RS(25) RS(26) RS(27) RS(28) RS(29) RS(30) } Code is from lab8.uasm 
This is where the HW sets 
the PC during an exception 
Macros can be used like an in-lined procedure call 
L18  Virtual Machines   20  6.004  Spring 2009 4/14/09Illop Handler 
|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| Handler for Illegal Instructions |||  (including SVCs) 
|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
I_IllOp:
SAVESTATE() | Save the machine state. 
LD(KStack, SP) | Install kernel stack pointer. 
LD(XP, -4, r0) | Fetch the illegal instruction 
SHRC(r0, 26, r0) | Extract the 6-bit OPCODE 
SHLC(r0, 2, r0) | Make it a WORD (4-byte) index 
LD(r0, UUOTbl, r0) | Fetch UUOTbl[OPCODE] 
JMP(r0) | and dispatch to the UUO handler. 
.macro UUO(ADR) LONG(ADR+0x80000000) | Auxiliary Macros 
.macro BAD() UUO(UUOError)
UUOTbl: BAD() UUO(SVC_UUO)  BAD() BAD()
BAD()       BAD()        BAD()          BAD() 
BAD()     BAD()        BAD()          BAD()  more table follows Dont trust the users stack! 
This is a 64-
entry dispatch 
table.  Each 
entry is an address of a handler supervisor bit</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L18  Virtual Machines   21  6.004  Spring 2009 4/14/09Actual Illops 
||| Here's the handler for truly unused opcodes (not SVCs): 
UUOError:
CALL(KWrMsg) | Type out an error msg, 
.text "Illegal instruction " 
LD(xp, -4, r0) | giving hex instr and location; 
CALL(KHexPrt)CALL(KWrMsg).text " at location 0x" 
MOVE(xp,r0)
CALL(KHexPrt)CALL(KWrMsg).text "! ....." HALT() | Then crash system. These utility routines (Kxxx) dont follow our usual 
calling convention  they take their args in registers or from words immediately following the 
procedure call!  They adjust LP to skip past any 
args before returning. 
L18  Virtual Machines   22  6.004  Spring 2009 4/14/09Supervisor Call Handler 
||| Sub-handler for SVCs, called from I_IllOp on SVC opcode: 
SVC_UUO:
LD(XP, -4, r0) | The faulting instruction. 
ANDC(r0,0x7,r0) | Pick out low bits, 
SHLC(r0,2,r0) | make a word index, 
LD(r0,SVCTbl,r0) | and fetch the table entry. 
JMP(r0)
SVCTbl: UUO(HaltH) | SVC(0): User-mode HALT instruction 
UUO(WrMsgH) | SVC(1): Write message 
UUO(WrChH) | SVC(2): Write Character 
UUO(GetKeyH) | SVC(3): Get Key 
UUO(HexPrtH) | SVC(4): Hex Print 
UUO(WaitH) | SVC(5): Wait(S) ,,, S in R3 
UUO(SignalH) | SVC(6): Signal(S), S in R3 
UUO(YieldH) | SVC(7): Yield() 000001----------------------xxx
SVC opcode SVC index SVC Instruction format 
Another
dispatch table!
L18  Virtual Machines   23  6.004  Spring 2009 4/14/09Handler for HALT SVC 
|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| SVC Sub-handler for user-mode HALTs |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
HaltH: BR(I_Wait) | SVC(0): User-mode HALT SVC 
||| Here's the common exit sequence from Kernel interrupt handlers: 
||| Restore registers, and jump back to the interrupted user-mode 
||| program. 
I_Rtn: RESTORESTATE()
kexit: JMP(XP) | Good place for debugging breakpoint! 
||| Alternate return from interrupt handler which BACKS UP PC, 
||| and calls the scheduler prior to returning.  This causes ||| the trapped SVC to be re-executed when the process is ||| eventually rescheduled... 
I_Wait: LD(UserMState+(4*30), r0) | Grab XP from saved MState, 
SUBC(r0, 4, r0) | back it up to point to 
ST(r0, UserMState+(4*30)) | SVC instruction 
CALL(Scheduler) | Switch current process, 
BR(I_Rtn) | and return to (some) user. Fills UserMState from 
PCB of next process to runLooks like HALT should really be called LOOP! 
L18  Virtual Machines   24  6.004  Spring 2009 4/14/09OS organization 
Applications are quasi-parallel 
PROCESSES
          on
          VIRTUAL MACHINES,
each with: 
/.notdef.g0001 CONTEXT (virtual address space) 
/.notdef.g0001 Virtual I/O devices
O.S. KERNEL has: 
/.notdef.g0001 Interrupt handlers 
/.notdef.g0001 SVC (trap) handlers 
/.notdef.g0001 Scheduler 
/.notdef.g0001 PCB structures containing the 
state of inactive processesScheduler
KERNELP1 P2
SVC 1 handler SVC 0 handler 
I/O Handler 
Device
0Alarm Clock I/O Handler 
Device
1
DPYNum=0
DPYNum=1PCBs:
    P1: 
    P2: loop:SVC(0)
...
SVC(1)
...BR(loop)loop:SVC(0)
...
SVC(1)
...BR(loop)</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L18  Virtual Machines   9  6.004  Spring 2009 4/14/09Each process has its own virtual machine 
OS Kernel (Specially privileged process) 
CPU MEM TIMER DISK I/O KVM CPUVirtual 
Memory Windows I/O
events les sockets SVCs P1Application CPUVirtual 
Memory Windows I/O
events les sockets SVCs Application 
CPUVirtual 
Memory Windows I/O
events les sockets SVCs Application CPUVirtual 
Memory Windows I/O
events les sockets SVCs Application CPUVirtual 
Memory Windows I/O
events les sockets SVCs Application 
P2
P3
P4
P5
L18  Virtual Machines   10  6.004  Spring 2009 4/14/09Processes:
Multiplexing the CPU 
PROCESS
1PROCESS
0Operating/.notdef.g0001
System
1
2 3 4 5
Virtual time 1. Running in process #0 
2. Stop execution of process #0 
either because of explicit yield  or 
some sort of timer interrupt ; trap 
to handler code, saving current PC 
in XP 
3. First: save process #0 state (regs, 
context) Then: load process #1 
state (regs, context) 
4. Return to process #1: just like 
return from other trap handlers (ie., use address in XP) but were returning from a dierent  trap than 
happened in step 2! 
5. Running in process #1
Key Technology: Interrupts. When this process is interrupted. 
We RETURN to this process! 
L18  Virtual Machines   11  6.004  Spring 2009 4/14/09Interrupt Hardware 
PC+4+4*SXT(C)
ASEL 0 1
Data Memory 
RDWD
AdrR/W
WDSEL 012WA Rc: &lt;25:21&gt;01XPPCJT
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt; Ra: &lt;20:16&gt;
RA2SELRc: &lt;25:21&gt;
+
Register
FileRA1 RA2
RD1 RD2
BSEL 0 1C: SXT(&lt;15:0&gt;)Z
ALUABJTWAWD
WE
ALUFNControl LogicZ
ASEL
BSELPCSEL
RA2SEL
WDSEL
ALUFN
Wr
PC+401
Wr0 1 2 3 4XAdrILL
OP
WASEL
WASELIRQWERF
WERF00If (IRQ == 1 &amp;&amp; PC31 == 0) { 
     // Reg[XP] /.notdef.g0001 PC+4;  PC /.notdef.g0001Xadr 
PCSEL = 4, 
   WASEL = 1, WDSEL = 0, WERF = 1, 
   WR = 0 
}PCSEL
L18  Virtual Machines   12  6.004  Spring 2009 4/14/09Beta Interrupt Handling 
SAVED 
STATE 
OF  A 
SP BR(...)0:
4:
8:
12:BR(...)
BR(...)BR(...)
User: Minimal Hardware Implementation: 
/.notdef.g0001Check for Interrupt Requests (IRQs) 
before each instruction fetch. 
/.notdef.g0001On IRQ j: 
/.notdef.g0001/.notdef.g0001copy PC into Reg[XP]; 
/.notdef.g0001/.notdef.g0001INSTALL j*4 as new PC. 
Handler Coding: 
/.notdef.g0001Save state in User structure 
/.notdef.g0001Call C procedure to handle the exception 
/.notdef.g0001re-install saved state from User 
/.notdef.g0001Return to Reg[XP] 
WHERE to nd handlers? 
/.notdef.g0001BETA Scheme:  WIRE IN a low-memory address for each exception handler entry point 
/.notdef.g0001Common alternative: WIRE IN the address of a TABLE of 
handler addresses (interrupt vectors) ILLOP /.notdef.g0002 0x8000000  RESET/.notdef.g0002 0x8000000
X_ADR/.notdef.g0002 0x8000000  
TRANSP ARENT  to 
interrupted 
program! /.notdef.g0002
/.notdef.g0002
/.notdef.g0002
/.notdef.g0002
/.notdef.g0002</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L18  Virtual Machines   5  6.004  Spring 2009 4/14/09Example II 
01 2
-- 0 --
01 4
-- 0 --
11 0
11 1
-- 0 ---- 0 ---- 0 --
-- 0 ---- 0 ---- 0 --
11 711 611 501 3Setup: 
    256 bytes/page (28)
    16 virtual pages (24)
    8 physical pages (23)
    12-bit VA (4 vpn, 8 oset)    11-bit PA (3 ppn, 8 oset)
    LRU page: VPN = 0xE 
ST(BP ,-4,SP), SP = 0x604 
  VA = 0x600, PA = _______ 16-entry 
Page Table 8-page 
Phys. Mem. 
D  R    PPN 1     1           5 
--     0           -- VPN 0x4 
VPN 0x5 
VPN 0x0 
VPN 0xF 
VPN 0x2 
VPN 0xE 
VPN 0xD 
VPN 0xC 0x000
0x0FC
0x100
0x1FC
0x200
0x2FC
0x300
0x3FC
0x400
0x4FC
0x500
0x5FC
0x600
0x6FC
0x700
0x7FCVPN 0x6 0
12
3
4567
89
AB
CD
E
F
0x500
VPN = 0x6 
/.notdef.g0002/.notdef.g0001Not resident, its on disk 
/.notdef.g0002/.notdef.g0001Choose page to replace (LRU = 0xE) 
/.notdef.g0002/.notdef.g0001D[0xE] = 1, so write 0x500-0x5FC to disk 
/.notdef.g0002/.notdef.g0001Mark VPN 0xE as no longer resident 
/.notdef.g0002/.notdef.g0001Read in page 0x6 from disk into 0x500-0x5FC 
/.notdef.g0002/.notdef.g0001Set up page map for VPN 0x6 = PPN 0x5 
/.notdef.g0002/.notdef.g0001PA = 0x500 
/.notdef.g0002/.notdef.g0001This is a write so set D[0x6] = 1 
L18  Virtual Machines   6  6.004  Spring 2009 4/14/09Contexts
Acontext  is an entire set of mappings from VIRTUAL to PHYSICAL page 
numbers as specied by the contents of the page map: 
We might like to support 
multiple VIRTUAL to 
PHYSICAL Mappings and, 
thus, multiple Contexts. 
PAGEMAPX
X
XDRVirtual Memory Physical Memory
THE BIG IDEA: Several programs, each with their own context, may be 
simultaneously loaded into main memory! 
Context switch: 
  reload the page map! Virtual 
Memory 1Virtual 
Memory 2Physical
Memory
map map
L18  Virtual Machines   7  6.004  Spring 2009 4/14/09Power of Contexts: Sharing a CPU 
1. TIMESHARING among several programs -- 
 Separate context for each program 
 OS loads appropriate context into pagemap when switching among pgms 
2. Separate context for Operating System Kernel (eg, interrupt handlers)... 
 Kernel vs User contexts 
 Switch to Kernel context on interrupt; 
 Switch back on interrupt return. TYPICAL HARDWARE SUPPORT: rapid context switch mechanism Every application can be 
written as if it has access 
to all of memory, without 
considering where other 
applications reside. 
More than Virtual Memory: 
   A VIRTUAL MACHINE Virtual 
Memory 1Virtual 
Memory 2Physical
Memory
L18  Virtual Machines   8  6.004  Spring 2009 4/14/09Building a Virtual Machine 
PROCESS #0  PROCESS #1  
virtual 
memory virtual 
memory physical 
memory 
P1
P0
P1
shared 
?
P0
P1
?
?P0
Context #1 Context #0 
Goal: give each program its own VIRTUAL MACHINE; 
programs dont know about each other 
New abstraction: a process  which has its own 
   machine state: R0, , R30  program (w/ shared code)    context (virtual address space)  virtual I/O devices (console) 
   PC, stack 
OS Kernel is a special, privileged process that oversees the other processes 
and handles real I/O devices, emulating virtual I/O devices for each process</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L18  Virtual Machines   13  6.004  Spring 2009 4/14/09External (Asynchronous) 
Interrupts
Example:
Operating System maintains current time of day (TOD) count. But...this value 
must be updated periodically in r esponse to clock EVENTs, i.e. signal triggered 
by 60 Hz timer hardware. 
Program A (Application) 
/.notdef.g0001Executes instructions of the user program. 
/.notdef.g0001Doesn't want to know about clock hardware, interrupts, etc!! 
/.notdef.g0001Can incorporate TOD into results by asking OS. 
Clock Handler 
/.notdef.g0001GUTS: Sequence of instructions that increments TOD.  Written in C. 
/.notdef.g0001Entry/Exit sequences save &amp; restore interrupted state, call the C handler.  Written as assembler stubs. 
L18  Virtual Machines   14  6.004  Spring 2009 4/14/09Interrupt Handler Coding 
long TimeOfDay; 
struct Mstate { int Regs[31];} User; 
/* Executed 60 times/sec */ 
Clock_Handler(){   TimeOfDay = TimeOfDay+1; 
}
Clock_h:
ST(r0, User)        | Save state of 
ST(r1, User+4)      | interrupted 
...                 |  app pgm... 
ST(r30, User+30*4) 
CMOVE(KStack, SP)   | Use KERNEL SP 
BR(Clock_Handler,lp)| call handler LD(User, r0)        | Restore saved 
LD(User+4, r1)      |   state. 
...
LD(User+30*4, r30) 
SUBC(XP, 4, XP)  | execute interrupted inst JMP(XP)             | Return to app. Handler 
(written in C) 
Interrupt stub (written in assy.) if (TimeOfDay % QUANTUM == 0) Scheduler(); 
L18  Virtual Machines   15  6.004  Spring 2009 4/14/09Simple Timesharing Scheduler 
struct Mstate { /* Structure to hold */ 
int Regs[31]; /* processor state   */ 
} User; 
struct PCB { 
struct MState State; /* Processor state   */ 
Context PageMap; /* VM Map for proc   */ 
int DPYNum; /* Console number    */ 
 } ProcTbl[N]; /* one per process
*/
int Cur; /* Active process */ 
Scheduler() { 
   ProcTbl[Cur].State = User;         /* Save Cur state */ 
Cur = (Cur+1)%N;         /* Incr mod N     */ 
User = ProcTbl[Cur].State; /* Install state for next User  */ 
LoadUserContext(ProcTbl[Cur].Context);  /* Install context */ 
}(PCB = Process Control Block) 
L18  Virtual Machines   16  6.004  Spring 2009 4/14/09Avoiding Re-entrance 
Handlers which are interruptable are called RE-ENTRANT, and pose special 
problems... Beta, like many systems, disallows reentrant interrupts!
Mechanism: Uninterruptable Kernel Mode for OS: 
USER mode  
(Application)  
KERNEL mode  
(Op Sys)  main()
{ ... 
  ... 
  ... 
}
Interrupt 
Vector Page 
Fault 
Handler 
Clock 
Handler SVC 
Handlers User
(saved  
state)  
Kernel  
Stack  PC = 0......... 
PC = 1......... Processor State K-Mode Flag: 
PC31 = 1 for Kernel Mode! 
Other K-mode functions, e.g.
/.notdef.g0001choosing Kernel/User context 
/.notdef.g0001Allowing privileged operations</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L18  Virtual Machines   1  6.004  Spring 2009 4/14/09Virtual Machines
Lab 6 due Thursday! 
L18  Virtual Machines   2  6.004  Spring 2009 4/14/09Review: Virtual Memory 
Goal: create illusion of large virtual address space 
/.notdef.g0001 divide address into (VPN,oset), map to (PPN,oset) or page fault 
/.notdef.g0001use high address  bits to select page: keep related data on same page  
/.notdef.g0001 use cache ( TLB) to speed up mapping mechanismworks well 
/.notdef.g0001long disk latencies : keep working set in physical memory, use write-back PAGEMAP X
X
XDRVirtual 
Memory Physical 
Memory PPNCPU RAM MMU VA PA 
L18  Virtual Machines   3  6.004  Spring 2009 4/14/09MMU Address Translation 
Typical Multi-level approach 
3232-bit virtual address 
3
Page fault 
(handled by SW) 1
Look in TLB: VPN /.notdef.g0002PPN cache 
Usually implemented as a small 
(16- to 64-entry) fully-associative 
cache 2
Data 20 12
PTBL
D   R    PPN virtual 
page 
number 20 12
L18  Virtual Machines   4  6.004  Spring 2009 4/14/09Example I 
01 2
-- 0 --
01 4
-- 0 --
11 0
11 1
-- 0 ---- 0 ---- 0 ---- 0 ---- 0 ---- 0 --
11 711 6
11 5
01 3Setup: 
    256 bytes/page (28)
    16 virtual pages (24)
    8 physical pages (23)
    12-bit VA (4 vpn, 8 oset)    11-bit PA (3 ppn, 8 oset)    LRU page: VPN = 0xE 
LD(R31,0x2C8,R0):
   VA = 0x2C8, PA = _______ 16-entry 
Page Table 8-page 
Phys. Mem. 
D  R    PPN VPN 0x4 
VPN 0x5 
VPN 0x0 
VPN 0xF 
VPN 0x2 
VPN 0xE 
VPN 0xD 
VPN 0xC 0x000
0x0FC
0x100
0x1FC
0x200
0x2FC
0x300
0x3FC
0x400
0x4FC
0x500
0x5FC
0x600
0x6FC
0x700
0x7FC0x4C8
VPN = 0x2 
/.notdef.g0002 PPN = 0x4 0
12
3
4
5
67
8
9
A
B
C
D
E
F8 4 VA oset VPN
8 3 PA 
PPN</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Sequential logic</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec05/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>L05  Sequential Logic   9  6.004  Spring 2009 2/19/09New Device: D Latch  
GDQD
TPDV1 V2
V2 V1
TPDG
QG=1:
Q follows D G=0:
Q holds 
G=1:  Q Follows D, independently of Q 
G=0:  Q Holds stable Q, independently of D Y0
1A
D
GQQ
BUT A change in D or G 
contaminates Q, hence Q 
 how can this possibly 
work?  
L05  Sequential Logic   10  6.004  Spring 2009 2/19/09A Plea for Lenience  
Y0
1A
D
GQD
TPDV1 V2
V2 V1
TPDGQ
Assume LENIENT Mux, propagation 
delay of TPD
Then output valid whenQ
Does lenience guarantee  a 
working latch? 
What if D and G 
change at about the 
same time  /.notdef.g0001Q=D stable for TPD,
independently of G; or  /.notdef.g0001G=1, D stable for TPD,
independently of Q; or
/.notdef.g0001G=0, Q stable for TPD,
independently of D GDQ Q
10 X 0
11 X 1
X0 0 0
X1 1 1
0X 0 0
0X 1 1
Q(D,G) 
Q(D,Q) 
Q(G,Q)
L05  Sequential Logic   11  6.004  Spring 2009 2/19/09Dynamic Discipline  for our latch: D Stable  with a little discipline  
Y0
1A
D
GQ
To reliably latch  V2: Q
/.notdef.g0001 Apply V2 to D, holding G=1 
/.notdef.g0001 After another TPD, Q &amp; D both valid 
for TPD;will hold Q=V2 independently of  
G
/.notdef.g0001 Set G=0, while Q &amp; D hold Q=D /.notdef.g0001 After TPD, V2 appears at Q=Q
/.notdef.g0001 After another TPD, G=0 and Q 
are sucient to hold Q=V2 
independently of DD
G
QV2
V2
TPDTPD
TSETUP THOLDTPD
TSETUP  = 2TPD: interval prior to  G 
transition for which D must be 
stable &amp; valid 
THOLD  = TPD: interval following  G 
transition for which D must be stable &amp; valid 
L05  Sequential Logic   12  6.004  Spring 2009 2/19/09Lets try it out!  
Combinational 
Logic GDQ
Current 
State New
State 
Input Output 
Plan: Build a Sequential Circuit with one bit of STATE  
/.notdef.g0001 Single latch holds CURRENT state 
/.notdef.g0001 Combinational Logic computes 
/.notdef.g0001 NEXT state (from input, current state) 
/.notdef.g0001 OUTPUT bit (from input, current state) 
/.notdef.g0001 State changes when G = 1 (briey!) What happens 
when G=1?</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L05  Sequential Logic   5  6.004  Spring 2009 2/19/09Needed: Storage  
Combinational logic is stateless :
valid outputs always reect current inputs. 
To build devices with state, we need components which store 
information (e.g., state) for subsequent access. 
ROMs  (and other combinational logic) store information wired in to their 
truth table 
Read/Write  memory elements are required to build devices capable of 
changing their contents. 
How can we store  and subsequently access -- a bit? 
/.notdef.g0001Mechanics: holes in cards/tapes 
/.notdef.g0001Optics: Film, CDs, DVDs,  
/.notdef.g0001Magnetic materials 
/.notdef.g0001Delay lines; moonbounce 
/.notdef.g0001Stored charge 
L05  Sequential Logic   6  6.004  Spring 2009 2/19/09Storage: Using Capacitors  
Weve chosen to encode information using voltages and we know 
from 6.002 that we can store a voltage as charge on a capacitor:  
Pros: 
/.notdef.g0001 compact  low cost/bit 
(on BIG memories) 
Cons: 
/.notdef.g0001 complex interface 
/.notdef.g0001 stable? (noise, ) /.notdef.g0001 it leaks! /.notdef.g0002 refresh 
To write: 
   Drive bit line, turn on access fet, 
   force storage cap to new voltage 
To read: 
   precharge bit line, turn on access fet, 
   detect (small) change in bit line voltage N-channel fet serves 
as access switch VREFword line
Bit 
line
Suppose we refresh 
CONTINUOUSLY?  
L05  Sequential Logic   7  6.004  Spring 2009 2/19/09Storage: Using Feedback  
IDEA: use positive feedback  to maintain storage indenitely.  
Our logic gates are built to restore marginal signal levels, so 
noise shouldnt be a problem! 
VINVOUTResult: a bistablestorage element
Feedback constraint: 
VIN = VOUTVTC for  
inverter pair 
VINVOUT Three solutions: 
/.notdef.g0001 two end-points are stable
/.notdef.g0001 middle point is unstable Not aected 
by noise 
Well get back to this! 
L05  Sequential Logic   8  6.004  Spring 2009 2/19/09Y
SBSettable Storage Element  
Its easy to build a settable storage element (called a latch )
using a lenient  MUX: 
0
1G
0
0
11D
--
--
01Q
IN
0
1
--
--QOUT 
0
1
0
1state signal 
appears as both input and output
Q follows D Q stable A
D
GQHeres a feedback path, 
so its no longer a 
combinational circuit.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L05  Sequential Logic   21  6.004  Spring 2009 2/19/09Flip Flop Timing - II  
CLKt1
t1 = tCD,reg1  + tCD,1 &gt; tHOLD,reg2  1DQ DQ
CLKreg1 reg2Questions for register-based designs: 
/.notdef.g0001 how much time for useful work  
(i.e. for combinational logic 
delay)?
/.notdef.g0001 does it help to guarantee a 
minimum tCD?  How bout  
designing registers so that 
tCD,reg  &gt; tHOLD,reg ?
/.notdef.g0001 what happens if CLK signal 
doesnt arrive at the two registers at exactly the same time (a phenomenon known as clock skew)?   t2
t2 = tPD,reg1  + tPD,1 &lt; tCLK - tSETUP ,reg2  QR1tCD,reg1 
tCD, 1 tPD, 1 tPD,reg1 QR1
L05  Sequential Logic   22  6.004  Spring 2009 2/19/09Model: Discrete Time  
Active Clock Edges punctuate time --- 
/.notdef.g0001Discrete Clock periods 
/.notdef.g0001Discrete State Variables 
/.notdef.g0001Discrete specications (simple rules  eg tables  relating 
outputs to inputs, state variables) 
/.notdef.g0001ABSTRACTION: Finite State Machines (next lecture!) Combinational 
Logic Current 
State New
State 
Input Output Memory 
Device 
Clock 
L05  Sequential Logic   23  6.004  Spring 2009 2/19/09Sequential Circuit Timing  
Questions: 
/.notdef.g0001Constraints on TCD for the logic? 
/.notdef.g0001Minimum clock period? 
/.notdef.g0001Setup, Hold times for Inputs? Combinational 
Logic Current 
State New
State 
Input Output Clock tCD,L = ? 
tPD,L = 5ns tCD,R = 1ns 
tPD,R = 3ns 
tS,R = 2ns 
tH,R = 2ns 
&gt; 1 ns 
&gt; 10 ns (TPD,R+TPD,L+ TS,R)
TS = TPD,L +TS,R
TH = TH,R-TCD,L
This is a simple  Finite State Machine   more next lecture!! 
L05  Sequential Logic   24  6.004  Spring 2009 2/19/09Summary
Sequential Circuits (with memory):  
Basic memory elements: 
/.notdef.g0001Feedback, detailed analysis =&gt; 
basic level-sensitive devices 
(eg, latch) 
/.notdef.g00012 Latches =&gt; Flop 
/.notdef.g0001Dynamic Discipline: 
constraints on input timing 
Synchronous 1-clock logic: 
/.notdef.g0001 Simple rules for sequential 
circuits
/.notdef.g0001 Yields clocked circuit with TS, TH
constraints on input timing 
Finite State Machines 
Next Lecture Topic! &gt;ts &gt;th
Clk
QD
&gt;tcd
&lt;tpd
D Q D Q Out In
Clk Combinational 
logic</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L05  Sequential Logic   1  6.004  Spring 2009 2/19/09Sequential Logic:  
adding a little state  
Lab #1 is due tonight 
(checko meeting by next Thursday).
modied 2/17/09 10:26 QUIZ #1 Tomorrow! 
(covers thru L4/R5) 
L05  Sequential Logic   2  6.004  Spring 2009 2/19/096.004: Progress so far  
01101PHYSICS: Continuous 
variables, Memory, Noise, 
f(RC) = 1 - e-t/RCCOMBINATIONAL: Discrete, 
memoryless, noise-free, 
lookup table functions 
2.71354 voltsCBAY
0000
0011
0100
0111
1000
1010
1101
1111What other 
buildingblocks do we 
need in order 
to compute? 
L05  Sequential Logic   3  6.004  Spring 2009 2/19/09Something We Cant Build (Yet)  
What if you were given the following design specication:
When the button is pushed: 
1) Turn on the light if 
it is o
2) Turn o the light if 
it is on
The light should change 
state within a second 
of the button pressbutton light
What makes this circuit so dierent 
from those weve discussed before? 
1. State  i.e. the circuit has memory 
2. The output was changed by a input      event (pushing a button) rather 
     than an input value 
L05  Sequential Logic   4  6.004  Spring 2009 2/19/09Digital State  
One model of what wed like to build  
Plan: Build a Sequential Circuit with stored digital STATE  
/.notdef.g0001 Memory stores CURRENT state, produced at output 
/.notdef.g0001 Combinational Logic computes 
/.notdef.g0001 NEXT state (from input, current state) 
/.notdef.g0001 OUTPUT bit (from input, current state) 
/.notdef.g0001 State changes on LOAD control input Combinational 
Logic Current 
State New
State 
Input Output Memory 
Device 
LOAD</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L05  Sequential Logic   13  6.004  Spring 2009 2/19/09Combinational Cycles  
Combinational 
Logic GDQ
Current 
State New
State 
Input Output 
When G=1, latch is Transparent  
 provides a combinational path from D to Q. 
Cant work without tricky timing constrants on G=1 pulse: 
/.notdef.g0001 Must t within contamination delay of logic 
/.notdef.g0001 Must accommodate latch setup, hold times 
Want to signal an INSTANT, not an INTERVAL Looks like a stupid 
Approach to me 1
L05  Sequential Logic   14  6.004  Spring 2009 2/19/09Flakey Control Systems
Heres a strategy 
for saving 3 bucks on the Sumner 
Tunnel! 
L05  Sequential Logic   15  6.004  Spring 2009 2/19/09Escapement Strategy  
The Solution: 
  Add two gates  
  and only open 
  one at a time. 
L05  Sequential Logic   16  6.004  Spring 2009 2/19/09Edge-triggered Flip Flop  
GDQ
GDQDQ D
CLKQD
CLKQ
master slave  
Observations: 
/.notdef.g0001/.notdef.g0001 only one latch transparent at any time: 
/.notdef.g0001/.notdef.g0001 master closed when slave is open 
/.notdef.g0001/.notdef.g0001 slave closed when master is open 
/.notdef.g0001/.notdef.g0001 no combinational path through ip op 
/.notdef.g0001/.notdef.g0001 Q only changes shortly after 0 /.notdef.g0001/.notdef.g00011
    transition of CLK, so ip op appears 
    to be triggered by rising edge of CLK The gate of this 
latch  is open when 
the clock is low
The gate of this 
latch  is open when 
the clock is highWhat does 
that one do? 0
10
1
SD
GQ
(the feedback path in one of the master or slave latches is always active) Transitions mark 
instants , not intervals  
Figure by MIT OpenCourseWare.Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L05  Sequential Logic   17  6.004  Spring 2009 2/19/09Flip Flop Waveforms  
GDQ
GDQDQ D
CLKQD
CLKQ
master slave  
D
CLK
Q
master closed 
slave openslave closed 
master open
L05  Sequential Logic   18  6.004  Spring 2009 2/19/09Um, about that hold time  
GDQ
GDQDQ
master slave  
CLK
Consider HOLD TIME requirement for slave :
 Negative (1 /.notdef.g00010) clock transition /.notdef.g0001 slave freezes data: 
 SHOULD be no output glitch, since master held constant data; BUT 
 master output contaminated by change in G input! 
 HOLD TIME of slave not met, UNLESS we assume sucient
contamination delay in the path to its D input! 
Accumulated tCD thru inverter, G /.notdef.g0001 Q path of master must cover 
slave tHOLD  for this design to work! The masters contamination 
delay must meet the hold 
time of the slave 
L05  Sequential Logic   19  6.004  Spring 2009 2/19/09Flip Flop Timing - I  
CLK
DQDQ D
CLKQ&lt;tPD
tPD: maximum propagation delay, CLK /.notdef.g0001Q&gt;tCD
tCD: minimum contamination delay, CLK /.notdef.g0001Q&gt;tSETUP
tSETUP : setup time 
guarantee that D has propagated through feedback path before master closes &gt;tHOLD
tHOLD : hold time 
guarantee master is closed and data is stable before allowing D to change 
L05  Sequential Logic   20  6.004  Spring 2009 2/19/09Single-clock Synchronous Circuits  
Single-clock Synchronous Discipline
No combinational cycles 
Only care about value of register data 
inputs just before rising edge of clock 
P eriod greater than every 
   combinational delay 
Change saved state after noise-
inducing logic transitions have 
stopped! Well use Flip Flops and Registers   groups of FFs sharing a clock 
input  in a highly constrained way to build digital systems: 
Single clock signal shared among 
all clocked devices Does that 
symbol 
register?</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Beta instruction set architecture, compilation</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec10/</lecture_pdf_url>
      <lectureno>10</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>Instruction Sets   13  6.004  Spring 2009 3/10/09/.notdef.g0002 Programming Model 
a representative, simple, contemporary RISC
Fetch/Execute loop: 
/.notdef.g0001 fetch Mem[PC] 
/.notdef.g0001 PC = PC + 4
/.notdef.g0001 execute fetched instruction 
   (may change PC!) 
/.notdef.g0001 repeat! 00 PC
Even though each memory word is 32-bits 
wide, for historical reasons the /.notdef.g0002 uses byte 
memory addresses.  Since each word 
contains four 8-bit bytes, addresses of 
consecutive words dier by 4. Main Memory 
0 1 2 3
(4 bytes) 32-bit words 0 31
next instruction Processor State 
r0
r1
r2
...
r31 000000....0 32-bit words 
General Registers 
Instruction Sets   14  6.004  Spring 2009 3/10/09/.notdef.g0002 Instruction Formats 
All Beta instructions t in a single 32-bit word, whose elds 
encode combinations of 
/.notdef.g0001a 6-bit OPCODE (specifying one of &lt; 64 operations) 
/.notdef.g0001several 5-bit OPERAND locations, each one of the 32 
registers 
/.notdef.g0001an embedded 16-bit constant (literal) 
There are two instruction formats: 
/.notdef.g0001Opcode, 3 register operands 
(2 sources, destination) 
/.notdef.g0001Opcode, 2 register operands, 
16-bit literal constant OPCODE rc ra rb unused
OPCODE rc ra 16-bit signed constant 
Instruction Sets   15  6.004  Spring 2009 3/10/09/.notdef.g0002 ALU Operations 
Sample coded operation:  ADD instruction 
32-bit hex: 0x80611000 
What we prefer to write:    ADD(r1,r2,r3)
ADD(ra,rb,rc) :
Add the contents of ra to 
the contents of rb; store 
the result in rc OPCODE = 100000, 
encoding ADD  rc=3,
encoding R3 as 
destinationra=1,rb=2
encoding R1 and R2 as 
 source locations 
Reg[rc]  =  Reg[ra] + Reg[rb] arithmetic: ADD, SUB, MUL, DIV 
compare: CMPEQ, CMPLT, CMPLE 
boolean: AND, OR, XOR 
shift: SHL, SHR, SAR Similar instructions for other 
ALU operations: 100000000110000100010 00000000000 unused
assembly language 
Instruction Sets   16  6.004  Spring 2009 3/10/09/.notdef.g0002 ALU Operations with Constant 
ADDC instruction: adds constant, register contents: 
Symbolic version:  ADDC(r1,-3,r3)
Add the contents of ra to 
const; store the result in 
rc OPCODE = 110000, 
encoding ADDC  rc=3,
encoding R3 as 
destinationra=1,
encoding R1 as 
rst operand 
Reg[rc]  =  Reg[ra] + sxt(const) arithmetic: ADDC, SUBC, MULC, DIVC 
compare: CMPEQC, CMPLTC, CMPLEC 
boolean: ANDC, ORC, XORC 
shift: SHLC, SHRC, SARC Similar instructions for other 
ALU operations: constant eld, 
encoding -3 as 
second operand 
(sign-extended!) 
ADDC(ra,const,rc) :11000000011000011111111111111101</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Instruction Sets   5  6.004  Spring 2009 3/10/09An Optimized Program 
A/.notdef.g0001 1
A/.notdef.g0001 A * B 
B/.notdef.g0001 B - 1 B/.notdef.g0001 N
A/.notdef.g0001 A * B S0
S1
S2
S3Some parts of the program 
can be computed simultaneously: 
SNSN+1 Asel ALEBsel BLE
0 11101
1 20111
2 30100
3 30000
Instruction Sets   6  6.004  Spring 2009 3/10/09Computing Factorial 
L.E. L.E.
*AB1N
-10      1  0         1  ASEL BSEL
BLE ALE
ANSWER=0?
Control 
FSMAsel
Bsel
Ale
BleThe advantage of a programmable control system is that we can 
recongure it to compute new 
functions. 
In order to compute N! we will need 
to add some new logic and an input 
to our control FSM: 
Instruction Sets   7  6.004  Spring 2009 3/10/09Control Structure for Factorial 
A/.notdef.g0001  A * B  
B/.notdef.g0001  B - 1 B/.notdef.g0001 N 
A/.notdef.g0001  1  
Z=0
Z=1
DONES0
S1
S2Programmability allows us to reuse data 
paths to solve new problems.  What we need 
is a general purpose data path, which can be 
used to eciently solve most problems as 
well as an easier way to control it. 
Z SNSN+1 Asel ALEBsel BLE
-0
01
11
-2Z SNSN+1 Asel ALEBsel BLE
-0 11101
01 10111
11 20111
-2 20000
Instruction Sets   8  6.004  Spring 2009 3/10/09A Programmable Engine 
Weve used the same data paths for computing 
N*(N-1) and Factorial; there are a variety 
of other computations we might 
implement simply by re-programming the 
control FSM. 
Although our little machine is programmable, it 
falls short of a practical general-purpose 
computer  and fails the Turing 
Universality test  for three primary 
reasons: 
1. It has very limited storage: it lacks 
the expandable memory resource of 
a Turing Machine. 
2. It has a tiny repertoire of operations. 
3. The program is xed.  It lacks the 
power, e.g., to generate a new 
program and then execute it. Control 
FSMALE
BLEASEL
BSELL.E. L.E.
*AB1N
-10         1  ASEL BSEL
BLE ALE
ANSWER
=0?0         1  
/.notdef.g0001
/.notdef.g0001
/.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Instruction Sets   25  6.004  Spring 2009 3/10/09Beta Branch Instructions 
PC = PC + 4; 
Reg[rc] = PC;  
if (REG[ra] != 0) 
      PC = PC + 4*oset;BNE(ra,label,rc) :Branch if not equal 
PC = PC + 4; 
Reg[rc] = PC;  
if (REG[ra] == 0) 
      PC = PC + 4*oset;BEQ(ra,label,rc) :Branch if equal NB: oset is a SIGNED 
CONSTANT encoded as part of 
the instruction! OPCODE rc ra 16-bit signed constant The Betas branch instructions  provide a way of conditionally changing the PC to 
point to some nearby location... 
... and, optionally, remembering (in Rc) where we came from (useful for procedure 
calls). 
offset = (label - &lt;addr of BNE/BEQ&gt;)/4  1 
       = up to 32767 instructions before/after BNE/BEQ 
Instruction Sets   26  6.004  Spring 2009 3/10/09Now   we can do Factorial... 
int n, ans; 
r1 = 1; 
r2 = n; 
while (r2 != 0) {
   r1 = r1 * r2; 
   r2 = r2  1 }
ans = r1; Synopsis (in C): 
/.notdef.g0001Input in n, output in ans 
/.notdef.g0001r1, r2 used for temporaries 
/.notdef.g0001follows algorithm of our earlier 
data paths. 
n: long(123)
ans: long(0)
...
ADDC(r31, 1, r1) | r1 = 1 
LD(n, r2) | r2 = n 
loop: BEQ(r2, done, r31) | while (r2 != 0) 
MUL(r1, r2, r1) | r1 = r1 * r2 
SUBC(r2, 1, r2) | r2 = r2 - 1 
BEQ(r31, loop, r31) | Always branches! 
done: ST(r1, ans, r31) | ans = r1 Beta code, in assembly language: 
Instruction Sets   27  6.004  Spring 2009 3/10/09Summary
/.notdef.g0001 Programmable data paths provide some algorithmic exibility, just 
by changing control structure. 
/.notdef.g0001Interesting control structure optimization questions  e.g., what 
operations can be done simultaneously? 
/.notdef.g0001von Neumann model for general-purpose computation: need 
/.notdef.g0001support for suciently powerful operation repertoire 
/.notdef.g0001Expandable Memory 
/.notdef.g0001Interpreter for program stored in memory 
/.notdef.g0001 ISA design requires tradeos, usually based on benchmark results: 
art, engineering, evaluation &amp; incremental optimizations 
/.notdef.g0001Compilation strategy 
/.notdef.g0001runtime discipline for software implementation of a general 
class of computations 
/.notdef.g0001Typically enforced by compiler, run-time library, operating 
system.  Well see more of these!</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Instruction Sets   17  6.004  Spring 2009 3/10/09Do We Need Built-in Constants? 
P ercentage of the operations that use a constant operand 
One way to answer architectural questions is to evaluate the 
consequences of dierent choices using carefully chosen  representative 
benchmarks (programs and/or code sequences).  Make choices that are best according to some metric (cost, performance, ). 
Instruction Sets   18  6.004  Spring 2009 3/10/09Babys First Beta Program 
(fragment)
SUBC(r1,1,r2) | put N-1 into r2 
MUL(r2,r1,r2) | leave N*(N-1) in r2 Suppose we have N in r1, and want to compute N*(N-1), 
leaving the result in r2: 
These two instructions do what our little ad-hoc machine did.  Of course, 
limiting ourselves to registers for storage falls short of our ambitions....  it amounts to the nite storage limitations of an FSM! 
Needed: instruction-set support for reading and writing 
locations in main memory... 
Instruction Sets   19  6.004  Spring 2009 3/10/09/.notdef.g0002/.notdef.g0001 Loads &amp; Stores 
LD(ra,const,rc) Reg[rc]  = Mem[Reg[ra] + sxt(const)] 
ST(rc,const,ra) Mem[Reg[ra] + sxt(const)]  = Reg[rc] Fetch into rc the contents of the memory location whose 
address is C plus the contents of ra 
Abbreviation:  LD(C,rc) for   LD(R31,C,rc)
Store the contents of rc into the memory location whose 
address is C plus the contents of ra 
Abbreviation:  ST(rc,C)   for   ST(rc,C,R31)
BYTE ADDRESSES, but only 32-bit word accesses to word-aligned 
addresses are supported.  Low two address bits are ignored! OPCODE rc ra 16-bit signed constant 
address 
Instruction Sets   20  6.004  Spring 2009 3/10/09Storage Conventions 
Variables live in memory 
 Operations done on registers 
 Registers hold Temporary 
   values 
1000:
1004:
1008:
1010:100C:n
r
x
yAddr assigned at compile time int x, y; 
y = x * 37; 
LD(r31, 0x1008, r0) 
MULC(r0, 37, r0) 
ST(r0, 0x100C, r31) 
x=0x1008
y=0x100C
LD(x, r0) 
MULC(r0, 37, r0) 
ST(r0, y) translates 
to 
or, more 
humanely, 
to 
Ra defaults to R31 (0) Compilation approach: 
LOAD, COMPUTE, STORE TeX
Spice
GCC
TeX
Spice
GCC
TeX
Spice
GCCLoads
Compares
ALU operations
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%38%
26%
23%
83%
92%
49%
69%84%
52%
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Instruction Sets   9  6.004  Spring 2009 3/10/09A General-Purpose Computer 
The von Neumann Model 
Many architectural approaches to the general purpose computer have been explored.  
The one on which nearly all modern, practical computers is based was proposed by 
John von Neumann in the late 1940s.  Its major components are: 
Central 
Processing 
Unit
Central Processing Unit (CPU): containing several 
registers, as well as logic for performing a 
specied set of operations on their contents. Main
Memory 
Memory: storage of N words  of W bits each, where W 
is a xed architectural parameter, and N can be expanded to meet needs. Input/
Output 
I/O:  Devices for communicating with the outside world. Ah, an FSM! 
Like an 
Innite Tape? 
Hmm, guess J. 
von N was an 
engineer after 
all!  
Instruction Sets   10  6.004  Spring 2009 3/10/09The Stored Program Computer 
The von Neumann architecture easily addresses the rst two limitations of our 
simple programmable machine example: 
/.notdef.g0001A richer repertoire of operations, and 
/.notdef.g0001An expandable memory. 
But how does it achieve programmability ?
CPU fetches and executes  interprets  successive 
instructions of the program ... 
/.notdef.g0001Program is simply data for the interpreter, specifying 
what computation to perform 
/.notdef.g0001Single expandable resource pool  main memory  
constrains both data and program size. Key idea: Memory holds not only data, 
but coded instructions  that make up 
aprogram .Central 
Processing 
Unit
Instruction Sets   11  6.004  Spring 2009 3/10/09registers 
operations Anatomy of a von Neumann Computer 
Control 
UnitData 
Paths Internal storage 
MEMORY control 
status
instructions data
dest
asel
fnbsel
Ccs ALU PC1101000111011
 INSTRUCTIONS  coded as binary data 
PROGRAM COUNTER  or PC: Address of 
next instruction to be executed 
logic  to translate instructions into control 
signals for data path +1
R1/.notdef.g0001R2+R3address address 
Instruction Sets   12  6.004  Spring 2009 3/10/09Instruction Set Architecture 
Coding of instructions raises some interesting choices... 
/.notdef.g0001Tradeos: performance, compactness, programmability 
/.notdef.g0001Uniformity.  Should dierent instructions 
/.notdef.g0001Be the same size? 
/.notdef.g0001Take the same amount of time to execute? 
/.notdef.g0002/.notdef.g0001Trend: Uniformity.  Aords simplicity, speed, pipelinin g.
/.notdef.g0001Complexity.  How many dierent instructions?  What level operations? 
/.notdef.g0001Level of support for particular software operations: array indexing, 
procedure calls, polynomial evaluate, etc 
/.notdef.g0002/.notdef.g0001Reduced Instruction Set Computer (RISC) philosophy:  simple 
instructions, optimized for speed 
Mix of engineering &amp; Art... 
Trial (by simulation) is our best technique for making choices! 
Our representative example: the /.notdef.g0002 architecture! Main Memory  
data
data
datainstruction 
instruction 
instruction</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Instruction Sets   1  6.004  Spring 2009 3/10/09Designing an Instruction Set 
Nerd Chef at work. move   flour,bowl  
add    milk,bowl 
add    egg,bowl 
move   bowl,mixer  
rotate mixer 
...
Quiz 2 FRIDAY 
Instruction Sets   2  6.004  Spring 2009 3/10/09Lets Build a Simple Computer 
Data path for computing N*(N-1) 
*L.E.AL.E.B1N
-10           1 0             1 ASEL BSEL
BLE ALE
ANSWERL.E. = load enable.  Register only loads 
new value when LE=1 
Instruction Sets   3  6.004  Spring 2009 3/10/09A Programmable Control System 
Computing N*(N-1) with this data path is a multi-step process. We can control 
the processing at each 
step with a FSM. If we 
allow dierent control 
sequences to be loaded 
into the control FSM, then we allow the machine to 
be programmed.
Control 
FSM ALEBLEASELBSELA/.notdef.g0001 1
A/.notdef.g0001 A * B 
B/.notdef.g0001 B - 1 B/.notdef.g0001 N
A/.notdef.g0001 A * B 
Instruction Sets   4  6.004  Spring 2009 3/10/09A First Program 
A/.notdef.g0001 1
A/.notdef.g0001 A * B 
B/.notdef.g0001 B - 1 B/.notdef.g0001 N
A/.notdef.g0001 A * B S0
S1
S2S3
S4Once more, writing a control program is  
nothing more than lling in a table: 
SNSN+1 Asel ALEBsel BLE
0
1234SNSN+1 Asel ALEBsel BLE
0 11101
1 20100
2 30011
3 40100
4 40000</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Instruction Sets   21  6.004  Spring 2009 3/10/09/.notdef.g0002/.notdef.g0002 can do these with appropriate 
choices for Ra and const Common Addressing Modes 
/.notdef.g0001Absolute : constant 
/.notdef.g0001Value = Mem[constant] 
/.notdef.g0001Use: accessing static data 
/.notdef.g0001Indirect (aka Register deferred) : (Rx) 
/.notdef.g0001Value = Mem[Reg[x]] 
/.notdef.g0001Use: pointer accesses 
/.notdef.g0001Displacement : constant(Rx) 
/.notdef.g0001Value = Mem[Reg[x] + constant] 
/.notdef.g0001Use: access to local variables 
/.notdef.g0001Indexed : (Rx + Ry) 
/.notdef.g0001Value = Mem[Reg[x] + Reg[y]] 
/.notdef.g0001Use: array accesses (base+index) /.notdef.g0001Memory indirect : @(Rx) 
/.notdef.g0001Value = Mem[Mem[Reg[x]]] 
/.notdef.g0001Use: access thru pointer in mem 
/.notdef.g0001Autoincrement : (Rx)+ 
/.notdef.g0001Value = Mem[Reg[x]]; Reg[x]++ 
/.notdef.g0001Use: sequential pointer accesses 
/.notdef.g0001Autodecrement : -(Rx) 
/.notdef.g0001Value = Reg[X]--; Mem[Reg[x]] 
/.notdef.g0001Use: stack operations 
/.notdef.g0001Scaled : constant(Rx)[Ry] 
/.notdef.g0001Value = Mem[Reg[x] + c + d*Reg[y]] 
/.notdef.g0001Use: array accesses (base+index) 
Argh!   Is the complexity worth the cost? 
Need a cost/benet analysis! 
Instruction Sets   22  6.004  Spring 2009 3/10/09Memory Operands: Usage 
Usage of dierent memory operand modes 
Instruction Sets   23  6.004  Spring 2009 3/10/09Capability so far: Expression Evaluation 
Translation of an Expression: 
int x, y; 
y = (x-3)*(y+123456) 
x: long(0)
y: long(0)c: long(123456)
...
LD(x, r1) SUBC(r1,3,r1)
LD(y, r2) 
LD(c, r3) ADD(r2,r3,r2)MUL(r2,r1,r1)ST(r1,y)VARIABLES are allocated 
storage in main memory
VARIABLE references translate 
to LD or ST 
 OPERATORS translate to ALU 
instructions 
 SMALL CONSTANTS translate 
to ALU instructions w/ built-in 
constant 
 LARGE CONSTANTS translate 
to initialized variables 
NB: Here we assume  that 
variable addresses t into 16-
bit constants! 
Instruction Sets   24  6.004  Spring 2009 3/10/09Can We Run Every Algorithm? 
Needed:
ability to 
change the 
PC.Model thus far: 
/.notdef.g0001Executes instructions sequentially  
/.notdef.g0001Number of operations executed = 
number of instructions in our program! 
Good news: programs cant loop forever! 
/.notdef.g0001Halting problem*  is solvable for our 
current Beta subset! 
Bad news: cant compute Factorial: 
/.notdef.g0001Only supports bounded-time 
computations; 
/.notdef.g0001Cant do a loop, e.g. for Factorial! NOT
Universal* *more next week! TeX
Spice
GCC
TeX
Spice
GCC
TeX
Spice
GCC
TeX
Spice
GCC
TeX
Spice
GCCAutoincrement
Displacement
Displacementdeferred
deferredScaled
Register
0% 10% 20% 30% 40% 50% 60% 70% 80%1%
3%
4%
2%
7%
2%
0%
20%
9%
41%
4%
18%
56%
66%
67%
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Devices and interrupt handlers, preemptive interrupts, real-time issues</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec19/</lecture_pdf_url>
      <lectureno>19</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>L19  Devices &amp; Interrupts   17  6.004  Spring 2009 4/16/09Weak (non-preemptive) Priorities 
ISSUE: Processor becomes 
interruptable (at fetch of next 
instruction), several interrupt 
requests are pending.  Which is 
served rst? 
LATENCIES with WEAK PRIORITIES:    Service of each device might be 
delayed by: 
/.notdef.g0001Service of 1 other (arbitrary) device, whose interrupt request 
was just honored; PLUS 
/.notdef.g0001Service of ALL higher-priority 
devices. DPK
Req:
P,D,KReq:
K,P,DKPD
DEVICE  
Keyboard  
Disk  
Printer  Service  
Time  
800  
500  400  Actual w/c  
Latency  
________  ________  ________  900
800
1300WEAK PRIORITY ORDERING :  Check in prescribed sequence, eg: 
   DISK &gt; PRINTER &gt; KEYBOARD. 
vs 1200  
Now delayed by only 1 service! 
L19  Devices &amp; Interrupts   18  6.004  Spring 2009 4/16/09The Need for Preemption 
Without preemption, ANY interrupt service can delay ANY other service 
request the slowest service time constrains response to fastest 
devices.  Often, tight deadlines cant be met using this scheme alone. 
EXAMPLE: 800 uSec deadline (hence 300 uSec maximum interrupt 
latency) on disk service, to avoid missing next sector... 
DEVICE  
Keybrd  
Disk  
Printer  Serv.  
Time  
800  
500  
400  Actual  
Latency  
900  
800  
1300  Max.  
Delay  
300  
need PREEMPTION:  Allow handlers for LOWER PRIORITY interrupts to be 
interrupted by HIGHER priority requests! Latency 
w/preemption Priority 
1
3
2~0
[D] 500 D,P   900 
CAN'T SATISFY the disk requirement in this system using weak priorities! 
L19  Devices &amp; Interrupts   19  6.004  Spring 2009 4/16/09Strong Priority Implementation 
SCHEME:
/.notdef.g0001Expand E bit in PC to be a PRIORITY integer PRI  
(eg, 3 bits for 8 levels) 
/.notdef.g0001ASSIGN a priority to each device. 
/.notdef.g0001Prior to each instruction execution: 
/.notdef.g0001/.notdef.g0001Find priority Pi of highest requesting device, say Di
/.notdef.g0001/.notdef.g0001Take interrupt if and only if Pi &gt; PRI, set PRI = Pi.
Strong priorities: 
     KEY:  Priority in Processor state 
     Allows interruption of (certain) handlers 
     Allows preemption, but not reentrance 
     BENEFIT: Latency seen at high priorities UNAFFECTED by service times 
       at low priorities. PC: Program Counter PRI
L19  Devices &amp; Interrupts   20  6.004  Spring 2009 4/16/09Recurring Interrupts 
DEVICE  
Keybrd  
Disk  
Printer  Serv.  
Time  
800  
500  
400  Actual  
Latency  
900  
0
500  Max.  
Delay  
300  P
354Max.  
Freq  
100/s  500/s  
1000/s  Consider interrupts which recur at bounded rates: 
Note that interrupt LATENCIES don't tell 
the whole storyconsider COMPLETION 
TIMES, eg for Keyboard in example to the 
right.
Keyboard service not complete until 3ms 
after request.  Often deadlines used
rather than max. delays. D
P
KPP
DPPDDP K DP DPP</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L19  Devices &amp; Interrupts   13  6.004  Spring 2009 4/16/09Interrupt Latency 
One way to measure the real-time performance of a system is INTERRUPT
LATENCY: 
/.notdef.g0001HOW MUCH TIME can elapse between an interrupt request and the 
START of its handler? 
time 
Request Latency Service 
Time Deadline? 
OFTEN  bad things happen when service is delayed beyond 
some deadline  - "real time" considerations: 
Missed characters System crashes 
Nuclear meltdowns HARD
Real time 
constraints 
L19  Devices &amp; Interrupts   14  6.004  Spring 2009 4/16/09Sources of Interrupt Latency 
What causes interrupt latency: 
/.notdef.g0001State save, context switch. 
/.notdef.g0001P eriods of uninterruptability: 
/.notdef.g0001/.notdef.g0001Long, uninterruptable instructions -- eg block moves, multi-level indirection. 
/.notdef.g0001/.notdef.g0001Explicitly disabled periods (eg for atomicity, during service of other 
interrupts). 
GOAL:  BOUND (and minimize) interrupt latency! 
/.notdef.g0001Optimize interrupt sequence context switch 
/.notdef.g0001Make unbounded-time instructions INTERRUPTABLE (state in registers, etc). 
/.notdef.g0001Avoid/minimize disable time 
/.notdef.g0001Allow handlers to be interrupted, in certain cases (while still avoiding reentrant
handlers!).  time 
Request Latency Service 
Time Deadline? 
We can consider this 
when we write our O/S We can address this in our ISA 
But, this is application 
dependent! 
L19  Devices &amp; Interrupts   15  6.004  Spring 2009 4/16/09Interrupt Disable/Enable 
E
Interrupt 
Enable/
Disable bit (Misc. other stu:
Context, K/U mode, 
etc.) INTERRUPT DISABLE 
BIT (part of processor 
status)...  in PC: 
Often in separate 
Processor Status
Word ... 
E=1: DISABLED 
E=0: ENABLED
e.g.
/.notdef.g0001BETA K-mode bit 
(disables interrupts, 
other functions) 
/.notdef.g0001Often separate bit/
mechanism PC
TYPICAL OPERATION: (as with Beta K-mode bit): 
/.notdef.g0001ONLY take interrupts if E=0; else defer. 
/.notdef.g0001SAVE OLD E on interrupt, install new E from interrupt vector (along 
with PC, etc).  New E=1 (to disable interrupts during handler). 
/.notdef.g0001Run handler, with interrupts disabled. 
/.notdef.g0001On JMP (at return from handler), saved state restored to processor, 
resuming interrupted program (with E=0 again). 
L19  Devices &amp; Interrupts   16  6.004  Spring 2009 4/16/09Scheduling of Multiple Devices 
DEVICE  
Keyboard  
Disk  
Printer  Service  
Time  
800  
500  400  Actual w/c  
Latency  
________  ________  ________  "TOY" System scenario: 
What is the WORST CASE latency seen by each device? 
Req: K,P ,DP K D
Req: D,P ,KD P K
Req: K,D,PK D P
Assumptions:
/.notdef.g0001Infrequent interrupt requests (each happens only once/scenario) 
/.notdef.g0001Simultaneous requests might be served in ANY order. Whence 
/.notdef.g0001Service of EACH device might be delayed by ALL others! 
 can we improve this? 500 + 400 = 900 
800 + 400 = 1200 
800+ 500 = 1300</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L19  Devices &amp; Interrupts   5  6.004  Spring 2009 4/16/09Asynchronous I/O Handling 
SVC call from application Application: 

ReadKey() | read key into R0 

. . . A Device Buer
(in OS Kernel) 
KEYhit_h() { 
   (read ASCII code, put in buer)
}
INTERRUPT from Keyboard n INTERRUPT
to OS IN OUT ReadKEY_h() { 
(remove next char from buer,  return in R0) 
   } TRAP to OS 
IN OUT 
L19  Devices &amp; Interrupts   6  6.004  Spring 2009 4/16/09Interrupt-based Asynchronous I/O 
struct Device { 
  char Flag, Data; } Keyboard; 
KEYhit_h() { 
  Buffer[inptr] = Keyboard.Data;   inptr = (inptr + 1) % BUFSIZE; 
}OPERATION:  NO attention to Keyboard during normal operation 
 on key strike: hardware asserts IRQ to request interrupt 
 USER program interrupted, PC+4 of interrupted inst. saved in XP 
 state of USER program saved on KERNEL stack; 
 KeyboardHandler invoked, runs to completion; 
 state of USER program restored; program resumes. 
TRANSPARENT to USER program. 
Keyboard Interrupt Handler (in O.S. KERNEL): 
Assume each 
keyboard has 
an associated 
buer
L19  Devices &amp; Interrupts   7  6.004  Spring 2009 4/16/09ReadKey SVC: Attempt #1 
Asupervisor call  (SVC) is an instruction that transfers control to the kernel so 
it can satisfy some user request.  Kernel returns to user program when 
request is complete. 
First draft of a ReadKey SVC handler (supporting  a Virtual  Keyboard): returns 
next keystroke on a users keyb oard to that users requesting application: 
Problem: Cant interrupt code running in the supervisor mode so the buer never gets lled.ReadKEY_h()
{
int kbdnum = ProcTbl[Cur].DPYNum; while (BufferEmpty(kbdnum)) { 
/* busy wait loop */ 
}
User.Regs[0] = ReadInputBuffer(kbdnum);  
}ReadKEY_h()
{
int kbdnum = ProcTbl[Cur].DPYNum; while (BufferEmpty(kbdnum)) { 
/* busy wait loop */ 
}
User.Regs[0] = ReadInputBuffer(kbdnum);  
}
L19  Devices &amp; Interrupts   8  6.004  Spring 2009 4/16/09ReadKey SVC: Attempt #2 
A BETTER keyboard SVC handler: 
ReadKEY_h()
{
int kbdnum = ProcTbl[Cur].DPYNum; if (BufferEmpty(kbdnum)) { 
   /* busy wait loop */ 
User.Regs[XP] = User.Regs[XP]-4; 
} else 
   User.Regs[0] = ReadInputBuffer(kbdnum); 
}Thats a 
funny way 
to write 
a loop 
Problem: The process just wastes its time-slice waiting for 
someone to hit a key... This one actually works!</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L19  Devices &amp; Interrupts   9  6.004  Spring 2009 4/16/09ReadKey SVC: Attempt #3 
EVEN BETTER: On I/O wait, YIELD remainder of quantum: 
ReadKEY_h()
{
int kbdnum = ProcTbl[Cur].DPYNum; if (BufferEmpty(kbdnum)) { 
User.Regs[XP] = User.Regs[XP]-4; 
Scheduler( ); 
} else 
   User.Regs[0] = ReadInputBuffer(kbdnum); 
}
RESULT: Better CPU utilization!! 
Does timesharing cause CPU use to be less ecient?
/.notdef.g0001COST: Scheduling, context-switching overhead; but 
/.notdef.g0001GAIN: Productive use of idle time of one process by running another. 
L19  Devices &amp; Interrupts   10  6.004  Spring 2009 4/16/09Sophisticated Scheduling 
To improve eciency further, we can avoid scheduling processes in 
prolonged I/O wait:
/.notdef.g0001Processes can be in ACTIVE or WAITING (sleeping) states; 
/.notdef.g0001Scheduler cycles among ACTIVE PROCESSES only; 
/.notdef.g0001Active process moves to WAITING status when it tries to read 
a character and buer is empty; 
/.notdef.g0001Waiting processes each contain a code (eg, in PCB) designating 
what they are waiting for (eg, keyboard N); 
/.notdef.g0001Device interrupts (eg, on keyboard N) move any processes 
waiting on that device to ACTIVE state. 
UNIX kernel utilities:
/.notdef.g0001sleep(reason) - Puts CurProc to sleep.  Reason is an arbitrary 
binary value giving a condition for reactivation. 
/.notdef.g0001wakeup(reason) - Makes active any process in sleep(reason). 
L19  Devices &amp; Interrupts   11  6.004  Spring 2009 4/16/09ReadKey SVC: Attempt #4 
ReadKEY_h() { 
    
   if (BuerEmpty(kbdnum)) { 
      User.Regs[XP] = User.Regs[XP] - 4; 
      sleep(kbdnum); 
    }sleep(status s) { 
   ProcTbl[Cur].status = s; 
   Scheduler() 
}
Scheduler() { 
    
   while (ProcTbl[i].status != 0) { 
      i = (i+1)%N; 
   } 
    
}wakeup(status s) { 
   for (i = 0; i &lt; N; i += 1) { 
      if (ProcTbl[i].status == s) 
         PCB[i].status = 0; 
   } 
}SVC call from application 
KEYhit_h() { 
    
      WriteBuer(kbdnum, key) 
      wakeup(kbdnum); 
    
}
INTERRUPT from Keyboard n 
L19  Devices &amp; Interrupts   12  6.004  Spring 2009 4/16/09The Need for Real Time 
Side-eects of CPU virtualization 
+ abstraction of machine resources 
(memory, I/O, registers, etc. ) 
+ multiple processes executing concurrently
+ better CPU utilization -  Processing throughput is more variable 
Our approach to dealing with the asynchronous world 
- I/O - separate event handling   from event processing 
Dicult to meet hard deadlines 
- control applications- playing videos/MP3s 
Real-time as an alternative to time-sliced
or xed-priority preemptive scheduling</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L19  Devices &amp; Interrupts   21  6.004  Spring 2009 4/16/09Interrupt Load 
DEVICE  
Keybrd  
Disk  
Printer  Serv.  
Time  
800  
500  400  Actual  
Latency  
900  
0
500  Max.  
Delay  
300  P
354Max.  
Freq  
100/s  
500/s  
1000/  %
Load  
______  
______  ______  How much CPU time  is consumed by interrupt service? 
D
P
KPP
DPPD PPD D
P
KPP
DP10 ms. cycle 
800u*100/s = 8% 
500u*500/s = 25% 
400u*1000/s = 40% 
Remaining fraction (27%) is left over for application; trouble if its &lt;0! 
L19  Devices &amp; Interrupts   22  6.004  Spring 2009 4/16/09&lt; 10 mS Task Period Service time    Deadline 
Supply ship guidance 30ms 5ms          25ms 
Gyroscopes 40 10          20 
Cabin pressure 100 ?          100 Example: Ben visits ISS 
International Space Stations on-board computer performs 3 tasks: 
/.notdef.g0001 guiding incoming supply ships to a safe docking 
/.notdef.g0001 monitoring gyros to keep solar panels properly oriented 
/.notdef.g0001 controlling air pressure in the crew cabin 
Assuming a weak priority system :
1. What is the maximum service time for cabin pressure that 
still allows all constraints to be met?  
2. Give a weak priority ordering that meets the constraints 
3. What fraction of the time will the processor spend idle? 
4. What is the worst-case delay for each type of interrupt until 
completion of the corresponding service routine? 16.6 % 
25%
10%
G &gt; SSG &gt; CP 
48.33%C,G = 10 + 10 + (5) = 25 
C     = 10 + (10) = 20 S,G = 5 + 10 + (10) = 25 
10
L19  Devices &amp; Interrupts   23  6.004  Spring 2009 4/16/09Example: Ben visits ISS (contd) 
Our Russian collaborators dont like the sound of a weak priority 
interrupt system and lobby heavily to use a strong priority interrupt system instead. 
Task Period Service time    Deadline 
Supply ship guidance 30ms 5ms          25ms 
Gyroscopes 40 10          20 
Cabin pressure 100 ?          100 
Assuming a strong priority system,    G &gt; SSG &gt; CP: 
1. What is the maximum service time for cabin pressure that 
still allows all constraints to be met? 
2. What fraction of the time will the processor spend idle? 
3. What is the worst-case delay for each type of interrupt until 
completion of the corresponding service routine? 100  (3*10)  (4*5) = 50 5016.6%
25%
50%
8.33%[G] 10 + 5 
10
100
L19  Devices &amp; Interrupts   24  6.004  Spring 2009 4/16/09Summary
Device interface  two parts: 
/.notdef.g0001Device side: handle interrupts from device (transparent to apps) 
/.notdef.g0001Application side: handle interrupts (SVCs) from application 
Scheduler interaction: 
/.notdef.g0001Sleeping (*inactive) processes waiting for device I/O 
/.notdef.g0001Handler coding issues, looping thru User mode 
Real Time constraints, scheduling, guarantees 
/.notdef.g0001Complex, hard scheduling problems  a black art! 
/.notdef.g0001Weak (non-preemptive) vs Strong (preemptive) priorities help 
/.notdef.g0001Common real-world interrupt systems: 
-/.notdef.g0001Fixed number (eg, 8 or 16) of strong priority levels 
-/.notdef.g0001Each strong priority level can support many devices, arranged 
in a weak priority chain 
/.notdef.g0001
/.notdef.g0001
/.notdef.g0001/.notdef.g0001
/.notdef.g0001
/.notdef.g0001
/.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L19  Devices &amp; Interrupts   1  6.004  Spring 2009 4/16/09Devices &amp; Interrupts
Lab #6 due tonight! Loop:
  LD(R3,0,R0)   ADDC(R3,4,R3) 
  SUBC(R2,1,R2) 
  BNE(R2,Loop) 
   (Cough) Excuse me, sir 
modied 4/13/09 10:14 L19  Devices &amp; Interrupts   2  6.004  Spring 2009 4/16/09Why an OS? 
What weve got: 
/.notdef.g0001A Single Sequence Machine, capable of doing ONE thing at a time  one 
instruction, one I/O operation, one program. 
/.notdef.g0001A universe of gadgets  e.g. I/O devices  that do similar things 
slightly dierently.
What wed like: 
/.notdef.g0001To listen to MP3s while reading email. 
/.notdef.g0001To access disk, network, and screen simultaneously. 
/.notdef.g0001To write a single program that does I/O with anybodys disk. 
Plausible approaches: 
/.notdef.g0001An innite supply of identical computers with 
uniform, high-level peripherals for every 
conceivable purpose or 
/.notdef.g0001An illusion: Make one real computer look like 
many virtual ones. 
L19  Devices &amp; Interrupts   3  6.004  Spring 2009 4/16/09Operating Systems 
An OS is the Glue that holds a 
computer together. 
  - Mediates between 
    competing requests 
  - Resolves 
     names/bindings 
- Maintains 
     order/fairness 
KERNEL - a RESIDENT portion 
of the O/S that handles the 
most common and 
fundamental service 
requests.
vir.tu.al \'v*rch-(*-)w*l, 'v*r-ch*l\ \.v*r-ch*-'wal-*t-e-\  \'v*rch-(*-)w*-le-, 'v*rch-(*-)le-
\ aj [ME, possessed of certain physical virtues, fr. ML virtualis, fr. L virtus strength, 
virtue : being in essence or effect but not in fact  - vir.tu.al.i.ty n Hardware 
Registers ALUs 
PCsCaches Kernel  Operating System Applications 
Device Drivers 
Scheduler Process Control 
Blocks (PCBs) Shared 
Libraries Word Processors 
Graphical User  
Interface (GUI) Games Spread Sheets 
Web 
Browser 
Page Tables Device 
Queues 
Network Interfaces Security 
File system 
I/O Devices 
L19  Devices &amp; Interrupts   4  6.004  Spring 2009 4/16/09OS organization 
Applications are quasi-parallel 
PROCESSES
          on
          VIRTUAL MACHINES,
each with: 
/.notdef.g0001 CONTEXT (virtual address space) 
/.notdef.g0001 Virtual I/O devices
O.S. KERNEL has: 
/.notdef.g0001 Interrupt handlers 
/.notdef.g0001 SVC (trap) handlers 
/.notdef.g0001 Scheduler 
/.notdef.g0001 PCB structures containing the 
state of inactive processesScheduler
KERNELP1 P2
SVC 1 handler SVC 0 handler 
I/O Handler 
Device
0Alarm Clock I/O Handler 
Device
1
DPYNum=0
DPYNum=1PCBs:
    P1: 
    P2: loop:SVC(0)
...
SVC(1)
...
BR(loop)loop:SVC(0)
...
SVC(1)
...
BR(loop)</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>CMOS technology, gate design, timing</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec03/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>L03 - CMOS Technology   17  6.004  Spring 2009 2/10/09The Combinational Contract  
ABA  B 
0  1 
1  0 tPD propagation delay 
tCDcontamination delay 
A
B
Must be ___________Must be ___________
Note: 
  1. No Promises during
  2. Default (conservative) spec: tCD = 0 &lt; tPD&gt; tCD
L03 - CMOS Technology   18  6.004  Spring 2009 2/10/09Acyclic Combinational Circuits  
If NAND gates have a tPD = 4nS and tCD = 1nS 
B
C
AYtPD = _______ nS 
tCD = _______ nS 12
2
tPD is the maximum  cumulative 
propagation delay over all paths 
from inputs to outputs tCD is the minimum  cumulative 
contamination delay over all paths from inputs to outputs 
L03 - CMOS Technology   19  6.004  Spring 2009 2/10/09Oh yeah one last issue 
Recall the rules for combinational devices :
Output guaranteed to be valid when all  inputs have been 
valid for at least tPD, and, outputs may become invalid no 
earlier than tCD after an input changes!A
B
ZtPD
tCDAZB0
0
1
101
0
110
0
0AB Z
NOR:A
B
ZtPD
tCD
Many gate implementations--e.g., CMOS 
adhere to even tighter restrictions. 
L03 - CMOS Technology   20  6.004  Spring 2009 2/10/09What happens in this case?  
A
B
ZtPD
tCDInput A alone is 
sucient to 
determine the 
output
AB
Z
A
B
Z0
X
101
X10
0AB Z
0
0
1
101
0
110
0
0AB ZNOR: Lenient 
NOR:LENIENT  Combinational Device: 
Output guaranteed to be valid when any  combination of inputs 
sucient to determine output value has been valid for at least tPD.
Tolerates transitions -- and invalid levels -- on irrelevant inputs! CMOS NOR:</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L03 - CMOS Technology   9  6.004  Spring 2009 2/10/09CMOS complements  What a nice 
VOH you have... 
Thanks.  It runs in the family... 
conducts when VGS is high conducts when VGS is low 
conducts when A is high 
and  B is high:  A.BA
BAB
conducts when A is low 
or B is low: A+B = A.B
conducts when A is high 
or B is high:  A+B AB
AB
conducts when A is low 
and  B is low: A.B = A+B 
L03 - CMOS Technology   10  6.004  Spring 2009 2/10/09A pop quiz!  
A
BWhat function does 
this gate compute? 
A   B           C 
0   0 
0   1 1   0 1   1 
1
1    NAND 1
0
16/.notdef.g0004/.notdef.g000482/.notdef.g0004/.notdef.g0004
Current technology: /.notdef.g0004/.notdef.g0004 = 45nm 
COST: 
/.notdef.g0001 $3500 per 300mm wafer 
/.notdef.g0001 300mm round wafer = /.notdef.g0002/.notdef.g0002(150e-3)2= .07m2
/.notdef.g0001NAND gate = (82)(16)(45e-9)2=2.66e-12m2
/.notdef.g00012.6e10 NAND gates/wafer (= 100 billion FETS!) 
/.notdef.g0001 marginal cost of NAND gate: 132n$
L03 - CMOS Technology   11  6.004  Spring 2009 2/10/09Heres another  
What function does 
this gate compute? 
A   B          C 
0   0 
0   1 1   0 1   1 AB
1
0    NOR 0
0
L03 - CMOS Technology   12  6.004  Spring 2009 2/10/09General CMOS gate recipe  
Step 1.  Figure out pulldown network that 
does what you want, e.g.,
(What combination of inputs 
generates a low output) A
BC
Step 2.  Walk the hierarchy replacing nfets with pfets, series subnets with parallel 
subnets, and parallel subnets with series 
subnets AB
C
So, whats the big 
deal?  
Step 3.  Combine pfet pullup network from Step 2 with nfet pulldown 
network from Step 1 to form fully-
complementary CMOS gate. AB
C
A
BCF=A(B+C)</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L03 - CMOS Technology   5  6.004  Spring 2009 2/10/09FETs come in two avors  
The use of both NFETs and PFETs  complimentary transistor types  is a key 
to CMOS (complementary MOS) logic families. p p
nGD S B
G
SD
BGS
DBConnect B to 
GND to keep PN 
reverse-biased 
(Vp &lt; Vn); keeps D  
and S insulated 
from B Connect B to VDD to keep 
PN reverse-
biasedn n
pD SG
BNFET: n-type source/drain 
diusions in a p-type substrate.  P ositive threshold voltage; inversion forms n-type channel PFET: p-type source/drain diusions in a n-type substrate.  Negative threshold voltage; inversion forms p-type channel. 
L03 - CMOS Technology   6  6.004  Spring 2009 2/10/09CMOS Recipe  
D
G
S
SD
SD NFET Operating regions: 
  o:
        VG &lt; VTH,NFET
  on: 
       VG &gt;  VTH,NFETS
G
D
PFET Operating regions: 
    o:
        VG &gt; VDD + VTH,PFET
    on: 
       VG &lt; VDD + VTH,PFETSD
SD If we follow two rules when constructing CMOS circuits then we can model the 
behavior of the mosfets as simple switches: 
     Rule #1: only use NFETs in pulldown circuits (paths from output node to GND) 
     Rule #2: only use PFETs in pullup circuits (paths from output node to VDD)
~VDD/5 ~ -VTH,NFET
L03 - CMOS Technology   7  6.004  Spring 2009 2/10/09VOL
VILVIHVOHCMOS Inverter VTC  
VinVout
Ipu
Ipd Steady state reached 
when Vout reaches value 
where Ipu = Ipd.
When VIN is low, the 
nfet is o and the pfet 
is on, so current ows 
into the output node 
and VOUT eventually 
reaches VDD (= VOH) at 
which point no more current will ow. 
pfet on 
nfet oWhen VIN is high, the 
pfet is o and the nfet 
is on, so current ows 
out of the output node  
and VOUT eventually 
reaches GND (= VOL) at  
which point no more current will ow. 
pfet o
nfet on 
When VIN is in the middle, both the pfet and nfet are on and the shape of the VTC 
depends on the details of the devices characteristics.   CMOS gates have very high gain 
in this region (small changes in VIN produce large changes in VOUT) and the VTC is almost a 
step function. 
L03 - CMOS Technology   8  6.004  Spring 2009 2/10/09Beyond Inverters:  
Complementary pullups and pulldowns  
We want complementary  pullup and pulldown logic, i.e., the 
pulldown should be on when the pullup is o and vice 
versa. 
pullup pulldown F(A1,,An)
on o driven 1 
o on driven 0 on on driven X o o no connection Now you know what the C 
in CMOS stands for! 
Since theres plenty of capacitance on the output node, when the output  becomes disconnected it remembers its previous voltage -- at least 
for a  while.  The memory is the load capacitors charge. Leakage 
currents will cause eventual decay of the charge (thats why DRAMs 
need to be refreshed!).</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L03 - CMOS Technology   21  6.004  Spring 2009 2/10/09Big Issue 2: Power  
Energy dissipated = C VDD2per cycle
P ower consumed = f n C VDD2per chip 
  where  f = frequency of charge/discharge 
  n = number of gates /chipVINVDD
CVOUT VIN moves from  
L to H to L VOUT moves from  
H to L to H 
C discharges and 
then recharges 
L03 - CMOS Technology   22  6.004  Spring 2009 2/10/09Unfortunately  
Modern chips (UltraSparc III, Power4, Itanium 2) dissipate from 80W to 150W with a Vdd  1.2V (Power supply current is  100 Amps) 
Hey: could we 
Somehow recycle 
the charge? Worse yet 
/.notdef.g0001Little room left to reduce Vdd 
/.notdef.g0001nC and f continue to grow Cooling challenge is like making the lament of a 
100W incandescent lamp cool to the touch! 
L03 - CMOS Technology   23  6.004  Spring 2009 2/10/09MUST computation consume energy?  
(a tiny digression)  
A   B           C 
0   0 
0   1 1   0 1   1 1110
How energy-ecient can we make a gate?  It 
seems that switching the input to a NAND gate  
will always dissipate some energy 
Landauers Principle (1961): discarding 
information  is what costs energy! 
Bennett (1973): Use reversible  logic gates, not NAND, and theres no lower 
bound to energy use! NAND GATE:  
2 bits /.notdef.g0003 1 bit  
(information  
Loss!)  
A   B 
0   0 
0   1 1   0 1   1 0011P   Q 
0110
FEYNMAN  
GATE:  
2 bits /.notdef.g0003 2 bits  
(information  
Preserving!)  Bennett, Fredkin, Feynman, others : Computer 
systems constructed from info-
preserving elements.  
Theory :  NO  lower bound on energy use! 
Practice :  Research frontier (qubits, etc.) http://www.research.ibm.com/journal/rd/441/landauerii.pdf 
The fundamental physical limits of computation , Bennett &amp; Landauer, Scientic American. Vol. 253, pp. 48-56. July 1985 http://www.research.ibm.com/journal/rd/176/ibmrd1706G.pdf 
L03 - CMOS Technology   24  6.004  Spring 2009 2/10/09Summary  
/.notdef.g0001CMOS
/.notdef.g0001Only use NFETs in pulldowns, PFETs in pullups /.notdef.g0003 mosfets behave as 
voltage-controlled switches 
/.notdef.g0001Series/parallel Pullup and pulldown switch circuits are 
complementary 
/.notdef.g0001CMOS gates are naturally inverting (rising input transition can only 
cause falling output transition, and vice versa). 
/.notdef.g0001P erfect VTC (high gain, VOH = VDD, VOL = GND) means large noise 
margins and no static power dissipation.
/.notdef.g0001Timing specs 
/.notdef.g0001tPD: upper bound on time from valid inputs to valid outputs 
/.notdef.g0001tCD: lower bound on time from invalid inputs to invalid outputs 
/.notdef.g0001If not specied, assume tCD = 0 
/.notdef.g0001Lenient gates: output unaected by some input transitions
/.notdef.g0001Next time: logic simplication, other canonical forms</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L03 - CMOS Technology   1  6.004  Spring 2009 2/10/09CMOS Technology  
1. Qualitative MOSFET model 
2. CMOS logic gates 3. CMOS design issues 
poly metal 
pdindi
modied 2/9/09 15:07 NEXT WEEK: 
/.notdef.g0001 TUE: no lecture 
/.notdef.g0001 THU: Lab 1 due! 
/.notdef.g0001 FRI: QUIZ 1!!! 
L03 - CMOS Technology   2  6.004  Spring 2009 2/10/09Combinational Device Wish List  
/.notdef.g0001/.notdef.g0001Design our system to tolerate some amount of error /.notdef.g0007
/.notdef.g0007 Add positive noise margins 
/.notdef.g0007/.notdef.g0007 VTC: gain&gt;1 &amp; nonlinearity 
/.notdef.g0001/.notdef.g0001Lots of gain /.notdef.g0007 /.notdef.g0007 big noise margin 
/.notdef.g0001/.notdef.g0001Cheap, small 
/.notdef.g0001/.notdef.g0001Changing voltages will require 
us to dissipate power, but if no 
voltages are changing, wed like 
zero power dissipation 
/.notdef.g0001/.notdef.g0001Want to build devices with 
useful functionality (what sort 
of operations do we want to 
perform?)VOL
VILVIHVOH
VinVout Vin
Vout
L03 - CMOS Technology   3  6.004  Spring 2009 2/10/09
W
LMOSFETS: Gain &amp; non-linearity  
gate 
drain source 
bulkInter-layer SiO2 insulation P olysilicon wire 
Doped (p-type or n-type) silicon substrate Very thin (&lt;20) high-quality SiO2
insulating layer isolates gate from channel 
region. Heavily doped (n-type or p-type) diusions
Channel region: electric eld from charges on 
gate locally inverts type of substrate to create 
a conducting channel between source and drain. 
MOSFETs (metal-oxide-semiconductor eld-eect transistors) are four-
terminal voltage-controlled switches.  Current ows between the diusion terminals if the voltage on the gate terminal is large enough to 
create a conducting channel, otherwise the mosfet is o and the 
diusion terminals are not connected. 
IDS/.notdef.g0006/.notdef.g0006 W/L 
L03 - CMOS Technology   4  6.004  Spring 2009 2/10/09FETs as switches  
CONDUCTION: 
If a channel exists, a 
horizontal eld will 
cause a drift current 
from the drain to the 
source. Ehgate 
INVERSION:A suciently strong vertical eld will attract enough 
electrons to the surface to create a conducting n-
type channel between the source and drain.  The gate 
voltage when the channel rst forms is called the 
threshold voltage  -- the mosfet switch goes from o
to on. Ev
inversion 
happens here The four terminals of a Field Eect Transistor (gate, source, drain and bulk) 
connect to conductors that generate a complicated set of electric elds in the channel region which depend on the relative voltages of each terminal. 
pn nsource drain 
bulkDepletion region 
(no carriers) 
forms at PN 
junction.  Self 
insulating!</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L03 - CMOS Technology   13  6.004  Spring 2009 2/10/09A Quick Review  
/.notdef.g0001Acombinational device  is a circuit element that has
/.notdef.g0001one or more digital inputs
/.notdef.g0001one or more digital outputs
/.notdef.g0001afunctional specication  that details the value of each output for 
every possible combination of valid input values 
/.notdef.g0001atiming specication consisting (at minimum) of an upper bound 
tPD on the required time for the device to compute the specied 
output values from an arbitrary set of stable, valid input values Static
discipline
If C is 1 then copy A to Y , 
otherwise copy B to Y
I will generate a valid 
output in no more than 
2 weeks after  
seeing valid inputsinput A
input B
input Coutput Y 
L03 - CMOS Technology   14  6.004  Spring 2009 2/10/09Big Issue 1: Wires  
Today (i.e., 100nm): 
/.notdef.g0005/.notdef.g0005RC 50ps/mm 
Implies &gt; 1 ns to traverse a 20mm x 20mm chip 
This is a long time in a 2GHz processorVINRVout VIN
C
L03 - CMOS Technology   15  6.004  Spring 2009 2/10/09Due to unavoidable delays  
Propagation delay (tPD):
An UPPER BOUND on the delay from valid inputs 
to valid outputs.
GOAL:
minimize
  propagation 
  delay! 
ISSUE:
keep  
  Capacitances   low and 
  transistors   fastVOUT &lt; tPD &lt; tPDVIN
VOLVOHVILVIH
time constant 
/.notdef.g0005/.notdef.g0005 = RPDCLtime constant/.notdef.g0001 /.notdef.g0001
/.notdef.g0005/.notdef.g0005 = RPUCL
L03 - CMOS Technology   16  6.004  Spring 2009 2/10/09Contamination Delay  
an optional, additional timing spec  
INVALID inputs take time to propagate, too... 
CONTAMINATION DELAY , tCD
ALOWER BOUND on the delay from any invalid input to an invalid outputVOUT &gt; tCD&gt; tCDVIN
VOLVOHVILVIH
 Do we really need tCD?
Usually not itll be 
important when we 
design circuits with 
registers (coming soon!) 
If t
CD is not specied, 
safe to assume its 0.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Models of computation, programmable architectures</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec12/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>L12 - Models of Computation   9  6.004  Spring 2009 3/17/09A Turing machine Example  
Turing Machine Specication 
 Doubly-innite tape 
 Discrete symbol positions 
 Finite alphabet  say {0, 1} 
 Control FSM 
INPUTS:
       Current symbol 
OUTPUTS:
write 0/1 
move Left/Right 
 Initial Starting State {S0}  Halt State {Halt} A Turing machine, like an FSM, 
can be specied with a truth table.   The following Turing Machine 
implements a unary (base 1) 
incrementer. 
Current 
State InputWrite 
Tape Move 
Tape Next
State 
S0
S1S0
S11
0
1
01
1
1
0R
L
L
RS0
S1S1
HALT 
0000 11 01 1 0 1
OK, but how about real  computations... like fact(n)? 
L12 - Models of Computation   10  6.004  Spring 2009 3/17/09Turing Machine Tapes  
as Integers  
Canonical names for bounded tape congurations: 
Thats  just Turing Machine 347  
operating on tape 51  0001 11 10 0 0b0b1 b2 b4 b6 b8 b10 b3b5b7 ... ...
FSM347
Encoding: starting at current position, build a binary 
integer taking successively higher-order bits from 
right and left sides.  If nonzero region is bounded, 
eventually all 1s will be incorporated into the 
resulting integer representation. 
L12 - Models of Computation   11  6.004  Spring 2009 3/17/09TMs as Integer Functions  
Turing Machine Ti operating on Tape x, 
where x = b8b7b6b5b4b3b2b1b0
I wonder if a TM can compute 
EVERY  integer function... y = Ti[x]
x: input tape conguration 
y: output tape conguration 
Meanwhile,
Turings buddies 
Were busy too 
L12 - Models of Computation   12  6.004  Spring 2009 3/17/09Alternative models of computation  
Turing Machines [Turing] 
FSM i0110 0010 0
Turing 
Lambda calculus [Church, Curry, Rosser...] 
/.notdef.g0005x./.notdef.g0005y.xxy
(lambda(x)(lambda(y)(x (x y)))) 
Church Recursive Functions [Kleene] 
(define (fact n) 
  (... (fact (- n 1)) ...) 
Kleene 
Production Systems [P ost, Markov] 
/.notdef.g0002/.notdef.g0001/.notdef.g0003
IF pulse=0 THEN    patient=dead 
P ost</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>L12 - Models of Computation   25  6.004  Spring 2009 3/17/09Coded Algorithms: Key to CS  
data vs hardware  
Algorithms as data:  enables 
COMPILERS: analyze, optimize, transform behavior 
SOFTWARE ENGINEERING: 
Composition, iteration, 
abstraction of coded behavior 
F(x) = g(h(x), p((q(x))) TCOMPILER-X-to- Y [PX] = PY, such that 
TX[PX, z] = TY[PY, z] 
LANGUAGE DESIGN: Separate specication 
from implementation 
/.notdef.g0001C, Java, JSIM, Linux, ... all run on X86, 
PPC, Sun, ... 
/.notdef.g0001Parallel development paths: 
/.notdef.g0001Language/Software design 
/.notdef.g0001Interpreter/Hardware design 
L12 - Models of Computation   26  6.004  Spring 2009 3/17/09Summary  
Formal models (computability, Turing Machines, Universality) 
provide the basis for modern computer science: 
/.notdef.g0001Fundamental limits (what cant be done, even given plenty of memory 
and time) 
/.notdef.g0001Fundamental equivalence of computation models 
/.notdef.g0001Representation of algorithms as data, rather than machinery 
/.notdef.g0001Programs, Software, Interpreters, Compilers, ... 
They leave many practical dimensions to deal with: 
/.notdef.g0001Costs: Memory size, Time Performance 
/.notdef.g0001Programmability
Next step: Design of a practical  interpreter!</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L12 - Models of Computation   5  6.004  Spring 2009 3/17/09Some Perennial Favorites...  
FSM837 modulo 3 counter 
FSM1077 4-bit counter 
FSM1537 lock for 6.004 Lab 
FSM89143 Steves digital watch 
FSM22698469884 Intel Pentium CPU  rev 1 
FSM784362783 Intel Pentium CPU  rev 2 
FSM72698436563783 Intel Pentium II CPU 
Reality: The integer indexes of actual FSMs are much
bigger  than the examples above.  They must include 
enough information to constitute a complete 
description  of each devices unique structure. 
L12 - Models of Computation   6  6.004  Spring 2009 3/17/09Models of Computation  
The roots of computer science stem from the 
study of many alternative mathematical models 
of computation, and study of the classes of 
computations they could represent. 
An elusive goal was to nd an ultimate model, 
capable of representing all practical 
computations... 
Weve got FSMs ... 
what else do we need? /.notdef.g0001switches 
/.notdef.g0001gates 
/.notdef.g0001combinational logic 
/.notdef.g0001memories 
/.notdef.g0001FSMs
Are FSMs the 
ultimate digital 
computing device?  
L12 - Models of Computation   7  6.004  Spring 2009 3/17/09FSM Limitations  
Despite their usefulness and exibility, there exist common problems that 
cannot be computed by FSMs. For instance: 
Paren 
Checker (()()) OK
Paren 
Checker (())()) NixWell-formed Parentheses Checker: 
Given any string of coded left &amp; right 
parens, outputs 1 if it is balanced, else 0. 
Simple, easy to describe. 
Is this device equivalent to one of our 
enumerated FSMs??? 
PROBLEM: Requires ARBITRARILY many states, 
depending on input.   Must "COUNT" unmatched 
LEFT parens. An FSM can only keep track of a 
nite number of unmatched parens: for every FSM, we can nd a string it cant check. NO!
L12 - Models of Computation   8  6.004  Spring 2009 3/17/09Big Idea #2:  
Turing Machines  
Alan Turing was one of a group of 
researchers studying alternative 
models of computation. 
He proposed a conceptual model 
consisting of an FSM combined 
with an innite digital tape that could be read and written at each 
step.
Turings model (like others of the time) 
solves the "FINITE" problem of FSMs.S11110 0001 0000 0000
S20,(1,R) 
0,(1,L) 
1,Halt1,(1,L)</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L12 - Models of Computation   21  6.004  Spring 2009 3/17/09Doom.  MP3s. Windows. P ayroll 
accounting.  Blue screen crashes.  
6.004.  GP Computers 
Brief History  
of Mathematics  
(6.004 view)  yeah? then Im the P ope 
- Russell 
Math = Bunk??? 
This statement 
cant be proved 
- Godel { consistency, completeness } 
 take your pick OK, heres the program 
- Hilbert 
Search for 
perfect logic: 
consistent, complete Some things just 
dont compute 
- Turing computability {Its all { sets }} bliss
All you need, 
In theory 
- Turing universality Lets build 
this baby 
- von Neumann von Neumann 
architecture 
L12 - Models of Computation   22  6.004  Spring 2009 3/17/09meanwhile...  
Turing machines Galore!  
FSM0110 0010 0
Multiplication 
FSM0110 0010 0
Sorting FSM0110 0010 0
Factorization FSM0110 0010 0
Primality Test 
Is there an 
alternative to 
Innitely many, 
ad-hoc 
Turing Machines? special-purpose 
      Turing Machines.... 
L12 - Models of Computation   23  6.004  Spring 2009 3/17/09
The Universal Function  
OK, so there are uncomputable functions  innitely many of them, in fact. 
Heres an interesting candidate to explore: the Universal function, U, 
dened by 
SURPRISE!   U is computable by a Turing Machine: 
TUk
j Tk[j ]  
In fact, there are innitely many such machines.  Each is capable of 
performing any computation that can be performed by any TM!it sure would be neat  
to have a single, 
general-purpose 
machine...  U(k, j) = Tk[j ]  
Could this be computable??? 
L12 - Models of Computation   24  6.004  Spring 2009 3/17/09Big Idea #4:  
Universality  
TUk
j Tk[j ]  Whats going on here? 
k encodes a program  a description of 
some arbitrary machine. 
j encodes the input data to be used. 
TUinterprets  the program, emulating its 
processing of the data! 
Turing Universality:  The Universal Turing Machine  is the paradigm for modern 
general-purpose computers!  (cf: earlier special-purpose  computers) 
/.notdef.g0001Basic threshold test:  Is your machine Turing Universal ?  If so, it can emulate 
every other Turing machine! 
/.notdef.g0001Remarkably low threshold: UTMs with handfuls of states exist. 
/.notdef.g0001Every modern computer is a UTM (given enough memory) 
/.notdef.g0001To show your machine is Universal: demonstrate that it can emulate some 
known UTM. KEY IDEA: Interpretation .
Manipulate coded representations   of 
computing machines, rather than the 
machines themselves.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L12 - Models of Computation   1  6.004  Spring 2009 3/17/09Programmability  
from silicon to bits  0110100110
1110010010
0011100011
the Big Ideas 
of
Computer Science 
modied 3/16/09 16:15 L12 - Models of Computation   2  6.004  Spring 2009 3/17/096.004 Roadmap  
Sequential logic: 
FSMs&lt;PC&gt;+4+C*4
ASEL 0 1
Data Memory 
RDWD
AdrR/W
WDSEL01 2WA
Rc &lt;25:21&gt;01XPPCSEL
PCJT
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt; Ra &lt;20:16&gt;
RA2SELRc &lt;25:21&gt;
+
Register
FileRA1 RA2
RD1 RD2
BSEL 01C: &lt;15:0&gt;
C: &lt;15:0&gt;
sign-extendedZ
ALUABJTWAWD
WEC: &lt;15:0&gt; &lt;&lt; 2
sign-extended
ALUFNControl LogicZ
ASEL
BSELPCSEL
RA2SEL
WDSEL
ALUFN
Wr
&lt;PC&gt;+401
Wr0 1 2 3 4XAdrILL
OP
WASEL
WASELIRQWERF
WERF00
CPU Architecture:  
interpreter  for coded 
programs  
Programmability: Models 
/.notdef.g0001Interpretation; Programs; Languages; 
Translation 
/.notdef.g0001Beta implementation 
/.notdef.g0001Pipelined Beta 
/.notdef.g0001Software conventions 
/.notdef.g0001Memory architectures 
Fets &amp; voltages 
Logic gates Combinational 
logic circuits 
L12 - Models of Computation   3  6.004  Spring 2009 3/17/09FSMs as Programmable Machines  
ROM-based FSM sketch: 
Given i, s, and o, we need a ROM 
organized as: 
   2i+s words x (o+s) bits
i
s0...010...00 0...00 10110 011
o2i+ssN+1 o sN iinputs outputs
2(o+s)2i+s
(some may be 
equivalent) An FSMs behavior is completely 
determined by its ROM contents.  
So how many possible 
   i-input, 
   o-output, 
   FSMs with 
   s-state bits 
   exist? 
L12 - Models of Computation   4  6.004  Spring 2009 3/17/09Big Idea #1:  
FSM Enumeration  
GOAL: List all possible FSMs in some 
canonical order. 
 INFINITE list, but 
 Every FSM has an entry         
and an associated index. 
0...010...00 0...00 10110 011sN+1 o sN iinputs outputs28
FSMs
264
Every possible FSM can be  
associated with a number.  
We can discuss the ith FSM  What if  
s=2,
i=o=1??</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L12 - Models of Computation   13  6.004  Spring 2009 3/17/09The 1st Computer Industry Shakeout  
Heres a TM that 
computes SQUARE ROOT! 
0001 11 10 0 0
FSMhow am I going 
to beat that ?
L12 - Models of Computation   14  6.004  Spring 2009 3/17/09And the battles raged  
Heres a Lambda Expression 
that does the same thing... 
... and heres one that computes 
the nth root for ANY n!(/.notdef.g0005/.notdef.g0005(x) .....)
(/.notdef.g0005/.notdef.g0005(x n) .....)maybe if I gave 
away a 
microwave oven 
with every 
Turing Machine... 
RESULT:  an N-way TIE! CONTEST:  Which model computes more functions? 
L12 - Models of Computation   15  6.004  Spring 2009 3/17/09Big Idea #3:  
Computability  
FACT: Each model studied is capable of computing exactly  the same 
set of integer functions! 
Proof Technique: 
Constructions that translate between models 
BIG IDEA: 
Computability, independent of computation scheme chosen 
Church's Thesis:  
Every discrete function computable  
by ANY  realizable machine is  
computable by some Turing machine.  unproved, but 
universally 
accepted... 
L12 - Models of Computation   16  6.004  Spring 2009 3/17/09Computable Functions  
Representation Tricks: 
/.notdef.g0001Multi-argument functions?  to compute fk(x,y), use 
&lt;x,y&gt; = /.notdef.g0004nteger whose even   bits come from x, and whose odd bits come from y;   
whence
fK(x, y)  =  TK[&lt;x, y&gt;] 
/.notdef.g0001Data types: Can encode characters, strings, oats, ... 
as integers. 
/.notdef.g0001Alphabet size: use groups of N bits for 2N symbols 
f(x) computable  &lt;=&gt; for some k, all x: 
              f(x) = TK[x]      fK(x)
Equivalently: f(x) computable on Cray, P entium, in C, Scheme, Java, ...</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L12 - Models of Computation   17  6.004  Spring 2009 3/17/09Enumeration of Computable functions  
fm(n)37 23
42
831 033
111 12fi fi(0) fi(1) fi(n) fi(2) ... ...
f0
f1
f2
fm...
......
............... ... ... ..................
... ... ... ... ... ...Conceptual table of ALL Turing Machine behaviors...
VERTICAL AXIS: Enumeration of TMs (computable functions) 
HORIZONTAL AXIS: Enumeration of input tapes. 
ENTRY AT (n, m): Result of applying mth TM to argument n 
INTEGER k: TM halts, leaving k on tape. 
         : TM never halts. 
arent all well-dened 
integer functions 
computable?  
NO!  
there are simply 
too many integer 
functions to t in 
our enumeration!  
L12 - Models of Computation   18  6.004  Spring 2009 3/17/09
THEOREM: fH is dierent from every function in our 
enumeration of computable functions; hence it cannot be 
computed by any Turing Machine. Uncomputable Functions  
Unfortunately, not every well-dened integer function is computable.  The most famous 
such function is the so-called Halting function, fH(k, j), dened by: 
fH(k, j)  =  1  if Tk[ j] halts; 
               0   otherwise. 
fH(k, j) determines whether the kth TM halts when given a tape containing j. 
PROOF TECHNIQUE: Diagonalization (after Cantor, Gdel)
/.notdef.g0001If fH is computable, it is equivalent to some TM (say, TH).
/.notdef.g0001Using TH as a component, we can construct another TM whose behavior 
diers from every entry in our enumeration and hence must not be 
computable. 
/.notdef.g0001Hence fH cannot be computable. 
L12 - Models of Computation   19  6.004  Spring 2009 3/17/09Why fH is uncomputable  
If fH is computable, it is equivalent to some TM (say, TH):
THk
j1 i Tk[ j] halts, 
else 0 
Then TN (N for Nasty), which must be computable if TH is: 
TN
TH ?1
0LOOP 
HALT TN[x]: LOOPS if Tx[x] halts; 
HALTS if Tx[x] loops 
Finally, consider giving N as an argument to TN:
TN[N]: LOOPS if TN[N] halts; 
HALTS if TN[N] loops TN cant be 
computable, hence 
TH cant either!  x
L12 - Models of Computation   20  6.004  Spring 2009 3/17/09Footnote: Diagonalization  
(clever proof technique used by Cantor, Gdel, Turing)
fm(n)37 23
42
831 033
111 12fi fi(0) fi(1) fi(n) fi(2) ... ...
f0
f1
f2
fm...
......
............... ... ... ..................
... ... ... ... ... ...
If TH exists, we can use it to construct TN.  Hence TN is computable if TH is. 
(informally we argue by Churchs Thesis; but we can show the actual TN
construction, if pressed) 
Why TN cant be computable: 
TN diers from every 
computable function 
for at least one 
argument  along the 
diagonal of our table.
Hence TN cant be 
among the entries in 
our table! 
Hence no such TH can be constructed, even in theory. Computable Functions: 
A TINY SUBSET of all 
Integer functions!</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Pipeline issues: delay slots, annulment, exceptions</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec23/</lecture_pdf_url>
      <lectureno>23</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>L23  Pipeline  Issues   9  6.004  Spring 2009 5/5/09Stall Logic 
(1) Freeze IF , RF 
stages
(2) Introduce 
NOP into ALU 
stage
(3) Wait until 
operand is available 
(NB: SAME RF
   AS ABOVE!) +4
PCRF
PCMEMPCALURb: &lt;15:11&gt; Ra &lt;20:16&gt;
RA2SELRc &lt;25:21&gt;Instruction
MemoryA
D
IRRFInstruction
Fetch
+
C: &lt;15:0&gt; &lt;&lt; 2
sign-extended
Register
FileWAWD
WEWDSEL0    1    2IRMEMDMEMYMEMDALUB IRALUA0 1 BSELZ
ALUAB
Y
RDData MemoryWD Adr R/WRegister
File
ALU
Write
BackASEL 0 1
Rc &lt;25:21&gt;&lt;PC&gt;+CPCSELJT
0 1 2 3 4XAdrILL
OP
PCIF00
01XP
WASELWARegister
FileRA1 RA2
RD1 RD2
JT
C: &lt;15:0&gt;
sign-extended
ALUFN
WERFADD(r4, r1, r5) 
LD(r1, 0, r4) STALL LE
LE LE
0 1 AnnulRFNOP
LD(r1, 0, r4) NOP
L23  Pipeline  Issues   10  6.004  Spring 2009 5/5/09Memory Timing &amp; Pipelining 
But, but, what about FASTER processors? 
FACT: Processors have become very fast relative to memories! 
And this gap continues to grow 
Do we just increase the clock period to accommodate this bottleneck 
component? 
ALTERNATIVE: Longer pipelines. 
1. Add MEMORY WAIT stages between START of read operation &amp; 
return of data. 
2. Build pipelined memories, so that multiple (say, N) memory 
transactions can be in progress at once. 
These steps add load delay slots; hence 
3. Stall pipeline on unbypassable load delays. 
A 4-Stage pipeline requires READ access in less than one clock. 
A 5-Stage pipeline would allow nearly two clocks... 
L23  Pipeline  Issues   11  6.004  Spring 2009 5/5/095-stage
Pipeline+4
PCRF
PCWBPCMEMPCALURb: &lt;15:11&gt; Ra &lt;20:16&gt;
RA2SELRc &lt;25:21&gt;Instruction
MemoryA
D
IRRF Omits some detail
 NO bypass or interlock logic
Instruction
Fetch
+
C: &lt;15:0&gt; &lt;&lt; 2
sign-extended
Data Memory
RD
Register
FileWAWD
WEWDSEL0    1    2IRWBYWBIRMEMDMEMYMEMDALUB IRALUABSEL 0 1Z
ALUAB
Y
WD Adr R/WRegister
File
ALU
Write
BackMemoryASEL 0 1
Rc &lt;25:21&gt;&lt;PCRF&gt;+4+C*4PCSELJT
0 1 2 3 4XAdrILL
OP
PCIF00
01XP
WASELWARegister
FileRA1 RA2
RD1 RD2
JT
C: &lt;15:0&gt;
sign-extended
ALUFN
WERFAddress available right 
after instruction enters 
Memory pipe stage 
Data needed right before 
rising clock edge at end of  
Write Back pipe stage almost 2 clock cycles 
L23  Pipeline  Issues   12  6.004  Spring 2009 5/5/095-stage
pipeline+4
PCRF
PCWBPCMEMPCALURb: &lt;15:11&gt; Ra &lt;20:16&gt;
RA2SELRc &lt;25:21&gt;Instruction
MemoryA
D
IRRF Omits some detail
 NO bypass or interlock logic
Instruction
Fetch
+
C: &lt;15:0&gt; &lt;&lt; 2
sign-extended
Data Memory
RD
Register
FileWAWD
WEWDSEL0    1    2IRWBYWBIRMEMDMEMYMEMDALUB IRALUABSEL 0 1Z
ALUAB
Y
WD Adr R/WRegister
File
ALU
Write
BackMemoryASEL 0 1
Rc &lt;25:21&gt;&lt;PCRF&gt;+4+C*4PCSELJT
0 1 2 3 4XAdrILL
OP
PCIF00
01XP
WASELWARegister
FileRA1 RA2
RD1 RD2
JT
C: &lt;15:0&gt;
sign-extended
ALUFN
WERFWe wanted a simple, 
clean pipeline but 
 added IRIF mux to 
annul branch-slot instructions NOP
 added LE/muxes to freeze IF/RF stage so we can wait for LD to reach WB stage NOP
 added A/B bypass muxes to get data before its written to regle  /.notdef.g0001
/.notdef.g0001
/.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L23  Pipeline  Issues   13  6.004  Spring 2009 5/5/09RF-stage Bypass Details 
RD1  RD2  Register File 
A Bypass B Bypass 
ASEL0 1
ABSEL0 1
BPC+4+4*SXT(C) SXT(C)
To ALU To ALU D
To Mem JT
Zfrom ALU/MEM/WB from ALU/MEM/WB 
Note: can use 
distributed mux built from tristate 
drivers.  
Weve been a little
sloppy about this 
detail1, 2, 3, 4 Hum,  
it looks like we 
have a few extra 
inputs on that 
mux
L23  Pipeline  Issues   14  6.004  Spring 2009 5/5/09Bypass Implementation 
A B YALU YMEM
to alu from regs to regs Bypass 
From ALU Bypass 
From MEM Bypass 
From WB 
Select 0     
from mem 
alu
PCALU 
To reduce the amount of bypass logic, the WDSEL mux has been 
split: choice between ALU and PC+4 is made in ALU stage, choice between ALU/PC and MEMDATA is made is WB stage. P art 1 of the 
WDSEL mux P art 2 of the 
WDSEL mux 
L23  Pipeline  Issues   15  6.004  Spring 2009 5/5/09Bypass Logic 
Ra or Rb/Rc 
Rc (WB)* 
Rc (MEM)* 
Rc (ALU)* 
31 Select 0 ALU bypass MEM bypass WB bypass Regle (no bypass) 
Beta Bypass logic (need two copies for A/B data): 
5-bit
compare  
* If instruction is a ST (doesnt write into regle), set RC for ALU/MEM/WB to R31 
L23  Pipeline  Issues   16  6.004  Spring 2009 5/5/09Linkage Register Write Timing 
| The code: Assume Reg[LP] = 100... 
ADD(r31, r31, LP) 
BR(f, LP)        | Reg[LP] = .+4 
x: SUB(LP, 1, LP) 
...
f: XOR(LP, r31, r0) 
OR(r31, LP, r1) 
ADD(r31, LP, r2) 
IF
RF
ALU 
MEM
WBi i+1 i+2 i+3 i+4 i+5 i+6
BR Decision Time ADD BR SUB XOR OR ADD
ADD BR NOP XOR OR ADD
ADD BR NOP XOR OR
ADD BR NOP XOR
ADD BR
ADD writes BR writes 
Can we make 
 XORs regle 
access work 
by bypassing? 
NOP</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L23  Pipeline  Issues   5  6.004  Spring 2009 5/5/09Load Hazard (easy) 
(NB: SAME RF
   AS ABOVE!) +4
PCRF
PCMEMPCALURb: &lt;15:11&gt; Ra &lt;20:16&gt;
RA2SELRc &lt;25:21&gt;Instruction
MemoryA
D
IRRFInstruction
Fetch
+
C: &lt;15:0&gt; &lt;&lt; 2
sign-extended
Register
FileWAWD
WEWDSEL0    1    2IRMEMDMEMYMEMDALUB IRALUA0 1 BSELZ
ALUAB
Y
RDData MemoryWD Adr R/WRegister
File
ALU
Write
BackASEL 0 1
Rc &lt;25:21&gt;&lt;PC&gt;+CPCSELJT
0 1 2 3 4XAdrILL
OP
PCIF00
01XP
WASELWARegister
FileRA1 RA2
RD1 RD2
JT
C: &lt;15:0&gt;
sign-extended
ALUFN
WERFXOR(r3, r4, r6) 
LD(r1, 0, r4) The XOR operand r4 
can simply be 
bypassed from the 
output of the 
memory in the WB 
stage to the RF stage by our 
normal bypass path. 
L23  Pipeline  Issues   6  6.004  Spring 2009 5/5/09Structural Data Hazard 
The XOR hazard is pretty easy, but 
LD ADD XOR
LD ADD XOR
LD ADD XOR
LD ADD XORLD(r1, 0, r4) 
ADD(r1, r4, r5) 
XOR(r3, r4, r6) 
???How do 
we x 
this
one? 
In a 4-stage pipeline, for a LD instruction fetched during clock i, the 
data from memory isnt returned from memory until late into cycle i+3. 
Bypassing can x the XOR but not ADD! 
L23  Pipeline  Issues   7  6.004  Spring 2009 5/5/09Load Hazard (hard) 
(NB: SAME RF
   AS ABOVE!) +4
PCRF
PCMEMPCALURb: &lt;15:11&gt; Ra &lt;20:16&gt;
RA2SELRc &lt;25:21&gt;Instruction
MemoryA
D
IRRFInstruction
Fetch
+
C: &lt;15:0&gt; &lt;&lt; 2
sign-extended
Register
FileWAWD
WEWDSEL0    1    2IRMEMDMEMYMEMDALUB IRALUA0 1 BSELZ
ALUAB
Y
RDData MemoryWD Adr R/WRegister
File
ALU
Write
BackASEL 0 1
Rc &lt;25:21&gt;&lt;PC&gt;+CPCSELJT
0 1 2 3 4XAdrILL
OP
PCIF00
01XP
WASELWARegister
FileRA1 RA2
RD1 RD2
JT
C: &lt;15:0&gt;
sign-extended
ALUFN
WERFADD(r4, r1, r5) 
LD(r1, 0, r4) The r4 operand to 
the ADD instruction 
hasnt yet been 
fetched from 
memory. 
It exists NOWHERE 
on our data paths  
we cant solve this problem by 
bypassing!  
L23  Pipeline  Issues   8  6.004  Spring 2009 5/5/09Load Delay 
Bypassing cant x the problem 
with ADD since the data simply 
isnt available!  We have to add 
some pipeline interlock hardware  to 
stall  ADDs execution.  
LD ADD XOR
LD ADD XOR
LD ADD XOR
LD ADD XORLD(r1, 0, r4) ADD(r1, r4, r5) 
XOR(r3, r4, r6) 
XOR
ADD
NOP
NOP
If  the compiler knows about a machines load delay, it can often 
rearrange code sequences to eliminate such hazards.  Many compilers provide machine-specic instruction scheduling .</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L23  Pipeline  Issues   1  6.004  Spring 2009 5/5/09Pipeline Issues 
This pipeline stu makes 
my head hurt! Maybe its that 
dumb hat 
Home Stretch: 
  Lab #8 due Thursday 5/7 ;
  Quiz 5 FRIDAY 5/8 !
modied 5/4/09 10:06 L23  Pipeline  Issues   2  6.004  Spring 2009 5/5/09Recalling Data Hazards 
IF
RF
ALU
WBi i+1 i+2 i+3 i+4 i+5 i+6
ADD CMP MUL SUB
ADD CMP MUL SUB
ADD CMP MUL SUB
ADD CMP MUL SUBADD(r1, r2, r3) 
CMPLEC(r3, 100, r0)  
MULC(r3, 100, r4) 
SUB(r0, r4, r5) PROBLEM: Subsequent instructions 
can reference the contents of a 
register well before the pipeline stage 
where the register is written.
SOLUTION #2: Add special hardware to maintain the sequential 
execution semantics of the ISA. SOLUTION #1: Deal with it in SOFTWARE; expose the pipeline for 
all to see.  
L23  Pipeline  Issues   3  6.004  Spring 2009 5/5/09Bypass Paths 
Register
FileWA WD
WEALUAB
Y
IRWBIRALURegister
FileRA1 RA2
RD1 RD2IRRF
YWBB ABypass 
 muxes 
MULC(r3,100,r4) SUB(r0,r4,r5) 
CMPLEC(r3,100,r0) Add special data paths, called 
BYPASSES, that route the 
results of the ALU and WB stages to the RF stage, thus substituting the registers old contents with a value that will be written to that register at some point in the future. 
Detection of these cases has to 
be incorporated into the decoding logic of the RF stage, which basically looks at the instructions in the ALU and WB stage to see if their destination  register matches a source register reference. IF
RF
ALU 
WB
But there are some problems that BYPASSING CANT FIX! 
L23  Pipeline  Issues   4  6.004  Spring 2009 5/5/09Load Hazards 
Consider LOADS: 
Can we x all these problems 
using bypass paths? 
LD ADD XOR
LD ADD XOR
LD ADD XOR
LD ADD XORLD(r1, 0, r4) 
ADD(r4, r1, r5) 
XOR(r3, r4, r6) 
The hazard between the XOR and the LD can be addressed by 
our established bypass paths</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L23  Pipeline  Issues   21  6.004  Spring 2009 5/5/09Annulment Logic 
+4Instruction
MemoryA
DPCSELJT XAdrILL
OP
Rb:&lt;15:11&gt; Ra:&lt;20:16&gt; Rc:&lt;25:21&gt;Instruction 
Fetch
Register 
FileWAW D
W EYMEMALUA BRegister 
File
ALU
Write 
BackMemory
Rc:&lt;25:21&gt;Register 
FileRA1 RA2
RD1 RD2
PCRF+4+4*SXT(C)
Data 
Memory
RDYPCSEL00
RA2SELIRRF
+
WDSEL0    1    20 1 BSEL
A, B BYPASSZJT
ALUFN
WERF01 AnnulIFNOP
BNE(R31,0,XP)0 1 2 3 4
W D Adr R /WDALU B IRALU A01
DMEMIRMEMPCRF
PCALU
PCMEM
YWBA, B BYPASS
A, B BYPASSIRWB PCWBBYPASSES BYPASSES
SXT(C)
0 1 ASEL 0 1 AnnulRFNOPPCRF+4+4*SXT(C)STALL STALLSTALL
2
A, B BYPASS
A, B BYPASSBNE(R31,0,XP)
0 1 AnnulALUNOP
2
BNE(R31,0,XP)
0 1 AnnulMEMNOP
2Fault in ??? stage: 
 PC /.notdef.g0001 address of fault 
handler  Force BNE(R31,0,XP) 
in ??? stage 
/.notdef.g0002 will save 
PC+4 in XP when it reaches WB stage 
 Annul all following
instructions (those earlier in the pipeline): called ushing the pipe MEM
FAULT
L23  Pipeline  Issues   22  6.004  Spring 2009 5/5/09Asynchronous I/O Interrupts 
This should be easy. 
Take, for example, 
| The interrupted code: 
...
ADD(...)
SUB(...)
MUL(...)
XOR(...)
...
| The interrupt handler: xh: OR(...)
...
JMP(xp)Interrupt 
Taken 
HERESuppose key struck, interrupt 
requested (via IRQ) during the 
fetch of ADD.  Then lets 
 Select XAdr (handler) as next 
PC
 Leave ADD in pipeline; NO 
annulment! 
 Code handler to return to SUB 
instruction. 
Can this work??? 
Lets nd out 
L23  Pipeline  Issues   23  6.004  Spring 2009 5/5/09Asynchronous Interrupt Timing 
...
ADD(...)SUB(...)
MUL(...)
XOR(...)...
xh: OR(...)   | interrupt handler 
...
JMP(xp)Interrupt 
Taken 
HERE
IF
RF
ALU 
MEM
WBi i+1 i+2 i+3 i+4 i+5 i+6
... ADD ... OR
ADD ... OR
ADD ... OR
ADD ... OR
ADD ... ORPROBLEM: When 
does old PC+4 
get written to 
XP??? Interrupt 
Occurs PC = Xadr?? 
L23  Pipeline  Issues   24  6.004  Spring 2009 5/5/09Making Interrupts Work 
Alternative: When taking interrupt, 
 ANNUL instruction in IF stage... BUT 
instead of changing it to a NOP , change it to BNE(r31,0,XP) 
This will cause PC+4 of annulled instruction to be written to XP! 
 CODE HANDLER to return to Reg[XP]-4 (since the annulled 
instruction is never executed) 
IF
RF
ALU 
MEM
WBi i+1 i+2 i+3 i+4 i+5 i+6
ADD
BNE
BNE
BNE
BNE... ... OR
... OR
... OR
... OR
OR
Interrupt taken</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L23  Pipeline  Issues   17  6.004  Spring 2009 5/5/09BR/JMP
PC bypass 
BR(,r28)+4Instruction
MemoryA
DPCSELJT XAdrILL
OP
Rb:&lt;15:11&gt; Ra:&lt;20:16&gt; Rc:&lt;25:21&gt;Instruction 
Fetch
Register 
FileWAW D
W EYMEMALUA BRegister File
ALU
Write 
BackMemory
Rc:&lt;25:21&gt;Register 
FileRA1 RA2
RD1 RD2
PCRF+4+4*SXT(C)
Data 
Memory
RDYPCSEL00
RA2SELIRRF
+
WDSEL0    1    20 1 BSEL
A, B BYPASSZJT
ALUFN
WERF01 AnnulIFNOP0 1 2 3 4
W D Adr R /WDALU B IRALU A01
A,B Bypass 
A,B Bypass NOPXOR(r28)
DMEMIRMEMPCRF
PCALU
PCMEM
YWBA, B BYPASS
A, B BYPASSIRWB PCWBBYPASSES BYPASSES
SXT(C)
0 1 ASELFor BR/JMP , Rc value 
is taken from PC, not ALU. 
So we have to add 
bypass paths for PC
ALU and PCMEM .
PCWB is already taken 
care of if we bypass 
WB stage from 
output of WDSEL 
mux.0 1 AnnulRFNOPPCRF+4+4*SXT(C)STALL STALLSTALL
L23  Pipeline  Issues   18  6.004  Spring 2009 5/5/09Unused Opcode Traps 
IDEA: TRAP illegal instructions to a 
special routine in the Operating 
System, which can 
 Interpret them in software; or 
 Print humane error report. | User program: 
...
BAD(...) | Illegal instr. 
r: ...
| Operating System: UUO Handler 
IllOp: ST(r0,...) | Save a reg, 
LD(xp,-4,r0) | Fetch bad instr 
...
LD(...,r0) | Restore regs, 
JMP(xp) | Return to pgm. IMPLEMENTATION: On Bad Opcode 
  (discovered in RF Stage): 
 Select IllOp adr as next PC 
 Annul instruction in IF stage  Substitute BNE(r31,0,XP) for 
bad instruction - will (eventually) 
store PC+4 into XP  ... need 
bypass paths to make XP usable 
immediately by code at IllOp! 
L23  Pipeline  Issues   19  6.004  Spring 2009 5/5/09Illegal Opcode Traps 
+4Instruction
MemoryA
DPCSELJT XAdrILL
OP
Rb:&lt;15:11&gt; Ra:&lt;20:16&gt; Rc:&lt;25:21&gt;Instruction 
Fetch
Register 
FileWAW D
W EYMEMALUA BRegister File
ALU
Write 
BackMemory
Rc:&lt;25:21&gt;Register 
FileRA1 RA2
RD1 RD2
PCRF+4+4*SXT(C)
Data 
Memory
RDYPCSEL00
RA2SELIRRF
+
WDSEL0    1    20 1 BSEL
A, B BYPASSZJT
ALUFN
WERF01 AnnulIFNOP
BNE(R31,0,XP)0 1 2 3 4
W D Adr R /WDALU B IRALU A01
BAD/.notdef.g0002/.notdef.g0002
BNE(,XP)
DMEMIRMEMPCRF
PCALU
PCMEM
YWBA, B BYPASS
A, B BYPASSIRWBPCWBBYPASSES BYPASSES
SXT(C)
0 1 ASEL 0 1 AnnulRFNOPPCRF+4+4*SXT(C)STALL STALLSTALL
2
A, B BYPASS
A, B BYPASS???/.notdef.g0002/.notdef.g0002
NOP
Bad opcode decoded in 
RF stage: 
 PC /.notdef.g0001/.notdef.g0001 address of IllOp 
handler  Annul instruction in IF 
 Force BNE(R31,0,XP) 
in RF stage 
/.notdef.g0002/.notdef.g0002 will save 
PC+4 in XP when it 
reaches WB stage 
L23  Pipeline  Issues   20  6.004  Spring 2009 5/5/09Taking Exception 
In general, wed like to annul ALL instructions following one that causes a 
trap or fault: 
FREEZE state at time of exception, for inspection by handler code. 
ILLEGAL INSTRUCTIONS are recognizable in RF stage of pipe;  are ALL faults 
&amp; traps? 
CONSIDER: 
ARITHMETIC EXCEPTIONS: divide by zero, etc. 
 Caught by ALU subsystem, during processing of data in ALU 
stage
MEMORY FAULTS: Program reference to illegal memory location... 
 Caught by MEMORY subsystem, during processing of address 
input in MEM stage</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>L23  Pipeline  Issues   25  6.004  Spring 2009 5/5/09Smart Interrupt Handler 
| The interrupted code: 
...
ADD(...)
SUB(...)
MUL(...)XOR(...)...
| The interrupt handler: xh: OR(...)
...SUBC(xp,4,xp)  | Adjust XP so 
we
JMP(xp)   | return to annulled 
  | instruction (ADD) Interrupt taken HERE, 
ADD instruction annulled 
L23  Pipeline  Issues   26  6.004  Spring 2009 5/5/095-stage Pipeline: 
Final Version 
+4Instruction
MemoryA
DPCSELJT XAdrILL
OP
Rb:&lt;15:11&gt; Ra:&lt;20:16&gt; Rc:&lt;25:21&gt;Instruction 
Fetch
Register 
FileWAW D
W EYMEMALUA BRegister File
ALU
Write 
BackMemory
Rc:&lt;25:21&gt;Register 
FileRA1 RA2
RD1 RD2
PCRF+4+4*SXT(C)
Data 
Memory
RDYPCSEL00
RA2SELIRRF
+
WDSEL0    1    20 1 BSEL
A, B BYPASSZJT
ALUFN
WERF01 AnnulIFNOP
BNE(R31,0,XP)0 1 2 3 4
W D Adr R /WDALU B IRALU A01
DMEMIRMEMPCRF
PCALU
PCMEM
YWBA, B BYPASS
A, B BYPASSIRWB PCWBBYPASSES BYPASSES
SXT(C)
0 1 ASEL 0 1 AnnulRFNOPPCRF+4+4*SXT(C)STALL STALLSTALL
2
A, B BYPASS
A, B BYPASSBNE(R31,0,XP)
0 1 AnnulALUNOP
2
BNE(R31,0,XP)
0 1 AnnulMEMNOP
22BNE(R31,0,XP)
 Can annul instruction at 
each stage 
 Can force instruction to 
BNE(R31,0,XP) in each 
stage/.notdef.g0002/.notdef.g0002 will save PC+4 
in XP when it reaches WB 
stage
 Can stall IF and RF 
stages while waiting for 
LD result to reach WB 
 Can bypass results from 
ALU, MEM and WB back 
to RF 
L23  Pipeline  Issues   27  6.004  Spring 2009 5/5/09Pipeline Review 
Simple unpipelined Beta: 
/.notdef.g00011 cycle/instruction 
/.notdef.g0001long cycle time: mem+regs+alu
+mem
2-Stage pipeline: 
/.notdef.g0001 increased throughput (&lt;2x) 
/.notdef.g0001 introduced branch delay slots 
/.notdef.g0001/.notdef.g0001Choice of executing or 
annulling inst.  after branch 
5-stage pipeline: 
/.notdef.g0001 increased throughput (3x???) 
/.notdef.g0001branch delay slots 
/.notdef.g0001delayed register writeback 
   (3 cycles) 
/.notdef.g0001/.notdef.g0001Add bypass paths (10) to 
access correct value/.notdef.g0001memory data available only in WB stage 
/.notdef.g0001/.notdef.g0001Introduce NOPs at IRALU, stall IF 
and RF stages  until LD result ready 
/.notdef.g0001handle RF/ALU/MEM stage exceptions 
/.notdef.g0001/.notdef.g0001Save PC+4 in XP (fake a BR) 
/.notdef.g0001/.notdef.g0001annul following insts. (those earlier 
in pipeline) 
/.notdef.g0001implement interrupts 
/.notdef.g0001/.notdef.g0001Throw away IF inst., save PC+4 in 
XP, x return 
/.notdef.g0001extra HW due to pipelining 
/.notdef.g0001/.notdef.g0001Registers to hold values between 
stages
/.notdef.g0001/.notdef.g0001Data bypass muxes in RF stage 
/.notdef.g0001/.notdef.g0001Inst. muxes for rewriting code to annul or save PC
L23  Pipeline  Issues   28  6.004  Spring 2009 5/5/09RISC = Simplicity??? 
Generalization of 
registers and 
operand coding  
Complex instructions, 
addressing modes  
Addressing  
features, eg  
index registers  
RISCsPrimitive Machines:  
direct
implementations  
VLIWs,  
Super-Scalars  ?
Pipelines, Bypasses,  
Annulment, , ...  The P .T. Barnum Worlds Tallest Dwarf Competition 
Worlds Most Complex RISC?</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Non-pipelined Beta implementation</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec14/</lecture_pdf_url>
      <lectureno>14</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>L14  Building a Beta   9  6.004  Spring 2009 3/31/09Instruction Fetch/Decode 
INSTRUCTION 
WORD FIELDSPC
+4Instruction
MemoryA
D
Control Logic
CONTROL SIGNALS 00
OPCODE &lt;31:26&gt;/.notdef.g0001 use PC as memory address 
/.notdef.g0001 add 4 to PC, load new value at 
   end of cycle 
/.notdef.g0001 fetch instruction from memory 
       use some instruction elds 
        directly (register numbers,         16-bit constant)        use bits &lt;31:26&gt; to  
        generate controls 3232
32/.notdef.g0001 Use a counter to FETCH the next instruction: 
       PROGRAM COUNTER (PC) 
L14  Building a Beta   10  6.004  Spring 2009 3/31/09ALU Op Data Path 
Register
FileRA1 RA2
RD1 RD2WA WD
WERc: &lt;25:21&gt; PC
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt; Ra: &lt;20:16&gt;
ALUAB
ALUFNControl Logic
WERFALUFNWERF00
32 32
32 WERF!Operate class: Reg[Rc] /.notdef.g0002 Reg[Ra] op Reg[Rb] Ra Rc Rb (UNUSED)01X XX X
L14  Building a Beta   11  6.004  Spring 2009 3/31/09ALU Operations (w/constant) 
WARc:  &lt;25:21&gt; PC
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt; Ra: &lt;20:16&gt;
Register
FileRA1 RA2
RD1 RD2
ALUABWA WD
WE
ALUFNControl Logic
ALUFNBSEL 0 1C: SXT(&lt;15:0&gt;)
BSELWERF
WERF00
32Operate class: Reg[Rc] /.notdef.g0002 Reg[Ra] op SXT(C) Ra Rc Literal C (signed) 11X XX X
L14  Building a Beta   12  6.004  Spring 2009 3/31/09Load Instruction 
WARc: &lt;25:21&gt; PC
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt; Ra: &lt;20:16&gt;
Register
FileRA1 RA2
RD1 RD2
ALUABWA WD
WE
ALUFNControl LogicBSEL 0 1C: SXT(&lt;15:0&gt;)
Data Memory
RDWD R/W
AdrWr
WDSEL0    1    2BSEL
WDSEL
ALUFN
WrWERF
WERF00
32
32LD:  Reg[Rc] /.notdef.g0002 Mem[Reg[Ra]+SXT(C)] Ra Rc Literal C (signed) 100 10 0</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L14  Building a Beta   1  6.004  Spring 2009 3/31/09Building the Beta 
Lab #5 due Thursday 
L14  Building a Beta   2  6.004  Spring 2009 3/31/09CPU Design Tradeos
Minimum Cost  : measured by the size 
of the circuit. 
Best P erformance/Price: measured by the 
ratio of MIPS to size.  In power-sensitive 
applications MIPS/Watt is important too.  Maximum P erformance: measured by the 
numbers of instructions executed per second 
L14  Building a Beta   3  6.004  Spring 2009 3/31/09Performance Measure 
MIPS  =Clock Frequency (MHz) 
C.P .I. Millions of Instructions per Second 
Clocks per instruction 
PUSHING PERFORMANCE ... 
TODAY:  1 cycle/inst. 
LATER:  more MHz via pipelining 
L14  Building a Beta   4  6.004  Spring 2009 3/31/09The Beta ISA 
Instruction classes 
distinguished by 
OPCODE: 
   OP
   OPC
   MEM   Transfer of Control OpCode 6
Operate class: Reg[Rc] /.notdef.g0002 Reg[Ra] op Reg[Rb] 6 555 1 1
Ra Rc Rb (UNUSED)01X XX X
Operate class: Reg[Rc] /.notdef.g0002 Reg[Ra] op SXT(C) 16
Ra Rc Literal C (signed) 11X XX X
Opcodes, both formats: 
ADD SUB MUL* DIV* *optionalCMPEQ CMPLE CMPLT AND OR XORSHL SHR SRA
LD:  Reg[Rc] /.notdef.g0002 Mem[Reg[Ra]+SXT(C)] 
ST:  Mem[Reg[Ra]+SXT(C)] /.notdef.g0002 Reg[Rc] 
JMP:  Reg[Rc] /.notdef.g0002 PC+4;  PC /.notdef.g0002 Reg[Ra] 
BEQ:  
Reg[Rc] /.notdef.g0002 PC+4;  if Reg[Ra]=0  then  PC /.notdef.g0002 PC+4+4*SXT(C) 
BNE:  
LDR:  Reg[Rc] /.notdef.g0002 Mem[PC + 4 + 4*SXT(C)] Reg[Rc] /.notdef.g0002 PC+4;  if Reg[Ra]/.notdef.g00010  then  PC /.notdef.g0002 PC+4+4*SXT(C) Ra Rc Literal C (signed) 10X XX X
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L14  Building a Beta   13  6.004  Spring 2009 3/31/09Store Instruction 
WARc: &lt;25:21&gt; PC
+4Instruction
MemoryA
D
Ra: &lt;20:16&gt;
Register
FileRA1 RA2
RD1 RD2
ALUABWA WD
WE
ALUFNControl LogicBSEL 0 1C: SXT(&lt;15:0&gt;)
Data Memory
RDWD R/W
AdrWr
WDSEL0    1    2BSEL
WDSEL
ALUFN
WrRb: &lt;15:11&gt;
RA2SELRc: &lt;25:21&gt;
01
RA2SELWERF
WERF00
32No WERF! ST:  Mem[Reg[Ra]+SXT(C)] /.notdef.g0002 Reg[Rc] Ra Rc Literal C (signed) 100 11 0
L14  Building a Beta   14  6.004  Spring 2009 3/31/09JMP Instruction 
WARc: &lt;25:21&gt; PC
+4Instruction
MemoryA
D
Ra: &lt;20:16&gt;
Register
FileRA1 RA2
RD1 RD2
ALUABWA WD
WE
ALUFNControl LogicBSEL 0 1C: SXT(&lt;15:0&gt;)
Data Memory
RDWD R/W
AdrWr
WDSEL0    1    2BSEL
WDSEL
ALUFN
WrRb: &lt;15:11&gt;
RA2SELRc: &lt;25:21&gt;
01
RA2SELJTPCSEL0 1 2 3 4JT
PCSELWERF
WERF00
32PC+4JMP:  Reg[Rc] /.notdef.g0002 PC+4;  PC /.notdef.g0002 Reg[Ra] Ra Rc Literal C (signed) 100 11 1
L14  Building a Beta   15  6.004  Spring 2009 3/31/09BEQ/BNE Instructions 
Data Memory 
RDWD R/W
AdrWr
WDSEL0    1    2WAPCSEL 0 1 2 3 4JT
PC
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt;
RA2SELRc: &lt;25:21&gt;
01Ra: &lt;20:16&gt;
+
Register
FileRA1 RA2
RD1 RD2
BSEL0 1C: SXT(&lt;15:0&gt;)Z
ALUABPC+4+4*SXT(C)
WA WD
WE4*SXT(&lt;15:0&gt;)
ALUFNControl LogicZ
PCSEL
RA2SEL
BSEL
WDSEL
ALUFN
WrRc: &lt;25:21&gt;
JTWERF
WERF0032
PC+4BEQ:  Reg[Rc] /.notdef.g0002 PC+4;  if Reg[Ra]=0  then  PC /.notdef.g0002 PC+4+4*SXT(C) 
BNE:  Reg[Rc] /.notdef.g0002 PC+4;  if Reg[Ra]/.notdef.g00010  then  PC /.notdef.g0002 PC+4+4*SXT(C) Ra Rc Literal C (signed) 101 11 0
Ra Rc Literal C (signed) 101 10 1
L14  Building a Beta   16  6.004  Spring 2009 3/31/09Load Relative Instruction 
Hey, WAIT A MINUTE. Whats Load Relative good for anyway???  I 
thought 
 Code is PURE, i.e. READ-ONLY; and stored in a PROGRAM region of 
memory; 
 Data is READ-WRITE, and stored either 
 On the STACK (local); or 
 In some GLOBAL VARIABLE region; or 
 In a global storage HEAP . 
So why an instruction designed to load data 
thats near the instruction??? C:    X = X * 123456; 
BETA:
      LD(X, r0) 
      LDR(c1, r1) 
      MUL(r0, r1, r0) 
      ST(r0, X) 
      ... 
c1:   LONG(123456) Addresses &amp; other large constants LDR:  Reg[Rc] /.notdef.g0002 Mem[PC + 4 + 4*SXT(C)] Ra Rc Literal C (signed) 101 11 1</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L14  Building a Beta   21  6.004  Spring 2009 3/31/09Exceptions
PC+4+4*SXT(C)
ASEL 0 1
Data Memory 
RDWD
AdrR/W
WDSEL 012WA Rc: &lt;25:21&gt;01XPPCJT
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt; Ra: &lt;20:16&gt;
RA2SELRc: &lt;25:21&gt;
+
Register
FileRA1 RA2
RD1 RD2
BSEL 0 1C: SXT(&lt;15:0&gt;)Z
ALUABJTWAWD
WE
ALUFNControl LogicZ
ASEL
BSELPCSEL
RA2SEL
WDSEL
ALUFN
Wr
PC+401
Wr0 1 2 3 4XAdrILL
OP
WASEL
WASELIRQWERF
WERF00Other:              Reg[XP] /.notdef.g0002 PC+4;  PC /.notdef.g0002Xadr Bad Opcode:   Reg[XP] /.notdef.g0002 PC+4;  PC /.notdef.g0002 IllOp PCSEL
L14  Building a Beta   22  6.004  Spring 2009 3/31/09Control Logic 
Implementation choices: 
/.notdef.g0001 ROM indexed by opcode, external branch &amp; trap logic 
/.notdef.g0001 PLA 
/.notdef.g0001 random logic (eg, standard cell gates) OP
OPC
LD
ST
JMP
BEQ
BNE
LDR
Illop
IRQ
ALUFN F(op) F(op) "+" "+" -- -- -- "A" -- --
WERF 1 1 1 0 1 1 1 1 1 1
BSEL 0 1 1 1 -- -- -- -- -- --
WDSEL 1 1 2 -- 0 0 0 2 0 0
W R00 0 1 00 0 0 0 0
RA2SEL 0 -- -- 1 -- -- -- -- -- --
PCSEL 0 0 0 0 2 Z ? 1 : 0 Z ? 0 : 1 0 3 4
ASEL 0 0 0 0 -- -- -- 1 -- --
WASEL 0 0 0 -- 0 0 0 0 1 1
L14  Building a Beta   23  6.004  Spring 2009 3/31/09Beta: Our Final Answer 
PC+4+4*SXT(C)
ASEL 0 1
Data Memory 
RDWD
AdrR/W
WDSEL 012WA Rc: &lt;25:21&gt;01XPPCJT
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt; Ra: &lt;20:16&gt;
RA2SELRc: &lt;25:21&gt;
+
Register
FileRA1 RA2
RD1 RD2
BSEL 0 1C: SXT(&lt;15:0&gt;)Z
ALUABJTWAWD
WE
ALUFNControl LogicZ
ASEL
BSELPCSEL
RA2SEL
WDSEL
ALUFN
Wr
PC+401
Wr0 1 2 3 4XAdrILL
OP
WASEL
WASELIRQWERF
WERF00PCSEL
L14  Building a Beta   24  6.004  Spring 2009 3/31/09Next Time: Tackling the Memory Bottleneck
Isthat  all 
there is to 
building a 
processor???  No.  
Y ouve gotta print 
up all those little  
Beta Inside 
stickers.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L14  Building a Beta   5  6.004  Spring 2009 3/31/09Approach: Incremental Featurism 
Each instruction class can be implemented using a simple component 
repertoire.  Well try implementing data paths for each class individually, 
and merge them (using MUXes, etc). 
Steps: 
1. Operate instructions 
2. Load &amp; Store Instructions 
3. Jump &amp; Branch instructions 
4. Exceptions 
5. Merge data paths Our Bag of Components: 
Registers 
0 1 Muxes
ALUABBlack box ALU 
Data
MemoryWD
A
RDR/WRegister
File
(3-port)RA1 RA2
WA
WE
WD
RD1 RD2Instruction
MemoryA
D
Memories 
L14  Building a Beta   6  6.004  Spring 2009 3/31/09D
Q1  0 s
QD
EN
clkMulti-Port Register Files 
Register
File
(3-port)RA1 RA2
WA
WE
WD
RD1 RD25
32
CLKWrite EnableWrite Address
Write Data(independent Read addresses)
(Independent Read Data)32 32
2 combinational READ ports*, 
1 clocked WRITE port 
*internal logic ensures Reg[31] reads as 0 55
dest
asel bselEN EN EN EN
clk
Read 
P ort A Read 
P ort B Write 
Po r t  
L14  Building a Beta   7  6.004  Spring 2009 3/31/09Register File Timing 
CLK
WE
WA
WDRA
RDA
Reg[A]
A
new Reg[A]2 combinational READ ports, 1 clocked WRITE port 
What if (say) WA=RA1??? 
       RD1 reads old value of Reg[RA1] until next clock edge! new Reg[A]
tSthtPD tPD
L14  Building a Beta   8  6.004  Spring 2009 3/31/09Starting point: ALU Ops 
Means, to BETA,    Reg[R4] /.notdef.g0002 Reg[R2] + Reg[R3] OpCode Rb Ra 10
(unused)0000 100 00 1 00 0 01 000 1
Rc 000 000 000 0032-bit (4-byte) ADD instruction: 
First, well need hardware to:  
 Read next 32-bit instruction 
 DECODE instruction: ADD, SUB, XOR, etc  READ operands (Ra, Rb) from Register File;  PERFORM indicated operation;  WRITE result back into Register File (Rc).</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L14  Building a Beta   17  6.004  Spring 2009 3/31/09LDR Instruction 
Data Memory 
RDWD R/W
AdrWr
WDSEL0    1    2WAPCSEL 0 1 2 3 4JT
PCIF
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt;
RA2SELRc: &lt;25:21&gt;
01Ra: &lt;20:16&gt;
+
Register
FileRA1 RA2
RD1 RD2
BSEL 0 1C:SXT( &lt;15:0&gt;)Z
ALUABWA WD
WE
ALUFNControl LogicZ
PCSEL
RA2SEL
BSEL
WDSEL
ALUFN
Wr
PC+4Rc: &lt;25:21&gt;
PC+4+4*SXT(C)
ASEL 0 1JT
ASELWERF
WERF00 LDR:  Reg[Rc] /.notdef.g0002 Mem[PC + 4 + 4*SXT(C)] Ra Rc Literal C (signed) 101 11 1
L14  Building a Beta   18  6.004  Spring 2009 3/31/09Exceptions
What if something BAD happens? 
/.notdef.g0001Execution of an illegal op-code 
/.notdef.g0001Reference to non-existent memory 
/.notdef.g0001Divide by zero 
Or, maybe, just something unanticipated 
/.notdef.g0001User hits a key 
/.notdef.g0001A packet comes in via the network 
GOAL: handle all these cases (and more) in SOFTWARE:
/.notdef.g0001Treat each such case as an (implicit) procedure call 
/.notdef.g0001Procedure handles problem, returns to interrupted program. 
/.notdef.g0001TRANSPARENT  to interrupted program! 
/.notdef.g0001Important added capability: handlers for certain errors (illegal op-
codes) can extend instruction set using software (Lab 7!). 
L14  Building a Beta   19  6.004  Spring 2009 3/31/09Exception Processing 
Plan:  
/.notdef.g0001Interrupt running program 
/.notdef.g0001Invoke exception handler (like a procedure call) 
/.notdef.g0001Return to continue execution. 
Wed like RECOVERABLE INTERRUPTS  for 
 Synchronous events, generated by CPU or system 
FAULTS (eg, Illegal Instruction, divide-by-0, illegal mem address) 
TRAPS &amp; system calls (eg, read-a-character) 
 Asynchronous events, generated by I/O 
(eg, key struck, packet received, disk transfer complete) 
KEY: TRANSPARENCY to interrupted program. 
/.notdef.g0001Most dicult for asynchronous interrupts 
L14  Building a Beta   20  6.004  Spring 2009 3/31/09Implementation
How exceptions work: 
/.notdef.g0001Dont execute current instruction 
/.notdef.g0001Instead fake a forced procedure call 
/.notdef.g0001 save current PC (actually current PC + 4) 
/.notdef.g0001 load PC with exception vector 
/.notdef.g00010x4 for synch. exception, 0x8 for asynch. exceptions 
Question: where to save current PC + 4? 
/.notdef.g0001Our approach: reserve a register (R30, aka XP) 
/.notdef.g0001Prohibit user programs from using XP .  Why? 
LD(R31,A,R0)
LD(R31,B,R1)DIV(R0,R1,R2)
ST(R2,C,R31)IllOp:
   PUSH(XP) 
Fetch inst. at Mem[Reg[XP]4] 
       check for DIV opcode, get reg numbers        perform operation in SW, ll result reg
   POP(XP) 
   JMP(XP) Forced by 
hardware Example: DIV unimplemented</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Virtual memory: mapping, protection, contexts</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec17/</lecture_pdf_url>
      <lectureno>17</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>L17  Virtual Memory   5  6.004  Spring 2009 4/9/09Extending the Memory Hierarchy 
So, weve used SMALL fast memory + BIG slow memory to fake BIG FAST 
memory. 
Can we combine RAM and DISK to fake DISK size at RAM speeds? 
VIRTUAL MEMORY
 use of RAM as cache to much larger storage pool, on slower devices 
 TRANSPARENCY - VM locations "look" the same to program whether on 
DISK or in RAM. 
 ISOLATION of RAM size from software. CPUFAST 
STATIC
"CACHE"DYNAMIC
RAM
"MAIN
MEMORY"3x-20x
"Secondary
Storage"DISK104x-105x
L17  Virtual Memory   6  6.004  Spring 2009 4/9/09Virtual Memory 
ILLUSION: Huge memory 
 (232 bytes? 264bytes?) 
ACTIVE USAGE: small fraction 
(224 bytes?) 
HARDWARE: 
 230 (1 G) bytes of RAM 
 237 (128 G) bytes of DISK... 
  ... maybe more, maybe less! 
ELEMENTS OF DECEIT: 
 Partition memory into 
Pages (2K-4K-8K) 
 MAP a few to RAM, others to 
DISK
 Keep HOT pages in RAM. CPU RAMMMU VA PA Memory Management Unit 
L17  Virtual Memory   7  6.004  Spring 2009 4/9/09Demand Paging 
Basic idea: 
/.notdef.g0001Start with all of VM on DISK (swap 
area), MMU empty 
/.notdef.g0001Begin running program each VA 
mapped to a PA 
/.notdef.g0001/.notdef.g0001Reference to RAM-resident page: RAM 
accessed by hardware 
/.notdef.g0001/.notdef.g0001Reference to a non-resident page: traps to software handler, which 
/.notdef.g0003/.notdef.g0001Fetches missing page from DISK into 
RAM
/.notdef.g0003/.notdef.g0001Adjusts MMU to map newly-loaded 
virtual page directly in RAM 
/.notdef.g0003/.notdef.g0001If RAM is full, may have to replace (swap out) some little-used page to 
free up RAM for the new page. 
/.notdef.g0001Working set incrementally loaded, 
gradually evolves Bean  get in here 
immediately!  And 
bring a mop! 
L17  Virtual Memory   8  6.004  Spring 2009 4/9/09Simple Page Map Design 
FUNCTION: Given Virtual Address, 
 Map to PHYSICAL address 
OR
 Cause PAGE FAULT  allowing page 
replacement Virtual Page # 
Physical Page # 
Why  use  HIGH  address  bits  to  select page? 
... LOCALITY .  
Keeps  related  data  on  same  page. 
PAGEMAP X
X
XDRVirtual 
Memory Physical 
Memory PPNPage Index 
Page Map 
1
1
001
10</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L17  Virtual Memory   21  6.004  Spring 2009 4/9/09Using Caches with Virtual Memory 
CACHE MMU CPUDYNAMIC
RAM
DISKCACHE
MMUCPUDYNAMIC
RAM
DISKPhysical Cache  
Tags match physical addresses  
/.notdef.g0001 Avoids stale cache data after 
context switch 
/.notdef.g0001 SLOW: MMU time on HIT Virtual Cache  
Tags match virtual addresses  
/.notdef.g0001 Problem: cache invalid after 
context switch 
/.notdef.g0001 FAST: No MMU time on HIT 
L17  Virtual Memory   22  6.004  Spring 2009 4/9/09Best of both worlds  
OBSERVATION: If cache line selection is based on unmapped  page 
oset bits, RAM access in a physical cache can overlap   page map 
access.  Tag from cache is compared with physical page number 
from MMU. 
Want small cache index /.notdef.g0001 go with more associativity CACHECPUDYNAMIC
RAMMMUDISK
L17  Virtual Memory   23  6.004  Spring 2009 4/9/09Alternative memory structures? 
Maybe were hung up on the simple address space model.  Some 
alternatives:
/.notdef.g0001Segments: named contiguous regions (Multics, x86, ) 
/.notdef.g0001Objects: Cons cells, arrays,  (LISP machines, 432,   ) 
/.notdef.g0001URIs (web) 
/.notdef.g0001Triples/relations (LEAP, SAIL, RDF, ) 
/.notdef.g0001Associations
/.notdef.g0001Etc etc etc 
Take a familiar model (viz, RAM). 
Virtualize  it. All of these, and more, have been tried  with occasional success.  But for the 
most part, we gravitate to that most venerable of Computer Science traditions: 
L17  Virtual Memory   24  6.004  Spring 2009 4/9/09Summary
Exploiting locality on a large scale 
/.notdef.g0001Programmers want a large, at address space 
 but theyll use it sparsely, unpredictably! 
/.notdef.g0001Key: Demand Page sparse working set into RAM from DISK 
/.notdef.g0001IMPORTANT: Single-level pagemap, arithmetic, operation 
/.notdef.g0001/.notdef.g0001Access loaded pages via fast hardware path 
/.notdef.g0001/.notdef.g0001Load virtual memory (RAM) on demand: page faults 
/.notdef.g0001Various optimizations 
/.notdef.g0001/.notdef.g0001Moving pagemap to RAM, for economy &amp; size 
/.notdef.g0001/.notdef.g0001Translation Lookaside Buer (TLB), to regain performance 
/.notdef.g0001/.notdef.g0001Moving pagemap to DISK (or, equivalently, VM) for economy &amp; size 
/.notdef.g0001Cache/VM interactions: can cache physical or virtual locations 
Semantic consequence: 
/.notdef.g0001CONTEXT: a mapping between V and P addresses  well see again! 
Challenge: Alternative models 
/.notdef.g0001Will we just use bigger addresses when we outgrow our current ISAs?</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L17  Virtual Memory   17  6.004  Spring 2009 4/9/09Example: mapping VAs to PAs 
Suppose 
/.notdef.g0001 virtual memory of 232 bytes 
/.notdef.g0001 physical memory of 224 bytes 
/.notdef.g0001 page size is 210 (1 K) bytes 1. How many pages can be stored in 
physical memory at once? 
2. How many entries are there in the 
page table? 
3. How many bits are necessary per 
entry in the page table?  (Assume 
each entry has PPN, resident bit, dirty 
bit)
4. How many pages does the page table  
require?  
5. Whats the largest fraction of VM 
that might be resident? 
6. A portion of the page table is given 
to the left.  What is the physical 
address for virtual address 
0x1804?VPN | R D PPN 
----+--------
 0  | 0 0  7 
 1  | 1 1  9 
 2  | 1 0  0 
 3  | 0 0  5  4  | 1 0  5 
 5  | 0 0  3 
 6  | 1 1  2 
 7  | 1 0  4 
 8  | 1 0  1   224-10= 214
222
16
223 bytes = 213 pages 
1/28
VPN=6 /.notdef.g0001 PPN=2/.notdef.g0001 PA=0x804 
L17  Virtual Memory   18  6.004  Spring 2009 4/9/09Contexts
Acontext  is a mapping of VIRTUAL to PHYSICAL locations, as dictated by 
contents of the page map: 
PAGEMAPX
X
XDRVirtual Memory Physical Memory
Several programs may be simultaneously loaded into main memory, each in 
its separate context: 
Virtual 
Memory 1Virtual 
Memory 2Physical
Memory
Context switch:   reload the page map! 
map
1 map2
L17  Virtual Memory   19  6.004  Spring 2009 4/9/09Contexts: A Sneak Preview
Virtual 
Memory 1Virtual 
Memory 2Physical
Memory
1. TIMESHARING among several programs -- 
 Separate context for each program 
 OS loads appropriate context into pagemap when switching among pgms 
2. Separate context for OS Kernel (eg, interrupt handlers)... 
 Kernel vs User contexts 
 Switch to Kernel context on interrupt; 
 Switch back on interrupt return. 
HARDWARE SUPPORT: 2 HW pagemaps Every application can 
be written as if it has 
access to all of 
memory, without 
considering where 
other applications reside. 
First Glimpse of a 
   VIRTUAL MACHINE 
L17  Virtual Memory   20  6.004  Spring 2009 4/9/09Rapid Context Switching
physical 
page 
number Virtual Address Physical Memory 
Context &amp; Virtual page number 
physical 
page 
number 
+Pa g e  T b l  Pt r  TLB hit 
TLB miss Context # Add a register to hold index of current context. To switch 
contexts: update Context # and Page Tbl Ptr registers.  Dont have to ush TLB since each entrys tag includes context # in 
addition to virtual page number /.notdef.g0001
/.notdef.g0001
/.notdef.g0001
/.notdef.g0001
/.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L17  Virtual Memory   13  6.004  Spring 2009 4/9/09Page Map Arithmetic 
PAGEMAP PHYSICAL MEMORY D R PPN
VPageNo PO
1
1
101p
v
PPageNo POm
(v + p) bits in virtual address 
(m + p) bits in physical address 2
vnumber of VIRTUAL pages 
2mnumber of PHYSICAL pages 
2pbytes per physical page 
2v+pbytes in virtual memory 
2m+p bytes in physical memory 
(m+2)2vbits in the page mapTypical page size: 1K  8K bytes 
Typical (v+p): 32 (or more) bits 
Typical (m+p): 30  32 bits                         (1G  4G) Wait if  v equals m, 
why have a pagemap at all? 
L17  Virtual Memory   14  6.004  Spring 2009 4/9/09Example: Page Map Arithmetic 
Virtual Page # 
PhysPg # SUPPOSE...
32-bit Virtual address 
212 page size (4 KB) 
230 RAM max (1 GB) 
THEN:
# Physical Pages = ___________ 
# Virtual Pages = _____________ 
# Page Map Entries = _________ 
# Bits In pagemap = __________ 
Use SRAM for page map???  OUCH! 218= 256K 
220
220= 1M 
20*220/.notdef.g0002 20M 0 11 12 31
0 11 12 291220
18
L17  Virtual Memory   15  6.004  Spring 2009 4/9/09RAM-Resident Page Maps 
SMALL page maps can use dedicated RAM gets expensive for big ones! 
SOLUTION:  Move page map to MAIN MEMORY: 
Virtual Address Physical Memory 
virtual 
page 
number 
physical 
page 
number 
Physical memory 
pages that hold page 
map entries PROBLEM:
Each memory references now takes 2 accesses 
to physical memory! 
+P age Tbl Ptr 
L17  Virtual Memory   16  6.004  Spring 2009 4/9/09Translation Look-aside Buer (TLB)
PROBLEM: 2x performance hit each memory reference now takes 2 accesses! 
SOLUTION:  CACHE the page map entries 
physical 
page 
number IDEA:
LOCALITY in memory 
    reference patterns /.notdef.g0001
SUPER locality in  
     reference to page map 
VARIATIONS: 
/.notdef.g0001 sparse page map storage 
/.notdef.g0001 paging the page map! 
TLB: small, usually fully-associative 
cache for mapping VPN /.notdef.g0001PPNVirtual Address Physical Memory 
virtual 
page 
number 
physical 
page 
number 
+P age Tbl Ptr TLB hit 
TLB miss</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L17  Virtual Memory   1  6.004  Spring 2009 4/9/09Virtual Memory 
Y ou heard me right, kid. 
TERABYTES  of main 
memory! 
modied 4/23/09 10:54 Quiz #3 Tomorrow! 
L17  Virtual Memory   2  6.004  Spring 2009 4/9/09Lessons from History 
There is only one mistake that can be made in computer design that is dicult
to recover fromnot having enough address bits for memory addressing and memory management. 
Gordon Bell and Bill Strecker 
speaking about the PDP-11 in 1976 
A partial list of successful machines that eventually starved to death for 
lack of address bits includes the  PDP 8, PDP 10, PDP 11, Intel 8080, Intel 8086, Intel 80186, Intel 80286, Motorola 6800, AMI 6502, Zilog Z80, 
Cray-1, and Cray X-MP . 
Hennessy &amp; Patterson
Why? Address size determines minimum width of anything that can 
hold an address: PC, registers, memory words, HW for address arithmetic (BR/JMP , LD/ST).  When you run out of address space its 
time for a new ISA! 
L17  Virtual Memory   3  6.004  Spring 2009 4/9/09Top 10 Reasons for a
BIG Address Space 
10. Keeping Micron and Rambus in 
business.
9.  Unique addresses within every 
internet host. 
8. Generating good 6.004 quiz 
problems.
7.  Performing  32-bit ADD  via table 
lookup
6. Support for meaningless 
advertising hype 
5. Emulation of a Turing Machines 
tape.
4. Bragging rights at geek parties. 3. Isolating ISA from 
IMPLEMENTATION
/.notdef.g0001details of HW conguration 
shouldnt enter into SW design 
2. Usage UNCERTAINTY 
/.notdef.g0001provide for run-time expansion of 
stack and heap 
1. Programming CONVENIENCE 
/.notdef.g0001create regions of memory with 
dierent semantics: read-only, 
shared, etc. 
/.notdef.g0001avoid annoying bookkeeping 
L17  Virtual Memory   4  6.004  Spring 2009 4/9/09Squandering Address Space 
Address Space 
CODE, large monolithic programs (eg, Oce, Netscape).... 
 only small portions might be used 
 add-ins and plug-ins 
 shared libraries/DLLs 

STACK: How much to reserve?  (consider RECURSION!) 
HEAP: N  variable-size data records... 
   Bound N?  Bound Size? 
OBSERVATIONS: 
 Cant BOUND each usage... 
without compromising use. 
 Actual use is SPARSE 
 Working set even MORE sparse 
/.notdef.g0001/.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L17  Virtual Memory   9  6.004  Spring 2009 4/9/09Virtual Memory vs. Cache 
MAIN
MEMORY A Mem[A]
B Mem[B]TAG DATA 
=?
PAGEMAP PHYSICAL MEMORY VPAGE NO. OFFSCache: 
/.notdef.g0001 Relatively short blocks 
/.notdef.g0001 Few entries:  scarce resource 
/.notdef.g0001 miss time: 3x-20x hit times 
Virtual memory: 
/.notdef.g0001 disk: long latency, fast xfer 
/.notdef.g0001 miss time: ~105 x hit time 
/.notdef.g0001 write-back essential! 
/.notdef.g0001 large pages in RAM 
/.notdef.g0001 lots of entries:  one for each page 
/.notdef.g0001 tags in page map, data in 
   physical memory 
L17  Virtual Memory   10  6.004  Spring 2009 4/9/09Virtual Memory: the VI-1 view 
PAGEMAP X
X
XDRVirtual Memory Physical Memory 
Pagemap Characteristics: 
 One entry per virtual  page! 
 RESIDENT bit = 1 for pages stored in RAM, or 0 for non-resident 
(disk or unallocated).  Page fault when R = 0. 
 Contains PHYSICAL page number (PPN) of each resident page 
 DIRTY bit says weve changed this page since loading it from disk 
(and therefore need to write it to disk when its replaced) 1
1
1
10
0
0PPN
L17  Virtual Memory   11  6.004  Spring 2009 4/9/09Virtual Memory: the VI-3 view 
int VtoP(int VPageNo,int PO) { 
 if (R[VPageNo] == 0) 
    PageFault(VPageNo);  return (PPN[VPageNo] &lt;&lt; p) | PO; 
}
/* Handle a missing page... */ 
void PageFault(int VPageNo) { 
  int i; 
  i = SelectLRUPage(); 
  if (D[i] == 1) 
  WritePage(DiskAdr[i],PPN[i]); 
  R[i] = 0; 
PPN[VPageNo] = PPN[i]; 
ReadPage(DiskAdr[VPageNo],PPN[i]);
  R[VPageNo] = 1; 
  D[VPageNo] = 0; 
}Virtual Page # 
Physical Page # Problem: Translate 
  VIRTUAL ADDRESS 
  to PHYSICAL ADDRESS 
Multiply by 2P, the page size 
L17  Virtual Memory   12  6.004  Spring 2009 4/9/09The HW/SW Balance 
IDEA:
/.notdef.g0001 devote HARDWARE to high-trac, performance-critical path 
/.notdef.g0001 use (slow, cheap) SOFTWARE to handle exceptional cases 
HARDWARE performs address translation, detects page faults: 
/.notdef.g0001 running program interrupted (suspended); 
/.notdef.g0001 PageFault() is forced; 
/.notdef.g0001 On return from PageFault; running program continues int VtoP(int VPageNo,int PO) { 
 if (R[VPageNo] == 0)PageFault(VPageNo);  return (PPN[VPageNo] &lt;&lt; p) | PO; 
}
/* Handle a missing page... */ 
void PageFault(int VPageNo) { 
  int i = SelectLRUPage(); 
  if (D[i] == 1) WritePage(DiskAdr[i],PPN[i]); 
  R[i] = 0; 
  PA[VPageNo] = PPN[i]; 
  ReadPage(DiskAdr[VPageNo],PPN[i]);   R[VPageNo] = 1; 
  D[VPageNo] = 0; 
}hardware 
software</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Multilevel memories; locality, performance, caches</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec15/</lecture_pdf_url>
      <lectureno>15</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>L15  Memory Hierarchy   13  6.004  Spring 2009 4/2/09The Cache Idea: 
Program-Transparent Memory Hierarchy 
Cache contains TEMPORARY COPIES of selected 
main memory locations...  eg. Mem[100] =  37 
GOALS:
1) Improve the average access time 
2) Transparency (compatibility, programming ease) 1.0 (1.0-/.notdef.g0003)
CPU
"CACHE" DYNAMIC 
RAM
"MAIN
MEMORY" 100     37 
/.notdef.g0003/.notdef.g0001
(1-/.notdef.g0003)HIT RATIO :Fraction of refs found in CACHE. 
MISS RATIO: Remaining references .Challenge: 
make the 
 hit ratio as  high as 
 possible. 
m c m c c ave t ) ( t ) t t )( ( t t/.notdef.g0002 /.notdef.g0001+ = + /.notdef.g0002 /.notdef.g0001+/.notdef.g0002= 1 1
L15  Memory Hierarchy   14  6.004  Spring 2009 4/2/09How High of a Hit Ratio? 
Suppose we can easily build an on-chip static memory with 
a 4 nS access time, but the fastest dynamic memories that we can buy for main memory have an average access 
time of 40 nS. How high of a hit rate do we need to sustain 
an average access time of 5 nS? /.notdef.g0002=1/.notdef.g0001tave/.notdef.g0001tc
tm=1/.notdef.g00015/.notdef.g00014
40=97.5%
L15  Memory Hierarchy   15  6.004  Spring 2009 4/2/09The Cache Principle 
Find Bitdiddle, Ben 
5-Minute Access Time: 5-Second Access Time: 
ALGORITHM: Look nearby for the 
requested information rst, if its not there, check secondary storage 
L15  Memory Hierarchy   16  6.004  Spring 2009 4/2/09Basic Cache Algorithm 
ON REFERENCE TO Mem[X]: Look for X among cache tags... 
HIT: X = TAG(i) , for some cache line i 
/.notdef.g0001READ: return DATA(i) 
/.notdef.g0001WRITE: change DATA(i); Start Write to Mem(X) 
MISS: X not found in TAG of any cache line 
/.notdef.g0001REPLACEMENT SELECTION: 
/.notdef.g0001/.notdef.g0001Select some line k to hold Mem[X] (Allocation) 
/.notdef.g0001READ: Read Mem[X] 
Set TAG(k)=X, DATA(K)=Mem[X] 
/.notdef.g0001WRITE: Start Write to Mem(X) 
Set TAG(k)=X, DATA(K)= new Mem[X]MAIN
MEMORYCPU
(1!/.notdef.g0003)Tag Data 
A
BMem[A]
Mem[B]
QUESTION: How do we search the cache? /.notdef.g0001
/.notdef.g0001
Figure by MIT OpenCourseWare .</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L15  Memory Hierarchy   1  6.004  Spring 2009 4/2/09The Memory Hierarchy 
Lab #5 due tonight 
L15  Memory Hierarchy   2  6.004  Spring 2009 4/2/09What we want in a memory 
PC
INST
MADDR
MDATA BETA MEMORY 
Capacity Latency Cost 
Register 100s of bits 20 ps $$$$
SRAM 100s Kbytes 1 ns $$$
DRAM 100s Mbytes 40 ns $
Hard disk* 100s Gbytes 10 ms 
Want 1s Gbytes 1 ns cheap 
* non-volatile ADDR
DOUT
ADDR
DIN/DOUT
L15  Memory Hierarchy   3  6.004  Spring 2009 4/2/09SRAM Memory Cell 
6-T SRAM Cell 
word line N 
bit bitaccess FETs static
bistable
storage 
element 
word line N+1 There are two bit-lines per 
column: one supplies the bit, the other its complement. 
On a Read Cycle: 
    A single word line is activated (driven to 1), and the access transistors enable the selected 
cells, and their complements, onto the bit lines. 0               1 
1Good, but 
slow 0 Slow and 
almost 1 
Strong 
      1 Strong       0 Doesnt this 
violate our 
static
discipline? Writes are similar to reads, 
except the bit-lines are driven with the desired value of the cell.  
The writing has to overpower 
the original contents of the memory cell. 
L15  Memory Hierarchy   4  6.004  Spring 2009 4/2/09Multiport SRAMs 
(a.k.a. Register Files) 
One can increase the number of SRAM ports by adding access 
transistors.  By carefully sizing the inverter pair, so that one 
is strong and the other weak, we can assure that our WRITE 
bus will only ght with the weaker one, and the READs are 
driven by the stronger one - thus minimizing both access and 
write times. write 
read0 
read1 PU = 2 / 1 
PD = 4 / 1 
PU = 2 / 2 
PD = 2 / 3 4/1
5 / 1 2 / 1 2 / 1 wd rd1 rd0 
This transistor 
isolates the storage 
node so that it wont 
ip unintentionally.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L15  Memory Hierarchy   9  6.004  Spring 2009 4/2/09Best of Both Worlds 
What we WANT:  A BIG, FAST memory! 
Wed like to have a memory system that 
 PERFORMS like 1 GBytes of SRAM; but 
 COSTS like 1 GBytes of slow memory. 
SURPRISE: We can (nearly) get our wish! 
KEY: Use a hierarchy of memory technologies: 
CPUSRAMMAIN
MEM
L15  Memory Hierarchy   10  6.004  Spring 2009 4/2/09Key IDEA 
/.notdef.g0001 Keep the most often-used data in a small, fast 
SRAM (often local to CPU chip) 
/.notdef.g0001 Refer to Main Memory only rarely, for 
remaining data. 
/.notdef.g0001The reason this strategy works:  LOCALITY 
Locality of Reference: 
Reference to location X at time t implies 
that reference to location  X+ /.notdef.g0002/.notdef.g0002X  at time  
t+/.notdef.g0002/.notdef.g0002t becomes more probable as /.notdef.g0002/.notdef.g0002X and  
/.notdef.g0002/.notdef.g0002t approach zero. 
L15  Memory Hierarchy   11  6.004  Spring 2009 4/2/09/.notdef.g0002tMemory Reference Patterns
timeaddress
data
stack
program|S|
/.notdef.g0002tS is the set of locations 
accessed during  /.notdef.g0002/.notdef.g0002t.
Working set:  a set S which 
changes slowly wrt 
access time. 
  Working set size, |S| 
L15  Memory Hierarchy   12  6.004  Spring 2009 4/2/09Exploiting the Memory Hierarchy 
Approach 1 (Cray, others): Expose  Hierarchy 
Registers, Main Memory,
    Disk each available as 
    storage alternatives; 
 Tell programmers: Use them cleverly 
Approach 2: Hide  Hierarchy 
Programming model: SINGLE kind of memory, single address space. 
 Machine AUTOMATICALLY assigns locations to fast or slow 
memory, depending on usage patterns.CPUSRAMMAIN
MEM
CPUSmall 
StaticDynamic
RAMHARD
DISK
CACHE 
MAIN MEMORY 
SWAP SPACE X?</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L15  Memory Hierarchy   5  6.004  Spring 2009 4/2/091-T Dynamic Ram 
word 
line 
bitaccess FET 
C in storage capacitor determined by: 
C =/.notdef.g0004A
dmore area better dielectric 
thinner lm 1-T DRAM Cell 
VREFExplicit storage 
capacitor Six transistors/cell may not sound like much, but they can 
add up quickly. What is the fewest number of transistors that can be used to store a bit? 
TiN top electrode (VREF)
Ta2O5 dielectric 
W bottom
electrode 
poly word line access fet Cant we get 
rid of the 
explicit  cap? 
L15  Memory Hierarchy   6  6.004  Spring 2009 4/2/09Tricks for increasing throughput
Row Address Decoder Col. 
1Col. 
2Col. 
3Col. 
2M
Row 1 
Row 2 
Row 2N
Column Multiplexer/Shifter  MNMultiplexed Address 
(row rst, then column) bit lines word lines 
memory 
cell 
(one bit) 
Dt1 t2 t3t4The rst thing that should 
pop into you mind when asked to speed up 
throughput 
PIPELINING
Synchronous DRAM 
(SDRAM)
Clock 
Data 
outDouble-clocked 
Synchronous DRAM 
(DDRAM)but, alas, not latency 
L15  Memory Hierarchy   7  6.004  Spring 2009 4/2/09 Hard Disk Drives 
Typical high-end drive: 
/.notdef.g0001 Average latency = 4 ms 
/.notdef.g0001 Average seek time = 9 ms 
/.notdef.g0001 Transfer rate = 20M bytes/sec 
/.notdef.g0001 Capacity = 100-500G byte 
/.notdef.g0001 Cost = ~$1/Gbyte 
L15  Memory Hierarchy   8  6.004  Spring 2009 4/2/09Quantity vs Quality 
Y our memory system can be 
 BIG and SLOW... or 
 SMALL and FAST. 
10-810-3100  .01  1100  
10  
.1  
10-6TAPE DISKDRAMSRAM
Access 
Time .001  $/MBWeve explored a range of 
circuit-design trade-os.
Is there an 
ARCHITECTURAL solution to this DILEMMA? Track
Sector
Zoned-bit recordingSector
Shaft
TrackCylinder
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L15  Memory Hierarchy   17  6.004  Spring 2009 4/2/09Associativity:  Parallel Lookup 
Find Bitdiddle, Ben 
Nope, Smith  
Nope, Jones  
Nope, Bitwit  HERE IT IS! 
L15  Memory Hierarchy   18  6.004  Spring 2009 4/2/09Fully-Associative Cache 
TAG Data
= ? 
TAG Data
= ? 
TAG Data
= ? Incoming 
Address 
HIT
Data 
 Out The extreme in associativity: 
      All comparisons made in       parallel 
Any data item could be 
located in any cache location 
L15  Memory Hierarchy   19  6.004  Spring 2009 4/2/09Direct-Mapped Cache 
(non-associative)
Find Bitdiddle, Ben NO Parallelism: 
Look in JUST ONE place, 
determined by parameters of 
incoming request (address bits)  
... can use ordinary RAM as table 
YZ
ABNeed: Address Mapping Function! 
Maps incoming BIG address to 
small CACHE address tells us which single cache location 
to use 
Direct Mapped : just use a subset 
of incoming address bits! 
Collision when several addresses 
map to same cache line. 
L15  Memory Hierarchy   20  6.004  Spring 2009 4/2/09The Problem with Collisions 
Find Bitwit 
Find Bituminous 
Find Bitdiddle Nope, Ive got  
BITWIT  
under B  PROBLEM:
Contention among Bs.... each 
competes for same cache 
line! 
- CANT cache both  
 Bitdiddle &amp; Bitwit 
... Suppose Bs tend  
to come at once? 
YZ
ABBETTER IDEA:  
        File by LAST letter!Figure by MIT OpenCourseWare.
Figure by MIT OpenCourseWare.Figure by MIT OpenCourseWare .</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L15  Memory Hierarchy   21  6.004  Spring 2009 4/2/09Optimizing for Locality:
selecting on statistically independent bits 
AYZFind Bitdiddle Heres 
BITDIDDLE,
under E 
Find Bitwit 
L15  Memory Hierarchy   22  6.004  Spring 2009 4/2/09Direct Mapped Cache 
Low-cost extreme:
Single comparator 
Use ordinary (fast) static RAM for cache tags &amp; data: 
Incoming Address 
K T
=?
HIT Data Out DISADVANTAGE: 
COLLISIONS 
QUESTION :Why not use HIGH-order  
    bits as Cache Index? K-bit Cache Index 
D-bit data word  T Upper-address bits Tag Data K x (T + D)-bit static RAM 
L15  Memory Hierarchy   23  6.004  Spring 2009 4/2/09Contention, Death, and Taxes... 
AYZFind Bitdiddle 
Find BittwiddleNope, Ive got  
BITTWIDDLE  
under E; Ill 
replace it.  
Nope, Ive got  
BITDIDDLE  
under E; Ill 
replace it.  LESSON: In a non-associative 
cache, SOME pairs of 
addresses must compete 
for cache lines... 
... if working set includes such 
pairs, we get THRASHING 
and poor performance. 
L15  Memory Hierarchy   24  6.004  Spring 2009 4/2/09Loop B: 
   Pgm at 
1024,  
data
at2048:   but not here! Loop A: 
   Pgm at 
1024,  
data
at 37: Works 
GREAT 
here Direct-Mapped Cache Contention 
Assume 1024-line direct-
mapped cache, 1 word/line. 
Consider tight loop, at 
steady state: 
   (assume WORD, not BYTE, 
addressing) Memory  
Address  
1024  
37  
1025  
38  
1026  
39  
1024  
...  
1024  
2048  1025  
2049  
1026  2050  1024  
...  Cache  
Line
0
37  
1
38  
2
39  
0
0
011220Hit/  
Miss  
HIT  
HIT  HIT  HIT  HIT  
HIT  HIT  
MISS  MISS  MISS  MISS  MISS  MISS  MISS  
We need some  associativity, 
But not full associativity 
Next lecture! Figure by MIT OpenCourseWare. Heres 
BITWIT, 
under T LESSON: Choose CACHE 
LINE from independent
parts of request to 
MINIMIZE CONFLICT 
given locality patterns...
IN CACHE: Select line by 
LOW ORDER address 
bits!
Does this ELIMINATE 
contention? 
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Course overview and mechanics, basics of information</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec01/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>L01 - Basics of Information   17  6.004  Spring 2009 2/3/09Able was I ere I saw Elba.*1024  
Uncompressed: 27648 bytes Compressed: 138 bytes 
L01 - Basics of Information   18  6.004  Spring 2009 2/3/09Does recompression  work?  
If ZIP compression of a 40MB Bible yields a 4MB ZIP 
le, what happens if we compress that?
/.notdef.g0001Do we get a 400 KB le? 
/.notdef.g0001Can we compress that , to get a 
40K le?? 
/.notdef.g0001Can we compress the whole 
Bible down to a single bit??? 
/.notdef.g0001Is it a 0 or a 1???? 
HINT: if th e initial compression works 
the result has no
y! , 
cperfectly
redundan
L01 - B asics of Inf ormation   19  6.004  Spring 2009 2/3/09Is redundancy always  bad?  
Enc oding schemes that attempt t o mat ch the 
information c ont ent of a data str eam ar e minimizing 
redundancy . They ar e data c ompr ession  techniques. 
However, sometimes the go al of enc oding inf ormation is t o 
incr ease r edundancy , rather than r emo ve it. W hy? 
     Make the inf ormation easy t o manipulat e 
(xed-sized enc odings) 
     Make the data str eam r esilient t o noise 
(err or det ecting and c orrecting c odes) 
L01 - B asics of Inf ormation   20  6.004  Spring 2009 2/3/09
Error detection and correction  
Suppose w e want ed t o reliably tr ansmit the r esult of a single c oin ip: 
Further suppose that during tr ansmission a single-bit err or occurs, i.e., 
a single 0 is turned int o a 1 or a 1 is turned int o a 0. 
Heads: 0 Tails: 1 This is a pr ototype of the bit c oin f or 
the new inf ormation ec onomy .  Value = 
12.5
"?"
ZIP
ZIPZIPHINT: if th e initial c ompr ession w orks 
the r esult has no perfectly, 
redundanc y! /.notdef.g0001Do we get a 400 KB le? 
/.notdef.g0001Can w e compr ess that , to get a 
40K le?? 
/.notdef.g0001Can we compress the whole 
Bible down to a single bit??? 
/.notdef.g0001Is it a 0 or a 1???? 
Figure by MIT OpenCourseWare.
"Tails" "Heads"
0 1
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>L01 - Basics of Information   25  6.004  Spring 2009 2/3/09Summary  
/.notdef.g0001 Information resolves uncertainty 
/.notdef.g0001 Choices equally probable: 
/.notdef.g0001 N choices down to M /.notdef.g0002 log2(N/M) bits of information 
/.notdef.g0001 use xed-length encodings 
/.notdef.g0001 encoding numbers: 2s complement signed integers 
/.notdef.g0001 Choices not equally probable: 
/.notdef.g0001 choicei with probability pi/.notdef.g0002 log2(1/pi) bits of information 
/.notdef.g0001 average number of bits = /.notdef.g0003pilog2(1/pi)
/.notdef.g0001 use variable-length encodings 
/.notdef.g0001 To detect D-bit errors: Hamming distance &gt; D 
/.notdef.g0001 To correct D-bit errors: Hamming distance &gt; 2D 
Next time: 
/.notdef.g0001 encoding information electrically 
/.notdef.g0001 the digital abstraction 
/.notdef.g0001 combinational devices 
Hand in Information Sheets!</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms
. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L01 - Basics of Information   5  6.004  Spring 2009 2/3/09What do we see?  
/.notdef.g0001Structure
/.notdef.g0001hierarchical design:  
/.notdef.g0001limited complexity at each level 
/.notdef.g0001reusable building blocks 
/.notdef.g0001What makes a good system design?
/.notdef.g0001Bang for the buck: minimal mechanism, maximal function 
/.notdef.g0001reliable in a wide range of environments 
/.notdef.g0001accommodates future technical improvements /.notdef.g0001Interfaces 
/.notdef.g0001Key elements of system engineering; typically 
outlive the technologies they interface 
/.notdef.g0001Isolate technologies, allow evolution 
/.notdef.g0001Major abstraction mechanism
L01 - Basics of Information   6  6.004  Spring 2009 2/3/09Our plan of attack  
/.notdef.g0001/.notdef.g0001 Understand how things work, bo ttom-up 
/.notdef.g0001/.notdef.g0001
 Encapsulate our understanding 
    using appr opriat
e abstractions 
/.notdef.g0001/.notdef.g0001Study organizational principles: 
abstractions, interfaces, APIs. 
/.notdef.g0001/.notdef.g0001 Roll up our sleeves and design at 
     each level of hier
archy 
/.notdef.g0001/.notdef.g0001
 Learn engineering tricks 
- hist ory 
- syst
ematic approaches 
- algorithms 
- diagnose, x, and avoid bugs 
L01 - Basics of Information   7  6.004  Spring 2009 2/3/09First up: INFORMATION  
If we want to design devices to 
manipulate, communicate and store information then we need 
to quantify information so we 
can get a handle on the engineering issues.  Goal: 
good  implementations  
/.notdef.g0001Easy-to-use 
/.notdef.g0001Ecient
/.notdef.g0001Reliable 
/.notdef.g0001Secure 
/.notdef.g0001/.notdef.g0001Low-level physical 
representations 
/.notdef.g0001 High-level symbols and 
sequences of symbols Whirlwind, MIT Lincoln Labs 
http://www.chick.net/wizards/whirlwind.html 
L01 - Basics of Information   8  6.004  Spring 2009 2/3/09What is Information?  
Information resolves uncertainty.
Information is simply that which 
cannot be predicted. 
The less predictable a message is, the more 
information it conveys! information ,n.  Knowledge 
communicated or received 
concerning a particular fact or circumstance .
Tell me something new  Two photographs removed due to copyright restrictions.
Please see http://www.chick.net/wizards/images/whirlwind.jpg and
http://www.chick.net/wizards/images/wwtea.gif.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L01 - Basics of Information   9  6.004  Spring 2009 2/3/09Quantifying Information  
(Claude Shannon, 1948)  
Suppose youre faced with N equally probable choices, and I 
give you a fact that narrows it down to M choices. Then 
Ive given you 
log2(N/M) bits   of information 
Examples:
/.notdef.g0001 information in one coin ip: log2(2/1) = 1 bit 
/.notdef.g0001 roll of 2 dice: log2(36/1) = 5.2 bits 
/.notdef.g0001 outcome of a Red Sox game: 1 bit 
 (well, actually, are both outcomes equally probable?) Information is measured in bits 
(binary digits) = number of 0/1s 
required to encode choice(s)  
L01 - Basics of Information   10  6.004  Spring 2009 2/3/09Encoding  
/.notdef.g0001Encoding describes the process of 
assigning representations to information
/.notdef.g0001 Choosing an appropriate and ecient encoding is a 
real engineering challenge 
/.notdef.g0001 Impacts design at many levels 
- Mechanism (devices, # of components used) 
- Eciency (bits used) 
- Reliability (noise) 
- Security (encryption) 
Next lecture: encoding a bit.
What about longer messages? 
L01 - Basics of Information   11  6.004  Spring 2009 2/3/09Fixed-length encodings  7bits
6.426&lt; = (86)2logbits 4
322
3
10
2 &lt; = . ) ( logIf all choices are equally likely  (or we have no reason to expect 
otherwise), then a xed-length code is often used. Such a code will 
use at least enough bits to represent the information content.
ex. ~86 English characters =  
              {A-Z (26), a-z (26), 0-9 (10),  punctuation (11), math (9), nancial (4)}  
7-bit ASCII ( American Standard Code for Information Interchange )ex. Decimal digits 10 = {0,1,2,3,4,5,6,7,8,9}  
4-bit BCD (binary coded decimal)  
L01 - Basics of Information   12  6.004  Spring 2009Encoding numbers  
/.notdef.g0001/.notdef.g0002
==1 n 0 ii
ib 2 v21121029282726252423222120
011111010000
03720
Octal - base 8 
000 - 0 
001 - 1 
010 - 2 011 - 3 100 - 4 
101 - 5 
110 - 6 
111 - 7 0x7d0
Hexadecimal - base 16 
0000 - 0   1000 - 8 
0001 - 1     1001 - 9 
0010 - 2    1010 - a 
0011 - 3     1011 - b 
0100 - 4     1100 - c 
0101 - 5     1101 - d 
0110 - 6     1110 - e 
0111 - 7     1111 - f Oftentimes we will nd it  
convenient to cluster  
groups of bits together  
for a more compact  
notation. Two popular  
groupings are clusters of  
3 bits and 4 bits.  It is straightforward to encode positive integers as a sequence of bits. 
Each bit is assigned a weight. Ordered from right to left, these weights are  increasing powers of 2. The value of an n-bit number encoded in this fashion 
is given by the following formula: 
= 2000
10
0 2 7 3 0 d 7</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L01 - Basics of Information   13  6.004  Spring 2009 2/3/09Signed integers: 2s complement  
20 21 22 23 2N-2 -2N-1  N bits 
8-bit 2s complement example: 
11010110 = 27 + 26 + 24 + 22 + 21 =  128 + 64 + 16 + 4 + 2 =  42 
If we use a twos complement representation for signed integers, the same 
binary addition mod 2n procedure will work for adding positive and negative 
numbers (dont need separate subtraction rules).  The same procedure will also 
handle unsigned numbers! 
By moving the implicit location of decimal point, we can represent fractions 
too: 
1101.0110 = 23 + 22 + 20 + 2-2 + 2-3 =  8 + 4 + 1 + 0.25 + 0.125 =  2.625 sign bit decimal point Range:  2N-1  to  2N-1  1 
L01 - Basics of Information   14  6.004  Spring 2009 2/3/09When choices arent equally probable  
When the choices have dierent probabilities (pi), you get more 
information when learning of a unlikely choice than when learning 
of a likely choice
Information from choicei = log2(1/pi) bits 
Average information from a choice = /.notdef.g0003pilog2(1/pi)
Example
choicei pi
A  1/3  
B  1/2  
C  1/12  
D  1/12  Average information 
  = (.333)(1.58) + (.5)(1)  + (2)(.083)(3.58) 
  = 1.626 bits 
Can we nd an encoding where 
transmitting 1000 choices is close to 1626 bits on the 
average?  Using two bits for each choice = 2000 bits log2(1/pi)
1.58 bits  
1 bit  
3.58 bits  
3.58 bits  
L01 - Basics of Information   15  6.004  Spring 2009 2/3/09Variable-length encodings  
(David Human, MIT 1950)  
choicei pi encoding  
A  1/3  11  
B  1/2  0
C  1/12  100  
D  1/12  101  B
C DA1 0
1 0
1 0Use shorter bit sequences for high probability choices, 
longer sequences for less probable choices 
010011011101
Human Decoding TreeC B A A D
Average information 
  = (.333)(2)+(.5)(1)+(2)(.083)(3) 
  = 1.666 bits 
Transmitting 1000 choices 
takes an average of 1666 
bits better but not 
optimal
To get a more ecient encoding (closer to information content) we need to 
encode sequences of choices , not just each choice individually.  This is the 
approach taken by most le compression algorithms B
L01 - Basics of Information   16  6.004  Spring 2009 2/3/09Data Compression  
Key: re-encoding to remove 
redundant information: match 
data rate to actual information  
content. 
A84b!*m9@+M(pOutside of a dog, a book is 
mans best friend.  Inside of 
a dog, its too dark to 
read 
             -Groucho Marx Ideal: No redundant info  Only 
unpredictable bits transmitted.
Result appears random! 
LOSSLESS: can uncompress, get back 
original.
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L01 - Basics of Information   21  6.004  Spring 2009 2/3/09Hamming Distance  
(Richard Hamming, 1950)  
HAMMING DISTANCE:  The number of digit 
positions in which the corresponding digits of two encodings of the same length are dierent 
The Hamming distance between a valid binary code word and the same 
code word with single-bit error is 1. 
The problem with our simple encoding is that the two valid code words 
(0 and 1) also have a Hamming distance of 1.  So a single-bit error changes a valid code word into another valid code word 
1 0 heads tailssingle-bit error 
L01 - Basics of Information   22  6.004  Spring 2009 2/3/09Error Detection  
What we need is an encoding where a single-bit 
error doesnt produce another valid code word. 
11 00 heads tails01
10single-bit error 
We can add single-bit error detection to any length code word by adding a 
parity bit  chosen to guarantee the Hamming distance between any two 
valid code words is at least 2.  In the diagram above, were using even 
parity where the added bit is chosen to make the total number of 1s in 
the code word even. 
Can we correct detected errors?   Not yet 
If D is the minimum 
Hamming distance between code words, we 
can detect up to 
(D-1)-bit errors  
L01 - Basics of Information   23  6.004  Spring 2009 2/3/09Error Correction  
110
000 heads tails
100
010single-bit error 111
001101
011
By increasing the Hamming distance between valid code words to 3, we 
guarantee that the sets of words produced by single-bit errors dont overlap.  So if we detect an error, we can perform error correction  since we 
can tell what the valid code was before the error happened. 
 Can we safely detect double-bit errors while correcting 1-bit errors? 
 Do we always need to triple the number of  bits? 
If D is the minimum Hamming 
distance between code words, we can correct up to 
                     - bit errors  
/.notdef.g0005/.notdef.g0003/.notdef.g0005
/.notdef.g0004/.notdef.g0002/.notdef.g0004/.notdef.g0001
21D
L01 - Basics of Information   24  6.004  Spring 2009 2/3/09The right choice of codes can solve hard problems  
Reed-Solomon (1960) 
First construct a polynomial from 
the data symbols to be transmittedand then send an over-sampled plot 
of the polynomial instead of the 
original symbols themselves  spread the information out so it can be recovered from a subset of the transmitted symbols. 
Particularly good at correcting 
bursts of erasures (symbols known to be incorrect) 
Used by CD, DVD, DAT, satellite 
broadcasts, etc. Viterbi (1967) 
A dynamic programming algorithm 
for nding the most likely sequence of hidden states that result in a 
sequence of observed events, 
especially in the context of hidden Markov models. 
Good choice when soft-decision 
information is available from the demodulator.
Used by QAM modulation schemes 
(eg, CDMA, GSM, cable modems), disk drive electronics (PRML)</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L01 - Basics of Information   1  6.004  Spring 2009 2/3/09Welcome to 6.004!
 
Handouts: Lecture Slides, Calendar, Info sheet I thought this 
course was called Computation 
StructuresThe Way
Digital
Things
WorkThe Way
Digital
Things
Work
modified 1/30/09 11:37 6.004  Spring 2009 2/3/09Course Mechanics  
Unlike other big courses, youll have 
NO evening quizzes 
NO nal exam NO weekly graded problem sets 
Instead, youll face 
Repository of tutorial problems 
(with answers) 
FIVE quizzes, based on these problems 
(in Friday sections) 
EIGHT labs + on-line lab questions + Design Contest 
(all labs and olqs must be completed to pass!) 
ALGORITHMIC assignment of your grade! 
L01 - Basics of Information   4  6.004  Spring 2009 2/3/09How do you build systems with &gt;1G components?  
P ersonal Computer: 
Hardware &amp; Software 
Circuit Board: 
/.notdef.g00011-8 / system 
1-2G devices
Integrated Circuit: 
/.notdef.g00018-16 / PCB 
.25M-1G devices
Module: 
/.notdef.g00018-64 / IC 
.1M-1M devices
Cell: 
/.notdef.g00011K-10K / Module 
16-64 devices
 Gate: 
/.notdef.g00012-16 / Cell 
8 devicesScheme for  
representing 
 informationMOSFETFigure by MIT OpenCourseWare.
P+ P+P+
N+N+
N+
Figure by MIT OpenCourseWare.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Pipelined Beta implementation, bypassing</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec22/</lecture_pdf_url>
      <lectureno>22</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>L22  Pipelining the Beta   13  6.004  Spring 2009 4/30/09Branch Alternative 2b(i) 
Put USEFUL instructions  in  
the branch delay slots; remember they will be 
executed whether the 
branch is taken or not 
IF
EXEi i+1 i+2 i+3 i+4 i+5 i+6
CMP ADD ADD BT 
CMP ADD BT BT CMP ADD
BT CMP ADD
Branch taken 
Pros: only two extra instructions are executed (on last iteration) 
Cons:  nding useful instructions that are always executed  
           is dicult; clever rewrite may be required.   Program executes 
           dierently on nave unpipelined implementation. LOOP: ADD(r1,r3,r3)
LOOPx: CMPLEC(r3,100,r0) 
BT(r0,LOOPx)ADD(r1,r3,r3)
SUB(r3,r1,r3)
XOR(r3,-1,r3)
MUL(r1,r2,r2)
...We need to 
add this silly instruction 
to UNDO the 
eects of 
that last 
ADD
L22  Pipelining the Beta   14  6.004  Spring 2009 4/30/09Branch Alternative 2b(ii) 
Put USEFUL instructions  in  
the branch delay slots; annul them if branch doesnt 
behave as predicted 
IF
EXEi i+1 i+2 i+3 i+4 i+5 i+6
CMP ADD ADD BT 
CMP ADD BT BT CMP ADD
BT CMP ADD
Branch taken 
Pros: only one instruction is annulled (on last iteration); about 70% 
         of branch delay slots can be lled with useful instructions 
Cons:  Program executes dierently on nave  unpipelined implementation; 
           not really useful with more than one delay slot. LOOP: ADD(r1, r3, r3) 
LOOPx: CMPLEC(r3, 100, r0) 
BT.taken(r0, LOOPx)ADD(r1, r3, r3) 
XOR(r3, -1, r3) 
MUL(r1, r2, r2) 
...
L22  Pipelining the Beta   15  6.004  Spring 2009 4/30/09Architectural Issue: 
Branch Decision Timing 
BETA approach: 
 SIMPLE branch condition logic ... 
Test for Reg[Ra] = 0! 
 ADVANTAGE: early decision, 
   single delay slot 
ALTERNATIVES: 
 Compare-and-branch... 
   (eg, if Reg[Ra] &gt; Reg[Rb]) 
 MORE powerful, but 
 LATER decision (hence more      delay slots) IF
instruction Instruction 
Fetch 
ALU ALU CLA B instruction Register 
File CLRF  (read)  
instruction instruction YWrite 
Back 
CL
RF  (write)  instruction YMemory 
CL
Suppose decision were made in the ALU 
stage ...  then there would be 2 branch 
delay slots (and instructions to annul!) Wow! I guess those guys really 
were thinking when they made up all those instructions 
L22  Pipelining the Beta   16  6.004  Spring 2009 4/30/09(NB: SAME RF
   AS ABOVE!) +4
PCRF
PCMEMPCALURb: &lt;15:11&gt; Ra &lt;20:16&gt;
RA2SELRc &lt;25:21&gt;Instruction
MemoryA
D
IRRFInstruction
Fetch
+
C: &lt;15:0&gt; &lt;&lt; 2
sign-extended
RD
Register
FileWAWD
WEWDSEL0    1    2IRMEMDMEMYMEMDALUB IRALUA0 1 BSELZ
ALUAB
Y
Data MemoryWD Adr R/WRegister
File
ALU
Write
BackASEL 0 1
Rc &lt;25:21&gt;&lt;PC&gt;+CPCSELJT
0 1 2 3 4XAdrILL
OP
PCIF00
01XP
WASELWARegister
FileRA1 RA2
RD1 RD2
JT
C: &lt;15:0&gt;
sign-extended
ALUFN
WERF4-Stage
 Beta Pipeline 
Treat register le as two 
separate devices: combinational READ, 
clocked WRITE at end of 
pipe. 
What other information do 
we have to pass down pipeline?    PC 
   instruction elds 
What sort of improvement 
should expect in cycle time?  (return addresses) 
(decoding)</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L22  Pipelining the Beta   9  6.004  Spring 2009 4/30/09Branch Delay Slots 
PROBLEM: One (or more) following instructions have been pre-
fetched by the time a branch is taken. 
2. Program around it.  Either 
a) Follow each BR with a NOP instruction; or 
b) Make compiler clever enough to move USEFUL instructions 
into the branch delay slots 
i. Always execute instructions in delay slots 
ii. Conditionally execute instructions in delay slots NOP = no-operation, e.g. 
ADD(R31, R31, R31) POSSIBLE SOLUTIONS: 
1. Make hardware annul instructions following 
branches which are taken, e.g., by disabling WERF and 
WR.
L22  Pipelining the Beta   10  6.004  Spring 2009 4/30/09Branch Alternative 1 
Make the hardware annul instructions in the branch delay slots of a taken
branch. 
IF
EXEi i+1 i+2 i+3 i+4 i+5 i+6
CMP ADD XOR BT 
CMP ADD BT CMP ADD BT 
CMP ADD XOR
Pros: same program runs on both unpipelined and pipelined hardware 
Cons: in SPEC benchmarks 14% of instructions are taken branches /.notdef.g0001
                                                              12% of total cycles are annulled LOOP: ADD(r1, r3, r3) 
CMPLEC(r3, 100, r0) 
BT(r0, LOOP) 
XOR(r3, -1, r3) 
MUL(r1, r2, r2) 
...
Branch taken NOP
L22  Pipelining the Beta   11  6.004  Spring 2009 4/30/09Branch Annulment Hardware 
ASEL 0 1
Data Memory 
RDWD
AdrR/W
WDSEL 012WA &lt;25:21&gt;
01XPPCIFJT
+4Instruction
Memory
AD
&lt;15:11&gt; &lt;20:16&gt;
RA2SEL&lt;25:21&gt;
+
Register
FileRA1 RA2
RD1 RD2
BSEL 0 1Z
ALUABJTWAWD
WE
ALUFN
PC+401
Wr0 1 2 3 4XAdrILL
OP
WASEL
WERF00PCSEL
&lt;15:0&gt;PCEXE00 IREXEANNULIF 01NOP
L22  Pipelining the Beta   12  6.004  Spring 2009 4/30/09Branch Alternative 2a 
Fill branch delay slots with 
NOP instructions (i.e., the software equivalent of alternative 1) 
IF
EXEi i+1 i+2 i+3 i+4 i+5 i+6
CMP ADD NOP BT 
CMP ADD BT CMP ADD BT 
CMP ADD NOP
Branch taken 
Pros: same as alternative 1 
Cons:  NOPs make code longer; 12% of cycles spent executing NOPs LOOP: ADD(r1, r3, r3) 
CMPLEC(r3, 100, r0) 
BT(r0, LOOP) 
NOP()
XOR(r3, -1, r3) 
MUL(r1, r2, r2) 
.../.notdef.g0001
/.notdef.g0001
/.notdef.g0001
/.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L22  Pipelining the Beta   21  6.004  Spring 2009 4/30/09Data Hazard Solution 3 
Bypass (aka forwarding) Paths: 
Add extra data paths &amp; control logic to re-route 
data in problem cases. 
ADD CMP MUL SUB
ADD CMP MUL SUB
r3
available ADD CMP MUL SUB
ADD CMP MUL SUB
Idea: the result from the ADD which will be written into the register le at 
the end of cycle I+3 is actually available at output of ALU during cycle I+2  just in time for it to be used by CMP in the RF stage! IF
RF
ALU
WBi i+1 i+2 i+3 i+4 i+5 i+6
L22  Pipelining the Beta   22  6.004  Spring 2009 4/30/09Bypass Paths (I) 
Register
FileWA WD
WEALUAB
Y
IRWBIRALURegister
FileRA1 RA2
RD1 RD2IRRF
YWBB ABypass 
 muxes SELECT this BYPASS path if 
OpCodeRF = reads Ra 
and  OpCodeALU = OP , OPC 
and  RaRF = RcALU 
i.e., instructions which use 
ALU to compute result 
and  RaRF != R31 ADD(r1,r2,r3)CMPLEC(r3,100,r0) 
L22  Pipelining the Beta   23  6.004  Spring 2009 4/30/09Bypass Paths (II) 
Register
FileWA WD
WEALUAB
Y
IRWBIRALURegister
FileRA1 RA2
RD1 RD2IRRF
YWBB ABypass 
 muxes 
MULC(r4,17,r5) ADD(r1,r2,r3)
XOR(r2,r6,r1)SELECT this BYPASS path if 
OpCodeRF = reads Ra 
and  RaRF != R31 
and  not using ALU bypass 
and  WERF = 1 
and  RaRF = WA 
But why cant we get It from the register le? Its being written this cycle! 
L22  Pipelining the Beta   24  6.004  Spring 2009 4/30/09Next Time 
More Beta 
Bypasses Ahead</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L22  Pipelining the Beta   1  6.004  Spring 2009 4/30/09Pipelining the Beta 
bet/.notdef.g0001ta ('be-t&amp;) n. Any of various species of 
small, brightly colored, long-finned 
freshwater fishes of the genus Betta,
found in southeast Asia.  
be/.notdef.g0001ta (bA-t&amp;, bE-) n. 1. The second letter  
of the Greek alphabet.  2. The exemplary 
computer system used in 6.004. 
I dont think they mean the sh... maybe theyll 
give me partial 
credit... 
modied 4/27/09 11:17 Lab #7 due Tonight! 
L22  Pipelining the Beta   2  6.004  Spring 2009 4/30/09CPU Performance 
Weve got a working Beta can we make it fast?
MIPS = Millions of Instructions/Second 
Freq = Clock Frequency, MHz CPI = Clocks per Instruction 
 MIPS  = Freq
CPI
To Increase MIPS: 
1. DECREASE CPI. 
- RISC simplicity  reduces CPI to 1.0. 
- CPI below 1.0?   Tough... youll see multiple instruction issue 
machines in 6.823. 
2. INCREASE Freq. 
- Freq limited by delay along longest combinational path; hence 
-PIPELINING is the key to improved performance through fast 
clocks. 
L22  Pipelining the Beta   3  6.004  Spring 2009 4/30/09Beta Timing 
New PC 
PC+4 Fetch Inst. 
Control Logic 
Read Regs RA2SEL mux 
ASEL mux BSEL mux 
ALU 
Fetch data +OFFSET
WDSEL mux 
RF setup PC setup Mem setup PCSEL mux =0?CLK/.notdef.g0002/.notdef.g0002
CLK/.notdef.g0002/.notdef.g0002Wanted: 
    longest paths 
Complications: 
/.notdef.g0001 some apparent paths arent 
possible 
/.notdef.g0001 operations have variable 
execution times (eg, ALU) 
/.notdef.g0001 time axis is not to scale (eg, 
tPD,MEM  is very big!) New PC 
PC+4
Control Logic 
RA2SEL mux 
ASEL mux BSEL mux Fetch Inst. 
Read Regs 
Fetch data +OFFSET
WDSEL mux 
RF setup PC setup Mem setup PCSEL mux =0?CLK/.notdef.g0002/.notdef.g0002
CLK/.notdef.g0002/.notdef.g0002precedence 
graph PC+4
ALU +OFFSETLD(R1,10,R0) LDR(X,R3)
L22  Pipelining the Beta   4  6.004  Spring 2009 4/30/09
Why isnt this a 20-minute lecture? 
1. The Beta isnt combinational 
/.notdef.g0001/.notdef.g0001Explicit state  in register le, memory; 
/.notdef.g0001/.notdef.g0001Hidden  state in PC. 
2. Consecutive operations  instruction executions  interact: 
/.notdef.g0001Jumps, branches dynamically change instruction sequence 
/.notdef.g0001Communication through registers, memory 
Our goals: 
/.notdef.g0001 Move slow components into separate pipeline stages, running 
clock faster 
/.notdef.g0001 Maintain instruction semantics of unpipelined Beta as far as possibleWeve learned how to pipeline combinational circuits.  
Whats the big deal? 
/.notdef.g0001
/.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L22  Pipelining the Beta   5  6.004  Spring 2009 4/30/09Ultimate Goal: 5-Stage Pipeline 
GOAL:  Maintain (nearly) 1.0 CPI, but increase clock speed to 
barely  include slowest components (mems, regle, ALU) 
APPROACH: structure processor as 5-stage pipeline: 
IFInstruction Fetch stage : Maintains PC, fetches 
one instruction per cycle and passes it to 
WB Write-Back stage : writes result back into 
register le. RFRegister File stage : Reads source operands from 
register le, passes them to 
ALU ALU stage : P erforms indicated operation, passes 
result to 
MEM  Memory stage : If its a LD, use ALU result  
as an address, pass mem data  
(or ALU result if not LD) to 
L22  Pipelining the Beta   6  6.004  Spring 2009 4/30/09First Steps: 
A Simple 2-Stage Pipeline 
ASEL 0 1
Data Memory 
RDWD
AdrR/W
WDSEL 012WA &lt;25:21&gt;
01XPPCIFJT
+4Instruction
MemoryA
D
&lt;15:11&gt; &lt;20:16&gt;
RA2SEL&lt;25:21&gt;
+
Register
FileRA1 RA2
RD1 RD2
BSEL 0 1Z
ALUABJTWAWD
WE
ALUFN
PC+401
Wr0 1 2 3 4XAdrILL
OP
WASEL
WERF00PCSEL
&lt;15:0&gt;PCEXE00 IREXEIF
EXE 
L22  Pipelining the Beta   7  6.004  Spring 2009 4/30/092-Stage Pipelined Beta Operation 
..
ADDC(r1, 1, r2) 
SUBC(r1, 1, r3) 
XOR(r1, r5, r1) 
MUL(r2, r6, r0) 
...Consider a sequence 
of instructions: 
Executed on our 2-stage pipeline: 
IF
EXEi i+1 i+2 i+3 i+4 i+5 i+6
... SUBC ADDC MUL XOR
... SUBC ADDC MUL XORTIME (cycles) Pipeline 
L22  Pipelining the Beta   8  6.004  Spring 2009 4/30/09Pipeline Control Hazards 
BUT consider instead: 
IF
EXEi i+1 i+2 i+3 i+4 i+5 i+6
... CMP ADD XOR BT 
... CMP ADD ? BT LOOP: ADD(r1, r3, r3) 
CMPLEC(r3, 100, r0) 
BT(r0, LOOP) 
XOR(r3, -1, r3) 
MUL(r1, r2, r2) 
...
This is the cycle where the branch decision 
is made but weve already fetched the following instruction which should be executed only if branch is not taken!</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L22  Pipelining the Beta   17  6.004  Spring 2009 4/30/094-Stage Beta Operation 
...
ADDC(r1, 1, r2) 
SUBC(r1, 1, r3) 
XOR(r1, r5, r1) 
MUL(r2, r6, r0) 
...Consider a sequence 
of instructions: 
Executed on our 4-stage pipeline: 
... SUBC ADDC MUL XOR
... SUBC ADDC MUL XOR
... SUBC ADDC MUL XOR
SUBC ADDC MUL XORTIME (cycles) Pipeline IF
RF
ALU
WBi i+1 i+2 i+3 i+4 i+5 i+6
L22  Pipelining the Beta   18  6.004  Spring 2009 4/30/09r3
fetched 
r3
available Pipeline Data Hazard 
BUT consider instead: ADD(r1, r2, r3) 
CMPLEC(r3, 100, r0) 
MULC(r1, 100, r4) 
SUB(r1, r2, r5) 
ADD CMP MUL
ADD
ADD
ADDCMP
CMP
CMPSUB
MUL
MUL
MULSUB
SUB
SUB
Oops!  CMP is trying to read Reg[R3] during cycle  
i+2 but ADD doesnt write its result into Reg[R3] until the end of cycle i+3! IF
RF
ALU
WBi i+1 i+2 i+3 i+4 i+5 i+6
L22  Pipelining the Beta   19  6.004  Spring 2009 4/30/09Data Hazard Solution 1 
Program around it 
  ... document weirdo semantics, declare it a software problem. 
- Breaks sequential semantics! 
- Costs code eciency. 
ADD(r1, r2, r3) 
CMPLEC(r3, 100, r0) 
MULC(r1, 100, r4) 
SUB(r1, r2, r5) ADD(r1, r2, r3) 
MULC(r1, 100, r4) 
SUB(r1, r2, r5) 
CMPLEC(r3, 100, r0) EXAMPLE: Rewrite 
as
How often can we do this? 
Programmers fallback: Insert NOPs (sigh!) 
L22  Pipelining the Beta   20  6.004  Spring 2009 4/30/09Data Hazard Solution 2 
Stall the pipeline: 
Freeze IF , RF stages for 2 cycles, inserting NOPs 
into ALU-stage instruction register 
IF
RF
ALU
WBi i+1 i+2 i+3 i+4 i+5 i+6
ADD CMP MUL SUB
ADD CMP MUL SUB
ADD
ADDCMP
CMPMUL NOP NOP
NOP NOPMUL
CMPMUL
CMP
Drawback:  NOPs mean wasted cycles</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Storage elements, finite state machines</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec06/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>L06  FSMs   21  6.004  Spring 2009 2/24/09Equivalent State Reduction 
Observation: Si/.notdef.g0001 Sjif
     1. States have identical outputs;  AND
     2. Every input /.notdef.g0002equivalent states. 
Reduction Strategy: 
Find pairs of equivalent states, MERGE them.
LOST 
FWall2 
TL,F
Wall1 
TR,FRCCW 
RL+RL+R
_
RLTL
_ _ L R _  _ 
L R _ _ L R _
L R 
TR,FCorner R _R
L06  FSMs   22  6.004  Spring 2009 2/24/09An Evolutionary Step 
Behaves exactly as previous (5-state) FSM, but requires half  the 
ROM in its implementation! Merge equivalent states Wall1 and Corner into a single new, 
combined state. 
LOST 
FWall2 
TL,F
Wall1 
TR,FRCCW 
RL+RL+R
_RLTL
_ _ L R _  _ 
L R _ _ L R _
L R 
L06  FSMs   23  6.004  Spring 2009 2/24/0900 1 -   01 0  0  1 
00 0 1   01 0  0  1 L+R RCCW L+R
01 1 - | 01 0  1  0 
01 0 1 | 01 0  1  0 TLBuilding the Transition Table 
S  L R | S TR TL F 
-------+-----------
00 0 0 | 00 0  0  1 
       |
       |
       |
       |
       | 
       |
       |
       | 
       | 
       | LOST 
F
_ _ 
L R 
L06  FSMs   24  6.004  Spring 2009 2/24/09Implementation Details 
S  L R | S TR TL F 
-------+-----------
00 0 0 | 00 0  0  1 
00 1 - | 01 0  0  1 
00 0 1 | 01 0  0  1 
01 1 - | 01 0  1  0 
01 0 1 | 01 0  1  0 
01 0 0 | 10 0  1  0 
10  0 | 10 1  0  1 
10  1 | 11 1  0  1 
11 1 - | 01 0  1  1 
11 0 0 | 10 0  1  1 
11 0 1 | 11 0  1  1 LOST 
RCCW 
WALL1 
WALL2 S1       S1S0
00 01 11 10 
00  0  1  1  1 
LR01  0  0  1  1 
11  0  0  0  1 
10  0  0  0  1 
S0       S1S0
00 01 11 10 
00  0  0  0  0 
LR01  1  1  1  1 
11  1  1  1  1 
10  1  1  1  0 0 1 0 1 1S R L S L S S S+ + = /.notdef.g0001
Complete Transition table 
0 1 0 LSS L R S+ + = /.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L06  FSMs   5  6.004  Spring 2009 2/24/09Abstraction du jour: 
Finite State Machines 
/.notdef.g0001A FINITE STATE MACHINE has Clocked
FSMmn
/.notdef.g0001k STATES: S1  Sk (one is initial state) 
/.notdef.g0001m INPUTS: I1  Im
/.notdef.g0001n OUTPUTS: O1  On
/.notdef.g0001Transition Rules s(s, I) for each state s and input I 
/.notdef.g0001Output Rules Out(s) for each state s 
L06  FSMs   6  6.004  Spring 2009 2/24/09State Transition Diagram 
SX
U=0S0
U=0 0S01
U=0 1S011
U=0 1S0110
U=1 01
0 00
1
1
XXX
U=0NAME
of state 
OUTPUT 
when in this 
state 0
INPUT
causing 
transition Heavy circle 
Means
INITIAL  state Designing our lock  
/.notdef.g0001Need an initial state; call it SX. 
/.notdef.g0001Must have a separate state for each step 
of the proper entry sequence 
/.notdef.g0001Must handle other (erroneous) entries Why do these 
go to S0 and S01? 
L06  FSMs   7  6.004  Spring 2009 2/24/09Yet Another Specication
SX
U=0S0
U=0 0S01
U=0 1S011
U=0 1S0110
U=1 01
0 00
1
1
IN    Current State              Next State Unlock 
0 SX S0      0 
 1 SX SX      0 
0 S0 S0      0 
 1 S0 S01      0 
0 S01 S0      0 
 1 S01 S011      0 
0 S011 S0110      0 
 1 S011 SX      0 0 S0110 S0       1  1 S0110 S01       1 All state transition 
diagrams can be described by truth 
tables
Binary encodings are 
assigned to each state  (a bit of an art) 
The truth table can then 
be simplied using the reduction techniques we learned for combinational logic 000
00000 1 
00 1 
0 1 1 0 1 1 0 10 0 10 
 100  100 00 1 
00000 1 
0 1 1 
00 1 0 10 1 00 000
00 1 0 1 1 
The assignment of codes to 
states can be arbitrary, however, 
if you choose them carefully you 
can greatly reduce your logic 
requirements. 
L06  FSMs   8  6.004  Spring 2009 2/24/09Valid State Diagrams 
/.notdef.g0001Arcs leaving a state must be: 
/.notdef.g0001  (1) mutually exclusive
/.notdef.g0001 cant have two choices for a given input value 
/.notdef.g0001  (2) collectively exhaustive 
/.notdef.g0001 every state must specify what happens for each possible input 
combination.  Nothing happens means arc back to itself. S1 S3
0 0
S2
11
10 1
0
MOORE Machine: 
Outputs on States S1 S3
0/0 0/1
S2
1/01/1
1/0
MEALY  Machine: 
Outputs on Transitions 00/0</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>L06  FSMs   25  6.004  Spring 2009 2/24/09Ant Schematic 
L06  FSMs   26  6.004  Spring 2009 2/24/09
Roboant  
Maze
selection FSM state 
table  
Status
displayPlan view 
of maze
Simulation 
controls  
Featuring the new Mark-II ant: can add (M), 
erase (E), and sense (S) marks along its path. 
L06  FSMs   27  6.004  Spring 2009 2/24/09Housekeeping issues 
ROM
or
gates 
NEXT STATE inputs outputs
s s1. Initialization?  Clear the memory? 
2. Unused state encodings? 
        - waste ROM (use PLA or gates) 
        - what does it mean?         - can the FSM recover?   
3. Choosing encoding for state?  4. Synchronizing input changes with 
     state update? 
IN
CLKU
Now, thats a funny  
looking state machine 
L06  FSMs   28  6.004  Spring 2009 2/24/09Twisting you Further 
MORE THAN ANTS: 
Swarming, ocking, and schooling can result 
from collections of very simple FSMs 
 PERHAPS MOST PHYSICS:  
Cellular automata, arrays of simple FSMs, 
can more accurately model uilds than 
numerical solutions to PDEs 
 WHAT IF: 
We replaced the ROM with a RAM and have 
outputs that modify the RAM? 
... Y ou'll see FSMs for the rest of your life! 
I prefer to think we 
ascended Did we all descend from FSMs???</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L06  FSMs   17  6.004  Spring 2009 2/24/09Bonk!
LOST 
FL+R
_ _ 
L R RCCW L+R
TL
_  _ 
L R Action: Turn left (CCW) until we dont touch anymore  
L06  FSMs   18  6.004  Spring 2009 2/24/09A little to the right 
LOST 
FRCCW L+RL+R
Wall1 
TR,FR
_RTL
_ _ L R _  _ 
L R Action: Step and turn right a little, look for wall  
L06  FSMs   19  6.004  Spring 2009 2/24/09Then a little to the left 
LOST 
F
Wall1 
TR,FRCCW 
RL+RL+R
_RTL
_ _ 
L R _  _ 
L R 
_ _ 
L R Wall2 
TL,F L_
L R Action: Step and turn left a little, till not touching (again)  
L06  FSMs   20  6.004  Spring 2009 2/24/09Dealing with corners 
LOST 
FWall2 
TL,F
Wall1 
TR,FRCCW 
RL+RL+R
_RLTL
_ _ 
L R _  _ 
L R _ _ L R _
L R 
TR,FCorner R _
RAction: Step and turn right until we hit perpendicular wall</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L06  FSMs   1  6.004  Spring 2009 2/24/09(Synchronous)
Finite State Machines 
Lab 2 is due Thursday Great   -  Theory! 
Finally!  
Some ENGINEERING!
modied 2/23/09 09:27 L06  FSMs   2  6.004  Spring 2009 2/24/09Our New Machine 
Combinational 
Logic Current 
State New
State 
Input Output Clock State 
Registers kk
m n
/.notdef.g0001Acyclic graph 
/.notdef.g0001Obeys static discipline 
/.notdef.g0001Can be exhaustively enumerated by a 
truth table of 2k+mrows and k+n output 
columns 
/.notdef.g0001Engineered cycles 
/.notdef.g0001Works only if dynamic 
discipline obeyed 
/.notdef.g0001Remembers k bits for a total 
of 2k unique combinations 
L06  FSMs   3  6.004  Spring 2009 2/24/09Must Respect Timing Assumptions! 
Questions: 
/.notdef.g0001Constraints on TCD for the logic? 
/.notdef.g0001Minimum clock period? 
/.notdef.g0001Setup, Hold times for Inputs? Combinational 
Logic Current 
State New
State 
Input Output Clock tCD,L = ? 
tPD,L = 5ns tCD,R = 1ns 
tPD,R = 3ns 
tS,R = 2ns 
tH,R = 2ns 
tCD,L &gt; 1 ns 
tS = tPD,L + tS,R = 7 nS 
tH = tH,R- tCD,L= 1 nS 
We know how fast it goes But what can it do? tCD,R (1 ns) + tCD,L(?) &gt; tH,R(2 ns) 
tCLK &gt; tPD,R+tPD,L+ tS,R &gt; 10nS 
L06  FSMs   4  6.004  Spring 2009 2/24/09A simple sequential circuit 
Lets make a digital binary Combination Lock: 
Specication: 
/.notdef.g0001One input ( 0 or 1) 
/.notdef.g0001One output (Unlock signal) 
/.notdef.g0001UNLOCK is 1 if and only if: 
Last 4 inputs were the 
combination: 0110 How many 
registers do 
I need? Lock INU
CLK</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L06  FSMs   9  6.004  Spring 2009 2/24/09Now put it in Hardware! 
ROM
16x4unlock 
Next state Current state IN
Trigger update periodically (clock) 3 34 inputs /.notdef.g0002/.notdef.g000224 locations 
each location supplies 4 bits 
We assume 
inputs are 
synchronized 
with clock 
L06  FSMs   10  6.004  Spring 2009 2/24/09Discrete State, Time 
Clock
STATE
NEXT
Clock 
P eriod 
1Clock 
P eriod 
2Clock 
P eriod 
3Clock 
P eriod 
4Clock 
P eriod 
5ROM
NEXT STATE inputs outputs
s s
s state bits /.notdef.g0002/.notdef.g0002 2s possible states Two design choices: 
  (1) outputs only depend on state 
  (2) outputs depend on inputs + state (Moore) 
         (Mealy) 
L06  FSMs   11  6.004  Spring 2009 2/24/091 1 1 0Asynchronous Inputs - I 
Our example assumed a single clock transition per input. What if the  
button pusher is unaware of, or not synchronized with, the clock? 
SX
U=0S0
U=0S01
U=0S011
U=0
U=0B0B0
U=0B1B1
U=0B1B1
U=0B1B1What if each button input is an 
asynchronous 0/1 level?  How do we prevent a single button
press, e.g., from making 
several transitions? Lock B1UB00
1 01
Use intervening states  to synchronize button presses! But what 
About the 
Dynamic
Discipline? 
L06  FSMs   12  6.004  Spring 2009 2/24/09FSM Party Games 
ROM
k k1.  What can you say about the 
number of states? 
2.  Same question: m
Statesn
Statesx y z
3. Here's  an  FSM.  Can you 
discover  its  rules? 
You Win!o 1
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L06  FSMs   13  6.004  Spring 2009 2/24/09Whats My Transition Diagram? 
10
101
01 1
01
01
0 0
vs. 0=
"1
You Win!o 1OFF ,
1=ON?
111" =
Surprise!
/.notdef.g0001If you know NOTHING about the FSM,  youre never sure! 
/.notdef.g0001If you have a BOUND on the number of states, you can discover its 
behavior: 
              K -state FSM: Every (reachable) state can be 
          reached in &lt; k steps.
BUT ... states may be equivalent !1
L06  FSMs   14  6.004  Spring 2009 2/24/09FSM Equivalence 
1 01
01
 01 1
01
01
0 0
vs.
ARE  THEY  DIFFERENT? 
NOT in any practical sense! They are EXTERNALLY 
INDISTINGUISHABLE, hence interchangeable. 
FSMs EQUIVALENT  i every input sequence 
yields identical output sequences. 
ENGINEERING  GOAL: 
 HAVE an FSM which  works... 
 WANT  simplest   (ergo cheapest) equivalent  FSM. 
L06  FSMs   15  6.004  Spring 2009 2/24/09Lets build an Ant
/.notdef.g0001SENSORS: antennae L and R, each 1 if in  
contact with something. 
/.notdef.g0001ACTUATORS: Forward Step F , ten-degree 
turns TL and TR (left, right). 8 legs?
GOAL: Make our ant smart enough to get out of a maze like:
STRATEGY: "Right antenna to the wall" 
L06  FSMs   16  6.004  Spring 2009 2/24/09Lost in space 
?
LOST 
FL+R
_ _ 
L R 
lost is the 
initial stateAction: Go forward until we hit something.  Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Parallel processing, shared memory, cache coherence, consistency criteria</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec24/</lecture_pdf_url>
      <lectureno>24</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>L24 P arallel Processing   17  6.004 Spring 2009 5/7/09Uniprocessor Outcome 
But, what are the possible outcomes if we ran Process A and 
Process B on a single timed-shared processor ?
SEQUENCE A prints B prints 
x=3; print(y); y=4; print(x); 2 3
x=3; y=4; print(y); print(x); 4 3x=3; y=4; print(x); print(y); 4 3
y=4; x=3; print(x); print(y); 4 3
y=4; x=3; print(y); print(x); 4 3y=4; print(x); x=3; print(y); 4 1Plausible Uniprocessor execution sequences: Process A
x = 3; 
print(y);Process B
y = 4; print(x);
Notice that the 
outcome 2, 1 does not appear 
in this list! 
L24 P arallel Processing   18  6.004 Spring 2009 5/7/09Sequential Consistency 
Semantic constraint: 
Result of executing N parallel programs should correspond to some
interleaved execution on a single processor.  
P ossible printed values: 2, 3;   4, 3;   4, 1. 
(each corresponds to at least one interleaved execution) 
IMPOSSIBLE printed values:  2, 1 
(corresponds to NO valid interleaved execution). Process A
x = 3; 
print(y);Process B
y = 4; print(x);Shared Memory
int x=1, y=2; 
Werent 
caches supposed to 
be invisible to  
programs? 
L24 P arallel Processing   19  6.004 Spring 2009 5/7/09Cache Incoherence 
PROBLEM:  stale values in cache ... 
Process B
y = 4; 
print(x);Process A
x = 3; print(y);
Q: How does B know that A has changed the value of x?P1
$1: x=3
        y=2 
Shared Memory P2
$2: x=1
       y=4 
x=3, y=4 
Does  
WRITE-THRU  
help?  
_______!  NO
The problem is 
not that 
memory has stale values, 
but that other 
caches may! 
L24 P arallel Processing   20  6.004 Spring 2009 5/7/09Snoopy Caches 
P1
$1: x=1
        y=2 
Shared Memory P2
$2: x=1
        y=2 
x=1,       y=2 
IDEA:
 P1 writes 3 into x; write-thru cache causes bus transaction. 
 P2, snooping, sees transaction on bus.   INVALIDATES or UPDATES its cached 
x value. 
Presume 
WRITE-THRU 
caches! X 3 
X 3 X 3</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L24 P arallel Processing   21  6.004 Spring 2009 5/7/09Snoopy Cache Design 
Two-bit STATE in cache line encodes one of M, E, S, I states (MESI cache): 
INVALID:  cache line unused. 
SHARED ACCESS : read-only, valid, not dirty.  Shared with other read-only 
copies elsewhere.  Must invalidate other copies before writing.  
EXCLUSIVE : exclusive copy, not dirty.  On write becomes modied. 
MODIFIED: exclusive access; read-write, valid, dirty.  Must be written back 
to memory eventually; meanwhile, can be written or read by local 
processor. 
4-state  
FSM for 
each  
cache line!  
(FREE!!: Can redene 
VALID and DIRTY bits)Current
stateRead Hit Read Miss,
Snoop HitRead Miss,
Snoop MissWrite Hit Write Miss Snoop for
ReadSnoop for
Write
Modified Modified Invalid
( Wr-Back)Invalid
( Wr-Back)Modified Invalid
( Wr-Back)Shared
(Push)Invalid
(Push)
Exclusive Exclusive Invalid Invalid Modified Invalid Shared Invalid
Shared Shared Invalid Invalid Modified
(Invalidate)Invalid Shared Invalid
Invalid X Shared
(Fill)Exclusive
(Fill)X Modified
(Fill- Inv)X X
L24 P arallel Processing   22  6.004 Spring 2009 5/7/09Who needs Sequential Consistency, anyway? 
ALTERNATIVE MEMORY SEMANTICS: 
WEAK consistency 
EASIER GOAL: Memory operations from each processor appear to be 
performed in order issued by that processor; 
Memory operations from dierent processors may overlap in arbitrary ways 
(not necessarily consistent with any interleaving). 
ALTERNATIVE APPROACH:
 Weak consistency, by default; 
 MEMORY BARRIER instruction: stalls processor until all previous memory 
operations have completed. 
L24 P arallel Processing   23  6.004 Spring 2009 5/7/09MIMD Multicore Arrays 
/.notdef.g0001Can Leverage existing CPU 
designs / development tools 
/.notdef.g0001H/W focuses on 
communication 2-D Mesh /
cache hierarchy/ ) 
/.notdef.g0001S/W focuses on partitioning, 
extracting parallelism 
/.notdef.g0001speculative execution hacks 
http://www.tilera.com/ /.notdef.g0001 16 cores/32 thr 
/.notdef.g0001 250W @ 2.3GHz 
/.notdef.g0001 Transactional Mem 
/.notdef.g0001 Thread Speculation 
/.notdef.g0001 scout threads 
L24 P arallel Processing   24  6.004 Spring 2009 5/7/09Parallel Processing Summary 
Prospects for future CPU architectures:
Pipelining - Well understood, but mined-out 
Superscalar - At its practical limits 
SIMD - Limited use for special applications 
VLIW - Returns controls to S/W but inexible 
Prospects for future Computer System architectures:
Single-thread limits: forcing multicores, parallelism 
Brains work well, with dismal clock rates  parallelism? 
Needed: NEW models, NEW ideas, NEW approaches 
FINAL ANSWER:  Its up to YOUR generation! 
Figure by MITOpenCourseWare.
/.notdef.g0001 64 cores 
/.notdef.g0001 22 W @ 700MHz 
/.notdef.g0001 2D Mesh</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L24 P arallel Processing   1  6.004 Spring 2009 5/7/09Parallel Processing 
modied 5/4/09 10:08 L24 P arallel Processing   2  6.004 Spring 2009 5/7/09The Home Stretch 
TODAY 5/7: Lab 8 (LAST!) due 
Friday 5/8 section:  LAST QUIZ (#5)!
Tu 5/12: Wrapup (LAST!) Lecture! 
Wednesday 5/13: 
NO SECTION MEETINGS!
/.notdef.g0001/.notdef.g0001Optional DESIGN PROJECT due 
/.notdef.g0001/.notdef.g0001ALL (late) Assignments due 
/.notdef.g0001/.notdef.g0001Immense Satisfaction/Rejoicing/Relief/Celebration/Wild 
Partying.
L24 P arallel Processing   3  6.004 Spring 2009 5/7/09Taking a step back 
Dynamic
Execution Path Static Code 
Path Length = number of instructions along path aka Thread of Execution loop:  
   LD(n, r1)
   CMPLT(r31, r1, r2)  
   BF(r2, done)  
   LD(r, r3)     LD(n,r1)
   MUL(r1, r3, r3)
   ST(r3, r)
   LD(n,r1)
   SUBC(r1, 1, r1)   ST(r1, n)
              BR(loop)  done: 
L24 P arallel Processing   4  6.004 Spring 2009 5/7/09We have been building machines to execute 
one thread (quickly) 
Beta 
Processor Memory 
Execution Thread 
                          Path Length  x  Clocks-per-Instruction 
Time     =
                                      Clocks-per-second</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L24 P arallel Processing   9  6.004 Spring 2009 5/7/09SIMD Coprocessing Units 
SIMD data path added to a traditional CPU core 
Register-only operands 
Core CPU handles memory trac
Partitionable Datapaths for variable-sized 
PACKED OPERANDS Reg File 
64-bit ALU6464
64
Intel MMX, SSE 
Sparc VIS 
L24 P arallel Processing   10  6.004 Spring 2009 5/7/09SIMD Coprocessing Units 
SIMD data path added to a traditional CPU core 
Register-only operands
Core CPU handles memory trac
Partitionable Datapaths for variable-sized 
PACKED OPERANDS Reg File 
32-bit ALU6464
64
32-bit ALU Two 
32-bit ALUs FA a   b 
sco    ciFA a   b 
sco    ciA32 B32  A31 B31 
S32        S31 ... ...
L24 P arallel Processing   11  6.004 Spring 2009 5/7/09SIMD Coprocessing Units 
SIMD data path added to a traditional CPU core 
Register-only operands 
Core CPU manages memory trac
Partitionable Datapaths for variable-sized 
PACKED OPERANDS Reg File 
16-bit ALU6464
64
16-bit ALU16-bit ALU16-bit ALUFour 
16-bit ALUs Nice data size for: 
Graphics, Signal Processing, 
Multimedia Apps, 
etc. 
L24 P arallel Processing   12  6.004 Spring 2009 5/7/09SIMD Coprocessing Units 
SIMD data path added to a traditional CPU core 
Register-only operands 
Core CPU manages memory trac
Partitionable Datapaths for variable-sized 
PACKED OPERANDS Reg File 
6464
64
Eight
8-bit ALUs 8-bit ALU 8-bit ALU 8-bit ALU 8-bit ALU 8-bit ALU 8-bit ALU 8-bit ALU 8-bit ALU MMX instructions: 
PADDB - add bytes 
PADDW - add 16-bit words 
PADDD - add 32-bit words 
(unsigned &amp; w/saturation) 
PSUB{B,W,D}  subtract PMULTLW  multiply low 
PMULTHW  multiply high 
PMADDW  multiply &amp; add 
PACK  
UNPACK  PAND  
POR -</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L24 P arallel Processing   13  6.004 Spring 2009 5/7/09VLIW Variant of SIMD Parallelism 
(Very Long Instruction Word) 
A single-WIDE instruction controls multiple heterogeneous 
datapaths.
Exposes parallelism to compiler (S/W vs. H/W) 
Register File 
Integer ALU #1 
Floating P oint 
Adder Integer ALU #2 Floating P oint 
MultiplierFP Regs Instr. Fetch 
&amp; Branch 
Prediction 
Load 
Store 
UnitInstr
$
Data 
$Memory Interface IOP1RC1RA1RB1IOP2RC2RA2RB2FOP FD1FA1FB1FD2FA2FB2MemOP
L24 P arallel Processing   14  6.004 Spring 2009 5/7/09Multiple Instruction Streams: MIMD 
Exploiting Thread Level Parallelism 
All processors share a common main memory 
Leverages existing CPU designs 
Easy to map Processes (threads) to Processors 
Share data and program 
Communicate through 
shared memory 
UpgradeableProblems:
Scalability
Synchronization/.notdef.g0001
$/.notdef.g0001
$/.notdef.g0001
$/.notdef.g0001
$/.notdef.g0001
$
Main Memory  
SMP  Symmetric Multi-Processor One thread per processor 
L24 P arallel Processing   15  6.004 Spring 2009 5/7/09Hmmm.does it even work? 
P1
$1: x = 1 
      y = 2 
Shared Memory,  x = 1, y = 2 P2
$2: x = 1 
      y = 2 
Process A
x = 3; 
print(y);Process B
y = 4; print(x);Consider the following trivial processes running on P1 and P2:
L24 P arallel Processing   16  6.004 Spring 2009 5/7/09What are the Possible Outcomes? 
SEQUENCE A prints B prints 
x=3; print(y); y=4; print(x); 2 1
x=3; y=4; print(y); print(x); 2 1x=3; y=4; print(x); print(y); 2 1
y=4; x=3; print(x); print(y); 2 1
y=4; x=3; print(y); print(x); 2 1y=4; print(x); x=3; print(y); 2 1Plausible execution sequences: Process A
x = 3; 
print(y);Process B
y = 4; print(x);
$1: x = 1 
      y = 2 $2: x = 1 
      y = 2 
Hey, we get the 
same answer every time Lets go 
build it! X  3 
X  4</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L24 P arallel Processing   5  6.004 Spring 2009 5/7/09Can we make CPI &lt; 1 ? 
Two Places to Find Parallelism 
Instruction Level (ILP)  Fetch and issue 
groups of independent instructions within a 
thread of execution 
Thread Level (TLP)   Simultaneously execute 
multiple execution streams
Implies we can complete  
more than one  instruction each clock cycle! 
L24 P arallel Processing   6  6.004 Spring 2009 5/7/09Instruction-Level Parallelism 
Sequential Code 
This is okay, but smarter coding does better in this example! loop:  
   LD(n, r1)
   CMPLT(r31, r1, r2)  
   BF(r2, done)  
   LD(r, r3)  
   LD(n,r1)   MUL(r1, r3, r3)
   ST(r3, r)
   LD(n,r4)
   SUBC(r4, 1, r4)
   ST(r4, n)
              BR(loop)  
done: What if I tried to 
do multiple iterations at 
once? loop:  
   LD(n, r1)   CMPLT(r31, r1, r2)  
   BF(r2, done)  
   LD(r, r3)  LD(n,r1)  LD(n,r4)     MUL(r1, r3, r3) SUBC(r4, 1, r4)   ST(r3, r) ST(r4, n) BR(loop)  done: Safe Parallel Code 
L24 P arallel Processing   7  6.004 Spring 2009 5/7/09
Superscalar Parallelism 
-/.notdef.g0001Popular now, but the limits are near (8-issue) 
-/.notdef.g0001Multiple instruction dispatch 
-/.notdef.g0001Speculative execution 
L24 P arallel Processing   8  6.004 Spring 2009 5/7/09SIMD Processing 
(Single Intruction Multiple Data) 
Each datapath has its own local data (Register File) 
All data paths execute the same instruction 
Conditional branching is dicult
(What if only one CPU has R1 = 0?) 
Conditional operations are common in SIMD machines 
if (ag1) Rc = Ra &lt;op&gt; Rb 
Global ANDing or ORing of ag registers are used for high-level 
controlReg File 
ALUPC+1 or Branch 
Reg File 
ALUReg File 
ALUReg File 
ALUData 
Memory 
Instruction 
Memory addr
addrdata
dataAddressing 
Unit
Control 
Model: hide parallelism in primitives (eg, vector operations) This sort of 
construct is also becoming 
popular on 
modern uniprocessors</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Stacks and procedures</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec13/</lecture_pdf_url>
      <lectureno>13</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>Stacks&amp;Procedures   17  6.004  Spring 2009 3/19/09Our favorite procedure 
fact: PUSH(LP) | save linkages 
PUSH(BP)
MOVE(SP,BP) | new frame base 
PUSH(r1) | preserve regs 
LD(BP,-12,r1) | r1 /.notdef.g0002 n 
BNE(r1,big) | if (n != 0) 
ADDC(r31,1,r0) | else return 1; 
BR(rtn)
big: SUBC(r1,1,r1) | r1 /.notdef.g0002 (n-1) 
PUSH(r1) | push arg1 
BR(fact,LP) | fact(n-1) 
DEALLOCATE(1) | pop arg1 
LD(BP,-12,r1) | r0 /.notdef.g0002 n 
MUL(r1,r0,r0) | r0 /.notdef.g0002 n*fact(n-1) 
rtn: POP(r1) | restore regs 
MOVE(BP,SP) | Why? 
POP(BP) | restore links 
POP(LP)
JMP(LP,R31) | return. int fact(int n) 
{
    if (n != 0) 
        return n*fact(n-1); 
    else 
        return 1; }
6.004:
Factorial Structures 
Stacks&amp;Procedures   18  6.004  Spring 2009 3/19/09Recursion?
But of course! SP
old &lt;BP&gt; old &lt;LP&gt; 
old &lt;R1&gt; 3
BP
SPfact(3) 
BPold &lt;BP&gt; old &lt;LP&gt; 
old &lt;R1&gt; 
SP2
fact(2) 
BPold &lt;BP&gt; old &lt;LP&gt; 
old &lt;R1&gt; 
SP1
fact(1) 
BPold &lt;BP&gt; old &lt;LP&gt; 
old &lt;R1&gt; 
SP0
fact(0) /.notdef.g0001Frames allocated for each 
recursive call... 
/.notdef.g0001De-allocated (in inverse order) as 
recursive calls return. 
Debugging skill:  
stack crawling 
/.notdef.g0001Given code, stack snapshot  gure 
out what, where, how, who... 
/.notdef.g0001Decode args, locals, return 
locations, etc etc etc 
Particularly useful on 6.004 quizzes! /.notdef.g0001Follow old &lt;BP&gt; links to parse 
frames 
Stacks&amp;Procedures   19  6.004  Spring 2009 3/19/09Stack Detective 
fact(n) is called.  During the 
calculation, the computer is stopped 
with the PC at 0x40; the stack 
contents are shown (in hex).
BP
SP???80
???6
10C40
55
11C40
44
12C40
33
old &lt;BP&gt; old &lt;LP&gt; 
old &lt;R1&gt; arg n /.notdef.g0001/.notdef.g0001Whats the argument to the most 
recent  call to fact? 
/.notdef.g0001/.notdef.g0001Whats the argument to the original  call 
to fact? 
/.notdef.g0001/.notdef.g0001Whats the location of the original 
calling (BR) instruction? 
/.notdef.g0001/.notdef.g0001What instruction is about to be 
executed? 
/.notdef.g0001/.notdef.g0001What value is in BP? 
/.notdef.g0001/.notdef.g0001What value is in SP? 
/.notdef.g0001/.notdef.g0001What value is in R0? 
/.notdef.g0001/.notdef.g0001What follows the call to fact(n)? 3
6
80  4 = 7C 
DEALLOCATE(1) 
13C
13C+4+4=144
fact(2) = 2 main pgm 
fact fact(6) 
fact(5) 
fact(4) 
another call to fact .  Its the only 
program these guys have. 
Stacks&amp;Procedures   20  6.004  Spring 2009 3/19/09Man vs. Machine 
Heres a C program which was fed to the C compiler*.  
Can you generate code as good as it did? 
int ack(int i, int j) 
{
  if (i == 0) return j+j; 
  if (j == 0) return i+1; 
  return ack(i-1, ack(i, j-1)); 
}
* GCC P ort courtesy of Cotton Seed, Pat LoPresti, &amp; Mitch Berger; 
available on Athena: 
Athena% attach 6.004 
Athena% gcc-beta -S -O2 file.c</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Stacks&amp;Procedures   21  6.004  Spring 2009 3/19/09Tough Problems 
2. "Dangling References" - - -  1. NON-LOCAL variable access, particularly in nested procedure  denitions.
f(int x)/.notdef.g0001
 { int g(int y)/.notdef.g0001
    { return x+y; }/.notdef.g0001
   return g;/.notdef.g0001
 }/.notdef.g0001
z = f(3)(4);/.notdef.g0001(((lambda (x)/.notdef.g0001
   (lambda(y)(+ x y)))/.notdef.g0001
  3)/.notdef.g0001
 4)/.notdef.g0001"FUNarg" problem of LISP: 
Conventional solutions:  
/.notdef.g0001Environments, closures. 
/.notdef.g0001static links in stack frames, pointing to frames of statically 
enclosing blocks.  This allows a run-time discipline which 
correctly accesses variables in enclosing blocks. 
(C avoids this problem by outlawing nested procedure declarations!) BUT enclosing block may no longer exist (as above!). Python: 
   def f(x):/.notdef.g0001
      def g(y): return x+y/.notdef.g0001
      return g/.notdef.g0001
z = f(3)(4)/.notdef.g0001
Stacks&amp;Procedures   22  6.004  Spring 2009 3/19/09Dangling References 
int *p; /* a pointer */ 
int h(x) 
{
   int y = x*3; 
   p = &amp;y; 
   return 37; 
}
h(10);
print(*p);
What do we expect??? P= ? 
BP y = 30 old &lt;LP&gt; 
old &lt;BP&gt; x = 10 
h(10)?
Randomness.  Crashes.  Smoke.  Obscenities. 
Furious calls to Redmond, WA. 
Stacks&amp;Procedures   23  6.004  Spring 2009 3/19/09Dangling References: 
dierent strokes... 
C and C++: real tools, real dangers.
Y ou get what you deserve". 
Safety as a language/runtime property: guarantees against 
stray reads, writes. 
/.notdef.g0001Tension: (manual) algorithm-specic optimization opportunites vs. simple, 
uniform, non-optimal storage management 
/.notdef.g0001Tough language/compiler problem: abstractions, compiler technology that 
provides simple safety yet exploits eciency of stack allocation.Java / Scheme / Python / ...: kiddie scissors only.
/.notdef.g0001No " ADDRESS OF" operator: language restrictions forbid  
constructs which could lead to dangling references. 
/.notdef.g0001Automatic storage management: garbage collectors, 
reference counting: local variables allocated from a heap rather than a stack. 
Stacks&amp;Procedures   24  6.004  Spring 2009 3/19/09Next Time: Building a Beta 
ack:    PUSH (LP)
        PUSH (BP)        MOVE (SP, BP)
        PUSH (R1)
        PUSH (R2)        LD (BP, -12, R2)        LD (BP, -16, R0)_L4:    SHLC (R0, 1, R1) 
        BEQ (R2, _L1)
        ADDC (R2, 1, R1)        BEQ (R0, _L1)         SUBC (R2, 1, R1)        SUBC (R0, 1, R0)
        PUSH (R0)
        PUSH (R2)
        BR (ack, LP)        DEALLOCATE (2)         MOVE (R1, R2)
        BR (_L4)
_L1:    MOVE (R1, R0)         POP (R2)        POP (R1)        POP (BP)
        POP (LP)
        JMP (LP)
Figure MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Stacks&amp;Procedures   5  6.004  Spring 2009 3/19/09Revisiting Procedures Storage Needs 
Basic Overhead for Procedures/Functions:  
 Arguments 
f(x,y,z)  or perhaps...  sin(a+b)
 Return Address back to caller 
 Results to be passed back to caller. In C its the callers job to 
evaluate its arguments as 
expressions, and pass their 
resulting values  to the callee 
Thus, a variable name is just a 
simple case of an expression. 
Temporary Storage: 
intermediate results during expression evaluation. 
(a+b)*(c+d)
Local variables: 
{  int x, y; 
    ... x ... y ...; 
}
Each of these is specic to a particular activation  of a 
procedure; collectively, they may be viewed as the 
procedures activation record. 
Stacks&amp;Procedures   6  6.004  Spring 2009 3/19/09Lives of Activation Records 
fact(3)  TIME
A procedure call creates a new 
activation record.  Callers record is preserved because well need it when call nally returns. Return to previous activation record when procedure nishes, permanently discarding activation record created by call we are returning from. fact(3)  
fact(2)  int fact(int n) 
 { if (n &gt; 0) return n*fact(n-1); 
   else return 1; 
 } 
fact(3)  
fact(2)  
fact(1)  fact(3)  
fact(2)  
fact(1)  fact(3)  
fact(2)  
fact(1)  
fact(0)  fact(3)  
fact(2)  fact(3)  
Stacks&amp;Procedures   7  6.004  Spring 2009 3/19/09 Insight (ca. 1960): We need a STACK! 
Suppose we allocated  a 
SCRATCH memory for holding temporary variables. Wed like 
for this memory to grow and 
shrink as needed. And, wed like it to have an easy management
policy. 
One possibility is a  
STACK
A last-in-rst-out (LIFO) data 
structure. Some interesting 
properties of stacks: 
/.notdef.g0001Low overhead: Allocation, 
deallocation  by simply 
adjusting a pointer. 
/.notdef.g0001Basic PUSH, POP 
discipline: strong constraint on 
deallocation order. 
/.notdef.g0001Discipline matches 
procedure call/return, block entry/exit, 
interrupts, etc. 
Stacks&amp;Procedures   8  6.004  Spring 2009 3/19/09Stack Implementation 
CONVENTIONS:
Dedicate a register for the Stack 
P ointer (SP), R29. 
 Builds UP  (towards higher 
addresses) on push 
 SP points to rst UNUSED
location; locations below SP are 
allocated (protected). 
 Discipline: can use stack at any 
time ; but leave it as you found it! 
 Reserve a block of memory 
well away from our program and its data 
We use only software conventions  to 
implement our stack (many 
architectures dedicate hardware) 
Humm suddenly up is
down, and down up
Other possible implementations 
include stacks that grow down, 
SP points to top of stack, etc. unused
space stacked data stacked data 
stacked data 
stacked data 
Reg[SP] 
PUSHLOWER ADDRESSES 
HIGHER ADDRESSES 
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Stacks&amp;Procedures   1  6.004  Spring 2009 3/19/09
Stacks and Procedures 
Fritzs stack is 
easily overowed  Lets see, before going to 
class,. Id better look over my 6.004 notes but 
Ill need to nd my 
backpack rst that means Ill need to nd the car meaning, Ill need to  
remember where I parked 
it maybe it would help if I could remember where I was last night um, I 
forget, what was I going 
to do... 
Lab 4 due tonight! 
modied 3/19/09 12:08 Stacks&amp;Procedures   2  6.004  Spring 2009 3/19/09Where we left things last week 
    int n = 20; 
    int r = 1; 
    while (n&gt;0) { 
        r = r*n; 
        n = n-1; 
    } int fact(int n) {
    return r; 
}
fact(4);Procedures &amp; Functions 
- Reusable code fragments 
   that are called  as needed 
- Single named entry point 
- Upon completion control 
   is transferred back to 
caller - Parameterizable 
- Local state (variables) 
Stacks&amp;Procedures   3  6.004  Spring 2009 3/19/09Procedure Linkage: First Try 
int fact(int n) 
{
    if (n&gt;0) 
        return n*fact(n-1);  
    else 
        return 1; 
}
fact(4);fact(4) = 4*fact(3) 
fact(3) = 3*fact(2) fact(2) = 2*fact(1) 
fact(1) = 1*fact(0) 
fact(0) = 1 Oh no, not recursion! Didnt we get  
enough of that in 6.001? 
Proposed convention: 
/.notdef.g0001 pass arg in R1 
/.notdef.g0001 pass return addr in R28 
/.notdef.g0001 return result in R0 
/.notdef.g0001 questions: 
/.notdef.g0001 nargs &gt; 1? 
/.notdef.g0001 preserve regs? Lets just use some 
registers.  Weve got 
plenty 
Stacks&amp;Procedures   4  6.004  Spring 2009 3/19/09Procedure Linkage: First Try 
int fact(int n) 
{
    if (n&gt;0) 
        return n*fact(n-1);  
    else 
        return 1; 
}
fact(3);fact:
CMPLEC(r1,0,r0)
BT(r0,else)
MOVE(r1,r2) | save n SUBC(r2,1,r1)BR(fact,r28)
MUL(r0,r2,r0)
BR(rtn)
else: CMOVE(1,r0) rtn: JMP(r28,r31)
main: CMOVE(3,r1)
BR(fact,r28)
HALT()
Proposed convention: 
/.notdef.g0001 pass arg in R1 
/.notdef.g0001 pass return addr in R28 
/.notdef.g0001 return result in R0 
/.notdef.g0001 questions: 
/.notdef.g0001 nargs &gt; 1? 
/.notdef.g0001 preserve regs? 
Need: O(n) storage locations!</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Stacks&amp;Procedures   9  6.004  Spring 2009 3/19/09Stack Management Macros 
PUSH(RX) :  push Reg[x] onto stack 
Reg[SP] ==Reg[SP] + 4; 
Mem[Reg[SP]-4] = Reg[x] 
POP(RX) : pop the value on the top of the stack into Reg[x] 
       Reg[x] ==Mem[Reg[SP]-4] 
 Reg[SP] = Reg[SP] - 4; 
ALLOCATE(k) : reserve k WORDS of stack 
   Reg[SP] == Reg[SP] + 4*k 
DEALLOCATE(k) : release k WORDS of stack 
   Reg[SP] == Reg[SP] - 4*k 
ADDC(R29, 4, R29) 
ST(RX,-4,R29)
LD(R29, -4, RX) ADDC(R29,-4,R29)
ADDC(R29,4*k,R29)
SUBC(R29,4*k,R29)Why? 
Stacks&amp;Procedures   10  6.004  Spring 2009 3/19/09Fun with Stacks 
We can squirrel away variables for later. For instance, 
the following code fragment can be inserted 
anywhere within a program. 
|
  | Argh!!! Im out of registers Scotty!! 
  | 
  PUSH(R0)   | Frees up R0 
  PUSH(R1)   | Frees up R1 
     LD(R31,dilithum_xtals, R0) 
  LD(R31,seconds_til_explosion, R1) 
suspense: SUBC(R1, 1, R1) 
  BNE(R1, suspense, R31) 
  ST(R0, warp_engines,R31) 
     POP(R1)     | Restores R1 
  POP(R0)   | Restores R0
AND Stacks can also be used to solve other problems... Data is 
popped 
o the 
stack 
in the 
opposite 
order 
that
it is
pushed on 
Stacks&amp;Procedures   11  6.004  Spring 2009 3/19/09Solving Procedure Linkage Problems 
BUT FIRST, WELL COMMIT SOME MORE REGISTERS: 
r27 = BP . Base ptr, points into stack to the local 
variables of callee 
r28 = LP . Linkage ptr, return address to caller 
r29 = SP . Stack ptr, points to 1st unused word 
PLAN: CALLER puts args on stack, calls via something like 
BR(CALLEE, LP) 
leaving return address in LP . A reminder of our storage needs: 
1) We need a way to pass arguments  into procedures 
2) Procedures need their own LOCAL variables
3) Procedures need to call other procedures
4) Procedures might call themselves  (Recursion) 
Stacks&amp;Procedures   12  6.004  Spring 2009 3/19/09args Stack frames as activation records 
The CALLEE will use the 
stack for all of the 
following storage 
needs: 
1.saving the RETURN 
ADDRESS back to the 
caller 
2.saving the CALLERs 
base ptr 
3.Creating its own local/
temp variables
In theory its possible to use SP to access stack 
frame, but osets will change due to PUSHs 
and POPs.  For convenience we use BP so we can 
use constant osets to nd, e.g., the rst 
argument. unused
space Am I the Caller 
or Callee? callee 
pushes caller 
pushes 
SP old &lt;LP&gt; 
SP old &lt;BP&gt; 
SP SP , BP locals 
...
temps 
SPBP
 /.notdef.g0001
/.notdef.g0001
/.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Stacks&amp;Procedures   13  6.004  Spring 2009 3/19/09Stack Frame Details 
The CALLER passes arguments 
to the CALLEE on the stack in REVERSE order 
F(1,2,3,4) is translated to: 
ADDC(R31,4,R0)
PUSH(R0)ADDC(R31,3,R0)
PUSH(R0)ADDC(R31,2,R0)PUSH(R0)ADDC(R31,1,R0)PUSH(R0)BEQ(R31, F, LP)
Why push args  
in REVERSE order???  (callers 
return 
PC) old &lt;LP&gt; 
BParg 0 
SPunusedold &lt;BP&gt; arg n-1 old old &lt;BP&gt; old old &lt;LP&gt; 
Callers Local 0 ...
...
local 0 
local 1 ...
temps CALLERS 
FRAME
CALLEES 
FRAME
Stacks&amp;Procedures   14  6.004  Spring 2009 3/19/09Order of Arguments 
1) It allows the BP to serve double duties 
    when accessing the local frame 
To access kth local variable (k /.notdef.g0001/.notdef.g0001 0) 
LD(BP, k*4, rx)
or
ST(rx, k*4, BP)
To access jth argument ( j /.notdef.g0001/.notdef.g0001 0): 
LD(BP, -4*(j+3), rx)
or
ST(rx, -4*(j+3), BP) 
2) The CALLEE can access the rst few 
arguments without knowing how many 
arguments have been passed! Why push args onto the stack in 
reverse  order? 
&lt;BP&gt;  12 
&lt;BP&gt;  8 
&lt;BP&gt;  4 &lt;BP&gt; 4*( j+3) 
&lt;BP&gt; + 4*k old &lt;LP&gt; 
BParg 0 
SPunusedold &lt;BP&gt; arg n-1 
...
...
local 0 
local k ...
temps arg j 
Stacks&amp;Procedures   15  6.004  Spring 2009 3/19/09Procedure Linkage: The Contract 
The CALLER will: 
 Push args onto stack, in reverse order. 
 Branch to callee, putting return address into LP . 
 Remove args from stack on return.
The CALLEE will: 
 P erform promised computation, leaving result in R0. 
 Branch to return address. 
 Leave stacked data intact, including stacked args. 
 Leave regs (except R0) unchanged.
Stacks&amp;Procedures   16  6.004  Spring 2009 3/19/09Procedure Linkage 
typical boilerplate templates 
Wheres the 
Deallocate?  
Calling 
Sequence      PUSH(argn) | push args, last arg first 
    ...
    PUSH(arg1)
    BEQ(R31,f, LP) | Call f. 
    DEALLOCATE(n) | Clean up! 
    ... | (fs return value in r0) 
Return 
Sequence      (pop other regs) | restore regs 
    MOVE(val, R0) | set return value 
    MOVE(BP,SP) | strip locals, etc 
    POP(BP) | restore CALLERs linkage 
    POP(LP) | (the return address) 
    JMP(LP,R31) | return. 
Entry 
Sequence  f:  PUSH(LP) | Save LP and BP 
    PUSH(BP) | in case we make new calls. 
    MOVE(SP,BP) | set BP=frame base 
    ALLOCATE(nlocals) | allocate locals 
    (push other regs) | preserve any regs used</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Synchronization, metastability</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec07/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>L07 - Synchronization   13  6.004  Spring 2009 2/26/09The Metastable State:  
Why is it an inevitable risk of synchronization?  
/.notdef.g0001 Our active devices always have a xed-point voltage, VM, such that 
VIN=VM implies VOUT = VM
/.notdef.g0001 Violation of dynamic discipline puts our feedback loop at some voltage  
V0 near VM
/.notdef.g0001 The rate at which V progresses toward a stable 0 or 1 value is proportional to (V - V
M)
/.notdef.g0001 The time to settle to a stable value depends on (V0 - VM);  its 
theoretically innite for V0 = VM
/.notdef.g0001 Since theres no lower bound on (V0 - VM), theres no upper bound on 
the settling time. 
/.notdef.g0001 Noise, uncertainty complicate analysis (but dont help). 
L07 - Synchronization   14  6.004  Spring 2009 2/26/09Sketch of analysis I.  
0
1 (Synchronized) S(t)
Clock Synchronizer Assume asynchronous 0-&gt;1 
at TA, clock period CP: 
Whats the FF output voltage, 
V0,  immediately after TA?A
C
&lt; tS+tH
CPVM1. Whats the probability that the 
voltage, V0, immediately after 
TA is within /.notdef.g0003/.notdef.g0003 of VM?
) (2 ) (] [0
L HH S
MV V CPt tV V P/.notdef.g0002/.notdef.g0003+/.notdef.g0001 /.notdef.g0001/.notdef.g0002/.notdef.g0004
/.notdef.g0004V0
tA-tCP otential trouble comes when V0 is near the metastable point, VM
L07 - Synchronization   15  6.004  Spring 2009 2/26/09Sketch of analysis II.  
We can model our 
combinational 
cycle as an 
amplier with gain 
A and saturation at V
H, VLA0
1VoutVin
0R
CVH
VLVout 
Vin Slope = A 
2. For Vout near VM, Vout(t) is an 
exponential whose time constant 
reects RC/A:
3. Given interval T, we can compute a 
minimum value of /.notdef.g0003/.notdef.g0003 = |V0-VM| that will 
guarantee validity after T: Vout(t)- VM/.notdef.g0002/.notdef.g0002/.notdef.g0003/.notdef.g0003et(A-1)/RC 
/.notdef.g0002/.notdef.g0002/.notdef.g0003/.notdef.g0003et//.notdef.g0001/.notdef.g0001
/.notdef.g0003/.notdef.g0003 (T) /.notdef.g0002/.notdef.g0002 (VH  VM) e -T//.notdef.g0001/.notdef.g0001
4. Probability of metastability after T is 
computed by probability of a V0
yielding/.notdef.g0003/.notdef.g0003 (T)  PM(T) /.notdef.g0002/.notdef.g0002 P[|V0-VM| &lt; /.notdef.g0003/.notdef.g0003 (T)]  
/.notdef.g0002/.notdef.g0002 K e -T//.notdef.g0001/.notdef.g0001
L07 - Synchronization   16  6.004  Spring 2009 2/26/09Failure Probabilities vs Delay  
Making conservative assumptions about the distribution of V0 and system 
time constants, and assuming a 100 MHz clock frequency, we get results like the following: 
Average time 
Delay P(Metastable) between failures 
31 ns 3x10
-161 year 
33.2 ns 3x10-17 10 years 
100 ns 10-45 1030 years! 
[For comparision: 
Age of oldest hominid fossil:  5x106 years 
Age of earth: 5x109 years] 
Lesson: Allowing a bit of settling time is an 
easy way to avoid metastable states in 
practice!</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L07 - Synchronization   5  6.004  Spring 2009 2/26/09
The Asynchronous Arbiter:  
a classic problem  
ArbiterB
CSB:
C:at t B
at t C
B:
C:
S:tD tD&gt;t E &gt;t E
tDArbiter specications: 
/.notdef.g0001 nite tD (decision time) 
/.notdef.g0001 nite tE (allowable error) 
/.notdef.g0001 value of S at time tC+tD:
1 if tB &lt; tC  tE
0 if tB &gt; tC + tE
0, 1 otherwise 
CASE 1 CASE 2 CASE 3 UNSOLVABLE 
For NO nite value of t
E and tD is this 
spec realizable, even with reliable components! 
L07 - Synchronization   6  6.004  Spring 2009 2/26/09Violating the Forbidden Zone  
The image cannot be displayed. Your computer may not have enough memory to open the image, or the image may have been corrupted. Restart your computer, and then open the le again. If 
the red x still appears, you may have to delete the image and then insert it again.
tB-tCArbiter 
Output
1
o
(tB=tC)B
EarlierC
EarlierArbiterB
CSB:
C:at t B
at t C
Issue: Mapping the continuous  variable (tB  tC)
onto the discrete  variable S in bounded time .
With no forbidden zone,  all inputs have to be 
mapped to a valid output.  As the input 
approaches discontinuities in the mapping, it 
takes longer to determine the answer.  Given 
a particular time bound, you can nd an input that wont be mapped to a valid output 
within the allotted time. 
L07 - Synchronization   7  6.004  Spring 2009 2/26/09Unsolvable?  
that cant  be true...  
Lets just use a D Flip Flop: 
DQB:
C:at t B
at t CDECISION TIME  is TPD of op.  
ALLOWABLE ERROR is max(tSETUP , tHOLD )
Our logic: 
 TPD after TC, well have 
Q=0 i tB + tSETUP  &lt; tC
Q=1 i tC+ tHOLD  &lt; tB
Q=0 or 1 otherwise. 
Were lured by the digital 
abstraction into assuming 
that Q must be either 1 or 0.  But lets look at the input latch in the ip op when B and C change at about the same time... 
GDQ
GDQB
Cmaster slave  
L07 - Synchronization   8  6.004  Spring 2009 2/26/09The Mysterious Metastable State  
VinVoutVTC of
closed latch
VTC of feedback 
path (Vin=Vout)
Latched in 
a 0 stateLatched in 
a 1 state
Latched in  
an undefined  
stateY0
1Q
VoutVin
Recall that the latch output is the 
solution to two simultaneous 
constraints: 
1. The VTC of path thru 
MUX; and 
2. Vin = Vout
In addition to our expected stable solutions, we nd an unstable 
equilibrium in the forbidden zone called the  Metastable State</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L07 - Synchronization   9  6.004  Spring 2009 2/26/09Metastable State: Properties  
1. It corresponds to an invalid  logic level   
the switching threshold of the device. 
2. Its an unstable equilibrium; a small 
perturbation will cause it to 
accelerate toward a stable 0 or 1. 
3. It will settle to a valid 0 or 1... 
eventually. 
4. BUT  depending on how close it is to 
the Vin=Vout xed point of the device 
 it may take arbitrarily long to settle
out.
5. EVERY bistable system exhibits at 
least one metastable state! EVERY bistable system? 
Y ep, every last one. 
Coin ip?? 
Could land on edge. 
Horse race?? 
Photo nish. 
Presidential Election?? 
(Wheres this twit 
been hiding???)  
L07 - Synchronization   10  6.004  Spring 2009 2/26/09Observed Behavior:  
typical metastable symptoms  
Following a clock edge on an asynchronous input: 
We may see exponentially-distributed metastable intervals: 
Or periods of high-frequency oscillation (if the feedback path is long): CLK
D
Q
Q
L07 - Synchronization   11  6.004  Spring 2009 2/26/09Mechanical Metastability  
If we launch a ball up a hill we 
expect one of 3 possible 
outcomes:
a) Goes over 
b) Rolls back 
c) Stalls at the apex 
That last outcome is not 
stable.
- a gust of wind 
- Brownian motion 
- it doesnt take muchState A
State BMetastable State
State AState B
L07 - Synchronization   12  6.004  Spring 2009 2/26/09How do balls relate to digital logic?
Our hill is analogous to the derivative
of the VTC (Voltage Transfer 
Curve) at the metastable 
point, the derivative (slope) is 
ZERO.
Notice that the higher the gain thru 
the transition region, the steeper 
the peak of the hill... making it 
harder to get into a metastable state
We can decrease the probability of 
getting into the metastable state, but  assuming continuous 
models of physics  we cant 
eliminate the slope=0 point!VinVoutinoutVV
/.notdef.g0001/.notdef.g0001 /.notdef.g0001
/.notdef.g0001
/.notdef.g0001
/.notdef.g0001
/.notdef.g0001</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L07 - Synchronization   1  6.004  Spring 2009 2/26/09Synchronization, Metastability  
and Arbitration  
Due tonight: 
/.notdef.g0001/.notdef.g0001Lab #2 
/.notdef.g0001/.notdef.g0001Lab #1 checko meeting 
"If you can't be just,  
be arbitrary"  
- Wm Burroughs,  Naked Lunch 
- US Supreme Court 12/00 Did you vote for Bush or Gore? 
Didnt have enough time to decide. 
Well, which hole did you punch? 
Both, but not very hard... 
modied 2/23/09 09:30 L07 - Synchronization   2  6.004  Spring 2009 2/26/09The Importance of being Discrete  
Digital Values: 
Problem: Distinguishing voltages 
representing 1 from 0 
Solution: Forbidden Zone: avoid 
using similar voltages for 1 
and 0 Digital Time: 
Problem: Which transition 
happened rst? questions 
Solution: Dynamic Discipline: avoid 
asking such questions in 
close races 
VOLVILVIHVOHVOUT 
VIN
VOLVIL VIHVOHtStH
Clk
QD
tCD
tPDWe avoid possible errors by disciplines that avoid asking the tough 
questions  using a forbidden zone  in both voltage and time dimensions: 
L07 - Synchronization   3  6.004  Spring 2009 2/26/09If we follow these simple rules  
Can we guarantee that our system will always work? 
With careful design we can make sure that the dynamic 
discipline is obeyed everywhere*... D Q D Q Out In
Combinational
logicD Q Out
Combinational
logicD Q In
ClkCombinational
logic
D Q Combinational
logicD Q Combinational
logicD Q Out
Combinational
logic
* well, almost  everywhere... 
L07 - Synchronization   4  6.004  Spring 2009 2/26/09Which edge 
Came FIRST? 
The world doesnt run on our clock!  
What if each button input is 
an asynchronous 0/1 
level?   Lock B1UB00
1 01
To build a system with asynchronous inputs, we have to break the rules: 
we cannot guarantee that setup and hold time requirements are met at the 
inputs!
So, lets use a synchronizer at each input:
0
1(Unsynchronized) U(t)
(Synchronized) S(t)
Clock Synchronizer Valid except for brief periods 
following active clock edges But what 
About the 
Dynamic
Discipline?</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L07 - Synchronization   21  6.004  Spring 2009 2/26/09Modern Reconciliation:  
delay buys reliability  
D Q D Q Out
Combinational
logicD Q In
ClkA metastable state here 
will probably resolve itself 
to a valid level before it 
gets into my circuit.
And one here will almost certainly 
get resolved. 
D Q D Q Out
Combinational
logicD Q D Q In
ClkSynchronizers, extra ip 
ops between the asynchronous input and 
your logic, are the best 
insurance against metastable states. 
The higher the clock rate, 
the more synchronizers 
should be considered. 
SETTLING TIME  
Cures  
Metastability!  
L07 - Synchronization   22  6.004  Spring 2009 2/26/09Things we CANT build  
1. Bounded-time Asynchronous Arbiter: 
S valid after tpd following (either) edge ArbiterB
CSS=0 i B edge rst, 1 i C edge rst, 
1 or 0 if nearly coincident 
DQAsynchronous 
InputOutput = D at active clock edge, either 1 or 0 i D invalid near clock edge 
Q valid after tpd following active clock edge 2. Bounded-time Synchronizer: 
&gt; 3.14159 ? Continuous 
Variable 3. Bounded-time Analog Comparator: 
0 or 1, 
nite tpd 
L07 - Synchronization   23  6.004  Spring 2009 2/26/09Some things we CAN build  
1. Unbounded-time Asynchronous Arbiter: 
S valid when Done=1; unbounded time. 
ArbiterB
CSS=0 i B edge rst, 1 i C edge rst, 1 or 0 if nearly coincident Done 
2. Unbounded-time Analog Comparator: 
&gt; 3.14159 ? Continuous 
Variable 0 or 1
Done After arbitrary interval, 
decides whether input at 
time of last active clock 
edge was above/below 
threshold. 
3. Bounded-time combinational logic: 
Produce an output transition within a xed 
propagation delay of rst (or second) transition on the input. 
L07 - Synchronization   24  6.004  Spring 2009 2/26/09Interesting Special Case Hacks  
For systems with unsynchronized clocks 
of same nominal frequency .  Data goes to 
two ops clocked a half period apart; one 
output is bound to be clean.  An observer 
circuit monitors the slowly-varying phase relationship between the clocks, and 
selects the clean output via a lenient MUX. CLK2Data1 
delayData2 
CLK1
CLK2Mesochronous communication: 
Constraints on clock timing  periodicity, 
etc  can often be used to hide time 
overhead associated with synchronization. Exploits fact that, given 2 periodic 
clocks, close calls are predictable .
Predicts, and solves in advance, 
arbitration problems (thus eliminating 
cost of delay) Predictive periodic synchronization: 
CLK1Data1 
CLK2Data2</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L07 - Synchronization   17  6.004  Spring 2009 2/26/09The Metastable State:  
a brief history  
Antiquity: Early recognition 
Denial: Early 70s 
Folk Cures: 70s-80s 
Reconciliation: 80s-90s Buridens Ass, and other fables 
Widespread disbelief.  Early analyses 
documenting inevitability of problem 
rejected by skeptical journal editors. 
P opular pastime: Concoct a Cure for 
the problem of synchronization failure.  
Commercial synchronizer products. 
Acceptance of the reality: 
synchronization takes time.  Interesting 
special case solutions. 
L07 - Synchronization   18  6.004  Spring 2009 2/26/09Ancient Metastability  
Metastability is the occurrence of a persistent invalid 
output an unstable equilibria. 
The idea of Metastability is not new:
The Paradox of Buridans Ass 
Buridan, Jean (1300-58), French Scholastic philosopher, 
who held a theory of determinism, contending that the 
will must choose the greater good. Born in Bethune, he was educated at the University of Paris, where he studied with the English Scholastic philosopher William of Ockham (whom 
you might recall from his razor business). After his studies were 
completed, he was appointed professor of philosophy, and later rector, at the same university. Buridan is traditionally, but probably incorrectly, associated with a philosophical dilemma of moral choice called "Buridan's ass. 
In the problem an ass starves to death between two alluring 
bundles of hay because it does not have the will to decide which one to eat.
L07 - Synchronization   19  6.004  Spring 2009 2/26/09Folk Cures  
 the perpetual motion machine of digital logic  
FF "FIXER"
delayAsync 
Input"Clean" 
OutputBad Idea # 1: Detect metastable state &amp; Fix 
The
image
can
not
The
image
can
not
The
image
can
notvalid 
"0"valid 
"1"Bad Idea #2: Dene the problem away by making metastable point a valid output Bug: detecting metastability is 
itself subject to metastable 
states, i.e., the xer will fail to 
resolve the problem in bounded 
time. 
Bug: the memory element will ip  
some valid 0 inputs to 1 
after a while. 
Many other bad ideas  involving noise injection, 
strange analog circuitry,  have been 
proposed. 
L07 - Synchronization   20  6.004  Spring 2009 2/26/09Theres no easy solution
 so, embrace the confusion.  
"Metastable States": 
 Inescapable consequence  of bistable systems 
 Eventually a metastable state will resolve itself to valid binary 
level.
 However, the recovery time is UNBOUNDED ... but inuenced by 
parameters (gain, noise, etc) 
 Probability of a metastable state falls o EXPONENTIALLY with 
time -- modest delay after state change can make it very unlikely. 
Our STRATEGY; since we cant eliminate metastability, we will do the  
best we can to keep it from contaminating our designs</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>L07 - Synchronization   25  6.004  Spring 2009 2/26/09Every-day Metastability - I  
BitBucketCafe
The image 
cannot be displayed.
Your
computermay not have
enough
memoryto open the image, Ben Bitdiddle tries the famous 
6.004 defense: 
Ben leaves the Bit Bucket Caf 
and approaches fork in the road.  He hits the barrier in the middle of the fork, later explaining I cant be expected 
to decide which fork to take in bounded time!. 
Is the accident Bens fault? 
Y es; he should have stopped until his decision 
was made.  
Judge R. B. Trator, MIT 86  
L07 - Synchronization   26  6.004  Spring 2009 2/26/09Every-day Metastability - II  
GIVEN :
/.notdef.g0001Normal trac light: 
/.notdef.g0001    GREEN, YELLOW, RED sequence 
/.notdef.g000155 MPH Speed Limit 
/.notdef.g0001Suciently long YELLOW, GREEN periods 
/.notdef.g0001Analog POSITION input 
/.notdef.g0001digital RED, YELLOW, GREEN inputs 
/.notdef.g0001digital GO output 
Can one reliably obey.... 
PLAUSIBLE STRATEGIES :
A. Move at 55.  At calculated distance D from light, sample color (using an 
unbounded-time synchronizer).  GO ONLY WHEN stable GREEN. 
B. Stop 1  foot before intersection.  On positive GREEN transition, gun it. /.notdef.g0001LAW #1: DONT CROSS LINE while light is RED. 
GO = GREEN 
/.notdef.g0001LAW #2: DONT BE IN INTERSECTION while light is RED. 
L07 - Synchronization   27  6.004  Spring 2009 2/26/09
Summary  
As a system designer 
Avoid the problem altogether, where possible 
/.notdef.g0001Use single clock, obey dynamic discipline 
/.notdef.g0001Avoid state.  Combinational logic has no metastable 
states!
Delay after sampling asynchronous inputs: a 
fundamental cost of synchronizationThe most dicult decisions 
are those that matter the least. Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Wrapup lecture</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec25/</lecture_pdf_url>
      <lectureno>25</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>L25  Wrapup Lecture   5  6.004  Spring 2009 5/12/09Things to look forward to 
6.004 is only an appetizer! 
Algorithms
Arithmetic 
Signal Processing 
Language implementation 
Processors 
Superscalars 
Deep pipelines 
Multicores 
Systems Software 
Storage 
Virtual Machines 
Networking 
Languages &amp; Models 
Python/Java/Ruby/ 
Objects/Streams/Aspects 
Networking 
Tools 
Design Languages 
FPGA prototyping 
Timing Analyzers 
L25  Wrapup Lecture   6  6.004  Spring 2009 5/12/09Verilog example: Beta Register File 
// 2-read, 1-write 32-location register file
module regfile(ra1,rd1,ra2,rd2,clk,werf,wa,wd);
input [4:0] ra1; // address for read port 1 (Reg[RA]) 
output [31:0] rd1; // read data for port 1
input [4:0] ra2; // address for read port 2 (Reg[RB], Reg[RC] for ST) 
output [31:0] rd2; // read data for port 2
input clk;input werf; // write enable, active high
input [4:0] wa; // address for write port (Reg[RC])
input [31:0] wd; // write data 
reg [31:0] registers[31:0]; // the register file itself (local)
  // read paths are combinational, check for reads from R31 
assign rd1 = (ra1 == 31) ? 0 : registers[ra1];
assign rd2 = (ra2 == 31) ? 0 : registers[ra2];
  // write port is active only when WERF is asserted 
always @(posedge  clk)
if (werf) registers[wa] &lt;= wd;
endmodule
L25  Wrapup Lecture   7  6.004  Spring 2009 5/12/09PCmodule pc(clk,reset,pcsel,offset,jump_addr, 
          branch_addr,pc,pc_plus_4); 
input clk;
input reset; // forces PC to 0x80000000 
input [2:0] pcsel; // selects source of next PC 
input [15:0] offset; // inst[15:0] 
input [31:0] jump_addr; // from Reg[RA], used in JMP instruction 
output [31:0] branch_addr; // send to datapath for LDR instruction 
output [31:0] pc; // used as address for instruction fetch 
output [31:0] pc_plus_4; // saved in regfile during branches, JMP, traps 
reg [31:0] pc;
wire [30:0] pcinc; 
  wire [31:0] npc; 
// the Beta PC increments by 4, but wont change supervisor bit assign pcinc = pc + 4; 
assign pc_plus_4 = {pc[31],pcinc}; 
  // branch address = PC + 4 + 4*sxt(offset) 
assign branch_addr = {0,pcinc + {{13{offset[15]}},offset[15:0],2'b00}}; 
assign npc = reset ? 32'h80000000 :
               (pcsel == 0) ? {pc[31],pcinc} : // normal 
               (pcsel == 1) ? {pc[31],branch_addr[30:0]} : // branch 
               (pcsel == 2) ? {pc[31] &amp; jump_addr[31],jump_addr[30:0]} : // jump
               (pcsel == 3) ? 32'h80000004 : 32'h80000008; // illop, trap 
// pc register, pc[31] is supervisor bit and gets special treatment always @(posedge  clk) pc &lt;= npc;
endmodule
L25  Wrapup Lecture   12  6.004  Spring 2009 5/12/09The Crystal Ball 
some trends in computer evolution 
/.notdef.g0001Technology shrinks 
/.notdef.g000130% linear shrink/generation 
/.notdef.g0001Cheaper, faster, lower power 
/.notdef.g0001Multicores (SMP , Tiled NUMA, ) 
/.notdef.g0001Superscalar/SMT pipelines 
/.notdef.g0001P ower management 
/.notdef.g0001Recongurable processing/interconnect 
/.notdef.g0001VLIW, SIMD inuences</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms
. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L25  Wrapup Lecture   21  6.004  Spring 2009 5/12/09The Dilemma 
/.notdef.g0001We have no clue how to build a practical quantum computer 
/.notdef.g0001Currently, quantum computing is merely a fantasy of 
theoreticians
/.notdef.g0001What other problems can a quantum computer solve more 
eciently than a classic computer? 
A SUBTLE Reminder:  
Turing, Church, P ost,  
Kleene, and Markov really invented most 
of modern day computer 
science long before a practical implementation. 
L25  Wrapup Lecture   22  6.004  Spring 2009 5/12/096004: The Big Lesson 
Engineering Abstractions: 
/.notdef.g0001Understanding of their technical 
underpinnings
/.notdef.g0001Respect for their value 
/.notdef.g0001Techniques for using them 
But, most importantly: 
/.notdef.g0001The self assurance to discard them, in 
favor of new abstractions! 
Good engineers use abstractions; 
GREAT engineers create  them! Y ouve built, debugged, understood a complex 
computer from FETs to OS what have you 
learned? 
L25  Wrapup Lecture   23  6.004  Spring 2009 5/12/09THE END! 
P ens, pencils, paper they attempt to solve problems that teachers set forth. The only problem with Haiku is that you just get started and then</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L25  Wrapup Lecture   13  6.004  Spring 2009 5/12/092010 Architecture? 
I/O
Embedded DRAM Embedded DRAM 
O-chip
DRAMTiles Tiled (VLIW/recongurable/vector) machines 
become popular in systems with resource constraints (hardware cost, low power, hard 
real time) 
/.notdef.g0001 10 GHz processor clock 
/.notdef.g0001 5 GHz network clock 
/.notdef.g0001 128 processing tiles 
/.notdef.g0001 &gt;5 TFLOPS peak (32b FLOPS) 
/.notdef.g0001 &gt;40 TOPS peak (8b OPS) 
/.notdef.g0001 1GB on-chip DRAM 
/.notdef.g0001 100 GB/s o-chip DRAM interface 
/.notdef.g0001 100 GB/s I/O 
/.notdef.g0001 25x25mm
2 in 0.045 m CMOS Giant uniproc
essors (maybe with SMT) remain popular in markets 
where software is the main expense. 
L25  Wrapup Lecture   14  6.004  Spring 2009 5/12/09Thinking Outside the Box 
Will computers always look 
and operate the way 
computers do today? 
Some things to question: 
/.notdef.g0001Well-dened system state 
/.notdef.g0001Programming
/.notdef.g0001Silicon-based logic 
/.notdef.g0001Logic at all 
Si 
Boolean 
Logic 
 MOSFET
transistors 
Synchronous 
Clocked 
Systems 
Von Neumann 
Architectures 
L25  Wrapup Lecture   15  6.004  Spring 2009Our programming hangup 
Our machines slavishly execute 
sequences of instructions. Does a 
cerebellum?  A society? A beehive? 
An MIT student? Is there an engineering 
discipline for building goal-
oriented systems from 
goal-oriented 
components? 
Islearning  an alternative to 
programming? 
Adaptive 
Memory PUNISH
L25  Wrapup Lecture   16  6.004  Spring 2009 5/12/09Wet Computers 
1) The most reliable, sustainable, ecient,
and smartest??? machines that we 
know of are biological 
2) Fined tuned through millions of years of 
evolution
3) The assembly, repair, and operation 
instructions for multi-billion element 
machines are digitally encoded in a single molecule 
4) We are just beginning to understand the 
gates and the machine language I wonder if 
 2289384-1
is prime?</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L25  Wrapup Lecture   1  6.004  Spring 2009 5/12/09Computer Architecture: 
Exciting Times Ahead! 
Prediction is very 
dicult, especially about the future.  
               -- Neils BohrThe best way to predict the future is to invent it.                 -- 
Alan Kay
modied  5/4/09 10:17 L25  Wrapup Lecture   2  6.004  Spring 2009 5/12/09Youve mastered a lot 
Fets &amp; voltages 
Logic gates 
Combinational 
logic circuits 
Combinational contract: 
/.notdef.g0001/.notdef.g0001 discrete-valued inputs 
/.notdef.g0001/.notdef.g0001 complete in/out spec. 
/.notdef.g0001/.notdef.g0001 static discipline Acy
clic connections 
Summary specication 
Design: 
/.notdef.g0001/.notdef.g0001 sum-of-products 
/.notdef.g0001/.notdef.g0001 simplication 
/.notdef.g0001/.notdef.g0001 muxes, ROMs, PLAs Stor
age &amp; state 
Dynamic discipline 
Finite-state machines Metastability Throughput &amp; latency Pipelining Sequential logic 
L25  Wrapup Lecture   3  6.004  Spring 2009 5/12/09 a WHOLE lot  
Sequential logic &lt;PC&gt;+4+C*4
ASEL 0 1
Data Memory 
RDWD
AdrR/W
W DS EL01 2WA 
Rc &lt;25:21&gt; 01XP PCSEL
PCJT
+4Instruction
MemoryA
D
Rb: &lt;15:11&gt; Ra &lt;20:16&gt; 
RA2SELRc &lt;25:21&gt; 
+
Register
FileRA1 RA2
RD1 RD2
BSEL 0 1C: &lt;15:0&gt; 
C: &lt;15:0&gt; 
sign-extended Z
ALUABJTWA WD
WEC: &lt;15:0&gt; &lt;&lt; 2 
sign-extended 
ALUFN Control LogicZ
ASEL
BSELPCSEL
RA2SEL
WDSEL
ALUFN 
Wr 
&lt;PC&gt;+40 1
Wr 0 1 2 3 4XAdr ILL
OP
WASEL 
WASEL IRQWERF
WERF00
CPU Architecture 
Computing Theory 
Instruction Set Architectures Beta implementation Pipelined Beta Software conventions Memory architectures ?
Interconnect Virtual machines Interprocess communication Operating Systems Real time, Interrupts Parallel Processing Computer Systems MEM
MEM
CPU
DISK  I/OI/
OL2 $ Graphics 
I/O
AGP bus 
L25  Wrapup Lecture   4  6.004  Spring 2009 5/12/096.035 (U,     ) 
Computer 
Language
 Engineering 
Whats next?
Some follow-on options
Software Hardware 6.374 (G,    ) 
Analysis and Design 
 of Digital 
 Integrated Circuits
6.033 (U,     ) 
Computer 
System 
 Engineering 
6.111 (U,         ) 
Introductory 
Digital Systems 
 Laboratory 
LA for 6.004 UROP
Special  
Topics  6.823 (G,     ) 
Computer 
System 
 Architecture 
6.115 (U,     ) 
Microcomputer 
Project 
Laboratory 
6.375 (U,     ) 
Complex 
Digital System 
Design</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L25  Wrapup Lecture   17  6.004  Spring 2009 5/12/09DNA Chips 
(DNA probes or microarrays) 
Leverages VLSI fabrication techniques 
(photolithography)
Use PCRs (polymerase chain reactions) to 
make an exponential number of DNA 
copies
Mechanically bind specic tagged gene 
sequences onto a patterned substrate 
Expose to bath of denatured nucleotides 
(separated and diced up pieces of DNA) 
Look for phosphorescent markers 
Medical applications are obvious, but what 
does it have to do with computation? 
Micro vials 
of a gene 
sequence Questions: 
What inputs satisfy  
f(x1,x2,xN) =1. We can reliably reslice and 
recombine (state machines?) 
L25  Wrapup Lecture   18  6.004  Spring 2009 5/12/09Can we Program Microbes? 
DNA = program 
Protein synthesis = gates? 
Can we engineer organisms 
to perform computations 
for us? 
Can we make a standard cell library oering digital 
building blocks from DNA sequences? 
This is alien thinking for biologist, but standard fare 
for systems designers F(n) = n * F(n-1); 
F(0) = 1 
L25  Wrapup Lecture   19  6.004  Spring 2009 5/12/09Computing at the limit 
At the particle level nature behaves very strangely 
Far separated particles can be entangled 
- electron spins 
- photon polarizations 
- magnetic elds 
They can be simultaneously in either state
(so long as you dont look). 
The act of looking at them (measuring, or observing them) 
forces the entangled particle into one of its states. 
Strangely enough, it is believed that we can use such 
entangled particles in computations w/o disturbing them. 
L25  Wrapup Lecture   20  6.004  Spring 2009 5/12/09Quantum Computing? 
Classic computers perform operations on strings of bits (0s 
and 1s). 
A quantum computer would be able to compute on bits 
(qubits) that can be simultaneously in either state. 
F(0&lt; x &lt; 220) = x * 371 F(?) = 197001 Classic computer: 
(with a dumb algorithm) Search through all 2
20
permutations Quantum computer: Insert 20 qubits, select 
the desired answer, then 
look back and see what 
the qubits resolved to</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Communicating processes: semaphores, synchronization, atomicity, deadlock</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec21/</lecture_pdf_url>
      <lectureno>21</lectureno>
      <slides>
        <slide>
          <slideno>7</slideno>
          <text>L21  Processes &amp; Synchronization   25  6.004  Spring 2009 4/28/09Summary
Communication among asynchronous processes requires 
synchronization.
/.notdef.g0001Precedence constraints: a partial ordering among operations 
/.notdef.g0001Semaphores as a mechanism for enforcing precedence 
constraints
/.notdef.g0001Mutual exclusion (critical sections, atomic transactions) as a 
common compound precedence constraint 
/.notdef.g0001Solving Mutual Exclusion via binary semaphores 
/.notdef.g0001Synchronization serializes  operations, limits parallel execution. 
Many alternative synchronization mechanisms exist! 
Deadlocks:
/.notdef.g0001Consequence of undisciplined use of synchronization mechanism 
/.notdef.g0001Can be avoided in special cases, detected and corrected in others.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L21  Processes &amp; Synchronization   5  6.004  Spring 2009 4/28/09Example: Bounded Buer Problem 
send(char c) 
{
   buf[in] = c; 
   in = (in+1)% N; }char rcv() {  char c; 
   c = buf[out]; 
   out = (out+1)% N;    return c; 
}PRODUCER: CONSUMER: char buf[N];          /* The buffer */ int in=0, out=0; SHARED MEMORY: 
Problem:  Doesnt enforce  precedence  constraints 
    (e.g. rcv( ) could be invoked prior to any send() )
L21  Processes &amp; Synchronization   6  6.004  Spring 2009 4/28/09Semaphores (Dijkstra) 
Programming construct for synchronization: 
/.notdef.g0001NEW DATA TYPE: semaphore,  integer-valued 
semaphore s = K; /* initialize s to K */
/.notdef.g0001NEW OPERATIONS (dened on semaphores): 
/.notdef.g0001wait(semaphore s) 
stall current process if (s &lt;= 0), otherwise s = s  1 
/.notdef.g0001signal(semaphore s) s = s + 1, (can have side eect of letting other processes proceed) 
/.notdef.g0001SEMANTIC GUARANTEE: A semaphore s initialized to K 
enforces the constraint: 
wait(s)i+K signal(s)iThis is a precedence 
relationship,  
meaning that the (i+K)th
call to wait  
cannot proceed before 
the  
ith call to  
signal completes.  Often you will see  
P(s) used for wait(s)  
and
V(s) used for signal(s)! 
P = proberen(test) or 
pakken(grab) 
 V= verhogen(increase) 
L21  Processes &amp; Synchronization   7  6.004  Spring 2009 4/28/09Semaphores for Resource Allocation 
ABSTRACT PROBLEM:
  POOL  of  K  resources
  Many  processes,  each  needs  resource  for  occasional 
    uninterrupted  periods   MUST  guarantee  that  at  most  K resources are in use at any time.
Semaphore Solution: 
In shared memory: 
  semaphore s = K;  /* K resources  */ 
In each process:
  ... 
  wait(s);    /* Allocate one       */ 
  ...         /* use it for a while */ 
  signal(s);  /* return it to pool  */ 
  ... 
Invariant: Semaphore value = number of resources left in pool 
L21  Processes &amp; Synchronization   8  6.004  Spring 2009 4/28/09Bounded Buer Problem 
w/Semaphores
send(char c) {
   buf[in] = c; 
   in = (in+1)%N;    signal(chars); 
}char rcv() 
{  char c; 
   wait(chars); 
   c = buf[out];    out = (out+1)%N; 
   return c; 
 } PRODUCER: CONSUMER: char buf[N];          /* The buffer */ 
int in=0, out=0; semaphore chars=0; SHARED MEMORY: 
RESOURCE managed by semaphore:  Characters in FIFO. 
DOES  IT  WORK?</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L21  Processes &amp; Synchronization   17  6.004  Spring 2009 4/28/09Semaphore Implementations 
Semaphore implementation must address a basic arbitration problem: 
how to choose among simultaneously waiting processes when a signal 
occurs.  This involves some basic atomicity assumption in the 
implementation technology. 
Approaches:
/.notdef.g0001SVC implementation, using atomicity of kernel handlers.  Works in 
timeshared processor sharing a single uninterruptable kernel. 
/.notdef.g0001Implementation by a special instruction (e.g. test and set), using 
atomicity of single instruction execution.  Works with shared-bus 
multiprocessors supporting atomic read-modify-write bus 
transactions.
/.notdef.g0001Implementation using atomicity of individual read or write operations.
Complex, clever, 2-phase scheme devised by Dijkstra.  Unused in 
practice.
Bootstrapping: A simple lock (binary semaphore) allows easy 
implementation of full semaphore support. 
L21  Processes &amp; Synchronization   18  6.004  Spring 2009 4/28/09Semaphores as Supervisor Call 
wait_h( ) 
{
int *addr; 
addr = User.Regs[R0];    /* get arg */ 
if (*addr &lt;= 0) { 
    User.Regs[XP]  = User.Regs[XP]  4; 
    sleep(addr); 
} else 
    *addr = *addr - 1; 
}
signal_h( ) 
{
int *addr; 
addr = User.Regs[R0];    /* get arg */ 
*addr = *addr + 1; 
wakeup(addr);
}Calling sequence: 

|| put address of lock 
|| into R0 
CMOVE(lock, R0) 
SVC(WAIT)
SVC call is not interruptible 
since it is executed in 
supervisory mode. 
L21  Processes &amp; Synchronization   19  6.004  Spring 2009 4/28/09Atomicity 
Guaranteed, e.g.  by 
Bus protocols H/W support for Semaphores 
TCLR(RA, literal, RC) test and clear location 
PC/.notdef.g0002/.notdef.g0002 PC + 4
EA/.notdef.g0002/.notdef.g0002 Reg[Ra] + literal 
Reg[Rc] /.notdef.g0002/.notdef.g0002 MEM[EA] 
MEM[EA] /.notdef.g0002/.notdef.g0002 0 
Executed ATOMICALLY (cannot be interrupted) 
Can easily implement mutual exclusion using binary semaphore 
wait: TCLR(R31, lock, R0) 
BEQ(R0,wait)
 critical section  
CMOVE(1,R0)
ST(R0, lock, R31) wait(lock) 
signal(lock) 
L21  Processes &amp; Synchronization   20  6.004  Spring 2009 4/28/09Synchronization: The Dark Side 
The indiscriminate use of synchronization constraints can
introduce its own set of problems, particularly when a 
process requires access to more than one 
protected resource. 
Transfer(int account1, int account2, int amount) 
{
wait(lock[account1]);
wait(lock[account2]);
balance[account1] = balance[account1] - amount; 
balance[account2] = balance[account2] + amount; 
signal(lock[account2]);
signal(lock[account1]);
}
Transfer(6004, 6001, 50) Transfer(6001, 6004, 50) 
DEAD- 
LOCK!</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L21  Processes &amp; Synchronization   9  6.004  Spring 2009 4/28/09Flow Control Problems 
Q: What  keeps  PRODUCER  from  putting  N+1 characters
into  the  N-character  buer?P CN-character  
FIFO buer  
rcvi sendi+NWHAT we still need: A:  Nothing. 
sendi rcviWHAT weve got thus far: Result:  OVERFLOW.  Randomness. Havoc.  Smoke.  Pain.  Suering.
    Ds and Fs in MIT courses.
L21  Processes &amp; Synchronization   10  6.004  Spring 2009 4/28/09Bounded Buer Problem w/^Semaphores
RESOURCEs managed by semaphore:  Characters in FIFO, Spaces in FIFO send(char c) 
{
   wait(space); 
   buf[in] = c;    in = (in+1)%N; 
   signal(chars); 
}char rcv() {
   char c; 
   wait(chars);    c = buf[out]; 
   out = (out+1)%N; 
   signal(space); 
   return c; 
}PRODUCER: CONSUMER: char buf[N];          /* The buffer */ 
int in=0, out=0; semaphore chars=0, space=N; SHARED MEMORY: 
more 
WORKS with single producer, consumer.   But what about 
L21  Processes &amp; Synchronization   11  6.004  Spring 2009 4/28/09Simultaneous Transactions 
Suppose you and your friend visit 
the ATM at exactly the same time, and remove $50 from your 
account. What happens? Debit(int account, int amount) 
{
   t = balance[account]; 
   balance[account] = t  amount; 
}
What is supposed  to happen? 
Debit(6004, 50) Debit(6004, 50) Process # 1 Process #2 
LD(R10, balance, R0) 
SUB(R0, R1, R0) 
ST(R0, balance, R10) 

LD(R10, balance, R0) 
SUB(R0, R1, R0) ST(R0, balance, R10) 
NET:  Y ou have $100, and your bank 
balance is $100 less. 
L21  Processes &amp; Synchronization   12  6.004  Spring 2009 4/28/09But, what if 
Process # 1 Process #2 
LD(R10, balance, R0) 

LD(R10, balance, R0) 
SUB(R0, R1, R0) ST(R0, balance, R10) 

SUB(R0, R1, R0) 
ST(R0, balance, R10) 

NET: You have $100 and your bank 
balance is $50 less! We need to be careful when writing 
concurrent programs. In particular, 
when modifying shared data. 
For certain code segments, called 
CRITICAL SECTIONS, we would like to assure that no two executions 
overlap.
This constraint is called
      MUTUAL EXCLUSION. 
Solution: embed critical sections in 
wrappers (e.g., transactions) 
that guarantee their atomicity
, i.e. 
make them appear to be single, 
instantaneous operations.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L21  Processes &amp; Synchronization   13  6.004  Spring 2009 4/28/09Semaphores for Mutual Exclusion 

Debit(int account, int amount) {
t = balance[account]; 
balance[account] = t  amount; 
}
RESOURCE managed by lock semaphore:  Access to critical section 
ISSUES:
Granularity of lock 
1 lock for whole balance database? 1 lock per account? 
1 lock for all accounts ending in 004? 
Implementation of wait() and signal() functions 
/.notdef.g0003/.notdef.g0003precedes /.notdef.g0004/.notdef.g0004/.notdef.g0001/.notdef.g0001
or
/.notdef.g0004/.notdef.g0001 precedes /.notdef.g0003/.notdef.g0003
(i.e., they dont overlap) 
/.notdef.g0003/.notdef.g0003/.notdef.g0001/.notdef.g0001/.notdef.g0004/.notdef.g0004/.notdef.g0001/.notdef.g0001
signal(lock);  /* Finished with lock */ semaphore lock = 1; 
wait(lock);     /* Wait for exclusive access */ 
L21  Processes &amp; Synchronization   14  6.004  Spring 2009 4/28/09Producer/Consumer Atomicity Problems 
Consider multiple PRODUCER processes: 
P1CN-character  
FIFO buer  P2
...
buf[in] = c; 
in = (in+1) % N; 
......
buf[in] = c; 
in = (in+1) % N; 
...P1P2
BUG: Producers interfere with each other. 
L21  Processes &amp; Synchronization   15  6.004  Spring 2009 4/28/09Bounded Buer Problem w/^Semaphores
send(char c) 
{
   wait(space); 
   wait(mutex);    buf[in] = c; 
   in = (in+1)%N; 
   signal(mutex); 
   signal(chars); 
}char rcv() {  char c; 
   wait(chars); 
   wait(mutex);    c = buf[out]; 
   out = (out+1)%N; 
   signal(mutex); 
   signal(space); 
   return c;  } PRODUCER: CONSUMER: char buf[N];          /* The buffer */ 
int in=0, out=0; 
semaphore chars=0, space=N; 
semaphore mutex=1; SHARED MEMORY: 
even more 
L21  Processes &amp; Synchronization   16  6.004  Spring 2009 4/28/09The Power of Semaphores 
send(char c) {
   wait(space); 
   wait(mutex)    buf[in] = c; 
   in = (in+1)%N; 
   signal(mutex); 
   signal(chars); 
}char rcv() {  char c; 
   wait(chars); 
   wait(mutex);    c = buf[out]; 
   out = (out+1)%N; 
   signal(mutex); 
   signal(space); 
   return c;  } PRODUCER: CONSUMER: char buf[N];          /* The buffer */ 
int in=0, out=0; 
semaphore chars=0, space=N; 
semaphore mutex=1; SHARED MEMORY: 
A single 
synchronization primitive that enforces both: 
Precedence relationships: 
       sendi rcvi
rcvi sendi+N
Mutual-exclusionrelationships:      protect variables
in and out</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L21  Processes &amp; Synchronization   21  6.004  Spring 2009 4/28/09Famous Toy Problem:
Dining Philosophers 
Take  (wait for) LEFT  stick
Take  (wait for) RIGHT  stick
EAT until sated
Replace  both  sticksPHILOSOPHER'S  ALGORITHM:Philosophers think deep thoughts, but have 
simple secular needs.  When hungry, a group 
of N philosophers will sit around a table 
with N chopsticks interspersed between 
them.  Food is served, and each philosopher 
enjoys a leisurely meal using the chopsticks 
on either side to eat (2 sticks are required, 
to avoid an ancient  Zen paradox about the 
sound of one stick feeding). 
They are exceedingly polite and patient, and 
each follows the following dining protocol: 
L21  Processes &amp; Synchronization   22  6.004  Spring 2009 4/28/09Deadlock!
CONDITIONS: 
1)Mutual exclusion - only one 
process can hold a resource 
at a given time 
2) Hold-and-wait - a process 
holds allocated resources while waiting for others  
3) No preemption - a resource 
can not be removed from a 
process holding it 
4) Circular Wait SOLUTIONS: 
 Avoidance   
-or-
Detection and Recovery No one can make progress because they are all waiting for an unavailable resource 
L21  Processes &amp; Synchronization   23  6.004  Spring 2009 4/28/09One Solution 
Take  LOW  stick
Take  HIGH  stick
EAT
Replace  both  sticks.KEY: Assign a unique number to each 
chopstick, request resources in 
globally consistent order:
New Algorithm: 
SIMPLE PROOF: 
Deadlock means that each philosopher is waiting for a resource held by  
some other philosopher  
But, the philosopher holding the highest numbered chopstick cant be 
waiting for any other philosopher (no hold-and-wait)  
Thus, there can be no deadlock 
L21  Processes &amp; Synchronization   24  6.004  Spring 2009 4/28/09Dealing with Deadlocks 
Cooperating processes: 
/.notdef.g0001 Establish a xed ordering to shared resources and require all requests to 
be made in the prescribed order 
Transfer(int account1, int account2, int amount) 
{
int a, b; 
if (account1 &gt; account2) { a = account1; b = account2; } else {a = account2; b = account1; } 
wait(lock[a]);
wait(lock[b]);
balance[account1] = balance[account1] - amount; 
balance[account2] = balance[account2] + amount; 
signal(lock[b]);
signal(lock[a]);
}
Unconstrained processes: 
- O/S discovers circular wait &amp; kills waiting process 
- Transaction model 
- Hard problem Transfer(6004, 6001, 50) Transfer(6001, 6004, 50) 123 4
5Figure by MIT OpenCourseWare.
Figure by MIT OpenCourseWare.
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L21  Processes &amp; Synchronization   1  6.004  Spring 2009 4/28/09Processes, Synchronization, &amp; Deadlock 
Lab #7 due Thursday 
modied 4/27/09 11:15 L21  Processes &amp; Synchronization   2  6.004  Spring 2009 4/28/09Interprocess Communication 
Why communicate? 
/.notdef.g0001Concurrency
/.notdef.g0001Asynchrony
/.notdef.g0001Processes as a 
programming primitive 
/.notdef.g0001Data/Event driven 
How to communicate? 
/.notdef.g0001Shared  Memory
(overlapping  contexts)... 
/.notdef.g0001Supervisor  calls 
/.notdef.g0001Synchronization instructions, 
(hardware support) Classic Example: 
    PRODUCER-CONSUMER Problem: 
Real-World Examples: 
    UNIX pipeline,
    Word processor/Printer Driver, 
    Preprocessor/Compiler, 
    Compiler/Assembler P1 P2
Code 
Stack 
Data Shared 
Data Code 
Stack 
Data PPRODUCER
CCONSUMER
loop: &lt;xxx&gt;;
send(c); 
goto loop loop: c = rcv(); 
&lt;yyy&gt;;goto loop 
L21  Processes &amp; Synchronization   3  6.004  Spring 2009 4/28/09Synchronous Communication 
PRODUCER
2&lt;xxx&gt;
3&lt;xxx&gt;&lt;xxx&gt;1
send1
send2
send3CONSUMER
&lt;yyy&gt;1rcv1
&lt;yyy&gt;2rcv2
&lt;yyy&gt;3rcv3loop: &lt;xxx&gt;;
send(c); 
goto loop loop: c = rcv(); 
&lt;yyy&gt;;goto loop 
rcvi sendi
+1
sendi rcviCant CONSUME data  
before its PRODUCED
/.notdef.g0003/.notdef.g0003/.notdef.g0001/.notdef.g0001/.notdef.g0004/.notdef.g0004/.notdef.g0001/.notdef.g0001Precedence 
Constraints: 
/.notdef.g0003/.notdef.g0003precedes /.notdef.g0004/.notdef.g0004
  Producer cant 
OVERWRITE data 
before its consumed
L21  Processes &amp; Synchronization   4  6.004  Spring 2009 4/28/09FIFO  Buering
RELAXES  interprocess
synchronization  constraints. Buering relaxes the following 
OVERWRITE constraint to:P CN-character  
FIFO buer  
&lt;xxx&gt;;
send(c0);
rcv(); //c0
&lt;yyy&gt;;&lt;xxx&gt;;
send(c1);
rcv(); //c1
&lt;yyy&gt;;&lt;xxx&gt;;
send(c2);
rcv(); //c2
&lt;yyy&gt;;&lt;xxx&gt;;
send(c3);
time c0c1c2 c0c1c2 c0c1c2 c0c1c2 c3
rcvi sendi+N
c0c1c2 c3 c0c1 c0 c0c0Read ptr 
Write ptr c0Ring Buer:</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Communication issues: busses, networks, protocols</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec20/</lecture_pdf_url>
      <lectureno>20</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>L20  Communication   17  6.004  Spring 2009 4/23/09Serial, point-to-point communications. 
Becoming standard at all levels?
ETHERNET: Broadcast technology 
/.notdef.g0001Sharing (contention) issues 
/.notdef.g0001Multiple-drop-point issues 
Evolution: P oint-to-point 
/.notdef.g000110BaseT, separate R &amp; T wires 
/.notdef.g0001Each link shared by only 2 hosts 
/.notdef.g0001Network riddled with switches, 
routers 
Serial point-to-point bus replacements 
/.notdef.g0001Multi Gbit/sec serial links! 
/.notdef.g0001PCIe, Inniband, SATA, ... 
/.notdef.g0001Packets, headers 
/.notdef.g0001Switches, routing 
/.notdef.g0001Trend: localized, superfast, serial 
networks! 
L20  Communication   18  6.004  Spring 2009 4/23/09Buses &amp; Bridges in Todays Computers 
North
Bridge
South
BridgeAGP
Bus
Memory Bus Frontside Bus
ATA Bus
PCI Bus
Serial ATA 
Firewire USB 1.1/2.0 
PCI Express x16 
(point-to-point) 
L20  Communication   19  6.004  Spring 2009 4/23/09Generalizing Buses 
Communication Topologies 
RING
/.notdef.g0002/.notdef.g0002(n) steps for random message delivery BUS
ONE  step for random message delivery (but 
only one message at a time) 1-dimensional approaches: 
Low cost networks  constant cost/node 
L20  Communication   20  6.004  Spring 2009 4/23/09Quadratic-cost Topologies 
COMPLETE GRAPH: 
Dedicated lines connecting each pair of 
communicating nodes. 
/.notdef.g0002
/.notdef.g0002(n) simultaneous 
c
ommunications. 
CROSSBAR SWITCH: 
/.notdef.g0001Switch dedicated between each pair of 
nodes 
/.notdef.g0001Each Ai can be connected to one Bj at any 
time 
/.notdef.g0001Special cases: 
/.notdef.g0001A = processors, B = memories 
/.notdef.g0001A, B same type of node 
/.notdef.g0001A, B same nodes (complete graph) Figure by MIT OpenCourseWare.Figure by MIT OpenCourseWare.
1 1 2 3 4 5
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L20  Communication   21  6.004  Spring 2009 4/23/09Mesh Topologies 
2-Dimensional Meshes 4-Neighbor 8-Neighbor 
3-D, 6-Neighbor Mesh 
Nearest-neighbor connectivity: 
    P oint-to-point interconnect 
        - minimizes delays 
        - minimizes analog eects 
    Store-and-forward 
    (some overhead associated       with communication routing) 
L20  Communication   22  6.004  Spring 2009 4/23/09Logarithmic Latency Networks 
BINARY TREE: 
Maximum path length is /.notdef.g0002/.notdef.g0002(log n) steps; 
C
ost/node constant.
HYPERCUBE (n-cube): 
Cost = /.notdef.g0002/.notdef.g0002(n log n) 
W
orst-case path length = /.notdef.g0002/.notdef.g0002(log n) 
L20  Communication   23  6.004  Spring 2009 4/23/09Communication Topologies: Latency 
Theorist's view: 
/.notdef.g0001Each point-to-point link requires one hardware unit. 
/.notdef.g0001Each point-to-point communication requires one time unit.
IS IT REAL? 
 Speed of Light: ~ 1 ns/foot (typical bus propagation: 5 ns/foot) 
 Density limits: can a node shrink forever? How about P ower, Heat, etc  ? 
OBSERVATION: Links on Tree, N-cube must grow with n; hence time/link must grow. Topology $
Complete Graph
Crossbar
1D Bus
2D Mesh
3D MeshTree
N-cube/.notdef.g0002/.notdef.g0002(n2)
/.notdef.g0002/.notdef.g0002(n )/.notdef.g0002/.notdef.g0002(n2)
/.notdef.g0002/.notdef.g0002(n )
/.notdef.g0002/.notdef.g0002(n )
/.notdef.g0002/.notdef.g0002(n )
/.notdef.g0002/.notdef.g0002( ) n log nTheoretical
Latency
/.notdef.g0002/.notdef.g0002(n3)/.notdef.g0002/.notdef.g0002(n )/.notdef.g0002/.notdef.g0002(1)/.notdef.g0002/.notdef.g0002(1)/.notdef.g0002/.notdef.g0002(1)
/.notdef.g0002/.notdef.g0002( log n )
/.notdef.g0002/.notdef.g0002( log n )/.notdef.g0001/.notdef.g0001/.notdef.g0002/.notdef.g0002(n3)
/.notdef.g0001/.notdef.g0001/.notdef.g0002/.notdef.g0002(n3)/.notdef.g0001/.notdef.g0001/.notdef.g0002/.notdef.g0002(n3)/.notdef.g0002/.notdef.g0002(n)
/.notdef.g0002/.notdef.g0002(n)Actual
Latency
L20  Communication   24  6.004  Spring 2009 4/23/09Communications Futures 
The Old Standbys:
/.notdef.g0001 In box: Backplane buses: parallel, shared data paths 
/.notdef.g0001 Arbitration, skew problems 
/.notdef.g0001 Local area: shared, single ether cable 
/.notdef.g0001 Contention, collisions 
New switched fabric tech (in &amp; out of box): 
/.notdef.g0001 Shared wires replaced by point-to-point serial 
/.notdef.g0001 P arallel data paths replaced by serial packets 
/.notdef.g0001 Communication network extended via active switches 
Topological Invariants: 
/.notdef.g0001 Asymptotic performance/cost tradeos
/.notdef.g0001 Log-latency topologies: a useful ction 
/.notdef.g0001 Best-case scaling with 3D mesh 
Watch this space! 
/.notdef.g0001 Technologies: optical, proximity, . 
/.notdef.g0001 3D packaging, interconnect 
/.notdef.g0001 ??? 
SATA 
EISA
PCIePCI
Inniband FireWire 
RDRAM
SDRAM
USB</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L20  Communication   5  6.004  Spring 2009 4/23/09Interface Standard: Backplane Bus 
Modular cards that plug into 
a common backplane: 
CPUs
Memories 
Bulk storage I/O devices S/W?The backplane provides: 
P ower 
Common system clock 
Wires for communication 
L20  Communication   6  6.004  Spring 2009 4/23/09The Dumb Bus: ISA &amp; EISA 
Original primitive approach -- 
Just take the control 
signals and data bus from
the CPU module, buer it, and call 
it a bus. ISA bus (Original IBM PC bus) - 
    Pin out and timing is nearly identical 
to the 8088 spec. 
Ah, you forget, 
Unibus, S-100,  
SWTP SS-50, 
STB, MultiBus, 
Apple 2E,  
L20  Communication   7  6.004  Spring 2009 4/23/09Smarter Processor Independent Buses 
NuBus, PCI 
Isolate basic communication 
primitives from processor 
architecture:
/.notdef.g0001Simple read/write protocols 
/.notdef.g0001Symmetric: any module can 
become Master (smart I/O, 
multiple processors, etc) 
/.notdef.g0001Support for plug &amp; play 
expansion
Goal: vendor-independent 
interface standard TERMINOLOGY  
BUS MASTER  a module that 
     initiates a bus transaction. 
     (CPU, disk controller, etc.) 
BUS SLAVE  a module that 
     responds to a bus request. 
     (Memory, I/O device, etc.) 
BUS CYCLE  The period from 
     when a transaction is      requested until it is served. PCI: initiator 
PCI:  target http://www.techfest.com/hardware/bus/pci.htm 
L20  Communication   8  6.004  Spring 2009 4/23/09Buses, Interconnect 
whats the big deal? 
Arent buses simply logic circuits with long wires? 
Wires: interconnect engineers view: 
Transmission lines. 
Finite signal propagation 
velocity. 
Space matters.
Time matters.Reality matters.Wires: circuit theorists view: 
Equipotential nodes of a 
circuit. 
Instant propagation of v, i 
over entire node. 
space abstracted out of 
design model. 
Time issues dictated by RLC 
elements; wires are 
timeless.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L20  Communication   1  6.004  Spring 2009 4/23/09Interconnect &amp; Communication 
Space, Time, &amp; stu
Quiz #4 tomorrow! 
modied 4/22/09 11:14 L20  Communication   2  6.004  Spring 2009 4/23/09Computer System Technologies 
Whats the most important part of this picture? 
Mother boards 
SDRAM LAN technology Linux Window s
XP Hard Disk 
Drives DRAM
Flash Memory 
Graphics 
Acceleration ActiveX 
Controls App
Servers 
L20  Communication   3  6.004  Spring 2009 4/23/09Technology comes &amp; goes; 
interfaces last forever 
Interfaces typically deserve more engineering attention than the 
technologies they interface 
/.notdef.g0001Abstraction: should outlast many technology generations 
/.notdef.g0001Often virtualized to extend beyond original function (e.g. memory, I/O, 
services, machines) 
/.notdef.g0001Represent more potential value to their proprietors than the technologies 
they connect. 
Interface sob stories: 
/.notdef.g0001Interface warts: Windows aux.c bug, Big/little Endian wars 
/.notdef.g0001IBM PC debacle 
... and many success stories: 
/.notdef.g0001IBM 360 Instruction set architecture; Postscript; Compact Flash; ... 
/.notdef.g0001Backplane buses 
L20  Communication   4  6.004  Spring 2009 4/23/09
CPUMEM
I/O
DISKI/OMEMAncient Times (Ad hoc connections) System Interfaces &amp; Modularity 
Late 60s (Processor-dependent Bus) 
CPU
MEMI/ODISK
I/O MEM
?
80s (Processor-independent Bus) 
CPU
CPUI/ODISK
I/O MEM
Today 
Buses Galore MEM
MEM
CPU
DISK  I/O I/O  L2/L3 $ Graphics 
I/O
AGP bus Front-side bus Back-side bus 
Bridge</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: 
http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L20  Communication   9  6.004  Spring 2009 4/23/09Bus Lines as Transmission Lines 
??? ?ANALOG ISSUES: 
/.notdef.g0001Propagation times 
/.notdef.g0001/.notdef.g0001Light travels about 1 ft / ns 
(about 7/ns in a wire) 
/.notdef.g0001Skew 
/.notdef.g0001/.notdef.g0001Dierent points along the bus see the signals at dierent times 
/.notdef.g0001Reections &amp; standing waves 
/.notdef.g0001/.notdef.g0001At each interface (places where the propagation medium changes) 
the signal may reect if the 
impedances are not matched. 
/.notdef.g0001/.notdef.g0001Make a transition on a long line  
may have to wait many transition 
times for echos to subside. 
L20  Communication   10  6.004  Spring 2009 4/23/09
Coping with Analog Issues... 
Wed like our bus to be technology independent... 
Self-timed protocols allow bus transactions to accommodate 
varying response times; 
Asynchronous protocols avoid the need to pick a (technology-
dependent) clock frequency. 
i iWIRED-OR GLITCH: what happens 
when a switch is opened??? 
COMMON COMPROMISE: Synchronous, Self-Timed protocols 
 Broadcast bus clock 
 Signals sampled at safe times * DEAL WITH: noise, clock skew (wrt signals) BUT... asynchronous protocols are vulnerable to analog-domain 
problems, like the infamous 
L20  Communication   11  6.004  Spring 2009 4/23/09
Synchronous Bus Clock Timing 
CLK
Signal 
at sourceassertion edge sample edge
Signal 
at destination
Allow for several round-trip bus delays so that ringing can die down.  
Settling
Time de-skew time 
L20  Communication   12  6.004  Spring 2009 4/23/09A Simple Bus Transaction 
CLKassertion edge sample edge
start
finish
operation
address
dataWRITE (Master)
(Master)
(Master)(Master)
(Slave)
MASTER:
   1) Chooses bus operation 
   2) Asserts an address 
   3) Waits for a slave to 
        answer. 
SLAVE: 
   1) Monitors start 
   2) Check address 
   3) If meant for me 
        a) look at bus operation         b) do operation 
        c) signal nish of cycle 
BUS:  1) Monitors start 
  2) Start count down 
  3) If no one answers before 
       counter reaches 0 then        time out</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L20  Communication   13  6.004  Spring 2009 4/23/09Multiplexed Bus:  Write Transaction 
CLK
operationstart
finish
address
/dataWRITE (Master)(Master)
(Slave)
adr (Master) data (Master)OK (Slave)We let the address and data 
buses share the same 
wires. 
Slave sends a status 
message by driving the operation control signals 
when it nishes.  P ossible 
indications: 
    - request succeeded 
    - request failed 
    - try again 
A slave can stall the write by 
waiting several cycles before  
asserting the nish signal. assertion edge sample edgeMore ecient use of shared wires 
L20  Communication   14  6.004  Spring 2009 4/23/09Multiplexed Bus: Read Transaction 
Throughput:  3+  Clocks/wordCLK
operationstart
finish
address
/dataREAD (Master)(Master)
(Slave)
adr (Master) data (Slave)OK (Slave)On reads, we allot one cycle for 
the bus to turn around (stop 
driving and begin receiving). It 
generally takes some time to 
read data anyway. 
A slave can stall the read (for 
instance if the device is slow 
compared to the bus clock) by 
waiting several clocks before 
asserting the nish signal. 
These delays are sometimes called WAIT-STATES assertion edge sample edge
Turn around time 
Turn around time 
L20  Communication   15  6.004  Spring 2009 4/23/09Bus Arbitration: Multiple Bus Masters 
ISSUES:
/.notdef.g0001Fairness - Given uniform requests, bus cycles should be divided evenly 
among modules (to each, according to their needs) 
/.notdef.g0001Bounded Wait  An  upper bound on how long a module has to wait between 
requesting and receiving a grant 
/.notdef.g0001Utilization - Arbitration scheme should allow for maximum bus 
performance
/.notdef.g0001Scalability - Fixed-cost per module (both in terms of arbitration H/W and 
arbitration time. 
STATE OF THE ART ARBITRATION:  N masters, log N time, log N wires. Request 
Grant In 
Grant Out Request 
Grant In 
Grant Out Request 
Grant In 
Grant Out Request 
Grant In 
Grant Out 
Module 1 Module 2 Module 3 Module 4 Request Daisy-Chain Arbitration
L20  Communication   16  6.004  Spring 2009 4/23/09Meanwhile, outside the box 
The Network as an interface standard
Application  
Session  
TCP  UDP  
IP  
Ethernet  Token Ring Physical Network Transport EMERGING IDEA: Protocol 
layers that isolate 
application-level interface 
from low-level physical 
devices: ETHERNET: In the mid-70s Bob 
Metcalf (at Xerox PARC, an MIT alum) devised a bus for networking 
computers together. 
/.notdef.g0001Inspired by Aloha net (radio) 
/.notdef.g0001COAX replaced ether 
/.notdef.g0001Bit-serial  (optimized for long wires) 
/.notdef.g0001Variable-length packets: 
- self-clocked data (no clock, skew!) 
- header (dest), data bits     
/.notdef.g0001Issues: sharing, contention, arbitration, 
backo</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Cache design issues</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec16/</lecture_pdf_url>
      <lectureno>16</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>L16  Cache Issues   9  6.004  Spring 2009 4/7/09Associativity
the birds-eye view
Can place caches in 2D space: 
/.notdef.g0001Total lines = # Sets * Set Size 
/.notdef.g0001# Sets = 1: Fully Associative 
/.notdef.g0001Set Size = 1: Direct Mapped 
/.notdef.g0001Set Size = N: N-way Set Associative # Sets 
Set Size /.notdef.g0001/.notdef.g0001/.notdef.g0001/.notdef.g0001/.notdef.g0001set 
L16  Cache Issues   10  6.004  Spring 2009 4/7/09ISSUE: Replacement Strategy Associativity  implies choices 
address Fully associative 
/.notdef.g0001 compare addr with each 
tag simultaneously 
/.notdef.g0001 location A can be 
 stored in any cache line address Direct-mapped 
/.notdef.g0001 compare addr with 
only one tag 
/.notdef.g0001 location A can be 
stored in exactly one 
cache line Naddress N-way set associative 
/.notdef.g0001 compare addr with N  tags  
simultaneously 
/.notdef.g0001 location A can be stored in  
exactly one set, but in any of the N cache lines 
belonging to that set 
L16  Cache Issues   11  6.004  Spring 2009 4/7/09Replacement Strategy 
LRU (Least-recently used) 
/.notdef.g0001 keeps most-recently used locations in cache 
/.notdef.g0001 need to keep ordered list of N items /.notdef.g0001 N! orderings 
/.notdef.g0001 O(log2N!) = O(N log2N) LRU bits + complex logic (0,1,2,3) Hit 2 -&gt; (2,0,1,3) 
(2,0,1,3) Hit 1 -&gt; (1,2,0,3) 
(1,2,0,3) Miss  -&gt; ( 3,1,2,0)
(3,1,2,0) Hit 3 -&gt; (3,1,2,0) 
Overhead is 
O(N log2N)
bits/set
Overhead is 
O(log2N)
bits/set
Overhead is 
O(log2N)
bits/cache! FIFO/LRR (rst-in, rst-out/least-recently replaced) 
/.notdef.g0001 cheap alternative: replace oldest item (dated by access time) 
/.notdef.g0001 within each set: keep one counter that points to victim line 
Random (select replacement line using random, uniform distribution) 
/.notdef.g0001 no pathological reference streams causing wost-case results 
/.notdef.g0001 use pseudo-random generator to get reproducible behavior; 
/.notdef.g0001 use real  randomness to prevent reverse engineering! 
L16  Cache Issues   12  6.004  Spring 2009 4/7/09Cache Benchmarking 
Suppose this loop is entered with R3=4000:
ADR:         Instruction I D
400:    LD(R3,0,R0)     400    4000+... 
404:    ADDC(R3,4,R3)   404 408:    BNE(R0,400)     408
GOAL: Given some cache design, simulate (by hand or machine) execution 
well enough to determine hit ratio. 
1. Observe that the sequence of memory locations referenced is 
400, 4000, 404, 408, 400, 4004, ... 
   We can use this simpler reference string , rather than the program, to 
simulate cache behavior. 
2. We can make our life easier in many cases by converting to word
addresses:  100, 1000, 101, 102, 100, 1001, ... 
(Word Addr = (Byte Addr)/4)</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L16  Cache Issues   5  6.004  Spring 2009 4/7/09Loop B: 
   Pgm at 
1024,  
data
at2048:   but not here! Loop A: 
   Pgm at 
1024,  
data
at 37: Works 
GREAT 
here Direct-Mapped Cache Contention 
Assume 1024-line direct-
mapped cache, 1 word/line. 
Consider tight loop, at 
steady state: 
   (assume WORD, not BYTE, 
addressing) Memory  
Address  
1024  
37  
1025  
38  
1026  
39  
1024  
...  
1024  
2048  1025  
2049  
1026  2050  1024  
...  Cache  
Line
0
37  
1
38  
2
39  
0
0
011220Hit/  
Miss  
HIT  
HIT  HIT  HIT  HIT  
HIT  HIT  
MISS  MISS  MISS  MISS  MISS  MISS  MISS  
We need some  associativity, 
But not full associativity 
L16  Cache Issues   6  6.004  Spring 2009 4/7/09Fully-assoc. vs. Direct-mapped 
Fully-associative N-line cache: 
/.notdef.g0001 N tag comparators, registers used 
for tag/data storage ($$$) 
/.notdef.g0001 Location A might be cached in any one 
of the N cache lines; no restrictions! 
/.notdef.g0001 Replacement strategy (e.g., LRU) 
   used to pick which line to use when 
   loading new word(s) into cache  
/.notdef.g0001PROBLEM: Cost! Direct-mapped N-line cache: 
/.notdef.g0001 1 tag comparator, SRAM used for 
   tag/data storage ($) 
/.notdef.g0001 Location A is cached in a specic line 
of the cache determined by its 
address; address collisions possible 
/.notdef.g0001 Replacement strategy not needed: 
each word can only be cached in one 
specic cache line 
/.notdef.g0001PROBLEM: Contention! 
L16  Cache Issues   7  6.004  Spring 2009 4/7/09Cost vs Contention 
two observations...
1. Probability of collision diminishes with cache size... 
... so lets build HUGE direct-mapped caches, using cheap SRAM! 
2. Contention mostly occurs between 
independent hot spots -- 
/.notdef.g0001Instruction fetches vs stack frame vs data 
structures, etc 
/.notdef.g0001Ability to simultaneously cache a few (2? 4? 8?) 
hot spots eliminates most collisions 
... so lets build caches that allow each location to be 
stored in some restricted set of cache lines, 
rather than in exactly one (direct mapped) or 
every line (fully associative). 
Insight: an N-way set-associative cache aords modest parallelism 
/.notdef.g0001parallel lookup (associativity): restricted to small set of N lines 
/.notdef.g0001modest parallelism deals with most contention at modest cost 
/.notdef.g0001can implement using N direct-mapped caches, running in parallel 
L16  Cache Issues   8  6.004  Spring 2009 4/7/09N-way Set-Associative Cache 
k
HITDATA TO CPUINCOMING  ADDRESS
=? =? =?t
0MEM DATAN direct-mapped caches, each with 2t lines 
Simultaneously addressed  line in each subcache constitutes a set</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L16  Cache Issues   13  6.004  Spring 2009 4/7/09Cache Simulation 
Addr   Line#   Miss? 
100     0       M 
1000     1       M 
 101     2       M 
 102     3       M 
 100     0 
1001     1       M 
 101     2 
 102     3 
 100     0 
1002     1       M 
 101     2 
 102     3 
 100     0 
1003     1       M 
 101     2 
 102     3 4-line Fully-associative/LRU 
1/4 miss Addr   Line#   Miss? 
100     0       M 
1000     0       M 
 101     1       M 
 102     2       M 
100     0       M 
1001     1       M 
101     1       M 
 102     2  100     0 
1002     2       M 
 101     1 
102     2       M 
 100     0 
1003     3       M 
 101     1 
 102     2 4-line Direct-mapped 
7/16 miss Compulsory 
MissesCollision 
Collision 
miss
L16  Cache Issues   14  6.004  Spring 2009 4/7/09Associativity: Full vs 2-way 
Addr   Line#   Miss? 
100     0       M 
1000     1       M 
 101     2       M 
 102     3       M 
 100     0 
1001     4       M 
 101     2 
 102     3 
 100     0 
1002     5       M 
 101     2 
 102     3 
 100     0 
1003     6       M 
 101     2 
 102     3 8-line Fully-associative, LRU 
1/4 miss Addr  Set#/N   Miss? 
100    0,0      M 
1000    0,1      M 
 101    1,0      M 
 102    2,0      M 
 100    0,0 
1001    1,1      M 
 101    1,0 
 102    2,0 
 100    0,0 
1002    2,1      M 
 101    1,0 
 102    2,0 
 100    0,0 
1003    3,1      M 
 101    1,0 
 102    2,0 2-way, 8-line total, LRU 
1/4 miss 
L16  Cache Issues   15  6.004  Spring 2009 4/7/0902468101214
1k 2k 4k 8k 16k 32k 64k 128k1-way
2-way
4-way
8-way
fully assoc.Associativity vs. miss rate 
Miss rate 
(%)
Cache size (bytes) Associativity H&amp;P: Figure 5.9 
/.notdef.g0001 8-way is (almost) as eective as fully-associative 
/.notdef.g0001 rule of thumb: N-line direct-mapped == N/2-line 2-way set assoc. (direct-mapped) 
L16  Cache Issues   16  6.004  Spring 2009 4/7/09Devils Advocacy Games 
Y our company uses the 
cheaper FIFO cache, 
the competition uses  
LRU.  Can you devise 
a benchmark to make 
your cache look better?
Assume 0x100 sets, 
2-way 2-way, LRU 2-way, FIFO 
Set 0 tags: 
Adr Set, # H/M Set, # H/M
100 0, 0 M 0, 0 M
1000 0, 1 M 0, 1 M
100 0, 0 H 0, 0 H
2000 0, 1 M 0, 0 M
1000 0, 0 M 0, 0 H#0 #1 #0 #1
A carefully-designed benchmark can make either  look better
P essimal case: next adr referenced is the one just replaced! 
Random  replacement makes this game harder 100 100 1000 1000 1000 2000 2000 1000 100 2000 2000 1000
BINGO!</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L16  Cache Issues   21  6.004  Spring 2009 4/7/09Write-through
ON REFERENCE TO Mem[X]: Look for X among tags... 
HIT:  X == TAG(i) , for some cache line i 
/.notdef.g0001READ: return DATA[I] 
/.notdef.g0001WRITE: change DATA[I]; Start Write to Mem[X] 
MISS: X not found in TAG of any cache line 
/.notdef.g0001REPLACEMENT SELECTION: 
/.notdef.g0002/.notdef.g0001Select some line k to hold Mem[X] 
/.notdef.g0001READ: Read Mem[X] 
/.notdef.g0004/.notdef.g0001Set TAG[k] = X, DATA[k] = Mem[X] 
/.notdef.g0001WRITE: Start Write to Mem[X] 
/.notdef.g0004/.notdef.g0001Set TAG[k] = X, DATA[k] = new Mem[X] 
L16  Cache Issues   22  6.004  Spring 2009 4/7/09Write-back
ON REFERENCE TO Mem[X]: Look for X among tags... 
HIT:  X = TAG(i) , for some cache line I 
/.notdef.g0001READ: return DATA(i) 
/.notdef.g0001WRITE: change DATA(i); Start Write to Mem[X] 
MISS: X not found in TAG of any cache line 
/.notdef.g0001REPLACEMENT SELECTION: 
/.notdef.g0002/.notdef.g0001Select some line k to hold Mem[X] 
/.notdef.g0002/.notdef.g0001Write Back: Write Data(k) to Mem[Tag[k]]
/.notdef.g0001READ: Read Mem[X] 
/.notdef.g0004/.notdef.g0001Set TAG[k] = X, DATA[k] = Mem[X] 
/.notdef.g0001WRITE: Start Write to Mem[X] 
/.notdef.g0004/.notdef.g0001Set TAG[k] = X, DATA[k] = new Mem[X] 
Is write-back worth the trouble?  Depends on (1) cost of write; (2) consistency issues. 
L16  Cache Issues   23  6.004  Spring 2009 4/7/09Write-back w/ Dirty bits 
ON REFERENCE TO Mem[X]: Look for X among tags... 
HIT:  X = TAG(i) , for some cache line I 
/.notdef.g0001READ: return DATA(i) 
/.notdef.g0001WRITE: change DATA(i); Start Write to Mem[X] D[i]=1
MISS: X not found in TAG of any cache line 
/.notdef.g0001REPLACEMENT SELECTION: 
/.notdef.g0002/.notdef.g0001Select some line k to hold Mem[X] 
/.notdef.g0002/.notdef.g0001If D[k] == 1 (Write Back) Write Data(k) to Mem[Tag[k]]
/.notdef.g0001READ: Read Mem[X]; Set TAG[k] = X, DATA[k] = Mem[X], D[k]=0
/.notdef.g0001WRITE: Start Write to Mem[X] D[k]=1
/.notdef.g0004/.notdef.g0001Set TAG[k] = X, DATA[k] = new Mem[X] MAIN
MEMORYCPUA Mem[A]
B Mem[B]TAG DATA V
110
0
0
0
0D
1
0
L16  Cache Issues   24  6.004  Spring 2009 4/7/09Caches: Summary 
Associativity:
/.notdef.g0001 Less important as size increases 
/.notdef.g0001 2-way or 4-way usually plenty for typical program clustering; BUT additional 
associativity 
/.notdef.g0001 Smooths performance curve 
/.notdef.g0001 Reduces number of select bits (well see shortly how this helps) 
/.notdef.g0001TREND: Invest in RAM, not comparators. 
Replacement Strategy:
/.notdef.g0001 BIG caches: any sane approach works well 
/.notdef.g0001 REAL randomness assuages paranoia! 
 P erformance analysis:
/.notdef.g0001Tedious hand synthesis may build intuition from simple examples, BUT 
/.notdef.g0001Computer simulation of cache behavior on REAL programs (or using REAL trace  
data) is the basis for most real-world cache design decisions.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L16  Cache Issues   17  6.004  Spring 2009 4/7/09Increasing Block Size
More Data/Tag 
A31:4 Mem[A] Mem[A+4] Mem[A+8] Mem[A+12]
= ? [3:2]
[31:4]32ADDR
DATA 
HIT
/.notdef.g0001blocks  of 2B words, on 2B word boundaries 
/.notdef.g0001 always read/write 2B word block from/to memory 
/.notdef.g0001 locality: access on word in block, others likely 
/.notdef.g0001 cost: some fetches of unaccessed words 
BIG WIN if there is a wide path to memory Enlarge each line in cache: 
TAG D0 D1 D2 D34 x 32 = 128 bits 28 bits Overhead &lt;  bit of 
Tag per bit of data  
L16  Cache Issues   18  6.004  Spring 2009 4/7/094-word block, DM Cache 
= ? [3:2]
[31:8]32ADDR
DATA 
HITTAG D0 D1 D2 D3
[7:4] Use ordinary 
(fast) static 
RAM for tag and 
data storage 
Only one comparator for entire cache! 015
16 cache lines  
/.notdef.g0001 4 bit index 
0x12 M[0x1230]  M[0x1234]  M[0x1238]  M[0x123C]  0x12 M[0x1240]  M[0x1244]  M[0x1248]  M[0x124C]  24-bit Tag! 
L16  Cache Issues   19  6.004  Spring 2009 4/7/09Valid bits 
V
1
10
0
0
0
0MAIN
MEMORYCPUA Mem[A]
B Mem[B]TAG DATA
Problem: 
/.notdef.g0001Ignoring cache lines that don't contain anything of value... e.g., on 
/.notdef.g0002/.notdef.g0001start-up 
/.notdef.g0002/.notdef.g0001Back door changes to memory (eg loading program from disk) 
Solution:  
/.notdef.g0001Extend each TAG with VALID bit .
/.notdef.g0001Valid bit must be set for cache line to HIT. 
/.notdef.g0001At power-up / reset : clear all valid bits 
/.notdef.g0001Set valid bit when cache line is rst replaced.
/.notdef.g0001Cache Control Feature:  Flush  cache by clearing all valid bits, Under 
program/external control. 
L16  Cache Issues   20  6.004  Spring 2009 4/7/09Handling of WRITES 
Observation: Most (90+%) of memory accesses are READs .  How should we 
handle writes?  Issues: 
Write-through : CPU writes are cached, but also written to main memory 
(stalling the CPU until write is completed). Memory always holds the 
truth.
Write-behind : CPU writes are cached; writes to main memory may be 
buered,  perhaps pipelined.  CPU keeps executing while writes are 
completed (in order) in the background. 
Write-back : CPU writes are cached, but not immediately written to main 
memory.  Memory contents can be stale. 
Our cache thus far uses write-through. 
Can we improve write performance?</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L16  Cache Issues   1  6.004  Spring 2009 4/7/09
Cache Issues 
Cache miss  Why the book? Lecture  
notes are faster!  
modied 4/6/09 14:12 Quiz #3 Friday! 
L16  Cache Issues   2  6.004  Spring 2009 4/7/09Basic Cache Algorithm 
ON REFERENCE TO Mem[X]:
Look for X among cache tags... 
HIT: X = TAG(i) , for some cache line i 
/.notdef.g0001READ: return DATA(i) 
/.notdef.g0001WRITE: change DATA(i); Start Write to Mem(X) 
MISS: X not found in TAG of any cache line 
/.notdef.g0001 REPLACEMENT SELECTION: 
/.notdef.g0002/.notdef.g0001Select some line k to hold Mem[X] (Allocation) 
/.notdef.g0001 READ: Read Mem[X] 
Set TAG(k)=X, DATA(K)=Mem[X] 
/.notdef.g0001 WRITE: Start Write to Mem(X) 
Set TAG(k)=X, DATA(K)= new Mem[X]MAIN
MEMORYCPU
(1!/.notdef.g0002)Tag Data 
A
BMem[A]
Mem[B]
L16  Cache Issues   3  6.004  Spring 2009 4/7/09Cache Design Issues 
Associativity  a basic tradeo between 
/.notdef.g0001Parallel Searching (expensive) vs
/.notdef.g0001Constraints on which addresses can be stored where 
Replacement Strategy: 
/.notdef.g0001OK, weve missed. Gotta add this new address/value pair to the 
cache.  What do we kick out? 
/.notdef.g0002/.notdef.g0001Least Recently Used: discard the one we havent used the longest. 
/.notdef.g0002/.notdef.g0001Plausible alternatives, (e.g. random replacement. 
Block Size: 
/.notdef.g0001Amortizing cost of tag over multiple words of data 
Write Strategy: 
/.notdef.g0001When do we write cache contents to main memory? 
L16  Cache Issues   4  6.004  Spring 2009 4/7/09Associativity

0
1
Fully Associative 
-/.notdef.g0001expensive! 
-/.notdef.g0001 exible: any 
address can be 
cached in any line Lots... 
... or NONE! 
Direct Mapped 
-/.notdef.g0001 cheap (ordinary SRAM) 
-/.notdef.g0001 contention: addresses 
compete for cache lines</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Machine language programming issues</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec11/</lecture_pdf_url>
      <lectureno>11</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>L11 - Machine Language   21  6.004  Spring 2009 3/12/09Data Structures: Structs 
struct Point 
 { int x, y; 
 } P1, P2, *p; 
...
P1.x = 157; 
...
p = &amp;P1; 
p-&gt;y = 157; Memory: 
P1: P1.x
P1.y
P2: P2.x
P2.y P1: .=.+8 
P2: .=.+8 
x=0              | Offset for x component 
y=4              | Offset for y component 
...
CMOVE(157,r0)       | r0 &lt;- 157 
ST(r0,P1+x)         | P1.x = 157 
...
&lt;p in r3&gt; ST(r0,y,r3)         | p-&gt;y = 157; might translate to: 
Address:  
VARIABLE base address + 
  CONSTANT component oset
L11 - Machine Language   22  6.004  Spring 2009 3/12/09Conditionals
C code: 
if (expr)
 { 
STUFF1
 }
else
 { 
STUFF2
 } Beta assembly: 
(compile expr  into rx) 
BF(rx, Lelse) 
(compile STUFF1 )
BR(Lendif)
Lelse:
(compile STUFF2 )
Lendif:C code: 
if (expr)
 { 
STUFF
 } Beta assembly: 
(compile expr  into rx) 
BF(rx, Lendif) 
(compile STUFF )
Lendif:There are little tricks 
that come into play when  compiling conditional 
code blocks. For 
instance, the statement: 
  if (y &gt; 32) 
   { 
      x = x + 1; 
   } 
compiles to: 
LD(y,R1)
  CMPLEC(R1,32,R1) 
  BT(R1,Lendif) 
  ADDC(R2,1,R2) 
Lendif:theres no 
&gt;32
instruction! 
L11 - Machine Language   23  6.004  Spring 2009 3/12/09Loops
Beta assembly: 
Lwhile:
(compile expr into rx) 
BF(rx,Lendwhile)  
(compile STUFF) 
BR(Lwhile)
Lendwhile:C code: 
while (expr) 
 { 
    STUFF 
 }Alternate Beta 
assembly:
   BR(Ltest) 
Lwhile:
(compile STUFF)
Ltest:
(compile expr into rx) 
BT(rx,Lwhile)
Lendwhile:
Compilers spend a lot of time optimizing in and around loops. 
- moving all possible computations outside of loops 
- unrolling  loops to reduce branching overhead 
- simplifying expressions that depend on loop variables Move the test 
to the end of the  
loop and branch 
there the rst 
time thru 
saves a branch  
L11 - Machine Language   24  6.004  Spring 2009 3/12/09Our Favorite Program 
n: LONG(20) 
r: LONG(0) 
start:
ADDC(r31, 1, r0) ST(r0, r) 
loop:
LD(n, r1) 
CMPLT(r31, r1, r2) BF(r2, done) 
LD(r, r3) 
LD(n,r1)MUL(r1, r3, r3) 
ST(r3, r) 
LD(n,r1)
SUBC(r1, 1, r1) 
ST(r1, n) 
BR(loop)
done:
Cleverness: 
    None 
    straightforward 
    compilation 
(11 instructions in loop...)  
Optimizations 
are what make compilers 
complicated 
interesting! int n = 20, r; 
r = 1; 
while (n &gt; 0) 
 { 
    r = r*n; 
    n = n-1; 
 }</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>L11 - Machine Language   25  6.004  Spring 2009 3/12/09Optimizations
n: LONG(20) 
r: LONG(0) 
start:
   ADDC(r31, 1, r0)    ST(r0, r) 
LD(n,r1) | keep n in r1 
   LD(r,r3) | keep r in r3 
loop:
   CMPLT(r31, r1, r2)    BF(r2, done)    MUL(r1, r3, r3) 
   SUBC(r1, 1, r1) 
   BR(loop) 
done:
ST(r1,n) | save final n 
   ST(r3,r) | save final r 
Cleverness: 
    We move LDs/STs 
    out of loop! 
(Still, 5 instructions in loop...) int n = 20, r; 
r = 1; 
while (n &gt; 0) 
 { 
    r = r*n; 
    n = n-1; 
 } 
L11 - Machine Language   26  6.004  Spring 2009 3/12/09Really  Optimizing 
n: LONG(20) 
r: LONG(0) 
start:
   LD(n,r1)        | keep n in r1    ADDC(r31,1,r3)  | keep r in r3 
BEQ(r1, done)   | why? 
loop:   MUL(r1, r3, r3)    SUBC(r1, 1, r1) 
BNE(r1,loop)
done:   ST(r1,n)      | save final n 
   ST(r3,r)      | save final r 
Cleverness: 
    We avoid overhead 
    of conditional! 
(Now 3 instructions in loop...) 
UNFORTUNATELY ,
 20! = 2,432,902,008,176,640,000 &gt; 261(overows!)  
but 12! = 479,001,600 = 0x1c8cfc00  int n = 20, r; 
r = 1; 
while (n &gt; 0) 
 {     r = r*n; 
    n = n-1; 
 } 
L11 - Machine Language   27  6.004  Spring 2009 3/12/09Coming Attractions:
Procedures &amp; Stacks</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L11 - Machine Language   17  6.004  Spring 2009 3/12/09Abstraction step 2:
High-level Languages 
Most algorithms are naturally 
expressed at a high level. Consider the 
following algorithm: Weve used (and will continue to use 
throughout 6.004) C, a mature and 
common systems programming lanugage.
Modern popular alternatives include C++, 
Java, Python, and many others. 
Why use these, not assembler? 
/.notdef.g0001readable
/.notdef.g0001concise
/.notdef.g0001unambiguous
/.notdef.g0001portable
 (algorithms frequently outlast 
  their HW platforms) 
/.notdef.g0001Reliable (type checking, etc) 
Reference: C handout (6.004 web site) struct Employee 
 { char *Name; /* Employee's name. */
long Salary; /* Employee's salary. */ 
long Points;}/* Brownie points. */ 
/* Annual raise program. */
Raise(struct Employee P[100])  { int i = 0; 
while (i &lt; 100)  { struct Employee *e = &amp;P[i];
   e-&gt;Salary =
           e-&gt;Salary + 100 + e-&gt;Points;
   e-&gt;Points = 0;  /* Start over! */ 
   i = i+1; 
    } 
 } 
L11 - Machine Language   18  6.004  Spring 2009 3/12/09How Compilers Work 
Contemporary compilers go far 
beyond the macro-expansion 
technology of UASM.  They 
/.notdef.g0001Perform sophisticated analyses 
of the source code 
/.notdef.g0001Invoke arbitrary algorithms to 
generate ecient object code for 
the target machine 
/.notdef.g0001Apply optimizations at both 
source and object-code levels to 
improve run-time eciency.
Compilation to unoptimized   code is 
pretty straightforward... following is 
a brief glimpse. What 
compilers do isnot all that complicated.  
(at least, in principle) 
L11 - Machine Language   19  6.004  Spring 2009 3/12/09Compiling Expressions 
C code: 
int x, y; 
y = (x-3)*(y+123456)
Beta assembly code: 
x: LONG(0)
y: LONG(0)
c: LONG(123456)
...
LD(x, r1) 
SUBC(r1,3,r1)
LD(y, r2) 
LD(C, r3) 
ADD(r2,r3,r2)MUL(r2,r1,r1)
ST(r1,y)c:x:
y:
123456
VARIABLES are assigned 
memory locations and 
accessed via LD or ST 
 OPERATORS translate to ALU 
instructions 
 SMALL CONSTANTS translate 
to literal-mode ALU 
instructions 
 LARGE CONSTANTS translate 
to initialized variables 
L11 - Machine Language   20  6.004  Spring 2009 3/12/09Data Structures: Arrays 
int Hist[100];
...
Hist[score] += 1; 
hist: .=.+4*100 | Leave room for 100 ints 
...
&lt;score in r1&gt; 
MULC(r1,4,r2)    | index -&gt; byte offset LD(r2,hist,r0)   | hist[score] 
ADDC(r0,1,r0)    | increment 
ST(r0,hist,r2)   | hist[score] Memory :
hist:
score 
Hist[score] The C source code 
might translate to: 
Address:  
CONSTANT base address + 
   VARIABLE oset computed from index</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L11 - Machine Language   9  6.004  Spring 2009 3/12/09UASM Source Language
A UASM SOURCE FILE contains, in symbolic text, values of 
successive bytes to be loaded into memory... e.g. in 
37   -3   255 
0x250b100101decimal (default); 
binary (note the 0b prex); 
hexadecimal (note the 0x prex); 
Values can also be expressions; eg, the source le 
37+0b10-0x10   24-0x1   4*0b110-1  0xF7&amp;0x1F 
generates 4 bytes of binary output, each with the value 23!
L11 - Machine Language   10  6.004  Spring 2009 3/12/09Symbolic Gestures 
We can also dene SYMBOLS for use in source programs: 
x = 0x1000 | A variable location 
y = 0x1004 | Another variable 
| Symbolic names for registers: 
R0 = 0 
R1 = 1 
 ... 
R31 = 31 
. = 0x100 | Assemble into 100 
   1  2  3  4 five = . | Symbol five is 0x104 
   5  6  7  8 
. = .+16 | Skip 16 bytes 
   9 10 11 12Special variable .  (period) means next byte address to be lled: A bar denotes 
the beginning of 
a comment 
The remainder 
of the line is 
ignored 
L11 - Machine Language   11  6.004  Spring 2009 3/12/09Labels (Symbols for Addresses) 
LABELS are symbols that represent memory addresses. 
They can be set with the following special syntax: 
x: is an abbreviation for  x = .
. = 0x1000 
sqrs: 0 1 4 9 
16 25 36 49 
64 81 100 121 
144 169 196 225 
slen: .-sqrsAn Example-- 
---- MAIN MEMORY ---- 
1000: 09 04 01 00 
1004: 31 24 19 10 
1008: 79 64 51 40 
100c: E1 C4 A9 90 
1010: 10     
0 1 2 3
L11 - Machine Language   12  6.004  Spring 2009 3/12/09Mighty Macroinstructions 
| Macro to generate 4 consecutive bytes: 
.macro consec(n)  n  n+1  n+2  n+3 
| Invocation of above macro: 
consec(37)Macros  are parameterized abbreviations, or shorthand 
37 38 39 40Has same eect as: 
| Assemble into bytes, little-endian ( least-sig byte 1st) 
.macro WORD(x) x%256 (x/256)%256 
.macro LONG(x) WORD(x) WORD(x &gt;&gt; 16)Here are macros for breaking multi-byte data types into byte-sized chunks 
Has same eect as: 
0xef 0xbe 0xad 0xdeBoy, thats hard to read. 
Maybe, those big-endian 
types do have a point. 
Mem: 0x100  0x101 0x102  0x103. = 0x100 
LONG(0xdeadbeef)</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L11 - Machine Language   13  6.004  Spring 2009 3/12/09Assembly of Instructions 
| Assemble Beta op instructions
.macro betaop(OP,RA,RB,RC) {     .align 4 
    LONG((OP&lt;&lt;26)+((RC%32)&lt;&lt;21)+((RA%32)&lt;&lt;16)+((RB%32)&lt;&lt;11)) 
}
| Assemble Beta opc instructions 
.macro betaopc(OP,RA,CC,RC) { 
    .align 4 
    LONG((OP&lt;&lt;26)+((RC%32)&lt;&lt;21)+((RA%32)&lt;&lt;16)+(CC % 0x10000)) }
| Assemble Beta branch instructions 
.macro betabr(OP,RA,RC,LABEL) betaopc(OP,RA,((LABEL-(.+4))&gt;&gt;2),RC)OPCODE RC RA RB UNUSED
OPCODE RC RA 16-BIT SIGNED CONSTANT 1000000000000000 0000001111 110000
.align 4 ensures instructions will begin on 
word boundary (i.e., address = 0 mod 4) 
Arrgh! 
For Example: 
       ADDC(R15, -32768, R0)--&gt; betaopc(0x30,15,-32768,0)
L11 - Machine Language   14  6.004  Spring 2009 3/12/09Finally, Beta Instructions
| BETA Instructions: 
.macro ADD(RA,RB,RC) betaop(0x20,RA,RB,RC)
.macro ADDC(RA,C,RC) betaopc(0x30,RA,C,RC)
.macro AND(RA,RB,RC) betaop(0x28,RA,RB,RC)
.macro ANDC(RA,C,RC) betaopc(0x38,RA,C,RC)
.macro MUL(RA,RB,RC) betaop(0x22,RA,RB,RC)
.macro MULC(RA,C,RC) betaopc(0x32,RA,C,RC)



.macro LD(RA,CC,RC) betaopc(0x18,RA,CC,RC)
.macro LD(CC,RC) betaopc(0x18,R31,CC,RC).macro ST(RC,CC,RA) betaopc(0x19,RA,CC,RC)
.macro ST(RC,CC) betaopc(0x19,R31,CC,RC)



.macro BEQ(RA,LABEL,RC) betabr(0x1D,RA,RC,LABEL) 
.macro BEQ(RA,LABEL) betabr(0x1D,RA,r31,LABEL).macro BNE(RA,LABEL,RC) betabr(0x1E,RA,RC,LABEL) 
.macro BNE(RA,LABEL) betabr(0x1E,RA,r31,LABEL)Convenience macros 
so we dont have to 
specify R31 
(from beta.uasm) 
L11 - Machine Language   15  6.004  Spring 2009 3/12/09Example Assembly 
ADDC(R3,1234,R17)
betaopc(0x30,R3,1234,R17)expand ADDC macro with RA=R3, C=1234, RC=R17 
.align 4 
LONG((0x30&lt;&lt;26)+((R17%32)&lt;&lt;21)+((R3%32)&lt;&lt;16)+(1234 % 0x10000)) expand betaopc macro with OP=0x30, RA=R3, CC=1234, RC=R17 
WORD(0xC22304D2)   WORD(0xC22304D2 &gt;&gt; 16)expand LONG macro with X=0xC22304D2 
0xC22304D2%256   (0xC22304D2/256)%256   WORD(0xC223)expand rst WORD macro with X=0xC22304D2 
0xD2   0x04   0xC223%256   (0xC223/256)%256evaluate expressions, expand second WORD macro with X=0xC223 
0xD2   0x04   0x23   0xC2 evaluate expressions 
L11 - Machine Language   16  6.004  Spring 2009 3/12/09Dont have it?  Fake it! 
.macro MOVE(RA,RC) ADD(RA,R31,RC) | Reg[RC] &lt;- Reg[RA] 
.macro CMOVE(CC,RC) ADDC(R31,C,RC) | Reg[RC] &lt;- C 
.macro COM(RA,RC) XORC(RA,-1,RC) | Reg[RC] &lt;- 
~Reg[RA]
.macro NEG(RB,RC) SUB(R31,RB,RC) | Reg[RC] &lt;- 
-Reg[RB]
.macro NOP() ADD(R31,R31,R31) | do nothing 
.macro BR(LABEL) BEQ(R31,LABEL) | always branch 
.macro BR(LABEL,RC) BEQ(R31,LABEL,RC) | always 
branch
.macro CALL(LABEL) BEQ(R31,LABEL,LP) | call 
subroutine
.macro BF(RA,LABEL,RC) BEQ(RA,LABEL,RC) | 0 is false 
.macro BF(RA,LABEL) BEQ(RA,LABEL)
.macro BT(RA,LABEL,RC) BNE(RA,LABEL,RC) | 1 is true .macro BT(RA,LABEL) BNE(RA,LABEL)
| Multi-instruction sequences 
.macro PUSH(RA) ADDC(SP,4,SP)  ST(RA,-4,SP) 
.macro POP(RA) LD(SP,-4,RA)   ADDC(SP,-4,SP) Convenience macros can be used to extend our assembly language: 
(from beta.uasm)</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L11 - Machine Language   5  6.004  Spring 2009 3/12/09Compilation
Model of Compilation: 
M1/.notdef.g0001Given some hard-to-program 
machine, say M1...P2
/.notdef.g0001Find some easier-to-program language L2
(perhaps for a more complicated machine, 
M2); write programs in that language P1 C2-1
/.notdef.g0001Build a translator (compiler) that translates programs from M2s language to 
M1s language.  May run on M1, M2, or some other machine. 
Interpretation &amp; Compilation: two tools for improving programmability ... 
/.notdef.g0001Both allow changes in the programming model 
/.notdef.g0001Both aord programming applications in platform (e.g., processor) independent 
languages
/.notdef.g0001Both  are widely used in modern computer systems!
L11 - Machine Language   6  6.004  Spring 2009 3/12/09Interpretation vs Compilation 
Interpretation Compilation 
How it treats input x+2 computes x+2 generates a program that 
computes x+2 
When it happens During execution Before execution 
What it complicates/slows Program Execution Program Development 
Decisions made at Run Time Compile Time 
Major design choice well see repeatedly: 
do it at Compile time or at Run time? There are some characteristic dierences between these two 
powerful tools... 
L11 - Machine Language   7  6.004  Spring 2009 3/12/09Software: Abstraction Strategy 
Initial steps: compilation tools 
Assembler (UASM): 
symbolic representation 
of machine language Hides: bit-level representations, 
hex locations, binary values 
Compiler (C): symbolic 
representation of algorithmHides: Machine instructions, 
registers, machine 
architecture 
Subsequent steps: interpretive tools 
Operating system Hides: Resource (memory, CPU, 
I/O) limitiations and details 
Apps (e.g., Browser) Hides: Network; location; local 
parameters 
L11 - Machine Language   8  6.004  Spring 2009 3/12/09Abstraction step 1: 
A Program for Writing Programs 
UASM - the 6.004 (Micro) Assembly Language 
UASM 
PGM01101101
1100011000101111
10110001
.....
Symbolic 
SOURCE 
text le Binary 
Machine 
LanguageUASM 
Translator 
program 
(built into BSIM) 
UASM:  
1. A Symbolic LANGUAGE for representing strings of bits 
2. A PROGRAM (assembler = primitive compiler) for translating 
UASM source to binary. STREAM of Bytes 
to be loaded 
into memory</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L11 - Machine Language   1  6.004  Spring 2009 3/12/09
Machine Language, Assemblers, 
and Compilers 
When I nd my code in tons of trouble,  
Friends and colleagues come to me,  
Speaking words of wisdom:  
"Write in C."  Long, long, time ago, I can still remember  
 how mnemonics used to make me smile...  
And I knew that with just the opcode names  
  that I could play those BSim games  
 and maybe hack some macros for a while.  
But 6.004 gave me shivers  
 with every lecture they delivered.  
Bad news at the door step,  
I couldnt read one more spec.  
I cant remember if I tried  
 to get Factorial optimized,  
But something touched my nerdish pride  
the day my Beta died.  
And I was singing  
References (on web site):
/.notdef.g0001/.notdef.g0001 Documentation 
 BSIM reference 
Notes on C Language 
Quiz 2 TOMORROW! 
modied  February 23, 09 L11 - Machine Language   2  6.004  Spring 2009 3/12/09/.notdef.g0001/.notdef.g0001 Machine Language: 32-bit instructions 
Ra and Rb are the operands, 
Rc is the destination. R31 reads as 0, unchanged by writes arithmetic: ADD, SUB, MUL, DIV 
compare: CMPEQ, CMPLT, CMPLE
boolean: AND, OR, XOR 
shift: SHL, SHR, SRA 
arithmetic: ADDC, SUBC, MULC, DIVC 
compare: CMPEQC, CMPLTC, CMPLEC
boolean: ANDC, ORC, XORC 
shift: SHLC, SHRC, SRAC 
branch: BNE/BT, BEQ/BF  (const = word displacement from PCNEXT )
jump: JMP (const not used) 
memory access: LD, ST  (const = byte oset from Reg[ra]) Twos complement 16-bit constant for 
numbers from 32768 to 32767; 
sign-extended to 32 bits before use. OPCODE rc ra rb unused
OPCODE rc ra 16-bit signed constant 
How can we improve the programmability of the Beta? 
L11 - Machine Language   3  6.004  Spring 2009 3/12/09Encoding Binary Instructions 
Means, to BETA,    Reg[4]  = Reg[2] + Reg[3] OpCode Rb Ra 10
(unused)000 100 00 1 00 0 01 000 1
Rc 000 000 000 0032-bit (4-byte) ADD instruction: 
But, most of us would prefer to write 
ADD(R2, R3, R4) 
a = b+c; or, better yet, (ASSEMBLER)
(High Level Language) 0
Software Approaches:  INTERPRETATION, COMPILATION 
L11 - Machine Language   4  6.004  Spring 2009 3/12/09
Structure Language
Application Applic Lang (())()
(()())
(())()APPLICATION M2
/.notdef.g0001Result: a virtual M2Interpretation
Turings model of Interpretation: 
M1/.notdef.g0001Start with some hard-to-program 
universal  machine, say M1 Pgm
/.notdef.g0001Write a single program for M1which mimics 
the behavior of some easier machine, say 
M2
Layers of interpretation: 
/.notdef.g0001Often we use several layers of 
interpretation to achieve desired behavior, eg:DATA 
Scheme Interp Scheme SCHEME
Hardware X86 Instrs X86 /.notdef.g0001X86 (P entium), running
/.notdef.g0001Scheme, running
/.notdef.g0001Application, interpreting
/.notdef.g0001Data.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Case study: multipliers</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec09/</lecture_pdf_url>
      <lectureno>9</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>L09 - Multipliers   9  6.004  Spring 2009 3/5/09Observations:  
Hmmm./.notdef.g0004(n2) par t ial pr oduct s.
/.notdef.g0004(n2)f u l l a d d e r s .MULT ADD
a0b2a0b3
a1b2a1b3
a0b0a0b1
a1b0a1b1 a2b2a2b3
a3b2a3b3
a2b0a2b1
a3b0a3b1
L09 - Multipliers   10  6.004  Spring 2009 3/5/09Repackaging Function  
Engineering Principle #2: 
Put the Solution where the 
Problem is. 
How about n2 blocks, each doing a 
little multiplication and   a little
addition? 2 1ab 0 1ab
 1 1ab  0 0ab
 1 0ab
 2 0ab
 3 0ab 3 1ab 0 2ab
 1 2ab 0 3ab
 1 3ab
 2 2ab
 3 2ab 2 3ab
 3 3abMULT ADD/.notdef.g0004(n2) par t ial pr oduct s.
/.notdef.g0004(n2)f u l l a d d e r s .
L09 - Multipliers   11  6.004  Spring 2009 3/5/09Goal:  
Array of Identical Multiplier Cells  
Single  "brick" of brick-wall 
  array...  
       Forms partial product 
       Adds to accumulating sum  
        along with carry
Sk+1 SkSk+1 Sk
Ck+2Ckbi
aj
AiBi
(A+B)iCi Ci+1 FA Necessary Component: Full Adder 
Takes 2 addend bits plus carry bit.  Produces sum 
and carry output bits. 
CASCADE to form an n-bit adder. 2 1ab 0 1ab
 1 1ab  0 0ab
 1 0ab
 2 0ab
 3 0ab 3 1ab 0 2ab
 1 2ab 0 3ab
 1 3ab
 2 2ab
 3 2ab 2 3ab
 3 3abb3
b2
b1
b0
a3a2a1a0
L09 - Multipliers   12  6.004  Spring 2009 3/5/09Design of 1-bit multiplier "Brick":
 2 1ab 0 1ab
 1 1ab  0 0ab
 1 0ab
 2 0ab
 3 0ab 3 1ab 0 2ab
 1 2ab 0 3ab
 1 3ab
 2 2ab
 3 2ab 2 3ab
 3 3abb3
b2
b1
b0
a3a2a1a0Array Layout: 
/.notdef.g0001operand bits bused diagonally 
/.notdef.g0001Carry bits propagate right-to-left 
/.notdef.g0001Sum bits propagate down 
Brick design: 
/.notdef.g0001AND gate forms 1x1 product 
/.notdef.g00012-bit sum propagates from top to 
bottom
/.notdef.g0001Carry propagates to left 
Sk+1SkSk+1 Sk
Ck+2 Ckbi
ajFA FA 0
Wastes some gates but consider 
(say) optimized 4x4-bit brick!</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>L09 - Multipliers   25  6.004  Spring 2009 3/5/09Summary:  
Latency 
/.notdef.g0004(n)
/.notdef.g0004(n)
/.notdef.g0004(n)
/.notdef.g0004(n2)Thruput 
/.notdef.g0004(1/n)
/.notdef.g0004(1)
/.notdef.g0004(1/n)
/.notdef.g0004(1/n2)$
/.notdef.g0004(n2)
/.notdef.g0004(n2)
/.notdef.g0004(n)
/.notdef.g0004(1)*Scheme: 
Combinational 
N-pipe 
Slice-serial 
Bit-serial 
Lots  more multiplier technology: fast adders, Booth Encoding, column 
compression, ...</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L09 - Multipliers   21  6.004  Spring 2009 3/5/09Moving down the cost curve...  
Suppose we have INFREQUENT 
multiplications... pipelining 
doesnt help us. 
Can we do better from a cost/
performance standpoint? 
Hmmm, do I 
really need 
all these 
extras? a0
a1
a2
a3b3
b2
b1
b0
 0 1ab
 0 0ab 0 2ab 0 3ab
 1 1ab
 1 0ab 1 2ab 1 3ab
 2 1ab
 2 0ab 2 2ab 2 3ab
 3 0ab 3 1ab 3 2ab 3 3aba0
a1
a2
a3b3
b2
b1
b0
 0 1ab
 0 0ab 0 2ab 0 3aba0
a1
a2
a3b3
b2
b1
b0
 1 1ab
 1 0ab 1 2ab 1 3aba0
a1
a2
a3b3
b2
b1
b0
 2 1ab
 2 0ab 2 2ab 2 3aba0
a1
a2
a3b3
b2
b1
b0
 3 0ab 3 1ab 3 2ab 3 3ab
L09 - Multipliers   22  6.004  Spring 2009 3/5/09Multiplier Cookbook:  Chapter 4
Stages:
/.notdef.g0004/.notdef.g0001( 1 ) ( constant!) Clock P eriod: 
Hardware cost for n by n bits: /.notdef.g0004/.notdef.g0001(n )
Latency: 
Throughput: 1
/.notdef.g0004/.notdef.g0001(n )
/.notdef.g0004/.notdef.g0001(1/n)aib3
b2
b1
b0
 i 0ab i 1ab i 2ab i 3abSequential Multiplier: 
/.notdef.g0001Re-uses a single n-bit slice to 
emulate each pipeline stage 
/.notdef.g0001a operand entered serially 
/.notdef.g0001Lots of details to be lled in... 
L09 - Multipliers   23  6.004  Spring 2009 3/5/09(Ridiculous?)
Extremes Dept...  
Cost minimization: how far can we go?  
aib3
b2
b1
b0
 i 0ab i 1ab i 2ab i 3ab i 3ab
 i 2ab
 i 1ab
 i 0abSuppose we want to minimize 
hardware (at any cost) 
/.notdef.g0001Consider bit-serial!
/.notdef.g0001Form and add 1-bit 
partial product per clock  
/.notdef.g0001Reuse single brick for 
each bit bj of slice; 
/.notdef.g0001Re-use slice for each bit 
of a operand 
L09 - Multipliers   24  6.004  Spring 2009 3/5/09aib3
b2
b1
b0Multiplier Cookbook:  Chapter 5  
Latency: 
Throughput: Stages:
/.notdef.g0004/.notdef.g0001(1) Clock P eriod: 
Hardware cost for n by n bits: /.notdef.g0004/.notdef.g0001(1n)
/.notdef.g0004/.notdef.g0001(1) + ?
/.notdef.g0004/.notdef.g0001(n2)
/.notdef.g0004/.notdef.g0001(1/n2) i 3ab
 i 2ab
 i 1ab
 i 0abBit Serial multiplier: 
/.notdef.g0001Re-uses a single brick to emulate 
an n-bit slice 
/.notdef.g0001both operands entered serially 
/.notdef.g0001O(n2) clock cycles required 
/.notdef.g0001Needs additional storage 
(typically from existing 
registers) 
(constant)</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L09 - Multipliers   13  6.004  Spring 2009 3/5/09Latency revisited  
Heres our combinational multiplier:
b3 a0
 2 1ab 0 1ab
 1 1ab 0 0ab
 1 0ab
 2 0ab
 3 0ab 3 1ab 0 2ab
 1 2ab 0 3ab
 1 3ab
 2 2ab
 3 2ab 2 3ab
 3 3aba1
a2
a3b2
b1
b0Whats its propagation delay? 
Naive (but valid) bound: 
/.notdef.g0001O(n) additions 
/.notdef.g0001O(n) time for each addition 
/.notdef.g0001Hence O(n2) time required 
On closer inspection: 
/.notdef.g0001Propagation only toward 
left, bottom
/.notdef.g0001Hence longest path bounded  
by length + width of array: 
O(n+n) = O(n)! 
L09 - Multipliers   14  6.004  Spring 2009 3/5/09Multiplier Cookbook:  
Chapter 2  
/.notdef.g0004(n2)/.notdef.g0001Hardware for  
n by n bits:  
Latency: 
Throughput: /.notdef.g0004(n)/.notdef.g0001
/.notdef.g0004(1/n)/.notdef.g0001Combinational Multiplier:
b3 a0
 2 1ab 0 1ab
 1 1ab 0 0ab
 1 0ab
 2 0ab
 3 0ab 3 1ab 0 2ab
 1 2ab 0 3ab
 1 3ab
 2 2ab
 3 2ab 2 3ab
 3 3aba1
a2
a3b2
b1
b0
+Note: lots of tricks are 
available to make a faster 
combinational multiplier 
L09 - Multipliers   15  6.004  Spring 2009 3/5/09Combinational Multiplier:  
best bang for the buck?  
Suppose we have LOTS of 
multiplications. 
Can we do better from a 
 cost/performance 
standpoint? PIPELINING
L09 - Multipliers   16  6.004  Spring 2009 3/5/09The Pipelining Bandwagon...  
where do I get on?  
WE HAVE: 
 Pipeline rules - "well 
formed pipelines" 
 Plenty of registers 
 Demand for higher 
throughput. 
What do we do? Where do we 
dene stages? b3 a0
 2 1ab 0 1ab
 1 1ab 0 0ab
 1 0ab
 2 0ab
 3 0ab 3 1ab 0 2ab
 1 2ab 0 3ab
 1 3ab
 2 2ab
 3 2ab 2 3ab
 3 3aba1
a2
a3b2
b1
b0</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L09 - Multipliers   17  6.004  Spring 2009 3/5/09Stupid Pipeline Tricks  
/.notdef.g0004(n) Stages:
Clock P eriod: 
/.notdef.g0004(n2)Hardware cost for n by n bits: /.notdef.g0004(n)
Latency: /.notdef.g0004(n2)
Throughput: /.notdef.g0004( 1/n )  0 3ab
 0 2ab 1 3ab
 0 1ab 1 2ab 2 3ab
 3 0ab 2 0ab 3 1ab 1 0ab 2 1ab 3 2ab 0 0ab 1 1ab 2 2ab 3 3abgotta break 
that long 
carry chain! 
L09 - Multipliers   18  6.004  Spring 2009 3/5/09Even Stupider Pipeline Tricks  
 0  1 ab
 0  0 ab
 1  0 ab 0 2ab 0 3ab
 1 1ab 1 2ab
 2 1ab
 2 0ab
 3 0ab 1  3 ab
 2  2 ab 2  3 ab
 3  1 ab 3  2 ab 3 3ab
Back to basics: 
whats the point of pipelining, anyhow? WORSE idea:
 Doesnt break long 
combinational paths 
 NOT a well-formed pipeline... 
... dierent register 
counts on alternative 
paths 
... data crosses stage 
boundaries in both 
directions! 
L09 - Multipliers   19  6.004  Spring 2009 3/5/09Breaking O(n) combinational paths  
GOAL: /.notdef.g0004(n) stages; /.notdef.g0004 (1) clock period! /.notdef.g0001 0 1ab
 0 0ab 0 2ab 0 3ab
 1 1ab
 1 0ab 1 2ab 1 3ab
 2 1ab
 2 0ab 2 2ab 2 3ab
 3 0ab 3 1ab 3 2ab 3 3aba0
a1
a2
a3b3
b2
b1
b0LONG PATHS go down, to left: 
/.notdef.g0001Break array into diagonal 
slices 
/.notdef.g0001Segment every long 
combinational path 
L09 - Multipliers   20  6.004  Spring 2009 3/5/09Multiplier Cookbook:  Chapter 3  
 Well-formed pipeline 
(careful!) 
 Constant (high!) 
throughput, 
independently of 
operand size. 0 1ab
 0 0ab 0 2ab 0 3ab
 1 1ab
 1 0ab 1 2ab 1 3ab
 2 1ab
 2 0ab 2 2ab 2 3ab
 3 0ab 3 1ab 3 2ab 3 3aba0
a1
a2
a3b3
b2
b1
b0Stages:
Clock P eriod: 
/.notdef.g0004(n2) Hardware cost for n by n bits: 
/.notdef.g0004(n) Latency: 
Throughput: /.notdef.g0004(1)/.notdef.g0004(1)/.notdef.g0004(n)
... but suppose we dont need    
the  throughput?</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Our induction step:  
2n-bit by 2n-bit multiplication: 
1. Divide multiplicands into n-bit pieces 
2. Form 2n-bit partial products, using n-bit by n-bit 
multipliers.
3. Align appropriately 4. Add. 
Induction:  we can use the same structuring 
principle to build a 4n-bit multiplier from our 
newly-constructed 2n-bit ones...  
6.004  Spring 2009 3/5/09 L09 - Multipliers   5  x
a  baHaL bHbLaLbLaLbH
aHbLREGROUP partial 
products - 
2 additions 
rather than 3! 
aHbHBrick Wall view  
of partial products  
Making 4n-bit multipliers from n-bit 
ones: 2  induction steps
6.004  Spring 2009 3/5/09 L09 - Multipliers   6  b 3 2 1 0 x bbb 3  2 1 0 a a a aa0b2a0b3
a1b2a1b3
a0b0a0b1
a1b0a1b1 a2b2a2b3
a3b2a3b3
a2b0a2b1
a3b0a3b1
Multiplier Cookbook: Chapter 1  
Step 1: Form (&amp; arrange) Given problem: Partial Products: 
Subassemblies: 
 P artial Products  Adders 
Step 2:  Sum 
6.004  Spring 2009 3/5/09 L09 - Multipliers   7   3  2 1 a 0 a a a
b 3 2 1 0 x bbb
MULT ADDa0b2a0b3
a1b2a1b3
a0b0a0b1
a1b0a1b1 a2b2a2b3
a3b2a3b3
a2b0a2b1
a3b0a3b1Performance/Cost Analysis  
2Partial Products: n =2/.notdef.g0004(n)
Things to Add: 2n -2 =/.notdef.g0004(n)
Adder Width: 2n =/.notdef.g0004(n)
2Hardware Cost: ? = /.notdef.g0004(n)
Latency: /.notdef.g0005/.notdef.g0001(n2) ?? 
6.004  Spring 2009 3/5/09 L09 - Multipliers   8  
Example:
2n +2n+3 = /.notdef.g00042(n )
since   
2n/.notdef.g00022 (n +2n+3) /.notdef.g00022 2n
"almost always"
/.notdef.g0004(...) implies both 
inequalities; O(...)
implies only the 
second.  "Order Of" notation: 
such that for all but nitely many
g(n) = O(f(n)) "g(n) is of order f(n)" g(n) = /.notdef.g0004/.notdef.g0004 (f(n)) 
g(n) = /.notdef.g0004(f(n))  if there exist  C2/.notdef.g0003/.notdef.g0003C1&gt;&gt; 0,
 integral  n/.notdef.g00030
c1f(n) /.notdef.g0002/.notdef.g0002/.notdef.g0001/.notdef.g0001g(n) /.notdef.g0002/.notdef.g0002/.notdef.g0001/.notdef.g0001c2f(n)</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L09 - Multipliers   1  6.004  Spring 2009 3/5/09Cost/Performance Tradeos:  
a case study  
Digital Systems Architecture 1.01 
modied 2/23/09 10:44 Lab #3 due tonight! 
L09 - Multipliers   2  6.004  Spring 2009 3/5/09Binary Multiplication  
Engineering Principle:
Exploit  STRUCTURE in problem.aba
b xn bits 
n bits 
2n bits 
since (2n-1)2 &lt; 22nEASY PROBLEM:  design 
combinational circuit to multiply 
tiny (1-, 2-, 3-bit) operands... 
HARD PROBLEM:  design circuit to 
multiply BIG (32-bit, 64-bit) 
numbers 
We can make big
multipliers out of 
little  ones! 
L09 - Multipliers   3  6.004  Spring 2009 3/5/09Making a 2n-bit multiplier  
using n-bit multipliers  
Given n-bit multipliers: 
Synthesize 2n-bit multipliers:  x
abaHaL
bHbL
aLbL
aLbH
aHbL
aHbHa x b= ab
n bits n bits 2n bits  
xa
b2n bits  
2n bits  
ab
4n bits  
L09 - Multipliers   4  6.004  Spring 2009 3/5/09Our Basis:  
n=1: minimalist starting point 
Multiplying two 1-bit numbers is pretty simple: 
a x b= ab 0
Of course, we could start with optimized combinational 
multipliers for larger operands; e.g. 
2a1a0
2b1b04c3c2c1c02-bit
Multiplierthe logic gets 
more complex, 
but some 
optimizations
are possible...</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Digital abstraction, combinational logic, voltage-based encoding</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec02/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>L02 - Digital Abstraction   5  6.004  Spring 2009 2/5/09
Representing information with voltage
Representation of each point (x, y) on a B&amp;W Picture: 
0 volts: BLACK
1  volt: WHITE
0.37 volts: 37% Gray 
etc. 
Representation of a picture: 
    Scan points in some prescribed 
    raster order generate voltage     waveform 
How much information 
at each point? 
L02 - Digital Abstraction   6  6.004  Spring 2009 2/5/09Information Processing = Computation
First lets introduce some processing blocks:
v Copy v
INV v 1-v
L02 - Digital Abstraction   7  6.004  Spring 2009 2/5/09Why have processing blocks?  
The goal of modular design:
What does that mean anyway: 
 Rules simple enough for a 6-3 to follow 
 Understanding BEHAVIOR 
without knowing IMPLEMENTATION 
 Predictable composition of functions  Tinker-toy assembly 
 Guaranteed behavior, 
under REAL WORLD circumstances Abstraction 
L02 - Digital Abstraction   8  6.004  Spring 2009 2/5/09?Lets build a system!  
Copy INV
Copy INV
Copy INV
Copy INV
output
(In Theory)   (Reality)   
input
Figure by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L02 - Digital Abstraction   21  6.004  Spring 2009 2/5/09A Buer  
00 11A simple combinational device:
Static Discipline requires that the VTC avoid the shaded regions (aka 
forbidden zones ), which correspond to valid  inputs but invalid  outputs.Voltage Transfer Characteristic (VTC): 
Plot of Vout vs. Vin where each 
measurement is taken after any 
transients have died out. Vout
VinVil
VolVihVoh
Vol Vil Vih Voh
Note: VTC does not tell you anything about 
how fast a device is   it measures 
static behavior not dynamic behavior
Net result:  combinational devices must have GAIN &gt; 1 and be NONLINEAR.
L02 - Digital Abstraction   22  6.004  Spring 2009 2/5/09Can this be a combinational device?  
VOUT
VIN
1 2345 0012345(0,5)  
(1,4)  
(2.5,1)  
(3,0.5)  
VOLVOLSuppose that you measured the voltage transfer curve of the device shown below. 
Could we build a logic family using it as a single-input combinational device? 
The device must be able to actually produce 
the desired output level. Thus, VOL can be 
no lower than 0.5 V. 
VIHVIHVIL
VILVOH
VOH
VIH must be high enough to produce VOL
Now, choose noise margins  nd an N and set 
VOH = VIH + N 
VIL   = VOL + N 
Such that 
VIH IN generates VOL or less out; AND 
VIL IN generates VOH or more out. Try VOL = 0.5 V
Try VIH = 3 V
Try N  = 0.5 VHmmm, it had better be an INVERTER
L02 - Digital Abstraction   23  6.004  Spring 2009 2/5/09Summary  
/.notdef.g0001 Use voltages to encode information 
/.notdef.g0001 Digital encoding 
/.notdef.g0001 valid voltage levels for representing 0 and 1 
/.notdef.g0001 forbidden zone avoids mistaking 0 for 1 and vice versa 
/.notdef.g0001 gives rise to notion of signal VALIDITY . 
/.notdef.g0001 Noise 
/.notdef.g0001Want to tolerate real-world conditions: NOISE. 
/.notdef.g0001 Key: tougher standards for output than for input 
/.notdef.g0001 devices must have gain and have a non-linear VTC 
/.notdef.g0001Combinational devices 
/.notdef.g0001 Each logic family has Tinkertoy-set simplicity, modularity 
/.notdef.g0001 predictable composition: parts work /.notdef.g0002/.notdef.g0002 whole thing works 

/.notdef.g0001 static discipline 
/.notdef.g0001digital inputs, outputs; restore marginal input voltages 
/.notdef.g0001 complete functional spec 
/.notdef.g0001 valid inputs lead to valid outputs in bounded time
L02 - Digital Abstraction   24  6.004  Spring 2009 2/5/09Next time:  
Building Logic w/ Transistors  
Its about 
time! Id have 
preferred the 
dominos</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L02 - Digital Abstraction   13  6.004  Spring 2009 2/5/09
Using Voltages Digitally  
/.notdef.g0001/.notdef.g0001Key idea: dont allow 0 to be mistaken for a 1 or vice versa 
/.notdef.g0001/.notdef.g0001Use the same uniform representation convention for every
component and wire in our digital system 
/.notdef.g0001/.notdef.g0001To implement devices with high reliability, we outlaw close calls via a representation convention which forbids a range of voltages between 
0 and 1. 
CONSEQUENCE:  
Notion of VALID and INVALID logic levelsvolts Valid 
0Valid 
1Forbidden ZoneInvalid
L02 - Digital Abstraction   14  6.004  Spring 2009 2/5/09A Digital Processing Element  
Static
discipline
Output a 1 if at  
least 2 out of 3 of 
my inputs are a 1. 
Otherwise, output 0.
I will generate a valid 
output in no more than 
2 minutes after  
seeing valid inputsinput A
input B
input Coutput Y 
A combinational device is a circuit element that has 
/.notdef.g0001one or more digital  inputs
/.notdef.g0001one or more digital outputs
/.notdef.g0001afunctional specication  that details the value of each 
output for every possible combination of valid input values 
/.notdef.g0001atiming specication  consisting (at minimum) of an upper 
bound tpd on the required time for the device to compute 
the specied output values from an arbitrary set of stable, valid input values
L02 - Digital Abstraction   15  6.004  Spring 2009 2/5/09A Combinational Digital System  
A set of interconnected elements is a 
combinational device if 
/.notdef.g0001each circuit element is combinational 
/.notdef.g0001every input is connected to exactly one output 
or to some vast supply of constant 0s and 1s 
/.notdef.g0001the circuit contains no directed cycles 
Why is this true? 
Given an acyclic circuit meeting the above 
constraints, we can derive functional and timing 
specs for the input/output behavior from the 
specs of its components! 
Well see lots of examples soon.  But rst, we need to 
build some combinational devices to work with 
L02 - Digital Abstraction   16  6.004  Spring 2009 2/5/09Wires: theory vs. practice  
Vin Vout
(voltage close to boundary 
with forbidden zone) (voltage in forbidden zone: 
Oops, not a valid voltage! )Does a wire obey the static discipline? 
Noise: changes voltage 
Questions to ask ourselves: 
In digital systems, where does noise come from? 
   How big an eect are we talking about? VinVin</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: 
http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L02 - Digital Abstraction   17  6.004  Spring 2009 2/5/09Power Supply Noise  
+
-Integrated circuit 
Rs and Cs from Aluminum 
wiring layers  Current loads from on-
chip devices  Ls from chip leads  
/.notdef.g0001/.notdef.g0001V from: 

IR drop
(between gates: 30mV, within module: 50mV, across chip: 350mV) 
L(dI/dt) drop
(use extra pins and bypass caps to keep within 250mV) 
LC ringing  trigger ed by current steps P ower supply 
L02 - Digital Abstraction   18  6.004  Spring 2009 2/5/09Crosstalk  
CC
COVA
VBA
B
If node B is driven +
-AV/.notdef.g0001
A
C OC
B VC CCV /.notdef.g0001+= /.notdef.g0001
This situation frequently happens on integrated circuits where there 
are many overlapping wiring layers.  In a modern integrated circuit /.notdef.g0001/.notdef.g0001VA
might be 2.5V , CO = 20fF and CC = 10fF/.notdef.g0002/.notdef.g0002/.notdef.g0001/.notdef.g0001VB=0.83V !  Designers 
often try to avoid these really bad cases by careful routing of signals, 
but some crosstalk is unavoidable. 
L02 - Digital Abstraction   19  6.004  Spring 2009 2/5/09Sequential Interference  
/.notdef.g0001/.notdef.g0001V from energy storage left over from earlier signaling on the wire: 

transmission line discontinuities
(reections o of impedance mismatches and terminations) 
[Dally]Fig. 6-17 
charge storage in RC circuit 
(narrow pulses are lost due to 
incomplete transitions) 
[Dally]Fig. 6-19 
[Dally]Fig. 6-20 RLC ringing (triggered by voltage steps) 
Fix: slower operation, limiting 
voltage swings and slew rates 
L02 - Digital Abstraction   20  6.004  Spring 2009 2/5/09Needed: Noise Margins!  
Vin Vout
(marginally valid) (invalid!) Does a wire obey the static discipline?
No!   A combinational device must restore marginally valid signals. It 
must accept marginal inputs and provide unquestionable outputs (i.e.,  
to leave room for noise).
volts Forbidden ZoneValid 
0Valid 
1
Vil Vol Vih VohVALID INPUT REPRESENTATIONS
VALID OUTPUT REPRESENTATIONS NOISE MARGINS
Thats what 
the small print 
was about! Noise
z0,t1RT=Zo(1+ e)e/2
l
tw
2t1 2t1tw tw
V=18 10n
10p
2
1
0
2
1.5
1
1 2 3 4 5 6 7 8 9 10 11121314 1516171819
1 2 3 4 5 6 7 8 9 10 11121314 15161718190.5
2
1.5
1
0.51 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 (A)
(B)
(C)A4/2 4/2
1BB C
1C
500 fF
Figure s by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L02 - Digital Abstraction   1  6.004  Spring 2009 2/5/09The Digital Abstraction  
Handouts: Lecture Slides 1. Making bits concrete 
2. What makes a good bit 
3. Getting bits under contract
modied 1/30/09 11:46 L02 - Digital Abstraction   2  6.004  Spring 2009 2/5/09Concrete encoding of information  
To this point weve discussed encoding information using 
bits. But where do bits come from? 
If were going to design a machine that manipulates 
information, how should that information be physically 
encoded? 
What makes a good bit? 
  - cheap (we want a lot of them)   - stable (reliable, repeatable)   - ease of manipulation
    (access, transform, combine, transmit, store)He said to his friend, "If the British march 
By land or sea from the town to-night, Hang a lantern aloft in the belfry arch 
Of the North Church tower as a signal light,-- 
One if by land, and two if by sea;
And I on the opposite shore will be, 
Ready to ride and spread the alarm Through every Middlesex village and farm, For the country folk to be up and to arm." 
L02 - Digital Abstraction   3  6.004  Spring 2009 2/5/09Substrates for computation  
We can build upon almost any physical 
phenomenon
Wait! Those last ones might have potential...
lanterns 
polarization of a photon dominos 
engraved stone tablets 
Billiard balls E. Coli 
L02 - Digital Abstraction   4  6.004  Spring 2009 2/5/09But, since were EEs  
Stick with things we know about: 
voltages phase
currents frequency 
This semester well use voltages to encode information.  But the best choice 
depends on the intended application... 
    Voltage pros: 
easy generation, detection 
lots of engineering knowledge potentially low power in steady state 
    Voltage cons: 
easily aected by environment DC connectivity required? R &amp; C eects slow things downzero</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L02 - Digital Abstraction   9  6.004  Spring 2009 2/5/09Why did our system fail?  
Why doesnt reality match theory? 
1. COPY Operator doesnt work right 
2. INVERSION Operator doesnt work right 
3. Theory is imperfect 
4. Reality is imperfect 
5. Our system architecture stinks 
ANSWER: all of the above!  
Noise and inaccuracy are inevitable; we cant reliably 
reproduce innite information-- we must design our system  
to tolerate some amount of error  if it is to process 
information reliably. 
L02 - Digital Abstraction   10  6.004  Spring 2009 2/5/09The Key to System Design  
A system is a structure that is guaranteed to exhibit a 
specied behavior, assuming all of its components 
obey their specied behaviors.
How is this achieved? 
Contracts! 
Every system component will have clear obligations 
and responsibilities. If these are maintained we have 
every right to expect the system to behave as 
planned. If contracts are violated all bets are o.
L02 - Digital Abstraction   11  6.004  Spring 2009 2/5/09The Digital Panacea ...  
Why digital? 
 because it keeps the contracts simple! 
The price we pay for this robustness: 
All the information that we transfer between 
             modules is only 1 crummy bit! 
But, we get a guarantee of reliable processing.
0 or 1
L02 - Digital Abstraction   12  6.004  Spring 2009 2/5/09The Digital Abstraction  
Real WorldIdeal 
Abstract World
Volts or 
Electrons or 
Ergs or GallonsBits0/1
Keep in mind that the world is not digital, we would simply like to 
engineer it to behave that way. Furthermore, we must use real 
physical phenomena  to implement digital designs!NoiseManufacturing
Variations</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Pipelining; throughput and latency</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec08/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>L08 - Pipelining   17  6.004  Spring 2009 3/3/09Back to our bottleneck...  
A
4 nS B
3 nS C
8 nS 
D
4 nS 
E
2 nS F
5 nS 
T = 1/8ns 
L = 24ns Recall our earlier example... 
/.notdef.g0001C  the slowest component  
limits clock period to 8 ns. 
/.notdef.g0001HENCE throughput limited to 
1/8ns.
We could improve throughput by 
/.notdef.g0001Finding a pipelined version of C;  
OR ... 
/.notdef.g0001interleaving  multiple copies of C! 
L08 - Pipelining   18  6.004  Spring 2009 3/3/09Circuit Interleaving  
We can simulate a pipelined 
version of a slow 
component by replicating the critical element and alternate inputs between the various copies. C0GDQ
DQ1
0
C GDQC1Xi
C(Xi-2)
This is a simple 
2-state FSM 
that alternates 
between 0 and 1 
on each clock  clk
Q
L08 - Pipelining   19  6.004  Spring 2009 3/3/09Circuit Interleaving  
We can simulate a pipelined 
version of a slow 
component by replicating the critical element and alternate inputs between the various copies. C0GDQ
DQ1
0
C GDQC1Xi
C(Xi-2)
clk
QWhen Q is 1 the lower path is 
combinational (the latch is open), yet the output of the upper path will be enabled onto the input of the output register ready for the NEXT clock edge. 
Meanwhile, the other latch 
maintains the input from the last clock. 
Codd C1 output 
Ceven Mux output Codd It acts like a 2-stage pipeline 
L08 - Pipelining   20  6.004  Spring 2009 3/3/09C0GDQ
DQ1
0
C GDQC1Xi
xx C(Xi-2)C0GDQ
DQ1
0
C GDQC1X0
01 C(Xi-2)C0GDQ
DQ1
0
C GDQC1X1
10 C(Xi-2)C0GDQ
DQ1
0
C GDQC1X2
01 C(X0)C0GDQ
DQ1
0
C GDQC1X3
10 C(X1)Circuit Interleaving  
Latency = 2 clocks 
/.notdef.g0001Clock period 0: X0 presented at input, 
propagates thru upper latch, C0.
/.notdef.g0001Clock period 1: X1 presented at input, 
propagates thru lower latch, C1. C0(X0)
propagates to register inputs. 
/.notdef.g0001Clock period 2: X2 presented at input, 
propagates thru upper latch, C. C0(X0) loaded 
into register, appears at output. N-way 
interleave N registers  
N-way interleaving  
is equivalent to  
N pipeline Stages... 2-Clock Martinizing  
In by ti, out by ti+2</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>L08 - Pipelining   25  6.004  Spring 2009 3/3/09Self-timed Example  
a glimpse of an asynchronous, locally-time discipline
Elegant, timing-independent design: 
 Each component species its own time constraints 
 Local adaptation to special cases (eg, multiplication by 0) 
 Module performance improvements automatically exploited 
 Can be made asynchronous (no clock at all!) or synchronous X
AC
BA(X)
heres   
Got it.
L08 - Pipelining   26  6.004  Spring 2009 3/3/09Control Structure Taxonomy  
Synchronous Asynchronous 
Globally 
Timed 
Locally 
Timed Centralized clocked 
FSM generates all 
control signals.  Central control unit tailors 
current time slice to 
current tasks.  
Start and Finish signals 
generated by each major 
subsystem, 
synchronously with global  
clock.  Each subsystem takes 
asynchronous Start, 
generates asynchronous 
Finish (perhaps using local 
clock).  Easy to design but xed-sized 
interval can be wasteful (no data-
dependencies in timing) Large systems lead to very 
complicated timing generators 
just say no! 
The best way to build large 
systems that have 
independently-timed 
components.  The next big idea for the last several decades: a lot of design 
work to do in general, but extra 
work is worth it in special cases 
L08 - Pipelining   27  6.004  Spring 2009 3/3/09Summary  
/.notdef.g0001 Latency (L) = time it takes for given input to arrive at output 
/.notdef.g0001 Throughput (T) = rate at each new outputs appear 
/.notdef.g0001 For combinational circuits: L = tPD of circuit, T = 1/L 
/.notdef.g0001 For K-pipelines (K &gt; 0): 
/.notdef.g0001 always have register on output(s) 
/.notdef.g0001 K registers on every  path from input to output 
/.notdef.g0001 Inputs available shortly after clock i, outputs available 
shortly after clock (i+K) 
/.notdef.g0001 T = 1/(tPD,REG  + tPD of slowest pipeline stage + tSETUP )
/.notdef.g0001more throughput /.notdef.g0002 split slowest pipeline stage(s) 
/.notdef.g0001 use replication/interleaving if no further splits possible
/.notdef.g0001 L = K / T 
/.notdef.g0001 pipelined latency /.notdef.g0001 combinational latency</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>L08 - Pipelining   13  6.004  Spring 2009 3/3/09Pipeline Example  
A
BC X
Y2
11
0-pipe: 
1-pipe: 2-pipe: 3-pipe: LATENCY THROUGHPUT 
4 1/4OBSERVATIONS: 
 1-pipeline improves neither  
L or T. 
 T improved by breaking long 
combinational paths, 
allowing faster clock. 
 Too many stages cost L, 
dont improve T. 
 Back-to-back registers are 
often required to keep pipeline well-formed. 4 1/41
4 1/22
1/2 63
L08 - Pipelining   14  6.004  Spring 2009 3/3/09Pipelining Summary  
Advantages:
/.notdef.g0001Allows us to increase thruput, by breaking up long 
combinational paths and (hence) increasing clock frequency
Disadvantages:
/.notdef.g0001May increase latency... 
/.notdef.g0001Only as good as the weakest link: slowest step 
constrains system thruput. 
Isnt there a way around this weak link problem? This bottleneck
is the only 
problem 
L08 - Pipelining   15  6.004  Spring 2009 3/3/09
but... but... 
How can I pipeline 
aclothes dryer??? A (2-pipe) Pipelined Components  
CX
Y1Pipelined systems can be 
hierarchical: 
/.notdef.g0001Replacing a slow 
combinational component 
with a k-pipe version may 
increase clock frequency B
1312 4
4-stage pipeline, thruput=1 /.notdef.g0001Must account for new 
pipeline stages in our plan 
L08 - Pipelining   16  6.004  Spring 2009 3/3/09How do 6.004 Aces do Laundry?  
They work around the bottleneck.
First, they nd a place with 
twice as many dryers as 
washers.
Throughput =    ______ loads/min 
 Latency =   ______ mins/load 1/30
90Step 1:
Step 3:
Step 4:Step 2:
Figure by MIT OpenCourseware.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L08 - Pipelining   1  6.004  Spring 2009 3/3/09Pipelining
 what Seymour Cray taught the laundry industry  
Ive got 3 months  
Worth of laundry  
To do tonight  Funny, considering that 
hes only got one 
outt
Due Thursday: Lab #3  
modied 2/23/09 10:45 L08 - Pipelining   2  6.004  Spring 2009 3/3/09Forget circuits lets solve a Real Problem  
Device: Washer 
Function: Fill, Agitate, Spin Washer
PD = 30 mins 
Device: Dryer 
Function: Heat, Spin Dryer
PD = 60 mins INPUT:
dirty laundry 
OUTPUT: 
6 mor e w
eeks 
L08 - Pipelining   3  6.004  Spring 2009 3/3/09Total = WasherPD + DryerPD  
= _________ mins  90One load at a time  
Everyone knows that the real 
reason that MIT students put 
o doing laundry so long is not 
because they procrastinate, 
are lazy, or even have betterthings to do.
The fact is, doing one load at a time 
is not smart. 
L08 - Pipelining   4  6.004  Spring 2009 3/3/09Doing N loads of laundry  
Heres how they do laundry at 
Harvard, the combinational way.
Total = N*(WasherPD + DryerPD)
= ____________ mins  N*90(Of course, this is just an urban legend. 
No one at Harvard actually does 
laundry. The butlers all arrive on 
Wednesday morning, pick up the dirty 
laundry and return it all pressed and 
starched in time for  afternoon tea)  
Figure by MIT OpenCourseware.Step 1:
Step 2:
Figure by MIT OpenCourseware.
Image by MIT OpenCourseWare.Step 1:
Step 3:Step 2:
Step 4:
...Figure by MIT OpenCourseware.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L08 - Pipelining   9  6.004  Spring 2009 3/3/09Pipeline diagrams  
Input
F Reg 
G Reg 
H Reg i i+1 i+2 i+3
Xi Xi+1
F(Xi)
G(Xi)Xi+2
F(Xi+1)
G(Xi+1)
H(Xi)Xi+3
F(Xi+2)
G(Xi+2)
H(Xi+1)Clock cycle Pipeline stages 
The results associated with a particular set of input data 
moves diagonally through the diagram, progressing 
through one pipeline stage each clock cycle. H(Xi+2)
F
GH X P(X)15
2025
L08 - Pipelining   10  6.004  Spring 2009 3/3/09Pipeline Conventions  
DEFINITION:
aK-Stage Pipeline  (K-pipeline) is an acyclic circuit having exactly K registers 
on every  path from an input to an output. 
a COMBINATIONAL CIRCUIT is thus an 0-stage pipeline. 
CONVENTION: 
Every pipeline stage, hence every K-Stage pipeline, has a register on its 
OUTPUT  (not on its input). 
ALWAYS: 
The CLOCK common to all registers must have a period sucient to cover 
propagation over combinational paths PLUS (input) register tPD PLUS 
(output) register tSETUP .
The LATENCY of a K-pipeline is K times the 
period of the clock common to all registers. 
The THROUGHPUT of a K-pipeline is the 
frequency of the clock.
L08 - Pipelining   11  6.004  Spring 2009 3/3/09Ill-formed pipelines  
BC X
YA
Problem: 
Successive inputs get mixed : e.g., B(A(Xi+1), Yi).  This 
happened because some paths from inputs to outputs 
have 2 registers, and some have only 1!
This CANT HAPPEN on a well-formed K pipeline! none For what value of K is the following circuit a K-Pipeline?  ANS: ____________ Consider a BAD job of pipelining: 
2 1
L08 - Pipelining   12  6.004  Spring 2009 3/3/09A pipelining methodology  
Step 1: 
   Draw a line that crosses every output 
in the circuit, and mark the endpoints 
as terminal points. 
Step 2: 
   Continue to draw new lines between 
the terminal points across various 
circuit connections, ensuring that every  connection crosses each line in 
the same direction.  These lines 
demarcate pipeline stages .
Adding a pipeline register at every 
point where a separating line crosses a 
connection will always generate a valid pipeline.STRATEGY:
   Focus your attention on placing 
pipelining registers around the 
slowest circuit elements (BOTTLENECKS).
A
4 nS B
3 nS C
8 nS 
D
4 nS 
E
2 nS F
5 nS 
T = 1/8ns 
L = 24ns INPUTS OUTPUTS</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L08 - Pipelining   5  6.004  Spring 2009 3/3/09Doing N Loads the MIT way  
MIT students pipeline 
the laundry process. 
Thats why we wait! 
Total = N * Max(WasherPD, DryerPD)
       = ____________ mins N*60
Actually, its more like N*60 + 30 
if we account for the startup 
transient correctly.  When doing 
pipeline analysis, were mostly 
interested in the steady state 
where we assume we have an innite supply of inputs. 
L08 - Pipelining   6  6.004  Spring 2009 3/3/09Performance Measures  
Latency:
The delay from when an input is established until the output 
associated with that input becomes valid. 
(Harvard Laundry = _________ mins) 
(      MIT Laundry = _________ mins) 
Throughput:
The rate  at which inputs or outputs are processed. 
(Harvard Laundry = _________ outputs/min) 
(      MIT Laundry = _________ outputs/min) 90
120
1/90
1/60Assuming that the wash 
is started as soon as 
possible and waits (wet) 
in the washer until dryer 
is available. 
L08 - Pipelining   7  6.004  Spring 2009 3/3/09Okay, back to circuits  
F
GH X P(X)For combinational logic: 
   latency = tPD,
   throughput = 1/tPD.   
We cant get the answer faster, but are we making eective use of our 
hardware at all times? 
G(X)F(X)
P(X)X
F &amp; G are idle, just holding their outputs 
stable while H performs its computation
L08 - Pipelining   8  6.004  Spring 2009 3/3/09Pipelined Circuits  
use registers to hold Hs input stable! 
F
GH X P(X)15
2025Now F &amp; G can be working on input Xi+1
while H is performing its computation on 
Xi.  Weve created a 2-stage pipeline : if we 
have a valid input X during clock cycle j, P(X) is valid during clock j+2. 
Suppose F , G, H have propagation delays of 15, 20, 25 ns and 
we are using ideal zero-delay registers:  
latency
45
______throughput
1/45
______unpipelined 
2-stage pipeline 50
worse  1/25
betterStep 1:
Step 3:Step 2:
...
Figure by MIT OpenCourseware.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L08 - Pipelining   21  6.004  Spring 2009 3/3/09Combining techniques  
We can combine interleaving and 
pipelining. Here, C interleaves two C 
elements with a propagation delay of  
8 nS.
The resulting C circuit has a 
throughput of 1/4 nS, and latency of  
8 nS. This can be considered as an 
extra pipelining stage that passes 
through the middle of the C module. One of our separation lines must 
pass through this pipeline stage. A
4 nS B
3 nS C 
2x4nS
D
4 nS 
E
2 nS F
5 nS By combining interleaving with 
pipelining we move the 
bottleneck from the C element 
to the F element. 
T = 1/5ns 
L = 25ns 
L08 - Pipelining   22  6.004  Spring 2009 3/3/09And a little parallelism  
We can combine interleaving 
and pipelining with parallelism. 
Throughput = 
_______ load/min 
Latency =  _______ min 2/30 = 1/15 
90
L08 - Pipelining   23  6.004  Spring 2009 3/3/09Control Structure Approaches  
RIGID
Laid
BackALL computation events 
occur at active edges of a periodic clock: time is divided into xed-size discrete intervals. Synchronous 
Events -- eg the loading of a register -- can happen at at arbitrary times. Asynchronous Timing dictated by centralized FSM according to a xed schedule. Globally Timed 
Each module takes a START signal, generates a FINISHED signal.  Timing is dynamic, data dependent. Locally Timed 
L08 - Pipelining   24  6.004  Spring 2009 3/3/09Control Structure Alternatives  
LE
LE
Control 
Logic Synchronous, globally-timed: 
Control signals (e.g., load enables) 
From FSM controller 
X
heres X 
got X 
CLKheres X 
got X X X2 X1Synchronous, locally-timed: 
Local circuitry, handshake controls 
ow of data: 
X
heres X 
got X heres X 
got X X X2 X1Asynchronous, locally-timed system using transition signaling: Step 1:
Step 2:
Step 3:
Step 4:
Step 5:
Figure by MIT OpenCourseware.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: 
http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Canonical forms; synthesis, simplification</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/resources/mit6_004s09_lec04/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>L04 - Logic Synthesis   13  6.004  Spring 2009 2/12/09AB=A+B  Practical SOP Implementation  
NAND-NAND
NOR-NORC
A
BY/.notdef.g0001/.notdef.g0001C
A
BY
z y x xyz++++==
/.notdef.g0001/.notdef.g0001C
A
BY
y x y x==++C
A
BY
C
A
BYAB=A+B  Pushing Bubbles 
C
A
BY
Y ou might think all these  extra 
inverters would make this structure less attractive. However, quite the 
opposite is true. 
L04 - Logic Synthesis   14  6.004  Spring 2009 2/12/09Logic Simplication  
Can we implement the same function with fewer gates? 
Before trying well add a few more tricks in our bag. 
BOOLEAN ALGEBRA: 
OR rules: a + 1 = 1,  a + 0 = a,  a + a = a 
AND rules: a1 = a,  aO = 0,  aa = a 
Commutative: a + b = b + a,  ab = ba 
Associative: (a + b) + c = a + (b + c),  (ab)c = a(bc) 
Distributive: a(b+c) = ab + ac,  a + bc = (a+b)(a+c) 
Complements:Absorption:
Reduction:
DeMorgans Law: 0 a a 1, a a====++
b a b a a a, ab a++==++==++
ab b) a a( a, b) a(a==++==++
b b) a b)( (a b, b a ab==++++==++
b a b a , ab b a++====++
L04 - Logic Synthesis   15  6.004  Spring 2009 2/12/09
Boolean Minimization:  
An Algebraic Approach  
BA C CBA A CB A B C Y+ + + =Lets (again!) simplify 
Using the identity /.notdef.g0001 /.notdef.g0001 /.notdef.g0001= +A A
BA C CBA A CB A B C Y+ + + =
CB A C Y+ =BA C CB A B C Y+ + =Cant he come up 
with a new example???
For any expression /.notdef.g0002/.notdef.g0002 and variable A: 
Hey, I could write 
Aprogram  to do 
That! 
L04 - Logic Synthesis   16  6.004  Spring 2009 2/12/09A Case for Non-Minimal SOP  
AB CB A C Y++++==A
C
BY
NOTE: The steady state behavior of 
these circuits is identical. They 
dier in their transient behavior. Y(1)C(1)
Y=CA+CBA(1)
B(1)
tCD = 1 nS 
tPD = 2nS 00
1C  B A Y
00000011
0100
01111000
101011011111CA
CB
BAA
B
C
Y
Thats what 
we call a 
glitch or 
hazard  
A
B
C
Y
Now its 
LENIENT!</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>L04 - Logic Synthesis   9  6.004  Spring 2009 2/12/09One will do!
NANDs and NORs are universal:
Ah!, but what if we want more than 2-inputs =
=
==
=
=
L04 - Logic Synthesis   10  6.004  Spring 2009 2/12/09Stupid Gate Tricks  
Suppose we have some 2-input XOR gates: 
And we want an N-input XOR: A
00
1
1B
01
0
1C
01
1
0
tpd = 1 
tcd = 0 
tpd = O( ___ ) -- WORST CASE.   output = 1 
  i number of 1s 
  input is ODD 
  (ODD PARITY)
Can we compute N-input XOR faster? NA1A3A4AN
A2A
BC
L04 - Logic Synthesis   11  6.004  Spring 2009 2/12/09I think that I shall never see  
a circuit lovely as...  
N-input TREE has O( ______ ) levels... 
Signal propagation takes O( _______ ) gate delays.
Question: Can EVERY N-Input Boolean function be implemented as a 
tree of 2-input gates?log N
log N21222log2NA1A2
A4A3
AN
L04 - Logic Synthesis   12  6.004  Spring 2009 2/12/09Are Trees Always Best?  
Alternate Plan: Large Fan-in gates
/.notdef.g0001N pulldowns with complementary pullups
/.notdef.g0001Output HIGH if any input is HIGH = OR
/.notdef.g0001 Propagation delay: O(N) since each 
      additional MOSFET adds  C ...
Ntpd
O(log N)O(N)
~4Dont be mislead by the big O stu
the constants in this case can be much smaller so for small N this plan might 
be the best.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>L04 - Logic Synthesis   17  6.004  Spring 2009 2/12/09Truth Tables with Dont Cares  
C  B A Y
00000011
0100
01111000101011011111 CA
CB
BAC  B A Y
0- -  000- -  11
1 0 -- 0
1 1 -- 1
-- 0 0 0
-- 1 1 1One way to reveal the opportunities for a more compact implementation is 
to rewrite the truth table using dont cares (--) to indicate when the value of a particular input is irrelevant in determining the value of the 
output.
L04 - Logic Synthesis   18  6.004  Spring 2009 2/12/09Weve been designing a mux  
D0
D1
S0
1
0
10
1
S
0
10
1
S0
10
1
SD00
D01
D10
D11
S0    S1 and implemented as a  
tree of smaller MUXes: 
00
011011D00
D10
D11
S0
S1YD01MUXes can be generalized to 2k data  
inputs and k select inputs  2-input Multiplexer YCBAY
0000
0011
0100
0111
1000
1010
1101
1111Truth Table 
Y
L04 - Logic Synthesis   19  6.004  Spring 2009 2/12/09Systematic Implementations  
 of Combinational Logic  
Consider implementation of some arbitrary Boolean 
function, F(A,B,C) ... using a MULTIPLEXER 
as the only circuit element: 
ABC inCout
0000
0010
0100
0111
1000
1011
1101
1111Full-Adder 
Carry Out Logic 
0
12
3
4567
A,B,C
inCout0
00
1
0111
L04 - Logic Synthesis   20  6.004  Spring 2009 2/12/09General Table Lookup Synthesis  
MUX
Logic AB
Fn(A,B) 
Generalizing: 
  In theory, we can build any 1-output combinational 
  logic block with multiplexers. 
For an N-input function we need a _____ input  mux. 
BIG Multiplexers? 
   How about 10-input function?  20-input? AB Fn(A,B )
00 0
01 1
10 1
11 0
2N
Muxes are UNIVERSAL! 
In future technologies 
muxes might be the 
natural gate. 0
10
1
S1
0
AY A                Y =
010
1
S0
B
AY
010
1
SB
1
AY=
=A
BY
ABY
010
1
SB
B
AYWhat does 
that one do?</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>L04 - Logic Synthesis   25  6.004  Spring 2009 2/12/09Summary  
/.notdef.g0001Sum of products 
/.notdef.g0001Any function that can be specied by a truth table or, equivalently, 
in terms of AND/OR/NOT (Boolean expression) 
/.notdef.g00013-level implementation of any logic function 
/.notdef.g0001Limitations on number of inputs (fan-in) increases depth  
/.notdef.g0001SOP implementation methods 
/.notdef.g0001NAND-NAND, NOR-NOR 
/.notdef.g0001Muxes used to build table-lookup implementations 
/.notdef.g0001Easy to change implemented function -- just change constants 
/.notdef.g0001ROMs
/.notdef.g0001Decoder logic generates all possible product terms 
/.notdef.g0001Selector logic determines which pterms are ored together</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>L04 - Logic Synthesis   21  6.004  Spring 2009 2/12/09A New Combinational Device  
kD1D2
DNDECODER: 
k SELECT inputs,  
N = 2k DATA OUTPUTs. 
Selected Dj HIGH;
all others LOW. 
NOW, we are well on our way to building a general 
purpose table-lookup device.  
We can build a 2-dimensional ARRAY of decoders and 
selectors as follows ... Have I 
mentioned 
that HIGH 
is a synonym 
 for 1 and 
LOW means 
the same 
as 0 
L04 - Logic Synthesis   22  6.004  Spring 2009 2/12/09Read-only memories (ROMs)  
COUT S000
001
010
011
100
101
110
111
A
B
CINABCiSCo
00000
0011001010
01101
10010
10101
1100111111FA AB
Co Ci
SFull Adder 
For K inputs, decoder 
produces 2K signals, 
only 1 of which is 
asserted at a time -- 
think of it as one signal 
for each possible 
product term. Each column is large fan-in OR as described 
on slide #12.  Note location of pulldowns 
correspond to a 1 output in the truth table! 
Shared 
decoder 
One selector for 
each output 
L04 - Logic Synthesis   23  6.004  Spring 2009 2/12/09Read-only memories (ROMs)  
ABCiSCo
00000
0011001010
01101
10010
10101
1100111111FA AB
Co Ci
SFull Adder LONG LINES slow down propagation times 
The best way to improve this is to build 
square arrays , using some inputs to drive 
output selectors (MUXes):
00
01
10
11
01 01A
B
CIN
COUT S
2D Addressing: Standard for ROMs, RAMs, logic arrays 
L04 - Logic Synthesis   24  6.004  Spring 2009 2/12/09Logic According to ROMs  
ROMs ignore  the structure of combinational functions ... 
 Size, layout, and design are independent of function  Any Truth table can be programmed by 
  minor reconguration: 
- Metal layer (masked ROMs) 
- Fuses (Field-programmable PROMs) 
- Charge on oating gates (EPROMs) 
... etc. 
Model: LOOK UP value of function in truth table... 
Inputs: ADDRESS of a T.T. entry ROM SIZE = # TT entries... 
... for an N-input boolean function, size = __________ 
2N x #outputs 
ROMs tend to 
generate glitchy outputs. WHY?</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>L04 - Logic Synthesis   1  6.004  Spring 2009 2/12/09Synthesis of Combinational Logic  
Lab 1 is due Thursday  2/19
Quiz 1  is a week from Friday (in section) A
B
modied 2/12/09 10:01 L04 - Logic Synthesis   2  6.004  Spring 2009 2/12/09Functional Specications  
There are many ways of specifying the 
function of a combinational device, for 
example:
A
BYIf C is 1 then 
copy B to Y , 
otherwise copy 
A to Y C
Concise alternatives: 
truth tables  are a concise description of the combinational 
systems function.  
Boolean expressions  form an algebra in whose operations are 
AND (multiplication), OR (addition), and inversion
(overbar). 
Any combinational  (Boolean) function can be specied as a truth 
table or an equivalent sum-of-products Boolean expression! Argh Im tired of word games
CBAY
0000
0011
0100
0111
1000
1010
1101
1111Truth Table 
CBA A CB BA C A B C Y+ + + =
L04 - Logic Synthesis   3  6.004  Spring 2009 2/12/09Heres a Design Approach  
1) Write out our functional spec as a 
truth table 
2) Write down a Boolean expression with 
terms covering  each 1 in the output: 
3) Wire up the gates, call it a day, and 
declare success! 
This approach will always give us 
Boolean expressions in a particular 
form: SUM-OF-PRODUCTSCBAY
0000
0011
0100
0111
1000
1010
1101
1111Truth Table 
-its systematic! 
-it works! 
-its easy! 
-are we done yet???CBA A CB BA C A B C Y+ + + =
L04 - Logic Synthesis   4  6.004  Spring 2009 2/12/09Straightforward Synthesis  
We can implement
SUM-OF-PRODUCTS
with just three levels of 
logic.
INVERTERS/AND/OR
Propagation delay -- 
No more than 3 gate delays
(assuming gates with an arbitrary number of inputs) A
B
C
A
B
C
A
B
C
A
B
CY</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>L04 - Logic Synthesis   5  6.004  Spring 2009 2/12/09Basic Gate Repertoire  
Are we sure we have all the gates we need? 
Just how many two-input gates are there? 
AB Y
00 0
01 0
10 0
11 1AND
AB Y
00 0
01 1
10 1
11 1OR
AB Y
00 1
01 1
10 1
11 0NAND
AB Y
00 1
01 0
10 0
11 0NOR
2   = 24 = 1622Hmmmm all of these have 2-inputs (no surprise) 
 each with 4 combinations, giving 22 output cases 
How many ways are there of assigning 4 outputs? ________________ 
L04 - Logic Synthesis   6  6.004  Spring 2009 2/12/09There are only so many gates  
There are only 16 possible 2-input gates 
 some we know already, others are just silly 
I
N
P
U
T
ABZ
E
R
OA
N
DA&gt;BAB
&gt;
ABX
O
RO
RNORX
NO
RNO
T
BA
&lt;=
BNO
T
AB
&lt;=
AN
A
N
DON
E
0 0000000001111 1111
0 1000011110000 1111
1 0001100110011 0011
1 1010101010101 0101How many of 
these gates 
can be 
implemented 
using a single 
CMOS gate? 
CMOS gates are inverting; we can always respond positively to positive 
transitions by cascaded gates.  But suppose our logic yielded cheap 
positive  functions, while inverters were expensive 
L04 - Logic Synthesis   7  6.004  Spring 2009 2/12/09Logic Geek Party Games  
You have plenty of ANDs and ORs, but only 2 inverters.  Can you invert 
more than 2 independent inputs? 
CHALLENGE: Come up with a combinational circuit using ANDs, ORs, and 
at most 2 inverters that inverts A, B, and C ! 
Such a circuit exists.  What does that mean? 
-/.notdef.g0001If we can invert 3 signals using 2 inverters, can we use 2 of the pseudo-
inverters to invert 3 more signals? 
-/.notdef.g0001Do we need only 2 inverters to make ANY combinational circuit? 
Hint: theres a subtle dierence between our 3-inv device and three 
combinational inverters! A
B
CA
B
C3-inv
Is our 3-inv device LENIENT?
L04 - Logic Synthesis   8  6.004  Spring 2009 2/12/09Fortunately, we can get by with a few basic gates  
How many dierent gates do we really  need? ABY
00 0
01 1
10 0
11 0B&gt;A
A
ByAB Y
00 0
01 1
10 1
11 0XOR
ABYAND, OR, and NOT are sucient (cf Boolean Expressions): 
A
ByAB=A+B  That is just 
DeMorgans
Theorem!AB=A+B  
A+B = AB  A
BY</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 6.004 Computation Structures 
Spring 2009</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
