<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/</course_url>
    <course_title>Advanced Algorithms</course_title>
    <course_tags>
      <list>Engineering </list>
      <list>Computer Science </list>
      <list>Algorithms and Data Structures </list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>LP: complexity; introduction to the ellipsoid algorithm</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec11/</lecture_pdf_url>
      <lectureno>11</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>.  Lemma3 If A   Znn then |det(A  )| 2size(A  )n2  1. 
Proof: Recall that for A  =[a1,a2,...,ak], | det(A  )| can be visualized as the volume of 
the parallelipiped spanned by the column vectors. Hence, 
n n n 
1+|det(A  )| 1+ /barblai/barbl (1+/barblai/barbl) 2size(ai)n =2size(A )n2 . 
i=1 i=1 i=1 
Lemma4 L  size(LP)  mnL. 
Proof: Using the fact that size(n)  2+log2(n)for n  1, we have that the second 
inequalityholdsbecause: 
size(A) mnmax (size(aij )) mn(2+log2(detmax)), 
i,j 
size(b) m(2+log2(bmax)), 
and 
size(c) n(2+log2(cmax)). 
Adding these together gives the desired inequality for m  2, n  2. The rst  holds 
because, by the previous lemma, the determinant of any minor of A is bounded by the size 
ofA.Hence, 
detmax  2size(A). 
Also, 
m +logbmax  size(b), 
and 
n +logcmax  size(c). 
Finally,
2L =2m2ndetmaxcmaxbmax  2size(LP)
From the denition of L, the following remark follows; this is what we will need mostly 
when analyzing running times or sizes. 
Remark1 detmax  bmax  cmax  2m+n =2L . 
Complexity of LP 
Here is the decision problem corresponding to linear programming. 
Given A  Zmn , b  Zm , c  Zn, and , determine whether 
min{c T x : Ax = b,x  0} . (2) 
11-3 3</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>4 E1 E0 a 0 a1 
P 
Figure 1: One iteration of the ellipsoid algorithm. 
The Ellipsoid Algorithm 
The Ellipsoid algorithm was proposed by the Russian mathematician Shor in 1977 for 
general convex optimization problems, and applied to linear programming by Khachyan in 
1979. The problem being considered by the ellipsoid algorithm is: 
Given a bounded, convex, non-empty and full-dimensional set P  Rn nd 
x  P. 
We will see that we can reduce linear programming to an instance of this problem. 
The ellipsoid algorithm works as follows. We start with a big ellipsoid E thatisguar
anteed to contain P. We then check if the center of the ellipsoid is in P. If it is, we are 
done, we found a point in P.Otherwise,we nd anhyperplanepassing through thecenter 
of the ellipsoid, so that P is contained in one of the half spaces dened by it. One iteration 
of the ellipsoid algorithmisillustratedinFigure1. Theellipsoid algorithmisthefollowing. 
 Let E0 be an ellipsoid containing P 
 while center ak of Ek is not in P do: 
 Let cT
k x  cT
k ak be such that {x : cT
k x  ckT ak} P 
 Let Ek+1 be the minimum volume ellipsoid containing Ek {x : ckT x  ckT ak} 
 k  k +1 
Theellipsoidalgorithmhastheimportantpropertythattheellipsoidsconstructed shrink 
by, at least, a constant (depending on the dimension) factor in volume as the algorithm 
proceeds; this is stated precisely in the next lemma. As P is full dimensional, we will 
eventually nd a point in P. 
Lemma8 V ol(Ek+1) &lt;e  2n1
+2 .V ol(Ek) 
11-5</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>2 We may assume that cT y  0 (otherwise choose y). Moreover, if cT y = 0, we can 
assume that there exists j such that yj &lt; 0. 
Assume, by contradiction, that for all j, yj  0. Then, cT y&lt; 0. But this implies that 
c T (x + y)  as   
Then min{cT x : x  P} is not nite. Contradiction! 
Therefore, there exists j such that yj &lt; 0. Choose 
 = min xj . (1) 
j: yj &lt;0 yj 
Thisimpliesthat x +y isin P, and cT (x +y) cT x. Moreover, one more component of 
 x is0. We can apply thesameprocedureto x = x+y, and eventually we aregoing toget 
to a vertex. (Formally, we couldapply induction on the number of nonzero entries of x). 
Size of LP 
In order to be able to discuss the complexity for solving a linear program, we need rst to 
discussthesizeof theinput. Weassumethat everyintegerdataisgiveninbinary encoding, 
thusfor n  Z, we need 
size(n)=1+log2(|n| +1) 
bits,for v  Zp, we need 
p 
size(v)=(vi) 
i=1 
bits, and for A  Znxm, we need 
nm 
size(A)= (ai,j ). 
i=1 j=1 
bits. As a result, to represent all the data of a linear program, we need a size equal to 
size(LP)= size(b)+size(c)+size(A). 
The above sizeis not very convenient whenproving thecomplexity of alinearprogram
ming algorithm. Instead, we will be considering another size, dened by 
L = m + n + log2(detmax)+log2(bmax)+log2(cmax), 
wheredetmax = max| det(A  )| over all submatrices A  of A, bmax = maxi |bi| and cmax = 
maxj |cj |. 
Inthefollowing twolemmas,weshowthat L ispolynomially comparablewith size(LP), 
whichimpliesthat an algorithmhas a running timepolynomially boundedinterms of L if, 
and only if, it is polynomial in size(LP). 
11-2</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>1 18.415/6.854 Advanced Algorithms October15,2008
Lecture 11 
Lecturer: Michel X. Goemans 
In this lecture, we will start continuing from where we left in the last lecture on linear 
programming. We then argue that LP  NP  co  NP. In the end of this lecture, we 
introduce the rst polynomial algorithm to solve LP, known as the EllipsoidAlgorithm. 
LP continuation 
Last time, we had proved that, given a polyhedral set P = {x : Ax = b, x  0}, a point 
x is a vertex of P if and only if A{j: xj &gt;0} has linearly independent columns. Now assume 
that rank(A)= m, where m is the number of rows. We had then dened the notion of a 
basicfeasible solution(bfs) corresponding to abasis B, see last lecture for details. 
Theorem1 Consider the polyhedral set P = {x : Ax = b, x  0} where rank(A)= m.A 
point x is a vertex of P if and only if it is a basic feasible solution. 
Proof: If x is a vertex of P, then we know that A{j :xj&gt;0} has linearly independent 
columns. Let J == {j : xj &gt; 0}. Thus rank(AJ )= |J|. Since rank(A)= m, we can add 
columns to J toget aset B with |B| = m and rank(AB)= m,i.e. AB is invertible. We 
musthavethat: 
A1 xB = B b 
xN =0. 
Therefore, x is a basic feasible solution. 
Conversely, assume x is a basic feasible solution, that is, 
xB = A1bB 
xN =0. 
By denition, J = {j : xj &gt; 0} B and thefactthat rank(AB)= |B| impliesthat AJ has 
linearly independent columns. Thus, x is a vertex of P.  
Theorem2 Let P = {x : Ax = b, x  0}. Assume min{cT x : x  P} is nite. Then, for 
any x  P, there exists a vertex x   P suchthat cT x   cT x 
Proof: If x is a vertex, we are done. Otherwise, there exists y /n}ationslash=0 such that x y isinP. 
Note that, as Ay =0(because A(x +y)= b = Ax), for any  R, A(x +y)= b. Observe 
that, 
(x + y)j  0 for   x
yj
j ,if yj &lt; 0 
always,if yj  0 
11-1</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>To show thatLPisinNP, we need tobe able toprovide a concise(i.e. polynomially 
bounded in the size of the input) certicate for yes instances. A feasible point of cost less 
or equal to  will clearly be a certicate, but will it be concise? 
Claim5 LP  NP 
We now showthatif wetake notjustany feasible solution,but abasicfeasible solution, 
then its size will be polynomially bounded in the size of the input. 
Theorem6 Let x be a vertex(orbasicfeasible solution) of Ax = b,x  0. Then xi = p
q i . 
for i=1,...,n where pi,q  N and pi &lt; 2L and q&lt; 2L . 
Proof: Since x is a vertex, then x is a basic feasible solution with basis B such that 
xB = A1b and xN =0(noticethat AB is square). By Cramers rule: B 
A1 1 xB = B b = cof(AB )b, det(AB ) 
where cof(A) is a matrix whose entries are all determinants of submatrices of A. Letting 
q =det(AB ), we get thatq  detmax &lt; 2L and pi  mdetmax bmax &lt; 2L .  
Now, to prove Claim 5, for yes instances, the certicate will be a vertex of {x : Ax = 
b,x  0} such that cT x  . 
However,tobeprecise,wealsohavetodeal with thecaseinwhich theLPisunbounded, 
since in that case, there might not be any such vertex. But in that case, we can give a 
certicate of unboundedness by (i) exhibiting a vertex of {x : Ax = b,x  0} (showing 
it is not empty, and it is concise by the above theorem) and (ii) showing that the dual 
feasible region {y : AT y  c} is empty by using Farkas lemma and exhibiting a vertex of 
Ax = b,x  0,cT x = 1 which is also concise by the above theorem. 
Alternatively, one can show a concise feasible solution to 
min{c T x : Ax = b,x  0,c T x   1}. (3) 
Claim7 LP  co  NP. 
Indeed, for the complement instances of LP, we can use strong duality and exhibit a 
basic feasible solution of AT y  c s.t. bT y&gt; (or show that {x  0: Ax = b} is empty 
using Farkas lemma). In the case when {x : Ax = b,x  0} is feasible, the correctness 
follows from strong duality saying that 
min{c T x : Ax = b,x  0} =max{bT y : AT y  c}. 
Thus, LP  NP  co NP which makesitlikely tobeinP.Andindeed,LP was shown 
to be polynomially solvable through the ellipsoid algorithm. 
11-4</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Note that the ratio is independent of k. 
Before we can state the algorithm more precisely, we need to dene ellipsoids. 
Denition1 Given a center a, and a positive denite matrix A, the ellipsoid E(a,A) is 
dened as {x  Rn :(x  a)T A1(x  a) 1}. 
One important fact about a positive denite matrix A is that there exists B suchthat 
A = BT B, and hence A1 = B1(B1)T . Ellipsoids areinfactjust anetransformations 
of unit balls. To see this, consider the (bijective) ane transformation T : x  y = 
(B1)T (x  a). It maps E(a,A){y : yT y  1} = E(0,I), the unit ball. 
V ol(Ek+1)Thisgives a motivationforthefactthattheratio V ol(Ek) isindependentof k. Indeed, 
as linear transformations preserve ratio of volumes, we can reduce to the case when Ek is 
the unit ball. In this case, by symmetry of the ball, the volume ratio will be independent 
ofk. 
11-6</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Voronoi diagrams</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec23/</lecture_pdf_url>
      <lectureno>23</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>We look now at how complex a Voronoi diagr am can be. We know that each cell 
is delimited by at most n  1 sides (edges), but in the lemma below, we show that 
collectiv ely all cells do not have too many edges and vertices. 
Lemma 2 For a Voronoi diagr am with n points, the following relations hold: 
 The numb er of vertices of a Voronoi diagr am is nv  2n  5. 
 The numb er of edges in any Voronoi diagr am is ne  3n  6. 
Figur e 2: To prove Lemmma 2 we add a point q to the Voronoi Diagram (solid 
lines), and connect all of the innite edges to this point (shown in dotted lines). 
Proof: We can view the Voronoi diagram as a plana r graph, G, with some edges 
extending out to innit y. We add a point at innit y q represen ting innit y and 
connect edges that extend to innit y to this point as shown in Figur e 2. Note that 
the resulting graph G is still planar. 
The number of vertices in G is nv + 1; the number of edges is ne, and the number 
of faces is n. By Eulers formula, we have 
nv +1  ne + n =2. 
Since we know that vertices will have at least 3 edges incident to them, we obtain, 
by summing the degrees over all vertices, that: 
d(v)=2ne  3(nv + 1). 
vertices v 
23-3</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Figur e 7: Site event. Parabolae shown with thin lines and the beach line shown as a 
thick line. 
2.3.2 Data Structur es 
In order to construct a diagram, we will describ e three data structures: 
1. Event queue: 
Constru ct a prior ity queue containing events. The key of an event is its y-
coordinate. For a site event the y-coordina te is the y-coordina te of the asso
ciated point. For a circle event, this is the position of the sweep line which is 
(lower) tangent to the circle. 
We rst insert the n site events into the priority queue , as we know the y 
coordinate of all the points. Conside r moving the line down and processing 
events as they occur. Circle events are dened by looking at three consec utive 
segmen ts of the beach line. Every time we introduce a new segmen t in the 
beach line, as happens in a site event, we potentially creat e two new circle 
events (potentially, since three consecutiv e segmen ts create a circle event only 
if the 3 points are distinct) . We may also need to delete some circle events. 
Let us consider the additio n shown in Figure 7. We will have removed the 
potential circle event pi pj pk and added potential circle events pi pj pl and 
pj pl pk. Note that the deleted event can be thoug ht of as a fake event because 
it was remo ved before it really happ ened and was processsed. Still such a circle 
event was added to the event queue and then removed. There is at most one 
deleted (fake) circle event for each site event processe d. Notice that the number 
of real circle events is equal to the number of vertices of the Voronoi diagram, 
nv  2n  5. 
Any circle event that is processed is real, and leads to a segmen t of the beach 
line disappearing. In terms of Figures 6 and 8, we would take p1 p2 p3 to p1 p3. 
23-8</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>of a breakpoint. Given a breakp oint as an ordered pair (pi,pj ) and a sweep 
line, we can easily comp ute the x positio n of the break point and decide if we 
must move to the right or to the left. In a circle event, we have three parabola 
segmen ts and must remove the middle one. This is a delete operation. Thus 
there are a constan t number of BST operations per circle or site event. Using 
a BST with amortized cost O(log n) time per operation, main taining the beach 
line is therefore O(n log n) time. 
3. Voronoi Diagram: 
Let us replace each edge (shared by 2 cells) of the Voronoi diagram with two 
corresponding directed half-e dges which are twin to each other. Each half edge 
corresponds to one of the two cells, and each is orien ted coun terclockwise (with 
respect to its cell). For each half-edge, we dene pointers: 
 to its twin, 
 to the next half-edge on the cell, 
 to the previo us half-edge on the cell. 
From a given vertex we can follow the half-edges around a cell; by calling twin, 
we can move between cells and we can for example enumera te all half-edges 
inciden t to a vertex. 
Let us conside r how to modify this structure upon processing a site (Figure 
7) and circle (Figure 8) events. In a site event, the two new break points are 
equidista nt from pj and pk, and are part of an edge of the Voronoi diagram. 
This will create two new half-edges. In a circle event we link the half edges that 
meet to construct the diagram. Thus there are a linear number of operations 
on this data structure as wll. 
In summa ry, the rst structure requires a linear number of operatio ns each taking 
O(log n) time. Similar ly, for the second data structure, with a balanced BST. The 
last one requires constant time per event, for a linear number of events. Henc e the 
total time to construct a Voronoi diagram is O(n log n). 
We can show this is optimal because the Voronoi diagram of the set of points 
given by P = {(xi, 1)} solves the problem of sorting P , hence the diagram must 
take at least O(n log n) time to sort. 
Note we use 1 since we have assumed throughout this that we are not in the 
purely degenerate case in which all points are colinear; one can show that this is 
indeed the only case in which the Voronoi diagram has innite lines and no vertices. 
23-10</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Consider the set of planes tangent to each point in P . The intersection of the 
upper half spaces of these planes gives a polyhedral set Q whose projection back 
to R2 gives the Voronoi diagr am in the following sense : the projection of the facets 
(resp. edges, vertices) of Q gives the Vornoi cells (resp. edges, vertices ) of the Voronoi 
diagram. This computa tion can be done in O(n log n) time since this calculation is 
the geometr ic dual of the convex hull comput ation. 
If, instead, we were to compu te the convex hull of P  (rather than the halfs
paces tangen t to the paraboloid at P ) and project it back to R2, we would obtain 
a straight-line drawing on P (dua l to the Voronoi diagram) known as the Delaunay 
Triangulation , see problem set. 
2.3 Sweep Line Algorithm 
The idea of a sweep line algorithm is to advance a line (in 2D) or a plane (in 3D) 
down throug h space, processing events as they occur. We will construct the Voronoi 
diagram as we sweep the line from top to bottom, and at any instance we will only 
have needed to consider points at or above the sweep line. 
We cannot construct the entire diagr am above the sweep line, but we can construct 
pieces of it. If we look at a single point above the line, pi, for some points, they will 
assuredly be closer to it than to any points below the sweep line. This forms a 
parabola C(pi) dene d by the points equidis tant from the point and the sweep line. 
We can nd the parabola associated with each of the points. For any point that is 
above some parabola, we can correctly assign it to its Voronoi Cell. 
Figur e 4: A set of parabolae C(pi) associated with four points pi. Parabolae are 
denot ed with thin lines, the beach line with a thick line, and the associated sweep 
line with a thick dashed line. 
Denition 3 (Beach line) We dene a Beach Line as the lower envelop e of all 
parabolae C(pi) for all points above the sweep line. A beach line is shown in Figur e 
4. 
23-5</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Figur e 6: Illustra tion of points q on an edge of a Voronoi diagram as constr ucted by 
a moving sweep line. 
Well see that this is the only way of creating a new segmen t in the beach line, 
so this implies that the total number of segmen ts in the beach line is at most 
2n  1 (1 segment for the rst site event, and 2 more for each subsequen t site 
event). 
2. A Circle Event occurs when lowering the beach line causes a segment to disap
pear from the beach line. This bounda ry case is illustra ted in Figure 8, which 
can be compa red to Figure 6 to show the efect of a moving sweep line. 
When a segment disapp ears, we have disco vered a new vertex in the Voronoi 
diagram. Indeed, when a circle event occurs, we must have the three closest 
points equidista nt to the vertex, and thus we have a vertex by Lemma 1. 
The center of the circle is determined by p1, p2 and p3 (corresponding to 3 
consecutiv e segments on the beach line), and the circle event will happ en when 
the sweep line is tangent to the circle (below it). When a circle event happens, 
the beach line is modied in the following way: 
p1 p2 p3  p1 p3 
. 
Claim 3 The only way for the beach line to change is through a site event or a circle 
event. In other words, these are the only ways to create and remove segments. 
We will not forma lly prove this  this is intuitive. 
23-7</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Refer ences 
[1] S Fortune. A sweepline algorithm for voronoi diagrams. In SCG 86: Proceedings 
of the second annual symp osium on Computational geometry, pages 313322, New 
York, NY, USA, 1986. ACM. 
23-11</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Figur e 8: Circle event. Parabolae shown with thin lines, Voronoi diagram with thick 
lines, and the sweep line with a thick dashed line. 
In general, we can write this as Go from pi pj pk pl pm to pi pj pl pm. We may 
need to delete up to two circle events corresp onding to the lost segm ent and 
add two new events, corresp onding to the new order. In this example, we are 
deleting circle events pi pj pk and pk pl pm and adding pi pj pl and pj pl pm (or 
a subset of them if some of the indices are equal). We are always adding and 
deleting a constant number of events (for each site event and real circle event), 
thus the total number of addit ions and deletio ns to the priority queue will be 
linear . Since we must process O(n) events corresponding to O(n) priority queue 
operations, the total runtime will be O(n log n). 
2. Beac h line encoding: 
We keep track of the points corresp onding to the parabola segmen ts constitut ing 
the beach line and the breakp oints pi pj by creating a binar y search tree in which 
points are leaves and internal nodes are breakp oints. 
Note that this is an extension of the standar d binary search tree because we 
have two dierent types of nodes (parabola segments and break points). This 
prevents us from directly using a splay tree, since the splay actio n permutes the 
leaves and branc hes of the tree. One way to deal with this is to forget about 
parabola segments, and keep track of the breakpoints (as pairs of points), keyed 
from left to right. 
When a site event occurs, we need to be able to locate the x value in the 
beach line. To use a binary search tree, we thus need to be able to perform 
binar y compariso ns to determine if the desired x value is to the left or right 
23-9</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Denition 4 (Breakp oint) A breakpoint q is a point on the beach line that belongs 
to at least two parabolae. 
Figur e 5: Sample beach line illustrating multiple break points origin ating from the 
same parabola 
The beach line is a series of segmen ts of parabolae. A breakpoint q corresponding 
to the parabolas C(pi) ad C(pq) must be equidista nt from both pi and pj since we 
know that d(q,pi)= d(q,sweep)= d(q,pj ). Furthermor e, no other point of P is closer 
to q. Thus, by Lemma 1, q is part of an edge of the Voronoi diagram, and is part of 
the bisector between pi,pj . An example is shown in Figure 6. 
We will keep track of which pi the breakpoints are associated with in order. Note 
a beach line could have several segmen ts from the same parabola, as illustr ated in 
Figur e 5. 
2.3.1 Events 
As we sweep the line, we are not going to keep track of the precise location of the 
beach line (as it constan tly chang es) but we will just keep track of the points pi 
corresponding to the parabola segments of the beach line from left to right. Several 
events can happ en that modify this sequence of points pi. 
1. A Site Event occurs when the sweep line goes through a new point pl. This 
results in additition of an arbitr arily narrow parabola around pl to the beach 
line. A sample site event is shown in Figur e 7. If pl intersects the parabola 
associated with pj , we could write the change in the sequence of points as: 
pi pj pk  pi pj pl pj pk 
Note we insert exactly one segmen t per site event, so there are n in total. Notice 
that each such addition increases the number of segments by 2, as shown above. 
23-6</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Com bining this with Eulers formula, we get: 
2(nv + 1) + 2n  4 + 3(nv + 1) 
or 2n  5  nv. Using this in Eulers formula, we now get 
ne = nv  1+ n  3n  6. 
2 Computation of Voronoi Diagram s 
2.1 Introducti on 
There are two prima ry algorithms we want to introduce. Both of these will be shown 
to compute the Voronoi diagram in time O(n log n). First, we can reduce the com
puta tion of the Voronoi diagram to that of a convex hull in R3, which is computa ble 
in time O(n log n); this is our rst algorithm. Secondly, we will review the sweep line 
algorithm of Fortune [1]. 
2.2 Convex Hull 
Figur e 3: Projectio n of a point onto a paraboloid in R3 . To use the convex hull to 
comput e the Voronoi diagram, this projection is done for all points in the set of points 
for which we want to compute the Voronoi diagram. 
Supp ose we have a set P  R2 and we want to compute the corresponding Voronoi 
diagram. Let us consider the set P  = {(xi,yi,xi 2 +yi 2):(xi,yi)  P }. This projection 
onto a parabola is shown in Figure 3. 
23-4</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6.854 Advanced Algorithms Decem ber 3, 2008 
Lecture 23 
Lecturer: Michel X. Goemans 
1 Vorono i Diagrams 
1.1 Introducti on 
Supp ose we are given a set P of points in the Euclidean plane, and we are interested 
in the problem of, given a point x, nd the closest point of P to x. One approa ch 
to this problem is to divide the plane into regions associated with each pi  P for 
which x is closest to pi. Finding these regio ns in two dimens ions is the problem of 
constru cting the Voronoi Diagram. One applicat ion of this structur e is to compute 
the mimumum spanning tree of a comple te graph of n vertices in the Euclidean plane 
in time O(n log n). 
1.2 Denitions 
We will focus on the two-dimensiona l case. We are given a set 
P = {p1,p2,...,pn} R2 
and we want to partitio n the plane into regio ns which corresp ond to points which are 
closest to a specic point. 
Figur e 1: Voronoi Diagram (solid lines) for four points p1,p2,p3,p4. 
23-1</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Denition 1 (Voronoi Cell) Given a set of points in R2 , P = {p1,p2,...,pn} 
R2, a Voronoi Cell V (pi) is dene d by: 
V (pi)= {x : d(p i,x) &lt;d(p j ,x) j =i}. 
Anot her way to dene a Voronoi Cell is by dening h(p i,pj) to be the halfpla ne 
containing pi dened by the bisector of pi and pj . A cell is then dened as: 
V (pi)= h(p i,pj ). 
j=i 
This impies that every cell is convex and is a (convex) polygonal regio n with at most 
n  1 sides . 
Denition 2 (Voronoi Diagram) A Voronoi Diagr am is a collection of Voronoi 
cells that covers R2 . 
1.3 Motivation 
Why is a Voronoi Diagram useful? If the points repres ent restations, the Voronoi cells 
represen t the partition of the plane into regiosn which are closer to each restat ion. 
More generally, given a point in a plane, it is useful to know the point from a set of 
points that is closest to it. Of course, this also requires a data structur e to be able to 
answ er the point location problem of, given x, ndin g the Voronoi cell that contains it. 
We will only learn how to constr uct the Voronoi diagram, not how to build a query 
datastructur e for it. . 
Having such a diagr am is useful for many problems. For example , a Voronoi 
diagram allows comput ation of the Euclidian minim um spanning tree on a set of 
points in O(n log n) time, see the problem set. 
1.4 Properties 
The Voronoi cells are all disjoint and their closur es cover the entire plane. The 
Voronoi diagram will consist of edges (possibly semi-innite, extending to innit y) 
and vertices where 3 or more of these edges meet; these vertices will be equidista nt 
to 3 or more points of P . One can characterize the vertices and the edges in the 
following way: 
Lemma 1 1. A point q  R2 is a vertex of a Voronoi Diagram  there exists 
an empty circle (i.e. its inter ior is empty) center ed at q having at least 3 points 
of P on its boundary. 
2. Part of the bisector between pi and pj is an edge of the Voronoi diagr am  
there exists an empty circle center ed at a point q having precisely pi and pj (and 
no other point) on its boundar y. 
23-2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Dynamic trees (part 1)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec7/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>1 18.415/6.854 Advanced Algorithms	 September29,2008 
Lecture 7 -Dynamic Trees 
Lecturer: Michel X. Goemans 
Overview 
In this lecture, we discuss dynamic trees, a sophisticated data structure introduced by Sleator and 
Tarjan. Dynamic trees allow to provide the fastest worst-case running times for many network ow 
algorithms. In particular, it will allow us to eciently perform the Cancel operation in the Cancel 
and Tighten algorithm. Dynamic trees build upon splay trees, which we introduced in the previous 
lecture. 
Dynamictrees manage a set of node-disjoint(not necessarily binary) rooted trees. With each 
node v is associated a cost. In our use of dynamic trees, the cost will be coming from the edge 
(p(v),v), wherep(v)denotes the parent of v; the cost of the root in that case will be set arbitrarily 
large(largerthanthe cost of any other node), say +. 
Figure 1: Example of Dynamic Tree. 
Dynamic trees will support the following operations: 
	make-tree(v): Creates a tree with a single node v, whose cost is +. 
	find-root(v): Finds and returns the root of the tree containing the node v. 
	find-cost(v): Returns the cost of node v. (This may sound like a trivial operation, but 
in fact there is real work to be done, because we will not explicitly maintain the costs of all 
nodes.) 
	find-min(v): Finds and returns the ancestor of w of v with minimum cost. Ties go to the 
node closest to the root. 
	add-cost(v, x): Adds x to the cost of all nodes w onthepathfrom find-root(v)to v. 
	cut(v): Breaks the rooted tree in two by removing the link to v from its parent. The node v 
is now the root of a new tree, and its cost is set to +. 
	link(v, w, x): Assumes that(1) w is a root, and(2) v and w are not in the same tree, i.e. 
find-root(v)/negationslashw. Combinestwotreesby adding anedge(v,w),i.e.p(w)= v. = Sets the cost 
of w equalto x. 
We will later show that all of these operations run in O(logn)amortized time. 
7 -Dynamic Trees-1</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>2 v v 
Figure2: cut(v)operation. 
LINK 
W 
V 
COST(W) = X 
Figure3: link(v,w,x)operation. 
Theorem 1 The total running time of any sequence of m dynamic tree operations is O((m + 
n)logn), where n is the number of nodes. 
We defer the proof of this theorem until the next lecture. 
Implementation of Cancel with dynamic trees 
Recall the setting for the Cancel step in the algorithm Cancel and Tighten for the minimum cost 
ow problem. We have a circulation f and node potentials p in an instance dened on graph G. 
Recall that an edge (v,w) is admissible if cp(v,w) &lt; 0, and the admissible graph (V,Ea), is the 
subgraph of Ef (the residualgraphcorresponding to ourcirculation) containing only the admissible 
edges. Our aim is to repeatedly nd a cycle in the admissible graph and saturate it. Each time we 
do this, all of the saturated edges disappear from the graph. Also recall that no edges are added 
to the admissible graph during this process, because any new edge in the residual graph must have 
positive reduced cost and are therefore is not admissible. 
We representtheproblem withdynamictrees, wherethe nodesinthedynamictrees correspond 
to nodes in G and the edges of the dynamic trees are a subset of the admissible edges. We maintain 
two(disjoint) sets of admissible edges: those which are currentlyinthedynamictree, andthose 
which still need to be considered. The cost of a node v will correspond to the residual capacity 
uf (p(v),v) of the edge(p(v),v), unless v is a root node, in which case it will have cost +. We 
will also mark some of the roots (denoted graphically with a ()) to indicate that we dealt with 
them and concluded they cant be part of any cycle. For the edges not in the dynamic tree, we also 
maintain the ow value. (We dont need to maintain the ow explicitly for the edges in the trees, 
since we can recover the ow from the edge capacities in G and the residual capacity.) 
Tosummarize,webeginwith aset of n singletontrees. All of theedgesstart outintheremaining 
pool. Ineachiteration,wetry to nd anadmissibleedgeleading totheroot r of oneof thedynamic 
trees. If we fail to nd such an edge, this implies there are no admissible cycles which include r, 
7 -Dynamic Trees-2</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Figure 4: Decomposition of rooted tree. 
to the edges on these paths as solid edges, and we will refer to the remaining edges as dashed 
edges, or middle edges.Eachpathisdirectedfromits tail (highestinthetree)toits head lowest 
inthetree). 
Thereare manypossible waystopartition atreeinto solidpaths. Forinstance,if we aregivena 
solid edge and a dashed edge which are both children of a single parent, we can swap the solid and 
dashed edges. Thisfollowsfromthebasic observationthat,for any middle edge(v,w),w isthetail 
of a solid path. This operation is known as splicing as shown in Figure 5. 
Splicing 
Figure 5: Splicing in the rooted tree. 
In a dynamic tree, each solid path is represented by a splay tree, where the nodes are sorted 
in increasing order from the head to the tail, as shown in Figure 6. In other words, the node with 
smallestkeyisthehead(thelowestinthetree),and thenodewithlargestkeyisthetail(thehighest 
inthetree) 
In addition, we will maintain links between the dierent splay trees. The root of each splay 
tree is attached to the parent of the tail of the path in the rooted tree, as shown in Figure 7. For 
example,the edge(e,f)inthe original rooted treebecomesthe edge(e,i)linking e to the root i of 
the splay tree corresponding to the solid path f  i. The entire data structure  with the splay 
trees corresponding to the same rooted tree being connected to each other  forms what is called 
a virtual tree. Any given node of the virtual tree may have at most one left child and at most one 
right child(of a splay tree), as well as any number of children attachedby dashed edges. Children 
attached by dashed edges are known as middle children, and we draw them in between the left 
and right children. 
Noticethat wecanreconstructtherooted treefromthevirtual tree. Each splay treecorresponds 
to a solid path from the node of lowest key to the node of highest key. In addition, for any middle 
7 -Dynamic Trees-4</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>f 
e 
d 
c 
b 
a c 
b 
a e 
f d 
HEAD TAIL 
Figure6: Representation of solidpathfromhead totailinBST(Splay Tree). 
a b c d e 
f 
i g 
h b a c e 
i 
f 
g 
h d 
Figure 7: Rooted tree on the left and corresponding virtual tree on the right. 
edge,weget anedgeof theoriginal rooted tree; forexample,to(e,i)inthevirtualtree,corresponds 
the edge(e,f)in the original tree where f is the node with highest key in the splay tree in which i 
resides. 
Note that there are many dierent ways to represent rooted trees as virtual trees, and we can 
modify virtual trees in various ways which dont aect the rooted trees. 
Inparticular,wedenethe Expose(v)operation, whichbringsagivennode v to the root of the 
virtual tree. This operation involves three main steps: 
1. Make sure that the path from v to the root only uses roots of splay trees. This can be done 
by performing splay operations whenever we enter a new splay tree. 
2. Makesurethatthepathfrom v to the root consists entirely of solid edges. We can ensure this 
through repeated splicing. 
3. Do the splay operation to bring v tothetop of the resulting splay tree. Thisisjustied since 
v is now in the same splay tree as the root of the original rooted tree. 
7 -Dynamic Trees-5</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>and so we mark it and remove it from consideration. Suppose, on the other hand, that we do nd 
an edge(w,r) leading into the root. If w isin adierent tree, wejoin the twotreesby adding an 
edgeconnecting w and r. On the other hand, if w and r arepart of the sametree,it means wehave 
found a cycle. In this case, we push ow along the cycle and remove the saturated edges from the 
data structure. 
In more detail, we keep repeating the following procedure as long as there still exist unmarked 
roots: 
 Choose an unmarked root r. 
 Among admissible edges, try to nd one which leads to r. 
 CASE1: thereis no such(v,r) Ea. 
 Mark r, since we know it cannot possibly be part of a cycle. 
 Cut all the children v of r. 
 Set 
f(r,v)	 u(r,v) uf (r,v) 
= u(r,v) find-cost(v) 
 CASE 2: there is an admissible edge (w,r) from a dierent tree, i.e. find-root(w)=/negationslash
r. 
 Linkthetwotrees: link(w,r,u(w,r) f(w,r)) 
 CASE 3: there is an admissible edge (w,r) from the same tree, i.e. find-root(w)= 
r. 
 Weve found a cycle, so push ow along the cycle. The amount we can push is 
 =min(u(w,r) f(w,r),find-cost(find-min(w))) 
 add-cost(w, )
 Increase f(w,r)by 
 If f(w,r)= u(w,r),then(u,r)is inadmissible, so we get rid of it.
 While find-cost(find-min(w))=0:
z  find-min(w)
f(p(z),z) u(p(z),z)
 cut(z)
The last while loop is to delete all the edges that became inadmissible along the path from r to w. 
2.1 Running time 
In a cancel step, we end up cancelling at most O(m) cycles, where m is the number of edges. In 
addition, each edgegets saturated at most once(ifitdoes,itbecomesinadmissible); thereforethe 
number of cut(z) and find-min(w) over all cases 3 is O(m). Thus the total number of dynamic 
tree(and also other arithmetic or control) operationsis at most O(m). Hence, by Theorem 1, the 
running time of each Cancel operation is O((m + n)logn)= O(m logn). The overall running time 
of Cancel-and-Tighten istherefore O(m2n log2 n)(stronglypolynomialrunning timebound) or 
O(mn logn log(nC)). 
3 Dynamic trees implementation 
We nowturntotheimplementation ofdynamictrees. Here wepresentthedenitions; we will cover 
the running time analysis in the next lecture. The dynamic trees data structure is a collection of 
rootedtrees. Wedecompose each rootedtreeinto a set of node-disjoint(directed) paths, as shown 
inFigure4. Each nodeisinprecisely onepath(possibly containing that node only). We will refer 
7 -Dynamic Trees-3</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>LP: duality, geometry, simplex</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec10/</lecture_pdf_url>
      <lectureno>10</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>Figure 1: Physical visualization of the dual with n = 2 (two dimension s), m = 6 (six hyperplanes), 
and b as gravity. The dual is maximize d when our bT y ball is at the lowest point of the polyhedr on. 
minimize the primal. For this, we will show that the value cT x equals bT y, and therefore by weak 
duality, this will mean that x is a minimizer for the primal. The value cT x is: 
c T x = cj xj = (ajT y)xj , 
j j 
since xj is non-zero only where aT
j y = cj (a non-zero force is only exerted by a wall on our ball if 
the ball is touching that wall), and thus 
c T x = (ajT y)xj = y T ( aj xj )= y T b = bT y. 
j j 
1.2 Rules for Writing a Dual 
So far, we have dealt only with the dual of the standard primal linear progr amming problem, 
minimizing cT x such that Ax = b and x  0. What if we are confronted with a non-stand ard linear 
program, such as a progr am that involves inequalities on the aij xj , or non-positivity constraints on 
the xj ? We have two option s. The rst is to massage the linear progr am into the standard primal 
form, immediat ely convert to the standar d dual, and then potentially massage the dual problem into 
a form more suitable to our original problem. This can be a long, frustrating process, however, and 
so instead we present a set of stand ard rules for convertin g any linear program into its dual form. 
Consider a linear problem with the objective of minimizing j cj xj subject to the following 
constrain ts: 
 
= bi i  I=
 bi i  I (1)
 aij xjj  bi i  I 
xj  
 
  0 j  J+
 0 j  J (2)
 R j  J0. 
Earlier, the way we obtained the dual was to get a lower bound (or an upper bound if it was a 
maximization problem) on the objective function of the primal, and to maximize this upper bound. 
We claim that the same process leads to the dual of maximizin g i biyi subject to the constrain ts: 
10-2</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>aij yi  cj j  J+
 cj j  J (3)
i = cj j  J0 
yi  
 
  0 i  I 
 0 i  I (4) 
 R i  I= 
Weak duality is pretty straightforward. Constraints (4) on yi guarantee that, when multiplying 
constrain t (1) by yi and summing them over i, we get 
yi aij xj  yibi. (5) 
i j i 
Similarly, constraints (3) togeth er with constrai nts (2) imply that 
cj xj  xj aij yi. (6) 
j j i 
The left-h and-side of (5) being equal to the right-hand-side of (6) (after rearr angin g the summation ), 
we get weak duality that 
c T x  bT y. 
And strong duality also holds provided that either the primal or the dual has a feasible solution. 
1.3 Complementary Slackness 
Com plementary slackness allows to easily check when a feasible primal and dual soluti ons are simul
taneously optimal. Consider the primal 
min{c T x : Ax = b,x  0}. 
Consider an altern ative denition of the dual LP obtain ed by adding slack variables: 
max{bT y : AT y + Is = c,s  0}, 
where s  Rn . Given a feasible primal solution x and a feasible dual soluti on (y,s), we see that the 
dierence in their value is 
c T x  bT y = s T x + y T Ax  y T b = s T x, 
and this quantity better be 0 if x is optimum for the primal and (y,s) is optimal for the dual. Notice 
that x  0 and s  0, and therefore xT s = 0 if and only if xj sj = 0 for all j. Thus, for the 2 
soluti ons to be simultaneously optimum in the primal and in the dual, we need that, for all j, xj =0 
whenev er sj &gt; 0 (or equivalently that sj = 0 whenev er xj &gt; 0). 
Summarizing, we have: 
Theorem 1 Let x be feasibl e in the primal, and (y,s) be feasibl e in the dual. Then the following 
are equival ent. 
1. x is optimal in the primal, and (y,s) is optimal in the dual, 
2. For all j: x 
j &gt; 0=  sj =0, 
10-3</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>For all currently known pivoting rules, there is at least one instance that will cause the simplex 
method to run in exponen tial time. (This is in contrast with the simplex method in practice 
for which the number of iteration s is usual ly good. A partial explanati on of this sharp contrast 
between the worst-case behavior and a typical behavior is highligh ted in the work of Spielman 
and Teng on smoothed analysis.) 
We will cover other algor ithms that will guarantee a polynomial running time in the worst-cas e; 
they will however not proceed from vertex to vertex of the polyhedral set. 
There is a lower bound on the number of iterations of the Simplex Metho d, which is the number 
of edges in the path from the starti ng vertex of P to the optimum vertex of P . For a given P , this 
lower bound will be the diameter of P , the maxim um over all pairs of vertices of the length of the 
shortest path between them . In 1957, Hirsch conjectured that the diameter of a polyhedral set is 
upper bounded by n  d, where d is the dimension of the space, and n is the number of hyperplanes 
den ing P . While this has not been proven true in the general case, the following results have been 
found: 
	The conjecture is not true in the unbound ed case, name ly there exist unbounded polyhedra 
with diame ter n  d +  d 
5 . 
	No polynomial bound on the diame ter is known for the general case (even for just bound ed 
polyhedra). 
	Kalai and Kleitman deriv ed a subexponen tial bound nO(log d) on the diameter. 
	If the Hirsc h Conjecture can be proven for n =2d, then the conjecture holds for all n. 
	The Hirsch Conj ecture is true for polytopes with all their vertce s in {0, 1}d . 
10-6</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>2 3. For all j: x 
j s 
j =0, 
4. x 
j s 
j =0. 
j 
For a general pair of primal-du al linear programs as given in (1)-(2) and (3)-(4), complem entary 
slackness says that, for x to be optimal in the primal and for y to be optimal in the dual, we must 
have that 
1. yi = 0 whenev er j aij xj =bi and, 
2. xj = 0 whenev er i aij yi =cj . 
The Geometry of Linear Programm ing 
We now switch gears and discuss the geometry of linear programm ing. First, we den e a polyhedr al 
set P = {x  Rn : Ax  b} as the nite intersection of halfspaces. We then dene a vertex of 
polyhedral set P to be any x  P such that x + y  P  x  y  P =  y = 0. Intuitively, a vertex 
is a corner of a polyhedral set. We can state this geometric den ition also algebraically . Given an 
index set J {1, 2,  ,n}, AJ denot es the m |J| submatr ix of A consis ting of all columns of A 
indexed by J. 
Lemma 2 For P = {x : Ax = b,x  0} and x  P , x is a vertex of P if and only if AJ has linearly 
indep enden t colums for J = {j : xj &gt; 0}. 
Proof: For both directions, we prove the contrapositive. 
  : Assumin g x is not a vertex implies that y =0: x + y,x  y  P . Therefore A(x + y)= 
b,A(x  y)= b, which impli es that Ay = 0. However, because membership in P requires points to 
be non-negativ e, we have that if xj = 0 then yj = 0. Thus, if we let w = yJ (i.e. w corres ponds 
to the comp onents of y in J), we see that w = 0 and  AJ w = 0, which implies that AJ has linearly 
dependent columns. 
: If AJ has linearly dependent columns, then w =0: AJ w = 0. This implies you can construct  
a y via zero padd ing such that y = 0 and Ay =0,yj = 0 for j  J. Thus, A(x + y)= A(x  y)= b 
for any   R. We also note that 
xj  yj  0 if   xj , which is strictly greater than 0. There fore, |yj | 
if we choose  = min xj , we have that x  y  P , and thus x is a not a vertex of P .  
j:yj =0
|yj |
We can take the notions in this lemm a a step further by introducin g the notions of a basis, a 
basic soluti on, and a basic feasible soluti on. For what follows, we assume that rank(A)= m (if 
thats not the case, then either there is no solution to Ax = b and our problem is infeasible, or there 
exists a redundant constrain t (possibly more than one) in Ax = b which can be removed). 
Deniti on 1 For a polyhedral set P = {x : Ax = b,x  0}, a basis B is a subset of {1...n} such 
that |B| = m and AB is invertibl e (i.e. rank(AB )= m). 
Deniti on 2 x is a basic solution of P if  basis B : xB = A1b,xN =0 for N = {1...n}\ B.B 
Note that by this den ition, AB xB + AN xN = b must be true, but x could be negative and 
therefor e infeasible. 
Deniti on 3 x is a basic feasibl e solution (bfs) if it is a basic solution such that x  0. 
We are now ready to prove the following theorem relating vertice s to basic feasible solutions. 
10-4</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>3 Theorem 3 Given a polyhedral set P = {x : Ax = b,x  0} such that rank(A)= m, and a point 
x  P , x is a vertex of P if and only if it is a basic feasible solution of P . 
Proof: Will be provided in Lecture 11.  
There are several notab le remarks to make pertaining to this theorem : 
	The vertex to basic feasible solution relation ship is one-to-m any, or in other words, there may 
be multiple basic feasible solut ions that correspond to a single vertex. 
	The number of vertices of P is less than or equal to the number of bases of P . This follows from 
the rst remark, and the fact that some bases may be infeasible. Therefor e, the number of 
nvertice s of P is upper bound ed by m . However, a stricter upper bound has been shown using 
a more detailed analysis, namely the number of vertices of P is upper bounded approximately 
mby n 2 . m 
2 
We now know that nding basic feasible solut ions of P is equivalent to nding vertices of P . Why 
is this importan t? Because there must an optimum solut ion to our linear programming problem that 
is a vertex of the polyhedral set den ed by the linear constraints. More formally , 
Theorem 4 Given a polyhedral set P = {x : Ax = b,x  0}, if min{cT x : x  P } is nite (the 
program is feasible and bounde d), and x  P , then  vertex xofP : cT x  cT x. 
Proof: Will be provided in Lecture 11.	  
This theorem directly leads us to the insigh t behind the Simplex Metho d for solving linear 
programs by nding the best vertex. 
Sketch of the Simplex Method 
Here is a very basic sketch of how the simplex method works. 
1. Choose a basic feasible soluti on x corres ponding to the basis B. 
2. While x is not an optimal solution, choose j and k such that the new basis B 
T T	= B \{j}{k}
forms a bfs x with cx  cx. 
There are several important remarks to make about this method: 
	It is not clear that j and k will always exist. But they do, and this can be shown. 
	As dened, x and x will either be equal or will be adjacent vertices on P . 
	The reason it is called a metho d and not an algor ithm is because we havent specied yet 
how to choose j and k if several choices exist. The choice of j and k is referred to as a pivoting 
rule; many pivoting rules have been proposed. 
	As such, there is no guarantee that cT x &lt;cT x, namely we could have cT x = cT x; in fact 
we could even have x = x since we could switch from one basis to another repres enting the 
same vertex. There is therefor e the risk that we repeat the same basis and the algori thm 
never termin ates. And this can happ en for some of the pivoting rules. There exist however 
anticycling pivoting rules which guarantee that the same basis is never repeated. With such a 
rule, the simplex method will terminate since there are nitely many bases. 
	The running time of the simplex method depends on the number of bases consid ered before 
nding an optimal one. 
10-5</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6. 854 Advanced Algorithms Octob er 8, 2008 
Lecture 10 
Lecturer: Michel X. Goemans 
Last lecture we introduced the basic formulation of a linear programm ing problem, namely the 
problem with the objective of minimizing the expression cT x (where c  Rn,x  Rn) subject to 
the constraints Ax = b where A  Rmxn,b  Rm) and x  0. We then introduced the dual linear 
program, with the objective of maximiz ing bT y, subject to the constraints that AT y  c. Eventually, 
we were able to relate the two forms via the Theorem of Strong Dual ity, which state s that if either 
the primal or the dual has a feasible solution then their values are equal: 
w := min{c T x : Ax = b,x  0} = max{bT y : AT y  c} =: z. 
Today, we further explore duality by justifying the Theorem of Strong Duality via a physical 
argument, introducing rules for constru cting dual problems for non-standard linear programm ing 
formulation s, and further discussing the notion of compleme ntary slackness mentioned in the last 
lecture. We then shift gears and discuss the geom etry of linear programming, which leads us to the 
Simplex Method of solvin g linear programs . 
1 The Dual 
1.1 Physical Justi cati on of the Dual 
Consider the standard dual form of a linear program. The set of feasible solutions y that satisfy the 
constrain ts AT y  c form a polyhedr on in Rn; this is the interse ction of m halfspace s. Consider a 
tiny ball within this polyhedron at position y. To maximize bT y, we move the ball as far as possible 
in the direction of b within the con nes of our polyhedron . This is analogou s to having a force , say 
gravity, acting on the ball in the b direction. 
We now switc h over entirely to the physical analogy . At equilibrium, the ball ends up at a point 
y maximizing bT y over AT y  c, and the gravity force b is in equilibrium with the forces exerted 
again st the ball by the walls of our polyhedron. These wall forces are normal to the hyperplanes 
den ing them, so for the hyperplane dened by ajT y  c (where aj is the jth column of A), the force 
exerted on the ball can be expressed as xj aj for some magnitude multiplier xj  0. As stated 
previously , our ball is at equilibrium (there is no net force on it), and so we nd 
b  xj aj =0. 
j 
We also note that for any wall which our ball is not touching, there is no force exerted by that wall 
on the ball. This is equivalent to saying 
xj =0 if ajT y&lt;cj . 
We now argue that these multipliers xj form an optim um solution to the primal linear program. 
We rst note that  
b  xj aj =0 
j 
is equivalent to Ax = b, and that the multipliers xj are either zero or positiv e, and thus x  0. 
This shows that our xj s yield a feasible solution to the primal, now we need to prove that the xj s 
10-1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Splay trees</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec6/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>7</slideno>
          <text>3.3 Amortized Cost of BST operations 
We now need to show how to implement the various BST operation s, and analyze their (amortize d) 
cost (still with the weights set to 1). 
3.3.1 Find 
Finding an element in the splay tree follows the same behavior as in a BST. After we nd our node, 
we splay it, which is O(log n) amortized cost. The cost of going down the tree to nd the node can 
be charged to the cost of splaying it. Thus, the total amortize d cost of Find is O(log n). (Note : if 
the node is not found, we splay the last node reached.) 
3.3.2 Find-Min 
This operation will only go down the left children, until none are left, and this cost will be charged 
to the subsequent splay operation . After we nd the min node, we splay it, which takes O(log n) 
amortize d cost. The total amortize d cost is then O(log n). 
3.3.3 Find-Max 
The process for this is the same as for Find-Min , except we go down the right child. The total 
amortize d cost of this is O(log n) as well. 
3.3.4 Join 
Given two trees T1 and T2 with key(x) &lt; key(y) x  T1,y  T2, we can join T1 and T2 into one tree 
with the following steps: 
1. Find-Max (T1). This makes the max element of T1 the new root of T1. 
2. Make T2 the right child of this. 
The amortized cost of the rst step is O(log n). For the second step, the actual cost is 1, but we 
need to take into account in the amortized cost the increase in the potential function value. Before 
step 2, T1 and T2 had a potential function value of (T 1) and (T 2). After it, the resulting tree has 
a potential function value  (T 1)+ (T 2) + log n, since the rank of the new root is  log(n). So 
the amortized cost of Join is O(log n). 
3.3.5 Split 
Given a tree T and a pivot i, the split operation partition s T into two BSTs: 
T1 : {x | key(x)  i}, 
T2 : {x | key(x) &gt;i}. 
We split the tree T by performin g Find(i). This Find will then splay on a node, call it x, which 
brings it to the root of the tree. We can then cut the tree; everything on the right of x belongs to 
6 -Splay Trees-7</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Figure 5: When splaying node 1, the resulting tree has half its original heigh t. 
3 Running -Time Analysis 
3.1 Potential Functi on 
We den e a class of potential functions for the amortized analy sis of operations on a splay tree. The 
potential function depends on weights that we can choose. For each node x in the tree, make the 
following den itions: 
	T (x) is the subtree rooted at x (and it inclu des teh node x itself), 
	weight function: w(x) &gt; 0 is the weight of node x (we can choose what this is; well often take 
w(x) = 1 for all nodes x) 
	weight-sum function: s(x) = w(y), 
yT (x) 
	rank function: r(x) = log2 s(x). 
6 -Splay Trees-4</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6. 854 Advanced Algorithms September 24, 2008 
Lecture 6 -Spla y Trees 
Lecturer: Michel X. Goemans 
1 Introducti on 
In this lecture, we investigate splay trees, a type of binary search tree (BST) rst formulated by 
Sleator and Tarjan in 1985. Splay trees are self-adjusting BSTs that have the additional helpful 
property that more commonl y accessed nodes are more quickly retrieved. They have good behavior 
when compared to many other types of self-balancin g BSTs, even when the operations are unknown 
and non-u niform. Whil e in the worst case, operation s can take O(n) time, splay trees maintain 
O(log n) amorti zed cost for basic BST operations, and are within a constant factor to the cost of 
any static BST. 
We rst give an overview of the operations used in splay trees, then give an amortized analy sis of 
its behavior. We conclu de by noting its behavior relative to other Binar y Searc h Trees. 
2 Splay Tree Structure 
A splay tree is a dynamic binary search tree, meaning that it performs additional operations to 
optimize behavior. Because they are BSTs, given a node x in a splay tree and a node y in the left 
subtree of x, we have key(y) &lt; key(x). Similar ly, for a node z in the right subtree of x, we have 
key(x) &lt; key(z). This is the binary search tree property. A well-balan ced splay tree will have height 
(log(n), where n is the number of nodes. 
Splay trees achieve their eciency through use of the following operation s: 
2.1 Rotation 
The basic operation used in splay trees (or any other dynamic BST) is the rotati on. A rotati on 
involves rearran ging the nodes of a subtree rooted at y so that one of the children x of y becomes 
the new root of the subtree, while maintaining the binary search tree property. This is illustrated 
in Figure 1. 
When the left child becomes the new root, the rotation is a right rotat ion. When the right child 
becomes the new root, the rotation is a left rotation . We call a right rotation a zig and a left rotati on 
a zag. 
The key idea of the splay tree is to bring node x to the root of the tree when accessing x via rotation s. 
This brings the most recently accessed nodes closer to the top of the tree. 
However, there are many ways of bringing a node to the root via rotation s, and we must therefore 
specify in which order we perform them. Consider a linear tree (eectively a linked list) of the values 
1,...,n, rooted at n. Suppose we access the value 1. If we use the naive (and most natural) method 
of repeatedly performin g a zig to bring 1 at the top, we proceed as illustrated in Figure 2. The 
resulting tree has the same heigh t as the origin al tree, and is clearly not better balance d. We must 
try a more clever approac h than successive, single rotation s. 
6 -Splay Trees-1</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>T2, and everyth ing on the left belongs to T1. Depending on its key, we add x to either T1 or T2. 
Thus, we either make the right child or the left child of x a new root by simply remo ving its pointer 
to its parent. 
The amorti zed cost of the Find operation is O(log n). The actual cost of creating the second BST 
(by cutti ng o one of the children) is just O(1), and the potential function does not increas e (as the 
rank of the root does not increase). Thus the total amortized time of a Split is also O(log n) time. 
Join and Split make insertion and deletion very simple. 
3.3.6 Insert 
Let i be the value we want to insert. We can rst split the tree around i. Then, we let node i be 
the new root, and make the two subtrees the left and right subtrees of i respectively. The amortized 
cost again is O(logn). 
3.3.7 Delete 
To delete a node i from a tree T , we rst Find(i) in the tree, which brings node i to the root. 
We then delete node i, and are left with its left and right subtrees . Because everyth ing in the left 
subtree has key less than everything in the right subtree, we can then join them. It is easy to see 
that this has amortize d cost O(log n) as well. 
3.3.8 Total cost of m operations 
The next theorem shows that the cost of any sequence of operation s on a splay tree has worst-case 
time similar to any balan ced BST (unless the number of operation s m is o(n) where n is the number 
of keys). 
Theorem 3 For any sequence of m operations on a splay tree containing at most n keys, the total 
cost is O((m + n)log n). 
Proof of Theor em 3: Let ai be the amortized cost of the ith operation. Let ci be the real cost 
of the ith operation. Let 0 be the potential before and m be the potential after the m operations. 
The total amortized cost of m operations is: 
m m
ai = ci + m  0. 
i=1 i=1 
Then we have: m m
ci = ai + 0  m. 
i=1 i=1 
Since we chose w(x) = 1 for all x, we have that, for any node x, r(x)  log n. Thus 0 m  n log n, 
so we conclud e: 
m m
ci = ai + O(n log n)= O(m log n)+ O(n log n)= O((m + n)log n). 
i=1 i=1 
6 -Splay Trees-8</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Then we den e the potential function as: 
 = r(x). 
xT (root) 
3.2 Amortized Cost of Splay(x) 
Using the potential function described above, we can show that the amorti zed cost of the splay 
operation is O(log n). For the purposes of cost analysis, we assume a rotation takes 1 unit of time. 
Lemma 1 For a splay -step operation on x that transforms the rank function r into r, the amor tized 
cost is ai  3(r(x)  r(x)) + 1 if the parent of x is the root, and ai  3(r(x)  r(x)) otherw ise. 
Proof of Lemm a 1: Let the potential before the splay-step be  and the potential after the splay-
step be . Let the worst case cost of the operation be ci. The amortized cost ai is ai = ci +   . 
We consider the three cases of splay-step operations. 
Case 1: In this case, the parent of x is the root of the tree. Call it y. After the splay-step, x 
becomes the root and y becomes a child of x. The operation involves exactly one rotati on, so ci = 1. 
The splay step only aects the rank for x and y. Since y was the root of the tree and x is now the 
root of the tree, r(x)= r(y). Additionall y, since y is now a child of x, (the new) T (x) contains (the 
new) T (y), so r(y)  r(x). Thus the amorti zed cost is: 
ai = ci +    
= 1+ r(x)+ r(y)  r(x)  r(y) 
= 1+ r(y)  r(x) 
 1+ r(x)  r(x) 
 1 + 3(r(x)  r(x)), 
since r(x)  r(x). 
Case 2: In this case, we perform two zigs or two zags, so ci = 2. Let the parent of x be y and the 
parent of y be z. Node x takes the place of z after the splay-step, so r(x)= r(z). Also, we see in 
Figure 3 that r(y)  r(x) (since y was the paren t of x) and r(y)  r(x) (since y is now a child of 
x). Then the amortized cost is: 
ai = ci +    
= 2+ r(x)+ r(y)+ r(z)  r(x)  r(y)  r(z) 
= 2+ r(y)+ r(z)  r(x)  r(y) 
 2+ r(x)+ r(z)  r(x)  r(x). 
Next, we use the fact that the log function is concave, or log a+lo g b  log( a+b ). If the splay-step 2 2 
operation transforms the weight-sum function s into s, we have: 
log2 (s(x)) + log2 (s(z)) s(x) + s(z) 
2  log2 2 . 
6 -Splay Trees-5</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Figure 1: Rotati on via zigs and zags. 
Figure 2: When we access node 1 and try to bring it up via pure rotation s, the result is a tree that 
is just as unbalan ced as before. 
2.2 Splay-Step 
We now den e an operation called splay-step. In one splay-step on a node x, x is brought up 2 
levels with rotation s (or just 1 level if xs parent is the root). When some node x is accessed in the 
splay tree, we bring x up with a series of splay-steps until it is the root. 
We separate the actions performed for the splay-step into the following categories. Call the node 
that we are trying to access x, its parent y, and ys parent z. 
	Case 0: x is the root. Do nothing in this case. 
	Case 1: y is the root. If x is the left child of the root, perform a zig on x and y. If not, 
perform a zag. 
	Case 2: x and y are both left children (or both right children). Let us look at the case when 
both x and y are left children. We rst do a zig on the y-z connection. Then, we do a zig on 
the x-y connection. If x and y are right children, we do the same thing, but with zags instead. 
(See Figure 3.) 
	Case 3: x is a left child and y is a right child, or vice versa. Consider the case where x is a 
right child, and y is a left child. We rst do a zag on the x-y edge, and then a zig on the x-z 
edge. In the case where x is a left child and y a right child, we do the same thing, but with a 
zig on the rst move, followed by a zag. (See Figur e 4.) 
6 -Splay Trees-2</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>The left side is equal to r(x)+
2 r (z) . On the right side, note that 
s(x)+ s(z)  s(x); 
indeed the old subtree T (x) and the new subtree T (z) cover all nodes of T (x), except y (thus 
s(x)+ s(z)= s(x)  w(y)). Thus, we have: 
r(x)+ r(z) log2 (s(x)) 
2  2= r(x)  1, 
or 
r(z)  2r(x)  r(x)  2. 
Therefore, the amortized cost is: 
ai	 2+ r(x)+2r(x)  r(x)  2  r(x)  r(x) 
= 3(r(x)  r(x)). 
Case 3: In this case, we perform a zig followed by a zag, or vice versa, so ci = 2. Let the parent 
of x be y and the parent of y be z. Again, r(x)= r(z) and r(y)  r(x). Then the amortize d cost is: 
ai	= ci +    
=	2+ r(x)+ r(y)+ r(z)  r(x)  r(y)  r(z) 
	2+ r(y)+ r(z)  r(x)  r(x). 
Note in Figure 4 that s(y)+ s(z)  s(x). Using the fact that the log function is concave as before, 
we nd that r(y)+ r(z)  2r(x)  2. Then we conclu de 
ai	 2+2r(x)  2  r(x)  r(x) 
 2(r(x)  r(x)) 
 3(r(x)  r(x)). 
Lemma 2 The amortize d cost of the splay operation on a node x in a splay tree is O(1+log s(root) ). s(x) 
Proof of Lemma 2: The amortize d cost a(spla y(x)) of the splay operation is the sum of all of the 
splay-step operation s performe d on x. Suppose that we perform k splay-step operation s on x. Let 
r0(x) be the rank of x before the splay operation . Let ri(x) be the rank of x after the ith splay-step 
operation. Then we have rk(x)= r0(root) and: 
a(spla y(x))	 3(rk(x)  rk1(x)) + 3(rk1(x)  rk2(x)) + ... + 3(r1(x)  r0(x)) + 1 
= 3(rk(x)  r0(x)) + 1 
= 3(r0(root)  r0(x)) + 1. 
The added 1 comes from the possibility of a case 1 splay-step at the end. The den ition of r gives 
the result.  
The above lemma gives the amortized cost of a splay operation, for any settings of the weights. To 
be able to get good bounds on the total cost of any sequence of operations, we set w(x)=1 for all 
nodes x. This implies that s(root)  n where n is the total number of nodes ever in the BST, and 
by Lemma 2, the amorti zed cost of any splay operation is a(spla y(x)) = O(log n). 
6 -Splay Trees-6</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>4 Comparison to other BSTs 
4.1 Static Opti mality Property 
We will show that splay trees are competitive against any binary search tree that does not involve 
any rotati ons. We consider BSTs containing n keys, and sequences of operation s that contain only 
Find operations (thus, no Insert or Delete for exampl e). 
Theorem 4 Dene a static binary search tree to be one that uses no rotation operations. Let mi 
be the numb er of times elem ent i is accessed for i =1,...,n. We assume mi  1 for all i. Then the 
total cost for accessing every element imi times is at most a constant times the total cost of any 
static binary search tree. 
Proof of Theorem 4: Consider any binary searc h tree T rooted at t. Let l(i) be the height 
of of i in T , or the number of nodes on the path from i to the root of T , so l(t)=1. In T , the 
cost for accessing an element i is l(i), so the total cost for accessing every element imi times is 
l(i)mi. We want to show that the total cost of operations on a splay tree, irrespective of the 
i  
startin g con guration, is O( l(i)mi). 
i 
We choose a dieren t weight function that earlier. Here, we dene the weights to be w(i)=3l(i) 
for all i. Note that s(t)  1 + 2( 31 
2 )+22( 31 
3 )+ ... = 1. Then, by Lemm a 2, the amortized cost of 3 
nding i is: 
s(t) 1 a(i)= O(1 + log2 )= O(1 + log2 )= O(1 + l(i)). s(i) 3l(i) 
The total amortized cost of accessing every element imi times on a splay tree is thus: 
O(m + l(i)mi)= O l(i)mi . 
i i 
This is the amortized cost, we now need to argue about the actual cost. Let  be the potential 
before the beginn ing of the sequence, and  be the potential after the sequence of operation s. For 
a node i, let r(i) be the rank of i before and r(i) be the rank after the operations. Note that (since 
r(i)  log2 1 and r(i)  log2 w(i)): 
  
   =  
i r(i)  r(i)   
i log2 1 
3l(i) = O  
i l(i) . 
Then we have:            
=ci ai +    = O l(i)mi + O l(i)= O l(i)mi , 
i i i 
since our assumption mi  1 implies that i l(i)  i l(i)m(i).  
4.2 Dynamic Optimality Conjecture 
The Dynamic Optimalit y Conj ecture claims that Splay Trees are ecient up to a constan t factor to 
any self-adjusting Binary Searc h Tree (allowing an arbitrary number of (arbitrary) rotation s between 
accesses). This conjecture was rst put forth in the Tarjan and Sleate rs original Splay Tree paper 
in 1985, and has withstood attempts to prove or disprove it since. 
6 -Splay Trees-9</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>4.3 Scanni ng Theorem 
The scanning theorem state s that, for a splay tree that contains the values [1, 2,...,n], accessing 
all of those elements in sequen tial order takes O(n) time, regardl ess of the initial arrangem ent of 
the tree. An interesting point is that, even though the Scann ing Theorem has been proved, if the 
Dynamic Optimality Conj ecture were true, then it would follow directly from the fact that one can 
create dynamic BSTs that perform sequential access in linear time. 
6 -Splay Trees-10</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Figure 3: Case 2 of the splay-step is when x and y are the same type of children. In this gure, we 
rst do a zig on y  z, and then a zig on x  z. 
Figure 4: In Case 3, x and y are not the same type of children. In this case, we do a zag on the 
x  y edge, and then a zig on the x  z edge. 
Note that in the case of the earlier exam ple with the chain of nodes, using splay-ste p instead of 
direct rotati ons results in a much more balance d tree, see Figure 5. 
2.3 Splay 
With the splay-ste p operation, we can bring the node x to the root of the splay tree with the 
procedure: 
splay(x): 
WHILE x=root: 
DO splay-step(x) 
The d escribed procedure performs the spla y operation in a bottom-up order. It is possible to perform 
the splay operation in a top down fashion, which would result in the same running time. 
6 -Splay Trees-3</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Fibonacci heaps</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec1/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>S      G     k(v)    
T   V \S     T =   S = V  k(s)=0        s  k(v)=+
 v = s 
    S    
      u   S           u = s       T  
               u  T     k(u) 
           v/ S  u            k(v)    min{k(v),w((u,v))}  
          
                             
                          |V |      
|V |                            
  |E|        
    
                        T      
             S         
        T    h       2i       i  i&lt;h  
            
                          
                        
                           
 O(log n)     n                          
       |V |                      
  O((|V |+|E|)log |V |)    |E||V |              
        O(|E| log |V |)                
         
    
                                   
  d                             
           O(logd |S|)            
        O(d logd |S|)                d = |E|/|V |
                 O((|E|+d|V |)logd |V |)= O(|E|log|E|/|V ||V |) 
                             
                                     
                            
                 O(|E| + |V | log |V |)</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>u   k          u     Fk+2   
  Fi   i          F0 =0 F1 =1  Fi = Fi1 + Fi2  i  2 
                             
 
    
               s            
      k(s)                      
              
    
             s                 
            s                  
                s           
         s                     
    
                               
             s                  
                              
                       s           
                                   
                         s</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>j     tj             
    kj        j   j =1, ,                                     j kj tj  
                 
                               
                                
                           
                        
                     c1,c2,c3,...,ck    
                     ci           
                                  
                      
                          
                           
                             
    
                 Di        
     D                       
   0 = (D 0)=0.         o1,o2,o3,...,ok   Di    
              i</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text></text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>O(1)            
                                 
                                
                          
t = rt +2mt 
  rt           mt              t        
                              
   
            ct = O(1)                
rt = rt1 +1                     
at = ct +(rt  rt1) + 2(m t  mt1)= O(1)+1+0 = O(1). 
    
              rt               
  d   rt1 + d  1               rt     
                     O(log n)      
   rt = O(log n)                      O(1) 
                            
ct = rt1+d1                           
                    
at = ct +(rt  rt1)+2(m t  mt1)=(rt1 + d  1)+(rt  rt1)+0 = rt + d  1= O(log n). 
 
                k  k  1        
                               
     rt  rt1            k           mt1  mt  
       k  1  k                    
    mt1  mt  k  1             1+ k    
                   
at = ct +(rt  rt1) + 2(m t  mt1)  1+ k + k  2(k  1) = O(1). 
                       
                 O(1)     
        O(log n)     
                   
                              
   O(|E| + |V | log |V |)</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>t :t = (D t)  0. 
    oi        ci             
ai = ci +  i = ci +i  i1. 
                               
k k k k
ai = (ci +i  i1)= ci +k  0  ci. 
i=1 i=1 i=1 i=1 
                              
  
                          
             
                        
                           
                            
   
        x           d   y1,y2,...,yd       
                     yi        i  2 
    yi      x      i  1    y1  yi1        
          yi     i  1              
                     yi              
  yi      i  2     
                            
           d      Fd+2               
       
     N (d)                                
d   N(d)  Fd+2                    n    O(log n) 
    N      N(0) = 1 N(1) = 2            
d
N(d)  2+ N(i  2) 
i=2 
                      y1  N(i  2)    
    yi          d      N(j)  Fj+2  j&lt;d    
  
d d
N(d)  2+ Fi =1+ Fi. 
i=2 i=0 
       Fd+2              d 1+ 
id 
=0 Fi = Fd+1 + Fd = 
Fd+2                   N (d)  Fd+2  
                         
  
  N(d)  Fd+2 = 1
5  
1 + 
2 
5 d+2 
  
1 
2 
5 d+2 
 1.61d . 
  N(d)  n               log1.61 n</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>s        s    
                    s                 
                               
         
                              
                              
                             
                             
                                
                             
                   k                 
k +1                           
                                
     k +1                 
    
                                 
        
              n              
                               
                           
           O(n)</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>S    
           s         k(s)                 
              S  
         s      k(s)  S  
        s  S          s   S  
               s            
                           
                        
  
      
           G =(V,E)     s  V        l : E R+  
                         v  V   
         ds(v)         s  v  
                   
                S      G     k(v)   
S = V  k(s)=0  k(v)=+  
    S    
       u   S          k(u)      ds(u) 
       v  S  u               k(v)  v   
  min{k(v),k(u)+ l((u,v))}  
    k(v)              s  v         
     S      ds(v)                
     
       
       G =(V,E)        w : E R            
    G</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Cancel-and-tighten algorithm; binary search trees</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec5/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>2.2.2 Cancel Step 
We now shift our atten tion to the impleme ntation and analy sis of the Cancel step. Navely, it takes 
O(m) time to nd a cycle in the admissible graph Ga =(V,A) (e.g., using Depth-Fir st Search) and 
push ow along it. Using a more careful implementation of the Cance l step, we shall show that each 
cycle in the admiss ible graph can be found in an amortized time of O(n). 
We use a Depth-Fir st Search (DFS) approach, pushing as much ow as possible along an ad
missible cycle and removing saturat ed edges, as well as removing edges from the admiss ible graph 
whenev er we determine that they are not part of any cycle. Our algor ithm is as follows: 
Cancel(G a =(V,A)): Choose an arbitrary vertex u  V , and begin a DFS rooted at u. 
1. If we reach a vertex v that has no outgoi ng edges , then we backtrack, deleting from A the 
edges that we backtrac k along, until we nd an ancestor r of v for which there is another child 
to explore. (Notice that every edge we backtrac k along cannot be part of any cycle.) Continue 
the DFS by explorin g paths outgoin g from r. 
2. If we nd a cycle , then we push the maximum possible ow through it.	This causes at 
least one edge along  to be saturated. We remove the saturat ed edges from A, and start 
the depth-rst-s earch from scratch using G
a =(V,A), where A denot es A with the saturated 
edges removed. 
Every edge that is not part of any cycle is visited at most twice (since it is removed from the 
admiss ible graph the second time), so the time taken to remove edges that are not part of any cycle 
is O(m). Since there are n vertice s in the graph, it takes O(n) time to nd a cycle (excluding the 
time taken to traverse edges that are not part of any cycle ), determin e the maxi mum ow that 
we can push through it, and update the ow in each of its edges. Since at least one edge of A is 
saturat ed and remo ved every time we nd a cycle , it follows that we nd at most m cycles. Hence , 
the total running time of the Cance l step is O(m + mn) = O(mn). 
2.2.3 Overall Running Time 
From the above analysis, we see that the Cancel step requi res O(mn) time per iterati on, where as 
the Tigh ten step only requi res O(m) time per iterati on. In the previous lecture, we determined 
that the Cance l-and -Tigh ten algorith m requi res O(min( n log(nC),mn log n)) iteration s. Hence the 
overall running time is O(min( mn2 log(nC),m2n2 log n)). 
Over the course of the next few lectures, we will develop data structures that will enable us to 
reduce the running time of a single Cancel step from O(mn) to O(m log n). Using dynamic trees, we 
can reduce the running time of the Cancel step to an amortized time of O(log n) per cycle canceled. 
This will reduce the overall running time to O(min( mn log(nC)log n,m2n log2 n)). 
3 Binary Search Trees 
In this section , we review some of the basic properties of binary search trees and the operations 
they support, before introducing splay trees. A Binar y Search Tree (BST) is a data structure that 
main tains a diction ary. It stores a collection of objects with ordered keys. For an object (or node) 
x, we use key[x] to denote the key of x. 
Prop erty of a BST. The following invariant must always be satised in a BST: 
 If y lies in the left subtree of x, then key[y]  key[x] 
 If z lies in the right subtree of x, then key[z]  key[x] 
5-4</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Since we begin with at most m admiss ible edges , we cann ot cance l more than m cycles, as each cycle 
cance ling reduces the number of admiss ible edges by at least one. 
After the cance l step, every cycle  contains at least one non-admissible edge, say (u1,v1)   
with cp(u1,v1)  0. Then the mean cost of  is 
c() 1  
cp(u,v) (|| 1) (f)=  1  11  1 (f). || || (u1,v1 )=(u, v) || || (f)  n 
Therefore, (f)= (f)  1  n 1 (f).  
2.2 Implementation and Analysis of Runni ng Time 
2.2.1 Tigh ten Step 
We rst discuss the Tigh ten step of the Cance l-and-Tigh ten algor ithm. In this step, we wish to nd 
a new potential function p and a constan t  such that cp (v,w)  for all edges (v,w)  Ef 
and   1  n 1 . We can nd the smallest possible  in O(mn) time by using a variant of the 
Bellman-Ford algorith m. However, since we do not actually need to nd the best possible , it is 
possible to vastly reduce the running time of the Tighten step to O(n), as follows. 
When the Cance l step termin ates, there are no cycle s in the admissible graph Ga =(V,A), the 
subgr aph of the residual graph with only the admissible edges. This implies that there exists a 
topological sort of the admiss ible graph. Recall that a topological sort of a directed acyclic graph 
is a linear ordering l : V {1,...,n} of its vertices such that l(v) &lt;l(w) if (v,w) is an edge of the 
graph; it can be achieved in O(m) time using a standard topological sort algorith m (see, e.g., CLRS 
page 550). This linear orderin g enab les us to dene a new potential function p by the equation 
p(v)= p(v)  l(v)/n. We claim that this potential function satises our desired properties. 
Claim 3 The new potent ial function p(v)= p(v)l(v)/n satises the property that f is -optimal 
with respect to p for some constant   (1  1/n). 
Proof: Let (v,w)  Ef , then 
cp (v,w)= c(v,w)+ p(v)  p(w) 
= c(v,w)+ p(v)  l(v)/n  p(w)+ l(w)/n 
= cp(v,w)+(l(w)  l(v))/n. 
We consider two cases, depending on wheth er or not l(v) &lt;l(w). 
Case 1: l(v) &lt;l(w). Then 
cp (v,w)= cp(v,w)+(l(w)  l(v))/n 
 + /n 
= (1  1/n). 
Case 2: l(v) &gt;l(w), so that (v,w) is not an admis sible edge. Then 
cp (v,w)= cp(v,w)+(l(w)  l(v))/n 
 0  (n  1)/n 
= (1  1/n). 
In either case, we see that f is -optimal with respect to p, where   (1  1/n).  
5-3</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6. 854 Advanced Algorithms September 17, 2008 
Lecture 5 
Lecturer: Michel X. Goemans 
Today, we continue the discuss ion of the minimum cost circul ation problem. We rst review the 
Gold berg-Tarjan algorit hm, and improve it by allowing more exib ility in the selection of cycles. 
This gives the Cancel-and -Tigh ten algor ithm. We also introduce splay trees, a data structure which 
we will use to create anoth er data structure, dynamic trees, that will further impr ove the running 
time of the algor ithm. 
1 Review of the Goldberg-Tarjan Algorithm 
Recall the algori thm of Golb erg and Tarjan for solvin g the minimum cost circulati on problem : 
1. Initiali ze the ow with f = 0. 
2. Repeatedly push ow along the minimum mean cost cycle  in the residual graph Gf , until 
no negativ e cycles exist. 
We used the notation 
c() (f) = min 
cycle Ef ||
to denote the minimum mean cost of a cycle in the residual graph Gf . In each iteration of the 
algor ithm, we push as much ow as possible along the minimum mean cost cycle, until (f)  0. 
We used (f) to denote the minimum  such that f is -optimal. In other words 
(f) = min{ :  potential p : V R such that cp(v,w)  for all edges (v,w)  Ef }.  
We proved that for all circulation s f, 
(f)= (f). 
A conse quenc e of this equality is that there exists a potential p such that any minimum mean cost 
cycle  satises cp(v,w)= (f)= (f) for all (v,w)  , since the cost of each edge is bound ed 
below by mean cost of the cycle. 
1.1 Analysis of Goldberg-Tarjan 
Let us recall the analysis of the above algori thm. This will help us to improve the algorith m in order 
to achieve a better running time. Please refer to the previous lecture for the details of the analysis. 
We used (f) as an indication of how close we are to the optimal solut ion. We showed that (f) 
is a non-increas ing quantity, that is, if f is obtai ned by f after a single iteration , then (f)  (f). 
It remains to show that (f) decreases signican tly after several iterations. 
Lemma 1 Let f be any circulation, and f be the circulation obtaine d after m iterations of the 
Goldberg-Tarjan algor ithm. Then  1 (f)  1  (f). n 
We showed that if the costs are all integer valued, then we are done as soon as we reach (f) &lt; 1 . n 
Using these two facts, we showed that the number of iteration s of the above algorith m is at most 
O(mn log(nC)). An alternati ve analysis using -xed edges provides a stron gly polynomial bound 
of O(m2n log n) iterati ons. Finally, the running time per a singl e iteration is O(mn) using a varian t 
of Bellman-Ford (see problem set). 
5-1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Operations on a BST. Here are some operations typically supported by a BST: 
	Find(k ): Dete rmines whether the BST contains an object x with key[x]= k; if so, returns the 
object, and if not, retur ns false. 
	Insert(x): Inserts a new node x into the tree. 
	Delete(x): Deletes x from the tree. 
	Min: Finds the node with the minimum key from the tree. 
	Max : Finds the node with the minimum key from the tree. 
	Successor(x ): Find the node with the smallest key greate r than key[x]. 
	Predecess or(x ): Find the node with the greate st key less than key[x]. 
	Split(x): Retur ns two BSTs : one containing all the nodes y where key[y] &lt; key[x], and the 
other containing all the nodes z where key[z]  key[x]. 
	Join(T1,x,T2): Given two BSTs T1 and T2, where all the keys in T1 are at most key[x], and 
all the keys in T2 are at least key[x], returns a BST containi ng T1,x and T2. 
For exam ple, the procedure Find(k ) can be impleme nted by traversin g through the tree, and 
branching to the left (resp. right) if the current node has key greater than (resp. less than) k. The 
running time for many of these operation s is linear in the heigh t of the tree, which can be as high 
as O(n) in the worst case, where n is the number of nodes in the tree. 
A balanc ed BST is a BST whose heigh t is maintained at O(log n), so that the above operation s 
can be run in O(log n) time. Examples of BSTs include Red-Blac k trees, AVL trees , and B-tree s. 
In the next lecture, we will discuss a data structur e called splay trees, which is a self-balan cing 
BST with amort ized cost of O(log n) per operati on. The idea is that every time a node is accessed, 
it gets pushed up to the root of the tree. 
The basic operations of a splay tree are rotations. They are illustrated the following diagram. 
A BCxy
A
B Cx
yzig (right rotation)
zag (left rotation)
5-5</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>1.2 Towards a faster algorithm 
In the above algori thm, a signican t amou nt of time is used to compu te the minim um cost cycle. 
This is unnecessary, as our goal is simply to cance l enough edges in order to achieve a signi can t 
impr ovement in  once every several iterations. 
We can impro ve the algorith m by using a more exib le selection of cycle s to cancel. The idea of 
the Cance l-and -Tighten algorith m is to push ows along cycles consis ting entirely of negativ e cost 
edges . For a given potential p, we push as much ow as possible along cycles of this form, until no 
more such cycles exist, at which point we update p and repeat. 
2 Cancel -and-Tig hten 
2.1 Descri ption of the Algorithm 
Deniti on 1 An edge is admiss ible with respect to a potential p if cp(v,w) &lt; 0. A cycle  is 
admiss ible if all the edges of  are admissibl e. 
Cancel and Tigh ten Algorit hm (Goldberg and Tarjan): 
1. Initiali zation : f  0, p  0,   max (v,w)E c(v,w), so that f is -optimal respect to p. 
2. While f is not optim um, i.e., Gf contains a negative cost cycle, do: 
(a) Cancel: While Gf contains a cycle  which is admissible with respect to p, push as much 
ow as possible along . 
(b) Tighten: Update p to p and  to , where p and  are chosen such that cp (v,w)  
for all edges (v,w)  Ef and   1  n 1 . 
Remark 1 We do not update the potential p every time we push a ow. The potential p gets updated 
in the tighten step after possibly sever al ows are pushe d through in the Canc el step. 
Remark 2 In the tighten step, we do not need to nd p and  such that  is as small as possible; 
it is only necessary to decrease  by a facto r of at least 1  1 . However, in practic e, one tries to n 
decrease  by a smal ler factor in order to obtain a better running time. 
Why is it always possible to obtai n improvement factor of 1  1 in each iteration? This is n 
guaranteed by the following result, whose proof is similar to the proof used in the analysis during 
the previous lecture. 
Lemma 2 Let f be a circulation and f be the circulation obtained by perform ing the Cancel step. 
Then we cancel at most m cycles, and 
1 (f)  1  n(f). 
Proof: Since we only cance l admissible edges, after any cycle is cance led in the Cancel step: 
	All new edges in the residual graph are non-admis sible, since the edge costs are skew-symmetric; 
	At least one admiss ible edge is removed from the residual graph, since we push the maxim um 
possible amoun t of ow through the cycle. 
5-2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Linear programming (LP)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec9/</lecture_pdf_url>
      <lectureno>9</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>2. y  Rm : AT y  0, bT y &lt; 0. 
Clearly , both cannot simultaneously happen, since the existence of such an x and a such a y 
would mean: 
yT Ax = yT (Ax) = y T b &lt; 0, 
while 
yT Ax =(AT y)T x  0, 
as the inner product of two nonnegativ e vectors is nonnegativ e. Together this gives a contradiction . 
9.4.1 Generali zing Farkas Lemm a 
Before we provide a proof of the (other part of) Farkas lemm a, we would like to briey mention 
other possible generalization s of the solvability of syste m of equation s. 
First of all, consider the case in which we would like the variables x to take integer values , 
but dont care whether they are nonnegativ e or not. In this case, the natural condition indeed is 
necessary and suc ient. Formally , suppose we take this set of constrai nts: 
Ax = b 
x Zn 
Then if yT Ax = yT b, and we can nd some yT A  Zn and some yT b that is not integral, then the 
system of constrai nts is infeasible. The converse is also true. 
Theorem 2 Exact ly one of the following holds: 
1. x  Zn : Ax = b, 
2. y  Rm : AT y  Zn and bT y /Z. 
One could try to combine both nonnegativ ity constraints and integral restrictions but in that case, 
the necessary condition for feasibility is not suc ient. In fact, for the following set of constrain ts: 
Ax = b 
x 0 
x Zn ,  
determini ng feasibility is an NP-har d problem, and therefor e we cannot expect a good characteriza
tion (a necessary and sucient condition that can be checked eciently). 
9.4.2 Proof of Farkas lemma 
We rst examine the projection theorem, which will be used in proving Farkas lemma (see Figure 
1). 
Theorem 3 (The projection theorem) If K is a nonempty , close d, convex set in Rm and b /
K, dene 
p = projK (b) = arg min (1) 
zK z  b2. 
Then, for all z  K :(z  p)T (b  p)  0. 
9-3</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Figure 1: The projection theorem . 
Proof of Lemm a 1: We have seen that both syste ms cannot be simultaneously solvable. 
So, now assume that x : Ax = b, x  0 and we would like to show the existence of y satisfying 
the requi red conditions. Den e 
K = {Ax : x  Rn , x  0} Rm . 
By assumpti on, b /K, and we can apply the projection theorem. Den e p = projK (b). Since 
p  K, we have that p = Ax for some vector x  0. Let y = p  b  Rm . We claim that y satises 
the right conditions. 
Indeed, consid er any point z  K. We know that w  0: z = Aw. By the projection theorem , 
we have that (Aw  Ax)T y  0, i.e. 
(w  x)T AT y  0, (2) 
for all w  0. Choosing w = x + ei (where ei is the ith unit vector), we see that AT y  0. We still 
need to show that bT y&lt; 0. Observe that bT y =(p  y)T y = pT y  yT y &lt; 0 because pT y  0 
and yT y &gt; 0. The latter follows from y = 0 and the former from (2) with  w = 0: xT AT y  0, 
i.e. pT y  0.  
9.4.3 Coroll ary to Farkas lemma 
Farkas lemm a can also be written in other equivalent forms . 
Corollary 4 Exact ly one of the following holds: 
1. x  Rn : Ax  b, 
2. y  Rm : y  0, AT y =0, bT y&lt; 0. 
Again , x and y cannot simultan eously exist. This coroll ary can be either obtained by mass aging 
Farkas lemm a (to put the system of inequali ties in the right form), or directly from the projection 
theorem. 
9.5 Duality 
Duality is one of the key concepts in linear programm ing. Given a solution x to an LP of value z, 
how do we decide whether or not x is in fact an optimum solut ion? In other words, how can we 
calculate a lower bound on min cT x given that Ax = b, x  0? 
9-4</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Interior -point algor ithms (Karmark ar 1984). 
	This is a class of algorit hms which maintain a feasible point in the interior of P ; many 
varian ts (by many researchers) have been developed. 
	Polynomial time. 
	Fast in practic e. 
	Can beat the simplex method for larger problem s. 
9.2 Equivalent forms 
A linear programming problem can be modied to t a preferred alternate form by changing the 
objective function and/or the linear constrain ts. For example, one can easily transform any linear 
program into teh stand ard form: min{cT x : Ax = b,x  0}. One can use the following simpl e 
transformation s. 
Maximize to minimize	 max{cT x} min{cT x}  
aT
Equality to inequality aiT x = bi ai
T x  bi
 
i x  bi 
Inequ ality to nonn egativity constraint aiT x  bi  s aiT 
 x 
0+ s = bi (s  Rn) 
 replace xj everywhere by x +  x	 j j 
+Variables unrestricted in sign xj unrestricted in sign   xj  0 
x
j  0 
9.3 Denitions 
Here is some basic terminology for a linear program. 
Deniti on 1 A vector x is feasible for an LP if it satises all the constraints. 
Deniti on 2 An LP is feasible if there exists a feasible solution x for it. 
Deniti on 3 An LP is infeasible if there is no feasible solution x for it. 
Deniti on 4 An LP min{cT x : Ax = b, x  0} is unbounded if, for all   R, x  Rn such that 
Ax = b 
x  0 
cT x  . 
9.4 Farkas lemma 
If we have a system of equation s Ax = b, from linear algebra, we know that either Ax = b is 
solvable, or the system AT y = 0, bT y = 0 is solvable.  Indeed, since Im(A) = ker(AT ), either b 
is orthogon al to ker(AT ) (in which case it is in the image of A, i.e. Ax = b is solvable) or it is 
not orthogon al to it in which case one can nd a vector y  ker(AT ) with a non-zero inner product 
with b (i.e. AT y = 0, bT y = 0 is solvable). 
Farkas lemm a generalizes this when we have also linear inequal ities: 
Lemma 1 ((Farkas lemm a)) Exact ly one of the following holds: 
1.	x  Rn : Ax = b, x  0, 
9-2</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>If  = 0, we can scale by , and therefore assume that  = 1. Then we get that 
x  Rn : 
 
 Ax = b, 
x  0 
cT x &lt; z. 
This result is a contradiction, because x was the optim um solut ion, and therefore we should 
not be able to further minimize z. 
If  = 0 then  
x  Rm : 
 
 x  0 
Ax =0 
cT x &lt; 0. 
Consider now x + x for any &gt; 0. We have that 
x + x  0 
A(x + x) = Ax + Ax = b +0= b. 
Thus, x + x is feasible for any   0. But, we have that 
cT (x + x)= cT x + cT x &lt; z, 
a contradiction. 
9-6</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Suppose we have y such that AT y  c. Then observe that yT b = yT Ax  cT x for any feasible 
soluti on x. Thus yT b provides a lower bound on the value of our linear program. This conclu sion 
is true for all y satisfying AT y  c, so in order to nd the best lower bound, we wish to maximize 
yT b under the constraint of AT y  c. 
We can see that this is in fact itself anoth er LP. This new LP is called the dual linear progr am 
of the original problem, which is called the primal LP. 
 Primal LP: min cT x, given Ax = b, x  0, 
 Dual LP: max bT y, given AT y  c. 
9.5.1 Weak Dual ity 
The argume nt we have just given shows what is known as weak duality. 
Theorem 5 If the primal P is a minimization linear program with optimu m value z, then it has a 
dual D, which is a maxi mization problem with optimu m value w and z  w. 
Notice that this is true even if either the primal or the dual is infeasible or unbounded, provided 
we use the following convention: 
infeasible min. problem  value =+ 
unbounded min. problem  value =  
infeasible max. problem  value =  
unbounded max. problem  value =+ 
9.5.2 Stron g Duali ty 
What is remarkable is that one even has strong duality, name ly both linear programs have the same 
values provided at least one of them is feasible (it can happ en that both the primal and the dual 
are infeasible). 
Theorem 6 If P or D is feasible, then z = w. 
Proof: We assume that P is feasible (the argument if D is feasible is analogou s; or one could also 
argue that the dual of the dual is the primal and therefor e one can exchange the roles of primal and 
dual). 
If P is unbounded, z = , and by weak duality, w  z. So it must be that w =  and thus 
z = w. 
Otherwise (if P is not unbounded), let x be the optim um solution to P, i.e.: 
z = cT x 
Ax = b 
x 0 
We would like to nd a dual feasible soluti on with the same value as (or no worse than) x. That 
is, we are looking for a y satisfying: 
AT y  c 
bT y  z 
If no such y exists , we can use Farkas lemma to deriv e: x  Rn , x  0, and   R,  0: 
Ax  b = 0 and cT x  z &lt; 0. 
We now consid er two cases. 
9-5</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6. 854 Advanced Algorithms	 Octob er 6, 2008 
Lecture 9 
Lecturer: Michel X. Goemans 
9 Linear Programm ing 
Linear programm ing is the class of optimization problem s consisting of optimizing the value of a 
linear objective function , subject to linear equality or inequal ity constraints. Thes e constrai nts are 
of the form 
a1x1 +  + anxn {, =, } b, 
where ai,b  R, and the goal is to maximize or minimize an objective function of the form 
c1x1 + + cnxn.  
In addition, we constrain the variables xi to be nonnegativ e. 
The problem can be expressed in matr ix form. Given these constraints 
Ax b {, =, } 
x 0,  
maximize or minimize the value of 
Tcx, 
where x  Rn , A  Rmn , b  Rm , c  Rn . 
Linear progr amming has many applications and can also be used as a proof technique. In 
addition, it is important from a complexity point-of-view, since it is among the hardes t of the class 
of polynomial-time solvable problems . 
9.1 Algorithms 
Researc h in linear programming algor ithms has been an activ e area for over 60 years. In this class, 
we will discuss three major (classes of) algor ithms: 
Simplex metho d (Dan tzig 1947) .  
	Fast in practic e. 
	Still the most-use d LP algorith m today. 
	Can be nonpolynomial (exponential) in the worst case. 
Ellipsoid algorith m (Shor, Khachian 1979).  
	Polynomial time; this was the rst polynomial -time algorith m for linear programm ing. 
	Can solve LP (and other more general) problem s where the feasible region P = {x : Ax = 
b,x  0} is not explicitly given, but instead, given a vector x, one can eciently decide 
whether x  P or if not, nd an inequality satised by P but not by x. 
	Very useful for designing polynomial time algori thms for other problems. 
	Not fast in practice. 
9-1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Max-cut and sparsest-cut</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec19/</lecture_pdf_url>
      <lectureno>19</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6.854AdvancedAlgorithms November21,2008 
Lecture 19 
Lecturer: Michel X. Goemans 
1 Introduction 
In this lecture, we revisit MAXCUT and describe a randomized  (.87856)-approximation al
gorithm. We also explore SPARSEST-CUT, an NP-hard problem for which no constant factor 
approximation is known. We begin to describe an O(logk) approximation using multicommodity 
ows;here k is the number of commodities. To dene the relationship between the optimal values 
of SPARSEST-CUT and multicommodity ow, we introduce metrics and nite metric spaces. 
2 Revisiting MAXCUT 
Recall theMAXCUTproblem:givenagraph G =(V,E)and weights w: E R+ (wecouldassume 
that G is the complete graph and weights are 0 for the original non-edges), maximize w(S : S) 
(= wij )in S V. MAXCUT canbeformulated astheintegerprogram 
iS
jS
max wij (1xixj )/2 
(i,j)E 
subjectto 
xi {1},i. 
The prior lecture described a 1/2-approximation algorithm and an upper bound on the solution to 
the above optimization, via reduction to a semidenite program. 
2.1 SDP Relaxation of MAXCUT 
IntheSDP relaxation,wereplacedthe xi with unit vectorsinthesphere Sn1 := {x Rn : /bardblx/bardbl=1}. 
Thus, the goal of the relaxed MAXCUT was to nd 
max wij (1v T vj )/2i 
(i,j)E 
subjectto 
vi Sn1 ,i. 
Thoughitisnotimmediately clearthatthisrepresentsasemideniteprogram,it canbereformulated 
asfollows: 
max wij (1Yij )/2, 
(i,j) 
subjectto 
Yii =1,i 
Y /{ollowsequal0. 
19-1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Figure 2: An Example Graph where  &lt; . 
Remark7 Computing  is NP-hard. Howeveras we will see in the upcoming lecture  we can 
get a O(logk) approximation using the LP we have for , and a tighter O(logk) approximation 
using an SDP. 
To prove the above result, we introduce metric spaces. 
5 Finite Metric Spaces 
Denition1 Let X be an arbitrary set, and d afunction X R. (X,d)is a metric space if X 
the following properties hold for all x,y,z X: 
1. d(x,y)0 (Nonnegativity) 
2. d(x,y)= d(y,x) (Reexivity) 
3. d(x,y)+d(y,z)d(x,z)(TriangleInequality) 
Forsimplicity,wewilldeal only with nitemetricspaces(i.e. Xis nite). ||
Denition2 Let X, Y be sets with associated metrics d, . For c 1, we say that (X,d) embeds 
into(Y,)with distortion c if there is a mapping : X Y such that for any x,y X, d(x,y) 
((x),(y))cd(x,y). If c =1, the embedding is called isometric. 
This distortion measure is useful when we can transform a problem dened on one metric into 
another metric that is easier to deal with. This is precisely what we will do in the context of 
multicommodity cuts and ows. 
Themostfamiliarmetricspacesare n-dimensionalEuclideanspaces,where d(x,y):= /bardblxy/bardbl2 = 
(xi yi)2 . Generalizing gives the family of n spaces, where we work over the set Rn and i p 
d(x,y):= /bardblx y/bardblp =(  
i |xi yi|p)1/p. One can show that in the limit as p , this expression 
tends to maxi | |. This space is denoted n 
n xi yi . 
Suppose(X,d) is isometrically embeddable into 1 (thatis, 1 for some n). Is d isometrically 
embeddableinto 2 as well? Not necessarily. Here we claim that 2-embeddable metrics are only a 
subset of 1-embeddable metrics, which in turn are a subset of  metrics. Infact, weputforth the 
following lemma: 
19-5</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>3 
Figure 1: For the 5-cycle, the optimum vectors end up being in a lower-dimensional space (of 
dimension 2), see left gure. The angle between any two consecutive vectors is 4/5 and total SDP 
valueis5(1 cos(4/5))/2 =4.52. Taking a random hyperplane through the origin gives the  
cut(S : S), see the right gure. 
GivenasolutiontotheSDPintheformofunit vectors vi,wewouldliketo nd afeasible S givingas 
largea cut aspossible. Theidealistohavevertices i and j separatedby the cut when(1vT vj )/2i 
islarge,i.e., vi and vj are far apart on the sphere. Here is a way to do this. Choosing a hyperplane 
through the origin divides the vectors into two groups, and we let S be the intersection of one 
halfspace with the set of vectors. The sets of vectors on each side of the hyperplane correspond to 
S and S. As an example, we illustrate the vectors for a cycle of length 5 in Figure 1. 
Which hyperplane should we choose? Well, the optimum vectors are denitely not unique; any 
rotation of them (orthonormal transformation) will also provide an optimum solution since the 
objective function depends only on the inner products (viT vj ). Therefore we should not have a 
preferreddirectionforthehyperplane. 
MAXCUT -ApproximationAlgorithm 
Thisdiscussionprovidestheintuitionbehind thefollowing randomized algorithm,duetoGoemans 
andWilliamson([1]): 
1. Choose a unit vector r Sn1 uniformly. 
2. Let S = {i V : rT vi 0}. 
Remark1 In the case n =2, it is easy to pick a uniform r, by taking  [0,2) uniformly, 
whence r =(cos,sin)T . For a general n, we should nd r Sn1 by selecting each component 
independently from a Gaussian distribution, and then normalize to /bardblr/bardbl=1. 
Theorem1 The Goemans-Williamson algorithm is a randomized -approximation algorithm for 
2cos1 x MAXCUT, where  = min .87856). 
1x1 (1x)(
Proof: OPT and SDP will denote the optimal solution to the MAXCUT instance and its 
SDP relaxation. We show E[w(S : S)] SDP  OPT.   
19-2</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>4 SPARSEST-CUT and Multicommodity-Cut 
Wenowconsidertheproblemofidentifying asparsecutinagraph: onewhichisassmall aspossible, 
relative to the number of edges which could exist between the sets of vertices. The latter quantity 
is maximized by balancing the vertices across the partition. Hence, we seek S V minimizing 
w(S : S)/|S S|. A generalization of SPARSEST-CUT is the multicommodity cut problem, in 
which we have, in addition to a capacitated G =(V,E), somek commodities, each associated with 
a demand fi and a source and sink si,ti V. (The idea is that we want to ship units of  fi 
commodity i from si to ti.) We seekthe value of a cut(S : S)with minimum capacity relative to 
the demand across it, i.e., 
u(S : S)min  . 
S:S[ i:(si ,ti)(S:S)fi] 
We will write  for the objective in this expression, and denote its optimum by  . 
We recover SPARSEST-CUT by taking u = w and creating a commodity of demand 1 for each 
pairofvertices. Asanotherspecialcase,when k =1,weareminimizingu(S : S)overcutsseparating 
s and t, so we have the min st cutproblem(in an undirectedgraph). 
4.1 Concurrent multicommodity ow 
Let us now discuss a problem which is in a sense dual to the multicommodity cut. In concurrent 
multicommodity ow,wearegiven G =(V,E)with k commoditiesand capacity constraintsoneach 
edge E,and seek themaximum  such thatwecansend fi unitsof owacrossthegraphfrom si 
to ti forall i simultaneously, without violating the capacity constraints on each edge. Let  denote 
theoptimal value. Itiseasy toseehowtodomulticommodity owby linearprogramming. 
The multicommodity cut and ow problems are related by   . Indeed, if we can send fi 
from si to ti for all i, u(S : S)must be at least fi for each(si,ti)in the cut, so 
u(S : S) =  [ i:(si,ti)(S:S)fi]  
for all feasible  and . This is a weak duality-type condition. 
If k = 1, we have equality, by the max s t ow min s t cuttheorem(one can showthatthe 
theorem for directed graphs implies it also for undirected graphs). It is non-obvious that we have 
 =  for k = 2 as well. In general, however, we do not have equality. In gure 2, we show an 
example of agraph with a relatively small number of commodities(4) for which  is strictly less 
than  . 
Inthisgraph,allcapacitieshavevalue =1. Forthisgraph, =1. Considerthemulticommodity 
cutgivenby thedashedline. Forthis cut, and any similarcuts,the sum of the capacitiesacrossthe 
cutis u(S : S)= 3 and the amount of demand that needs to go through it is i:(si,ti )(S:S)fi =3 
also. If we choose a cut for which the capacties sum to 2 instead, the sum of the demands will also 
be 2. Therefore,  =1. 
Whatis  though? There are k =4 commodities in this graph, and yet a maximum of 3 units 
of ow can be pushed across a cut at one time. Since s2 and t2 are on the same side of the cut, you 
might think that  might be able to reach 1. However, since each si is at least two edges away 
fromits ti and there are 4 commodities, if  = 1 then the sum of the ow on all the edges of the 
graphwouldhavetobe(4)(2)(1) =8. Yetthereonly6edges,eachwithcapacity1. Thisshows 
that  3/4. 
So what IS the relationship between  and  ingeneral? 
Theorem2  
= O(logk).  
19-4</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>6 |V |Lemma3 Any nite metric space (V,d)is isometrically embeddable in  .
Proof: For notationalpurposes,let V = {1,2,...,n}. The mapping : V R|V | isgivenby
 
(v)=(d(1,v),d(2,v),...,d(n,v)). 
Using properties of metrics, we have 
d(u,v)= = |d(u,u)d(u,v)| 
 max d(i,u)d(i,v)
iV | | 
= /bardbl(u)(v)/bardbl 
= ((u),(v)). 
On the other hand, the triangle inequality gives 
((u)(v))i = d(i,u)d(i,v)d(u,v) 
((v)(u))i = d(i,v)d(i,u)d(u,v) 
for all i, so ((u),(v))=maxiV |((u)(v))i|d(u,v). 
/square 
Remark8 The 2-embeddable nite metrics are 1-embeddable. 
Theproofforthiswillberevisitedinthenextlecture. FornowwereturntotheMulticommodity-Cut 
problem, and how metrics can help us get an approximation algorithm for it. 
Back to multicommodity cut 
In the notation of metric spaces, we have the following. (M M   means M isisometrically 
embeddablein M  ) 
Theorem4 
e=(i,j)E u(e)(i,j) 
  = min 
 :(V,) k fi(si,ti)i=1 
e=(i,j)E u(e)(i,j) 
  = min k :(V,)1 fi(si,ti)i=1 
(Notethattheonlydierencebetweenthesetwoexpressionsistheclassofmetricsinwhich wepermit 
(V,)to reside. Thus, since  minimizes over a larger space, we have   immediatelyas we 
expect.) In the following lecture, we show an algorithm to compute  approximately, making use 
of the above. 
References 
[1] M.X. Goemans and D.P. Williamson, Improved Approximation Algorithms for Maximum Cut 
andSatisability ProblemsUsing SemideniteProgramming,J.ACM,42,11151145,1995. 
[2] U. Feige and G. Schechtman, On the optimality of the random hyperplane rounding technique 
forMAXCUT,Algorithms,2000. 
[3] J. Hastad, Some optimal inapproximability results, J. ACM, 48, 798869, 2001. 
19-6</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>/square By linearity of expectations, we have: 
E[w(S : S)] = E[ 
(i,j) wij {1if (i,j)(S : S); 0otherwise}] 
 
= wij Pr[(i,j)(S : S)]. 
(i,j) 
If we were in dimension 2 then vi and vj are separated by the line orthogonal to r if and only 
if this line falls between vi and vj and this occurs with a probability (vi,vj )/ (where (vi,vj ) 
denotes the angle between vi and vj ). The same is also true for higher dimensions. Indeed, let p 
denote the projection of r onto the 2-dimensional space F spannedby vi and vj . We have 
T T rvi = pvi 
T T rvj = pvj 
implying that vi and vj are separatedforthepartitiondenedby r if and only if they are separated 
forthepartitiondenedby p. But p/pis uniform over the unit circle in F. Therefore, ||||
Pr[(i,j)(S : S)]= (vi,vj )/ 
and, using the fact that vi and vj are unit vectors(andthus viT vj =cos(vi,vj )): 
Pr[(i,j)(S : S)]= cos 1(viT vj ). 
So, we get a closed-form formula for the expected weight of the cut produced: 
E[w(S : S)]= wij cos 1(viT vj )/. 
(i,j) 
On the other hand, we know that 
SDP = wij (1v T vj )/2.i 
(i,j) 
Since wij is non-negative, E[w(S : S)]/SDP the smallest ratio over all(vi,vj ): 
E[w(S : S)]/SDP  min (cos1(x)/)/[(1x)/2] 
1x1 
=: (0.87856). 
Several remarks are in order. 
Remark2 The analysis is tight in the sense that, for any &gt; 0, there exist instances such that 
OPT/SDP  + .[2] 
Remark3 ItispossibletoderandomizeGoemans-Williamson(and achieve aperformanceguaran
tee of );still, in practice, the fact that one can output many cuts is useful as one can then exploit 
the variance of the weight of the cut. 
Remark4 No approximation algorithm achieving better than  is currently known. 
Remark5 Approximating MAXCUT within 16/17 (.94117) + for any &gt; 0 is NP-hard[3]. 
Approximating MAXCUT within  +  for any &gt; 0 is UGC-hard; that is, an ecient algorithm 
doing such would imply the falsity of the Unique Games Conjecture. 
Remark6 It can be shown that the SDP relaxation above always has an optimal solution in dimen
sion r where r(r
2+1 n (i.e. r 2n). 
19-3</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Approximation algorithms (max-cut)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec18/</lecture_pdf_url>
      <lectureno>18</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>3 all edges. However, if we start from a cut in which the edges of the cycle alternate in and out 
of the cut, we have a locally optimum soluti on with only k/2 edges in the cut. 
(b) The local search algor ithm based on the MOVE neighborhood for MAX-CUT takes expo
nentially many steps in the worst-c ase. This is true even for graphs that are 4-regular (each 
vertex has exactly 4 neigh bors) (Hak en and Luby [1]). For 3-regular graphs the algorith m is 
polynomial (Poljak [4]). 
(c) To captu re the complexity of local search, John son, Papad imitri ou and Yannakakis [3] have 
den ed the class PLS (Polynomial Local Search). Members of this class are optimization 
problems of the form max{f(x): x  S} together with a neigh borhood N : S 2S . We say 
that v  S is a local optimum if c(v) = max{c(x) : x  N(v)}. To be in PLS, we need to 
have polynomial -time algori thms for (i) nding a feasible solution, (ii) deciding if a solution is 
feasible and if so compu ting its cost, and (iii) decidin g if a better solution in the neighborhood 
N(v) of a solution v exists and if so nding one. They introduce a notion of reduction , and 
this leads to PLS-complete problems for which any problem in PLS can be reduced to it. Their 
notion of reduction implies that if, for one PLS-complete problem , one has a polynomial-time 
algor ithm for nding a local optimum then the same true for all PLS problems. In particular , 
MAX-CUT with the MOVE neigh borhood is PLS-complete [5]. Furthermore, it follows from 
Johnson et al. [3] that the obvious local search algorith m is not an ecient way of nding 
a local optim um for a PLS-complete problem; indeed, for any PLS-compl ete problem, there 
exist instance s for which the local search algorit hm of repeatedly nding an impro ved solution 
takes exponential time. The result of Haken and Luby above is thus just a special case. Still, 
this does not preclud e other ways of nding a local optimum. 
Idea #2: Rando m Cut 
Algorithm: There are 2|V | possible cuts. Sample a cut randomly using a uniform distri bution over 
all possible cuts in the graph: v  V, Pr(v  S)= 1 , independently for all vertice s v  V .2 
Lemma 2 This randomiz ed algori thm gives a cut with expected weight that is  1 OPT .2 
Proof of lemma 2: 
E[w(S :  S)] = E[  
w(e)I(e  (S :  S))] =  
w(e)  P r(e  (S :  S)) 
= eE 
 
w(e)  1 
2 = 1 2 w(E). eE 
eE 
 
Using the method of conditional expectations, we can transform this randomized algor ithm into 
a determin istic algori thm. The basic idea is to use the following identity for a random variab le f 
and event A: 
E[f]= E[fA]Pr(A)+ E[fA]Pr(A) = E[f|A]Pr(A)+ E[f|A](1  Pr(A)) 
 max|
{E[f|A],E[f|A]|
}. 
In our settin g, we consider the vertices in a specic order, say v1,v2, , and suppose we have  
already decided/conditioned on the position (i.e. whether or not they are in S) of v1, ,vi1.  
Now, cond ition on whether vi  S. Letting f = w(S : S), we get: 
E[f|{v1,  ,vi1} S = Ci1] 
 max(E [f|{v1,  ,vi1} S = Ci1,vi  S],E[f|{v1,  ,vi1} S = Ci1,vi /S]). 
Lec18-2</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>[4] S. Poljak, Integer Linear Programs and Local Search for Max-Cut, SIAM J. on Com puting, 
24, 1995, pp. 822-839. 
[5] A.A. Schaer and M. Yannakakis, Simple local searc h problems that are hard to solve, SIAM 
Jour nal on Compu ting, 20, 5687, 1991. 
Lec18-7</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>5 (a) This LP can be solved in a polynomial time.	One possibility is to use the ellipsoid algor ithm 
as the separation problem over these inequ alities can be solved in polynomial time (this is not 
trivial). Anoth er possibil ity is to view the feasible region of the above linear progr am as the 
projection of a polyhedral set Q  Rn 2 with O(n3) number of constraints; again, this is not 
obvious. 
(b) If the graph	 G is planar, then all extrem e points of this linear program are integral and 
corres pond to cuts. We can therefore nd the maximum cut in a planar graph in polynomial 
time (there is also a simpler algor ithm working on the planar dual of the graph). 
(c) There exist instances for which OPT  1 (or G =(V,E),w(e)=1,OPT  n( 1 + ), LP LP 2	 2 
n(1  )), which means that any round ing algori thm we could come up with will not guarantee 
a factor better than 1 .2 
Idea #4: SDP relaxati on 
The idea is to use semidenite programm ing to get a more useful relaxati on of the maxim um cut 
problem. This is due to Goemans and Williamson [2]. 
Instead of dening variables on the edges as we did in the previous section, lets use variables on 
the vertices to denote which side of the cut a given vertex is. This leads to the following quad ratic 
integer formulation of the maximum cut problem: 
max  
w(i,j)1  yiyj 
2 (i,j)E 
s.t. yi {1, 1}n i  V. 
Here we have den ed a variable yi for each vertex i  V such that yi = 1 if i  S and yi = 1 
otherwise. We know that an edge (i,j) is in the cut (S : S) i yiyj = 1, and this explains the 
quadrat ic term in the objective function. 
We can rewrite the objective function in a slightly more convenient way using the Laplacian of 
the graph. The Laplacian matrix L is dened as follows: 
 
0 (i,j) /   E 
lij = w(i,j) i = j, (i,j)  E  
 
=i w(i,k) i = j. k:k
that is, the o-diagon al elements are the minus the weights, and the diagonal elements corres pond 
to the sum of the weights incident to the corresponding vertex. Using the Laplacian matrix , we can 
rewrite equivalently the objective function in the following way: 
n n n   
y T Ly = yiyj lij = y 2 
i w(i, k)  yiyj w(i, j) 
i=1 j=1 i=1 k=i  (i,j)E  
= 2w(E)   
yiyj w(i, j) = 4   
w(i, j) 1  yiyj 
2  , 
(i,j)E (i,j)E 
and thus  
w(i, j) 1  yiyj 
2 = 1 
4y T Ly. 
(i,j)E 
Lec18-4</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6. 854 Advanced Algorithms November 19, 2008 
Appro xima ion Algor ithms: MAXCUT 
Lecturer: Michel X. Goemans 
1 MAX-CUT problem 
MAX -CUT Problem: Given a graph G =(V,E) and weights on the edges w : E R+, nd a 
cut (S : S),S  V that maximize s w(S : S) =  
S) w(e).  
e(S:
MIN-CU T Problem: nd a cut (S : S) that minimizes w(S : S). 
There is a polynomial algorith m for the MIN- CUT problem: use the min s  t cut algor ithm 
on each pair of vertices (or, better, for a xed s), and take the smallest of them. However, the 
MAX-CUT problem is NP-hard, and well try several ways of designing approximation algorith ms 
for it. 
2 Idea #1: Local Search 
Algorithm: Start from any cut (S : S). Dene the neigh borhood N(S : S) of the cut to be the 
MOVE neigh borhood: all the cuts that result from moving one vertex from one side of the cut to 
the other side. Consider a locally maxim um cut for this neigh borhood. 
1Lemma 1 If (S : S) is a local maximu m for the MOVE neighb orhood, then w(S : S)  2 w(E) 
1 OPT .2 
Proof of lemma 1: Look at a vertex i  V . Let Ci be the set of all edges (i,j)  E that are 
part of the cut (S : S) (that is if i  S then j  S  and vice versa). Let Ai be the set of all edges 
(i,j)  E that are not part of the cut (S : S). Since moving any single vertex i to the other side of 
the cut does not improve the weight of the cut, we know that: 
w(Ci)  w(Ai). 
Summing over all vertice s i, we get: 
w(Ci)  w(Ai), 
iV iV 
or 2w(S : S)  2w(E\(S : S)). Rearranging, we get: 
4w(S : S)  2w(E) 
or 
w(S :  S)  1 
2 w(E)  1 
2 OP T. 
 
Remark s: 
(a) The bound of 1/2 cannot be impr oved for this MOVE neighborhood: Consider a k-vertex 
cycle, where k is a multiple of 4, as the graph G (with unit weights). The best cut will includ e 
Lec18-1</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>(b) Dual regularity condi tion: First consider the dual problem 
1min 4 zi 
iV 
z1 0 ... 0 
0 z2 ... 0 
. . . . . . .. . . . . 
0 0 ... zn   
  L  0, s.t. 
where zi  R for all i 
z1 0 ... 0 
0 z2 ... 0   V . The regulation cond ition is that there exist zis such that 
  L  0. This is for example satised if, for all i, zi &gt;max(L). ... . ... . .. .. 
00 ... zn 
Remark : If we add the cond ition that z1 = z2 = ... = zn to the dual then the smallest value zi 
can take is equal to max(L), and we derive that: 
n OPT  SDP  4 max(L), 
and therefore this SDP bound impro ves upon the eigenvalue bound. 
We will start the next lecture by proving the following theorem . 
Theorem 3 ([2]) For all w  0, we have that OPT  0.87856.SDP 
In order to prove this theorem, we will propose an algorith m which deriv es a cut from the solution 
to the semidenite program. To describe this algori thm, we rst need some preliminaries. From the 
Choleskys decomp osition , we know that: 
Y  0 V  Rkn ,k = rank(Y )  n, s.t. Y = V T V 
v1,...,vn s.t. Yij = v T vj ,vi  Rn .i 
Therefore, we can rewrite the SDP as a vector progr am: 
max w(i,j)1  viT vj 
2 
To be continued... s.t. (i,j)E 
i  V : 
i  V : vi = 1 
vi  Rn . 
Refer ences 
[1] A. Haken and M. Luby, Steep est descent can take exponential time for symmetric connection 
networks, Com plex Systems, 1988. 
[2] M.X. Goemans and D.P. Williams on, Impr oved Approximation Algori thms for Maxim um Cut 
and Satisab ility Problems Using Semiden ite Programming, J. ACM, 42, 11151145, 1995. 
[3] D.S. Johnson, C.H. Papadimitr iou and M. Yannakakis, How easy is local search, Jour nal of 
Com puter and System Sciences, 37, 79100, 1988. 
Lec18-6</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 Both terms in the max can be easily compu ted and we can decide to put vi on the side of the cut 
which gives the maximum, i.e. we set Ci to be either Ci1 or Ci1 {vi} in such a way that: 
E[f|{v1,  ,vi1} S = Ci1  E[f|{v1,  ,vi} S = Ci]. 
When we have processed all inequal ities, we get a cut (Cn : C n) such that 
1 
2 w(E)  E[f]  w(Cn : C n), 
and this provides a determin istic 0.5-app roximation algor ithm. 
Examining this deran domize d version more closely , we notice that we will place vi on the side 
of the cut that maximize s the total weight between vi and the previou s vertices {v1,v2, ,vi1}.  
This is therefore a simple greedy algori thm. 
Remark s: 
(a) The performance guaran tee of the randomized algorith m is no better than 0.5; just consider 
the complete graph on n vertice s with unit weights. Also, the performance guarantee of the 
greedy algori thm is no better than 0.5 int he worst-c ase. 
Idea #3: LP relaxation 
Algorithm: Start from an integer-LP formulation of the problem : 
Since we have a variable xe for each edge (if xe = 1 than e  (S : S)), we need the second type of max w(e)x e 
eE 
s.t. xe  {0, 1} e  E   
eF eC\F xe + (1  xe)  |C|  1 
  cycle C  E F  C, |F | odd 
 
eF eC\F xe  xe  |F |  1 cycle C  E F  C, |F | odd 
 
constrain ts to guarantee that S is a legal cut. The validity of these constraints comes from the fact 
that any cycle and any cut must interse ct in an even number of edges . even number of edges that 
are in the cut. 
Next, we relax this integer program into a LP: 
max w(e)x e 
eE 
s.t. 0  xe  1 e  E 
xe  xe |F | 1 cycle C  E F  C, |F | odd. 
eF eC\F 
This isa relaxation of the maxim um cut problem, and thus provides an upper bound on the value 
of the optimum cut. We could try to solve this linear program and devise a scheme to round the 
possibly fraction al solution to a cut. 
Remark s: 
Lec18-3</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Thus the maxi mum cut value is thus equal to 
1 max{ 4 y T LY : y {0, 1}n}. 
If the optimization was over all y  Rn with ||y||2 = n then we would get that 2 
1	 n max{ 4y T LY : y  Rn , ||y||2 = n} =4 max(L), 
where max(L) is the maximum eigen value of the matrix L. This shows that OPT  n max(L);4 
this is an eigenvalue bound introduced by Delorme and Poljak. 
Using semidenite programm ing, we will get a slightly better bound . Using the Frobenius inner 
product, we can again reform ulate the objective function as: 
1 1 y T Ly = L (yy T ),4 4  
or as 1 LY4  
if we dene Y = yyT . Obse rve that Y  0, Y has all 1s on its diagonal, and its rank is equal to 
1. It is easy to see that the coverse is also true: if Y  0, rank(Y ) = 1 and Yii = 1 for all i then 
Y = yyT where y  {1, 1}n . Thus we can reformulate the problem as: 
1 max LY4  
s.t.	 rank(Y )=1, 
i  V : Yii =1, 
Y  0. 
This is almost a semiden ite program except that the rank condition is not allowed. By removing 
the condition that rank(Y ) = 1, we relax the problem to a semiden ite program, and we get the 
following SDP: 
1 SDP = max LY4  
s.t.	 i  V : Yii =1, 
Y  0. 
Obviously , by removing the condition that rank(Y ) = 1 we only increas e the space on which we 
maximize , and therefor e the value (simply denoted by SDP ) to this semiden ite program is an 
upper bound on the solution to the maximum cut problem. 
We can use the algor ithms we described earlier in the class to solve this semidenite program 
to an arbitrary precision. Either the ellipsoid algori thm, or the interior-p oint algor ithms for conic 
programm ing. Remember that semideni te programs were better behaved if they satised a regular 
ity condition (e.g., they would satisfy stron g duality). Our semiden ite programm ing relaxation of 
MAX CUT is particularly simpl e and indeed satises both the primal and dual regularity conditions: 
(a)	Prima l regularit y condi tions Y  0 s.t. Yii =1 i. This cond ition is obviously satised 
(consider Y = I). 
Lec18-5</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Conic programming II</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec15/</lecture_pdf_url>
      <lectureno>15</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>K = R+ 	n 
	     K = p    K              
K = {X : yXy  0, y  Rp,y =0}  
               K            Rn   K 
       K         K = {s : x,s 0,  x  K}  
          
min c,x  Ax = b, 
x  K. 
          
max b,y  Ay + s = c, 
s  K, 
  A        A          
      
                             
    
      F : int(K ) R         
 F        
 (xk  x  K as k )  (F (xk)  as k ) 
        F       xk             K  
                             
         
 : min c,x + F (x)  Ax = b, 
(x   (K)).</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Axk+1 = b 
Ayk+1 + sk+1 = c 
sk+1 + k+1F (xk+1)=0 
            xk+1             F (xk+1) 
F (xk+1) F (xk)+(xk+1  xk)2F (xk) 
                xk+1               
  
x = xk+1  xk  
y = yk+1  yk  
s = sk+1  sk  
           k                    
                              
                           
    dk (xk,sk)  0.1  
k k+1 = 1+ 0.1 
 dk+1(xk+1,sk+1)  0.1 
                           
   x(k)                            
             
       
                              
                x0,y0,s0   O( log &lt;x0
,s0&gt; ) 
  
              n2               
    n                             
         n2         n           
       
              x                    
                                   
                             
                                 
                        x()</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>1 
x2
1 0  
2F (x)=  .    
10  2xn 
                             
             
  x12 0  
    
(2F (x))1 = . 
0 x2  n 

aT   b2 
1    0 
   
0    b2 
n  + x1 s  ab a                 =  
  
= 1 2 
= xj sj+ x1 2 
 1 . s sj 
 2xj xj x j j 
                         
      
          
X  S1  
x = S  X1 . 
s 2 21 1 1 1 1
2SX 12 12XS 12Tr X  I = Tr S  I =    
            Tr(AB )= Tr(BA)    A  B     
                     Tr( 1 SX  I)2   
                              
        
    d(x,s)  1  x,s 2  
                  1          0  
        0                      
         
      k         k  xk        x(k)       
  k+1 &lt;k  xk+1          x(k+1) 
       k      xk,sk,yk,k              
        xk+1,sk+1,yk+1,k+1</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>s = F (x).  
    s       c  s = Ay          
                F (x)          
   1 sj   =0,j =1 ...n xj 
   
s = x1 ,  
                    x           s  K 
    X       K = p         y  Rm  S   p  
 Ay + S = C, 
 S  X1 =0. 
  Ay = i yiAi         
               F  X            
          X           
 y, c + F (X)= Ay,  
  A          
F (X)= X1 .  
      X                     
    
F (X) 1  det X Cij ,xij =  det X xij =  det X 
  Cij          (i,j)           
             i  
det X = xij Cij . 
j 
      Cij     xij = xji             
             
c  X1 = Ay. 
   S = X1                    
S  K  S  0    X              
                       y,s            
 x,  Ax = b  x + F(s)=0             x  s1 =0     xs =   
   X  S1 =0    XS = I</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>x         (y,s) 
                          s,x
     x()                (y(),s())  
                           
             x(),s()                
                                 
               
                    s = x1     
       
x(),s() = xj () /x j ()= n.  
j 
     0 x(),s() 0 
         
X(),S() = X() S()= Tr(X() S()) = Tr(Ip)= p,   
  Ip              p      0 X(),S() 0 
        
                           
                      
     Q  Rn              F : Q  Rn           
                             
 |D3F (x)[h,h,h]| 2(D2F (x)[h,h])3/2 
 |DF (x)[h]|2  D2F (x)[h,h]  
 F (x)   x  Q 
  DkF (x)[h,...,h]   k       F  x     h  Rn   
                         
            
                x, &gt; 0,F (x)= F (x)   ln(). 
                              
            K = R+n  
n
F (x) =  ln(xj ) 
j=1 
n
= n ln()  ln(xj ) 
j=1 
= n ln()+ F (x) 
          = n</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>=    =0               
                  x   (K)         F    
           K               
 : max b,y F(s)  Ay + s = c, 
(s   (K)), 
  F        K 
                                   
                        
  K = R+ : F (X)=  n ln(xj ) n j=1 
  K =  p : F (X)=  ln(det(X )),  
    F  
                 X         det(X )  
             i    F (X)=  ln(j )               j 
    
            0       =0      
                                
               0               
       =                           
               
     
                              
                        
    x       K n = R+        y  s     
 Ay + s = c, 
 s  x1 =0. 
      F                    
                            
 y, c + F (x)= Ay</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>x             
          
                           x    
               =</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>K = p       
F (X)=  ln(det( X)) 
=  ln(p det(X )) 
= p ln( )  ln(det(X )) 
= p ln( )+ F (X) 
          = p  
       
                
       x0         y0,s0            0    
                       x(0)       s(0),y(0) 
                      
      k            xk,yk,sk         x(k)  
     s(k),y(k)                 
   0                 
                       
          
                                
         x   s    d(x,s)            
                           
d(x,s)=0  s + F (x)=0. 
                   d(x,s)=0  x + F(s)=0   
                                
                        
                     1          d(x,s)=0  
s + F (x)=0  x + F(s)=0 
                              
                  x          s    
d(x,s)= = . s x + F (x) + F(s) x s 
2F (b)         ab     ab = (2F (b))1a,a   
  
      
                    F (x)      
1 
x1
  
F (x)= x1 = . 
1 
xn</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>LP: ellipsoid algorithm</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec12/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6.854 Advanced Algorithms	 October20,2008 
Lecture 12 -Ellipsoid algorithm 
Lecturer: Michel X. Goemans 
In this lecture we describe the ellipsoid algorithm and show how it can be applied to the linear 
programmingproblem. 
1 Ellipsoid algorithm 
1.1 Denitions 
An ellipsoid isdenotedby 
E(a,A)= {x  Rn :(x  a)T A1(x  a) 1}, 
with center a  Rn and A  Rnm thatispositivedenite. 
Recall that A is symmetric if A = AT .Amatrixis positivedenite ifitissymmetricand x /ne}ationslash=0, 
wehave xT Ax &gt; 0. The inverse of a positive denite matrix is also positive denite. Symmetric 
matriceshaveonly real eigenvalues,andpositivedenitematriceshaveonly realpositiveeigenvalues. 
1.2 Problem statement 
Given P  Rn bounded, closed, convex, nd x  P or show that P = . 
1.2.1 Assumption: Separation oracle 
The rst issue is how the convex set P is given. We assume that we have a separation oracle for 
P which does the following. Given a, the oracle either 
1.	arms that a  P , or 
2.	outputs c  Rn such that P {x  Rn : cT x&lt;cT a}. 
Think of c as the normal vector of the plane separating a and P , pointing away from P . Such a 
hyperplane exists because P is convex and closed. 
An algorithmfor ourproblem wouldbejudgedbased onhow many timesitqueriesthe oracle. 
We wouldlikethe number ofqueriestobepolynomialinterms of theinputdata. 
1.2.2 Assumption: Outer ball and minimum volume 
As such, the problem is hopeless, since we do not know where to search for a point x  P , and P 
may even containjust a singlepoint x. So we make two further assumptions. They are 
	P  bigball,i.e. P  B(0,R), a ball with center 0 and radius R&gt; 0. This tell us where 
out search can be conned. 
	If P /ne}ationslash= , P has sucient volume. Lets say we aregiven r&gt; 0 such that we areguaranteed 
that P contains some ball of radius r if P is non-empty. 
We consider the size of our input to be n +logR  logr. 
12 -Ellipsoid algorithm-1</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Proof: By symmetry, Ek+1 is an axis-aligned ellipsoid with center along the x1 axis. It has to 
contain all points with x1 = 0. See Fig. (2). Formally, we want Ek+1  Ek {x : x1  0}, and 
one can showthatitis enoughtoguaranteethat(i) e1  Ek+1 and(ii) for all x with /bardblx/bardbl = 1 and 
x1 =0, we have x  Ek+1. 
ck=e1 P Ek=E(0,I) Ek+1 
0 
Figure 2: Diagram illustrating the case where Ek = E(0,I). 
Weproposethefollowing 
 2  2 n  
n +1 1 n 2  1  2Ek+1 = x : x1  + xi  1 n n +1 n2 
i=2  1 n2  2 T  
= E e1, I  e1e1 . n +1 n2  1 n +1 
It is easy to verify that this ellipsoid satises the constraints above. Since the volume of an 
ellipsoid is proportional to the product of its axis lengths, we obtain: 
Vol(Ek+1) n n2 n1 
Vol(Ek )= n +1  ( n2  1) 2 
1 1 n  1 &lt; exp  exp n +1 n2  12 
1 =exp  ,2(n +1) 
where wehave used thefactthat1+ x&lt;ex whenever x =/ne}ationslash0(for x =0 we have equality).  
Next, we do a slightly more general case. 
Claim 3 Proposition 1 holds when Ek = E(0,I), ck = d and /bardbld/bardbl =1. 
Proof: From the previous simple case, it is clear that the following Ek+1 works. 
 2   1 n 2 Ek+1 = E  d, I  ddT . n +1n2  1 n +1 
12 -Ellipsoid algorithm-3</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>1.3 Sketch of the algorithm 
Here is an outline of the ellipsoid algorithm: 
	Start with ellipsoid E0 =(a0,A0). 
	Maintain an ellipsoid Ek =(ak,Ak) P . At iteration k, ask the oracle if ak belongsto P . 
	If answer is yes, then we are done. 
	If ak does not belong to P ,thenthe oracleprovides a ck such that P {x  Rn : cT x&lt; 
c T
k ak}.Thus,theseparatinghyperplaneslices Ek and P isononesideof thishyperplane. 
We then determine a smaller ellipsoid Ek+1 such that 
Ek+1  Ek {x : c T
k x&lt;cT
k ak}.	 (1) 
	(RefertoFig. (1)). 
	Notice that Ek  P and we iterate on. If we can show that volume of Ek+1 decays 
exponentially,thenin few iterations,weeithernd apointin P , or reach Vol(Ek+1)&lt; 
Vol(B(0,r))and conclude that P = . 
Ek 
Ek+1 ck P ak 
Figure 1: Diagram illustrating a single iteration of the ellipsoid algorithm. 
1.4 Bounding volume of ellipsoids 
Proposition 1 Given Ek = E(ak,Ak)and ck, we can nd Ek+1 such that Eq. (1)is satised and 
Vol(Ek+1)  1  
&lt; exp  . Vol(Ek ) 2(n +1) 
Let us rst focus on the simple case in which our ellipsoid is the unit ball centered at the origin. 
Claim 2 Proposition 1 holds for the special case where Ek = E(0,I)and ck = e1. 
12 -Ellipsoid algorithm-2</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>1.5 Running time 
From Proposition 1, we know that Vol(Ek)&lt; Vol(E0)exp  2(nk 
+1) . If P is nonempty, then the 
ellipsoid algorithm terminates in 
Vol(E0)# iterations = On log . Vol(P ) 
Vol(E0) R n By our assumption on P containing a ball of radius r if non-empty, we have that Vol(P )  r , 
and thus the number of iterations is 
# iterations = O  
n 2(logR  logr) 
. 
If P is empty, by the same number of iterations, we are guaranteed of its emptyness. 
We conclude this section by noting a small subtlety. To compute d, we have to be able to nd B 
suchthat A = BT B. Cholesky decomposition takes O(n3)and guarantees that numbers in B have 
size polynomially bounded by the size of numbers in A. But wehaveto take square roots(in the 
calculation of d), so we might have to dealwith irrational numbers. As a result, we may have to do 
some rounding to make Ek+1 slightly bigger. We have to argue that the volume decrease factor is 
still reasonable, say exp  3(n1
+1) , but this detail shall be omitted. 
2 Applying ellipsoid algorithm to linear programming 
2.1 Linear programming problem 
Inthelinearprogrammingproblem,weareasked to nd 
min{c T x : Ax = b,x  0} 
withinputs A,b,c. The size of the input, from last lecture, is 
L = m + n +logdetmax +logbmax +logcmax. 
To apply the ellipsoid algorithm, we will need to 
1. Go from an optimization problem to a feasibility problem. 
2. Show that the initial convex set is bounded and argue about how big the bounding ellipsoid 
has to be. Argue about termination and provide an inner ball if P is nonempty. i.e. we want 
P tobe full-dimensional. 
2.2 Optimization to feasibility 
We will convert the optimization problem to a feasibility problem as follows: 
1. Check feasibility of Ax = b,x  0. 
2. If answer is infeasible, we are done because LP is infeasible. 
3. Otherwise, check feasibility of dual. Dual is max{bT y : AT y  c}. Check for feasibility of 
AT y  c. 
	If dual is not feasible, we are done because LP is unbounded. 
	Otherwise, both primal and dual are feasible. Their solutions have to match by strong 
duality. Hence, we check for feasibility of Ax = b,x  0,AT y  c,cT x = bT y to nd a 
solution for both primal and dual. 
12 -Ellipsoid algorithm-5</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>2.3 Outer and inner cubes 
Herewedescribehowtogofroma systemoflinearinequalitiesto anequivalentone(intermsof 
feasibility) which if non-empty is full-diemnsional and has enough volume. 
Proposition 4 Let P := {x : Ax  b} and e be the vector of all ones. Assume that A has full 
column rank n1 . Then P is nonempty i P  = {x : Ax  b + 21 
L e, 2L  xj  2L for all j} is 
nonempty. 
This proposition allows us to choose E0 to be a ball centered at the origin containing the cube 
2L , 2Ln . Also, if there exists a x such that Ax b then 
That gives us a little cube around The time for nding an x in P is thus O(n  nL),because  1   1  1 A x 22L  b + 22L namax e  2L e where amax is max entry of A. 
 x. 
the ratio of the volumes of 
2L , 2Ln to 
 221 
L , 221 
L n is8Ln . Recall that nding x in P takes 
O(n log V ol(E0) )iterations. That means LP takes polynomial time in L.V ol(P ) 
Proof of Proposition 4: We rst prove the forward direction. Suppose P =/ne}ationslash. Our only worry 
is whether there is any element in P insidethebig box. Thishasbeendoneinpreviouslecture. We 
consider a vertex x in P (this exists becauseA has full column rank). This implies that x isdened 
by AS x = bS , where AS is a submatrix of A. Using Cramers rule, we can write x as 
p1 p2 pn x = ,,  , qq q 
with |pi| &lt; 2L and1  q&lt; 2L . 
We now work on the converse. {x : Ax  b} =  implies, by Farkas Lemma, there exists a y 
such that y  0, AT y = 0, and bT y = 1. We can choose a vertex of AT y =0, bT y = 1, y  0. 
Rewrite this as  AT   0  
bT y = ,y  0.1 
By Cramers rule, we can bound the components of a basic feasible solution y as: 
T r1 rm  
y = ,  , , s s  AT  
with 0  s,ri  detmax bT . Expanding the determinant along the last row, we see that 
 AT  
detmax bT  mbmax detmax(A). Using the fact that 2L &gt; 2m2n detmax(A)bmax, we obtain 
m m0  s,ri &lt; 2m2n 2L  2m+1 2L . 
Therefore,  T 21 1 mb +2L ey = bT y +2L e T y = 1+ 2m+1 &lt; 0. 
1 
(Thelastinequalityholdsfor m  1.) By Farkas Lemma again, this y shows that there is no x 
satisfying Ax  b + 21 
L e,i.e. P  is empty.  
1Small detour: We have previously dealt with the constraint problem Ax = b,x  0. If this is non-empty, then 
we have a vertex in the feasible solution. However, there is not guaranteed if the constraints are of the form Ax  b. 
But if we have rank(A)= n, A  Rmn, then a non-empty P will always contain a vertex. In our case, since we 
convert from the problem with constraints x  0, we would have inequalities Ix  0 and full column rank. 
12 -Ellipsoid algorithm-6</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>2.4 Obtaining a solution 
There is one last problem. If the ellipsoid method returns a x in P , x might not be in P . 
One solution is to round the coecients of the inequalities to rational numbers and repair 
these inequalities to make x tin P . This is called simultaneous Diophantine approximations, and 
will not be discussed. 
We can solve this problem by another method. We give a general method for nding a feasible 
solution of a linear program, assuming that we have a procedure that checks whether or not the 
linear program is feasible, e.g. ellipsoid algorithm. 
Assume, we want to nd a solution of Ax  b. The inequalities in this linear program can be 
written as aT
ix  bi for i =1,  ,m. We use the following algorithm: 
1. I . 
2. For i  1to m do 
 If the set of solutions of 
ax  bj j = i +1,  ,m T
j
ax = bj j  I {i}T
j
is nonempty, then I  I {i}. 
3. Finally, solve x in aT
ix = bi for i  I with Gaussian elimination. 
We assume that the solution is a vertex and satises some equalities. If at step 2, making in
equality i anequality makestheprobleminfeasible,thenthevertexcannotdepend onthisinequality 
and we can discard it. 
12 -Ellipsoid algorithm-7</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Proof of Proposition 1: 
Ingeneral, we cantransform E(ak,Ak)to E(0,I)and map ck into some d. We can then nd an 
ellipsoid E as in the proof of Claims 2 and 3, and map it back to obtain Ek+1. Denote the linear 
transformation that maps E(ak,Ak)into E(0,I)as T . Here is a picture: 
T Ek  E(0, 1) 
 
T 1  Ek+1  E 
Recall that we have 
E(a,A)= {x :(x  a)T A1(x  a) 1}. 
ByCholeskydecomposition(since A ispositivedenite),wecanwrite A = BT B forsomematrix 
B. If we let y =(B1)T (x  1), then we have 
(x  a)T B1(B1)T (x  a) 1 
() y T y  1, 
so we have a unit ball in the y space. Thus, our linear transformation T and its inverse are: 
T (x)= y =(B1)T (x  ak), 
T 1(y)= ak + BT y. 
We need an equivalent half-space constraint after applying T . From Eq. (1), 
T T ck x&lt;ck ak 
c T
k (BT y + ak)&lt;cT
k ak 
ckT BT y&lt; 0. 
Hence,inthe new space,the unit normal vector of the separatingplaneis 
Bckd =  . 
ckT BT Bck 
FromClaim3,wecan ndanellipsoid E inthey space.Forconvenience(and aestheticpleasure), 
let b = BT d. 
Apply T 1 to E to obtain 
Ek+1 = E(ak+1,Ak+1) 
1 1 ak+1 = ak  BT d = ak  b n +1 n +1  2   2   n 2 n 2 Ak+1 = BT I  ddT B = Ak  bbT . n2  1 n +1 n2  1 n +1 
Sinceanetransformationspreservetheratiosbetweenvolumes,weimmediatelyhavethedesired 
bound. Here are the details. 
Vol(E(0,I))=det((B1)T )Vol(Ek) 
Vol(Ek+1)=det(BT )Vol(E  ). 
Rearranging, we have
V ol(Ek+1) V ol(E  )  1 
= &lt; exp  . V ol(Ek) V ol(E(0,I)) 2(n +1) 
12 -Ellipsoid algorithm-4</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Maximum flow; minimum cost circulation</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec3/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6. 854 Advanced Algorithms September 10, 2008 
Lecture 3 
Lecturer: Michel X. Goemans 
1 Introducti on 
Today we continue our discuss ion of maximum ows by introducing the fattest path augmenting 
algor ithm, an improvement over the Ford-Fulkerson algor ithm, to solve the max ow problem. We 
also discuss the minimum cost circulation problem. 
2 Maximum Flow 
In a maxi mum ow problem, the goal is to nd the greatest rate (ow) at which material can be 
sent from a source s to a sink t. Several problems can be modeled as a max-o w problem, includ ing 
bipartite matc hing, which will be discussed today. We will also discuss ow decomposition and the 
fattest augme nting path algorith m. 
2.1 Maximum Cardinality Matc hing in Bipartite Graphs 
A bipartite graph is a graph G =(V,E) whose vertex set V can be partitioned into two disjoi nt sets, 
A and B, such that every edge connects a vertex in A to one in B.A matching M is a subset of E 
such that the endpoints of all the edges in M are distinct. In other words, two edges in M cannot 
share a vertex. We are interested in solving the following problem: Given an undirected bipartite 
graph G =(V,E) where V = A  B, nd a matching M of maxim um cardinality. 
We can formulate this maximum cardinality matc hing problem as a max-o w problem. To do 
that, consider the network shown in Figure 1. 
Figure 1: The gure on the left represents a matc hing in a bipartite graph. The gure on the right 
shows how the bipartite graph can be converted into a max-ow network by imposing a capacity of 
1 on arcs out of s and into t. 
3-1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>3.1 Vertex Potentials 
Before we can solve MCCP, it is necessary to introduce the concept of vertex potentials, or simpl y 
potentials. 
Deniti on 4 A vertex potential is a function p : V  R that assigns each vertex a potent ial. The 
vertex potential denes a reduced cost function cp such that 
cp(v,w)= c(v,w)+ p(v)  p(w). 
Prop osition 5 The function cp satises the following properties: 
(i) Skew- Symmetry: cp(v,w)= cp(w,v). 
(ii)	Cycle Equivalenc e: for a cycle C, c(C)= cp(C); i.e., the reduced cost function agrees with 
the cost function. 
(iii)	Circulation Equi valenc e: for all circulations, the reduced cost function agrees with the cost 
function, c(f)= cp(f). 
Proof: The rst property is trivial. The second property follows since all the potential terms 
cance l out. And well prove the third property. By denition 
cp(f)= (c(v,w)+ p(v)  p(w))(f(v,w)) 
(v,w) 
= c(f)+ p(v) f(v,w)  p(w) f(v,w). 
v w:(v,w)E w v:(w,v)E 
Now by ow conservation , the inner sums are all zero. Hence cp(f)= c(f). (The third property also 
follows easily from ow decomposition, as the decomposition of a circulat ion only contains cycle s 
and thus the cost and the reduced cost of a circulat ion are the same because of (ii).)  
3.2 Kleins Cycle-Cance lling Algorithm 
We prese nt a pseudo-algorit hm for removing negative-cost cycles . While there exists a negativ e-cost 
cycle C in Gf , push a ow  along the cycle C, where  is the minimum residual ow: 
 = min uf (v,w). 
(v,w)C 
Of course , this doesnt lead to a straight-forw ard impleme ntation, since we havent specied which 
negativ e-cost cycle to select or how to nd them. We should also consider whether the algor ithm is 
ecient and whether it will terminate. Well answ er these question s in the next lecture. However, 
we will show now that if it termin ates, then the circulation output is of minimum cost. 
3.3 Optimality Conditions 
We now present a theore m that species the conditions requir ed for f to be a minimum cost circu
lation. 
Theorem 6 (Optim ality Cond ition) Let f be a circulation. The following are equivalent: 
(i) f is of minimum cost. 
(ii) Ther e exists no negative- cost cycle in the residual graph Gf . 
3-5</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>| 
 
 3 which impli es 
|f||fnew| = |f||f + |f||fnew|
1  1  m (|f||f|) . 
After k iterati ons, we get a ow f such that 
k 
|f||f| 1  m 1 mU. 
Eventually ff&lt; 1 which implies f = f since , for integral capaciti es, all interme diate ows |||| 
1 1will be integral. Since (1  m )m  e for all m  2, the number of iteration s requi red for the 
dierence to go below 1 is 
k = m log(mU). 
Combining the results mentioned above we have the following corollar y. 
Corollary 4 We can nd a maxim um ow in an integer-capacitat ed network with maxim um capacity 
U in O((m + n log n)m log(nU )) time 2 . 
Minimum Cost Circulation Problem (MC CP) 
A circulation is simply a ow where the net ow into every vertex (there are no sources or sinks) is 
zero. Notice that we can easily transfor m an s  t ow to a circulation by adding one arc from t to 
s (with innite capacit y) which carries a ow equal to the s  t ow value. 
Deniti on 1 A circulation f satises 
(i) Skew- Symmetry:  (v,w)  E, f(v,w)= f(w,v). 
(ii) Flow Conservation:  v  V , f(v,w)=0. w 
(iii) Capacity Constr aints:  (v,w)  E, f(v,w)  u(v,w). 
Deniti on 2 A cost function c : E  R assigns a cost per unit ow to each edge. We assume the 
cost function satises skew symmetry : c(v,w)= c(w,v). For a set of edges C (e.g. a cycle), we 
denot e the total cost of C by :  
c(C)= c(v,w). 
(v,w)C 
Deniti on 3 The goal of the Minimum Cost Circulation Problem (MCCP) is to nd a circulation 
f of minimu m cost c(f) where  
c(f)= c(v,w)f(v,w). 
(v,w) 
The MCCP is a special case of a Linear Programming (LP) problem (an optimiz ation problem 
with linear constrain ts and a linear objective function). But while no strongl y polynomial time 
algor ithms are known for linear programm ing, we will be able to nd one for MCCP. 
2Using the previou s footnot e, we can do this in O(m2 log(nU)) time . 
3-4</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>(iii) Ther e exists a potential function p such that for all (v,w)  Ef , cp(v,w)  0. 
Proof: To show that (i) implies (ii), well prove the contrapositive. Suppose there exists a negativ e 
cost cycle C in the residu al graph Gf where f is the optimal circulati on. Denote by C the reverse 
cycle (i.e. following the arcs in the reverse order). We dene a new circul ation f for any edge e as 
follows. If e  C, f(e)= f(e)+ . And if e  C, then f(e)= f(e)  . Otherwise , let f(e)= f(e). 
Then we compu te the cost of this new ow as 
c(f)= c(f)+()(c(C )) + ()(c(C)) 
= c(f)+2c(C ) 
&lt;c(f), 
where the last step follows since C is a negativ e cost cycle. Thus weve shown that f is indeed not 
optimal. Hence (i) implies (ii). 
Now we show that (ii) implies (iii). Add zero-cost (or of arbitrary cost) arcs from a new vertex 
s to every vertex in Gf (this is to make sure that s can reach every vertex in V ). Den e a potential 
p such that p(v) is the length of the shortest simple path from s to v. Then, since there are no 
negativ e cost cycle, we have the optimalit y condi tions for the shortes t-path length s: 
p(w)  p(v)+ c(v,w)  (v,w)  Ef , 
as one way to go from s to w is to go to v by a shortes t path and then go directly to w. 
Here, we have impli citly used the fact that Gf has no negativ e cost cycles. For if the shortest 
path from s to v already goes through w then adding (v,w), we create a cycle C (and the resulting 
path is not simple). However, this cycle cant be of negative cost by assumpti on. Thus, by removing 
it, we obtain a simple path to w of cost less or equal to p(v)+ c(v,w). Rearran ging the inequality 
gives the desired result 
cp(v,w)  0  (v,w)  Ef . 
Now we prove that (iii) implies (i) by showing the contrapositiv e. Suppose we have an optimal 
circulati on f and a suboptimal one f: c(f) &lt;c(f). Consider the cost of the circulation f  f: 
c(f  f)= cp(f  f) 
= cp(v,w)[f(v,w)  f(v,w)] 
(v,w)E 
=2 cp(v,w)[f(v,w)  f(v,w)] 
(v,w):ff&gt;0 
 0 
by (iii). Note that in the second to last step, we utilized the skew-symme try of the cost of reverse 
arcs (with ows of opposite parity). But since f is supposed to be strictly better than f, we have 
a contradiction.  
Refer ences 
[EK72] Jack Edmonds, and Richard M. Karp, Theoretical impr ovement s in algori thmic eciency 
for network ow problems, Journal of the ACM 19 (2): 248264, 1972. 
[Klein67] Klein , M. A prim al metho d for minimu m cost ows with application to the assignment and 
transportation problem. Management Science 14: 205-220, 1967. 
3-6</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>The network is constructed as follows: We orien t each edge in G from A to B and assign them a 
capacit y of 1 (any capacit y greate r than 1 works too). We also add two new vertices, s and t, and 
arcs from s to every vertex in A, and from every vertex in B to t. All the new arcs are given unit 
capacit y. 
Theorem 1 Let G =(V,E) be a bipartite graph with vertex partition V = A  B, and let G = 
(V ,E) be the capacitate d network constructe d as above. If M is a matching in G, then there is an 
integer-valued ow f in G with value |f| = |M|. Conversely, if f is an integer-value d ow in G, 
then there is a matching M in G with cardinal ity |M| = |f|. 
Proof: Given M, den e a ow f in G as follows: if (u,v)  M, then set f(s,u)= f(u,v)= 
f(v,t) = 1 and f(u,s)= f(v,u)= f(t,v)= 1. For all other edges (u,v)  E, let f(u,v) = 0. 
Each edge (u,v)  M corres ponds to 1 unit of ow in G that traverses the path s  u  v  t. 
The paths in M have distinct vertices, aside from s and t. The net ow across the cut (A  s : B  t) 
is equal to |M|. We know that the net ow across any cut is the same, and equals the value of the 
ow. Thus, we can conclude that |M| = |f|. To prove the converse, let f be an integer-v alued ow 
in G. By ow conservation and the choice of capacities, the net ow in each arc must be -1, 0 or 
1. Let M be the set of edges (u,v), with u  A, v  B for which f(u,v) = 1. It is easy to see, by 
ow conse rvation again , that M is indeed a matching and, using the same argument as before, that 
|M| = |f|.  
Since all the capacities of this maximum ow problem are integer valued, we know that there 
always exists an integer-valued maxim um ow, and therefore the theorem shows that this maxim um 
ow formulation correc tly models the maximum cardinality bipartite matc hing. 
2.2 Flow Deco mposition 
In an (raw) s-t ow, we have the following building blocks: 
 Unit ow on an s-t directed path. 
 Unit ow on a directed cycle. 
Any (raw) s-t ow can be written as a linear combination of these building blocks. 
Theorem 2 Any (raw) s-t ow r can be decomposed into at most m ows along either paths from s 
to t or cycles , where m is the numb er of edges in the netw ork. More precisely, it can be decomposed 
into at most |{e : r(e) &gt; 0}|  m paths and cycles. 
Proof: By tracing back the ow on an edge e and tracing forward the ow on e, we either get an 
s-t path T , or a cycle T with r(e) &gt; 0 for all e  T . Denote the min ow on T by (T ): 
(T ) = min r(e). 
eT 
We want to decrease the ow on T such that at least one edge goes to 0 (by subtracting out (T )), 
and keep doing that until there are no more edges with non-zero ows. More precisely, the following 
algor ithm extracts at most m paths and cycles. 
(i) While there is a directed cycle C with positive ow: 
(a) Decrease the ow on this cycle by (C) 
(b) Add this cycle as an element of the ow decomposition 
(ii) (The set of arcs with positiv e ow now form an acyclic graph.) While there is a path P from 
s to t with positive ow: 
3-2</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>(a) Decrease the ow on this path by (P ). 
(b) Add this path as an element of the ow decomposition. 
Each time we decrease the ow on a path or a cycle T , we zero out the ow on some edge. 
When we do this, the new raw ow is rnew(e)= r(e)  (T ) if e  T , or r(e) otherwise . Since 
there are |{e : r(e) &gt; 0}|  m edges with positiv e ow in the graph , there will be at most that 
number of decreas es in the ow, and conse quently, at most that number of paths or cycle s in the 
ow decomposition.  
2.3 Fattest Augm enting Path Algorithm (Edmo nds-Ka rp 72) 
Flow decom position is a key tool in the analysis of network ow algor ithms, as we will illustrate 
now. 
As we saw in the last lecture, the Ford-Fulkerson algor ithm for nding a maximum ow in a 
network may take exponential time, or even not terminate at all, if the augme nting path is not 
chosen appropriately . We proposed two specic choices of augme nting paths, both due to Edmonds 
and Karp , that provide a polynomial running time. One was the shortes t augmenting path, the 
other was the fattest augmen ting path or maxi mum- capacity augmenting path: the augmenting path 
that increases the ow the most. This is the varian t we analyze now. 
For an augme nting s-t path P  Gf , den e 
(P ) = min uf (v,w) 
(v,w)P 
where the uf are the residual capacities. The minimum residual capacity (P ) (the bottleneck) is 
the maxim um ow that can be pushed along the path P . We wish to nd the fattest augmen ting 
path P such that (P ) is maximized. The fattes t augme nting path P can be eciently found with 
Dijkstras algorith m in O(m + n log n) time 1 . 
Theorem 3 Assumi ng that capacities are integral and bounde d by U, the optimal ow for a network 
can be found in O(m log(mU )) = O(m log(nU )) iterations of augmenting along the fattest path. 
Proof: Start with a zero ow, f = 0. Consid er a maxim um ow f. Its value is at most the value 
of any cut, which is bounded by mU: 
|f| mU. 
Consider the ow f  f (this is, f(e)  f(e) for all edges e) in the residual graph Gf with residual 
capacities uf = u  f. 
We can decompose f  f into  m ows using ow decomposition. As a result, at least one of 
these paths carry a ow of value at least 1 (|f||f|). Suppose now that we push (P ) units of m 
ow along the fattest path in the residual graph Gf and obtain a new ow fnew of value: 
|fnew| = |f| + (P ). 
Since the fattes t path provides the greate st increas e in ow value, we must have that (P ) 
1 
m (|f||f|). Thus we have the following inequality 
1 |fnew||f| + m (|f||f|), 
1Actu ally, it can be found in O(m) time under the condi tion that we have the capaciti es sorte d beforeha nd, see 
the forthc omin g problem set. 
3-3</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Conic programming I</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec14/</lecture_pdf_url>
      <lectureno>14</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>condi tion stated above; however, well get very close , and once we do, we can show that a jump 
from this non-optimal solution (for either the primal or the dual) to a vertex of improved cost (of 
the corresponding program) will provide an optimal solution to the (primal or dual) program. 
In some linear programs, it may not be possible to start with a strictly positiv e solution . For 
exam ple, for any feasible solution to the program, it may be that xj = 0, so we may be unable to 
nd a strictly feasible soluti on with which to start the algor ithm. This can be dealt with easily, but 
we will not discuss this. Well assume that the primal and dual both have strictly feasible soluti ons. 
3 Semideni te Programm ing 
As introduced in the previou s lecture, in semidenite programming, our variab les are the entries of 
a symmetric postitiv e semideni te matrix X. Let Sn denot e the set of all real, symm etric and n  n 
matrice s. For two such matrice s A and B, we den e an inner product 
AB = Aij Bij = Trace(AT B)= Trace(AB).  
ij 
Semiden ite programming (as a minimization problem) is 
Min	 C  X 
s.t. Ai  X = bi i =1...m 
X  0. 
Remem ber that for a symm etric matrix M, M  0 means that M is positiv e semidenite, meaning 
that all of its (real) eigenvalues   0, or equivalently, x,xT Mx  0. 
3.1 Dual for SDP 
When working with linear programs, we know the existe nce of a dual linear program with a stron g 
property: Any feasible dual solution provides a lower bound on the optimum primal value and, if 
either program is feasible, the optimum primal and optimum dual values are equal. Does a similar 
dual for a semiden ite progr m exist? The answ er if yes, although we will need some additional 
condi tion. We claim that the dual takes the following form. 
Dual: Find yi  Rn, and S  Sn: 
Max yRm bT y 
s.t.	 yiAi + S = C 
i 
S  0. 
14-2</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6. 854 Advanced Algorithms Octob er 27, 2008 
Lecture 14 
Lecturer: Michel X. Goemans 
1 Introducti on 
For this lecture well look at using interior point algorith ms for solving linear programs, and more 
generally convex programs . Developing originally in 1984 by Narend ra Karmark ar, there have been 
many varian ts (with some of the keywords path following , primal-dual, potential reduction , etc.) 
on interior point algorit hms, especially through the late 80s and early 90s. In the late 90s, people 
began to realize that interior point algor ithms could also be used to solve semiden ite progr ams (or, 
even more generall y, convex progr ams). As much as possible, we will discuss linear progr amming, 
semiden ite programming, and even a larger class called conic progr amming in a unied way. 
2 Linear Programm ing 
We will start with linear programming. Remember that in linear progr amming, we have: 
Prima l: Given A  Rmn , c  Rn and b  Rm, nd x  Rn: 
Min c T x 
s.t. Ax = b,x  0. 
Its dual linear program is: 
Dual: Find y  Rm: 
Max bT y 
s.t. AT y  c. 
We can introduce non-negativ e slack variables and rewrite this as: 
Dual: Find y  Rm , s  Rn: 
Max bT y 
s.t. AT y + s = c,s  0. 
We know that, for a feasible solution, x in the primal, and a feasible solut ion (y,s) in the dual, 
we know by compl ementary slackness that they will both be optimal (for the primal and the dual 
resp.) i xT s = 0. Since this is the component-wise product of two non-negativ e vectors, we can 
equiv alently say: 
xj sj =0 j. 
2.1 Using the Interior Point Algorithm 
The interior point algor ithm will iteratively maintain a strictly feasible solution in the primal, such 
that for all values of j, xj &gt; 0. Similarl y in the dual, it will main tain a y and an s such that 
for all values of j, sj &gt; 0. Because of this strict inequality, we can never reach our optimali ty 
14-1</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>We will use the barrier function to punish candidate solutions that are close to the boundary 
of K, keeping the current point inside K. Good barrier functions, that result in a fast overall 
algor ithm, have more properties that will be described in a later lecture. For K = R+n , a good 
barrier function is  
F (x)=  log(xi). 
i 
As any one of the coordinates approac hes 0, the log approaches , so the total function goes to 
. One can also check that this function is strictly convex. 
For K = svec(PSDp) or more simply K = PSDp (the set of symmetric pp positive semiden ite 
matrice s), the interior of K is the set of positive denite matri ces, which all have strictly positive 
determinan ts. (This is because the determinant is equal to the product of the eigenvalues, which 
are all strictly positiv e for a positiv e den ite matrix .) So we can use the following barrier function: 
F (X)=  log(det(X)). 
As X approaches the boundary of K, the determin ant goes to zero, and F goes to innity. One can 
also check that this function is strictly convex (its Hessian, the matri x of second derivatives, can be 
shown to be positiv e denite). 
4.3 A Primal-D ual Interior-Point Method 
Once we have a barrier function , we will set the objectiv e function of the primal to c,x + F (x), 
where  is a parame ter that we will adjust throu gh the course of the algorit hm. Assuming that we 
start with an initial candidate that belongs to int(K ), we can ignore the constrain t that x  K, 
since that will be enfor ced through the barrier function, since there will be an innite penalty for 
leaving K. Our primal barrier problem BP () will be: 
min{c,x + F (x): Ax = b}. 
Anal ogously , for the dual, we change the objective function to b,y F (s), where F  is a 
barrier function for the dual; we can also eliminate the constrai nt that s  K. Our dual barrier 
problem, BD(), is: 
max{b,y F (s): Ay + s = c}. 
The basic metho d of the algor ithm is to have a current value of , and keep track of the optimal 
soluti ons in the primal BP () and dual BD(). As long as  is not zero, there is a unique optimum 
soluti on for both, since the objective function is the sum of a linear function and a strictly-convex 
function , which results in a strictly-convex function. We will steadi ly decrease , and keep track of 
the optimal solutions as they change; the paths the optimum soluti ons trace out is called the central 
path (or central trajectory ). We will show that the (primal and dual) central paths will converge to 
an optimum value of the primal and dual original progr ams. 
In the special case of linear progr amming, once we are suc iently close , we can round the current 
soluti on to the nearest vertex to obtain an optim um solution. For semiden ite programming, though , 
we do not have such an algorith m to convert a solut ion for small enough  to an optimum soluti on. 
Lets characterize the optim um solut ion to BP () and BD(). We derive now the so-called 
KKT optimalit y conditions. If there were no constrai nts in the conic program, then the minimum 
would be found when the gradien t of the objective function is zero. If there are ane constraints 
like Ax = b, however, the minimum will occur when the gradi ent is normal to the ane space of 
feasible solution s. Otherwise , we could move along the projection of the gradient on the feasible 
space , and improve our objective function. 
For simplicity, lets rst look at the case when K = K = R+n , and the barrier function is F (x)= 
 log(xi). The objectiv e function of the primal is c,x F (x), and the partial derivatives are i 
 (c,x F (x)) = cj xj xj 
14-6</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>4.0.5 Stron g Duali ty 
In the general case, we dont know that the two values will be equal. But we have the following 
state ment (analogous to the regularity condition for SDP): if there exists an x in the interi or of K, 
such that Ax = b, and a s in the interior of K, with Ay + s = c, then the primal and the dual 
both obtai n their optimal values, and those values are equal. 
4.1 Semideni te Programm ing as a Special Case of Conic Programming 
LP is a special case of conic programm ing, if we let K = Rn and take the inner product to be the + 
stand ard dot product a,b = aTb. We can also make any SDP into a conic program; rst, we need 
a way of transfor ming semidenite matri ces into vectors. Since we are optimizing over symmetric 
matrice s, we introduce a map svec(M ) that only takes the lower triangl e of the matri x (inclu ding 
the diagon al). To be able to use the stand ard dot product with these vectors, svec multiplies all of 
the o-diagonal matrices by 
2. So svec maps X to 
(x11,x22,...,xnn, 
2x12
2x13,..., 
2x(n1)n). 
As a result: 
n
svec(X ),svec(Y ) =  
xiiyii +  
2xij 
2yij =  
xij yij = Tr(AB)= A B.  
i=1 1i&lt;jn 1i,jn 
This means that using the basic dot product as the inner product is compati ble with the inner product 
used in SDP. So we can formulate an SDP as a conic progr am by letting K = {svec(X ): X  0}, 
which is a close d convex cone. To show convexity, we need to show that if A and B are matri ces in 
PSD, then A + (1  )B is also in PSD for 0    1. Indeed, for any vector v, we have 
v T(A + (1  )B)v = v TAv + (1  ) v TBv  0. 
Then, we can let the matrix A be a matri x that is the comp osition of the corresponding Ai of 
the semiden ite program, so that 
A svec(X)=(Ai  X)i=1,. ..,m. 
Now that the semiden ite program is cast into a conic program, we could write the conic dual, and 
one could verify that what we get is precisely the dual of the semiden ite progr am we dened earlier. 
Instead of mapp ing the space of symm etric matri ces (say p  p) into Rn (with n = p+1 ) using 2 
svec(), one could simply dene K = {X  Sp : X  0} and X,Y  = X  Y . Now our linear 
operator A : Sn Rm then maps X into (Ai  X)i=1, ,m. Its adjoint A : Rm Sn is den ed by:    
m
A(y),X := y,A(X) = yiAi  X, 
i=1 
mimplying that A maps y to i=1 yiAi. The dual SDP now arises as the dual conic program. 
4.2 Barrier Functi ons 
To solve the conic progr am, we will require a barrier function F . This is a function from int(K ), 
the interior of K, to R such that 
1. F is strictly convex, 
2. F (xi)  as xi  x  K, where K is the boundary of K. 
14-5</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>so the gradi ent is c  x1, where x1 denot es the vector {1/xi}. But since this gradi ent is normal 
to the constraint Ax, the gradient must be of the form ATy for some y. So if we let s = x1, then 
we know c  s is of the form ATy, or equivalently, 
AT y + s = c 
s = x1 . 
The last constrain t is equivalent to 
xj sj =  (1) 
for all j. 
Now, looking at the dual: the gradient with respect to y is b, which must be of the form Ax for 
some x. The gradien t with respect to s is s1, which must equal the same x. This means that 
Ax = b 
s = x1 , 
and the last equality is again equiv alent to (1). 
So if we denote by x() the optimum solution to the primal BP () and by (y(),s()) the 
optimum solution to the dual BD(), one observes that each of them is a certicate of optimalit y 
for the other and furthermore: 
xj ()sj ()= . 
This means that the duality gap in the original primal/du al pair of linear programs is xT s = n 
and therefor e the duality gap goes to 0 as  goes to 0. Thus the central path (x(),y(),s()) will 
converge to optim um solutions to both the primal and dual linear progr ams. 
14-7</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>3.1.1 Weak Dual ity 
For weak duality, consid er any feasible solution x in the primal, and any feasible solution (y,S) in 
the dual. We have: 
   
C  X = yiAi + S  X 
i  
= yi(Ai  X) + S  X 
i  
= yibi + S  X 
i 
= bT y + S  X 
 bT y, 
the last inequal ity following from Lemm a 1 below. This is true for any primal and dual feasible 
soluti ons, and therefore we have z  w, where: 
z = min{CX : X feasible for primal},  
w = max{bT y :(y,S) feasible for dual}. 
Lemma 1 For any A,B  0, we have AB  0.  
Proof of Lemma 1: Any positiv e semiden ite matrix A admits a Cholesvky decomp osition : 
A = V T V for some n  n matrix V . Thus, 
A  B = Trace(AB)= Trace(V T VB)= Trace(V BV T ), 
the last inequal ity following from the fact that, for (not necessarily symmetric) square matr ices C 
and D, we have Trace(CD)= Trace(DC). But V BV T is positiv e deni te (since xT V BV T x  0 
for all x), and thus its trace is nonnegativ e, proving the result.  
A similar lemm a was used when we were talkin g about linear programm ing, name ly that if 
a,b  Rn with a,b  0 then aT b  0. 
3.1.2 Stron g Duali ty 
In general, its not true that z = w. Several things can go wron g. 
In dening z, we wrote: z = min C  X. However, that min is not really a min, but rather 
an inmum. It migh t happ en that the inmum value can be approached arbitrarily closely but no 
soluti on may attai n that value precisely. Simil arly in the dual, the supremum may not be attain ed. 
In addition, in semiden ite programm ing, it is possible that the primal may have a nite value, 
but that the dual may be infeasible. In linear programming, this was not the case. If the primal 
had a nite feasible value and was bounded, the dual was also nite and with the same value. In 
semiden ite programming, the primal can be nite, while the dual may be infeasible or vice versa. 
In addition, both the primal and dual could be nite, but they could be of diering values. 
That all said, in the typical case, you do have strong duality (z = w), but only necessarily under 
certain conditions. 
3.1.3 Introducing a Regul arity Cond ition 
Assume that the primal and dual have a strictly feasible soluti on. This means that for the primal: 
X s.t.	Ai  X = bi i = (1...m). 
X  0. 
14-3</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>A  0 denot es that A is a positive-den ite matrix, meanin g that a =0,aT Xa &gt; 0, or equivalently 
that all its eigenvalues i satisfy i &gt; 0. 
Likewise, in the dual, there exists y and S such that: 
i yiAi + S = C 
S  0. 
If we assume this regul arity cond ition that weve den ed above, then the primal value z is nite 
and attainab le (i.e. it is not an inmum, but actually a minimum), and the dual value w is attained 
and furthermore z = w. This is given withou t proof. 
4 Conic Program ming 
Conic Programming is a generalization of both Linear Programm ing and Semideni te Progr amming. 
First, we need the deni tion of a cone: 
Deniti on 1 A cone is a subset C of Rn that has the property that for any v  C and   R+ , v 
is also in C. 
Conic Programm ing is constrai ned optimization over K,a close d convex cone, with a given inner 
product x,y. We can, for example, take K = Rn and x,y = xT y for any x,y  Rn; this will lead 
to linear progr amming. Conic programm ing, like LP and SDP, has both a primal and a dual form; 
the primal is: 
Prima l: Given A  Rmn,b  Rm, and c  Rn: 
min	 c,x 
s.t.	 Ax = b 
x  K. 
More generally , we could view K as a cone in any space , and then A is a linear operator from 
K to Rm . To form the dual of a conic program, we rst need to nd the polar cone, K, of K. The 
polar cone is den ed to be the set of all s such that for all x in K, s,x 0. For instance, the polar 
cone of Rn is Rn itself (indeed if sj &lt; 0 then we have s/ K since ej ,s &lt; 0; conversely, if s  0+ + 
then x,s 0). In the case that K = K, we say that K is self-polar. Similarl y, the polar cone of 
PSD, the set of positiv e semideni te matrice s, is also itself. 
We also den e the adjoint (operator) A of A to be such that, for all x and y, Ay,x = y,Ax. 
For exampl e, if the inner product is a stand ard dot product and A is the matrix corres ponding to 
a linear transformation from Rn to Rm, then A = AT . To write the conic dual, we introduce a 
variab le y  Rm and s  Rn and optimize : 
Dual: 
max b,y 
s.t. Ay + s = c 
s  K. 
4.0.4	Weak Dual ity 
We can prove weak duality  that the value of the primal is at least the value of the dual  as follows. 
Let x be any primal feasible soluti on and (y,s) be any dual feasible soluti on. Then 
c,x = Ay + s,x = Ay,x + s,x = y,Ax + s,x = b,y + s,xb,y, 
where we have used the den ition of K to show that s,x 0. This means that z, the inmum 
value of the primal, is at least the supremum value w of the dual. 
14-4</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Convex hulls and fixed dimension LP</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec22/</lecture_pdf_url>
      <lectureno>22</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>/ne}ationslash
/parenleftBig /parenrightBig The algorithm proceeds as follows. If H = C, then return C. If H = C, choose h randomly 
among H C. We recursivelycall LP (H {h},C)andget abasis B. If h issatisedby thesolution 
denedby B, then return B. Otherwise, we call LP (H, basis(B,h)), where basis(B,h)denotes an /uniontext optimalbasisfor LP (B {h}). 
Claim2 The expected running time is 
2
d log(n/
d)+O(
d)+O(log n)Oe . 
When d is xed, the running time is a polynomial of n. When n is xed, the running time is 
O(e 
d), subexponential ind. 
UseatrickduetoClarkson(through randomsampling),onecanshowthatlinearprogramswith 
n inequalitiesin d dimensions can be solved in 
O(d2 n + e d log d) 
time. This is the best bound currently known that is independent on the size of entries. See 
Goldwasser[1] for adiscussion. 
2 Convex Hull 
Given n points x1,...,xn Rd . Let P be the convex hull of x1,...,xn. For d = 2 and d =3, P 
canbefoundin O(n logn) time. In the previous lecture, we showed several algorithms that solve 
2-dimensional convex hull in O(n logn)time. 
Throughout this section, we assume that the points x1,...,xn are in general position, meaning 
that any d+1pointsdonotlieonthesamehyperplane.Ifthatsnotthecase,astandardperturbation 
argument can be used. 
2.1 Outputs of Convex Hull Algorithms 
In dimension 2, it is sucient to output the vertices of the convex hull in counterclockwise order. 
In this subsection, we introduce what the output is for a general d. 
Denition2 For any 0 k&lt;d,a k-face of a d-dimensional polytope P is a face of P with 
dimension k.A (d 1)-face is called a facet. A (d 2)-face is called a ridge. A 1-face is called an 
edge. A 0-face is called a vertex. 
Denition3 A simplicial polytope is a polytope where every face is a simplex. 
Sincethepoints x1,...,xn areingeneralposition,the convexhull P is a simplicial polytope. 
The convexhull algorithmoutputs afacetgraph F(P ). The vertices of F(P )are all facets of P . 
The edges of F(P )correspond to the ridges of P , connecting twofacets sharedby the ridge(Figure 
1). 
Forgeneral d, one can show that the number of facets of P is O(nd/2). Since the convex hull 
algorithm needs to output all the facets of P , the running time of any such algorithm is at least 
(nd/2). 
2.2 Convex Hull Algorithms 
Clarkson and Shor 89 developed a randomized algorithm to compute convex hull in O(n logn + 
nd/2)expected time. Chazelle 93 developed a deterministic algorithm in O(n logn +nd/2)time. 
These algorithms are optimal by the analysis in the previous subsection. 
22-3</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Figure 4: In the gure on the top, the shaded regions are visible facets. In the gure on the bottom, 
visible facets are removed and new facets are added. 
22-6</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Figure 1: The gure on the left is part of a 3-dimensional simplicial polytope with four vertices 
labeled x1,x2,x3,x4. Ontherightisthecorrespondingfacetgraph,wherethefaces x1x2x3, x2x3x4, 
and the edge x2x3 arelabeled. 
We willillustrateSeidels algorithm[3], whichhas running time O(n2 + nd/2). For d = 2 and 
d =3,Seidelsalgorithmtakestime O(n2),whichisnotoptimal. Butforlargerd,Seidelsalgorithm 
is optimal, and is considerably simpler. 
We take a random permutation x1,x2,...,xn of the points. Let Pi be the convex hull of the 
points x1,...,xi. 
InitiallyPd+1 =conv(x1,...,xd+1)isad-dimensional simplex. F(Pd+1)isthecompletegraphon 
d +1points. Weincrementally compute Pd+2,...,Pn. To do this, we need the following denitions. 
Denition4 A facet F of a polytope P is visible from a point xi if the supporting hyperplane of F 
seperates xi from P . Otherwise, F is called obscured. 
Denition5 A ridge of a polytope P is called visible from a point xi if both facets it connects are 
visible, and obscured if both facets are obscured. A ridge is called a horizon ridge if one of the facets 
it connects is visible and the other is obscured. 
To compute the convex hull Pi when adding a new point xi, Seidels algorithm performs the 
following four steps. 
Step 1 Find one visible facet F if one exists. If there is no visible facet, we are done. This step can 
be done using linear programming in O(d!i)time. Indeed we would like to nd a hyperplane 
aT xb (where the unknowns are a Rd and b) such that aT xi = b and aT xi b for   
j =1, ,i 1. Any extreme solution will correspond to a new facet and to a horizon ridge.  
One of the two facets indicident to this horizon ridge is visible. 
Step 2 Find all visible facets. Determine all horizon ridges. Delete all visible facets and all visible 
ridges.
This canbedoneby depth-rst-search(DFS), sincethe visiblefacets andinvisiblefacets are
seperatedbyhorizonridges. Intermsof running time,wechargethedeletiontimeof thefacets
to when the facets were created.
Step 3 Construct all new facets. Each horizon ridge corresponds to a new facet containing the point 
xi andthe ridge(Figure4). 
Step 4 Each new facet contains d ridges. Generate all these new ridges. Every new ridge R is a 
sequence of d 1points a1 &lt;a2 &lt; ... &lt; ad1. Then match corresponding ridges using radix 
sort to construct the facet graph. 
22-4</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Figure2: In3-D, ridges arejust edges. 
Figure 3: The visible ridges and the invisible ridges are seperated by horizon ridges. 
22-5</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>/intersectiondisplay 18.415/6.854AdvancedAlgorithms December1,2008 
Lecture 22 
Lecturer: Michel X. Goemans 
Inthislecture,weintroduceSeidelsalgorithm[3] tosolvelinearprograms with n constraints 
indimension d, when the dimension is small. The expected running time of Seidels algorithm is 
O(d!n),i.e.itisstronglypolynomialfor xeddimensiond (strongly, since it does not depend on the 
size of the input coecients). Then, we use Seidels algorithm to develop a randomized convex-hull 
algorithm in an arbitrary dimension d which is the best possible when d 4. 
1 Linear Programming in Fixed Dimension 
In this section, we x the dimension d. We wish to nd a strongly-polynomial time algorithm to 
solvelinearprogramming. 
1.1 Seidels Algorithm 
Let H be a set of n inequalities. Each inequality corresponds to a half-space h determined by a 
hyperplane. Let LP (H)be the linear program that minimizes cT x subject to the constraints: 
x  h, x Rd . 
hH 
To make the description of the algorithm simpler, we make the following two assumptions: 
1. Bounded: the feasible region is bounded, i.e. there exists M such that, for any feasible x, 
M xi M for all i =1, 2,...,d. 
This assumption can be enforced by cticiously imposing a large bounding box, and whenever 
one of the inequalities of this bounding box is tight at optimum, we know that the linear 
program is unbounded. 
2. Non-degenerate: the intersection of any d +1 hyperplanes is empty. In 2-D, non-degeneracy 
means that there do not exist three lines meeting at the same point. 
If H doesnot meetthisassumption,wecanusesomestandardtrickslikeperturbationtomake 
itnon-degenerate. Thiscanbehandledby doing so-calledlexicographicperturbation. 
Thesetwoassumptionsimply thatforany H H, LP (H)hasauniquesolutionx(H). Seidels 
algorithm will actually apply toamoregeneral classofproblemsthanlinearprogramming,buthere 
wellfocus onlinearprogramming. Whatis actually neededinthegeneralizationisthatthe unique 
solution x(H)is dened by a basis: 
Denition1 A subset B H is called a basis of the linear program LP (H)if x(B)= x(H)and 
B is minimal. 
SeidelsalgorithmsolvesthelinearprogramH incrementallyasfollows. Chooesuniformly h H. 
Solve the linear program with h removed, and get a solution x. If the solution x satises h, then 
return x. If the solution x does not satisfy h, we impose the condition that h is satised at equality, 
and eliminateonevariable. Thensolvethelinearprogramwith d1variablesand n1inequalities. 
The correctness of this algorithm was proved in the last lecture. 
In Seidels algorithm, we can stop the recursion when we have either n constraintsin d =1 
variable(which takes O(n)time to solve), or 1 constraint in d variables(whichtakes O(d)time to 
optimize over our cticious bounding box). 
22-1</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>/parenleftBigg /parenrightBigg /summationdisplay 
/parenleftbig/parenrightbig The expected running time of Seidels algorithm to compute the convex hull is O(n2 + nd/2). 
Indeed the running time is 
n 
O (i + Ni) , 
i=d+2 
where Ni is the number of facets created at step i. One has that 
i1 
E[Ni]= E[facets ofPi containing xi] d/parenleftbig/parenrightbig 1 O(id/2)= dO(id/2),i i d 
giving the required time bound. 
References 
[1] M. Goldwasser, A survey of linear programming in randomized subexponential time, ACM 
SIGACT News, 26,96104,1995. 
[2] J. Matousek, M. Sharir, and E. Welzl, A subexponential bound for linear programming, 
Algorithmica, 16,498516,1996. 
[3] R. Seidel, Small-dimensional linear programming and convex hulls made easy, Discrete &amp; 
Computational Geometry, 6,423434,1991. 
22-7</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>1.2 Analysis of Running Time 
Let T (d,n) be the expected running time of Seidels algorithm on an instance with n inequalities 
and d variables. To nd a recursive relation for T (d,n), note that we rst recursivelysolve an LP 
with n 1 inequalities and d variables, which takes time T (d,n 1). If the solution x satises 
the removed constraint h (which takes O(d) time to check), we are done and simply return the d 
coordinates of x. If x does not satisfy h, we rst reduce the LP to only d 1 variables in O(dn) 
time(it takes O(d) time to eliminate one variable in each constraint) using the constraint h, and 
then solve the LP with n 1inequalitiesand d 1variablesin T (d 1,n 1) time. Theprobability 
that x does not satisfy h is d/n, since the optimal solution is determined by exactly d inequalities 
and we have selected an inequality uniformly at random. This is the important step in the analysis 
and is known as backward analysis. 
By the analysis above, we have 
d T (d,n)= T (d,n 1)+O(d)+ (O(dn)+T (d 1,n 1)) n 
= T (d,n 1)+ dT (d 1,n 1)+O(d2). n 
The base cases are T (1,n)= O(n)and T (d, 1) = O(d). 
Using this recursive relation, we can prove by induction on d + n that 
Claim1   
/summationdisplay i2 
T (d,n)= O   d!n = O(d!n). i! 1id 
Proof: The base case is satised. We need to check the induction step. Suppose that 
  
/summationdisplay i2 
T (d,n 1) = O   d!(n 1)  ,i! 1id 
  
/summationdisplay i2 
T (d 1,n 1) = O   (d 1)!(n 1)  . i! 1id1 
Since 
  
/summationdisplay i2 
i!  d!(n 1)+ d 
n /summationdisplay i2 
i!  (d 1)!(n 1)+d2  /summationdisplay i2 
i!  d!n, 
1id 1id1 1id 
the claim also holds for T (d,n). 
The second equality in the claim follows from the fact that /summationtexti2 is nite. i=1 i! 
Thus, we have shown a strongly polynomial time algorithm to solve linear programs in a xed 
smalldimension d. 
1.3 Improvement (Matousek, Sharir, Welzl [2]) 
Although the expected running time of Seidels algorithm is strongly-polynomial in n,itincreases 
exponentially when d increases(moreprecisely,thedependenceond is2O(d log d)). Inthissubsection, 
webriey introduceanimprovementtoSeidels algorithmwhichgivesa subexponentialboundin d. 
Weconsiderthelinearprogramasfollows.TheLPalgorithm LP (H,C)takesasinputacandidate 
set C (that plays the role ofa basis), and returns x as well as a basis B. Initially, we call LP (H,C) 
with C = . 
22-2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Approximation algorithms</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec16/</lecture_pdf_url>
      <lectureno>16</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>One approach to solve this problem is to extend S to a bigger set P  S where the same problem 
is easier to solve. Namely, we extend the function f to a function g : P  R satisfying g(x)= 
f(x),x  S (org(x) f(x)). If this condition holds, then 
min f(x) min g(x), 
xS xP 
which gives a lower bound for the value of the optimal solution. Therefore, if an algorithm gives a 
solution x   S which satises f(x ) minxP g(x), then this is an-approximation algorithm 
fortheproblem. 
For example, many combinatorial optimization problems can be expressed as 
minc T x 
s.t.	Ax = b, 
x {0,1}n . 
A natural relaxation is to replace the integrality constraint xi {0,1} by the linear constraint 
0  xi  1, we obtain the LP relaxation of the integer program above. 
min c T x 
s.t.	Ax = b, 
0  xi  1, i =1,...,n. 
In some cases, the polytope corresponding to the LP relaxation has all integral extreme points. 
In such cases, it is sucient to solve the LP relaxation to solve the original problem exactly. But 
this is not true in general. 
3.1	LP Relaxation for the Vertex Cover Problem 
Given an undirected graph G =(V,E), a vertex cover of G is a collection of vertices C  V such 
that all edges e =(u,v) /\e}atio\slash. The Vertex Cover problem on an instance in E satisfy C {u,v} = 
G =(V,E),c : E  R+ is to nd a cover C of G of minimum cost c(C)= 
vC c(v). This is known 
tobe anNP-hardproblem. 
A naturalformulationusing integervariablesandlinear constraintsisthefollowing. Wedenea 
variable xu {0,1} which takes value 1 if it is in the vertex cover, 0 otherwise. Then the following 
is anintegerprogramming formulationforthe vertex coverproblem. 
min  
cvxv (1a) 
vV 
s.t.	xu + xv  1, (u,v) E, (1b) 
xu {0,1}, u  V. (1c) 
TheLP relaxationforthe vertex coverproblemis 
min  
cvxv (2a) 
vV 
s.t.	xu + xv  1, (u,v) E, (2b) 
xu  0, u  V. (2c) 
Notethatweremoved the xu  1constraints,sinceif xu &gt; 1wecanchangeitto xu =1without 
increasing the cost, and still have a feasible solution. 
Lec16-3</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>3 4 3 4
2 3 2 3 
y = 3 3 4 
3 2 y = 1 3 4 
3 2 y = 3 
3 y =3 4
y = 1 
3 y =1 2 
Figure 3: Illustration of the primal-dual algorithm for the vertex cover problem. The cost of the 
vertices are indicated next to each vertex. Dotted edge denotes the edge currently under considera
tion,thick edgesdenotethosealready coveredby the currentvertexcover. The verticesinthe cover 
are shown as solid circles. 
Proof: First of all, it is clear that the set C returned by the algorithm is a vertex cover. Let 
y be the dual solution returned. Observe that by construction, this solution is dual feasible (we 
maintain dual feasibility throughout the execution). Furthermore, for any v  C, we have that 
cv = 
e(v)ye. Let us now compute the cost of the vertex cover returned by the algorithm. 
cv = ( ye)= eye  2ye 
vC vCe(v) eE eE 
 2LP (4a) 
 2OPT, (4b) 
where e = 2, for edge e =(u,v)ifboth u,v  C,1otherwise. Theinequality(4a) followsfrom 
weak duality, and inequality (4b) follows from the fact that the primal LP is a relaxation of the 
vertex coverproblem.  
Figure 3 illustrates the execution of the primal-dual algorithm on a graph. For this instance, 
the algorithm returns a vertex cover of cost 9, whereas the optimal solution in this instance has 
Lec16-6</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>x1 =1/2 
x2 =1/2 x3 =1/2 
Figure2:AnexamplewheretheLPrelaxationfortheVertexCoverdoesnothaveanintegeroptimal 
solution. 
TheLPrelaxationdoesnot necessarilyhaveanoptimalintegral solutioningeneral. Forexample, 
considerthegraphgiveninFigure3.1 with all costsequalto1. Theoptimalsolutionforthisinstance 
has cost OPT =2 , but the optimal solution for the LP relaxation has cost LP =3/2, as shown in 
the gure. What this example shows is not only that LP &lt;OPT ingeneral,but alsoaninteresting 
fact about the strength of this relaxation. Suppose that we are going to use LP as a lower bound 
on OPT in order to prove an approximation guarantee. As we will see in the next subsection, we 
will be able to nd a cover C with cost at most 2LP. Therefore, we can say 
c(C) 2LP  2OPT 
toprove an approximationguarantee of2,However,the exampleprovesthat we will notbe ableto 
decreasethisfactorbeyond4/3. This follows from the fact that 
OPT  c(C) LP  OPT  OPT/LP   
then the best we can hope for is at most 4/3 by using this relaxation. This important property of 
the bad examples iscapturedintheconceptofintegralitygap. 
Denition2(Integralitygap) Given a relaxation LP() for an integer program IP() that 
formulates a combinatorial (minimization) optimization problem on a collection of instances {}, 
the integralitygap of thelinearprogram relaxation is the largest ratio between the optimal solution 
of both formulations, namely: 
IP() Integrality gap =sup 
 LP() 
For the Vertex Cover LP relaxation, the integrality gap is exactly 2. To see that it is at least 
2, consider the complete graph G = Kn, with unitary costs. The minimum vertex cover has cost 
n  1, while the linear program relaxation can assign 1/2 to all variables, which gives a total cost 
of n/2. Therefore, the integrality gap is at least 2(n
n 1)  2. The upper bound follows from the 
2-approximation algorithm we will see in the next subsection. 
3.2 A 2-approximation Algorithm for Vertex Cover 
A natural approach to get an integral solution from a fractional solution is to round the fractional 
values. A simple rounding scheme for the vertex cover is as follows. 
1. Solvethelinearprogramming relaxationgivenby(2a)-(2c),togetthefractional solution x  . 
Lec16-4</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>2. Compute the vertex cover as C = {v  V,x 
v  1/2} (i.e., roundeach fractional variable to the 
nearestinteger). 
Theorem2 The above rounding scheme is a 2-approximation algorithm for the Vertex Cover prob
lem. 
Proof: First,weneedtocheckthatC isindeedavertexcover.Foreach e =(u,v) E, xu +xv   1, 
so at least one of x  
u, x  
v has value at least 1/2, andisin C. Next, the cost of this vertex cover 
satises 
 c(C)=  
cv  2 
cvxv =2LP  2OPT, 
v:x 1/2 vV v 
hence the LP rounding is a 2-approximation algorithm for the vertex cover problem.  
Thisis a verybasic(the simplest) example of rounding; moresophisticated roundingprocedures 
have been used to design approximation algorithms; well see some in coming lectures. 
4 The Primal Dual Technique 
Yet another way of designing approximation algorithms for intractable problems is the primal dual 
method. The basic idea of the primal dual scheme is this: At every point of the algorithm, we 
keep a feasible dual solution, and a corresponding infeasible integer primal solution. The dual 
variables are then modied at every step and so is the infeasible primal solution, so as to achieve 
primalfeasibility. At thispoint, thedualgives alowerbound(for minimizationproblems) on the 
optimal primal objective function value, which is used to derive the approximation factor for the 
algorithm. The interesting thing about this technique is that we do not need to explicitly solve the 
linearprogram(asis the casein rounding); thelinearprogramis used onlyin the analysis of the 
algorithm. 
Weillustratethis methodforthe vertex coverproblem. Thelinearprogramforthe vertex cover 
problemisgivenby(2a)-(2c). Thedual of thislinearprogramisgivenby 
max ye 
eE 
s.t.  
ye  cv v  V, (3) 
e(v) 
ye  0 e  E. 
The primal dual algorithm for the vertex cover problem is as follows. In the algorithm, C 
correspondstothe set of verticesinthe(supposedtobe) vertex cover, and F is the set of edges in 
the graph not yet covered by C. 
1. y(v) 0 v  V, C ,F  E. 
2. While F /\e}atio\slash= 
3. Let e =(u,v)be any edge in F. 
4. Increase ye untilthe constraint(3) becomestightfor u or v. 
5. Addthatcorresponding vertex(say itis v)to C. 
6. F  F \ (v). 
Theorem3 The above algorithm achieves an approximation ratio of 2 for the vertex cover problem. 
Lec16-5</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6.854AdvancedAlgorithms November3,2008 
Lecture 16: Approximation Algorithms 
Michel X. Goemans 
1 Approximation Algorithms 
Manyoptimizationsproblemsarisinginpracticeare NP hard. Under the widelyaccepted conjecture 
that P /\e}atio\slashNP,wecannot computeeciently and exactly anoptimal solutionforallpossibleinstances = 
of these problems. Several approaches have been used to deal with this intractability. On one 
hand, dynamic programming, branch and bound, and implicit enumeration algorithms always nd 
an optimal solution by navigating the space of feasible solutions in a more ecient way than an 
exhaustivesearch,buttheir running timeis notguaranteed tobepolynomialintheinputs size. On 
theotherhand, heuristic algorithmsprovideasub-optimal solutiontotheproblem,buttheirrunning 
time is polynomial in the size of the input problem. In this lecture we will focus on approximation 
algorithms, which are heuristics that always nd a solution whose objective value is guaranteed to 
be within a certain factor of the optimum solution. 
Denition1(ApproximationAlgorithm) Let P be a minimization (resp. maximization) prob
lem with instances I I. An -approximation factor for   1 (resp.   1) algorithm for P is 
an algorithm A whose running time is polynomial in the size of the given instance I, and outputs a 
feasible solution of cost cA such that cA   OPTI (resp. cA   OPTI), where OPTI is the cost 
of the optimal solution for instance I. 
In this lecture, we will discuss three general techniques of designing approximation algorithms 
forNP-hardproblems: 
1. Using optimal value in the analysis without explicitly knowing it. 
2. Linearprogramming relaxation and rounding. 
3. Primal-dual technique. 
2 A 3/2-Approximation Algorithm for the Metric TSP 
The Traveling Salesman Problem is one of the most extensively studied problems in combinatorial 
optimization. In the metric version of the problem, an instance is a complete undirected graph 
G =(V,E)and c : E  R+, where c satises the metric property: c(u,v)= c(v,u)for all u,v  V, 
and the triangle inequality, c(u,v) c(u,w)+ c(w,v), for allu,v,w  V. The objective is to nd 
tour,thatis a cycle visiting every vertex exactly once(also called a tour)minimum cost . 
A 3 approximationalgorithmforthisproblemby Christodes[1] isasfollows. 2 
1. Find a minimum spanning tree T of G. 
2. Compute a minimum cost perfect matching M on the set of odd-degree vertices Vodd  T. 
 3. Find an Eulerian tour C (a cycle visitingall the edges exactly once) in M  T. 
 4. Output the tour C that visits the vertices of G intheorderof their rstappearanceinthe C . 
Lec16-1</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>2	 2 
4
6 8
10 9
3 5 72 
1 
4 
6 8 
10 9 
3 5 7 1 
4 
6 8 
10 9 
3 5 7 1 
11 11	 11 
Figure 1: Execution of Christodes algorithm on an instance. The rst gure shows a minimum 
cost spanning tree. Thesecondgureshowstheadditionof aminimumcost matching onodddegree 
vertices in the tree, and the third gure shows a cycle obtained after shortcutting an Eulerian 
tourinthepreviousgraph, starting from vertex1. 
Theorem1 The above algorithm is a 3/2-approximation algorithm for the metric TSP. 
Proof: It is clear that all steps in the algorithm can be implemented in polynomial time. The 
minimum spanning tree can be found using a greedy algorithm, and the minimum cost matching 
for Vodd can be found in polynomial time using the ellipsoid algorithm, as discussed in one of the 
previous lectures (or by a purely combinatorial algorithm also based on the linear program we 
discussed). Notethat c(T) OPT,becausetheoptimal tourwithoutanedgebecomesatree. Also, 
c(M) OPT/2. To seethis, consider any optimal tour, and then short-cutittoget a cycle visiting 
only vertices in Vodd with cost at most OPT. Since the cycle induces two matchings consisting of 
alternating edges,atleast oneof themwillhavecost at most OPT/2. Fromthis,thetotal cost of the 
Euleriancycle,anupperbound of the cost of thealgorithm,isat most OPT +OPT/2 =3/2 OPT. 
Note that in the analysis of the algorithm, we used the value of OPT even without explicitly 
computing it exactly, orgetting alowerbound onit. Figure1 shows aninstance of the metricTSP, 
and the execution of the algorithm on this instance. 
A few remarks: 
	The above analysis for the algorithm is tight, i.e. &gt; 0 there is an instance I suchthatthe 
algorithm returns a solution which is 3/2  times the optimal solution. 
	Currently, no algorithm with an approximation factor better than 3/2 is known for metric 
TSP. 
	TSPisknowntobeMAX-SNPhard[5] evenforthe casewhendistances areeither1 or2. 
Also,PapadimitriouandVempala[4]haveproved that a1.01 approximationalgorithmforthe 
metric TSP will imply P = NP. 
3 Designing Approximation Algorithms via Relaxations 
One of the most important paradigms in the design of approximation algorithms are relaxations. 
Considerthefollowing(hard) minimizationproblem. 
minf(x) 
s.t. x  S. 
Lec16-2</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>cost7(corresponding tothetwo vertices onthediagonal edge). Thelowerboundgivenby thedual 
solutionhasvalue3+1+1 =5. 
A few nal remarks: 
	Dinur andSafra[2] haveproved thatitisNP-hard to approximatetothe vertex cover with a 
factorbetterthan1.36. 
	Currently,thereisnoalgorithmforthevertexcoverproblemwhich achievesanapproximation 
ratiobetterthan2. Sothetwo(simple!) algorithmspresentedhereare,infact,thepresent 
best known approximation algorithms for this problem. 
	Khot andRegev[3] haveprovedthatitisUGC-hardto approximatevertexcover within a 
factor2 , for any &gt; 0. 
References 
[1] Christodes,N.(1976).Worst-caseanalysisofanewheuristicforthetravelling salesmanproblem, 
Report 388, Graduate School of Industrial Administration, CMU. 
[2] Dinur,I. andS.Safra(2002).Theimportance ofbeingbiased.In Proceedings of the 34th ACM 
Symposium on Theory of Computing,pp.33-42. 
[3] Khot, S. and O. Regev (2008). Vertex cover might be hard to approximate to within 2  . 
Journal of Computer and System Sciences,74:335-349. 
[4] Papadimitriou,C.H. andS.Vempala(2000).Onthe approximability ofthetravelling salesman 
problem. In Proceedings of the 32nd ACM Symposium on Theory of Computing, pp. 126-133. 
[5] Papadimitriou,C.H. andM.Yannakakis(1993).Thetravelling salesmanproblemwithdistances 
one and two. Mathematics of Operations Research,18:1-11. 
Lec16-7</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Goldberg-Tarjan min-cost circulation algorithm</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec4/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>|| k  m iterations we will nd an edge (v,w)  k+1 such that cp(v,w)  0. So by Theorem 1, (f k) 
is equal to the mean cost of k+1 and thus 
c(k+1) cp(k+1)(fk)= (f k)=  =  |k+1| |k+1| 
0+((f ))(| k+1| 1) |k+1| 
1  1  (f). n 
Corollary 4 If the costs are integer, then the number of iterations is at most mn log(nC). 
Proof: We have that 
 n log(nC) 
(fend)  1  1 (f = 0) &lt;e log(nC)|C| =1 |C| =1 , n nC n 
and thus the resulting circulation is optimal.  
The time per iteration will be shown to be O(nm) (see problem set), hence the total running 
time of the algorithm is O(m2n2 log(nC )). 
2.4 Strongly Polynomial Analysis 
In this section we will remove the dependence on the costs. We will obtain a strongly polynomial 
bound for the algorithm for solving the minim um cost circulation problem. In fact we will show 
that this bound will hold even for irrational capacities. The rst strongly polynomial-time analysis 
is due to Tardos; the one here is due to Goldb erg-Tarjan. This result was very signican t, since it 
was the most general subclass of Linear Programming (LP) for which a strongly polynomial-time 
algorithm was shown to exist. It remains a big open problem whether a strongly polynomial-time 
algorithm exists for general LP. 
Denition 3 An edge e is -xed if for all -optimal circulations f we have that f(e) maintains the 
same value. 
Note that (v,w) is -xed if and only if (w,v) is -xed, by skew-symmetry of edge-costs. 
Theorem 5 Let f be a circulation and p be a potential such that f is (f)-optimal with respect to 
p. Then if |cp(v,w)| 2n for some edge (v,w)  E, the edge (v,w) is -xed. 
Proof: Suppose (v,w) is not (f)-xed. There exists an f  that is (f)-optimal and f (v,w)=
f(v,w); without loss of generalit y assume f (v,w) &lt;f(v,w). Let E&lt; = {(x,y): f(x,y) &lt;f(x,y)}. 
We can see that E&lt;  Ef  by denition of Ef  . Furthermore, from ow conserv ation, we know that 
there exists a cycle   Ef  containing the edge (v,w). Indeed, by ow decomp osition, we know 
that the circulation f  f  can be decomp osed into (positive net) ows along cycles of Ef  , and thus 
one of these cycles must contain (v,w) 
Now we have the following, 
c() = cp() 2n(f )+(n  1)(f) &lt; n(f ). 
Consequen tly, c() &lt;  and so (f ) &lt; . As a result, f  is not (f)-optimal and thus we have a 
contradiction.  
lect-4</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6.854 Advanced Algorithms	 Septem ber 15, 2008 
Goldb erg-Tarjan Min-Cost Circulation Algorithm 
Lecturer: Michel X. Goemans 
1 Introduction 
In this lecture we shall study Kleins cycle cancelling algorithm for nding the circulation of minim um 
cost in greater detail. We will pay particular attention to the choice of cycle to cancel and we will 
rigorously prove two bounds on the number of iterations required, the rst of which depends on the 
magnitude of the cost and is valid only for integer-v alued costs, and the second of which is strongly 
polynomial and works even for irrational costs. 
Recall from last time that for a given circulation f, the following are equivalent: 
i.	f is of minim um cost 
ii. There is no negativ e cost cycle in the residual graph Gf 
iii. There exist potentials p : V  R such that the reduced costs 
cp(v,w)= c(v,w)+ p(v)  p(w)  0 
for all (v,w)  Ef , where Ef = {e : uf (e) &gt; 0}. 
2 Kleins cycle cancelling algorithm 
Algorithm 1 Kleins-Cycle-Cancel (Gf ) 
Let f be any circulation (e.g., f = 0) 
while there exists a negativ e cost cycle   Gf do 
Push (f) = min uf (v,w) along  
(v,w) 
end while 
It is important to note that the Ford-Fulkerson algorithm for the maxim um ow problem is a 
special case of Kleins cycle cancelling algorithm, by dening zero costs for all edges in the original 
graph and by adding an extra edge from the sink to the source with cost 1. 
2.1 Choice of cycle  
As in the Ford-Fulkerson algorithm, the question is which negativ e-cost cycle to choose. 
1. (Weintraub 1972).	 One idea is to try choosing the maxim um impro vement cycle, where 
the dierence in cost is as large as possible. One can show that the number of iterations is 
polynomial for rational costs, but nding such a cycle is NP-hard. For irrational costs, one 
can show that this algorithm may never terminate (Queyranne 1980) even for the maxim um 
ow problem (the fattest augmen ting path algorithm of Edmonds and Karp), although the 
solution converges to a minim um cost ow. 
lect-1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>|| || Lemma 6 After O(mn log n) iterations, another edge becomes xed. 
Proof: Let f be a circulation and f  be another circulation after application of mn log(2n) iterations 
of the Goldb erg-Tarjan algorithm. Also suppose that  is the rst cycle cancelled and p,p are the 
potentials for f,f  respectively. From the previous lemma, we have that (f )  (1 n 1 )n log(2n)(f) &lt; 
e log(2n) = 21 
n (f). Now from the denition of  we get the following, 
cp () c() = = (f)= (f) &lt; 2n(f ) 
This means that there exists an edge (v,w)   such that cp (v,w) &lt; 2n(f ) which means that it 
was not (f)-xed. Thus (v,w) becomes (f )-xed and the claim is proven.  
Notice that if e is xed, it will remain xed as we iterate the algorithm. An immediate con
sequence of the above lemma then is a bound on the number of iterations in the Goldb erg-Tarjan 
algorithm. 
Corollary 7 The number of iterations of the Goldberg-Tarjan algorithm, even with irrational costs, 
is O(m2n log n). 
lect-5</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>c(v,w)s 0 
0 0 v w 
Figure 1: p(v) is the length of the shortest path from s to v. 
paths, p(w)  p(v)+ c(v,w)= p(v)+ c(v,w)  (f). Therefore cp(v,w)  (f) for all (v,w)  Ef 
which implies that f is (f)-optimal and thus (f) (f). 
By combining (f) (f) and (f) (f) we conclude (f)= (f) as required.  
The nature of the algorithm is to push ow along negativ e cost cycles. We would like to know if 
this actually gets us closer to optimalit y. This is shown in the following remark. 
Remark 1 (Progress) Let f be a circulation. If we push ow along the minimum mean cost cycle 
 in Gf and obtain circulation f  then (f)  (f ). 
cp() c()Proof: By denition || = || = (f). Now, (f)= (f) implies that there exists a potential 
p such that cp(v,w)  (f) for all (v,w)  Ef . Furthermore for all (v,w)   the reduced cost 
cp(v,w)= (f)= (f). If ow is pushed along  some arcs may be saturated and disapp ear from 
the residual graph. On the other hand, new edges may be created with a reduced cost of +(f). More 
formally , Ef   Ef {(w,v):(v,w)  }. So for all (v,w)  Ef  it holds that cp(v,w) (f). 
Thus we have that (f )  (f).  
2.3 Analysis for Integer-v alued Costs 
We now prove a polynomial bound on the number of iterations for an integer cost function c : E  Z. 
At the start, for any circulation, the following holds for all (v,w)  E: 
(f)  C = max |c(v,w)|. 
(v,w)E 
Now we can continue with the rest of the analysis. 
Lemma 2 If costs are integer valued and (f) &lt; n 1 then f is optimal. 
Proof: Consider (f)= (f) &gt;  n 1 . For any cycle   Gf we have c() = cp() &gt;  n 1 ||1. 
Since the cost is an integer, c()  0. By the optimalit y condition, if there is no negativ e cycle in 
the graph, the circulation is optimal.  
Lemma 3 Let f be a circulation and let f  be the circulation after m iterations of the algorithm. 
Then (f)  (1  n 1 )(f). 
Proof: Let p be the potential such that cp(v,w) (f) for all (v,w)  Ef and let i and fi 
be the cycle that is cancelled and the circulation obtained at the ith iteration, respectively. Let 
A be the set of edges in Efi such that cp(v,w) &lt; 0 (we should emphasize that this is for the p 
corresp onding to the circulation f we started from). We now show that as long as i  A, then 
|A| strictly decreases. This is because cancelling a cycle removes at least one arc with a negativ e 
reduced cost from A and any new arc added to Efi must have a positive reduced cost. Hence after 
lect-3</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>|| || 2. (Goldb erg-Tarjan 1986). Alternativ ely, we can choose the cycle of minim um mean cost, 
dened as follows: 
(f) = min 
directed cycles   Gf c() 
|| 
 where c() = (v,w) c(v,w) and || is the number of edges in the cycle. 
Notice that there exists a negativ e cost cycle in Gf if and only if (f) is negativ e.
To see that we can indeed nd the minim um mean-cost cycle ecien tly, suppose we replace the
costs c with c such that c(v,w)= c(v,w) +  for each edge (v,w). Then (f)= (f) + ,
soif = (f) then we would have (f) = 0. In particular,
(f)=  inf{ : there is no negativ e cost cycle in Gf with respect to costs c +}. 
For any , we can decide if there is a negativ e cost cycle by using the Bellman-F ord algorithm. 
Now, perform binary search to nd the smallest  for which no such cycle exists. In the next 
problem set we will show a result by Karp, which nds the cycle of minim um mean cost in 
O(nm) time by using a variant of Bellman-F ord. 
2.2 Bounding the number of iterations 
We will give two bounds on the number of iterations for the algorithm. The rst depends on the 
magnitude of the cost and is valid only for integer-v alued costs; it is polynomial but not strongly 
polynomial. The second bound is strongly polynomial and works even for irrational costs. 
We rst need a measure of closeness to the optimal circulation. The following denition gives 
such a measure, and will be key in quantifying the progress of the algorithm. 
Denition 1 (Relaxed optimalit y) A circulation f is said to be -optimal if there exists a po
tential p : V  R such that cp(v,w)  for all edges (v,w)  Ef . 
Note that an 0-optimal circulation is of minim um cost. 
Denition 2 For a circulation f, let 
(f) = min{ : f is -optimal }. 
One important thing about this that we will prove soon is that when we push some ow in a 
circulation f along some cycle  and obtain a new circulation f , we get that (f )  (f). This means 
that  is monotonically non-increasing in general. First, we need the following strong relationship 
between (f) and (f), and this really justies the choice of cycle of Goldb erg and Tarjan. 
Theorem 1 For all circulations f, (f)= (f). 
Proof: We rst show that (f) (f). From the denition of (f) there exists a potential 
p : V  R such that cp(v,w) (f) for all (v,w)  Ef . For any cycle   Ef the cost c() is 
equal to the reduced cost cp() since the potentials cancel. Therefore c() = cp()  ||(f ) and 
c()so	|| (f) for all cycles . Hence (f) (f). 
Next, we show that (f) (f). For this, we start with the denition of (f). For every 
c()cycle   Ef it holds that ||  (f). Let c(v,w)= c(v,w)  (f) for all (v,w)  Ef . Then, 
c () c()=  (f)  0 for any cycle . Now dene p(v) as the cost of the shortest path from an 
added source s to v with respect to c in Gf (see Fig. 1); the reason we add a vertex s is to make sure 
that every vertex can be reached (by the direct path). Note that the shortest paths are well-dened 
since there are no negativ e cost cycles with respect to c . By the optimalit y property of shortest 
lect-2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Dynamic trees (part 2)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec8/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6. 854 Advanced Algorithms Octob er 1, 2008 
Lecture 8 
Lecturer: Michel X. Goemans 
Previously , we introduced the dynamic tree data structur e and the operations that dynamic 
trees must support. Today, we take a more detailed look at dynamic trees and describe the ecient 
implementation of the operation s. In doing so, much of our focus will be on the Expo se method, 
an extend ed splay operation that is essential in all these operations. We show that any sequence of 
m operations on a dynamic tree with n nodes takes O((m + n)log n) time. 
1 Dynamic Trees 
Dynamic trees (also known as link-cut trees) introduced by Sleator and Tarjan are a data structure 
intended to maintain a representation of a set of rooted trees. We will be able to perform various 
operations on these trees, to be discusse d later. Figure 1 shows an example tree as a virtual tree 
(left) and a rooted tree (right). 
1.1 Rooted Trees 
We view rooted trees as unions of node-disjoint (directed) paths. This divides the edges of the tree 
into two sets. Solid edges are those that are on the node-disjoint paths that the tree is comp osed 
of, and dashed edges are those that are not on these paths. Note that each path consistin g of solid 
edges is a directed path (we omit the arrows here) from top to bottom . 
1.2 Virtual Trees 
The union of disjoint paths described above can be used to represe nt virtual trees . In a virtual tree, 
each solid path is represented by a splay tree such that the following conditions hold: 
A successor node in a splay tree is an ancestor in the rooted tree.  
For each splay tree, its largest node is linked to the paren t of the root in the rooted tree.  
In the virtual tree, each node has at most one left child, at most one right child, and any  
number of middle (virtual) children. 
There are three kinds of edges in a virtual tree, corresponding to the three types of children a 
node can have. Left and right children of a node are conn ected to the node by solid edges, and 
midd le children of a node are conn ected to it by dashed edges. Note that there can be many virtual 
trees corresponding to a rooted tree, because there are two dierent degree s of freedom involved in 
constructin g a virtual tree  the union of disjoin t paths could be dierent, as could the structure 
of the splay trees corresponding to the paths. 
An imp ortan t conse quence of this setup is that r otations in a spla y tree do not ae ct the structure 
of the rooted tree. 
2 The Expose Operation 
The Expo se(v) operation is an extend ed splay operation that brings v to the root of the virtu al 
tree without changin g the structure of the rooted tree. The important parts of this operation are to 
8-1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Figure 5: Splaying on Virtu al Tree. 
v
v cw
ab b cw a
Figure 6: Rotati on. 
and  
cost(x) if x is the root of a splay tree,cost(x)= cost(x)  cost(p(x )) otherwise. 
Observe that, if x is the root of a splay tree, then cost(x ) =  cost(x ) and mincost(x ) =  cost(x ) 
min(x ). This fact, combined with the Expo se operation, shows that we can nd cost(x ) and 
mincos t(x) given  min(x) and  cost(x), so it is sucient to main tain the latter. 
We now claim that we can update  min(x) and  cost(x ) in O(1) time after a rotation or a 
splice, which will allow us to main tain cost(x) and mincost(x) in O(1) time. 
We rst consider a rotation , see Figure 6 for the labelling of the nodes. Let  cost(x ) and 
cost(x) correspond to before and after the rotation , respectively. Simil arly den e  min(x) and 
min(x). Obse rve that during a rotation, only the nodes b, w and v have their  cost(x) change. 
One can check that the updates are as follows: 
cost(v) =  cost(w) + (cost(v)  cost(w)) 
=  cost(w) +  cost(v ), 
cost(w)= cost(v), 
cost(b) =  cost(b) + (cost(v)  cost(w)) = cost(b) +  cost(v ). 
Before showing the corresponding updates for  min(x), observe that  min(x) and  cost(x ) 
8-5</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>We are using the splay operation on the k nodes v,p(t(v )),..., (p t)k1(v) in this step, 
meaning that we get a total amortized runtime of  
k1	  
9	r(t((p  t)i(v)))  r((p  t)i(v)) +1  9[r(root)  r(v)] + k, 
i=0 
since we have that r(t(p  t)i1(v))  r((p  t)i(v)), so the sum telescopes. The amorti zed cost 
of step 1 is therefore O(log n)+ k (since r(root)  r(v)  log n). 
	Step 2: Splicing does not change the value of (T ), so the amortized cost for this step is the 
same as its actual cost of k. 
	Step 3: We are using the splay operation once on node v at distance k from the root, so this 
has an actual cost of k. Using the fact that our potential  has an additional factor 3 in its 
den ition compared to the splay tree version, we get from the amortize d analysis of splaying 
that: 1 k + 3(T )  3[r(root)  r(v)]+1 = O(log n). 
Multiplying by 3, we see that we can also account for the additional cost of 2k from steps 1 
and 2, and have an amortized time of O(log n). 
	Total: We get O(log n)+ k in step 1, k in step 2, and these 2k plus step 3 gives O(log n), for 
a total of O(log n). 
4.3 Runtimes of all Operations 
We can now briey summ arize the runtimes of all other operation s in terms of Expo se. 
	find-cost, find-root, find-min, add-cos t 
Each of these operation s requires at most one use of Expo se, at most one run of splay, and 
at most one searc h of the tree which can be charged to the last splay. Therefore, they each 
run in O(log n) amortized time. 
cut 
We again use Expo se once. We now consider the eect of the other actions on the poten
tial function . Removing the edge (v, right(v)) decreases s(v) by s(right(v)) and leaves s(x) 
unchanged for all other x, so it decreases (T ), which we can safely ignore. This gives an 
amortize d runtime of O(log n). 
link  
We use Expo se twice. Now, when we link w to v, we see that r(v) increas es by O(log n), and 
all other r(x) remain unchanged. Hence , this operation increase s (T ) by O(log n), giving a 
total amortized runtime of O(log n). 
With this analysis, we see that every operation has amortized time O(log n). A sequence of m 
operations has therefore amortized time O(m log n). Furthermore, the potential function satises 
(T )= r(x)  log n  n log n, 
xT xT 
meaning that any increase in potential is at most O(n log n), imply ing that the total cost is at most 
O((m + n)log n). We now have the following theorem. 
Theorem 1 Any m operations on a dynamic tree with n nodes run in O((m + n)log n) time. 
8-8</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>satisfy the following equation; here x is any node and l is its left child and r is its right child: 
min(x )	= cost(x)  mincos t(x) 
= cost(x)  min(cost(x), mincos t(l), mincos t(r)) 
= max(0, cost(x)  mincos t(l), cost(x)  mincos t(r)) 
= max(0, min(l )  cost(l), min(r )  cost(r)). (1) 
Furthermore, the minimum of the subtr ee can be located by knowing which term attains the maxi
mum in the last express ion. 
Back to the updates for  min(x). The only subtrees that change are those of w and v, and so 
only those  min values change. Using (1), one can see that 
min(w) = max(0, min(b)  cost(b), min(c)  cost(c)) 
min(v) = max(0, min(a)  cost(a), min(w)  cost(w)). 
Notice that  min(v) depends on  min(w) that was just computed. 
Similar when we perform the splicing step given in Figure 3,  cost only change for v and u and 
only  min(w) changes . The updates are: 
cost(v) =(co st(v))  (co st(w)), 
cost(u) =  cost(u) +  cost(w ), 
min(w) = max(0, min(v )  cost(v), min(z )  cost(z)). 
3.2 Implementation of Operations 
We now describe the implementation of each of the desired operation s on a dynamic tree, makin g 
extensive use of the Expo se operation. 
	make -tree(v )
Simply create a tree with the single node v.
	find-root(v) 
First, run Expo se(v). Then follow right children until a leaf w of the splay tree containing v 
is reached. Now, splay(w), and then retur n w. 
	find-cost(v ) 
First, run Expo se(v). Now v is the root, so retur n  cost(v) = cost(v). Note that the actual 
computati ons here were done by the updates of  cost(v ) and  min(x) within the splay and 
splice operations. 
	find-min(v)
First, run Expo se(v). Now, lets rewrite (1):
min(v ) = max{0, cost(left(v)) +  min(l eft(v)), cost(right(v)) +  min(r ight(v))}. 
If  min(v) = 0, then splay(v) and then return v, as the minimum is achieved at v. Else, 
if cost(left(v))+min(left(v )) &gt; cost(right(v)) +  min(righ t(v)), then the minimum 
is contained in the left subtree and we walk down it recursively. Otherwise , the minimum is 
contained in the right subtree, so we recurse down the right. Once we have found the minimum, 
we splay it. 
8-6</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>add-cos t(v,x) 
First, run Expo se(v). Add x to  cost(v) and subtract x from  cost(left(v)). Also update 
min(v ) (usin g (1)). (The  min value of other nodes is unchanged.) 
	cut(v) 
First, run Expo se(v). Add  cost(v ) to  cost(righ t(v)). Remove the edge (v, right(v)). 
	link(v,w,x) 
First, run Expo se(v) and Expo se(w ). Then, add the root w as a middle child of v. Add 
cost(w)  x to  cost(ri ght(v)) and to  cost(left(v)). Also update  min(w). 
4 Analysis of Dynamic Trees 
We now give an amortized analysis of cost of operation s in these dynamic trees . We will see that 
any sequence of m dynamic tree operation s on n nodes will take O((m + n)log n) time. 
4.1 Potential Functi on 
We will use the following potential function in our analy sis, motivated by our analysis of splay trees. 
For each node x, let w(x) = 1 be the weight assigned to x, and dene 
s(x)= w(y), 
yTx 
where Tx is the entire virtu al tree subtree attac hed at x. Then, consid er r(x) = log2 s(x) and take 
our nal potential function to be  
(T )=3 r(x). 
xT 
This diers from the potential function for splay trees in 2 ways. First Tx is den ed over the entire 
virtual tree and secondly we have this additional factor 3. We will see later why the constan t factor 
of 3 was chosen here. 
4.2 Runtime of the Expose Operation 
We rst analy ze the runtime of Expo se(v), since it is used in all other operation s. We look at each 
step of Expo se(v) separately. Let k be the number of midd le edges separatin g v from the root of 
the entire virtu al tree. Equivalently, k is the number of splay operations performed during Step 1. 
	Step 1: Let t(v) be the root of the splay tree containing v. Recall that the amortized cost of 
splay(v) was 3(r(t(v))  r(v)) + 1 when we used the potential function 
splay(T )= r(x). 
xT 
We now have the potential function (T )=3splay(T ), sothe3(r(t(v))  r(v)) term here 
shoul d be multiplied by 3 to obtain an amortized runtime of 9(r(t(v))  r(v)) + 1 for each call 
of splay(v) (the +1 corres ponds to the cost of the last zig, if any, and so we do not need to 
multiply it by 3). 
8-7</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Figure 4: Left virtual tree is after rst splicing, the right virtual tree is the one at the end of step 2. 
The result of splicing every node on the path to the root for our example is illustrated in Figure 
4. 
2.3 Step 3 
Step 3 consists of walking from v to the root in the virtu al tree, splaying v to the root. Note that 
in the analysis, we can charge the entire cost of step 2 to the nal splaying operation in step 3. 
Figure 5 shows the relevant splay tree before and after this step. 
3 Operations on Dynami c Trees 
We will n ow describe the desired op eration s on a d ynamic tree and how to imp lement them e ciently 
using the Expo se method just dened. Some of these operations requi re keeping track of dierent 
costs in the tree, so we rst consider an ecient way of doing this. 
3.1 Maintaining Cost Infor mation 
When performing operation s on the dynamic tree, we need to keep track of cost(x ) for each node x, 
and we need to be able to nd the minimum cost along paths to the root of the rooted tree. If such 
a path is the prex of a path corresponding to a splay tree, it seems that, knowing the minimum 
cost in any subtree of any our splay trees migh t be helpful. So, in addition to cost(x), we would like 
to keep track of the value mincost(x ), given by 
mincos t(x) = min{cost(y) | y in the subtree rooted at x of xs splay tree}. 
Well see that, instead of main taining cost(x) and mincost(x), that it will be easier to main tain the 
following two quantities for every node x: 
min(x ) = cost(x )  mincos t(x) 
8-4</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Figure 1: Virtual tree (left) and corres ponding rooted tree (right). 
make sure that the path from v to the root is solid and that the splay tree representing the path to 
which v belongs is rooted at v. We can describe this operation in three steps. In our exam ple, we 
run Expo se on node 15. 
2.1 Step 1 
Step 1 consists of walkin g from v to the root of the virtual tree. Whenev er the walk enters a splay 
tree (solid edges ) at some node w,a Spla y(w) operation is performed, bringing w to the root of 
that tree. Middle children are not aected in this step. For instance, we splay nodes 11 and 5 in 
our examp le tree as in gure 2. Note that at the end of step 1 of an Expo se(v) operation, v will be 
connecte d to the root of the virtual tree only by dashed edges . 
2.2 Step 2: Splicing 
Step 2 consists of walking from v to the root of the virtual tree exchangin g along the way each 
midd le edge with the left subtree of the parent. This is illustrated in Figure 3 and called splicin g. 
A middle child of a node w and its left child can be exchanged (without changing the rooted tree) 
only if w is the root of its splay tree. This justies our execution of step 1 rst since at the end of 
step 1 all edges from v to the root are middle edges. 
Splicing is a valid operation on virtual trees. Indeed, referr ing to Figure 3, the left subtree of 
w in the splay tree corresponds to the part of the solid path that is below w in the rooted tree; 
this is because w is the root of its splay tree. Exchangi ng that solid subpath with the solid path 
corres ponding to the splay tree rooted at v still leaves the rooted tree decomposed into a node-disjoi nt 
union of paths. 
Note that after performing this operation on every edge to the root of the virtual tree, there will 
be a solid path from the root of the rooted tree to the node being exposed. 
8-2</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Figure 2: Walkin g Up and Splaying. The virtual tree after splaying 15 and 11 is shown on the left. 
The virtual tree on the right is at the end of step 1, after splaying also node 5. 
Figure 3: Splicing. w needs to be the root of its splay tree. 
8-3</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Approximation algorithms (facility location)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec17/</lecture_pdf_url>
      <lectureno>17</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>3 The primal-dual approach 
We shall follow the general outline behind primal-dual approaches to many problems: 
1. Formulatetheproblem as anintegerprogram, 
2. Relax it to a linear program, 
3. Look at the dual of the linear program, 
4. Deviseanalgorithmthat ndsanintegralprimal-feasiblesolutionand adual-feasiblesolution, 
5. Show that the solutions are within a small factor of each other, and hence of the optimum. 
3.1 IP formulation 
Let the variable yi denote whether the facility i is opened, i.e., 
1 if facility i is opened, yi = for each i  F. 0 otherwise 
Similarly,let xij denote whether the client j is assigned to facility i,i.e., 
1 if client j is assigned to i, xij = for each i  F and j D. 0 otherwise 
So we must have 
yi {0,1}for all i  F. (1) 
and 
xij {0,1}for all i  F, j D. (2) 
Further, we have the condition that each client must be assigned to exactly one facility: 
xij =1 (3) 
iF 
and the condition that clients can be assigned only to facilities that are actually open, i.e. that 
xij =1 = yi =1. One way of writing this as a linear relation is: 
yi xij  0 (4) 
Finally,the objectivefunction(cost) is 
fiyi + cijxij. (5) 
iF iFjD 
Theproblem of minimizing(5) subjectto conditions(1)(2)(3) and(4),is anintegerprogramming 
problem. 
17-2</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>3.2 LP relaxation 
The conditions(1) and(2) are notlinear constraints,but we can try to relax them to constraints 
that arelinear. We write,for(2),the condition 
0  xij (6) 
(wedonothavetowritexij  1,asthatisalreadyforcedby(3)),andfor(1),wewritethecondition 
0  yi (7) 
(as the cost is an increasing function of yi, the minimization will make sure that yi  1,if atall 
possible). Thus we have the following linear program: 
     
min fiyi + cijxij (8) 
iF iF jD  
s.t. xij = 1 j D (9) 
iF 
yi xij  0 i  F,j D (10) 
xij  0 i  F,j D (11) 
yi  0 i  F (12) 
We cannot expect every vertex of this LP to be 0-1; there can exist instances for which the LP 
optimum does not correspond to any convex combination of valid facility location integral solutions. 
ThustheLPdoes notgivea solutiondirectly. One way of using theLP wouldbeto solveit and 
then round the solution to a valid facility location; this needs some care but can be used to derive 
an approximation algorithm for the facility location problem. Another possibility is to pursue the 
primal-dual approach which is what we shall now do. 
3.3 LP dual 
Let us look at the dual of the LP. Introducing dual variables vi for the constraints(9) and wij for 
the constraints(10), wegetthedualLP: 
max vi (13) 
jD 
s.t. wij  fi i  F (14) 
jD 
wij + vj  cij i  F,j D (15) 
wij  0 i  F,j D (16) 
At the optimal solutions to the primal and dual, the complementary slackness condition says 
that: 
yi &gt; 0= wij = fi (17) 
jD 
xij &gt; 0= vj wij = cij (18) 
yi xij &gt; 0= wij =0. (19) 
If we could nd a primal feasible solution and a dual feasible solution that satised the comple
mentary slacknessconditions,andfurthermoretheprimal solutionwasintegral,then wewouldhave 
17-3</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>18.415/6.854 Advanced Algorithms November17,2008 
Lecture 17 
Lecturer: Michel X. Goemans 
1 Introduction 
We continue talking about approximation algorithms. 
Last time, we discussed the design and analysis of approximation algorithms, and saw that there 
were two approaches to the analysis of such algorithms: we can try comparing the solution obtained 
by ouralgorithmtothe(unknown) optimal solutiondirectly(aswedidfor Christodessalgorithm 
for TSP), or, when that is not possible, we can compare our solution to a relaxation of the original 
problem. 
We can also use a relaxation to design algorithms,even withoutsolving therelaxedproblem: we 
sawasimpleprimal-dual algorithmthatusedtheLP relaxationoftheVertex Coverproblem. 
Inthislecture, weshall examinefurthertheprimal-dual approach and alsothedesignof approx
imation algorithms through local search, and illustrate these on the facility location problem. 
2 The facility location problem 
2.1 Problem statement 
We are given a set F of facilities, and a set D of clients. Our goal is to open some facilities and 
assign clients to them so that each client is served by exactly one facility. We are given, for each 
i  F, the cost fi of opening facility i and the cost cij of assigning client j tofacility i for each 
j D. 
  If we open a certain subset F  F of facilities, the cost incurred is iF fi. Subsequently, 
we will assign each client to the nearest facility, incurring a cost miniF cij for client j. Thus our 
problem can be stated as the following optimization problem: 
min fi + (min cij) . 
F F iF 
iF jD 
Thisproblemarisesnaturallyinmany settings, wherethefacilitiesmightbeschools,warehouses, 
servers,and soon. Itispossibletoimagineadditional constraintssuch ascapacitiesonthefacilities; 
we shall deal with the simplest case and assume no other constraints. We shall also assume that the 
costs are all nonnegative, and that the cijs are in fact metric costs  that they come from a metric 
on F D wherethedistancebetween i  F and j D is cij. 
2.2 Current status 
ThisproblemisknowntobeNP-hard. Henceweseek todesignapproximationalgorithms. Thebest 
algorithmknownisa1.5-approximationalgorithm,duetoByrka[1]. Thisisclosetothebestpossible, 
in the sense that the following inapproximability result is true: if there is a 1.463-approximation 
algorithm,thenNP  DTIME(nlog log n)(see[2]). 
Since our focus in this lecture is on the techniques, we will see simpler approximation algorithms 
that illustrate the approaches, each of which gives only a 3-approximation. 
17-1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Figure1: Case(II).If i makes vj stop increasing via the third event from Section 3.4, there is no 
edgebetween i and j in G. Otherwise,(i,j) G. 
(I) j has exactly one open facility, say i = (j), in its neighborhood inG. 
(II) j has no open facility in its neighborhood in G. 
Firstconsidercase(I).Since wij &gt; 0 from the way we construct G, the algorithm freezes variables 
vj,wij after tightening the equation cij = vj wij. Thus, we have cij +wij = vj, and so 
cij +3wij  3(cij +wij)=3vj. (20) 
If wetakethe summation of(20) overthose clientsin case(I), we obtainfrom j 3wij =3fi that 
c(j)j +3 fi  3 vj. 
jD:case(I) iUjD:case(I) 
Thus, the opening of all facilities is already accounted for. 
Now consider case(II) where j contributes nothing for constructing facilities. Hence for com
pleting theproof,itis enough to showthatthe assigning-costfor j is at most 3vj i.e. there exists a 
facility i   U such that ci j  3vj. 
Let i be the facility that makes vj stop to increase, for which it follows that 
cij  vj and ti  vj. (21) 
In the case when i  U, it follows obviously that cij  vj  3vj. Hence assume i/ U. Since i is not 
open(although i is fully paid for), there exists a facility i   U such that i  cluster(i  ). Thus there 
exists a client j  which is connected to both i and i  in G. Since wij &gt; 0 and wi j &gt; 0, 
cij  ti and ci j  ti . (22) 
Fromthetriangleinequality,(21),(22) and ti  ti  vj (sincei was responsible for j freezing), we 
have 
ci j  ci j + cij + cij 
 ti + ti + vj 
 2ti + vj 
 3vj, 
which completes the proof.  
The local search based approach 
Now we study a dierent type of approximation algorithm based on local search. 
17-5 4</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Remark 1 Claim 2 guarantees an approximation ratio of 3 for this local-search algorithm since 
A+ O  3A  +2O   3(A  + O  )=3OPT  . 
Proof: In this lecture, we will see only the proof of (23) due to time constraints. (The proofof 
(24)would takelongerthanthe5 minutesavailableatthispoint.) Let U and U be the sets of open 
facilities in locally and globally optimal solutions respectively. For a facility i  U \U, the local 
optimality of U implies 
fi + c(j)j c(j)j  0, 
j: (j)=i 
where (j) and (j) are the open facilities which j is assigned to in U and in U respectively 
(since we couldjust reassignjustthe clientsfor which(j)is i). By taking the summation over all 
i  U \U,itfollowsthat 
O  + A  A  0. 
Now consider the time-complexity issue Q2. There exist instances for which this algorithm will 
take an exponential number of steps. In fact, the negative result for this issue comes from the fact 
thatthefacilitylocationproblem(with thisdenitionof the neighborhood)isPLS-complete[3], see 
next lecture for more details. Furthermore, it is unlikely that any algorithm(not necessarily based 
on this iterative local search process) can nd a locally optimal solution in polynomial time in the 
worst case. However, if the algorithm walks to a better solution only when it improves the current 
solution signicantly by  factor, it can be guaranteed that the algorithm terminates in polytime 
with respect to n and . Furthermore, one can obtain the -version of Claim 4.2, which leads to 
(3+  )-approximation ratio ofthe algorithm. 
References 
[1] Jaroslaw Byrka. An optimal bifactor approximation algorithm for the metric uncapacitated 
facility locationproblem. Proceedings of APPROX 2007,2007. 
[2] Sudipto Guha and Samir Khuller. Greedy strikes back: Improved facility location algorithms. 
In Journal of Algorithms,pages649657,1998. 
[3] Y.KochetovandD.Ivanenko. Computationally DicultInstancesfortheUncapacitatedFacility 
LocationProblem, volume 32. Springer US, 2005. 
17-7</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>4.1 General paradigm 
Suppose we want to minimize the objective function c(x)over the space S of feasible solutions. In 
the case of the facility problem, S is a subset of facilities and c(x) is the sum of the opening costs 
and the assigning costs. In a local search based algorithm, we have a neighborhood N: S  2S 
which satises the following two conditions: 
	v  N(v)for all v  S, 
	there exists an ecient algorithm to decide whether c(v)= minuN(v) c(u)for a given v and, 
if not, nd u  N(v)such that c(u)&lt;c(v). 
Using thisalgorithmforsearching the neighborhood,the algorithmtravelsinthespace S iteratively 
nding a better solution in N(v) than the current solution v  S. It terminates when the current 
solution v cannotbeimprovedi.e. v is a locally optimal solution. In a local search based algorithm, 
one also needs an algorithm for nding an initial feasible solution. 
We can raise some issues related to the design and analysis of local search algorithms: 
Q0: What neighborhood N should we choose?
-If |N(v)| is large, one can nd a better local solution in each iteration but designing an
algorithm to eciently search the neighborhood might be more dicult.
Q1: Howgoodis alocally optimal solution which the algorithmprovides?
-This decides the approximation ratio of the algorithm.
Q2: How many iterations does the algorithm require before nding a local optimum?
-Using the local search algorithm is one way to nd a local optimum; there might be some
more direct way, and the complexity of nding a local optimum has been studied (see the
discussion about the class PLS in next lecture).
Considerthe Traveling Salesman problem. Onepossibleneighborhood N arisesfrom 2-exchange 
where u  N(v)ifthetour u can be obtained by removing two edges in v and replacing these with 
two dierent edges that reconnect the tour. Therefore, |N(v)| = n 
2 , hence it is enough to check 
only O(n2) solutions to nd a better solution in N(v). Other neighborhoods can also be dened, 
such as for example k-exchange in which k edges are replaced. In the problem set, a neighborhood 
of exponential size is considered. 
4.2 Local search algorithm for the facility location problem 
Nowweexplain alocal searchbased approximationalgorithmforthefacility locationproblem. The 
set U of open facilities is enough for describing any solution in our solution space S since, after 
the openfacilities aredecided,the optimal assignmentfollows easily(and eciently). The simplest 
neighborhood one can consider is to simply allow the addition of a new facility, the deletion of an 
open facility, or replacing one open facility by another. More formally, N(U)is designed as follows: 
U   N(U)if U  = U {i}, U  = U \{i  }, or U  = U {i}\{i  } for some facilities i and i  . Note 
that |N(U)|= O(n2)which settles the time-complexity issue for nding a better solution in N(U). 
The following claim settles Q1. We will examine Q2 in the next lecture, albeit not for the facility 
locationproblem per se. 
Claim 2 Consider a locally optimal solution v for the above neighborhood N. Then, its opening 
cost O and assigning cost A satisfy 
A  A + O (23) 
O  O +2A , (24) 
where O and A are the opening cost and the assigning cost of the optimal solution respectively. 
17-6</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Network flows</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2008/resources/lec2/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>P            
               P                         
                          
                               
v  w  P = {(v,z), (z,w)}     0               v  z   
{(v,z)}      P    {(v,w), (w,z)}     0</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>x/y      e     x = f(e) 
 y = u(e)          |f| =3 
 s  t  
                            
  
            G       s      t   S    
   V     s  S  t/ S    S = V \ S     s  t         S  
     
(S : S)= {(v,w)  E : v  S  w  S}. 
        s  t    +(S)  (S)            (S : S) 
                    s  t  
        s  t              (S : S) 
      s  t  (S : S)                    
        
u(S : S)= u(v,w). 
(v,w)(S:S)</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>s  t      
                              
         
                  G     
     
max f= min u(S : S). 
f || 
(S:S) 
                              
                             
   
         G       f      uf : E R     
uf (v,w)= u(v,w) f(v,w)    (v,w)  E                (v,w)   
               v  w               
             uf (v,w)= u(v,w)  f(v,w)= u(v,w)+ 
f(w,v)  u(v,w)+ u(w,v)      f     u(v,w)  f(v,w)   uf (v,w)  0 
               (v,w)  E  
0  uf (v,w)  u(v,w)+ u(w,v). 
                                
        Ef  G       f       Ef = {(v,w)  E : 
uf (v,w) &gt; 0}               E            
             
           G                   
          
         Gf       G        f       
     Gf =(V,Ef )             uf  
                                
                           
           G        f                 
s     t         Gf  
                              
                    
          Gf          P   f      
 
             Gf              
     f         P  Gf              
           G                    
    P</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>I                         
 size(I)                   number (I)    
                              number (I) 
         m      size(I)               
              n  n        number (I)  
  n2 + n n2      n          size(I)        
                  
        A       I         
               A         size(I)  
                    A         size(I) 
                    
               A         number (I)  
                    A         size(I) 
                                
                              
                               
O(n3)</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
6.854J / 18.415J Advanced Algorithms 
Fall 2008
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>{(w,z), (z,w)}  
   
                          
          
       
                             
                                      
     
                  G =(V,E)        
  V           E          G  n       V  
m       E        v  V   N+(v)   N(v)      
              v  
N+(v)= {w  V :(v,w)  E}, 
N(v)= {w  V :(w,v)  E}. 
    u: E R+                       
        G         G       u     
            s  V       t  V           
             s  t       
      
                     G       
                            
            G     r : E R            
         (v,w)  E  0  r(v,w)  u(v,w) 
          v  V \{s,t}  
r(v,w)  r(w,v)=0. 
wV :(v,w)E wV :(w,v)E 
       r         r                         
s  
|r| = r(s,w)  r(w,s). 
wN+(s) wN (s)</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>G =(V,E)          V          E      
   : E R                 G         s  t  
V   s  t                      G   s  
t              P                
   P  
(P )= (v,w). 
(v,w)P 
           s            t        
           (e)           e  E      
             O(m + n log n)         m = |E|
 n = |V |             G              
          C                   
         s  t                   
                  
   v,w  V       (v,w)          e =(v,w)         
    (e)  (v,w)</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>r     G     f       r     
f : E  R    f(v,w)= r(v,w)  r(w,v) 
                        
         
                      
                             f(v,w)   
    r(v,w)  r(w,v)                   (v,w)  E  (w,v) 
         G                     G       
 (v,w)  E   (w,v)  E          G                
G     
     E = {(v,w)  E :(w,v) /E}  
     (v,w)  E       (w,v)       0     E  
                          f          
                  s 
|f| = f(s,w),  
wN(s) 
       N(s)    N+(s)= N(s)              
 s 
                     f            
        (v,w)  E  f(v,w)= f(w,v) 
        (v,w)  E  f(v,w)  u(v,w) 
         v  V \{s,t}  wN (v) f(v,w)=0 
     r     f              f       
                         G     
(v,w)           r(v,w)    (w,v)                 
  (w,v)       f(w,v)= r(v,w)              
    f(w,v)  u(w,v)=0              
                               
                               
   
               G        s  V     
  t  V                      G    
   
      G      E</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>P    (P )  
        
                            
                (P )  O(m + n log n)   
	                 O(m log U)   U        
                      O((m+ 
n log n)m log U) 
                           
                             
  
                             
                     P         
                 
                            
    O(m)         
	                    O(nm)            
   O(nm2)</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>G          s   t       f    s  t  
(S : S)    
|f| = f(v,w).  
(v,w)(S:S) 
         |f| u(S : S) 
               f         v  S \{s}       
f(v,w)=0. 
wN(v) 
            v  S \{s}    
f(v,w)=0. 
vS\{s} wN(v) 
               f             
|f| = f(s,w)+ f(v,w). 
wN (s) vS\{s} wN(v) 
         (v,w)                 w  S    (w,v) 
                            
   
|f| = f(v,w)+ f(v,w). 
(v,w)(S:S) vSwS 
         f                   0 
  f(v,w)  f(w,v)                 
|f| = f(v,w), 
(v,w)(S:S) 
   
           f      
|f| = f(v,w)  u(v,w)= u(S : S). 
(v,w)(S:S) (v,w)(S:S) 
           
        S = V \{t}  S = {t}               
      s          t                   
    
                                f  
                 s  t  (S : S)            f 
       (S : S)                   
          G            s     
t   
max f min u(S : S), 
f || 
(S:S) 
                              s  t 
  G</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>(P ) = min uf (v,w). 
(v,w)P 
    (P ) &gt; 0    P  Ef   P               
       f     
f(v,w)=  
 
 f(v,w)+ (P )  (v,w)  P  
f(v,w)  (P )  (w,v)  P  
f(v,w)   
   f           G    |f| = |f| + (P ) &gt; |f|     
  f         
                          
        f            G =(V,E)          
    Gf              f             
    S     v  V                  s  v  
Gf      s  S     Gf         t  S    (S : S) 
  s  t  
     uf (v,w)=0    (v,w)  (S : S)    uf (v,w)= u(v,w)  f(v,w) 
  f(v,w)= u(v,w)    (v,w)  (S : S)         
|f| = f(v,w)= u(v,w)= u(S : S). 
(v,w)(S:S) (v,w)(S:S) 
                              
  s  t          
max f= min u(S : S). 
f || 
(S:S) 
                
            G       f       G     
            
 f         
 Gf         
 |f| = u(S : S)    s  t  (S : S) 
                     (1) (2) (3) (1)  
 
(1) (2)                            
(2) (3)                        
(3) (1)</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>(G)
        f       
   Gf       P
   (P )           P    |f||f| + (P )
                               
          
                               
                       
        
           u  G               
      
              f             
                  f =0      
       (P )                       
                            
     (P )  1                      
                          
                            
                                    
                             
                      
    
               |f||N(s)|U  nU    U = max{u(s,w): w 
N(v)}      U             G            
                        
                          
                            
O(2L)                             
           u  G               
                          
                             
                                
                  
            u  G           u(E)  Q+ 
                           
            |f|</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
