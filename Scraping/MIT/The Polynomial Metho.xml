<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/</course_url>
    <course_title>The Polynomial Method</course_title>
    <course_tags>
      <list>Mathematics </list>
      <list>Algebra and Number Theory </list>
      <list>Discrete Mathematics</list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>Introduction to the Cellular Method (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec17/</lecture_pdf_url>
      <lectureno>17</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 THE CELLULAR METHOD
B Even distribution of lines. We suppose that all the k-rich points are in the open
cells, and the number of lines of Lthat enter each cell is 10L/d.
In each case, if we are able to choose d, we will be able to prove the Szemer edi-
Trotter bound |Pk|/lessorsimilarL2k3. Let us examine how the argument would go in each
case. We let Oidenote the open cells. We let Lidenote the number of lines of L
which intersect Oi. We let Nibe the number of k-rich points in Oi.
Case A.
Lemma 1.2. Ifd160Lk2, and if condition A. holds, then |Pk| 8Ldk1.
Proof. We have the following bounds for Ni. By the counting bound, if Li(1/4)k2,
thenNi2Lik1. Also, by assumption, Ni10|Pk|d2for all i. We call a cell big
ifL2i(1/4)k. We can bound |Pk|=/summationtextNiin terms of the number of big cells as
follows:
|Pk|=/summationdisplay
N
i(/summationdisplay
2Lik1) + (# big cells) 10d2|Pk|.
i i
We also know that/summationtext
iLiL(d+ 1) because each line enters d+ 1 open cells.
We can plug this in to the rst term of the right-hand side. Also, we see that the
number of big cells is at most/summationtextLi/(k2/4)8dLk2. Therefore we get the following
inequality:
|Pk| 4Ldk1+ 80Ld1k2|Pk|.
If the coecient 80 Ld1k2is1, this inequality is vacuous. But as long as
80Ld1k21/2, we can shift the term 80 Ld1k2|Pk|to the other side. Let us
assume that 80 Ld1k21/2. This is equivalent to d160Lk2. Under this
assumption, we see that |Pk| 8Ldk1. /square
Now suppose we were able to arrange dlines in the plane obeying condition A. for
anyd. We could choose d= 160 Lk2, and we would see that |P| 2000L2k3k , the
Szemer edi-Trotter bound.
Case B.
This case is similar and even a little easier.
Lemma 1.3. Ifd40Lk2, and if condition B. holds, then |Pk| 4dLk1.
Proof. Since we have assumed condition B, Li10L/d. If 10 L/d(1/4)k2, then
we can apply the counting bound to deduce that Ni2Li/k. Then we see that
|Pk|=/summationtext
iN1 1i2k/summationtext
iLi2L(d+ 1)/k 4dLk . /square</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>THE CELLULAR METHOD 3
Now suppose we were able to arrange dlines in the plane obeying condition B. for
anyd. We could choose d= 40Lk2, and we would see that |Pk| 200L2k3, the
Szemer edi-Trotter bound.
This raises the question, can we actually nd dlines in the plane obeying condition
A or B? We explore this in the next section.
2.Are there good cell decompositions?
Can we nd dlines obeying condition A? Morally the answer is no. Here is a more
precise related question.
Question 2.1. Given a set of Npoints in the plane, and an integer dN1/2, can we
nddlines which cut the plane into cells so that each open cell contains 1000N/d2
points?
The answer to this question is denitely no. Let be a closed strictly convex
curve, such as a circle. Pick Npoints on this curve. Pick dN1/2. Consider d
lines in the plane. Each line contains 2 of our points, so only a small fraction of
the points are in the lines. More importantly, each line intersects in at most 2
points. Therefore, the lines cut into2dpieces. One of those pieces must contain
(N2d)/(2d)/greaterorsimilarN1/2points of our set. This badly violates our goal. We wanted
to nd N1/2lines that cut R2into cells with /lessorsimilar1 point in each cell  but in fact
one of the cells must have /greaterorsimilarN1/2points in it.
Next we ask: Can we nd dlines obeying condition B? Morally the answer is yes
(although Im not sure if the answer is literally yes). The main idea is to choose a
subset of drandom lines from L. If we do this, a typical edge of the cell decomposition
will intersect /lessorsimilarL/dlines. To get a rough idea of whats happening, consider a line
lL. For simplicity, lets suppose that it intersects all the other lines of Lat
dierent points. The intersection points are L1 points along l. Now we randomly
pickdof the Llines - so essentially we randomly pick dof the intersection points.
Now the line lis cut into the segments betweent the selected points. The average
number of points in each segment is L/d, and the probability that a given segment
hasKL/d points falls o exponentially in K. So very few edges intersect more
than 1000L/d lines of L. Next we consider the cells of our decomposition. If a cell
has1000 edges, and each edge intersects 1000L/dlines of L, then the number
of lines of Lwhich intersect the cell is 106L/d. The cell decomposition may have
a few cells with &gt;1000 edges, but these are also pretty rare.
Heres another perspective. Suppose we rst choose d/2 random lines of Land
look at the resulting cells. Suppose that one of the cells intersects &gt; KL/d lines of L
for a very large K. When we choose d/2 more random lines of L, we are very likely
to choose one of the lines intersecting this popular cell. The probablility that we
will not choose any of these lines is exp(cK). As we keep adding random lines,</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>6 THE CELLULAR METHOD
The cellular method works well for incidences of codimension 1 objects, such as
planes or spheres in R3. In this case, we can build an interesting cell decomposition
by taking a random subset of the planes or spheres. For objects of codimension
&gt;1, such as lines in R3, it has been dicult to apply the cellular method (at least
directly).
Returning to our question, there are many examples where we cannot cut space
into evenly matched cells. Its not clear if these examples share a useful structure
or property that we could take advantage of. In our counterexamples, it seems that
the points or lines t onto a nice 2-dimensional surface or 1-dimensional curve. Does
that always happen, or is it just wishful thinking?
5.Polynomial cell decompositions
A union of dplanes is a special case of an algebraic surface of degree d. The main
idea in this chapter is to cut space into pieces with a degree dalgebraic surface.
Allowing an arbitrary degree dsurface instead of just dplanes greatly increases our
exibility. (When we pick dplanes, we have 3 dparameters to play with, but when
we pick a degree dsurface we have (1/6)d3parameters to play with!) With all
this extra exibility, we can do a much better job of decomposing space into evenly
matched cells. On the other hand, if Zis a degree dsurface, then a line either lies in
Zor intersects Zindpoints. Therefore, each line intersects d+ 1 components
of the complement of Z exactly the same bound as if Zwas a union of dplanes.
Theorem 5.1. IfXis any nite subset ofnRanddis any degree, then there is
a non-zero degree dpolynomial Pso that each component ofnR\Z(P)contains
C(n)|X|dnpoints of X.
We will prove this theorem next time. The proof is a cousin of nding a degree d
polynomial that vanishes at dnprescribed points, but it uses topology instead of
linear algebra.
We should also give a caveat. The theorem does NOT guarantee that the points
ofXlie in the complement of Z(P). In fact it is possible that XZ(P). There
are two extreme cases. If all the points of Xlie in the complement of Z(P), then
we get optimal equidistribution, and we have a good tool to do a divide-and-conquer
argument. If all the points of Xlie in Z(P), then we see that deg(X)d, and we
get a good degree bound on X. Generally, Xwill have some points in Z(P) and
some points in the complement. On one part of Xwe get a degree bound and on
the other part of Xwe get good equidistribution.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>THE CELLULAR METHOD 5
Now suppose that for any d1 we could choose dhyperplanes so that Aholds.
We would choose dL1/2k1, and then we would get the bound |P|/lessorsimilarL3/2k2k .
Condition B is similar. If we could nd d= 20L1/2k1planes obeying condition
B, then it would again follow that |P|/lessorsimilarL3/2k k2.
This looks like a promising route towards our target theorem:
Theorem 3.2. IfLis a set of Llines in R3withL1/2lines in any plane and
3kL1/2, then |P|/lessorsimilarL3/2k k2.
4.Are there good cell decompositions in three dimensions?
So we are led to the following question.
Question 4.1. IfLis a set of Llines in R3withL1/2lines in a plane, and if
dL1/2, can we nd dplanes obeying condition A or condition B?
We havent used or mentioned the restriction L1/2lines in any plane so far. We
take a moment to see how it may be relevant. Suppose we consider Llines which all
lie in a plane . If we include the plane among the dplanes, then the planes will
include all the k-rich points which completely violates condition A or B. Each other
plane intersects in a line (or not at all). So we are now eectively partitioning
the point of Pkwithdlines. But these dlines only cut intod2pieces, and
so an average piece must have /greaterorsimilar|Pk|d2k-rich points and must meet /greaterorsimilarLd1lines,
violating either condition.
Now we return to our set of lines LwithL1/2lines in any plane. Is it possible
that with this restriction, we can nd a good cell decomposition obeying one of
the conditions. The answer is still no. We have the same problems as before with
condition A. If Pis a set of points on a convex surface like a sphere, then for any
cell decomposition with dplanes, one of the cells will have /greaterorsimilar|P|d2points. Also, P
could be a set of points on a curve . There are many curves that intersect every
plane in 10 points - say a typical trefoil knot. If Pis a set of points on such a
curve, then any cell decomposition with dplanes has a cell with /greaterorsimilar|P|d1points on
it.
We also have a problem with condition B. Suppose that Pis a set of points
on a convex curve inR2, and LisPRR3. Suppose that one plane is
transverse to the x3-axis. This plane intersects the lines in |P|points lying on a
convex curve. Each other plane intersects the rst plane in a line. All together, the
other planes cut the rst plane into /lessorsimilard2faces. But they cut the convex curve into
/lessorsimilardsegments. Therefore, we get a 2-dimensional face of our decomposition which
transversely intersects /greaterorsimilarLd1lines. Any open cell bordering this face must intersect
/greaterorsimilarLd1lines of L. We could also try using planes that are all parallel to the x3axis,
but there are similar problems, and one of the cells still contains /greaterorsimilarLd1lines.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>THE CELLULAR METHOD
In this lecture, we introduce the cellular method as an approach to incidence
geometry theorems like the Szemer edi-Trotter theorem. The method was introduced
in the paper Combinatorial complexity bounds for the arrangements of curves and
spheres by Clarskon, Edelsbrunner, Guibas, Sharir, and Welzl (Discrete Comput.
Geom. (1990) 5, 99-160). In the next lectures, we will combine ideas from the cellular
method with polynomial method.
Our goal here is to describe some of the main ideas of the cellular method as
context. We will not give complete proofs but instead sketch the proofs and do
heuristic calculations. As a model problem, we consider using the cellular method to
prove the Szemer edi-Trotter theorem. (It has many other applications, and we will
mention some of them later.)
Suppose that we have a set LofLlines in R2and we x a number kin the range
2kL1/2. We wish to bound the number of k-rich points |Pk|.
The cellular method is a divide-and-conquer strategy. We cut the plane into cells.
We use elementary estimates to control the number of k-rich points in each cell, and
if the points and/or lines are well-divided among the cells, then we get a stronger
estimate by dividing into pieces in this way.
1.Good cell decompositions
Suppose we take dlines in R2(not necessarily in L). The complement of the d
lines has /lessorsimilard2connected components, which we call cells. If the lines are in general
position, the number of cells is d2. Each line enters d+ 1 cells. So each line of
Lenters only a small fraction of all the cells (at most /lessorsimilar1/d).
In each cell, we will employ a simple counting estimate for k-rich points, which we
proved in the rst lecture on incidence geometry.
Lemma 1.1. (Counting bound) If Lis a set of Llines, and if Lk2/4, then
|Pk| 2L/k.
Our strategy is to emply the counting bound in each cell and add up the results.
If all the lines go through a single cell and all the k-rich points lie in that cell, then
we havent gained anything by our cell division. The divide-and-conquer algorithm
works well if each cell is roughly equal. We consider two precise conditions.
A Even distribution of points. We suppose that all the k-rich points are in the open
cells, and the number of k-rich points in each open cell is 10|Pk|/d2.
1</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 THE CELLULAR METHOD
popular cells are likely to be cut down to size. If we make this analysis quantitative,
I believe we nd that the fraction of cells Oiwhere LiKL/d is/lessorsimilarexp(cK). So
this random decomposition nearly obeys condition B.
If the heuristics above are correct, we can arrange that every cell obeys Li
C(logL)L/d, and this implies the S-T estimate up to logarithmic losses. In order
to prove the real Szemer edi-Trotter theorem with the cellular method, one has to
subdivide the popular cells by adding some line segments. This requires some care,
and we dont discuss the details here.
3.Good cell decompositions in three dimensions
Having warmed up in two dimensions, now we consider a set LofLlines in R3.
We consider dplanes in R3which typically divide R3intod3cells. Each line can
only enter d+ 1 open cells, so each line enters only a small fraction of the cells.
If the lines and/or points are evenly distributed among the cells, then we get a good
bound for the number of k-rich points. We again consider two precise conditions.
A Even distribution of points. We suppose that all the k-rich points are in the open
cells, and the number of k-rich points in each open cell is 10|Pk|/d3.
B Even distribution of lines. We suppose that all the k-rich points are in the open
cells, and the number of lines of Lthat enter each cell is 10L/d2.
In either case, we get good bounds for Pkespecially if we can choose d.
Lemma 3.1. Ifd13L1/2k1, and if condition A. holds, then |Pk| 8Ldk1.
Proof. We have the following bounds for Ni. By the counting bound, if Li(1/4)k2,
thenNi2Lik1. Also, by assumption, Ni10|Pk|d3for all i. We call a cell big
ifLi(1/4)k2. We can bound |Pk|=/summationtextNiin terms of the number of big cells as
follows:
|Pk|=/summationdisplay
N
i(/summationdisplay
2Lik1) + (# big cells) 10d3|Pk|.
i i
We also know that/summationtext
iLiL(d+ 1) because each line enters d+ 1 open cells.
We can plug this in to the rst term of the right-hand side. Also, we see that the
number of big cells is at most/summationtextLi/(k2/4)8dLk2. Therefore we get the following
inequality:
|Pk| 4Ldk1+ 80Ld2k2|Pk|.
If the coecient 80 Ld2k2is1, this inequality is vacuous. But as long as
80Ld2k21/2, we can shift the term 80 Ld2k2|Pk|to the other side. Let us
assume that 80 Ld2k21/2. This is implied by d13L1/2k1. Under this
assumption, we see that |Pk| 8Ldk1. /square</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>The Elekes-Sharir Approach to the Distinct Distance Problem (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec11/</lecture_pdf_url>
      <lectureno>11</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>Let L = {ipq}p,qP , N2 lines. Then |G ' | is the number of points in  k lines of L. Remember that the k 
incidence geometry depended on whether they were all in the plane. 
Lemma 8. If q = r then ipq and iqr are skew. 
Proof. Spq = {g  G : g(p) = q}, so Spq  Spr = . This shows that ipq  ipr = , so we also have to show 
they arent parallel. The slope ((dx/dz, dy/dz )) of ipq is v(p, q) and these slopes are dierent. 
We also realized that there was a problem if too many lines lay in some regulus. We wont prove this in 
class today but defer this proof to a while later, but there are  N lines of L in any degree 2 surface. 
Conjecture (ES2A). If L is a set of L lines with at most L1/2 in any plane or degree 2 surface, then 
|P2| ; L3/2 . 
Conjecture (ES2B). If L is a set of L lines with at most L1/2 in any plane and 3  k  L1/2 , then 
|Pk| ; L3/2k2 . 
Finally, we saw another log-log graph of the bounds we had. We had the S-T bound for any L lines that 
was piecewise linear with two regions, from 2 to L1/2 and L1/2 to L. Then if we assume the number of lines 
in any plane or degree 2 surface is small, then we lower the rst line. 
This nishes our background on incidence geometry. In the next session, well pick up with the polynomial 
method. 
3</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Proof. We have 
k |Q(P )| = |G=k| 2 2 
N 
= [|Gk|  |Gk+1|](k2  k) 
k=2  
= |Gl| [(l2  l)  ((l  1)2  (l  1))] 
l  
l |Gl| . 
l 
We also have this other characterization of Gk: 
Lemma 6. Gk = {g  G : |gP  P |  k}. 
This is sort of a generalization of symmetries, where wed require gP = P . So we can think of these as 
partial symmetries. 
Example. Suppose our set of points is an s  s square grid with N 
2 pppp2 . Then |Gs2 | = 4. What about things 
1p? Well, it takes a while to explain, but |Gk|  N3k2 for all 2  k  = s
like N. pG 1 s10 10 
That this is the best you can do was a conjecture: 
Conjecture (ES1). If P  R2 with |P | = N and 2  k  n, then |Gk| ; N3k2 . 
pppThis has since been proven, and well prove it in this class using the polynomial method. 
N N N3k1Lets see the consequences. |Q(P )|  |Gk| k ; ; N3 log N. Then |d(P )| 2k=2 k=2 
23 ||N / Q(P )N/ log N Well prove this whole chain of implications using the polynomial metho d. We . 
ppsee that weve claimed that the conjecture itself is sharp for the square grid, so we know that the square 
grid indeed does have that many quadruples. But we could have lost some at the last step because we used Cauchy-Schwarz, and indeed, we checked earlier that there are N/ log N distinct distances in the large 
square grid. 
Lets get a better feel for these rigid motions. We rst have the translations T , which are congruent to 
the plane R2 . 
Lemma 7. |T  Gk| ; N3k2 . 
 N3 because  
E1(g)  Q(P ) = {(p 1, q1, p2, q2)  P 4 such that p1q1 
1, q1, p2, there is at most one choice of p2. Then dene E : QT  T Proof. Consider the number of translation quadruples QT = 
p2 q2 = 0}.
 
similar to before, and if g  Gk,
 Then #QT 
So |QT |  |Gk  T |  2 k 
2 k2 , and were done. . 
Now wed like to straighten G' := G/T . Theres a way to do this to make it correspond to the incidence 
geometry of points and lines. G' is a rotation around a xed point (x, y)  R2 by angle   (0, 2). Then 
we dene  : G  R3 by (x, y, ) = (x, y, cot /2). 
Proposition. (Spq  G') is a line ipq. 
Proof. Indeed, if we rotate from p to q, the point of rotation must be on the perpendicular bisector of p and 
q. Its just trigonometry from here. 
In fact, we have the following: 
p2q2 q1p1 1 p+qProposition. Let v = , be a vector perpendicular to p  q with length |p  q| and a = .2 2 2 2 
Then (Spq  G') is a line parameterized by ipq : t  (a + tv, t). 
2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>The Regulus Detection Lemma (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec24/</lecture_pdf_url>
      <lectureno>24</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>THE REGULUS DETECTION LEMMA
In this lecture we prove the regulus detection lemma, our last result about incidence
of lines in R3.
Regulus detection lemma. For any polynomial PinR[x1, x2, x3], we can associate
a list of polynomials RPwith the following properties.
(1)DegRP CDegP .
(2) If xis contained in two lines in Z(P), then RP(x) = 0.
(3) If Pis irreducible and RPvanishes on Z(P), and if there is a non-special
pointxcontained in two lines in Z(P), then Z(P)is a regulus.
The key fact about a regulus that we will use is that it is doubly ruled. A surface
Z(P) is called doubly ruled if each point of Z(P) lies in two distinct lines in Z(P).
The regulus and the plane are the only irreducible doubly ruled algebraic surfaces in
R3(as we will prove). The job of the polynomial RPis roughly to detect whether
there are two distinct directions in which the polynomial Pvanishes to high order.
(However, there is no polynomial that would do exactly this job. We discuss the
problems below and we will see that RPalmost does the job.)
Our rst task is to dene RP. Suppose that v= (v 1, v2, v3). Suppose that Qs(v) is
a homogenenous polynomial of degree s, fors= 1,2,3. Let Ibe the ideal generated
byQ1, Q2, Q3inR[v]. Recall that I=3denotes the homogeneous degree 3 polynomials
inIand that H= R ddenotes the homogeneous degree dpolynomials in [ v].
Lemma 0.1. The set {(Q1, Q2, Q3)H=1...H=3|dimI =38}is an algebraic
set. It is equal to Z(R), where Ris a nite list of polynomials in the coecients of
theQs. Each polynomial in Rhas degree 9.
(This is just a special case of a previous lemma. Our set is given by the vanishing
of some 9 9 subdeterminants of a multiplication matrix, whose coecients are
coecients of Qs.)
We dene Qs,x(v) =s
vP(x) =/summationtextI
|I|=sI!IP(x)v, a homogenenous polynomial in
vof degree s. The coecients of Qs,x(v) are polynomials in xof degree degP. We
letRPbeR(Q1,x, Q2,x, Q3,x). Therefore, RPis a nite list of polynomials of degree
9degP. We have now checked property 1 of the regulus detection lemma.
We let I(x) be the ideal generated by Q1,x, Q2,x, Q3,x. We have RP(x) = 0 if and
only if I(x)=3has dimension 8.
The next task is to discuss the geometric meaning of the condition dimI(x)=38.
The most important fact is contained in the following lemma.
1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 THE REGULUS DETECTION LEMMA
horizontal lines, and we will conclude that Z(P) is a plane or a regulus. (Finally the
assumption that x0is not at means that Z(P) can only be a regulus.)
The set OZ(P) is given by a graph. After a rotation and possibly shrinking O,
we can assume that Ois given by equation h(x1, x2) =x3for a smooth function h,
and that x0is the origin (0 ,0,0). After a linear change of coordinates, we can assume
that at x0, the direction V1is (1,0,0) and V2is (0,1,0). Let L1be the horizontal
line through x0, and let L2be the vertical line through x0. Notice that L1is just the
linex2=x3= 0. For each point (t, 0,0) inL1, letL2(t) be the vertical line through
(t,0,0). Notice that L2(t) is the graph of hrestricted to a line l2(t) in the x1x2
plane. The line l2(t) passes through (t, 0), and if tis small, it has slope close to (0, 1).
Similarly, let L1(u) be the horizontal line through (0 , u,0), which is the graph of h
restricted to l1(u) - a line in the plane thru (0, u ) with slope close to (1 ,0). If t, u
are small enough, then l1(u) and l2(t) intersect in a small neighborhood of 0, and so
L1(u) and L2(t) interect in O.
By shrinking O, we can arrange that no two vertical lines intesect in O. Now
x three vertical lines close to L2. There are innitely many horizontal lines that
intersect all three of the vertical lines in O. If the three vertical lines are skew, then
innitely many horizontal lines lie in a regulus. Now Z(P) intersects the regulus in
innitely many lines - and since Pis irreducible, Z(P) is a regulus. If two of the
vertical lines are coplanar, then innitely many horizontal lines lie in a plane, and
soZ(P) would be a plane. /square
0.1.On RP at critical and at points.
Lemma 0.6. IfP(x) = 0, then RP(x) = 0.
Proof. SinceP(x) = 0, we have Q1,x(v) = 0. Therefore, I(x) is the ideal generated
byQ2,xandQ3,x. Therefore, the dimension of I(x)=3is at most 3 + 1 = 4 8./square
Lemma 0.7. Assume xis a regular point of Z(P). Then xis at if and only if
2P(x) :TxZTxZRis equal to zero, if and only if Q2,xis a multiple of Q1,x.
Proof. The rst equivalence is an exercise in multivariable calculus. Rotate and
translate space so that x= 0, and 1P(0) = 2P(0) = 0 but 3P(0) = 0. Without
loss of generality we can work with these coordinates for the rest of the proof.
Locally near 0, the surface Z(P) is given by a graph of a function h:x3=h(x1, x2).
Therefore P(x1, x2, h(x1, x2)) = 0 for all ( x1, x2) in a neighborhood of 0. Dierentiat-
ing once, we see that 1h(0) = 2h(0) = 0. Using this information and dierentiating
twice, we see that
ijP(0) = 3P(0) ijh(0),fori, j {1,2}./ne}ationslash</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 THE REGULUS DETECTION LEMMA
Lemma 0.2. Suppose that xis a regular point of Z(P). Suppose that 2P(x) :
T R xZTxZhas signature (1,1). In this case there are two linearly-independent
directions, 1, 2TZso that 2
iP(x) = 0. Given these assumptions,
RP(x) = 0if and only if 3
1P(x) =3
2P(x) = 0.
This lemma says that under some fairly mild conditions, RPdetects whether
there are two linearly independent vectors which solve the equations 0 = s
P(x) for
s= 1,2,3.
Proof. We start by understanding the ideal I1,2generated by Q1,xandQ2,x. We claim
thatI1,2is exactly the ideal of polynomials that vanishes on the multiples of 1and
2. In other words, for any degree d,I1,2,=dis the space of degree dpolynomials that
vanish on 1and2.
We prove the claim as follows. Since xis a regular point of Z(P),P(x) is non-
zero. The ideal generated by Q1,xis exactly the set of polynomials that vanish on
TZ. After performing a linear transformation, we can arrange that TZis spanned
by (1,0,0) =1and (0 ,1,0) =2. Now R[v1, v2, v3]/(Q1,x) is isomorphic to R[v1, v2].
Next, we consider the image of Q2,xinR[v1, v2, v3]/(Q1,x) =R[v1, v2]. This image
is non-zero, because 2P(x) :TxZTxZRis non-degenerate. It vanishes on
(1,0,0) and on (0, 1,0), so it must be a non-zero multiple of v1v2. Therefore, I(x) is
the ideal generated by v3andv1v2. The rest of the claim is easy to check.
We see that I1,2,=dis the kernel of the evaluation map from R[v]=dto the two
points 1and2. For each d1, this map is surjective, and so for all d1,
dimI 1,2,=d=dimR[v]=d2. In particular, for d= 3, we get dimI 1,2,=3= 8.
Now we are ready to show the the conclusion of the lemma. We know that RP(x) =
0 if and only if the dimension of I=3is8. Now I=3is spanned by I1,2,=3andQ3,x,
and the dimension of I1,2,=3is already 8. So dimI =38 if and only if Q3,xI1,2if
and only if Q3,x(1) =Q3,x(2) = 0. Since Q3,x(v) =3
vP(x), this last equation is
equivalent to 3
1P(x) =3
2P(x) = 0. /square
We talk briey about other situations. If xis a critical point of P, then RP(x) = 0.
Ifxis a at point of Z(P) then RP(x) = 0. These are the only situations we will
actually need. We put the write-up in the appendix.
For context, we talk a little more generally. The basic issue is that we are trying to
detect whether some equations have two distinct roots. But having two distinct roots
is not an algebraic condition - which we can see already by considering quadratic
polynomials. Roughly speaking, if RP(x) = 0 then there are either two independent
directions which satisfy the ecnodal equation, or else there may be one direction that
satises the equation with multiplicity 2. I believe that this happens for Gaussian</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>THE REGULUS DETECTION LEMMA 3
at surfaces. So I believe that there are lots of irreducible Pwhere RP= 0 on Z(P):
planes and reguli and also Gaussian at algebraic surfaces such as cylinders...
Now we are ready to verify the second property in the regulus detection lemma.
Lemma 0.3. Ifxlies in two lines in Z(P), then RP(x) = 0.
Proof. Ifxis critical or at, then we have seen that RP(x) = 0. Suppose that xis not
critical or at. Let 1and2be the tangent directions of the two lines. We know that
s
iP(x) = 0 for i= 1,2 and for any s. In particular, 2P(x) :TxZTxZRis a
non-zero quadratic form (in two variables) that vanishes on two independent vectors,
and so it must have signature (1, 1). Now Lemma 0.2 implies that RP(x) = 0. /square
Finally, we are ready to prove the third property - that under some conditions
RP= 0 implies that Z(P) is a regulus. We state the result as a lemma.
Lemma 0.4. IfPis irreducible and RPvanishes on Z(P), and if there is a non-
special point x0contained in two lines in Z(P), then Z(P)is a regulus.
The proof is based on local-to-global results for ruled surfaces. In particular, we
will use the following result from last lecture:
Proposition 0.5. Suppose that PR[x1, x2, x3]. LetOZ(P)be an open subset of
Z(P). Suppose that Vis a smooth, non-zero vector eld on O, obeying the ecnodal
equation:
0 =s
VP(x),for all xO, s= 1,2,3.
Suppose that at each point xO,P(x) = 0 and2P(x) :TZTZRis
non-degenerate.
Then the integral curves of Vare straight line segments.
Proof. We know that 2P(x0) vanishes in the tangent directions to the two lines.
Since x0is not at, 2P(x0) :TxZTxZRis non-zero, and we see that it must
have signature (1, 1). We can choose an open neighborhood OZ(P) around x0,
so that P= 0 and 2P:TZTZRhas signature (1, 1) inO. (In particular,
2Pis non-degenerate on O.)
At each point of O, there are two independent vectors V1, V2TZwith2
VP(x) =
0. We can normalize them to get two smooth vector elds V1andV2. Since RP= 0 on
O, Lemma 0.2 implies that V1andV2each satisfy the ecnodal equation: s
ViP(x) =
0 fors= 1,2,3. Now by the proposition above, the integral curves of V1andV2are
each straight line segments. We call the integeral curves of V1horizontal lines, and
we call the integral curves of V2vertical lines.
In a small neighborhood of x0, we will check that each horizontal line intersects
each vertical line. Then we will nd a plane or regulus that contains innitely many/ne}ationslash
/ne}ationslash</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>THE REGULUS DETECTION LEMMA 5
This proves the rst equivalence. In these coordinates, we have at x= 0,Q1,x(v) =
cv3for a non-zero constant c. Also, Q2,x(v) =/summationtextI
|I|=2I!v IP(x). So Q2,x(v) is a
multiple of v3if and only if 1,1P(x) =1,2P(x) =2,2P(x) = 0, if and only if xis a
at point of Z(P). /square
Lemma 0.8. Ifxis a at point of Z(P), then RP(x) = 0.
Proof. By the last lemma, Q2,xis in the ideal generated by Q1,x. Therefore, I(x) is
the ideal generated by Q1,xandQ3,x. Therefore, the dimension of I(x)=3is at most
6 + 1 = 7 8. /square
1.Incidence estimates
Using the regulus detection lemma, and the ideas in the proof of the P3estimate
(lecture 15), its straightforward to prove the following.
Theorem 1.1. Suppose that Lis a set of Llines in R3withBlines in any plane
or regulus, and suppose that BL1/2. Then |P2(L)|/lessorsimilarBL.
Remark: Its not clear at all what happens for Bsmaller than L1/2- for example
B= 10.
This nishes our work on incidences of lines in R3. For large k, the number of
k-rich points is covered by the incidence estimate using polynomial ham sandwich
(lecture 20). All together we get the following result.
Theorem 1.2. Suppose that Lis a set of Llines in R3withBlines in any plane
or regulus. Suppose that BL1/2and2kL1/2.
Then|Pk(L)|/lessorsimilarBLk2.
Remark. The incidence estimate in lecture 20 gives the slightly sharper but more
complicated estimate /lessorsimilarL3/2k2+BLk3+Lk1, which holds for all 2 kL.
This incidence estimate gives enough information to carry out the program of
Elekes and Sharir on distinct distances (lecture 11).
At the beginning of next lecture, well talk briey about how everything ts to-
gether, and then well close this chapter of the course.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Thue&#8217;s Proof (Part II): Polynomials of Two Variables (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec27/</lecture_pdf_url>
      <lectureno>27</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>PROOF OF THUES THEOREM  PART II 5
deg()1 deg()1 deg()1
deg()+1qdeg()+1
deg() =/summationdisplay
A1
kdqdeg()k+=/summationdisplay
Ak
k1,dqk
deg()+/summationdisplay
Adeg()1,d(qk) .
k=0 k=1 k=0
/square
Plugging in this lemma, we see that qD D
deg()Aik, qdeg()Bikare integers of size 
D[2|Q|]D. The integer matrix that we are solving has coecients of size D[2|Q|]D.
It is a matrix with dimensions (2D + 2)deg()l, and so it has operator norm
(2D+ 2)D [2|Q|]DC()D.
Now applying Siegels lemma, we see that we can nd an integer solution Pwith
|P|bounded by
deg()l
C()D2Ddeg()lC()D/.
Since DC()l, we can redene C() so that |P| C()l/.
/square
3.Summary
Suppose that is an algebraic number, and that r1, r2are two very good rational
approximations of . We may suppose that /bardblr1/bardblis very large and /bardblr2/bardblis (much)
larger. Say /bardblr2/bardbl  /bardblr1/bardblm.
We consider polynomials PZ[x1, x2] of the simple form P(x1, x2) =P1(x1)x2+
P0(x1). We can arrange that j
1P(, ) = 0 for 0 jm1 with |P| C()m.
On the other hand, if j
1P(r) = 0 for 0 jl1, then we must have |P|/greaterorsimilar/bardblr1/bardbll/2.
Since /bardblr1/bardblis much larger than C(), it follows that lmust be much smaller than m.
This creates a certain tension.
As we will see, if rwas too close to ( , ), than Pwould have to vanish too much
atr, giving a contradiction.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 PROOF OF THUES THEOREM  PART II
We choose D= 10001l+10001log/bardblr1/bardbl/bardblr2/bardbl. With this value of D,D/10,2Dl
land so the exponent of /bardblr/bardblis almost l/2. Also, the term /bardblr/bardbl2Dl /bardblr/bardbl/101 2 1./square
Combining our parameter counting with the elementary example q2x2p2, we
can nd Pvanishing to order latrwith|P|on the order of min(/bardbl r1/bardbll/2,/bardblr2/bardbl). The
following result shows that these examples are quite sharp. I believe it is a special
case of a lemma of Schneider.
Proposition 1.2. (Schneider) If P(x1, x2) =P1(x1)x2+P0(x1)Z[x1, x2], and
rQ2, and j
1P(r) = 0forj= 0, ..., l1, and if l2, then
1l1|P| min((2 DegP )/bardblr1/bardbl
2,/bardblr2/bardbl).
Remark. We need to assume that l2 to get any estimate. If we have vanishing
only to order 1, then we could have P(x1, x2) = 2x1x2, which vanishes at (r 1,2r1)
for any rational number r1. As soon as l2, the size of |P|constrains the complexity
ofr. It can still happen that one component of ris very complicated, but they cant
both be very complicated.
Proof. Our assumption is that
jP1(r1)r2+jP0(r1) = 0,0jl1.
LetV(x) be the vector (P 1(x), P0(x)). Our assumption is that for 0 jl1,
the derivatives jV(r1) all lie on the line V(r2,1) = 0. In particular, any two
of these derivatives are linearly dependent. This tells us that many determinants
vanish. If VandWare two vectors in R2, we write [ V, W] for the 2 2 matrix with
rst column Vand second column W. Therefore,
det[j1V, j2V](r1) = 0,for any 0 j1, j2l1.
Now it follows by the Liebniz rule that
jdet[V, V](r1) = 0,for any 0 jl2.
Remark: Because the determinant is multilinear, we have the Leibniz rule det[V, W] =
det[V, W ]+det[V, W ], which holds for any vector-valued functions V, W:RR2.
Nowdet[V, V] is a polynomial in one variable with integer coecients. If this
polynomial is non-zero, then by Gausss lemma (see last lecture) we conclude that
|det[V, V]|  /bardblr1/bardbll1.
Expanding out in terms of P, we have |det[V, V]|=|P0P1P1P0| 2(DegP )2|P|2.
l1Therefore, we have |P| (2DegP )1/bardblr1/bardbl
2.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 PROOF OF THUES THEOREM  PART II
number, we will check that 1 , , ..., deg()1form a basis for the vector space Q[] over
the eld Q. In particular, any power ican be expanded as a rational combination
of 1, , ..., deg()1. Substituting in, we can rewrite equation (1) in the form:
deg()1
0 = kb A
k=/bracketleftBigg
iBik+ ai ik
0 i i/bracketrightBigg/summationdisplay /summationdisplay /summationdisplay
= 0,
where AikandBikare rational numbers. Since 1, , ..., deg()1are linearly indepen-
dent over Q, this list of equations is equivalent to the deg() equations
/summationdisplay
biBik+/summationdisplay
aiAik= 0,for all 0 kdeg()1. (2)
i i
After multiplying by a large constant to clear the denominators, we get deg()
equations with integer coecients. In total, our original lequations j
1P(r) = 0 for
j= 0, ..., l1 are equivalent to deg()linteger linear equations in the coecients
ofP. Since we have &gt;2Dcoecients, we can nd a non-trivial integer solution as
long as D(1/2)deg()l.
Our next task is to estimate the size of the solution. To do this, we need to
estimate the heights of the coecients Aik,Bik. Also we get a much better estimate
by taking Dslightly larger than (1 /2)deg()l, and for this reason we choose Dto
be the least integer (1 +)(1/2)deg()l. To estimate the heights of Aik,Bik, we
consider more carefully how to expand din terms of 1 , , ..., d1.
Lemma 2.2. Suppose Q() = 0, where QZ[x]with degree deg(Q) =deg()and
leading coecient qdeg(beta). Then for any d0, we can write
deg()1
qd d k
deg()= Akd ,
k=0
where AdkdZand|Akd| [2|Q|]./summationdisplay
deg()Proof. We have 0 = Q() =/summationtext
k=0qkk. We do the proof by induction on d,
starting with d=deg(). For d=deg(), the equation Q() = 0 directly gives
deg()1
deg()qdeg(be a)deg()
t=
d/summationdisplay
(qk)k. ()
k=0
eg()1If we multiply both sides by qdeg(), we get a good expansion for the case d=
deg()1deg(). Now we proceed by induction. Suppose that qd
g( )d
de =/summationtextk
k=0 Akd.
Multiplying by qdeg(), we get</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>PROOF OF THUES THEOREM  PART II 3
The polynomial det[V, V] may also be identically zero. This is a degenerate
case, and the polynomial must simplify dramatically. One possibility is that P1is
identically zero. In this case P(x1, x2) =P0(x1), and by the Gauss lemma we have
that|P|  /bardblr1/bardbll. IfP1is not identically zero, then the derivative of the ratio P0/P1
is identically zero. (The numerator of this derivative is det[V, V].) In this case,
the polynomial Pfactors as ( q2x  2p2)P(x1), where P(x1) has integer coecients.
(compare proof of Gauss lemma) In this case, |P|  /bardblr2/bardbl. /square
The lower bounds on |P|in this lemma are pretty close to the upper bounds on
|P|in the examples above. Speaking informally, both bounds are pretty close to
min(/bardbl r1/bardbll/2,/bardblr2/bardbl).
2.Polynomials that vanish at algebraic points
Our whole discussion can be generalized in a straightforward way to algebraic
points instead of rational points. In the proof of Thues theorem, we have an algebraic
number , and r1andr2are rational numbers that approximate with very large
heights. The point (r 1, r2) is close to (,  ). We are going to compare nding an
integral polynomial that vanishes to high order at ( , ) and nding an integral
polynomial that vanishes to high order at ( r1, r2).
By using parameter counting, we will see that there is an integral polynomial
vanishing to high order at ( , ) whose coecients are much smaller than what we
could nd for a polynomial vanishing to high order at (r 1, r2).
Proposition 2.1. LetRbe an algebraic number. For any natural number
l, and any  &gt;0, there is a polynomial PZ[x1, x2]with the form P(x1, x2) =
P1(x1)x2+P0(x1)with the following properties.
j
1P(, ) = 0for0jl1.
 |P| C()l/.
The degree of Pis(1 +)(1/2)deg()l+ 1.
Proof. This Proposition follows by the same parameter counting argument as above.
There is one signicant new idea in order to deal with algebraic numbers. We let Da
degree to choose later. As above, we write P1(x) =D
i=0bixiandP0(x) =D
i=0aixi.
The coecents aiandbiare2Dinteger variable/summationtext
s at our disposal. For/summationtext
each 0 
jl1, our vanishing equation is
i i0 = (1 /j!)j ij+1 ij
1P(, ) = bi
i/parenleftbigg /parenrightbigg
 + aiji/parenleftbigg
j/parenrightbigg
 . (1)
This is a linear equation in ai, b/summationdisplay
iwith coecients in/summationdisplay
Z[]. We will see that it is
equivalent to deg() linear equations with coecients in Z. Since is an algebraic</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>PROOF OF THUES THEOREM  PART II
1.Polynomials that vanish to high order at a rational point
Suppose that PZ[x1, x2] has the special form
P(x1, x2) =P1(x1)x2+P0(x1).
Suppose that rQ2. IfPvanishes to high order at a complicated point r, how
big do the coecients of Phave to be? More precisely, we suppose that j
1P(r) = 0
for 0jl1. Last time we gave two examples. The polynomial q2x2p2which
has size /bardblr2/bardbl, and the polynomial (q 1x1p1)l, which has size /bardblr1/bardbll.
By parameter counting it is possible to do somewhat better.
Proposition 1.1. For any rQ2, and any l0, there is a polynomial PZ[x1, x2]
with the form P(x1, x2) =P1(x1)x2+P0(x1)obeying the following conditions.
j
1P(r) = 0forj= 0, ..., l1.
 |P| C()l/bardblr1/bardbll+2, for any  &gt;0.
The degree of Pis/lessorsimilar1l+ log/bardblr1/bardbl/bardblr2/bardbl.
Proof. We will nd our solution/parenleftbig
by counting pa/parenrightbig
rameters. We will choose a degree
D, and let P0, P1be polynomials of degree D. The coecients of P0andP1are
2Dinteger variables at our disposal. We wish to satisfy the lequations
j
1P(r) = 0, j= 0, ..., l1. (1)
After a minor rewriting, each of these equations is a linear equation in the coef-
cients of Pwith integer coecients. If we write P1(xi1) =/summationtext
ibix1andP0(x1) =/summationtext
iaixi, then
0 =qD i i
1qj
2(1/j!)1P(r) =q2(/summationdisplay
bi/parenleftbigg /parenrightbigg
pij
1qDi+j
1) + (/summationdisplay
ai/parenleftbigg /parenrightbigg
pij
1qDi+j
1p2).j ji i
The size of the coecients in the equations is 2D/bardblr1/bardblD/bardblr2/bardbl.
By Siegels lemma on integer solutions of linear integer equations (in the last
lecture), we nd a non-zero integer solution of these equations with
l|P| /bracketleftbig lD3D2D/bardblrD
1/bardbl /bardblr2/bardbl/bracketrightbig
2DlCl/bardblrl2D l 2D l1/bardbl/bardblr2/bardbl.
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>A Version of the Joints Theorem for Long Thin Tubes (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec34/</lecture_pdf_url>
      <lectureno>34</lectureno>
      <slides>
        <slide>
          <slideno>8</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>6 THE MULTILINEAR KAKEYA INEQUALITY
inIwith probability /greaterorsimilar1. With high probability, the size of I(j) isNn12j.
Therefore, our bound for I() follows from the following lemma.
Lemma 3.3. LetTj,aa= 1...Ajbe cylinders of radius 1 nearly parallel to the xj
axis. Then the volume of the set of points lying in at least one tube of each direction
1
is/lessorsimilar/producttextn
j=1An1
j.
If all the Ajhappen to be equal, this lemma is exactly the theorem from the last
section.
The case of unequal Ajrequires an extra renement in the proof. We cut each
cubeQiinto many smaller pieces, and we choose Pto bisect each smaller piece. The
smaller pieces are arranged into a grid, cut more nely in the directions jwhere Ajis
small and more coarsely in the directions where Ajis large. Details in the exercises...
(More details. Take a cube Qi. Pick tubes Tj(Qi). Change coordinates so that
the vectors v(Tj(Qi)) become exactly orthogonal. In these coordinates, Qiis not
  quite a cube, but contains a slightly smaller cube Qi. Chop Qiinto a grid, where the
jthdirection is cut subdivided into/producttext
j=jAj. Choose Z(P) to bisect each of these
pieces. ...)
4.Sharp turns of algebraic varieties?
So far, the polynomial method has not led to any progress on the Kakeya problem.
There are major diculties in applying the methods we have seen to long thin tubes
instead of perfect lines.
In the proof of nite eld Kakeya or Nikodym, we use parameter counting to nd
a polynomial that vanishes in some places, and then we argue that the polynomial
also must vanish somewhere else. This step plays a key role in most of the proofs
we have seen in this course. Its hard to see whether something like this can work in
the setting of tubes.
Suppose as in the rst section that Kis the union of a Kakeya set of 1 Ntubes
with surprisingly small volume, and that Pis a polynomial so that Z(P) bisects each
cube of the unit lattice that intersects K. Pick a tube Tfrom the Kakeya set, and
imagine extending it to twice its length, and let qbe a unit cube in this extension.
Is there any hope that Z(P) also roughly bisects q? We know that Z(P) bisects
all the cubes in T, and weve also seen that in most of these cubes Z(P) is roughly
parallel to T. IfZ(P) keeps going in the direction of its tangent plane, it will come
reasonably close to q(although its still not clear it will really hit q). But its not at
all clear whether Z(P) will continue in the direction of its tangent plane. Perhaps
Z(P) will curve dramatically and go nowhere near q.
It might be helpful to understand better how many sharp bends there can be in a
degree dalgebraic surface. Here is a toy problem that gets at some of these issues./negationslash</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>THE MULTILINEAR KAKEYA INEQUALITY 7
LetPbe a polynomial in two variables. Let Pos(P ) :={x2R|P(x)&gt;0}.
For a given degree d, how closely can Pos(P ) look like the square [ 1,1]2? Recall
that the Hausdor distance from Pos(P ) to [1,1]2is&lt; if [1,1]2lies in the -
neighborhood of Pos(P ) and Pos(P ) lies in the -neighborhood of the square. Let
(d) be the inmum over all degree dpolynomials PofdistHaus(Pos(P),[1,1]2).
Can we describe the order of magnitude of (d)?
Very little is known about this. We know that (d)&gt;0 for each d. The reason is
thatdistHaus(Pos(P),[1,1]2) varies lower semi-continuously as Pmoves in V(d)\
{0}. Multiplying Pby a positive constant does not change Pos(P ), and so we can
restrict attention to polynomials in the unit sphere of V(d). By compactness the
inmum is attained. But if distHaus(Pos(P),[1,1]2) were zero, we would have
P= 0 on the boundary of the square. Then Pwould vanish on the line x= 1, and
(x1) would factor out of P. Write Pas (1x)aP1(x, y), where (1 x) does not
divide P1. The polynomial P1vanishes at only nitely many points of the line x= 1.
Ifais even, then we see that P1needs to vanish on the side of the square where
x= 1, and then 1 xdivides P1, and we get a contradiction. If ais odd, then we
see that P1needs to vanish on the part of the line x= 1 where |y|&gt;1. This still
implies that 1 xdivides P1, and we get a contradiction.
Ifdis even, a nice example is the polynomial Pd= 1xdyd. The set Pos(P d) is
the unit ball in the Ldnorm. As d , it approaches the square, which is the unit
ball in the Lnorm. For every even d,Pos(P d)[1,1]2, andPd&gt;0 on the square
[(1/2)1/d,(1/2)1/d]. Now 1 (1/2)1/d1/d, and so distHaus(Pos(P2d),[1,1] )
1/d. Hence (d)/lessorsimilar1/d. It seems plausible that Pdis near-optimal and that (d)/greaterorsimilar
1/d.
The hard problem is to give quantitative lower bounds on (d). I dont know of
any explicit lower bound in the literature. I worked on the problem, and I had a
plan for a lower bound of the form eed...
I think the moral issue is to give quantitative bounds on how sharply a degree d
curve can make a certain type of turn. Its important to keep in mind the following
example. The zero set of the hyperbola xy=makes a very sharp turn near the
origin, which looks something like the corner of a square. But the hyperbola has
two branches, and so instead of being positive on approximately one quartant, it is
positive on two opposite quartants, and its positive set does not really look like the
neighborhood of a corner of a square. An algebraic curve can make an arbitrarily
sharp turn if it looks locally like a hyperbola with two branches, but it is harder for
it to make a sharp turn with only one branch.
I might have gone on too long about this toy problem. A solution to this problem
would not directly lead to any bounds on Kakeya. Trying to go further with the
polynomial method and tubes, this type of estimate seems to come up. In general, it</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>8 THE MULTILINEAR KAKEYA INEQUALITY
might be helpful to have more quantitative estimates about the geometry of degree
dalgebraic surfaces.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>THE MULTILINEAR KAKEYA INEQUALITY 5
/integraldisplay
|/summationdisplaynTi|n1=
i/integraldisplay
1|/summationdisplay
T|n1
i... |/summationdisplay1Ti|n1
i i
1On the right hand side we have a product of nidentical copies of ||n1iTi. Now
we edit the formula, keeping only a constant fraction of the terms/summationtext
in each copy of
|/summationtext 1
iT|n1
i. Let I(j) be the subset of tubes Tiwhere the angle between v(Ti) and
thexjaxis is (100n)1. For each j, the number of such tubes is Nn1- they
form a positive fraction of all of the tubes.
Theorem 3.1. (Bennett-Carbery-Tao) For any  &gt;0, there exists a constant Cso
that for any Kakeya set of tubes,
/integraldisplayn/productdisplay1|/summationdisplay
n1CN
Ti| Nn.
j=1iI(j)
(In this inequality, the Nfactor can actually be removed, see my paper On the
endpoint case of the Bennett-Carbery-Tao multilinear Kakeya inequality. But this
takes a lot of extra work.)
This inequality is a generalization of the last theorem. We explain how they are
related and we sketch the extra steps needed to prove the theorem. For any integers
1, ...,  n0, consider the set of points:
I() :={xn|2j |/summationdisplay
|&lt;2j+1R Ti for all j.}
iI(j)
The left hand side is
/summationdisplay
|I()|/productdisplay
2j/(n1).
 j
Therefore, the theorem follows from the following lemma:
Lemma 3.2. For each as above, |I()|/lessorsimilarNn/producttext
j2j/(n1).
The lemma shows that each term in the sum above has size /lessorsimilarNn, and the number
of terms is /lessorsimilar(logN)n, and so we get a bound for the total of /lessorsimilarNn(logN)n, which
proves the theorem.
If= 0, we have I(0) contained in the n-fold intersection set Idened above, and
the inequality follows from the Theorem in the last section. The other values of 
are fairly similar.
Let us randomly choose I(j)I(j), including each tube with probability 2j.
LetIbe the points lying in one tube Ti,iI(j) for each j. A point of I() lies</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>THE MULTILINEAR KAKEYA INEQUALITY
1.The discussion from last time, heuristics and memories
Suppose that {TnR i}is a Kakeya set of tubes in . Each tube has radius 1 and
length N, and there are Nn1tubes. Suppose that | Ti| Nn.
The number of unit cubes from the unit cube lattice that intersect TiisNn.
We use the polynomial ham sandwich theorem to choose a polynomial Pso that
Z(P) bisects each of these unit cubes. The degree of Z(P) is/lessorsimilarN1/n. What does
such a polynomial tell us? Let Q(K) be this set of cubes.
Consider one of the tubes, Ti. Letlbe a line parallel to the axis of Ti, a randomly
chosen parallel line in the tube Ti. For almost every choice of l, we have |lZ(P)| 
deg(P)/lessorsimilarN1/n. On the other hand, the tube Ticontains Ncubes of Q(K), and
Z(P) bisects each of them. Let Q(Ti) be this list of cubes. They are disjoint, so we
get
Average1 /n
qQ(Ti),l|lZ(P)q|/lessorsimilarN deg (P)/lessorsimilarN .
For a typical cube q, we know that Z(P) bisects q, and yet Average l|Z(P)q|/lessorsimilar
N/nis much smaller than 1. This is only possible if the surface Z(P)qis
approximately parallel to the tube Ti. We can make a revised picture of the surface
Z(P) in the tube Ti.
So the geometry of the surface Z(P) is connected with the geometry of the tubes
Ti. If we try to imitate Dvirs proof of the nite eld Nikodym or Kakeya conjectures,
we are led to the following question. Extend each tube Tia further length N, and
letqbe a unit cube in the extension. Is it true that Z(P) approximately bisects
q? This type of question looks dicult, and it may be unlikely. The surface Z(P)
is approximately tangent to the tube Tiinside of Ti, but its hard to know whether
Z(P) will bend sharply as soon as it leaves Tiand come nowhere near to q.
I spent a while trying to force Z(P) to hit q, and it was pretty frustrating. I
would charge down one of the tubes T, trying to pin Z(P) and carry it down to qi ,
andZ(P) would stay with me for a while and then swing out of the way, while I
went charging harmlessly by...
However, the structure that we observed above does say something interesting
about Kakeya sets. We noticed that for a typical cube qTi, the surface Z(P) is
approximately tangent to Ti. But there are many dierent tubes Tjcontaining q.
With the method above, we can argue that Tjis approximately tangent to Z(P) for
1</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>THE MULTILINEAR KAKEYA INEQUALITY 3
theorem can be thought of as a version of joints for nearly-orthogonal tubes. It
implies, in particular, the joints theorem for nearly orthogonal lines.
The proof involves the idea of the directed volume of a surface. Suppose Sis a
smooth hypersurface innRwith normal vector N. Ifvis a unit vector, we dene the
directed volume of Sperpendicular to Vby the formula
VS(v) :=/integraldisplay
|Nv|dvol S.
S
Notice that if the tangent plane of Sis perpendicular to v, we have |Nv|= 1, and
if the tangent plane contains v, we have |Nv|= 0. For example, we consider the
directed volume of the unit circle in the direction v= (0,1). The directed volume of
an arc of the upper semi-circle in direction vis exactly the change in the x-coordinate
over the arc. Therefore, the directed volume of the whole upper semi circle is 2, and
the directed volume of the whole circle is 4.
The computation for the circle generalizes as follows. Let be the orthogonal
projection fromnRtovnR.
Lemma 2.2. VS(v) =/integraltext
|vS1(y)|dvol(y).
As a corollary, we can immediately estimate the directed volume of a degree d
variety in a cylinder T.
Lemma 2.3. (Cylinder estimate) Let Tbe an innite cylinder in Rof radius r.
Letvbe a unit vector parallel to the axis of T. Let Z(P)be the vanishing set of a
polynomial P.
Then V (v)/lessorsimilarrn1Z(P)T deg(P).
Proof. Letbe the projection from Tto the cross-section vT. This cross-
section is just an (n-1)-dimensional ball of radius r. For almost every yin this ball,
|1(y)Z(P)| deg(P). By the last lemma, VZ(P)T(v) is bounded by deg(P)
times the volume of the cross-section, which is rn1. /square
Lemma 2.4. IfSis a hypersurface innR, and v1, ..., v nare unit vectors and the
angle from vjto the xj-axis is (100n)1, then V oln1S2/summationtext
jVS(vj).
Proof. At a given point of Swith normal vector N, we have to prove thatj|N
vj| 1/2. Ifejare the coordinate vectors, then its straightforward to che/summationtext
ck that/summationtext
j|Nvj| 1 for any unit vector N. The vectors vjare very close to ej, and so the
error has size j|ejvj| (1/100). /square
Now we can do/summationtext
the proof of the theorem.
Proof. Consider the unit cubical lattice. Let Q1, ..., Q Vbe all the unit cubes in the
nlattice which intersect the set I. We will prove V/lessorsimilarAn1.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 THE MULTILINEAR KAKEYA INEQUALITY
most of the tubes. In fact, there must be a hyperplane (q), and the tubes Tjmust
usually be almost tangent to (q). This is a somewhat surprising structure, called
planiness.
Planiness was rst discovered by Katz, Laba, and Tao, in the paper An improved
bound on the Minkowski dimension of Besicovitch sets in3R. (Ann. of Math. (2)
152 (2000), no. 2, 383-446.) Planiness was one of the observations/tools that allowed
them to prove that a Kakeya set of tubes in3R(with mild additional hypotheses)
has volume at least N2.5+. Later, Bennett, Carbery, and Tao proved stronger and
more general planiness estimates in the paper On the multilinear restriction and
Kakeya conjectures in Acta Math. 196 (2006), no. 2, 261-302. We will come to
their work below.
If we had a hypothetical Kakeya set of tubes, a typical cube would lie in many tubes
Tj. Without any experience, we might guess that the dierent tubes Tjqwould
point in a bush of directions that was pretty dense on the unit sphere. Suprisingly,
they need to concentrate near to a plane. Another way to say this is that they dont
form a whole lot of joints.
During the course, we met many theorems about the incidence patterns of lines
in space. Each of these questions can be adapted to a question about long thin
tubes instead of lines. Usually the adapted question is wide open. But for the joints
problem, the adapted question has a nice answer based on the ideas we have just
been discussing.
2.The generalized Loomis-Whitney inequality
We prove here an analogue of the joints theorem with long thin tubes instead of
perfect lines.
Theorem 2.1. (Bennett-Carbery-Tao, Guth) Suppose that Tj,aare cylinders innR
for1jnand1aA. Each cylinder has radius 1 and innite length. The
axis of a cylinder Tj,amakes an angle of &lt;(100n)1with the xj-axis.
LetIbe the points which lie in one cylinder for each value of j= 1...n. In equations
I:=n
j=1(A
a=1Tj,a).
nThen the volume of Iis/lessorsimilarAn1.
Remarks. If the tubes Tj,aare parallel to the xj-axis, then this estimate follows
from the Loomis-Whitney inequality. We see that the projection of Ito any coordi-
nnate hyperplane lies in Aunit balls, and then Loomis-Whitney gives |I|/lessorsimilarAn1. The
case of axis-parallel cylinders is basically equivalent to the Loomis-Whitney inequal-
ity. The problem here is to see that the inequality remains true if we are allowed to
tilt the tubes a few degrees.
History. BCT proved a tiny bit weaker estimate using monotonicity formulas
for the heat equation. G proved this estimate using the polynomial method. This</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 THE MULTILINEAR KAKEYA INEQUALITY
LetPbe a non-zero polynomial so that Z(P) bisects each cube Q1, ..., Q Vand
degP /lessorsimilarV1/n. This bisection requires a certain amount of area, therefore:
V oln1Z(P)Qi/greaterorsimilar1.
LetTj(Qi) be a tube from our list, in direction j, which intersects Qi. Letvj,ibe
the direction of this tube. The directions v1,i, ..., v n,iare nearly orthonormal, and so
n/summationdisplay
VZ(P)Qi(vj,i)/greaterorsimilarV oln1Z(P)Qi/greaterorsimilar1.
j=1
For each cube, choose one direction jso that VZ(P)Qivj,i/greaterorsimilar1, and assign the cube
Qito the tube Tj(Qi). We have Vcubes and nAtubes, so one of the tubes has
/greaterorsimilarV/Acubes assigned to it. Let Tbe this tube, and let vbe its direction. We have
/greaterorsimilarV/Acubes Qiobeying the following conditions:
The cube Qiintersects T.
VZ(P)Qi(v)/greaterorsimilar1.
LetTbe a wider cylinder with radius 2 nand with the same central axis as T. All
of the cubes Q ilie inT. Therefore, we have
V/A/lessorsimilarV1/n Z(P)T(v)/lessorsimilarV .
The last inequality is by the cylinder estimate.
nRearranging we get V/lessorsimilarAn1. /square
3.Multilinear Kakeya
The strongest version of the Kakeya conjecture is the Lpversion. If Tiare a Kakeya
set of tubes of radius 1 and length N, theLpKakeya conjecture says that for each
 &gt;0,
/integraldisplay
|
Rn/summationdisplaynTi|n1CNNn. (1)
i
Remarks: If we arrange the tubes in a disjoint way, the left hand side is Nn. If
we arrange them all centered at the origin, then the left hand side is (logN)Nn.
If true, this conjecture gives essentially sharp bounds for /bardbliTi/bardblpfor every p. It
implies that the union of tubes has volume at least cNn f/summationtext
or any  &gt;0.
This conjecture is still wide open. The multilinear Kakeya conjecture allows us to
control a positive fraction of all the terms - in a certain sense. First we rewrite the
left hand side of (1).</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Oscillating Integrals and Besicovitch&#8217;s Arrangement of Tubes (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec31/</lecture_pdf_url>
      <lectureno>31</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>2 OSCILLATING INTEGRALS AND THE KAKEYA PROBLEM
The operators MRare all in a family, and if one gets a good understand of M1,
then by rescaling one can also get a good understanding of any MR. By standard
analysis tricks, this question is equivalent to the following:
Question: For a given dimension n, for which pdo we have /bardblM1f/bardblp/lessorsimilar/bardblf/bardblp?
2.Oscillating kernels
Last time we considered the kernel K(x) :=|x|. Now we consider an oscillating
version of this kernel.
K
(x) := [1 + |x|] cos |x|.
 The function K(x) is still radial. Near the origin, its bounded instead of having
a sharp peak. Also, it oscillates with the radius, so that it has positive and negative
parts. If one dropped a stone into a pond and looked at the ripples, the shape would
 be a little bit like K, with a modest peak in the center, and then waves going
outward and getting smaller the farther they are from the center.
  We dene Tf:=fK.
The operator M 1turns out to be very similar to Tn+1. Although they are not
2 exactly equal, all the arguments that we will make about Tn+1apply just as well to
2
M 1. From now on, well just talk about T.
 Our main question is the following, what are all the Lpestimates obeyed by T?
At rst sight, this problem looks like a small variation on the Hardy-Littlewood-
Sobolev problem - its just a similar kernel with some oscillations added. Because
of the oscillations, there are positive and negative terms in the integrals, and some
cancellation occurs. The key issue is to understand how much cancellation needs to
occur.
We will focus on estimates of the form /bardblTf/bardblp/lessorsimilar/bardblf/bardblp, so that we have less
parameters to keep track of. ( LpLqestimates are interesting too, but all of the
essential issues already appear in this main case.)
Example 1. We let f=Brfor some r. Its already somewhat complicated to
 estimate Tfbecause of the cancellation in the integral. But if fis&lt;1/100, then
at most points x, there is no cancellation in the integral
T 
f(x) =/integraldisplay
[1 +|xy|] cos |xy|dy.
B(r)
  The most interesting is to take r= 1/100. In this case, TfK. In this case,
 we have /bardblf/bardblp  1, and/integraltext
|Tf|p/integraltext
Rn(1 +|x|)p. So/bardblTf/bardblp&lt;ip &gt; n .
Considering r1/100 just gives the same information.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>OSCILLATING INTEGRALS AND THE KAKEYA PROBLEM 7
 Exercise. The operator Tp(n+1)/2is also not bounded on Lforp &lt;2. To see this,
choose Tiso that T+
iare disjoint and | iT+
i|is much larger than | iTi|.
HLS problem: connected with how balls overlap in space
BR problem: connected with how tubes overlap in space.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>OSCILLATING INTEGRALS AND THE KAKEYA PROBLEM 3
Example 2. (Focusing example) For large r, there is something better to do than
 Br. Suppose that we want to make Tf(0) large. Lets write it out as an integral:
Tf(0) = f(y)[1 +|y|]
 cos|y|dy.
Rn
If we choose fcarefully, then/integraldisplay
all the contributions in the integral are positive,
instead of cancelling each other. This motivates choosing f2=Brsign(cos|y|), for
 some large r1. We have /bardblfn/p2/bardblp=r. We also have |Tf2(0)|  rn. In fact,
for all |x|&lt;1/ T 100, we have |fn  n2(x)| r. Therefore, /bardblTf2/bardblp/greaterorsimilarr. So
/bardblTf2/bardblp/lessorsimilar/bardblf2/bardblpin/pn.
In summary, we have the following proposition.
Proposition 2.1. If/bardblTf/bardblp/lessorsimilar/bardblf/bardblpfor all the examples above, then
n n&lt; p . n 
Exercise. Being a little more clever/careful in Example 2., we can get eliminate
 the upper endpoint. If /bardblTf/bardblp/lessorsimilar/bardblf/bardblpfor all f, then
n n&lt; p &lt; . n 
(Ifn/p=n, we can consider f3= KBrn. This rules out the endpoint,
leaving only n/p &gt; n .)
If particular, if = (n+1)/2 , then we have a bound on all examples provided
that2n&lt; p &lt;2n
. This was the situation until the early 70s.n+1 n1
3.Examples shaped like tubes
There is another important example in the theory of these operators: an oscillating
function supported on a long thin tube.
LetTbe a cylinder of length L &gt;&gt; 1 and radius (1/ 1000)L1/2. The cylinder may
point in any direction. Let vTbe a unit vector parallel to the axis of the cylinder.
LetfTbe the function
f(x) :=(x)ei(vTx)
T T .
 We want to understand TfT. LetT+denote the cylinder we get by translating T
 by 2LvT. The most interesting part is the behavior of Tf+TonT. Consider a point
xinT+.
TfT(x) =/integraldisplay
|xy|cos|xy|ei(vty)dy.
T</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 OSCILLATING INTEGRALS AND THE KAKEYA PROBLEM
Now the key point is that the oscillations of ei(vty)and the oscillations of cos |xy|
are in sync on T. Lets consider the set where eivtyis equal to 1  this set is the set of
peaks of the real part of the wave eivty. We have eivty= 1 when vty= 2n,nZ.
This set is a union of parallel planes, perpendicular to the axis of Twith spacing 2 
between them. The peaks of the wave cos|xy|occur at |xy|= 2n, on spheres
around xwith radius 2 n. But inside of the tube T, each sphere looks almost like a
plane. Its a good idea at this point to draw a picture of the level sets of vtyand
of|xy|inside of T. Because of this, the two waves interfere constructively. Lets
examine the situation more computationally now.
The vector xyis nearly parallel to vt. The vtcomponent of xyisL, and
the perpendicular component is (1/1000)L1/2. By the Pythagorean theorem, we
have
(vtxvty)2104L |xy|2(vtxvty)2+ 106L
Since |vtxvty| L/4, we see that
|xy|  |vxvy| 105
t t .
Therefore, up to a small error, we have
TfT(x) =/integraldisplay
|xy|cos(v)
txvy)ei(vty
t dy+ small error.
T
Expanding cos a= (1/2)(eia+eia), we get
TfT(x) = (1 /2)eivtx/integraldisplay
|xy|dy+(1/2)eivtx/integraldisplay
|xy|e2ivtydy+ small error.
T T
The rst integral is the main term. Theres lots of cancellation in the second
integral, so its much smaller. The error term is bounded by/integraltext
|xy|105dy, soT
its much smaller than the main term.
The volume of TisLn+1, and|xy| L, so the main term has size Ln+12 2.
Proposition 3.1. Iff+TandTare dened as above, then for every xT+we have
|Tn+1
f
T(x)|/greaterorsimilarL2.
Corollary 3.2. If &lt;n+1  , then there are no bounds of the form /bardblTf/bardblp/lessorsimilar/bardblf/bardblp.2
Proof. Notice that T+has the same size as T. The function fThas size 1 and
 support on T. If &lt;n+1, then the function TfThas size &gt;&gt;1 onT+. So2
/bardblTfT/bardblpLn+12/bardblfT/bardblp. /square</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>OSCILLATING INTEGRALS AND THE KAKEYA PROBLEM 5
 This type of example appears in a number of linear operators besides T. There
are similar examples connected to the wave equation. It takes some work to write
them down precisely, but we can give some feel for it just in words. Imagine an
airplane traveling at the speed of sound. The path of the airplane in space-time is
like a long thin tube. The engine of the plane vibrates, making sound waves, and
these sound waves travel at the same speed as the airplane. The airplane can feel
dramatically stronger sound waves than it would have felt at a lower or higher speed.
Even if the airplane turns o the engine, there will still be strong sound waves in
the plane for some time. The action of the engine occurs on one tube in space time,
and the resulting sound waves have large amplitude on a longer tube. Although the
 operator Tis not an accurate model for sound waves, the mathematical issues in
understanding it are similar with those in the wave equation.
  We now return to our operators T. For(n+ 1)/2, we have /bardblTfT/bardblp/lessorsimilar/bardblfT/bardblp
for all p  . In particular, the ball multiplier M1is similar to T(n+1)/2, and we have
/bardblM1fT/bardblp /bardblfT/bardblpfor all pas well. So this example does not give any new information
about the ball multiplier. For all the examples we have considered so far, we have
2n 2n/bardblM1f/bardblp/lessorsimilar/bardblf/bardblp,for all &lt; p &lt; .n+ 1 n1
Until the early 70s, it was generally believed that these inequalities were true.
The only case that was proven was p= 2. In The multiplier problem for the ball,
Charles Feerman proved that these inequalities are false for all p= 2. (The paper
appeared in Ann. of Math. (2) 94 (1971), 330-336). These counterexamples are
given by arranging many tubes in a remarkable pattern found by Besicovitch.
4.Sums of many tubes
 Let us consider a function f=/summationtext
ifTiover many tubes Ti. Then we have Tf=/summationtext
iTfTi. Schematic picture: draw some tubes Tiin blue, and T+
iin red. For
example, Timay be disjoint and T+
imay intersect.
In the 1920s, Besicovitch constructed an arrangement of tubes so that Tiare
disjoint and T+
iintersect a lot.
Theorem 4.1. (Besicovitch, 1920s) Fix a dimension n2. For any L1, there
is a nite set of disjoint tubes Ti(with length Land radius (1/1000)L1/2), with
the property that
| iT+
i|/lessorsimilar(logL)1| iTi|.
Well prove Besicovitchs theorem next class (or maybe something a touch weaker).
The key point for the moment is that (log L)1can be arbitrarily small./negationslash</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>6 OSCILLATING INTEGRALS AND THE KAKEYA PROBLEM
Letf=/summationtext
ifTi, where the Tiare the tubes in Besicovitchs construction. How
 big is T(n+1)/2f? Suppose that xlies in Atubes T+
i. We have a sum of Aterms of
size1, but these terms are complex numbers that may point in any direction. We
would actually have to be quite lucky if the sum of Aterms had size A. The sum
ofArandom numbers |z| 1 has size A1/2. So we should expect something more
like
1/2
|T(n+1)/2f x T  ( )| /parenleftBigg/summationdisplay
|2
(n+1)/2fTi(x)|
i/parenrightBigg
().
In fact, if we dene fran=ifTiwith random signs, then (*) is true with
very high probability./summationtext
Proposition 4.2. Ifgiare any functions, then with high probability,
/bardbl/summationdisplay
g/bardbl  /bardbl (/summationdisplay
|g|2)1/2
i p i/bardblp.
i i
We defer this  the probability argument is similar to one earlier in the course.
 With these tools in hand, we can understand /bardblfran/bardblpand/bardblTfran/bardblp.
Corollary 4.3. IfTiis any set of tubes, and fran:=/summationtext
ifTi, then with high proba-
bility
2/bardblfra/bardblp /bardbl(/summationdisplay1/
n 2 1
i)/2
T/bardblp /bardbl/summationdisplay
Ti/bardblp/2.
i i
In Besicovitchs example, the tubes Tiare disjoint, and so /bardblf1/pran/bardblp | Ti|.
Corollary 4.4. IfTiis any set of tubes of length L, and fran=/summationtext
ifTi, then with
high probability
n+1/summationdisplay1/2/bardblTfran/bardblp/greaterorsimilarL2/bardblT+/bardbl
ip/2.
i
In Besicovitchs example,/summationtext
iT+is supported on a set of measure /lessorsimilar(logL)1|ii
Ti|, and so its average height is /greaterorsimilarlogL. Therefore, for q &gt;1, its Lqnorm is
/greaterorsimilar(logL)q(logL)1| iTi|, and we get
/bardblTn+1p2
f 1/p
ran/bardblp/greaterorsimilarL2(logL)4| iTi|.
We get
Theorem 4.5.  (Feerman 1971) If p &gt;2, then Tp(n+1)/2is not bounded on L.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>OSCILLATING INTEGRALS AND THE KAKEYA PROBLEM
1.The ball multiplier in Fourier analysis
We give a little background in Fourier analysis.
The Fourier transform innRis dened by
f() = f(x)e2ixdx.
Rn
In this short background section,/integraldisplay
we will assume that fis continuous and com-
pactly supported. With these assumptions, the integral above is clearly dened. A
function can be recovered from its Fourier transform as follows:
Proposition 1.1. Iffis a smooth compactly supported function, then
f(x) =/integraldisplay
f()e2ixd.
Rn
 As long as fisCsmooth, fdecays rapidly, and this integral is dened. If fis
 just continuous with compact support, then fis a continuous function, but it may
not be integrable. In this case, it requires thought to understand what the right-hand
side should mean. Partly for this reason, Fourier analysts considered integrating just
over a ball:
 M f(x) :=/integraldisplay
f()e2ix
R d.
Bn(R)
Iffis continuous with compact support, then MRfis well dened for any nite
R. It is natural to ask whether MRfconverges to fasR . Here are some
fundamental results about this question.
At a particular point x,MRf(x) may not converge at all. (19th century)
The functions MRfconverge to finL2(in every dimension). (One of the
motivations for dening L2convergence in the early 20th century)
Ifn= 1, then MRfconverges to finLpfor every 1 &lt; p &lt; . (Riesz, early
20th century.)
Question: For a given dimension n, for which pdo we have MRffinLpfor all
fC0
comp?
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Crossing Numbers and the Szemeredi-Trotter Theorem (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec7/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2  CROSSING NUMBERS AND THE SZEMER EDI-TROTTER THEOREM 
G )
For perspective, consider the complete graph Kn. It has n vertices and n 
2edges. 
For large n, this proposition shows that the crossing number of Kn is  n2 . On 
the other hand, the only upper bound we have so far is the trivial bound that the 
crossing number of Kn is ;n4 . 
What may we hope to improve in this proposition? When we remove an edge 
of G, its in our interest to remove the edge with the most crossings, and when we 
do this, the crossing number of G can decrease by more than 1. For example, for 
the complete graph Kn, it looks plausible that there is always an edge with  n2 
crossings. How may we estimate this? 
This seems to be a tricky problem, and Sz ekely found a very clever solution. 
Instead of trying to prove that one edge intersects many other edges, he considered a small random subgraph G
  G and proved that two edges of G must cross. Since 
G is only a small piece of G, it follows that many pairs of edges in G must cross. 
Theorem 1.3. If G is a graph with E edges and V vertices, and E  4V , then the 
crossing number of G is at least (1/64)E3V 2 . 
This theorem was proven by several authors before Sz ekely, but we give his proof. 
It shows that the crossing number of the complete graph Kn is n4 as a special 
case. 
Proof. Let p be a number between 0 and 1 which we choose below. Let G be a 
random subgraph of G formed by including each vertex of G independently with 
probability p. We include an edge of G in G if its endpoints are in G . 
We consider the expected values for the number of vertices and edges in G . The 
expected value of V  is pV . The expected value of Eis p2E. For every subgraph 
G  G, the crossing number of G is at least E 3V  . Therefore, the expected value 
of the crossing number of G is at least p2E 3pV . 
On the other hand, we give an upper bound on the expected crossing number of 
G as follows. Let k = k(G) be the crossing number of G. Let F : G  R2 be a legal 
embedding with k crossings. We claim that each crossing of F involves two disjoint 
edges. In other words, two edges that share a vertex dont cross. We come back 
to the claim at the end. By restricting F to G, we get an embedding of G with 
p4k crossings on average. This is because each crossing involves four vertices, and it 
appears as a crossing of F (G) only if all four vertices are included in G . (IfF had 
a crossing involving two edges containing a common vertex, then it would appear with the much higher probability p
3.) Therefore, the expected value of the crossing 
number of G is at most p4k. 
Comparing our upper and lower bounds, we see that p4k  p2E 3pV , and so we 
get the following lower bound for k.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>3  CROSSING NUMBERS AND THE SZEMER EDI-TROTTER THEOREM 
k  p 2E 3p 3V. 
We can now choose p to optimize the right-hand side. We choose p = 4V/E, and 
we have p  1 since we assumed 4 V  E. Plugging in we get k  (1/64)E3V 2. 
To nish the proof, we just have to check the claim that F has no crossings of 
edges that share a vertex. Given any map with such a crossing, we explain how to 
modify it to reduce the crossing number. Say that F (e1) and F (e2) each leave F (v) 
and cross at x. (If they cross several times, then let x be the last crossing.) We 
modify F as follows. Suppose that F (e1) crosses k1 other edges on the way from 
F (v) to x and that F (e2) crosses k2 other edges on the way from F (v) to x. We 
choose the labelling so that k1  k2. Then we modify F on the edge e2, making 
F (e2) follow parallel to F (e1) until x and then rejoin its original course at x, so that 
F (e1) and F (e2) never cross. This operation reduces the crossing number of x, and 
so a minimal map F has no such crossings. D 
2. The Szemer edi-Trotter theorem 
Theorem 2.1. Let L be a set of L lines in the plane. Let Pk be the set of points 
that lie on at least k lines of L. Then the number of points in Pk is at most 
max(2 Lk1 , 29L2k3). 
Proof. Using the lines and points, we make a graph mapped into the plane. The 
vertices of our graph G are the points of Pk. We join two vertices with an edge of 
G if the two points are two consecutive points of Pk on a line l  L. This graph is GL)
not embedded, but the crossing number of our map is at most 2 L2, since each 
crossing of the graph G must correspond to an intersection of two lines of L. 
We will count the vertices and edges of the graph G and apply the crossing number 
theorem. The number of vertices of our graph is V = |Pk|. The number of edges 
of our graph is kV L. (At rst sight, each vertex should be adjacent to 2 k edges 
which would give kV edges. But on each line l  L, the rst and last vertices are 
adjacent to one less edge than this initial count.) As long as E  4V , we can apply 
the crossing number theorem and it gives 
L2  (1/64)(kV L)3V 2 . 
Either V  2L/k, or else kV L  (1/2)kV . In the former case, we are done. In 
the latter case, we have L2  29k3V , which means V  29L2k3 . 
LOn the other hand, if E &lt; 4V , we have kV L  4V , and hence V  k4 . As 
long as k  8, this implies V  2L/k, and we are done. Finally, for k &lt; 8, the trivial GL) Gk)
bound |Pk|  2/ 2 2L2k2  29L2k3 . D</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>CROSSING NUMBERS AND THE SZEMER EDI-TROTTER
 
THEOREM
 
In this lecture we study the crossing numbers of graphs and apply the results 
to prove the Szemeredi-Trotter theorem. These ideas follow the paper Crossing 
numbers and hard Erds problems in discrete geometry by L aszl o A Sz ekely (Combin. Probab. Comput. 6 (1997), no. 3, 353-358). 
1. Crossing number estimates 
Proposition 1.1. If G is a planar graph with E edges and V vertices, then E 3V  
0. 
Proof. We can reduce to the case that G is connected. 
Suppose that G is planar and consider an embedding of G intoS
2 . This embedding 
cuts S2 into faces, and we get a polyhedral structure on S2 with V vertices, E edges, 
and some number F of faces. By the Euler formula, V E + F = 2. The number 
of faces cannot easily be read from the graph G, but we can estimate it as follows. 
Each face has at least three edges in its boundary, whereas each edge borders exactly two faces. Therefore F  (2/3)E. Plugging in we get 
2 = V E + F  V (1/3)E. 
Rearranging gives E 3V  6, and were done. D 
Technical details: Why did we assume G connected? Consider a graph homeo
morphic to two circles, embedded in S
2 as two concentric circles. This gives three 
faces - two disks and an annulus. The Euler formula is false for this conguration because annular faces are not allowed. In class, we discussed some other congurations that require thought, like a single edge, and a tree. There is an interesting book by Lakatos that describes of diculty of correctly formulating the hypotheses of the Euler formula. 
If E 3V is positive, then we see that G is not planar, and if E 3V is large then 
we may expect that G has a large crossing number. We prove a simple bound for 
this now. 
Proposition 1.2. The crossing number of G is at least E 3V . 
Proof. Let k(G) be the crossing number of G. Embed G in the plane with k(G) 
crossings. By removing at most k(G) edges, we get a planar graph G
 with E = Ek 
 3V edges and V   V vertices. We see 0  E  E k 3V . D 
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Polynomial Cell Decompositions (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec18/</lecture_pdf_url>
      <lectureno>18</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>2 POLYNOMIAL CELL DECOMPOSITIONS
The planes are exactly the zero sets of degree 1 polynomials (polynomials of the
forma1x1+...+anxn+b). We can generalize this setup by allowing other functions,
such as higher degree polynomials. Suppose that Vis a vector space of functions from
nRtoR. Multiplication by a scalar doesnt change the zero set of a function f, so
might say heuristically that the family of zero sets is given by dimV 1 parameters.
For example, if Vis the polynomials of degree 1, then dimV =n+ 1, and the
dimension of the set of hyperplanes is n. Since we have dimV 1 parameters to play
with, we might hope to bisect dimV 1 sets UinR. This heuristic turns out to
be correct under very mild conditions on the space V.
To state our theorem, we make a little basic notation. For any function f:nR
R, we let Z(f) :={xnR|f(x) = 0}. We say that fbisects a nite volume open
setUif
V oln{xU|f(x)&gt;0}=V oln{xU|f(x)&lt;0}= (1/2)V ol nU.
Theorem 2.2. (General ham sandwich theorem, Stone and Tukey, 1942) Let Vbe
a vector space of continuous functions onnR. Let U1, ..., U NnRbe nite volume
open sets with N &lt; dimV . For any function fV\ {0}, suppose that Z(f)has
Lebesgue measure 0. Then there exists a function fV\ {0}which bisects each set
Ui.
The ham sandwich theorem is one corollary, given by taking Vto be the degree
1 polynomials. If we consider the space of polynomials with degree d, we get the
following corollary.
Corollary 2.3. (Polynomial ham sandwich theorem)
Proof. We let V(d) be the space of polynomials of degree d. We saw in the very
beginning of the course that dimV (d) =/parenleftbigd+n/parenrightbig
. Its also easy to check that for an
non-zero polynomial P,Z(P) has measure 0. We leave this as an exercise. /square
The polynomial ham sandwich theorem is analogous to the more basic polynomial
existence lemma which we have been using throughout the course. We rewrite the
lemma here to make the analogy clear.
Lemma 2.4. (Polynomial existence lemma) If p1, ..., p NnRare points and N &lt;/parenleftbigd+n/parenrightbig
, then there is a non-zero polynomial of degree dthat vanishes at each xi.n
The polynomial existence lemma is analogous to the polynomial ham sandwich
theorem. The rst is based on linear algebra, and the second is based on topology.
The polynomial existence lemma was a basic step in all of our arguments. Using the
polynomial ham sandwich theorem instead gives a new direction to the polynomial
method.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>POLYNOMIAL CELL DECOMPOSITIONS 3
3.On the proof of the ham sandwich theorem
The heuristic argument above using parameter counting is denitely not a proof.
The proof of the ham sandwich theorem is based on the Borsuk-Ulam theorem.
Theorem 3.1. (Borsuk-Ulam) Suppose that :SNNRis a continuous map that
obeys the antipodal condition (x) =(x)for all xSN. Then the image of 
contains 0.
For a proof of the Borsuk-Ulam theorem, the reader can look at Matouseks book
Using the Borsuk-Ulam theorem or in the book Dierential Topology by Guillemin
and Pollack, Chapter 2.6. The book Using the Borsuk-Ulam theorem discusses some
surprising applications of Borsuk-Ulam to combinatorics.
Proof of the general ham sandwich theorem. For each ifrom 1 to N, we dene i:
V\ {0} Rby
i(F) :=V ol({xUi|F(x)&gt;0})V ol({xUi|F(x)&lt;0}).
Soi(F) = 0 if and only if fbisects Ui. Also, iis antipodal, i(F) =i(F).
We will check below that iis a continuous function from V\ {0}toR. We
assemble the NR iinto one function :V\ {0}  .
We know that dimV &gt; N , and without loss of generality we can assume that
dimV =N+ 1. Now we choose an isomorphism of VwithNR+1, and we think of
SNas a subset of V. The map :SNNRis antipodal and continuous. By the
Borsuk-Ulam theorem, there is a function fSNV\ {0}so that (f) = 0. This
function fbisects each Ui. /square
It only remains to check the technical point that iis continuous. This follows
from the next lemma. Its basically an exercise in measure theory.
Continuity Lemma. LetVbe a nite-dimensional vector space of continuous func-
tions onnR. Suppose that for each fV\ {0}, the set Z(f)has measure 0.
IfUis a nite volume open set, then the measure of the set {xU|f(x)&gt;0}
depends continuously on fV\ {0}.
Proof. Suppose that fis a function in V\ {0}andfnV\ {0}withfnFinV.
A priori, fnconverges to fin the topology of V. But then it follows that fnf
pointwise. Pick any  &gt;0. We can nd a subset EUso that fnfuniformly
pointwise on U\E, and m(E)&lt; .
The set {xU|f(x) = 0}has measure zero. Therefore, we can choose so that
the set {xUsuch that |f(x)|&lt; }has measure less than .
Next we choose nlarge enough so that |fn(x)f(x)|&lt; onUE. Then the
measures of {xU|fn(x)&gt;0}and{xU|f(x)&gt;0}dier by at most 2 . But 
was arbitrary. /square</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 POLYNOMIAL CELL DECOMPOSITIONS
4.Ham sandwich for finite sets
We now adapt the ham sandwich theorem to nite sets of points. Instead of open
setsUi, we will have nite sets Si. We say that a polynomial Pbisects a nite set S
if at most half the points in Sare in {P &gt;0}and at most half the points in Sare
in{P &lt;0}. Note that Pmay vanish on some or all of the points of S. We will give
an example below to illustrate why we want this denition.
Corollary 4.1. LetS1, . . ., S Nbe nite sets of points innRwithN &lt;/parenleftbign+d
n/parenrightbig
. Then
there is a non-zero polynomial of degree dthat bisects each set Si.
Let us give an example now. Suppose that we take two sets S1andS2in the
plane, both lying on the x-axis, with S1[0,1] {0}andS2[2,3] {0}. Since
2&lt;/parenleftbig2+1
2/parenrightbig
= 3, we should be able to choose a degree 1 polynomial to bisect both S1
andS2. The only option is to choose the x1-axis : any transverse line will fail to
bisect one of the two sets. Because of this situation, we have to allow pto bisect
a nite set Sin the case that pvanishes on S.
The proof of the theorem is to replace the nite sets by nite unions of -balls,
apply the polynomial ham sandwich theorem, and then take 0. We include the
details here, but this is again just an analysis exercise.
Proof. For each  &gt;0, dene Ui,to be the union of -balls centered at the points
ofSi. By the polynomial ham sandwich theorem we can nd a non-zero polynomial
Pof degree dthat bisects each set Ui,. In fact, the proof of the ham sandwich
theorem tells us that PSNV(d)\ {0}.
Now we can nd a sequence m0 so that pmconverges to a polynomial
PinSNV(d)\ {0}. Since the coecients of Pmconverge to the coecients of
P, its easy to check that Pmconverges to Puniformly on compact sets.
We claim that Pbisects each set Si. We prove the claim by contradiction. Suppose
instead that P &gt;0 on more than half of the points of Si. (The case P &lt;0 is similar.)
LetS+
iSidenote the set of points of Siwhere P &gt;0. By choosing suciently
small, we can assume that P &gt;  on the -ball around each point of S+
i. Also, we can
choose small enough that the -balls around the points of Siare disjoint. Since Pm
converges to puniformly on compact sets, we can nd mlarge enough that Pm&gt;0
on the -ball around each point of S+
i. By making mlarge, we can also arrange that
m&lt; . Therefore, Pm&gt;0 on more than half of Ui,m. This contradiction proves
thatPbisects Si. /square
5.Cell decompositions
Theorem 5.1. IfSis any nite subset ofnRanddis any degree, then there is
a non-zero degree dpolynomial Pso that each component ofnR\Z(P)contains
C(n)|S|dnpoints of S.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>POLYNOMIAL CELL DECOMPOSITIONS 5
Proof. Find a polynomial P0of degree 1 that bisects S. Some points of Slie in
Z(P0). The rest lie in S+andS, which each have  |S|/2 points. The sets S+
andSare in dierent components of the complement of Z(P0). Next we nd a
low degree polynomial P1that bisects S+andS. Neglecting the points in Z(P1)
we have four subsets of Sleft each with  |S|/4 points. These four subsets lie
in dierent components of the complement of Z(P0P1). We continue in this way to
dene polynomials P2,P3, etc. The polynomial Pbisects 2jj sets. By the polynomial
ham sandwich theorem, we can nd Pjwith degree C(n)2j/n. Each component of
the complement of Z(P0...Pj) has  |S|2jpoints.
We repeat Jtimes, and we let P=P0...PJ. Each component of the complement
ofZ(P) has  |S|2Jpoints of S. We need to choose dso that deg(P)d, which
means that C(n)/summationtextJ
j=02j/nd. The sum is a geometric sum, and the last term
is comparable to the whole. Therefore, we can arrange that degP dand also
2J/n/greaterorsimilard. Therefore, 2J/greaterorsimilardn, and each component of the complement of Z(P) has
/lessorsimilar|S|dnpoints of S. /square
We should also give a caveat. The theorem does NOT guarantee that the points
ofSlie in the complement of Z(P). In fact it is possible that SZ(P). There
are two extreme cases. If all the points of Slie in the complement of Z(P), then we
get optimal equidistribution, and we have a good tool to do a divide-and-conquer
argument. If all the points of Slie in Z(P), then we see that deg(S)d, and we
get a good degree bound on S. Generally, Swill have some points in Z(P) and some
points in the complement. One part of Shas a low degree and the other part of S
is spread out well among the cells.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>POLYNOMIAL CELL DECOMPOSITIONS
1.Polynomial cell decompositions
A union of dplanes is a special case of an algebraic surface of degree d. The main
idea in this chapter is to cut space into pieces with a degree dalgebraic surface.
Allowing an arbitrary degree dsurface instead of just dplanes greatly increases our
exibility. (In R3, when we pick dplanes, we have 3 dparameters to play with, but
when we pick a degree dsurface we have (1/6)d3parameters to play with!) With
all this extra exibility, we can do a much better job of decomposing space into evenly
matched cells. On the other hand, if Zis a degree dsurface, then a line either lies in
Zor intersects Zindpoints. Therefore, each line intersects d+ 1 components
of the complement of Z exactly the same bound as if Zwas a union of dplanes.
Theorem 1.1. IfSis any nite subset ofnRanddis any degree, then there is
a non-zero degree dpolynomial Pso that each component ofnR\Z(P)contains
C(n)|S|dnpoints of S.
We will prove this theorem today. The proof is a cousin of nding a degree d
polynomial that vanishes at dnprescribed points, but it uses topology instead of
linear algebra.
2.Ham sandwich theorems
We will build our polynomial cell decomposition using a tool from topology, the
ham sandwich theorem. In this section, we develop the tools that we will use.
Theorem 2.1. (Ham sandwich theorem) If U1, ..., U nare nite volume open sets in
nR, then there is a hyperplane that bisects each set Ui.
This theorem was rst proven by Banach in the late 30s (in the case n= 3).
Then Stone and Tukey generalized the argument to higher dimensions, and they
gave a much more general theorem (see below). We can get a heuristic sense of
the situation by counting parameters. The set of hyperplanes innRis given by n
parameters. Heuristically, we might expect that the subset of hyperplanes that bisect
U1is given by n1 parameters; that the subset of hyperplanes that bisect U1and
U2is given by n2 parameters etc. Another special case happens when each Uiis a
round ball. In that case, the solution is a plane that goes through the center of each
ball. If the centers are in general position, there will be exactly one solution.
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>An Application to Incidence Geometry (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec15/</lecture_pdf_url>
      <lectureno>15</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>APPLICATION TO INCIDENCE THEORY OF LINES IN SPACE
In connection with the distinct distance problem, we encountered the following
question about lines in R3. Given Llines in R3withL1/2lines in any plane, how
many points can there be in PLk( )? Elekes and Sharir conjectured the answer to
this question, and we will eventually prove their conjecture.
Theorem 0.1. IfLis a set of Llines in R3withL1/2lines in any plane, and
3kL1/2, then |P(L)|/lessorsimilarL3/2k k2.
Recall that Pk(L) is the set of points lying in klines of L.
Today, we will prove this result for k= 3. The proof is based on the new techniques
we have developed: degree reduction and special points (critical points and at
points).
Theorem 0.2. (Elekes-Kaplan-Sharir) Suppose Lis a set of Llines in R3withB
lines in any plane. If BL1/2, then |P3(L)| CBL.
Taking B=L1/2, we get the case k= 3 of the conjecture.
As in the proof of the joints theorem, we will try to prove that there is always one
line with not too many points of P3on it.
Lemma 0.3. Suppose Lis a set of Llines in R3withBlines in any plane, with
BL1/2. Then one of the lines contains CBpoints of P3(L).
Given this lemma, the theorem follows by induction on the number of lines.
1.The proof of the main lemma
We will do a proof by contradiction. We let C0be a large constant that we can
choose later. We assume that each line of Lcontains &gt; C0Bpoints of P3.
Step 1. Degree reduction
By the degree reduction theorem, there is a non-zero polynomial Pthat vanishes
on all the lines of Lwith degree /lessorsimilarL(C10B) . By choosing C0suciently large, we
can assume that
d:=degP (1/100)LB1(1/100)L1/2.
We can also assume that Pis square free.
Step 2. The points of P3are special points for P
1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>APPLICATION TO INCIDENCE THEORY OF LINES IN SPACE 5
consider the set of all lines in F2
q. The known proofs all somehow use the topology
ofR2. Theorem 0.1 has very similar diculties.
On the other hand, the case k= 3 of Theorem 0.1 has a nice proof with the
polynomial method. This case seems at least as hard as the joints problem, and no
one knows how to approach it (so far) without the polynomial method.
So the problem combines the diculties of the Szemer edi-Trotter theorem and
the joints theorem. To prove it, we will need to combine some type of topological
argument as in the ST theorem with some type of polynomial argument as in the
joints theorem. Our next main goal in the course is to see how to get these two
methods to cooperate.
2.1.On the tricky induction. Here we describe, for reference, the slightly tricky
inductive argument to get the corollary from the proposition. Actually, to do the
induction we need a slightly more general proposition.
Proposition 2.3. Suppose that 3k10L1/2. Suppose that Lis a set of Llines in
R3withBlines in any plane, with BL1/2. Then one of the lines of Lcontains
/lessorsimilarBk1/2points of Pk.
Proof sketch. Suppose that each line contains Apoints of Pk. IfA105L1/2k1/2,
then we can do degree reduction to t all the lines in Z(P) for Pof degree 
CLA1k1. This degree is (1/100)A and(1/100)L1/2. All the points of Pk
are special points of Z(P). Since A &gt;3degP, all the lines are special lines. Since
degP (1/100)L1/2,Z(P) only has room for &lt;(1/100)L special lines except in the
planes of Z(P). So almost all the lines actually lie in dplanes. One plane must
contain at least (1/ 2)L/d /greaterorsimilarAklines. Therefore,
A/lessorsimilarmin(L1/2k1/2, Bk1)Bk1/2.
Using this proposition and induction, we get the following corollary.
Corollary 2.4. Suppose that Lis a set of Llines in R3withBlines in any plane,
where BL1/2. Suppose that 3kL1/2. Then |Pk|/lessorsimilarLBk3/2.
Proof sketch. Remove the lines one at a time using the last lemma, until we get
down to (1/ 100)k2lines. At this point, we know that |Pk/2|/lessorsimilarkby the counting
bound. At each step, we remove a line that intersects /lessorsimilarLBk1/2points of Pk/2. By
the end, all but kpoint of Pkmust have had k/2 lines removed. So we see
(|Pk(L)| Ck)k/lessorsimilarL(Bk1/2).
Hence |Pk(L)|/lessorsimilarLBk3/2.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>APPLICATION TO INCIDENCE THEORY OF LINES IN SPACE 3
Lemma 1.1. Suppose that lZ(P)is a special line, i.e. SP= 0onl. Then either
llies in Z(Pj)for two dierent j, or else lis a special line of Z(Pj)for some j.
(We note that if llies in Z(Pj) for two dierent j, then P= 0 on l, solis a
special line.)
Proof. Letlbe a special line of Z(P). Suppose that llies in Z(Pj1) but ldoes not
lie in any other Z(Pj). We have to show that lis a special line of Z(Pj1). First,
suppose that lis a critical line of Z(P) - in other words, P= 0 on l. We expand
Pusing the Liebniz formula:
P=/summationdisplay
(P j0)/productdisplay
Pj.
j0 j=j0
Along the line l,Pj1= 0, and so the sum simplies to (P j1)/producttext
j=j1Pj. At all but
nitely many points of l, the product does not vanish, and so Pj1must vanish. By
the vanishing lemma, Pj1= 0 on l.
Next, suppose that lis not a critical line and is a at line. For almost every point
xL,Z(P) is a smooth manifold near xandZ(P) is at at x. But for almost every
point xinl,Z(P) =Z(Pj1) in a small neighborhood of x. SoZ(Pj1) is at at almost
every point xl. Therefore, SPj1(x) = 0 for almost every xl. By the vanishing
lemma, SPj1= 0 on l. /square
Now we count the number of special lines of various types, using the Bezout theo-
rem. The number of lines that lie in at least two Z(Pj) is/summationtext
j1,j2(degP j1)(degP j2)
d2104L.
IfPjis not a linear polynomial, then we proved last time that the number of
special lines in Z(Pj) is3(degP j)2. Therefore, the number of special lines in Z(Pj)
for all the PwithdegP 2 is3/summationtext(degP )23d23104j j j j L.
Therefore, at least (99/ 100)L lines of Lmust lie in the planes 1, ...,  T, with
Td(1/100)L/B . By the pigeon hole principle, one of the planes contains at
least 99 Blines of L. But we assumed that each plane contains Blines of L. This
contradiction proves the lemma.
2.What happens for large k?
We will eventually prove the following theorem.
IfLis a set of Llines in R3withL1/2lines in any plane and if 3kL1/2,
then|Pk(L)|/lessorsimilarL3/2k2.
Suppose that Lis a set of Llines in/R3withL1 2lines in any plane. We would
like to show that one of the lines contains L1/2k1points of Pk(L). (For heuristic
purposes, suppose that each line had L1/2k1points of Pk. Then we would have/negationslash
/negationslash</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 APPLICATION TO INCIDENCE THEORY OF LINES IN SPACE
Recall that a point xZ(P) is called special if it is either critical or at. Special
points can be detected by polynomials. Last lecture, we dened a vector of poly-
nomials SP(x) so that xis special if and only if P(x) = 0 and SP(x) = 0. Each
component of SP(x) has degree 3d4, and there are nine components.
We claim that each point of P3is either critical or at. Let xP3. By denition,
xlies in (at least) three lines of L. Pick three lines l1, l2, l3containing x. We know
thatP= 0 on these three lines. If the three lines are not coplanar, then we saw in
our study of joints that xis a critical point of P. The reason is that viP(x) = 0
where viare the tangent directions to the three lines. Since these directions form a
basis of R3,P(x) = 0. Suppose now that xis not a critical point of P. In this
case, we will prove that xis a at point of Z(P).
We see that the lines l1, l2, l3must lie in a plane. We still have viP(x) = 0 for each
i, and so the lines limust all lie in the tangent plane to Z(P) atx. Next we perform
a translation and rotation so that xis moved to 0 and Z(P) is locally described as
a graph
x3=f(x1, x2) =Q(x1, x2) +O(|x1|+|x2|)3, Qhomogeneous of degree 2.
 The translation and rotation moves the lines lito lines liwhich contain 0 and lie in
the plane x3= 0. Since these lines lie in the image of Z(P), we see that fvanishes
on them. Therefore, Qmust vanish on them. So we see that the quadratic form
Qvanishes on three lines through 0 in R2. Now by the vanishing lemma, Qmust
also vanish on any line that passes through the three lines at distinct points, and it
quickly follows that Q= 0. This means that the point xis at.
Each point of P3is either critical or at, and so SP(x) = 0 for each xP3.
Step 3. The lines of Lare special lines for P
Each line of Lcontains C B L1/20 points of P3. On the other hand, the
polynomial Phas degree (1/100)L1/2. The polynomials in SPhave degree 
3d4(3/100)L1/2. Each polynomial SPvanishes at L1/2points on each line
ofL. Therefore, SP= 0 on each line of L.
Step 4. Almost all the lines of Lmust lie in planes of Z(P)
Suppose that P=/producttext
jPjwithPjirreducible. Some of the Pjmay be linear, and
each linear factor corresponds to a plane in Z(P). Let 1, ...,  Tbe all the planes in
Z(P), with Td(1/100)L1/2. Next we consider how special lines of Z(P) relate
to special lines of the Z(Pj).</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 APPLICATION TO INCIDENCE THEORY OF LINES IN SPACE
L3/2k1incidences between LandPk. But each point of Pklies on klines, so we
would have L3/2k2points of Pk.)
Let us suppose that each line contains Apoints of Pk. For which values of A
can we hope to run the argument above? In order for the argument to work, its
crucial to be able to do degree reduction. Let us do a heuristic calculation of how
bigAneeds to be to do degree reduction.
Letdbe a degree that we can pick later. We nd a non-zero polynomial Pof
degree dthat vanishes on (1/ 10)d2random lines of L. Let lbe another line of
L. We want to estimate the number of points where this line intersects the random
lines above. The line lcontains Apoints of Pk. Each of these points lies in k
lines of L, and so lintersects Aklines of L. Each line of Lhas a probability
d2/Lof being chosen in the list of random lines. Therefore, the number of lines of
Lwhich intersect lis typically Akd2/L. If this number is &lt; A, then the number of
distinct intersection points is typically of the same order of magnitude. The number
of intersection points is capped at A, so we have
E|{xl|xthed2random lines }|/greaterorsimilarmin(Akd2L1, A).
We can do degree reduction only if this expected number is &gt; d. So to do degree
reduction we need Akd2L1&gt; dandA &gt; d . The rst inequality is equivalent to
d &gt; LA1k1. So to do degree reduction, we need A &gt; d &gt; LA1k1and hence
A &gt; L1/2k1/2. IfAis, say, 105L1/2k1/2, then we can do degree reduction down to
degree dLA1k1. The rest of the argument above works. Filling in the details,
it is possible to prove the following fairly weak estimate:
Proposition 2.1. Suppose that Lis a set of Llines in/R3withL1 2lines in any
plane. Suppose 3kL1/2. Then one of the lines contains /lessorsimilarL1/2k1/2points of
Pk.
Then, by a somewhat tricky induction argument we get
Corollary 2.2. Suppose that Lis a set of Llines in R3withL1/2lines in any
plane. Suppose 3kL1/2. Then |Pk|/lessorsimilarL3/2k3/2.
This estimate is signicantly weaker than the theorem we will eventually prove.
What is the source of our diculties, and why are we getting stuck at this point?
Its interesting to consider the example of lines in nite elds. Let Lbe the set
of all the lines in F3
q. The total number of lines is Lq4. The number of lines
in any plane is q2L1/2. Each point ofqFlies in kq2lines. Therefore
|Pk(L)|=q3L3/2k3/2.
This situation is similar to the Szemer edi-Trotter theorem. The Szemer edi-Trotter
theorem is true for lines in R2. But its false over nite elds, in particular if we</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>The Joints Problem (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec4/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>THE JOINTS PROBLEM
 
Suppose that we have a set of lines in R3 . A joint of the set of lines is a point 
which lies in three non-coplanar lines. The joints problem asks what is the maximal 
number of joints that can be formed from L lines. 
Lets look at some examples. 
1. A grid. An S  S  S grid of lines contains 3S2 = L lines and contains S3 
joints. So the number of joints is  L3/2 . 
2a. A tetrahedron. Six lines arranged as the edges of a tetrahedron produce four 
joints. This example generalizes as follows. 
2b. Take S planes in R3 in general position. Any two of the planes intersect in (S)
a line, giving L = 2lines. Any three of the planes intersect in a point, and each (S)
such point is a joint for this set of lines. Therefore, these lines determine 3joints. 
We again have that the number of joints is  L3/2, but the constant is better than 
in 1. These are the best known arrangements of lines in the joints problem. 
Next we look at upper bounds. Since any two lines intersect in  1 point, there ( ) ( )
are  L 
2intersection points, and so  L 
2joints. A joint involves not just two lines, 
but three lines. We remark that looking at triple intersections (intersections of three lines) is not very dierent from just intersections. Its possible to arrange L lines in 
a plane to give  L
2 triple intersections. Start with an evenly spaced grid of vertical 
and horizontal lines, and then add diagonal lines to make the triple intersections. But this example does not give any joints, because all the lines are coplanar. 
The joints problem was posed in the early 90s by B Chazelle, H Edelsbrunner, 
L.J Guibas, R Pollack, R Seidel, M Sharir, and J Snoeyink, in the paper Counting 
and cutting cycles of lines and rods in space (Comput. Geom. Theory Appls., 1 
L
7/4(1992), pp. 305323). They proved that the number of joints from L lines is ; , 
and the exponent has gradually improved. We will explain some of the ideas from that rst paper later. We mention that its not easy to prove that the number of joints is ;L
1.99 . 
With the polynomial method, we now have a rather sharp bound for the joints 
problem. 
Theorem 0.1. Any L lines in space determine  10L3/2 joints. 
Main Lemma. If a set of lines has J joints, then one of the lines contains  3J1/3 
joints. 
1</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 THE JOINTS PROBLEM 
The main lemma implies the theorem by removing the lines one at a time. We 
start with L lines and J joints. By cutting out one line, we reduce the number of 
joints by  3J1/3 . We look at the remaining lines L  1 lines, which contain  J 
joints. One of the lines has  3J1/3 joints on it. Removing this line, we reduce the 
number of joints by  3J1/3 . We remove all L lines, one at a time. Each time the 
number of joints decreases by  3J1/3, and we end up with no joints. Therefore, 
J  L(3J1/3). Rearranging we get J2/3  3L, which implies the theorem. 
Now we turn to the proof of the main lemma. 
Proof. Let P be a lowest degree non-zero polynomial that vanishes at every joint. 
The degree of P is  3J1/3 by dimension counting, as in Lecture 1. If every line has 
&gt; 3J1/3 joints, then P must vanish on every line. 
Lemma 0.2. If x is a joint lying in three (non-coplanar) lines, and if a smooth 
function F : R3  R vanishes on the lines, then F vanishes at x. 
Proof. Let v1, v2, v3 be tangent vectors for the three lines. The directional derivative 
of F in the direction vi must vanish at x. So we have F (x) vi = 0 for each i. Since 
the vi are a basis of R3, we have F (x) = 0. D 
So we see that the derivates of P vanish at each joint. The derivates have smaller 
degree than P . Since P was a minimal degree non-zero polynomial that vanishes 
at each joint, the derivatives of P are all the zero polynomial! Then P must be 
constant, and we get a contradiction. D 
For example, suppose that we start with an ABC grid of lines with A &lt; B &lt; C . 
The number of lines is AB +AC +BC, and the number of joints is ABC. All of the 
joints are contained in a union of A parallel planes. Therefore, there is a polynomial 
of degree A which vanishes on all the joints (the polynomial is a product of linear 
factors). This polynomial actually has minimal degree: its an exercise to check that 
a polynomial of degree  A 1 which vanishes on all the joints of this conguration 
must be the zero polynomial. The minimal polynomial vanishes on all the lines with B joints and all the lines with C joints, but on none of the lines with A joints. So we 
see that the minimal polynomial identies the important and less important lines, and locates at least one inessential line with not too many joints on it.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Introduction to Thue&#8217;s Theorem on Diophantine Approximation (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec25/</lecture_pdf_url>
      <lectureno>25</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>4 INTRODUCTION TO DIOPHANTINE EQUATIONS
The diophantine approximation theorem implies the diophantine equations theo-
rem for the following reason. ...
3.Outline of Thues proof
In this section we outline Thues proof, and we explain how it is analogous to
other arguments we have seen. We recall the main steps in the polynomial method
by outlining the proof of the nite eld Nikodym theorem.
Outline of the proof of nite eld Nikodym: Suppose that Nis a small Nikodym
set innF.
(1) Find a non-zero polynomial Pwith controlled degree that vanishes on N.
(Use parameter counting.)
(2) Because Nis a Nikodym set, the polynomial Pmust also vanish at many
other points. (Vanishing lemma.)
(3) The polynomial Pvanishes at too many points, so it must be zero. Contra-
diction.
Here is the outline of Thues proof. Suppose that the algebraic number has two
very good rational approximations r1andr2.
(1) Find a non-zero polynomial PZ[x, y] with controlled degree and coecients
that vanishes to high order at (,  ). (Use parameter counting.)
(2) Because r1andr2are good approximations of , the polynomial must also
vanish to high order at ( r1, r2).
(3) The polynomial Pvanishes too much at ( r1, r2), and so it must be zero.
Contradiction.
The rst step took Thue the longest to gure out. In the special case that is the
dthroot of a rational number, he constructed the polynomial Pby hand with some
diculty. In this way, we was able to prove his niteness theorem only for equations
of the form Axd+Byd=C. After trying hard to construct the polynomial Pfor
other values of , Thue realized that he could nd it by parameter counting.
Another important point about Thues proof is that it uses two good rational
approximations r1andr2. It might seem simpler to start with one rational approx-
imation rand try to get a contradiction. But it seems very dicult to do this. We
will come back to this point more later.
3.1.Final comment. Suppose that andare two algebraic numbers. Then +
is an algebraic number. Why? This is a bit in the same spirit as the polynomial
method...</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>INTRODUCTION TO DIOPHANTINE EQUATIONS
In the early 20th century, Thue made an important breakthrough in the study
of diophantine equations. His proof is one of the rst examples of the polynomial
method. His proof inuenced a lot of later work in number theory, including dio-
phantine equations, transcendental number theory, and later exponential sums. In
this lecture, we will introduce some basic questions and conjectures and explain what
Thue proved.
1.Naive guesses about diophantine equations
The most famous diophantine equation is the Fermat equation xd+ydzd= 0.
Ford= 2 there are many integer solutions, and for d3 there are no positive
integer solutions. The proof of the second part is extremely deep and hard. But is
there any simple reason to expect that this situation is likely? In this section, we
explore some naive guesses about diophantine equations.
Suppose that Pis a homogeneous polynomial of degree dinnvariables, with
integer coecients. Let us consider the equation P(x) =A, for some integer A.
Lets try to guess how many solutions this equation is likely to have. Lets try to
guess the number of solutions of size |x| 2s.
Guess the size of the set {xn|P(x) =A,|x| 2sZ }.
Notice that if |x| 2s, then |P(x)|/lessorsimilar2sd. Its hard to say much else about P(x)
based on the information so far, so we make a primitive probabilistic model.
For each x  with |x| 2s, letP(x) be a random integer of norm 2sd. The
 expected size of the set {xnZ|P(x) =A,|x| 2s}is2ns/2ds= 2(nd)s. If the
polynomial Pbehaved randomly, then the set of solutions of size |x| 2swould
be2(nd)s. This suggests the following naive conjectures.
Naive conjecture 1. IfdegP &lt; n , then the equation P(x) =Ahas innitely many
integer solutions, and the number of solutions of size 2sis2(nd)s.
Naive conjecture 2. IfdegP &gt; n , then the equation P(x) =Ahas only nitely
many integer solutions.
(The case degP =nis more delicate. Our heuristic gives that the number of
solutions of size 2sis1, which would suggest innitely many solutions. But
having no solutions would not be such a large departure from the estimate in the
heuristic...)
1</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 INTRODUCTION TO DIOPHANTINE EQUATIONS
These conjectures are both false, but they are still useful.
We give some counterexamples.
Consider the equation 2x + 2y= 1. Our model predicts it should have many
solutions, but it has none because the left-hand side is always even. Therefore, naive
conjecture 1 is false. (To x this particular counterexample, we should also assume
that the equation has lots of solutions modulo pfor some small primes p.)
Consider the equation ( x2+y2z2)10= 0. This equation has degree 20 in 3
variables, but every Pythagorean triple is a solution. There are also examples in two
variables. The equation ( xy)10= 1 has innitely many solutions. The equation
x22y2= 1 has innitely many solutions (approximately one for each scale |x| 2s,
as predicted by the heuristic). Therefore, the equation ( x22y2)10= 1 has innitely
many solutions. (We can rule out these particular counterexamples by insisting that
Pis irreducible.)
Although the conjectures are false, they give some useful intuition. If the degree
d &gt; n and there are innitely many solutions, then that seems to be a big coincidence,
and one may hope that there is some structure that explains what is happening.
Two of the big achievements in diophantine equations from the early 1900s conrm
this intuition. The circle method of Hardy-Littlewood proves that equations have lots
of solutions if the number of variables is much larger than the degree and if nothing
bad happens modulo pfor small primes p. Thue proved that Naive Conjecture 2 is
actually true in two variables, as long as the polynomial is irreducible.
Theorem 1.1. (Thue) Suppose PZ[x, y]is a homogeneous polynomial with degree
3which is irreducible (over Z). IfAis any integer, then the equation P(x) =A
has only nitely many integer solutions.
2.Diophantine approximation
Thue actually proved an even stronger theorem about rational approximations of
algebraic numbers. To see the connection, let us consider the equation x32y3= 7.
If (x, y)2Zsolves this equation, then we see that
x()32 = 7y3.y
Therefore, x/yis a good approximation of the cube root of 2, especially if yis
large. A short calculation shows that
|21/3x |/lessorsimilar|y|3.y
These are really very good rational approximations. For context, consider the
following.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>INTRODUCTION TO DIOPHANTINE EQUATIONS 3
Proposition 2.1. For any  &gt;0, for almost every real number , there are only
nitely many integer solutions to the inequality
x| |  | y|2. ()y
(The proof is a standard exercise in measure theory. Consider all the in an
interval so that ( ) has a solution with y &gt; Y . This set is a union of intervals of
total length /lessorsimilarY.)
Although its easy to prove this result for almost every R, its hard to check it
for any particular , say= 21/3. Liouville gave the rst estimates about diophan-
tine approximation of algebraic numbers.
Proposition 2.2. (Liouville, 1840s?) If is an irrational algebraic number andx
y
is a rational number, then
x| |  c()|y|deg().y
Recall that an algebraic number is a solution to a polynomial with integer coe-
cients. The degree degis the minimal degree of such a polynomial.
We will use a couple basic facts about algebraic numbers. There is actually a
unique minimal polynomial QwithQ() = 0. (Minimal here means that the degree
and the size of the coecients are minimal.) The polynomial Qwill be irreducible
overZ, and so it will have no rational roots. This polynomial also has Q() = 0.
Proof. Notice that Q(x/y) is a non-zero rational number. The denominator can be
taken to be ydeg(). Therefore, |Q(x/y)|  |y|deg(). Ifx/yis very close to , then
|Q(x/y)|=|Q() +Q()(x/y)|+ lower order terms  |Q()||x/y|.
/square
For example, |21/3x| c|y|3. This inequality is not strong enough to sayy
anything about the number of solutions of x32y3= 7. If we look back inside
the proof of the Liouville inequality, it boils down to saying that x32y3= 0
has no integer solutions and so |x32y3| 1. But this does nothing to constrain
the solutions of x32y3= 7. However, an inequality even slightly stronger than
Liouvilles does constrain the solutions to diophantine equations.
Theorem 2.3. (Thue) If is an irrational algebraic number, and  &gt;deg()+2, then2
there are only nitely many integer solutions to the inequality
x| |  | y|.y/ne}ationslash</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Crossing Numbers and Distance Problems (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec8/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>2Look at parabolas of the form y = x+ ax + b, let a run from 1 to s, let b run from 1 to 
2s. Look at the grid of points in the plane [1, 2, ..., s]  [1, 2, ..., 3s2], this gives us 3s3 points. 
Each of the parabolas dened above has s points on it, since plugging in any value of x from 
2 41 to s gives a value of y from 1 to 3s. Thus, this example would give us at least s= cN4/3 
unit distances, or incidences between unit parabolas and points. 
Denition 2. Given a set L of curves in the plane and another set S of points, we dene 
the set of incidences I(S, L) = {(x, l)  S  L : x  l. 
If we could obtain a similar example for unit circles, then we could add the set of centers 
of circles, and obtain a counterexample. In fact, for dierent norms, we can obtain such a 
set in a similar way. 
3 Crossing numbers for multigraphs 
Let us return to the distinct distance problem, and the problem of crossing numbers for 
multigraphs. 
What is the crossing number of KM , that is, K5 with each edge drawn M times?5 
We can easily embed it into the plain to get M2 crossings: embed K5 such that it has 
one crossing, and draw each edge M times. Can we do better? 
Suppose we have an embedding of KM with K(KM ) crossings. Take a random subgraph 5 5 
G ' , where we randomly choose each edge from the M parallel edges. In the induced embedding 
on the subgraph, each crossing occurs with probability 1/M2, since it occurs if and only if 
both edges are in G ' . Thus, the expected value of the number of crossings is 1/M2K(KM ),5 
and so 
1  E(K(G ' ))  K(KM )/M2 
5 
We can generalize this idea to obtain the following lemma, that gives a better bound than 
the proposition from earlier: 
Lemma 1. Let G be a multigraph with multiplicity at most M. Assume E  4MV , and 
each edge has multiplicity greater than M/2. Then K(G)  1/256E3V 2M1 . 
So we can see that although the constant is a bit worse, we have M1 instead of M3 . 
Proof. Take a random G '  G subgraph, where we randomly choose one edge from each set of 
parallel edges. Since each set has at least M/2 edges, each crossing remains with probability 
at most M2/4. Since the multiplicity is at most M, E '  1/ME  4V . Thus, we can write 
4/M2K(G)  E(K(G ' ))  1/64(E ' )3V 2  E3V 2M3 
Using this lemma, we can prove the following proposition (where we get rid of the lower 
bound on edge multiplicities): 
Proposition 2. If G is a multigraph with multiplicity at most M, and E  100MV , then 
K(G)  cE3V 2M1 for some c. 
Proof. Let G '  G consist of all edges that have multiplicity at least M/2. 
If E '  1/10E  10MV , then, using the lemma, 
K(G)  K(G ' )  1/256E '3V 2M1)  cE3V 2M1 
3</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>If E ' &lt; 1/10E , then take G1 to be the edges not in G, and use induction on G1, with M/2 
(this contains at least 9/10 of the edges, and the multiplicity is halved, so the E  100MV 
condition is satised). So we have E1  9/10E , and so 
K(G)  K(G1)  cE13V 2(M/2)1  (9/10)32cE3V 2M 1  cE3V 2M1 
4</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>The distinct distance problem and the unit distance
 
problem
 
During this lecture, we examine the distinct distance problem and the unit distance 
problem. We would like to apply the following theorem about crossing numbers, proven last 
time: 
Theorem 1. If G is a graph with E edges and V vertices, and E  4V , then the crossing 
number K(G) of G is at least (1/64)E3V 2 . 
1 Distinct distance problem 
Suppose we have a set S of N points in the plane, and amongst them we have t distinct 
distances, t &lt; N . How small can t be? 
Let T be the set of distances that arise between two points. We can draw Nt circles: 
for each point p  S and each distance d  T , we draw a circle with center p and radius 
d. We construct a graph G: the vertices will be the points of S, and the edges will be 
the arcs of circles between consecutive points. What is the crossing number of the graph? 
We know that any two circles intersect in at most two points. So we have the inequality t tNt K(G)  2  (Nt)2 . On the other hand, we know that the graph has N points. Each 2 
point is contained in N  1 circles, since all distances that arise between points is contained 
in T , so each point has degree 2(N  1). So, there are N(N  1) edges. So, we have the 
following inequality: 
N2t2  K(G)  1/64E3V 2 = 1/64N3(N  1)3N2  1/100N4 
This gives t  1/10N . 
This proof, however, is incorrect. When we proved the theorem for crossing numbers, we 
assumed that the graph was simple, however, the graph can have both multiple edges and 
loops: If a circle has a single point, that point will have a loop around it, and if there are 
two points P, Q, and many other points on their perpendicular bisector, then P, Q will have 
many circles going through them, and if there are no interior points on the arcs, there can 
be many edges between P and Q. 
Could the crossing numbers theorem work for graphs that are not simple? In the proof, 
we used the fact that 3F  2E. However, this is only true because each face has at least 
three incident edges. If we allow multiple edges, this is not necessarily the case. So our proof 
from last time does not work. 
In fact, if we have a planar graph, we can take an edge, and draw as many parallel edges 
as we want, without obtaining any new crossing. So the theorem is false for non-simple 
graphs, and the proof above in this form fails. 
Can we try to obtain some sort of theorem on crossing numbers for graphs with multiple 
edges? Obviously not for general non-simple graphs, but perhaps with some conditions, we 
can. 
1</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Denition 1. We will use the term multigraph to refer to a graph that can have multiple 
edges, but no loops. For a multigraph G, dene Mult(G) as the highest number of parallel 
edges between two points, so Mult(G)  M implies that no two points have more than M 
edges between them. 
Proposition 1. If Mult(G)  M, and E  4MV , then K(G)  1/64E3V 2M3 . 
Proof. Take G'  G to be the graph where we replace any parallel edges by one edge. 
If this graph has E' edges and V ' vertices, then V ' = V , and E'  1/ME . Obviously, 
K(G')  K(G), so we have 
K(G')  K(G)  1/64E'3V '2  1/64E3V 2M3 
From this, we can deduce the folloming: 
Theorem 2. If we have N points in the plane, no 100 of which are on a common line, then 
the number of distinct distances is at least cN, where c is a constant. 
Proof. Take the multigraph that is the graph we dened earlier, with the circles that have 
only one point on them omitted (since these would be loops). By removing these circles, 
we removed at most Nt edges, so if t  N/2, then there are still at least 1/2N2 edges. 
(Otherwise we are done.) Since there are less than 100 points on any line, we can have at 
most 200 edges between any two points. Thus, using the previous proposition, we obtain the 
desired result. 
2 Unit distance problem 
Last time, we constructed an example by taking a square n  n grid of the right size, a set 
of N points with U(N) unit distances, where (N)  U(N)  O(N1+E) for any epsilon. 
Using Proposition 1, we can deduce the following theorem: 
Theorem 3. A set S of N points in the plane determine at most U  O(N4/3) unit distances. 
Proof. Draw all the unit circles that have centers in S, and contain at least two points of 
S, and take the multigraph as before: the points are S, and the edges are arcs along circles. 
Assume U  10N (otherwise we are done). If we rst draw those unit circles that have at 
least one point on them, not just those with at least two, then we obtain a graph with at least 
2U edges: given a pair of points P, Q that are a unit distance apart, look at the circle with 
center P . This goes through Q, and we can assign to this unit distance the arc of the circle 
with center P that is to the left of Q (looking at it from P ), and vice versa. Thus, we have 
two edges for each unit distance. Now, if we delete those circles that have one point on them, 
we delete at most N circles, so we still have at least U edges. This graph has multiplicity at 
most 4: given any two points, there can be at most two unit circles that go through both of 
them, and each unit circle gives us at most two edges between them. Since any two circles 
intersect in at most two points, we can write 2N2  K(G)  cE3V 2  c'U3N2, which 
gives U  O(N4/3) as required. 
This result is almost 30 years old, published by Spencer, Szemer edi, and Trotter in 1984. 
This is the best known upper bound, to this day. One reason it is hard to improve is that 
it is hard to distinguish unit circles from unit parabolas. In that case, however, we have the 
following example: 
2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Thue&#8217;s Proof (Part I) (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec26/</lecture_pdf_url>
      <lectureno>26</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>4 PROOF OF THUES THEOREM  PART I
Suppose we are looking for a polynomial Pof degree Dsuch that jP(r) = 0 for
j= 0,1, . . .,  1. Let
D
P=/summationdisplay
aixi
i=0
We have
D D
jP(x) =/summationdisplay i! iaj
i xij=j!a xi
i .(ij)!/summationdisplay/parenleftbigg
ji=0 i=0/parenrightbigg
(Extracting out the j! factor in the last step is a useful trick of the trade that makes
it easier to bound the coecients.) Setting jP(r) = 0, we have
D/summationdisplay/parenleftbiggia/parenrightbigg
qD(ij)
i pij= 0.ji=0
The coecients of the ais are all bounded in absolute value by 2D/bardblr/bardblD. Viewing
(aD0, . . ., a D)Z+1as our unknowns, it follows from Proposition 2.2 that we can
nd a polynomial Pof degree DwithjP(r) = 0 for j= 0,1, . . .,  1 such that
|P| (2D/bardblr/bardblD)/(D) /bardblr/bardblD/(D).
So we could take, for example, D= 100 to get |P|  /bardblr/bardbl1.01. For comparison, the
optimal example (qx p)hasD=and|P|  /bardblr/bardbl.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>PROOF OF THUES THEOREM  PART I
In this lecture well do the rst half of the proof of Thues theorem.
Suppose that Pis a polynomial with integer coecients. Let rbe a rational point.
We would like to understand the relationship between Pvanishing to high order at
rand the size of Pin terms of its degree and size of its coecients. Dene |P|to
be the maximum absolute value of the coecients of P.
1.Polynomials vanishing to high order at a rational point
Let us start with the simple case where Pis a one-variable polynomial. Let
r=p/q, written in lowest form. We suppose that Pvanishes to orders at r, i.e.,
jP(r) = 0, j= 0,1, . . .,  1.
Here is the rst example of such a polynomial that comes to mind.
Example 1: P(x) = (qx p). Then |P|  /bardblr/bardbl, where /bardblr/bardbl:= max(| p|,|q|).
Could we do better? In other words, can we nd a polynomial Pwith smaller
coecients, i.e., |P|smaller? As we shall see, the answer is no.
Proposition 1.1 (Gauss). IfPZ[x]satises jP(r) = 0 forj= 0,1, . . .,  1,
thenP(x) = (qx p)P1(x)for some P1Z[x].
Proof. The vanishing condition tells us that P(x) = (qx p)P2(x) for some poly-
nomial P2R[x]. It remains to show that the coecients of P2are integers. By
expanding and comparing coecients, we see that we can solve for the coecients
ofP2in terms of the coecients of P, and we deduce that the coecients of P2are
at least rational.
 Taking out the lowest common demoninator, we write P(x) =1(qxp)P2(x),M for some P2Z[x  ] so that there is no prime dividing all the coecients of P2as well
 asM. SoMP(x) = (qx p)P2(x). IfM=1, then let sbe any prime divisor of
M. Then we get a contradiction modulo s, since qxpis not 0 mod sasp/qwas
 already given in lowest terms, and P2is also not 0 mod s. It follows that M=1
and hence P1Z[x]. /square
Were not quite done yet, as its not always true that the norm of a polynomial is
always at least as large as its factors.
Example 2: The polynomial ( x1)2=x22x+1 has norm 2, while (x 1)2(x+1) =
x3x2x+ 1 has norm 1, which is smaller.
1/ne}ationslash</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 PROOF OF THUES THEOREM  PART I
Fortunately, this example does not really pose an issue. The follow corollary
answers our question for one variable polynomials.
Corollary 1.2. |P|  /bardblr/bardbl.
Proof. InP(x) = (qx p)P1(x), we see that qdivides the top coecient and p
divides the bottom non-zero coecient. /square
Now, what about polynomials in two variables? Let PZ[x1, x2], and r=
(r1, r2) = (p /q21 1, p2/q2)Q. We want to assume that Pvanishes to high order at
r. Lets say jP(r) = 0 for all jJ, where Jis some list of pairs, e.g., all j= (j 1, j2)
with|j|:=j1+j21.
Dene /bardblr/bardbl:= max(/bardbl r1/bardbl,/bardblr2/bardbl). If /bardblr/bardblis large, does P(r) = 0 imply something
about the norm of P(as in the single variable case)? The following examples show
that the answer is no.
Example 3: P(x1, x2) =x1x2andr= (r 1, r1). Then P(r) = 0 but |P|= 1.
What if we assume Pvanishes at rto high order? Say jP(r) = 0 for all jwith
|j| 1? Still the answer is no.
Example 4: P(x1, x2) = (x 1x2)andr= (r 1, r1). Then jP(r) = 0 for all jwith
|j| 1, but |P| 2, independent of /bardblr/bardbl.
These examples suggest that perhaps our notion of vanishing to high order at
a point isnt very useful. It prompts us to modify the question. Let us consider
polynomials of the form
P(x1, x2) =P1(x1)x2+P0(x1).
Suppose we have
j
1P(r) = 0, j= 0,1, . . .,  1.
In this case, can we infer something about the size of Pfrom the size of r?
Since we are only dierentiating with respect to x1, this condition is equivalent to
j[p2P1+q2P0](r) = 0, j= 0,1, . . .,  1.
It follows by Corollary 1.2 that /bardblp2P1+q2P0/bardbl  /bardblr1/bardbl. We see that /bardblp2P1+q2P0/bardbl 
/bardblp2P1/bardbl+/bardblq2P0/bardbl 2/bardblr2/bardbl|P|. It follows that |P| 1/bardblr1/bardbl
2/bardblr2./bardbl
Let us look at some examples of polynomials that satisfy the above vanishing
conditions.
Example 5: Let P=q2x2p2. Then |P|=/bardblr2/bardblandj
1P(r) = 0 for all j.
Example 6: Let P= (q 2x2p1) . Then |P|  /bardblr1/bardbl.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>PROOF OF THUES THEOREM  PART I 3
2.Integer solutions to linear systems
So far weve been looking at explicit examples of polynomials that satisfy the
vanishing to high order condition. This is somewhat reminiscent of the rst lecture
in the course where we wanted to know how big the degree of a polynomial Pmust
be ifP(j,2j) = 0 for j= 1,2, . . .,106. There we also started by nding explicit
examples, but at the end we arrived at our bound by counting dimensions. In a
similar vein, we are going to nd polynomials in Z[x1, x2] by parameter counting.
Proposition 2.1. IfL:ZMZNis a linear map, given by a matrix with integer
coecients, with M &gt; N , then there exists a nonzero xZMsuch that Lx= 0.
For real vector spaces, this result follows from elementary results from linear alge-
bra. For integers, its actually even more elementary  its just pigeonhole principle.
Lets quickly sketch a proof rst. Afterwards well be more careful quantitative
bounds.
Proof. (Sketch) Let QM
S:={xZM:|xi| S, i= 1, . . ., M }. Since the map L
restricted to QM
SQN
CSwhere C=C(L) is some suciently large constant. We
have|QM
S| SMand|QNC S| CN S. So we can choose Sso that |QM
S|&gt;|QN
CS|.
Then by pigeonhole, there are x=xQM1 2 Ssuch that L(x1) =L(x2), so that
L(x1x2) = 0. /square
How big is the xproduced by the proof? Let us look for some quantitative bounds.
We can take C=|L|op:= max |x|=1,xRM|Lx|by the operator norm of L. In
particular, |L|opMmax|coe of L|. We need to take Sso that (2S + 1)M&gt;
(2|L|opS+1)N.It suces to have (2 S+1)M&gt;|L|op(2S+1)N, or equivalently 2S +1&gt;
M/(MN)|L|op . It follows that we can always nd a nonzero xZMwithLx= 0 and
N/(MN)|x| |L|op . So we can revise the proposition to a more quantitative version.
Proposition 2.2. IfL:ZMZNis a linear map, given by a matrix with integer
N/(MN)coecients, with M &gt; N , then there exists a nonzero xZMwith|x| |L|op
such that Lx= 0.
Note that if M=N+ 1, then our bound is |L|N
opwhich is not too great, where as
ifM= 1.01Nthen our bound is |L|100
opwhich is pretty good.
Lets go back to the one-variable polynomial case for a moment. Recall that we
already know that ( pxq)is the optimal polynomial vanishing to -th order at
r=p/q. Nevertheless, let us try this counting machinery here and see how well it
does in comparison./ne}ationslash</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Incidence Bounds in Three Dimensions (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec20/</lecture_pdf_url>
      <lectureno>20</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Background on Connections Between Analysis and Combinatorics (Loomis-Whitney) (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec29/</lecture_pdf_url>
      <lectureno>29</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>2 HOW COMBINATORICS AND ANALYSIS INTERACT
Proof. By projection onto translates of each xj-hyperplane, we see that |j(U)| 
Voln1(U), so we may apply Theorem 1.4. /square
Remark. The fact that Uwas bounded was used to dene the projection of Uonto
translates of each xj-hyperplane.
2.Sobolev Inequality
LetuC1Rn
comp( ) satisfy |u|= 1. How big can ube? We would like the nd
the right notion of size for u/integraltext
that answers this question.
Theorem 2.1 (Sobolev inequality). IfuC1
comp(Rn), then
||u|| n
n1/lessorsimilar||u||L1.L
Here, the Lp-norm ||u||Lpis given by
1/p
||u||Lp=/parenleftbigg/integraldisplay
|u|p/parenrightbigg
so that ||h||=h |A|1/pA p . For some context about Lp-norms, for a function u,
letS(h) :={xRn| |u(x)|&gt; h}.
Proposition 2.2. If||u||pM, then |S(h)| Mphp.
Proof. Just estimate Mp=/integraltext
|u|php|S(h)|. /square
We now prove the Sobolev inequality. A rst try is the following bound.
Lemma 2.3. IfuC1
comp(Rn),|j(S(h))| h1 ||u||L1.
Proof. ForxS(h), take a line in the xj-direction. It eventually reaches a point
xwhere u= 0, so/integraltext
|U| hby the fundamental theorem of calculus. This means
that
||u||L1/integraldisplay
|u|=/integraldisplay /integraldisplay
|u|dxjdxother |j(S(h))| h. /square
j(S(h))R j(S(h))R
If we apply Theorem 1.4 to the output of Lemma 2.3, we see that
n n|S(h)|/lessorsimilarhn1 ||u||n1,
which looks like the output of Proposition 2.2. So we would like to establish some-
thing like the converse in this case. For this, we require a more detailed analysis.
Lemma 2.4 (Revised version of Lemma 2.3) .LetS:={xRn|2k1k  |u(x)| 
2k}. IfuC1Rcomp(n), then we have
|jSk|/lessorsimilar2k/integraldisplay
|u|.
Sk1</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 HOW COMBINATORICS AND ANALYSIS INTERACT
1.B1, where Bris the ball of radius r. We see that
1 |x| 1|TB1(x)| /braceleftBigg
|x||x|&gt;1.
2.Br. We see that
rnr|x| r|TBr(x)| /braceleftBigg
rn |x||x|&gt; r.
2.1, the delta function. Morally, this is given by limnrnBr.
A question we would like to ask about Tis the following. Fix andn. For which
p, qis there an inequality
(1) ||Tf||q/lessorsimilar||f||p
for all choices of f?
In some sense, this measures how much bigger Tcan make f. First, we determine
the answer in Examples 1 and 2. For Example 1, ||B1||p1, and
||TB1||1
1/integraldisplay
(1 +|x|)qdx,
Rn
which is nite if and only if q &gt; n . So (1) holds in Example 1 if and only if q &gt; n .
Let us assume this from now on.
For Example 2, ||Br||n/ppr. For ||TBr||q, the value is given by two terms,
one coming from the ball |x| rand the outside tail. The condition q &gt; n says
that the contribution of the tail is nite, so we get the estimate
||Tn
Br||q ||r  Br||qrn+n/q.
Thus, we conclude that (1) holds in Example 2 if and only if q &gt; n andrn/p/lessorsimilar
rn+n/qfor all r &gt;0. The latter condition is equivalent to n/p=n+n/q.
For a general linear operator T, we would like to ask whether
||Tf||q/lessorsimilar||f||p
under the conditions that q &gt; n andn/p=n+n/q. If the answer is yes, we
conclude that the characteristic functions of balls are in some sense typical for the
action of T; otherwise, we would like to understand which functions fthis fails for.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>HOW COMBINATORICS AND ANALYSIS INTERACT 3
Proof. ForxSk, draw a line in the xj-direction through x. There is a point xon
withu(x) = 0. Between xandx, there is some region on where |u|is between
2k2and 2k1. Then we see that along each such , we have
/integraldisplay1|u| 2k.
Sk1 4
Summing this along all perpendicular to a translate of the xj-hyperplane yields the
result. /square
n
kn n1Corollary 2.5. |Sk|/lessorsimilar2n1 |u|.Sk1
Proof. Put Lemma 2.4 into Th/parenleftBig
eo/integraltext
rem 1.4./parenrightBig
/square
Proof of Theorem 2.1. Take the estimate
/parenleftBigg/integraldisplay/parenrightBigg n/integraldisplay n1 /summationdisplay /summationdisplay/parenleftbigg/integraldisplay n
n1n|u|n1 2kn|Sk|n1/lessorsimilar |u|  |u |
Rnk=Skk1/parenrightbigg
,
where in the last step we move the sum inside then-npower. /square1
Remark. The sharp constant in Theorem 2.1 is provided by a smooth approximation
to a step function where the width of the region of smoothing is very small.
3.Lpestimates for linear operators
Iff, g:RnRorC, dene the convolution to be
(f  g)(x) =/integraldisplay
f(y)g(xy)dy.
Rn
We can explain this denition by the following story. Suppose there is a factory at 0
which generates a cloud of pollution centered at 0 described by g(y). If the density
of factories at xisf(x), then the nal observed pollution is f  g.
We would like to study linear operators like Tf:=f|x|, which means explicitly
that
Tf(x) =/integraldisplay
f(y)|xy|dy.
We will take in the range 0 &lt;  &lt; n , so that if fC0
compthen the integral converges
for each x. Operators like these occur frequently in PDE. Another example is the
initial value problem for the wave equation.
Example. Let us rst see how Tbehaves on some examples for f.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>HOW COMBINATORICS AND ANALYSIS INTERACT
1.Loomis-Whitney Inequality
LetXbe a set of unit cubes in the unit cubical lattice in Rn, and let |X|be its
volume. Let  jbe the projection onto the x
jhyperplane. The motivating question
is: if  jis small for all j, what can we say about |X|?
nTheorem 1.1 (Loomis-Whitney 50s) .If|j(X)| A, then |X|/lessorsimilarAn1.
Remark. The sharp constant in the /lessorsimilaris 1. The original proof is by using H olders
inequality repeatedly.
Dene a column to be the set of cubes obtained by starting at any cube and taking
all cubes along a line in the xj-direction.
Lemma 1.2 (Main lemma). If|j(X)| B, then there exists a column of cubes
1with between 1andBn1cubes o/summationtext
fX.
1Proof. Suppose not, so every column has &gt; Bn1cubes. This means that there are
1 2&gt; Bn1cubes in some x1-line. Taking the x2-lines through those, there are &gt; Bn1
cubes in some x1, x2-plane, and so on. Repeating this n1 times, we get &gt; Bcubes
in the x1, . . ., x n1-plane, a contradiction. /square
/summationtext nCorollary 1.3. Ifj|j(X)| B, then |X| Bn1.
Proof. LetXbeXwith its smallest column removed. Then |j(X)| B1,
n 1so by induction we get |X| (B1)n1, hence |X| Bn1+/summationtext
|X|. /square
Note that Corollary 1.3 implies Theorem 1.1.
Theorem 1.4 (more general Loomis-Whitney) .IfUis an open set in Rnwith
n|j(U)| A, then |U|/lessorsimilarAn1.
nProof. Take UUbe a union of -cubes in -lattice. Then |U|/lessorsimilarAn1and
|U|  |U|. /square
Corollary 1.5 (Isoperimetric inequality). IfUis a bounded open set in Rn, then
nVoln(U)/lessorsimilarVoln1(U)n1.
Date: November 28, 2012.
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Why Polynomials? (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec5/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>2 WHY POLYNOMIALS? PART 1 
any plane or degree 2 algebraic surface. How many intersection points can there 
be? This is an open question, which looks quite important to me. We do know that there are signicantly less than L
2 intersections. The best known estimate is that 
the number of intersections is  CL3/2, and we will prove it later. 
The best example that I know has about 4 L intersections. The set of lines in R3 
is a 4-dimensional manifold. So choosing L lines gives us 4 L parameters to play 
with. If we want one particular line to intersect another, that gives us one equation 
that our parameters have to satisfy. Just counting parameters, one might guess that 
its not hard to nd examples with 4 L intersections, and that examples with more 
intersections require some type of coincidence or conspiracy. Given four lines in general position, we will see later that there is a line which meets all four. Using 
this fact, its straightforward to give examples with nearly 4 L intersections. 
2. Variations of the joints problem 
Last lecture, we proved that L lines in R
3 determine  10L3/2 joints. Now we will 
consider various special cases and/or generalizations of this problem, trying to see 
why the problem is hard without polynomials and what the role of polynomials is. 
We begin by recapping the proof. The key step was the following lemma. 
Main Lemma. If a set of lines has J joints, then one of the lines contains  3J1/3 
joints. 
The main lemma implies the theorem by removing the lines one at a time. We 
start with L lines and J joints. By cutting out one line, we reduce the number of 
joints by  3J1/3 . We look at the remaining lines L  1 lines, which contain  J 
joints. One of the lines has  3J1/3 joints on it. Removing this line, we reduce the 
number of joints by  3J1/3 . We remove all L lines, one at a time. Each time the 
number of joints decreases by  3J1/3, and we end up with no joints. Therefore, 
J  L(3J1/3). Rearranging we get J2/3  3L, which implies the theorem. 
An important special case of the joints theorem is the axis-parallel case, when each 
line is parallel to one of the coordinate axes. This case was studied by Loomis and 
Whitney in the early 50s, and they proved a sharp estimate for the possible number 
of joints. We now present a proof of the axis-parallel case more or less following their ideas. It suces to prove a version of the main lemma for axis parallel lines. 
Lemma 2.1. Suppose that L is a set of L lines in R
3, each parallel to one of the 
 J1/3coordinate axes. If L determines J joints, then one of the lines contains 
joints. Proof. Suppose that each line contains &gt; J
1/3 joints. Let Lj  L be the set of lines 
parallel to the xj axis. Start with a line in L1. It contains &gt; J1/3 joints. Each of 
these joints lies on a line of L2, giving &gt; J1/3 disjoint lines of L2. Each of those lines</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>WHY POLYNOMIALS? PART 1
 
The proofs of nite eld Kakeya and joints and short and clean, but they also 
seem strange to me. They seem a little like magic tricks. In particular, what is the 
role of polynomials in these problems? We will consider this question from several points of view all through the course. 
It would be interesting to know how hard it is to prove these results without the 
polynomial method. If there are other short proofs, it would be great to know about them. Perhaps they are less strange or strange in a dierent way. If its really hard to prove these results without the polynomial method, then there should be some reason. 
Were going to try to ferret out the role of polynomials by thinking about dierent 
cousins of these problems. In this section, well meet a key example, consider some mostly open problems, and state a result or two that well return to later. 
1. Arrangements of lines with lots of intersection points 
Suppose we have L lines in R
3 . How many intersection points can there be? There ( )
are at most L 
2intersection points, and this can be achieved by putting all the lines 
in a plane. 
What if we dont allow ourselves to put all the lines in a plane? Suppose we have 
L lines in R3 with  10 lines in any plane. How many intersection points can there 
be? Remarkably, there can still be  L2 . 
Our example uses a degree 2 algebraic surface dened by the equation z = xy. 
This surface contains many lines. For each y0, there is a horizontal line h(y0) in the 
surface parametrized by (t) = (t, y 0, y0t). And for each x0, there is a vertical line 
v(x0) in the surface parametrized by (t) = (x 0, t, x 0t). Any horizontal line intersects 
any vertical line: h(y0) intersects v(x0) at (x 0, y0, x0y0). Taking L/2 horizontal lines 
and L/2 vertical lines gives L2/4 intersections. Any plane intersects the surface in a 
degree 2 curve, and so any plane contains at most 2 of our lines. This surface is an 
example of a regulus, and we will study them more in later sections. 
This is a crucial example in combinatorial problems about intersecting lines. Clever 
examples dont come only from subspaces and objects of linear algebra - they also 
come from low degree algebraic surfaces. Enlisting the aid of polynomials can help 
us to either nd or rule out such examples. 
Continuing our questions, what if we dont allow ourselves to put all the lines in 
a degree 2 surface either? Suppose that we have L lines in R3 with  10 lines in 
1</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>3 WHY POLYNOMIALS? PART 1 
contains &gt; J1/3 joints, giving &gt; J2/3 joints all together. These joints all lie in a plane 
parallel to the x1 x2 plane. Therefore, each of these &gt; J2/3 joints lies on a dierent 
line of L3. So we have &gt; J2/3 disjoint lines of L3. They each contain &gt; J1/3 joints, 
for a total of &gt; J joints. This gives a contradiction. D 
It seems to be dicult to generalize this argument to the joints problem. It even 
seems dicult to adapt it to a small perturbation of the axis parallel case. Suppose 
that Lj is a disjoint set of lines with angle &lt;  to the xj axis, and let L be the union 
of the Lj. Even if  is small, say  = 1/1000, it seems hard to adapt the above proof 
to this case. The problem happens at the italicized word dierent. If the lines are not quite parallel to the axes, then some of the &gt; J
2/3 joints may lie on the same 
line of L3. The strength of this eect seems hard to bound. 
If we begin with axis parallel lines, and tilt them just slightly, than the problem 
gets a lot harder. For another perspective, we can consider bending the parallel lines slightly, leading to nearly axis parallel curves. Suppose that 
j is a (possibly disjoint) 
set of curves with tangent vectors always maintaining an angle &lt;  to the xj-axis. 
Let  be the union of the  j. Dene a joint of  to be a point that lies in one curve 
from each  j. If we have L curves, how many joints can we make? A priori, the 
answer may depend on both  and L. 
This problem is basically open. For a xed small , say  = 1/1000, do we get 
 CL3/2 joints? I dont know any examples with more joints. The angle condition 
guarantees that a curve in  i and a curve in  j intersect in at most 1 point for (L)
i j, and so the number of joints is  2. Even a bound like L1.99 would be =  L2 
interesting. Also, the bound may depend on . 
For a simple geometric argument, it may be dicult to distinguish the nearly 
axis-parallel lines from the nearly axis-parallel curves. It may turn out that nearly axis-parallel curves can have signicantly more than L
3/2 joints. This would oer an 
explanation of the use of polynomials in the proof of the joints theorem: polynomials 
treat straight lines and nearly straight curves very dierently. On the other hand, 
it may turn out that the L3/2 estimate extends to nearly axis-parallel curves, which 
would give a signicant new point-of-view about the joints theorem. 
3. Examination of the key facts we used 
In the polynomial method, we get a lot of mileage out of two rather simple facts 
about polynomials. 
(1) In n-dimensional space Fn, the dimension of the space of polynomials of 
degree  d is  dn/n!. 
(2) If a polynomial of degree  d vanishes at d + 1 points on a line, then it 
vanishes on the whole line.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 WHY POLYNOMIALS? PART 1 
The rst bullet says that there are lots of polynomials. This gives us a lot of 
exibility to nd a polynomial with certain properties. There are lot of ways that 
polynomials can behave on the whole space Fn . The second bullet says that the 
behavior of a polynomial on a line is comparatively limited. If we restrict the polynomials of degree  d to a line, then we get a vector space of dimension d + 1 of 
possible functions on the line. This dimension is much smaller than the dimension of the space of polynomials of degree  d on all of F
n . In summary, polynomials can 
behave in many ways on the whole space, but in comparatively few ways on a line. The gap between d
n/n! and d+ 1 gives us a kind of leverage. In some sense we 
would like to make this gap as large as possible. 
Let W(d) be a vector space of functions from Fn to F, for some eld F. We say 
that W(d) obeys the degree d vanishing lemma if, for any f  W(d), if f = 0 at 
d+ 1 points of a line, then f = 0 at every point on the line. 
Question: What is the maximum possible dimension of a vector space of functions 
from Fn to F which obeys the degree d vanishing lemma? 
Exercise. Using a (d + 1)  ...  (d+ 1) grid of points, prove that the dimension 
is  (d+ 1)n . 
I conjecture that the maximum dimension is achieved by the polynomials of degree 
 d. 
Are there examples of W(d) with dimension &gt; d1+ which are not polynomials? 
Next one may replace lines by some other subsets of Fn and ask again about the 
dimension of space of functions satisfying the vanishing lemma. Little or nothing is known about this...</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Special Points and Lines of Algebraic Surfaces (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec14/</lecture_pdf_url>
      <lectureno>14</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Introduction to Incidence Geometry (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec6/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>2 k kProof. Suppose not. Restrict to a subset P of size 2 . For all x  P , there are at least lines2 
k2 through x that dont contain any other points of P , so |L||P |k = 4 .2 
k2 |L|Proposition 1.6. If |L| &lt; , then |Pk| &lt; 2.4 k 
k kProof. Suppose not. By the last proposition, |Pk| &lt; 2 . For all x  P , there are at least lines2 
through x that dont contain any other points of P , so |L||Pk|k , as desired. 2 
So far, weve only used the fact that two lines intersect in at most one point. But that cant 
be enough to prove the Szemer edi-Trotter Theorem, because in a nite eld F2 , we could take q 
2all the lines: that gives |L| = q+ q and k = q + 1, which violates the Szemer edi-Trotter upper 
bound. (Note that in that case theres a phase transition around k = |L|, from |Pk| = |L| to 
|Pk| = |L|.) 
The extra fact well use is some topology, specically the Euler characteristic. Take a large disc 
containing all the intersections and let Vint and Eint be the interior vertices and edges; there are 
also 2|L vertices and 2|L| edges along the boundary of the disc. Every edge is in at most two faces 
(1 if along the boundary) and every face contains at least three edges, so 3|F | 2|Eint| + 2|L|,r so |Eint| 3|Vint| + 2|L|. Hence (1 deg(v )  3)  2L (in fact, its at most L). If every vVint 2 
2Lintersection had multiplicity at least 3, then |Pk| ; we need to gure out a stronger argument K3 
because intersections might have multiplicity 2. 
K5 isnt planar, since 10 = |E(K5)| &gt; 3|V (K5)| 6 = 9. 
Crossing Numbers of Graphs 
If G is a graph, a legal map F into the plane takes vertices to distinct points and edges to curves 
between their endpoints points. 
The crossing number of F is the number of pairs of edges curves that intersect, and the 
crossing number of a graph is the minimum crossing number over legal embeddings. For instance, 
CN(K5) = 1. 
2
 p p</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>1 Incidence Geometry 
Topic: take a bunch of simple shapes like circles or lines, and study how they can intersect each 
other. 
Denition 1.1. If L is a set of |L| lines in R2, let Pk(L) be the set of points lying in at least k 
lines, called k-fold intersections; then we can ask what the maximum value of Pk(L) in terms of k 
and |L| is. 
For example, we can get Pk(L) = |L|/k trivially by dividing the lines into sets of k and inter
secting each set. 
In an N  N grid of points, let L be the set of lines that contain between R and 2R points. 
Then there are at most (N2 
R2 ) lines of those lines through each point: in any such line, the closest 
2Npoint to x must lie in a square of sidelength R centered at x. We claim that there are at least 
(N2 
R2 ) of those lines through each point, too: each of the points in the quarter of that square of 
sidelength 2N closest to the center of the grid determines a line that contains at least R points, and R 
by the following lemma, a constant fraction of them are distinct and contain not too many points: 
2 1 BLemma 1. For all B, there are more than B2 integer pairs (x, y)  [B 
2 , with gcd 1 100 ] 
Proof. Throw out the 1 pairs where both are divisible by 2, the 1 divisible by 3, and so on. 4 9 1 1 99+ +  &lt;4 9 100 . 
If k is the smallest degree of any grid point, then k is about N 2 
R2 , |Pk| N2, and |L| = |Pk|k/R = 
N4 
R3 , so |Pk| = |L|2k3 . 
 
Proposition 1.2. k  [|L|], theres a conguration such that |Pk| cL2K3 . 
In the early 1980s, it was proven that one of the two bounds above is tight up to a constant 
factor: 
  
|L| |L|2 Theorem 1.3 (Szemer edi, Trotter). For some constant c, |Pk| c + .k k3
 
 
If k&gt;|L|, the rst term dominates; if k  L, the second term dominates.
 
)2Proposition 1.4. |Pk| (|L| 
 2L2k2 
(K)2 
    L kProof. There are pairs of lines, and x  Pk, there are at least pairs of lines that intersect 2 2
at x. 
k2 kProposition 1.5. Prop: If &gt; |L|, then |PK | &lt; 2 .4 
1</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Detection Lemmas and Projection Theory (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec22/</lecture_pdf_url>
      <lectureno>22</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>DETECTING REGULI AND PROJECTION THEORY 7
dimensional. This is true for j=J. Now Rj1is formed by adjoining a nilpotent
element to Rj. The inductive step is then straightforward. /square
Assembling these three propositions gives the fundamental theorem of projection
theory.
4.Taking stock
We have now dened the polynomial FP. We proved that degFP degP for
some constant . We proved that FP(x) = 0 if and only if the point xis ecnodal.
Ifxlies in a line in Z(P), then xis obviously ecnodal and so FP(x) = 0.
Suppose that Pis irreducible and that Z(P) contains &gt; (degP )2lines. The
polynomial FPvanishes on each of these lines. Since the number of lines is &gt;
(degP )(degFP ), it follows that Pdivides FP, and so FP= 0 on Z(P). We conclude
that every point of Z(P) is ecnodal: at every point there is a direction Vin which
Pvanishes to fourth order.
The next step is to prove that the surface is actually ruled. Because every point is
ecnodal, the surface looks nearly ruled at every point. The next step is a local-
to-global argument: because there is locally always a line nearly in the surface, the
surface is globally ruled. This argument is quite dierent - it has to do more with
dierential geometry than with algebra. We discuss it more next time.
Finally, we note that our set up so far is pretty exible. For example, suppose we
dene a point zto be t-ecnodal if there is a non-zero vector Vso that s
vP(x) = 0
for all sfrom 1 to t. By the same argument as above, we can construct a nite set
of polynomials FtPwith degree (t)degP so that zis t-ecnodal if and only if
FtP(z) = 0. If Pis irreducible and Z(P) contains &gt; (t)(degP )2lines, then every
point of Z(P) is t-ecnodal. The ecnode is dened with t= 3, because thats the
smallest value of twhere the local-to-global argument works. But we can choose to
work with any value of t, and its actually a little easier to prove the local-to-global
result with t= 4 or t= 10...
If a point lies in two lines in Z(P) we can nd two linearly independent vectors
V1, V2where s
VP(z) = 0 for all s. With a little modication of the technology,
we can build a polynomial RPthat vanishes whenever there are two independent
directions in which Pvanishes to order 4. We pick that up next time.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>DETECTING REGULI AND PROJECTION THEORY 3
The polynomial FPis called the ecnode polynomial. In fact FPis a single
polynomial (not a set of several polynomials), but this fact doesnt matter that
much in applications, and its easier to prove the Ruled surface detection lemma in
the form above. Given the ecnode polynomial, the estimate on the number of lines
in a non-ruled surface follows from Bezouts theorem.
Salmon dened FP(and gave a formula for it), and he proved properties 1 and 2.
Then Cayley proved property 3. (See pages 277-78 of Salmons book.)
We will try to explain the main ideas in this type of detection lemmas. We will
try to give a fairly general point of view about how to prove this type of lemma,
and we will try to avoid writing long formulas. We will give a complete proof of the
regulus detection lemma, and we will give the main ideas of the proof of the ruled
surface detection lemma.
We say a point zC3is ecnodal (for P) if there exists a non-zero vector Vso
thatPvanishes in the direction Vto fourth order. We write sPto denote the sth
V
directional derivative of Pin the direction V. We say Pis ecnodal at zif there
exists a non-zero vector Vso that
0 =VP(z) =2
VP(z) =3
VP(z). (1)
Ifzis contained in a line in Z(P), and if Vis tangent to the line, then equation
(1) holds.
It can be helpful to expand this expression in terms of derivatives of Pin the co-
ordinate directions. Vis a vector ( V1, V2, V3)C3. For a multi-index I= (i1, i2, i3),
we write VIforVi1...Vi3,fori1 i
1 3 I i1...3
i3, and I! fori1!i2!i3!.z1z3
s
VP(z) :=/summationdisplay
I!VIIP(z).
|I|=s
Salmon dened his polynomial FPand proved that FP(z) = 0 if and only if zis
a ecnodal point. So the ecnode polynomial detects ecnodal points. These facts
boil down to the following lemma.
Lemma 1.2. Consider the set of equations
0 =/summationdisplay
VIaI, s= 1,2,3. (2)
|I|=s
In these equations, aIare parameters in C. We let abe the vector with components
a, soaCMI for some M.
Sol:={aMC|Equation (2) has a non-zero solution VC3}.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 DETECTING REGULI AND PROJECTION THEORY
The set Solis an algebraic set in CM. In other words, Solis the zero set of some
list of polynomials G.
Given the lemma, we dene FP(z) =G(IP(z)). If Gis a set of polynomials of
degree CinaI, then FPis a set of polynomials of degree C(degP ) inz. By the
lemma, a point zis ecnodal if and only if FP(z) = 0.
In summary, given the Lemma 1.2, we can immediately dene FPand prove
properties 1 and 2 of the ruled surface detection lemma.
Lemma 1.2 is part of an area called projection theory. Its a special case of the
fundamental theorem of projection theory. We introduce projection theory and prove
the fundamental theorem in the next section.
2.Projection Theory
LetFbe a eld. Recall that an algebraic set in FMis just the zero set of a nite
list of polynomials. Suppose that Zis an algebraic set in FmFn, and we consider
the projection of Zonto the second factor. Is the projection also an algebraic set?
In general the answer is no. Lets consider two examples. We begin working over
the eld Rwhere everything is as simple as possible to visualize.
Example 2.1. (Circle example) Let Zbe the zero set of x2+y21inR2. If we
project Zto the xaxis we get the closed segment [1,1]. This is not an algebraic
set.
Example 2.2. (Hyperbola example) Let Zbe the zero set of xy= 1inR2. If we
project Zto the x-axis, we get R\ {0}. This is not an algebraic set.
Projection theory studies this situation. What kind of structure do the projections
have? Are there some situations where the projection is an algebraic set?
What would happen if we work over Cinstead of R? The example with the circle
gets better. If we let Zbe the zero set of x2+y21 inC2, then the projection of
Zto the xaxis is C. But the hyperbola example is the same as before  if we work
overC, the image of the projection is C\ {0}.
We can loosely describe the situation with the hyperbola in the following way.
For each xC\ {0}, there is a unique solution to the equation xy1 = 0. As
xapproaches zero, this solution y(x) tends to innity. In some sense, when xis
equal to zero, the solution is at innity. We can make this precise by working with
projective space. Instead of yFn, we can consider ynFP. Instead of starting
with an algebraic set ZFmnFn, we can start with an algebraic set ZFmFP.
IfFis algebraically closed and if we work projectively, then the projection of Zis
also algebraic.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>6 DETECTING REGULI AND PROJECTION THEORY
The key point of the proof is that M(x)=dis surjective! This follows from the
homogeneity. Suppose that fI(x)=d. By denition, fis degree dandf=/summationtext
jQj,xfjfor some polynomials fj. But since Qj,xis homogeneous of degree dj, we
see that f=/summationtext
jQj,xfj,=ddj. Sofis in the image of M(x)=d.
The linear map M(x)=dcan be described by a matrix. The dimension of I(x)=dis
exactly the rank of this matrix. The entries of the matrix are polynomials in x. The
matrix M(x)=dhas rank Bif and only if each ( B+ 1)(B+ 1) subdeterminant
vanishes. Therefore, the set of matrices M(x)=dwith rank Bis an algebraic
set. /square
Proposition 3.2. For any integers d, B0, the set {xFm|F[y]/I(x)is innite dimensional }
is an algebraic set.
Proof. The rst step is to see that F[y]/I(x) is innite dimensional if and only if
I(x)=dis a proper subspace of H=dfor every d0. Indeed, if I(x)=d=H=d
for some d, then I(x) contains all homogeneous polynomials of degree d, and so
F[y]/I(x) is nite dimensional. The other direction is straightforward.
So the set of xwhere F[y]/I(x) is innite dimensional is exactly
/intersectiondisplay
{xmF|dimI(x)=ddimH =d1}.
d0
By the last proposition this is a countable intersection of algebraic sets. By the
Noetherian property of F[y], the intersection stabilizes after nitely many values of
d, and so the innite intersection is also an algebraic set. /square
Proposition 3.3. IfFis algebraically closed and IF[y]is a homogeneous ideal,
thenZ(I)contains a non-zero point if and only if F[y]/Iis innite dimensional (as
a vector space over F).
Proof. We begin with the easy direction. Suppose that 0 = ylies in Z(I). By homo-
geneity, the line through 0 and yalso lies in Z(I). Now we consider the evaluation
map from F[y]/Ito the functions on this line. Since Fis algebraically closed, there
are innitely many points on the line. For any nite subset of the points on the line,
a polynomial can take arbitrary values. Therefore, the rank of the evaluation map
is innite, and the dimension of F[y]/Iis innite.
Suppose instead that 0 is the only point in Z(I). By the Nullstellensatz, the
radical of Iis the ideal generated by y1, ..., y n. This use of the Nullstellensatz uses
the fact that Fis algebraically closed. If Ihappens to be radical, then F[y]/IisF,
and we are done. In not, then we get some nite sequence of ideals I=I0I1
...IJ= (y 1, ..., y n), where each ideal is formed by adding a radical element to the
previous ideal. By backwards induction on j, we check that Rj=F[y]/Ijis nite/\e}atio\slash</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 DETECTING REGULI AND PROJECTION THEORY
The proof of Theorem 0.1 is essentially the proof of Theorem 0.2 using the regulus
detection lemma instead of the plane detection lemma. We will include the details
later, but there are no signicant new ingredients. The new tool is the regulus
detection lemma.
(The two detection lemmas are quite similar. The regulus detection lemma has an
extra condition in the last item: if there is a non-special point xcontained in two
lines in Z(P). Recall that xis special if it is either critical or at. This condition
is not very elegant, but it will be easy to meet in the application to Theorem 0.1.
If all the intersection points were critical or at, then we could handle the situation
with the plane detection lemma anyway.)
The regulus detection lemma is based on ideas about ruled surfaces developed
by Salmon and Cayley in the 19th century. They proved the rst interesting example
of a detection lemma.
1.Ruled surfaces and flecndes
We consider algebraic surfaces in C3in this section.
Suppose Pis an irreducible polynomial. How many lines can there be in Z(P)?
There can be innitely many, which happens for planes, reguli, cones, and cylinders.
There are actually many other examples.
For instance, consider a polynomial map  : C2C3of the form (s, t ) =
1(s)t+0(s). The image contains innitely many lines (x sand let tvary). Also,
the image is contained in Z(P) for some P. (Is the image exactly Z(P) for some P?)
An algebraic surface Z(P) is called ruled if each xZ(P) lies in a line Z(P).
Now we can ask a more rened question. If Pis irreducible of a given degree, and
Z(P) is not ruled, then how many lines can there be in Z(P)?
Theorem 1.1. IfPis an irreducible polynomial in C[z1, z2, z3], then either Z(P)is
ruled or the number of lines in Z(P)isC(degP )2.
This theorem follows from the work of Salmon and Cayley from the 1800s. It
appears in Salmons book A Treatise on the Analytic Geometry of Three Dimensions.
Chapter XIII deals with ruled surfaces, and ... First published in ?
In particular, the theorem follows from Salmon and Cayleys work on the ecnode
polynomial. They proved the following result.
Ruled surface detection lemma. For any polynomial PinC[x1, x2, x3], we can
dene a nite set of polynomials FPwith the following properties.
(1)DegFP CDegP .
(2) If xis contained in a line in Z(P), then FP(x) = 0.
(3) If FPvanishes on Z(P), then Z(P)is ruled.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>DETECTING REGULI AND PROJECTION THEORY
We have one more theorem about the incidence theory of lines in R3.
Theorem 0.1. IfLis a set of Llines in R3withBlines in any plane or regulus,
and if BL1/2, then the number of intersection points of Lis/lessorsimilarBL.
This theorem is an improvement of our earlier estimate on 3-rich points.
Theorem 0.2. IfLis a set of Llines in R3withBlines in any plane, and if
BL1/2, then |P3(L)|/lessorsimilarBL.
Recall that Pk(L) is the set of k-rich points of L in particular P2(L) is the set of
intersection points of L.
The proof of Theorem 0.2 uses the theory of critical points and at points. We
cant directly apply this theory to Theorem 0.1, because a point lying in two lines
in a surface may be neither critical nor at. So we will have to modify/rene these
tools.
Lets package what we need about critical/at points into one lemma for general-
ization.
Plane detection lemma. For any polynomial PinR[x1, x2, x3], we can associate
a list of polynomials SPwith the following properties.
(1)DegSP 3DegP.
(2) If xis contained in three lines in Z(P), then SP(x) = 0.
(3) If Pis irreducible and SPvanishes on Z(P), then Z(P)is a plane.
Roughly speaking, SPhas the job of detecting whether Z(P) looks like a plane.
IfSP(x) = 0, then it (roughly) means that Z(P) looks kind of like a plane near x.
IfSPvanishes on Z(P) (and Pirreducible), then it means that Z(P) is a plane.
We will rene this technique and build a polynomial RPthat detects whether Z(P)
looks like a regulus.
Regulus detection lemma. For any polynomial PinR[x1, x2, x3], we can associate
a list of polynomials RPwith the following properties.
(1)DegRP CDegP .
(2) If xis contained in two lines in Z(P), then RP(x) = 0.
(3) If Pis irreducible and RPvanishes on Z(P), and if there is a non-special
pointxcontained in two lines in Z(P), then Z(P)is a regulus.
1</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>DETECTING REGULI AND PROJECTION THEORY 5
Working with yin projective space is equivalent to using polynomials that are
homogeneous in y. We can phrase the fundamental theorem of projection theory in
the following way.
Fundamental Theorem of Projection Theory. Suppose that Q(x, y)is a nite
list of polynomials in xFmandyFn, each of which is homogeneous in y. Let
SOLFmbe the set
SOL:={xmF|the equation Q(x, y) = 0has a non-zero solution ynF}.
IfFis algebraically closed, then SOLis an algebraic set.
For example, consider the equations in Lemma 1.2. We have the equations 0 =/summationtext
|I|=saIVI, fors= 1,2,3. Each equation is homogeneous in V. By the fundamental
theorem of projection theory, the set of aso that these equations have a non-zero
solution VC3\ {0}is an algebraic set. So Lemma 1.2 is a corollary of the
fundamental theorem of projection theory.
3.Proof of the fundamental theorem of projection theory
LetFbe any eld. Let Qj(x, y) be homogeneous in ywith degree dj. If we think of
xas a parameter, for each x, we get Qj,x(y), a polynomial in ywhich is homogeneous
of degree dj. We let I(x)F[y] be the ideal spanned by the polynomials Qj,x(y).
This ideal is homogeneous. Recall that for any polynomial Qwe write Q=dfor
the degree dpart of Q. An ideal is homogeneous if for any QI, and any d, we
haveQ=dIalso. In particular, any ideal generated by homogeneous polynomials
is homogeneous. We let I(x)=dbe the homogeneous degree dpolynomials in I(x).
Proposition 3.1. For any integers d, B0, the set {xFm|dimI(x)=dB}is
an algebraic set.
This proposition follows from the homogeneity of Q(x, y) (iny).
LetH=dF[y1, ..., y n] be the degree dhomogeneous polynomials.
Proof. Consider the multiplication map M(x)=d:jH=ddjI(x)=d, given by
M=d(R) :=/summationdisplay
Qj,xRj.
j
Since Rjis homogeneous of degree ddjandQj,xis homogeneous of degree dj,
we see that M=d(R) is homogeneous of degree d. Since I(x) is the ideal spanned
byQj,x, the image of M(x)=dis inI(x). So we see that M(x)=dis a linear map to
I(x)=das claimed.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Thue&#8217;s Proof (Part III) (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec28/</lecture_pdf_url>
      <lectureno>28</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>PROOF OF THUES THEOREM  PART III
1.Outline of the proof of Thues theorem
Theorem 1.1. (Thue) If is an irrational algebraic number, and  &gt;deg()+2, then2
there are only nitely many integer solutions to the inequality
p| |  | q|.q
By using parameter counting, we constructed polynomials Pwith integer coe-
cients that vanish to high order at ( , ). The degree of Pand the size of Pare
controlled.
Ifr1,r2are rational numbers with large height, then we proved that Pcannot
vanish to such a high order at r= (r 1, r2). For some jof controlled size, we have
j
1P(r) = 0. Since Phas integer coecients, and ris rational, |j
1P(r)|is bounded
below.
Since Pvanishes to high order at ( , ), we can use Taylors theorem to bound
|j
1P(r)|from above in terms of |r1|and|r2|. So we see that |r1|or
|r2|needs to be large.
Here is the framework of the proof. We suppose that there are innitely many
rational solutions to the inequality |r|  /bardblr/bardbl. Let &gt;0 be a small parameter
we will play with. We let r1be a solution with very large height, and we let r2be a
solution with much larger height. Using these, we will prove that deg()+2+C().2
2.The polynomials
For each integer m1, we proved that there exists a polynomial P=Pm
Z[x1, x2] with the following properties:
(1) We have j
1P(, ) = 0 for j= 0, ..., m 1.
(2) We have Deg2P1 and Deg1P(1 +)deg()m.2
(3) We have |P| C(, )m.
3.The rational point
Suppose that r1, r2are good rational approximations to in the sense that
/bardblri/bardbl  /bardblr1/bardbl.
1/negationslash</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 PROOF OF THUES THEOREM  PART III
We see that /bardblr2/bardbl  /bardblr1/bardblm&gt; C(, )m, so the assumption about r2andmabove
is satised. The inequality becomes
deg()/bardblr1/bardbl mm2 /lessorsimilar/bardblr1/bardblm.
Multiplying through to make everything positive, we get
deg()+2/bardblr1/bardblm/lessorsimilar/bardblr1/bardblm2.
Unwinding the /lessorsimilar, this actually means
deg()+2/bardblr1/bardblm /bardblr1/bardblb+am+ m2.
(If we had been more explicit, we could have gotten specic values for a, b, but it
doesnt matter much.)
Taking the logarithm to base /bardblr1/bardbland dividing by m, we get
deg() + 2(b/m) +a+ .2
If/bardblr2/bardblis large enough compared to /bardblr1/bardbl, then (1 /m), and we have 
(a+b)+deg()+2. Taking 0 nishes the proof.2</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 PROOF OF THUES THEOREM  PART III
Also, we will suppose that /bardblr1/bardblis suciently large in terms of , , and that /bardblr2/bardbl
is suciently large in terms of , ,and/bardblr1/bardbl.
Ifl2 and j
1P(r) = 0 for j= 0, ..., l1, then we proved the following estimate:
l1|P| min((2 degP)1/bardblr1/bardbl
2,/bardblr2/bardbl).
Given our bound for |P|, we get
l1C(, )mmin(/bardbl r1/bardbl
2,/bardblr2/bardbl).
From now on, we only work with msmall enough so that
C(, )m&lt;/bardblr2/bardbl. Assumption
l1Therefore, /bardblr/bardbl
12C(, )m. We assume that /bardblr1/bardblis large enough so that
/bardblr1/bardbl&gt; C(, ), and this implies that lm. Therefore, there exists some jm
so that j
1P(r) = 0.
LetP= (1/j  !)j
1P  . The polynomial Phas integer coecients, and |P| 2degP|P|.
 Therefore, Pobeys essentially all the good properties of Pabove:
 (1) We have j
1P(, ) = 0 for j= 0, ...,(1)m1.
 (2) We have Deg2P1 and Deg1P(1 +)deg()m.2
(3) We have |P| C(, )m.
 (4) We also have P(r) = 0.
 Since P  has integer coecients, we can write P(r) as a fraction with a known
Deg PDeg Pdenominator: q1q2
1 2 . Therefore,
 deg()|P(r)|  /bardblr/bardblDeg1P/bardblr/bardblDeg2P /bardblr/bardbl(1+) m/bardblr/bardbl121 2 1 2.
We make some notation to help us focus on whats important. In our problem,
terms like /bardblr1/bardblmor/bardblr2/bardblare substantial, but terms like /bardblr1/bardblmor/bardblr1/bardblare minor in
comparison. Therefore, we write A/lessorsimilarBto mean
A /bardblr1/bardblam/bardblrb1/bardbl, for some constants a, bdepending only on .
Recall that /bardblr/bardblis bigger than C(, ), soC(, )m1 /lessorsimilar1. Our main inequality for
this section is
deg()|P(r)|/greaterorsimilar/bardblr/bardbl m/bardblr/bardbl121 2. (1)
4.Taylors theorem estimates
We recall Taylors theorem./negationslash
/negationslash</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>PROOF OF THUES THEOREM  PART III 3
Theorem 4.1. Iffis a smooth function on an interval, then f(x+h)can be
approximated by its Taylor expansion around x:
f(x+h) =/summationtextm1 j
j=0(1/j!)jf(x)h+E,
where the error term Eis bounded by
|E| (1/m!) supy[x,x+h]|mf(y)|.
In particular, if fvanishes to high order at x, then f(x+h) will be very close to
f(x).
Corollary 4.2. IfQis a polynomial, and Qvanishes at xto order m1, and if
|h| 1, then
|Q(x+h)| C(x)degQ|Q|hm.
Proof. We see that (1 /m!)mQis a polynomial with coecients of size 2degQ|Q|.
We evaluate it at a point ywith|y|  | x|+ 1. Each monomial has norm 
2degQ|Q|(|x|+ 1)degQ, and there are degQ monomials. /square
LetQ(x ) =P(x, ). The polynomial Qvanishes to high order (1 )matx=,
and|Q| C(, )m.
From the corollary we see that
|P(r1, )| C(, )m|r1|(1)m.
 On the other hand, 2Pis bounded by C(, )min a unit disk around ( , ), and
so
 |P(r1, r2)P(r1, )| C(, )m|r2|.
Combining these, we see that
|P(r)|/lessorsimilar|r1|(1)m+|r2|/lessorsimilar/bardblr1/bardblm+/bardblr
2/bardbl. (2)
5.Putting it together
As long as /bardblr m1/bardbl&gt; C(, ) and /bardblr2/bardbl&gt; C(, ) , we have proven the following
inequality:
deg()/bardblr m 1 m 21/bardbl /bardbl r2/bardbl/lessorsimilar/bardblr1/bardbl+/bardblr2/bardbl
Now we can choose m. Asmincreases, the right-hand side decreases until /bardblr/bardblm1
/bardblr2/bardbl, and then the /bardblr2/bardblterm becomes dominant. Therefore, we choose mso that
/bardblrm m+1
1/bardbl  /bardbl r2/bardbl  /bardblr1/bardbl.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Reguli; The Zarankiewicz Problem (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec10/</lecture_pdf_url>
      <lectureno>10</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>3 REGULI AND APPLICATIONS, ZARANKIEWICZ PROBLEM 
Lemma 1.6. Suppose that L has  10 lines in any plane or degree 2 surface. Then 
At has no 3 20 2t minor of all 1s. 
Proof. Suppose that At has a 3 20 2t minor of all 1s. Let the three rows by labelled 
by l1, l2, l3. If l1, l2, l3 are all skew, then the  20 column lines all lie in the degree 2 
surface R(l1, l2, l3), which is impossible. Suppose that l1, l2, l3 are not all skew. After 
relabelling, we can assume that l1 and l2 are not skew. If l1 and l2 interesect in a 
point p and lie in a plane P , then we either get 5  2t column lines containing p or 
5 2t column lines lying in P . There cant be that many lines in a plane. Also, by 
the denition of At, there should only be  2t lines of L containing p. Finally, if l1 
and l2 are parallel lines in the plane P , then we get 10  2t column lines in the plane 
P . D 
Knowing that the matrix At does not have any 3 20 2t minors of all 1s controls 
the number of 1s in the matrix by the following classical theorem. It touches on an 
important area of combinatorics with many open questions. 
Theorem 1.7. (K ov ari-S os-Tur an, 1954) Suppose that A is an L L matrix whose 
entries are 0 or 1. Suppose that A has no V W minor of all 1s, for some integers 
2V 1 
V V  W . Then the number of 1s in A is at most C(V )W 1/V L . 
We give the proof and discuss the problem more generally below. So we see 
|At|;2t/3L5/3 . 
;L5/3 2(5/3)t ;L5/3|At|22t . 
t t 
D 
Using the polynomial method, we will eventually improve this bound to L3/2 . 
2. The Zarankiewicz problem 
In the early 1950s, Zarankiewicz posed the following problem. Suppose that A is 
an M  N matrix with entries 0 or 1, and suppose that A has no V  W minor of 
all 1s. What is the maximum possible number of 1s that we can have in A? We 
considered the problem above for square matrices M = N = L. 
Theorem 2.1. (K ov ari-S os-Tur an, 1954) Suppose that A is an M N matrix whose 
entries are 0 or 1. Suppose that A has no V W minor of all 1s, for some integers 
V  W . Then the number of 1s in A is at most C(V )W 1/V MN V 1 .V 
Proof. Let C1, ..., CN denote the columns of A. We can think of each column as a ( )
subset of the numbers [1 , ..., M]. We let M denote all of the sets of V distinct (V )
elements of the numbers 1 , ..., M. We let C
V j denote all of the sets of V distinct /summationdisplay /summationdisplay</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 
LREGULI AND APPLICATIONS, ZARANKIEWICZ PROBLEM 
(Cj ) (M)
elements of Cj. Clearly V  V . We let |Cj|be the number of elements in Cj, so ( ) ( )Cj |Cj |that the number of elements in is .V V 
The condition that A has no V W minor of all 1s implies that each element of (M) (Cj )
V occurs in &lt; W of the sets V . So we get the following inequality: 
N |Cj| M &lt; W . V V j=1 
We write A ; B for A  C(V )B. Up to constant C(V ), the left-hand side is 
roughly |Cj|V , and so 
N 
|Cj|V ;WMv . 
j=1 LThe total number of 1s in A is j |Cj|. Now by Holders inequality, 
N 
V 1 V 1 V 1 |Cj|V )1/V N W 1/V MN V V V |Cj| ( ; (WMV )1/V N = . 
j=1 
D 
The Zarankiewicz problem has been in the background of many questions in in
cidence geometry. For example, suppose that we have S points and L lines in the 
plane. We can form the incidence matrix, an S  L matrix. Each row corresponds 
to a point, each column corresponds to a line, and there is a 1 if the point lies on 
the line. This matrix has no 2  2 submatrix of all 1s, because two lines intersect 
in only one point. Therefore, the number of incidences is ;SL1/2 . (The situation is 
symmetric, so the number of incidences is also ; S1/2L.) These bounds are equiv
alent to the rst bounds we proved about incidence geometry of points and lines in 
the plane. 
We can do other examples with unit circles and/or circles. For instance, consider 
the unit distance problem. We have N points in the plane. Form an N  N 0/1 
matrix with a 1 whenever the distance between the corresponding points is 1. We can think of this as an incidence matrix. The rows correspond to points, and the 
columns correspond to unit circles centered at the points, and an entry is 1 if the point corresonding to the row lies on the unit circle corresponding to the column. Two unit circles intersect in at most 2 points, and so this matrix has no 3 2 minor 
of all 1s. Therefore, the number of unit distances is ;N
3/2 . 
Its a very interesting question how sharp the K ov ari-S os-Tur an theorem is. After 
a couple of examples, we come to deep open problems. /summationdisplay
/summationdisplay
/summationdisplay /summationdisplay</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>REGULI AND APPLICATIONS, ZARANKIEWICZ PROBLEM 
One of our long-term goals is to pursue some questions of incidence geometry in 
R3 . We recall one question to direct our focus during this lecture. 
Question 1. If L is a set of L lines in R3, and if at most 10 (or at most B) lines lie 
in a plane or degree 2 surface, what is the maximum possible number of intersection 
points of L? 
Now we introduce an important tool for incidence geometry in three dimensions. 
1. Reguli 
It is a classical fact that any three lines in R3 lie in the zero set of a degree 2 
polynomial. This fact can be used to prove estimates in incidence geometry in three dimensions. 
Proposition 1.1. For any three lines l
1, l2, l3 in R3, there is a non-zero degree 2 
polynomial Q that vanishes on all three lines. 
Proof. We will prove this result by counting dimensions. We can think of the argu
ment as an example of the polynomial method. 
Let V (2) be the space of polynomials of degree  2 in three variables. The space 
V (2) is a vector space of dimension 10. (A basis is given by x2, xy, xz, y2, yz, z2, x, y, z, 1.) 
Choose three points on each line. Let pi,j be three distinct points on li. By linear 
algebra, we can nd a non-zero degree 2 polynomial Q that vanishes at all the points 
pi,j. Since Q has degree 2 and vanishes at three distinct points of li, it must vanish 
on all of li. So Q vanishes on all three lines as desired. D 
This proposition allows us get good information about the lines that intersect all 
three lines l1, l2, and l3. Exactly what happens depends a little on the properties of 
l1, l2, and l3. Recall that two lines in R3 are skew if they dont intersect and theyre 
not parallel. The most important case concerns three skew lines. Proposition 1.2. If l
1, l2, and l3 are pairwise skew, then there is an irreducible 
degree 2 algebraic surface R(l1, l2, l3)which contains every line that intersects l1, l2, 
and l3. 
Proof. By the last proposition, there is a non-zero degree 2 polynomial Q that van
ishes on l1, l2, and l3. Let R(l1, l2, l3) be the zero set of Q. Suppose that l intersects 
l1, l2, and l3. Since l1, l2, and l3 are disjoint, the line l must intersect R in three 
distinct points. But then Q vanishes identically on l, and l is contained in R. 
1</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 REGULI AND APPLICATIONS, ZARANKIEWICZ PROBLEM 
Finally, if Q was reducible, then it would be a product of linear factors, and R 
would be a union of two planes. But since the lines l1, l2, and l3 are skew, no two of 
them lie in a plane, and so R cannot be a union of two planes. Also, if Q had degree 
1, then R would be a plane, and this cannot happen either. D 
The surface R(l1, l2, l3) is called a regulus. Reguli have played an important role in 
incidence geometry for a long time... including the rst work on the joints problem 
in the paper Counting and cutting cycles of lines and rods in space, by Chazelle, 
Edelsbrunner, Guibas, Pollack, Seidel, Sharir, and Snoeyink (Computational Geometry, Theory and Applications 1 (1992) 305-323). 
To complement this proposition, we record a couple of trivial lemmas which deal 
with the case when two lines are not skew. 
Lemma 1.3. Suppose that l
1 and l2 are lines in R3 that intersect at a point p. 
Suppose that P is the plane that contains l1 and l2. Then any line which intersects 
both l1 and l2 either contains p or lies in P . 
Lemma 1.4. Suppose that l1 and l2 are parallel. Let P be the plane that contains 
them. Then any line which intersects both l1 and l2 lies in P . 
Chazelle et al applied these results to 3d incidence geometry. For example, they 
proved that the number of joints determined by L lines is ;L7/4 . We will use their 
method to work on Question 1. 
Theorem 1.5. Suppose that L is a set of L lines in R3 with  10 lines in any plane 
or degree 2 surface. Then the number of intersection points of L is ;L5/3 . 
Proof. We will work with the intersection matrix of a set of lines L. Let us record 
which pairs of lines intersect. We make an L L matrix A whose entries are 0 or 1, 
where the entry aij is 1 if and only if li and lj intersect. (Convention for the diagonal: 
all zeroes.) 
We write |A| to mean the number of 1s in the matrix A. If every intersection 
point was a simple intersection of two lines, then the number of intersection points 
would be (1 /2)|A|. Some intersection points have multiplicity 2, others may have 
very high multiplicity, and we want to keep track of them separately. We let At be 
the matrix with a 1 in the (i,j)-entry if li and lj intersect at a point lying in  2t 
lines of L. (More precisely,  2t means more than 2t1 but at most 2t.) The number 
of points with intersection multiplicity  2t is  |At|22t . Therefore, the number of 
intersection points is 
 | At|22t . 
t 
Our next goal is to estimate |At|.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>5 REGULI AND APPLICATIONS, ZARANKIEWICZ PROBLEM 
Example 1. Consider an N  N 0-1 matrix with no 2  2 submatrix. The KST 
N3/2theorem says that the matrix has ; 1s. This estimate is sharp. The example 
was discovered by Reiman in 1958 (Uber ein Problem von K. Zarankiewicz, Acta 
Mathematica Hungarica 9 (34): 269-273.) We have essentially already seen the 
example: it is the incidence matrix of lines over a nite eld. We pick N = q2 lines 
in the plane F2 
q . We let the rows of our matrix correspond to the points of F2 q and 
the columns correspond to the q2 chosen lines. We put a 1 in the matrix if the point 
corresponding to the row lies in the line corresponding to the column. Since two 
lines intersect in at most 1 point, there are no 2  2 submatrices. Since each line 
N3/2contains q points, our matrix has q3 = 1s. Working with the projective plane 
over Fq is even slightly better. 
Example 2. Next consider an N N 0-1 matrix with no 3 3 submatrix. The KST 
theorem says that the matrix has ; N5/3 1s. This example was found by Brown in 
the early 60s. It involves a clever construction with some low-degree polynomials over nite elds. We will do it on the homework. 
This example is clever and special, and it seems very hard to generalize it to 4 4 
minors. Consider an N N 0-1 matrix with no 4 4 submatrix. The KST theorem 
says that the matrix has ; N
7/4 1s. But the best examples have only  N5/3 1s 
and these are basically Browns examples which have no 3  3 minor of all 1s! Its 
a longstanding open problem in combinatorics where the truth lies between Browns example and the KST upper bound. 
Example 3. Finally, consider an N  N 0-1 matrix with no V  V submatrix. 
The KST theorem says that the number of 1s is  C(V )N
2(1/V ). For large V , the 
best examples come from a random construction. On the homework, you will use 
the technique to prove that there are examples with  N2 2 1s. For V  5, I V +1 
believe these are the largest known examples.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Hardy-Littlewood-Sobolev Inequality (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec30/</lecture_pdf_url>
      <lectureno>30</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>HARDY-LITTLEWOOD-SOBOLEV INEQUALITY 3
By interchanging summation and integral, we have/integraldisplay
|f|/summationdisplay
2k(p1)/integraldisplay
|f|  |f|p1=/bardblf/bardblp
p.
2k1|f|
So,/bardblMf/bardblp/lessorsimilar/bardblf/bardblp. /square
3.Proof of HLS Inequality
Step 1. Tf(x) can be written in terms of/contintegraltext
f.B(x,r)
Lemma 3.1.
Tn1
f(x) =/integraldisplay
r
0/parenleftbigg/contintegraldisplay
f
B(x,r)/parenrightbigg
dr.
Proof. Just a computation. /square
Step 2. Upper bounds of/contintegraltext
f. One trivial upper bound is Mf(x) by denition.B(x,r)
Also, we can get/contintegraldisplay
f/lessorsimilarrn/integraldisplay
|f|/lessorsimilarrn/bardblf/bardbl/p=rn/p
prn(p1)/bardblf/bardblp
B(x,r) B(x,r)
by H older. We would fail if we only use one of them. Rather, x rcrit(x) and use
Mf(x) forrrpcrit,Lbound for rrcrit. This approximation always gives us
|Tf(x)|/lessorsimilar(Mf)A/bardblf/bardblB
pfor some A, BwithA+B= 1.
Step 3. |Tf|q/lessorsimilar/bardblf/bardblBq
p(Mf)Aq/lessorsimilar/bardblf/bardblBq
p/bardblf/bardblAq
Aqas long as Aq &gt; 1. Ifp=Aq,
then we ha/integraltext
ve/integraltext
/integraltext
|Tf|q/lessorsimilar/bardblf/bardblq
p, so/bardblTf/bardblq/lessorsimilar/bardblf/bardblp. This case together with Aq &gt; 1
is exactly the hypothesis condition in the theorem. Also, we already know that this
condition is the only possible case, so we are done. You may calculate rcrit,A,Bto
check.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 HARDY-LITTLEWOOD-SOBOLEV INEQUALITY
Is it sharp? It seems to be 2ninstead of 6n, but Im not sure and at least hard
to prove. This coecient is not so important for the proof be given later, so lets go
over it.
2.Hardy-Littlewood maximal function
Denote the average of f on Aby/contintegraltext
f:=1f. The Hardy-Littlewood maximalA VolA A
function offis dened to be Mf(x) := supr/integraltext
/contintegraltext
|f|. LetS R g(h) :={xn:|g|&gt;B(x,r)
h}. Then,
Lemma 2.1. |SMf(h)|/lessorsimilarh1/bardblf/bardbl1.
Proof. For each xSMf(h), there exists r(x) such that |f| h, so |f| B(x,r(x)) B(x,r(x))
h|B(x, r(x))|. These B(x, r(x)) cover SMf(h), so by V/contintegraltext
itali covering lemm/integraltext
a, we can
nd disjoint Bjs whose multiple cover SMf(h). Hence,
|SMf(h)|/lessorsimilar/summationdisplay
|Bj|/lessorsimilarh1
j/contintegraldisplay
|f| h1/bardblf/bardbl1.SBj
/square
Now we can estimate the Lp-norm of Mfby that of f.
Proposition 2.2. /bardblMf/bardblp/lessorsimilar/bardblf/bardblp.
One naive approach would be dividing the range and estimate in each range.
Namely, let T(2k) :={xn: 2k&lt;|Mf| 2k+1R Mf } SMf(2k) and we have
/integraldisplay 
|Mf|p/summationdisplay
|Tk kp k kp
Mf(2 )|2/lessorsimilar
=/summationdisplay
2 2 /bardblf/bardbl1,
k k
but the summation in the righthand side diverges. We need a slight modication of
the previous lemma.
Lemma 2.3. |S1Mf(h)|/lessorsimilarh |f|.Sf(h/2)
Proof. In the previous proof, w/integraltext
e found disjoint Bjwhich covering SMf(h) such that/integraltext
|f| h|Bj|. However, we also have/integraltext
|f| h|Bj|, so |f| Bj Bj\Sf(h/2) 2 BjSf(h/2)
h|Bj|. Do the same estimate with BjSf(h/2) instead of Bjand/integraltext
get the desired2
result. /square
Now we can prove the proposition.
Proof. Use the same approach above with our modied lemma.
/integraldisplay 
|Mf|p/lessorsimilar
k/summationdisplay
|Sk p
Mf(2k)|2kp/lessorsimilar 2( 1)|f|.
S(2k1)=/summationdisplay
k/integraldisplay
f</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>HARDY-LITTLEWOOD-SOBOLEV INEQUALITY
Consider a kernel K(x) :=|x|and convolution Tf:=fK. Last time, we
looked at how Tworks when f=Bris the characteristic function on a ball of
radius r.
Proposition 0.1. /bardblTBr/bardblq/lessorsimilar/bardblBr/bardblpif and only if q &gt; n andn+n=n. Orq p
equivalently, p &gt;1and=n(11+1).q p
In fact, this result is true for general cases.
Theorem 0.2. (Hardy-Littlewood-Sobolev) If p &gt;1and=n(11+1), thenq p
/bardblTf/bardblq/lessorsimilar/bardblf/bardblp.
Apart from our previous examples, the next simplest example would be f:=/summationtext
jBjwhere Bjare some balls. It is easy to treat nonoverlapping balls, but rather
dicult in overlapping cases. So, it might be helpful to know about the geometry of
overlapping balls.
1.Ball doubling
Lemma 1.1. (Vitali Covering Lemma) If {Bi}iIis a nite collection of balls,
then there exist a subcollection JIsuch that {Bj}jJare disjoint but/uniontext
iIBi/uniontext
jJ3Bj.
What happens if Iis innite? It is no longer true for innite I: consider {B(0, r) :
r+R}. Any two of them are overlapping, so any disjoint subcollection can contain
only one ball. You cannot cover whole space by a bounded ball, so the theorem is
false for this case. How can we x it? If we loosen the conclusion to cover only a
compact set K/uniontext
iIBi, then we can always nd a disjoint subcollection J(K)I
such that K/uniontext
jJ(K)3Bj.
From Vitali covering lemma, we get the following:
Lemma 1.2. (Ball doubling) If {Bi}iIis a nite collection of balls, then |/uniontext2Bi| 
6n|Bi|.
Pro/uniontext
of.From the proof of Vitali Covering Lemma, for each Biwe can nd some jJ
such that Bi3Bj. So, 2 Bi6Bj. Hence |/uniontext2Bi|  |/uniontext6Bj| 6n/summationtext|Bj|=
6n|/uniontextBj|. /square
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Degree Reduction (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec12/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>ALGEBRAIC STRUCTURE AND DEGREE REDUCTION 5
(1/20)d2A/L104logq, and so d2CLA1logq=|X|q2logqC(logq)2. In
this case we can arrange that d/lessorsimilarlogq. The rest of the argument goes the same. /square
Remark: It would be nice to remove this suspicious log qfactor, and it would also
be nice to clean up the proof.
Lets try to list examples of such sets. A plane has this property. A regulus (like
z=xy) has this property. If Xiare sets with this property then the union of Xi
has this property. In particular, unions of planes and reguli have this property. Very
large sets also have this property - say the complement of a few points. Of course,
the complement of a few points is a union of planes, but I wouldnt be surprised
to nd sets with q3points with this property which arent unions of planes and
reguli. Later we will meet a strange example: the Heisenberg group. The Heisenberg
group has this property, it has q5/2points, and it is not a union of planes and
reguli. I conjecture that a set Xwith this property and &lt;(1/100)q5/2points is a
union of planes and reguli.
2.An Application
Proposition 2.1. LetL={li}iIbe a set of lines in3Fq. Let Silibe a subset
of size q/2. LetX=iSi  ili=Y.
Then |Y| C(logq)|X|.
Remark: As above, the log qfactor appears only if |X|&lt;(logq)q2. Perhaps it can
be removed entirely.
We start with a naive application of the polynomial method. We can nd a non-
zero polynomial Pthat vanishes on Xwith degree d/lessorsimilar|X|1/3. If|X|is close to q3,
there is nothing to prove, and so we can assume that d &lt; q/ 2. Now Pvanishes on
q/2&gt; dpoints on each line li, soPvanishes on Y. However, this does not give
such a good bound for |Y|. It only implies that |Y| C|X|1/3q2. For example, if
|X|=q5/2, we get |Y|/lessorsimilarq17/6.
We can do better by a degree reduction argument. We sketch the argument here.
It is similar to the last proposition. We make a subset I1Ias follows. We
consider the lines lione at a time and decide whether to add itoI1. We add itoI1
ifSicontains q/4 points that arent already in the union of {Si}iI1. At the end
|I1|=L4|X|q1. Also for each iI\I1,Siintersects the sets in I1inA=q/4
points.
By the same argument as above, we can nd a non-zero polynomial Pof degree
d106logq|X|q2so that that Pvanishes on lifor each iI\I1, and vanishes on
liforiI1as long as Siintersects other sets {Si}iIforq/4 points.
Dene Imeager Ito be the set of iso that Siintersects other Sis inq/4 points.
The polynomial Pvanishes on lifor each iI\Imeager. The union of lines liwith</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>ALGEBRAIC STRUCTURE AND DEGREE REDUCTION 3
Lemma 1.2. (Probability lemma) Let Sbe a set of Nelements. Let XSbe a ran-
dom subset where each element of Sis included in Xindependently with probability
p. The expected size of XispN.
(1)P[|X|&gt;2pN]exp(1pN).100
(2)P[|X|&lt;(1/2)pN]exp(1pN).100
We will prove the probability lemma at the end. The lemma says that the size of
|X|is close to the expected value pNalmost all the time. Now we can begin the
formal proof of Proposition 1.1. We will use large constants that hopefully make the
argument more transparent.
Proof. Letdbe a degree which we will choose later. Let pbe the number (1 /20)d2/L.
We form a subset L0Lby including each line independently with probability p.
With high probability, the size of L0is at most (1 /10)d2, and therefore we can nd
a non-zero polynomial Pof degree dthat vanishes on the lines of L0. (The
probability of this step going wrong is at most exp(1d2), which we can arrange2000
is always &lt;1/100.)
Fix a line l. It contains Aintersection points with other lines of L. Each of
these intersection points has a probability pof lying in a line of L0\ {l}. These
events are independent. The expected number of points of llying in lines of L0is
EAp= (1/20)d2A/L.
We now choose din the range (1061)L/A d106L/A. An easy calculation
shows that E104d.
Iflintersects L0ind+1 points, then P= 0 on l. But by the probability lemma,
the probability that lintersects L0indpoints is exp(1E)exp(100d)100
exp(107L/A).
IfL/A &gt; 1000 log Lthen the probaiblity that lcontains dintersection points
withLis&lt; L100 . In this case, with high probability, P= 0 on every line of L, and
we are done. This is the main case.
In the case that L/Ais quite small, the proposition is still true but the proof is
trickier. We sketch what to do in this minor case. We can arrange that Pvanishes
on 99% of the lines of L. Let LLbe the lines where Pdoesnt vanish. We have
|L| (1/100)|L|. Each line of Lhasdintersection points with lines of L\L0.
But it has Aintersection points with lines of L. Now in this case, Ais close to
Landdis extremely small, so we can assume that each line of Lhas(99/100)A
intersection points with other lines of L. Now we can iterate or induct to nd a
polynomial Pthat vanishes on Lwith degree d(1/10)d, and were done. /square
Here is a related result which is special to nite elds.
Proposition 1.3. Suppose that X=3lLlFq. If each point of Xlies in at least
2 lines of L, then degX /lessorsimilarlogq|X|q2.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 ALGEBRAIC STRUCTURE AND DEGREE REDUCTION
Before we prove the result, lets discuss the bound. We saw in an early lecture
that a non-zero polynomial of degree dvanishes at dq2points of3Fq. Therefore, for
any set X3Fq, we have |X|q2degX /lessorsimilar|X|1/3. Sets with degree near the upper
bound have no particular algebraic structure. Sets with degree near the lower bound
have the most algebraic structure. So this proposition says that unions of lines with
2 lines through every point are almost as algebraically structured as possible. In
fact, we will see that the log qfactor can be removed as long as |X|q2logq.
As a heuristic, imagine that we also knew that each point of Xlies in 10 lines
ofL. Then |L|=L10|X|/q. Each line of Lcontains qpoints of intersection with
other lines of L. In this case, the last proposition implies that deg(X)/lessorsimilarL/A
|X|q2. The full proof is a modication of the proof of the last proposition, and the
annoying special case at the end seems harder to deal with.
Proof. We form a subset L1Las follows. Suppose that the lines of Lare put in
order, l1, l2, ...We go through the list of lines one at a time and decide whether to
add each line to L1. If a given line contains q/2 points which are not in any line
already in L1, then we add the line to L1. Otherwise we dont. Since each line of L1
brings q/2 new points of X,|L1| 2|X|q1. Every line in L\L1intersects lines
ofL1atq/2 distinct points. (Otherwise, we would have added it to L1.) We let
L=|L1|  |X|/q.
We let dbe a degree to be chosen later, and as above we let L0L1be a
random subset where each line of L1is included independently with probability
p= (1/20)d2/L. With high probability, |L0| (1/10)d2, and we can choose a
non-zero polynomial Pof degree dso that P= 0 on each line of L0.
Lets assume for now that |X|q2logq. Letlbe a line of Lthat intersects lines of
L1atA=q/2 points. Note that every line of L\L1has this property. The expected
number of intersections between land lines of2L0isE=Ap= (1/20)d A/L . As
in the last proof, we choose Eso that E104d. We can do this with a degree
dL/A |X|q2. More precisely, we can arrange that dis between 105|X|q2and
106|X|q2, and that E104d. Now the probability that lintersects lines of L0in
dplaces is exp(1E)exp(107|X|q2)exp(107logq) =q107. The100
total number of lines in3Fqis10q4, which is much smaller. So we can arrange that
Pvanishes on every line lwithq/2 intersections with lines of L1. In particular
Pvanishes on all the lines of L\L1. Finally, a line of L1either intersects lines of
L1inq/2 points, or else it intersects lines of L\L1inq/2 points. Either way,
we conclude that Pvanishes on l. To summarize, assuming that |X|q2logq, we
have proven that deg(X)106|X|q2.
Next we turn to the small case, |X|q2&lt;logq. The argument goes basically the
same, but now we need to choose Eso that E104dandE104logq. The second
criterion may be harder in the small case. To arrange it, we need to know that</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>6 ALGEBRAIC STRUCTURE AND DEGREE REDUCTION
iI\I2meager has size dq/lessorsimilarlogq|X|. The size of Imeager is4|X|q1. So the
union of the lines in Imeager has size 4|X|.
3.A Probability Lemma
We recall and prove the probability lemma that we used above.
Lemma 3.1. (Probability lemma) Let Sbe a set of Nelements. Let XSbe a ran-
dom subset where each element of Sis included in Xindependently with probability
p. The expected size of XispN.
(1)P[|X|&gt;2pN]exp(1pN).100
(2)P[|X|&lt;(1/2)pN]exp(1pN).100
Proof. We let athjbe 1 if the jelement of Sis included in Xand 0 otherwise. The
functions ajare independent, and the probability that aj= 1 is p. Also |X|=jaj.
Using independence we get the following equation, which holds for any n/summationtext
umber
R:
e|X|=/productdisplay
eaE Ej=/productdisplay
Eeaj= (pe+ 1p)N.
j j
On the other hand, P[|X|&gt;2pN]e2pNEe|X|. Combining these equations, we
get the following upper bound for the probability that |X|is&gt;2pN:
Npe+ 1pP[|X|&gt;2pN]/bracketleftbigg
e2p/bracketrightbigg
.
This bound holds for any . If &gt;0, then the fraction in brackets is &lt;1. Taking
= 1, the fraction in brackets is (1+p(e1))/(1+2p) exp(p/100). Therefore,
inequality 1 holds.
To prove inequality 2, we use a similar argument. We observe that P[|X|&lt;(1/2)pN]e(1/2)pN
Ee|X|. Thus we get the following upper bound for the probability that |X|is
&lt;(1/2)pN:
Npe+ 1pP[|X|&lt;(1/2)pN]/bracketleftbigg
e(1/2)p/bracketrightbigg
.
This bound again holds for any . Ifis negative and close to zero, then the
expression in brackets is &lt;1. In particular, if =1/10 then the the expression in
brackets is at most
1(1/10)p+ (2/100)pexp(p/100).1(1/20)p
Therefore, inequality 2 holds. /square</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>ALGEBRAIC STRUCTURE AND DEGREE REDUCTION
LetSnF. We dene deg(S) to be the minimal degree of a non-zero polynomial
that vanishes on S. We have seen that for a nite set S,deg(S)n|S|1/n. In fact,
we can say something a little sharper. Let V(d) be the vector space of polynomials
of degree dinnvariables. It has dimensiond+n. IfN &lt; dimV (d), thenn
deg(S)d. This bound is sharp for generic sets/parenleftbig
S./parenrightbig
(should we prove it?...) If
deg(S) is signicantly smaller than |S|1/n, then it means that Shas more algebraic
structure than a generic set.
We are going to explore the connection between combinatorial properties of a set
Sand its algebraic structure. We will see that interesting examples in the kind of
incidence geometry questions we have been studying need to have algebraic structure.
Once we prove that a set has some algebraic structure, it makes sense to try to use
that structure to study the set.
As a warmup, we consider a set of Llines in3F. Its easy to nd a degree L
polynomial that vanishes on the Llines, but in fact we can do better.
Proposition 0.1. For any Llines in3 1/2F, there is a polynomial of degree 3L
that vanishes on each line.
Proof. LetV(d) be the space of polynomials in three variables of degree d. The
dimension of V(d) is/parenleftbigd+3/parenrightbig
(1/6)d3. We will choose the degree dlater. We pick3
d+ 1 points on each of the Llines. If dimV (d)&gt;(d+ 1)L , we can nd a non-zero
polynomial of degree dthat vanishes on all the points. Since it vanishes on d+ 1
points on each line, it will also vanish on all the lines. Therefore, we can nd such a
polynomial as long as (1 /6)d3&gt;(d+ 1)L . /square
1.Degree reduction
We have seen that the union of any Llines in3Fhas degree /lessorsimilarL1/2. Now we
consider arrangements of lines with lots of incidences and prove that the the union
has much lower degree. This process is called degree reduction.
Proposition 1.1. LetXbe a union of Llines in3F. Suppose that each line contains
Aintersection points with other lines. Then the degree of Xis/lessorsimilarL/A.
This proposition holds automatically if AL1/2, and it becomes interesting when
Ais signicantly larger than L1/2. For example, suppose that we have Llines in3R
with much more than L3/2intersection points. If there are approximately the same
number of intersection points on each line, then each line would contain much more
1</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 ALGEBRAIC STRUCTURE AND DEGREE REDUCTION
thanL1/2intersection points. Then the proposition would imply that the union of
the lines has degree much smaller than L1/2. The union has some special polynomial
structure, and its reasonable to try to use the polynomial structure to study the
lines.
The rst proof of the joints theorem used degree reduction. I think of it as one of
the main steps/ideas in the polynomial method. This proposition is the rst step in
the proof of the Elekes-Sharir conjecture on the number of intersection points of a
set of lines in3R. I also think of it as philosophically important in explaining why
polynomials are relevant. The combinatorial structure of the problem forces the set
of points or lines to have a special algebraic structure - and then it makes sense to use
this structure to study the problem. The proof of degree reduction is similar to the
proof of nite eld Nikodym or other fundamental results. By counting dimensions,
we nd a low degree polynomial that vanishes on some points of X. Then by using
the vanishing lemma, we see that it also has to vanish at other points of X, and
eventually we prove that it vanishes on all of X.
We begin with heuristics - with an informal argument that describes the main idea
of the proof. Let Lbe our set of lines. Let dbe a degree that we will choose later.
We randomly choose a subset L0Lof size (1 /10)d2. By the last proposition, we
can nd a non-zero degree dpolynomial Pthat vanishes on every line of L0.
Now the key point is that there are many incidences between the lines of L0and
the other lines of L. Therefore, our polynomial vanishes at many points on other
lines of L. If we can check that our polynomial vanishes at d+ 1 points on each
line of L, then it vanishes on all the lines of L. So lets pick a line lLand try to
estimate how many points of lintersect a line of L0.
Pick a line lL. It has Aintersection points with other lines of L. Fix one of
the intersection points. The probability that this intersection point lies in one of the
lines of Lis(1/10)d20 /L. Therefore, the expected number of intersection points
between land lines of L20isE(1/10)Ad /L . We are going to choose dso that
E100d. It suces to choose dso that
(1/10)Ad2/L100d.
Rearranging, it suces to choose dso that d1000LA1. We now choose dto be
an integer which is 1001L/Aand so that E100d. On average, the polynomial
Pvanishes on 100dpoints of l. This suggests that it vanishes on &gt; dpoints of l
with high probability. Since lwas an arbitrary line of L, this suggests that Pusually
vanishes on most of the lines of L.
To get rigorous estimates, we need a little bit of probability. In particular, we will
use the following lemma.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Local to Global Arguments (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec23/</lecture_pdf_url>
      <lectureno>23</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>2 FROM LOCAL TO GLOBAL
2
V,WF(x) =/summationdisplay
ViWjijF(x).
i,j
We abbreviate 2
V=2
V,V. Higher derivatives are similar.
Now we can state our special case.
Proposition 0.2. Suppose that PR[x1, x2, x3]. LetOZ(P)be an open subset of
Z(P). Suppose that Vis a smooth, non-zero vector eld on O, obeying the ecnodal
equation:
0 =s
VP(x),for all xO, s= 1,2,3.
We add a technical assumption. Suppose that at each point xO,P(x) = 0
and2P(x) :TZTZRis non-degenerate.
Then the integral curves of Vare straight line segments. Therefore, every point in
Olies in a line in Z(P).
A word about the technical assumption. We dened above 2
V,WP(x) for any
vectors V, W. Therefore, 2P(x) is a map from R3R3R. We restrict it to a
mapTZTZR. Being non-degenerate means that for each non-zero VTZ,
there is some WTZso that 2
V,WP(x) = 0. For most surfaces Z(P),2Pis
non-degenenerate on a dense open set. In this case, our propisition allows us to
nd a line of Z(P) thru almost every point. And since the non-degenerate points
are dense, we can nd a line of Z(P) thru the other points by taking limits. There
are, however, some surfaces where 2Pis degenerate at every point of Z(P). These
surfaces require a dierent argument - so we begin to see that the general theorem
requires cases.
Proof. It suces to show that at each point xO,VVis a multiple of V. If we
letV1be a unit length renormalization of V, then if follows that V1V1= 0 on O.
This equation implies that the integral curves of V1(orV) are straight lines.
(Suppose that :ROis an integral curve of V1. In other words, (t) =
V1((t)). If we dierentiate, we get (t) =V1((t))V1((t)) = 0. )
To explain the argument, we need a dierent derivative - the Lie derivative. If
Vis a vector eld, we let LVdenote the Lie derivative, dened by LVF(x) =/summationtext
iVi(x)iF(x). Actually, LVF(x) =VF(x), but we come to second derivatives,
there is an important dierence:
LV(LVF) =2
VF! (1)
Lets clarify what the left-hand side means. LVFis a function. Then LV(LVF)
is the Lie derivative of that function. The reason that the two sides are dierent is
that on the left-hand side, the outer dierentiation hits the vector eld Vappearing/negationslash
/negationslash
/negationslash</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>FROM LOCAL TO GLOBAL 3
in (L VF). On the right-hand side it doesnt. To compute the right-hand side at a
point x, we only need to know Vat the point x. But to compute the left-hand side,
we need to know Vin a small neighborhood - or at least the value of the derivative
VV. ThisVVis a vector eld with jthcomponent =/summationtext
iViiVj. Expanding both
sides of (1) and computing, we get:
LV(LVF) =2
VF+VVF. (2)
Now we return to P. We know that LVP=VP= 0 on O. Therefore, its
derivative vanishes on O, and we get
0 =LV(LVP) =2
VP+VVP=VVP.
So we conclude that VVP= 0 on O, and hence VVTZ.
We can get more information by doing a similar computation with third derivatives.
A third-order formula analogous to equation (2) reads
L(2F) =3F+ 22
V V V VV,VF. (3)
We know that 2
VPvanishes on O, and therefore its derivative vanishes on Oalso,
and we get:
0 =LV(2
VP) =3
VP+ 22 2
VV,VP= 2VV,VP. (4)
So at each point of O, we know that VVTZand that 2
VV,VP= 0. Since we
assumed that 2Pis non-degenerate on TZ, this implies that VVis a multiple of
V. Here are the details. We assumed that 2Pis non-degenerate at each point of O.
In other words, for each non-zero vTZ, the kernel of the map Kv:w 2
w,vPis
one-dimensional. For our particular, V, we know that 2
V,VP= 0, and so the kernel
ofK2Vis exactly the span of V. Since VVTZandVV,VP= 0, we conclude
thatVVis in the span of V. /square
Exercises and comments. 1. Check that the above argument can be adapted to
C3.
2. The above argument is fundamentally geometric, and it can be adapted to any
smooth surface  R3. The condition that 2Pis non-degenerate is equivalent to
the second fundamental form of  being non-degenerate, which is equivalent to the
Gauss curvature of  being non-zero.
3. Suppose that 2Pis degenerate at every point of Z(P). This is equivalent
to saying that the Gauss curvature of Z(P) vanishes at every regular point. One
example is a cylinder S1R. In the category of smooth surfaces there are many
other examples - take a piece of paper and bend it gently in space. I think there are</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 FROM LOCAL TO GLOBAL
also many examples of Gauss at algebraic surfaces Z(P), but Im not positive. If
Z(P) is Gauss at and FP= 0 on Z(P), prove that Z(P) is still ruled.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>FROM LOCAL TO GLOBAL
In this lecture, we discuss Cayleys theorem on ecnodes and ruled surfaces.
Theorem 0.1. IfPis a polynomial in C[z1, z2, z3], and if FPvanishes on Z(P),
thenZ(P)is ruled.
We know from last lecture that FP(z) = 0 if and only if zis ecnodal. So for
eachzZ(P), we know that there is a non-zero vector Vso that Pvanishes in the
direction Vto fourth order. Informally, this means that Z(P) locally looks ruled.
We want to put the local information together and prove that there are actual global
lines contained in Z(P).
Here is the basic diculty with the proof. Suppose that V(z) is a smooth non-
vanishing vector eld on Z(P) which obeys the ecnodal equation at each point
ofZ(P). How can we use Vto nd lines? A natural method is to look at the
integral curves of V. But consider the following example. The surface Z(P) may be
a plane. At each point zin the plane Z(P), every tangent vector obeys the ecnodal
equation. So let Vbe any smooth (tangent) vector eld in Z(P). It obeys the
ecnodal equation at every point, but the integral curves of Vare basically arbitrary
curves in the plane. If Z(P) is irreducible and not a plane, then this method actually
works, but we can see the proof needs to be a little subtle because we need to use
the fact that Z(P) is not a plane.
There are also unfortunately a couple of cases in the proof. We wont give a
complete proof. Instead we will carefully do one case, which I think of as the main
case. Moreover, this one case is enough to give the full proof of the regulus detection
lemma.
In our model case, we will work over the real numbers, which is technically easier
(and all we need in the regulus detection lemma). The argument works over the
complex numbers with minor modications, but we think its easier to see the main
ideas over R.
Lets recall/clarify our notation for derivatives and higher derivatives, because we
will need to be clear-headed about it.
IfF:R3Ris a function, we write iFto abbreviate the standard partial
derivativeFxi. IfVis a vector, we write VF(x) for/summationtext
iViiF(x). The most
important role in our story is played by second derivatives. If V, W are two vectors,
then we write
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>What&#8217;s Special About Polynomials? (A Geometric Perspective) (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec21/</lecture_pdf_url>
      <lectureno>21</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 WHATS SPECIAL ABOUT POLYNOMIALS? (A GEOMETRIC PERSPECTIVE)
Theorem 0.5. Pick a degree dand consider the space of polynomials of degree d
in one variable: V1(d). This space has dimension d+ 1. LetWbe any other vector
space of real-valued functions with dimension d+ 1. Every polynomial in V1(d)\ {0}
has at most dzeroes. Then some function FW\ {0}has at least dzeroes.
This is a basic dimension counting argument, of the kind we have used many times.
Proof. Pick any dpoints x1, ...., x dR. Let Ebe the evaluation map E:WRd
given by E(F) = (F (x1), ..., F (xd)). The map Eis linear, and the dimension of the
domain is greater than the dimension of the range. Therefore Ehas a non-trivial
kernel. Let Fbe a non-zero element in ker E. /square
The set of real polynomials in nvariables is also ecient in a similar way.
Theorem 0.6. (Gromov) For any d1,
sup V oln1Z(P)Bnd.
0=PVn(d)
IfWis any vector space of continuous functions dened on the unit n-ball Bn,
withdimWdimVn(d), then
supV oln1Z(F)Bn/greaterorsimilard.
0=FW
This theorem says that the vector space Vn(d) is fairly ecient in terms of the
volumes of zero sets. For a space of functions Wfrom the unit ball BntoR,
dene MaxV ol (W) to be sup0=FWV oln1Z(F)Bn. The theorem says that if
dimW =dimV n(d), then MaxV olV n(d)CnMaxV olW . (Its an open problem
whether MaxV olV n(d)MaxV olW .)
The rst half of the result comes from integral geometry, and it was known in the
early 20th century. The second half is much more recent. It was proven by Gromov
in the paper, Isoperimetry of waists and concentration of maps in Geom. Funct.
Anal. 13 (2003), no. 1, 178-215.
We describe the proof of each half.
1. Let Pbe a non-zero polynomial of degree d. For a line lRn, either
|lZ(P)| dor else lZ(P). IfXn1Rnis a hypersurface, then the volume
ofXis connected to the number of intersections |lX|with dierent lines. The
connection is made by the Crofton formula, which we now describe.
LetAG(1, n) be the set of ane lines in Rn. The group of rigid motions of Rn,
Grigid, acts transitively on AG(1, n). In fact, AG(1, n) is the quotient of the group of
rigid motions by the stabilizer of one line. Using the Haar measure on Grigid, we get
aGrigid-invariant measure on AG(1, n),d. This measure is unique up to scaling./negationslash
/negationslash
/negationslash</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>WHATS SPECIAL ABOUT POLYNOMIALS? (A GEOMETRIC PERSPECTIVE) 3
|LZ(P)B|  |LZ(F)B|.
The intersections of a surface Xwith various lines and the volume of Xare con-
nected. The branch of math that studies this connection is called integral geometry.
Carefully assembling the information in the last lemma, its possible to prove that
V ol[Z(P)B]V ol[Z(F)B]. We wont sketch the proof here, but we give a tiny
introduction to integral geometry below.
Complex polynomials are also ecient in terms of the topological complexity of
their zero sets. In particular, there is a striking theorem about polynomials in two
variables.
Theorem 0.4. (Kronheimer-Mrowka) Suppose that P:C2Cis a complex poly-
nomial in two variables. We identify C2withR4, and suppose that F:R4R2
is any smooth function which agree with Poutside of the unit ball B4. Assume that
0 is a regular value for both PandF. Let Z(P)denote the zero set of P, and let
Z(F)denote the zero set of F. Lets also assume that Z(P)andZ(F)are connected.
Then the genus of Z(P)is at most the genus of Z(F).
IfZ(P) orZ(F) is disconnected, some form of this theorem still holds, but it
takes more care to state it. The theorem was proven in the paper Gauge theory
for embedded surfaces. I. in Topology 32 (1993), no. 4, 773-826. The proof of the
theorem uses gauge theory, and we cant even sketch it here. It has applications in
low-dimensional topology, for example in knot theory. I believe this theorem is also
true more generally for holomorphic functions (because an arbitrary holomorphic
function can be well-approximated by a polynomial in any compact set). Im curious
whether some version of this topological eciency holds for complex polynomials
P:CnC as far as I know, this is an open problem.
So far, we have seen examples of the eciency of complex polynomials, and more
generally of holomorphic functions. The reader may well say that the key property
involved is being holomorphic, not being polynomial. What about real polynomials?
Are any of these theorems true for polynomials over R?
All three theorems are completely false for polynomials over R. For example, a
real polynomial may have P(1) = 1,P(1) = 1, and may have 113 zeroes in
(1,1). A competitor function Fmay have only 1 zero in ( 1,1) - the other 112
zeroes are unnecessary. Modifying this example a bit, its easy to check that the
second theorem is false, and the its not hard to see that the third theorem is false
too. In fact, any smooth function can be well approximated by a real polynomial,
which suggests that real polynomials cannot have any special properties at all.
But if we switch our point of view from individual polynomials to the whole space
of polynomials, then some version of the rst two theorems survives for polynomials
overR. Let Vn(d) denote the vector space of all polynomials of degree dinn
variables. This vector space of functions is ecient in a certain sense.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>WHATS SPECIAL ABOUT POLYNOMIALS? (A GEOMETRIC PERSPECTIVE) 5
Theorem 0.7. (Crofton) There exists a constant nso that the following equation
holds for every (smooth) hypersurface XRn:
V oln1(X) =n/integraldisplay
|lX|d(l).
AG(1 ,n)
We give the idea of the proof. We abbreviate the RHS by Crof(X). We want to
prove that the two sides are equal, and we note some qualities that the two sides
have in common.
1. Disjoint unions. If Xis the disjoint union of X1andX2, we have V oln1X=
V oln1X1+V oln1X2andCrof(X) =Crof(X1)Crof(X2).
2. Rigid motion invariance. If gis a rigid of Rn, then V oln1(gX) =V oln1(X)
andCrof(gX) =Crof(X).
We choose nso that Crof([0,1]n1) = 1 = V oln1([0,1]n1). By the two prop-
erties above, we easily see that Crof([0, s]n1) =sn1for any s. (We start with
positive integers and with s= 1/N, and then rational s, and then take a limit to
get all s.) Next if Xis a nite union of (n-1)-cubes with various side lengths, we see
thatV oln1X=Crof(X).
Finally, given an arbitrary hypersurface X, we approximate XbyXcub- a -
nite union of (n-1)-cubes. We just have to check that V oln1(Xcub) approximates
V oln1(X) and that Crof(Xcub) approximates Crof(X).
Now using the Crofton formula, we can bound the volume of Z(P)Bn. Note
that if lis any line which intersects Bn, then |Sn1l|= 2. The set of lines lwith
lZ(P) has measure 0. So we see that for dalmost every lRn,
|Z(P)Bnl| (d/2)|Sn1l|.
Using the Crofton formula, we see that V oln1n1Z(P)B(d/2)V olS . This
inequality is sharp for every even dby taking Z(P) to be a union of d/2 spheres with
radii very close to 1. (The sharp argument and example were explained to me by
Jake Solomon.)
The second half of the theorem follows from the general ham sandwich theorem,
which we recall.
Theorem 0.8. (Stone-Tukey) If Wis a vector space of continuous functions from
BntoR, and U1, ..., U NBnare nite volume open sets, with N &lt; dimW , and if
each function FW\ {0}hasmeas(Z(F)) = 0, then there is a non-zero FW
which bisects each set Ui.
In our case, dimW dimV n(d)dn. (If any non-zero FWhasZ(F) with
positive Lebesgue measure, then V oln1Z(F) is innite.) We can apply the theorem.
We let U1, ..., U Nbedndisjoint balls in Bn, each with radius d1.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>6 WHATS SPECIAL ABOUT POLYNOMIALS? (A GEOMETRIC PERSPECTIVE)
A hypersurface which bisects the unit n-ball must have (n-1)-volume at least cn&gt;
0. This fact follows, for example, from the isoperimetric ienquality. By scaling,
Z(F)Uimust have (n-1)-volume at least cnd(n1). Therefore, V oln1Z(F)/greaterorsimilar
dnd(n1)=d.
To end this chapter, lets mention a couple themes that appear in both the ge-
ometry today and the combinatorics weve been studying. We always exploit the
fundamental fact that a non-zero degree dpolynomial in one variable vanishes at
mostdtimes. Next we come to polynomials in several variables. This is a very large
space, and it has the simple but remarkable property that if we restrict a degree d
polynomial in several variables to a line, then we get a degree dpolynomial in one
variable. So we get a lot of information about what the polynomial is doing on each
line. In both settings, we want to assemble that information to give global informa-
tion about what the polynomial is doing globally. In the geometric setting, integral
geometry gives an important tool for assembling the information, leading to some of
the geometric estimates above.
Weve also seen the general ham sandwich theorem in both settings. The way its
applied is a little dierent, but the geometric theorem on eciency of real polynomials
is still a kind of precursor for the approach in this chapter.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 WHATS SPECIAL ABOUT POLYNOMIALS? (A GEOMETRIC PERSPECTIVE)
The result says that Phas no unnecessary zeroes. Also, there is nothing special
about 0. If wCdenotes any regular value of PandF, then there are at least as
many points in Dwhere F(z) =was points where P(z) =w. There is also nothing
special about the unit disk, which can be replaced by other open sets. I dont know
the history of this result. It may have been known in the 19th century.
This result holds for all holomorphic functions, and in fact just for functions whose
derivatives are orientation preserving.
Complex polynomials in several variables are ecient in terms of the surface area
of their zero sets.
Theorem 0.2. Suppose that P:CnCis a complex polynomial (or just a holo-
morphic function). We identify Cwith R2andCnwith R2n, and suppose that
F:R2nR2is any smooth function which agree with Poutside of the unit ball
B2n. Finally, assume that 0 is a regular value for both PandF. Let Z(P)denote
the zero set of P, and let Z(F)denote the zero set of F. Since 0 is a regular value,
these are both smooth manifolds of dimension 2n2.
Then the volume of Z(P)Bis smaller than the volume of Z(F)B:
V ol2n2[Z(P)B]V ol2n2[Z(F)B].
Here we are using the standard Euclidean metric on R2n. If we take n= 1, then
this theorem reduces to the rst theorem, because Z(P) is a nite set of points and
its volume is just the number of points. A related result is that Z(P) is a minimal
surface. If we take Z(P)B, we get a closed (2 n3)-dimensional surface, and
Z(P)Bis the smallest surface with that boundary.
This result plays an important role in the theory of minimal surfaces and in dif-
ferential geometry. (I am not sure of its history either. I have seen it attributed to
DeRham or to Federer. I believe it dates from the 1950s. ) The proof uses dier-
ential forms. It has had a signicant inuence in geometry - many other arguments
modelled on it have appeared since then. This type of argument was dubbed a cali-
bration argument by Harvey and Lawson who generalized it to many other settings.
A good place to read about this material is their paper Calibrated geometries in
Acta Math. 148 (1982), 47-157.
We can give some idea of the argument without mentioning dierential forms as
follows. Let Ldenote any complex line in Cn. The intersection LZ(P) is just the
points of Lwhere Pvanishes, and LZ(F) is just the points of Lwhere Fvanishes.
Let us therefore consider Fas a function from LtoC. It wont necessarily happen
that zero is a regular value for this function, but for almost every complex line L,
zero is a regular value for both FandP. Then we can apply the one-dimensional
result, and we get the following.
Lemma 0.3. For almost every complex line LCn,</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>WHATS SPECIAL ABOUT POLYNOMIALS? (A GEOMETRIC
PERSPECTIVE)
This section is for context and background. We discuss some results about polyno-
mials from the point of view of geometry/topology. I think there are some interesting
philosophical ideas here. We build up to an application of the general ham sandwich
theorem to prove a geometric estimate about polynomials. This geometric argument
is a precursor of the applications of the ham sandwich theorems in this section. We
will not give complete proofs here. We sketch the main ideas when we can.
From the point of view of dierential geometry and topology, polynomials (over C
orR) are strikingly ecient. I learned this point of view from V. I. Arnolds essay
on the Topological economy principle in algebraic geometry, in the Arnoldfest.
We begin with examples about complex polynomials. In fact, all these examples
are true more generally of holomorphic functions. Polynomials in one variable are
ecient in terms of the number of zeroes. We make this precise in the following
proposition, which is closely related to material in a rst course on complex analysis
or in dierential topology.
Theorem 0.1. Suppose that P:CCis a complex polynomial in one variable (or
just a holomorphic function). We identify CwithR2, and suppose that F:R2R2
is any smooth function which agree with Poutside of the unit disk D. Finally, assume
that 0 is a regular value for both PandF. Then the number of zeroes of PinDis
less than or equal to the number of zeroes of FinD.
We sketch the main idea of the proof. A point xR2is a regular point of Fif
the derivative dF:R2R2x is an isomorphism. When we say that zero is a regular
value, it means that each point xwithF(x) = 0 is a regular point. Let x1, ..., x Nbe
the points in the unit disk where F(x) = 0. Each such xcan be given a multiplicity
of +1 if detdF x&gt;0 and 1 ifdetdF x&lt;0. We denote the multiplicity by m(xi).
Let us assume for the sketch that FandPdont vanish on the unit circle S1. Then
F:S1R2\ {0}, and Fhas a well-dened winding number around 0, denoted
W(F). In dierential topology, one proves that the winding number W(F) is equal
to the sum of the multiplicities: W(F) =im(xi). There is a similar formula for the
polynomial P. Since PandFagree on S/summationtext
1,W(F) =W(P). But Pis a holomorphic
function, and so dPxis a complex linear map which must be orientation preserving.
The multiplicity of Pat each of its zeroes is 1, and so the number of zeroes of Pin
Dis exactly W(P) =W(F). Therefore, the number of zeroes of FinDis at least
the number of zeroes of PinD.
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Using Cell Decompositions (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec19/</lecture_pdf_url>
      <lectureno>19</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>USING (POLYNOMIAL) CELL DECOMPOSITIONS
1.Szemer edi-Trotter
We will recall the standard form of the theorem.
Theorem 1.1. IfSis a set of Spoints and Lis a set of Llines (all in R2), then
the number of incidences obeys the following bound:
I(S,L)C0[S2/3L2/3+S+L].
We will prove the result by using a polynomial cell decomposition together with
elementary counting bounds in each cell. We rst recall the counting bounds.
Lemma 1.2. IfSandLare as above, then
I(S,L)L+S2.
I(S,L)L2+S.
Proof. FixxS. Let Lxbe the number of lines of Lthat contain xand no other
point of S. For each other point yS, there is at most one line of Lcontaining x
andy. Therefore, I(x,L)S+Lx. SoI(S,L)S2+/summationtext
xSLxS2+L.
The proof of the other inequality is similar. /square
Now we turn to the proof of the theorem.
Proof. IfL &gt; S2/10 or S &gt; L2/10, then the conclusion follows from the counting
lemma. Therefore, we can now restrict to the case that
101/2S1/2LS2/10. (1)
We will also use induction on L, and so we can assume the theorem holds for
smaller sets of lines.
Now we come to the heart of the proof. We use the polynomial cell decomposition
to cut R2into cells, and then we use the counting lemma in each cell.
Letdbe a degree to choose later. By the polynomial cell decomposition lemma,
we can nd a non-zero polynomial Pof degree dso that each component of the
complement of Z(P) contains /lessorsimilarSd2points of S. Let Oibe the components, Si
the number of points of SinOi, and Lithe number of lines of Lthat intersect Oi.
Since each line intersects d+ 1 cells, we know that/summationtextLiL(d+ 1).
Applying the counting lemma in each cell, we get
1</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>USING (POLYNOMIAL) CELL DECOMPOSITIONS 3
In particular, if kis suciently large and we take Sto be the set of points in k
lines of L, then plugging in we get |S|/lessorsimilarL3/2k2+LBk3+Lk1. Taking B=L1/2k
and combining with our earlier bound for 3-rich points, we get
Corollary 2.2. IfLis a set of Llines in R3withL1/2lines in any plane and
k3, then the number of k-rich points is /lessorsimilarL3/2k2.
Now we discuss some examples. The Sterm and the Lterm are easy. If we choose
L/Bplanes, and use a grid conguration in each plane, we get L1/3B1/3S2/3
incidences. Finally, if we choose points and lines coming from a 3-dimensional grid,
we can get S1/2L3/4incidences. In particular, the theorem is sharp up to constant
factors.
The main ideas are similar to the ideas in the proof of ST above, but there are one
or two extra twists and the computations are longer. In this outline, we want to ex-
plain the main steps/ideas, especially the new twists, but postpone the calculations.
We let dbe a degree we can choose later, and we build a degree dpolynomial cell
decomposition. In each cell we apply an incidence bound that we already know. We
could apply the counting lemma as above. We can also apply the Szemer edi-Trotter
theorem in each cell. Recall that the Szemer edi-Trotter theorem holds for points and
lines innRfor any nby a random projection argument. Since it is stronger than the
counting lemma bounds, we may as well use ST in each cell. Then adding up the
contributions from the cells, we get
I(S,L)/lessorsimilarS2/3L2/3 1
ell d/3
c +S+L.
Asdincreases, we get stronger and stronger bounds on the incidences in the
cells. On the other hand, as dincreases, we get more points in Z(P) and weaker
information about Z(P).
We can again divide the lines as L L ce landL l alg . Each line of cellhasdincidences
withSalg. Therefore, we get
I(S,L)/lessorsimilardL+d1/3S2/3L2/3+S+L+I(Salg,Lalg).
In the proof of ST, we chose dL/2, which forced LalgL/2 and allowed us to
use induction. We cannot quite do that here. A surface of low degree may contain
arbitrarily many lines. This is true for planes and reguli, and also for many other
examples. We cannot yet use induction. Also, we need to use the bound on the
number of lines in a plane, which we havent used yet.
The surface Z(P) contains dplanes. Each of these planes contains Blines
ofL. Let Lplanar be the subset of lines of Lwhich lie in one of the planes of Z(P).
Using this information and applying Szemer edi-Trotter in each plane, its not hard
to bound I(S,Lplanar). In particular, well get the following bound:</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 USING (POLYNOMIAL) CELL DECOMPOSITIONS
I(S Li,i)Li+S2
i.
We let S S cellbe the union of i- all the points of Sthat lie in the interiors of the
cells.
I(Scell,L) =/summationdisplay
I(S2
i,Li)/summationdisplay
Li+/summationdisplay
Si/lessorsimilarLd+Sd2/summationdisplay
S=Ld+S2d2
i .
i i i i
We let S=ScellS Salg, where algis the set of points in Z(P). It remains to
bound I(Salg,L). We divide LasLcellL Lalg, where cellare the lines that intersect
some open cells, and Lalgare the lines contained in Z(P).
Each line of Lcellhasdintersection points with Z(P), hence dincidences
withSalg. Hence I(Salg,Lcell)Ld. Summarizing everything so far, we have the
following:
I(S,L)C(Ld+S2d2) +I(Salg,Lalg).
We will deal with the last term by induction. We will choose dL/2. So Lalg
contains L/2 lines. By induction,
I(S,/ /L2 3 2 3
alg alg )C0[S(L/2) + S+L/2].
Now we are ready to optimize over d. We need to choose dto be an integer between
1 and L/2. We choose dS2/3L1/3. Because of the bounds in equation (1), we
can nd dthis size in the range 1 dL/2. Plugging in, we get
I(S,L)CL2/3S2/3+C0[S2/3(L/2)2/3+S+L/2].
Finally, we choose C0large enough compared to C, and the whole right hand side
is bounded by C0[S2/3L2/3+S+L].
/square
2.The 3-dimensional version - outline of the ideas
We will prove (today and next lecture) the following 3-dimensional result, which
we can think of as a possible analogue of the ST theorem for lines in R3.
Theorem 2.1. IfSis a set of Spoints in R3andLis a set of Llines in R3with
at most Blines in any plane, then
I(S,L)C0[S1/2L3/4+L1/3B1/3S2/3+S+L].</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 USING (POLYNOMIAL) CELL DECOMPOSITIONS
I(, )/lessorsimilarB1/ /S L3 2
plana L1 3
r S/3+dL+S+L.
This estimate is ne, and it remains to bound I(Salg,Lalg\Lplanar). We will do
this using our tools about special points and lines in an algebraic surface  as in the
proof of the esimate on the number of 3-rich points. As in that lecture, we call a
point special if it is critical or at, and we call a line special if each point on the line
is special. A point xZ(P) is special if and only if a set of polynomials called SP
vanishes at x, and the polynomials in SPhave degree 3d.
One of the main tools in the special lines discussion is that there arent that many
special lines. The number of special lines in Z(P) which arent in any of the planes
is10d2. We will choose dso that 10d2L/2, and then we can control this term
by induction. We write Lalg=LspecL L nonspec where specare the special lines of
Lalg. Note that L Lplanar  spec. We just recalled that |Lspec\Lplanar| 10d2.
We have
I(Salg,L L al\L S L L Sg planar )I(alg,spec\planar) +I(alg,nonspec ).
We can control the rst term by induction as long as we choose 10 d2L/2. And
we will see that the second term is minor.
We write Salg=SspecSnonspec . Each non-special line contains at most 3d special
points, so
I(Sspec,Lnonspec )3dL.
On the other hand, if a point xZ(P) lies in three lines in Z(P), then we saw
thatxis a special point of Z(P). Therefore, each point of Snonspec is incident to le2
lines of Lalg. In particular, we get
I(S Lnonspec ,nonspec )2S.
Combining all the work so far, we see that
I(S,L)C[dL+d1/3S2/3L2/3+B1/3L1/3S2/3+S+L] +I(Salg,Lspec\Lplanar).
This inequality holds for any integer d1, and if 10 d2L/2, then the number
of lines in Lspec\Lplanar isL/2, and we can control that term by induction. We
optimize din this range, and we get the bound in the theorem.
(In the full proof, we have to be a touch more careful about some of the terms
because of the induction.)
Next lecture we will do the details.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>The Finite Field Nikodym and Kakeya Theorems (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec3/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>2 THE FINITE-FIELD NIKODYM AND KAKEYA PROBLEMS 
R vanishes for each t  F . It has degree  d &lt; q, and so its coeceints all vanish. 
In particular, its coecient of degree d vanishes. But the coecient of td in R is 
exactly Pd(a). So we see that Pd(a) vanishes for all a  F n \ {0}. But since the 
degree of Pd is d &lt; q, it easily follows that Pd vanishes at 0 also. Then we see that 
Pd is identically zero, and we reach a contradiction. D 
The Kakeya and Nikodym problems presented here are the analogues of deep open 
problems in Euclidean space. A Kakeya set K  Rn is a set which contains a unit 
line segment in each direction. For example, the ball of radius 1/2 is a Kakeya 
set. Besicovitch constructed surprising examples of Kakeya sets with arbitrarily 
small volume and even with measure 0. Besicovitchs construction works in each dimension n  2. Although his sets have measure zero, they all have full Hausdor 
dimension. The Kakeya conjecture is that every Kakeya set K  R
n has Hausdor 
dimension n. 
It can be hard to appreicate the polynomial method proofs without some back
ground trying to prove this type of result without it. We give two simple combinatorial estimates for the size of a nite eld Kakeya set K  F
qn . 
1. (Bush method) By pigeonholing, there is a point x  K which lies in at least 
qn/|K|lines of the Kakeya set. The union of all the lines of the Kakeya set thru a 
given point is called a bush. All of these lines are disjoint except at x. Therefore, 
the bush contains at least qn(q  1)/|K|points. Since the bush is contained in K, 
we see that |K| (1/2)q n+1 .2 
2. (L2-method, or just counting) Consider the lines of K one at a time. The rst 
contains q points. The second must contain at least q 1 points not in the rst. The 
third must contain at least q 2 points not in the rst two, etc. Therefore, the rst 
q lines must contain at least (1/ 2)q2 distinct points. So |K| (1/2)q2 . 
Both these methods only use the fact that two distinct lines intersect in  1 point 
and that a Kakeya set is the union of  qn1 distinct lines. In other words, we have 
not used the fact that the lines point in dierent directions! However, there are q2 
lines in a plane. In order to see that a Kakeya set in F3 must contain q2+ points, 
we need to use that the lines point in dierent directions in order to rule out the 
example that they all lie in a plane.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>THE FINITE-FIELD NIKODYM AND KAKEYA PROBLEMS 
These notes are rougher than I would like, but they still have some main proofs. 
Let F be a nite eld with q elements. A set N  F n is called a (generalized) 
Nikodym set, if for each point x  F n, there is a line L(x) containing x so that 
|L(x)N| q/2. A trivial example of a Nikodym set is the entire set F n . Can one 
nd a signicantly smaller Nikodym set? 
Theorem 0.1. (Dvir) Any (generalized) Nikodym set in F n contains at least cnqn 
elements. Proof. Let V (d) be the vector space of degree d polynomials in n variables with 
coecients in F . We pick a polynomial P (not identically zero) that vanishes on 
|N|
1/nN with degree  Cn . If this degree is &lt; q/2, then P must vanish at every 
point x  F n . But a polynomial of degree  q/2 cannot vanish at every point of F n 
unless it vanishes identically. We conclude that the degree of P is at least q/2 and 
so |N| Cn 1(q/2)n . D 
(We used the following lemma. A polynomial P in n variables over F of degree 
d &lt; q cannot vanish at every point of F n unless each coecient of P is zero. 
proof by induction on n. The case n = 1 appears in Lecture 2. dSuppose P vanishes at each point of F n . Write P (x1, ..., xn) = Pj(x1, ..., xn1)xd .j=0 n
For each particular choice of x1, ..., xn1, we know that P (x1, ..., xn) = 0 for all 
xn  F . Since d &lt; q , we see that the coecients Pj(x1, ..., xn1) must vanish for 
each j. Therefore Pj(x1, ..., xn1) = 0 for each (x 1, ..., xn1) F n1 . By induction, 
we see that the coecients of Pj all vanish. But then the coecients of P all vanish.) 
Dvir also proved a small variation which is a tiny bit harder than the proof above. 
A set K  F n is called a Kakeya set if it contains a line in every direction. In other 
words, for every vector a  F n \{0}, there is a vector b so that the line {at+b|t  F } 
is contained in K. A trivial example of a Kakeya set is the entire vector space F n . 
Can one nd a Kakeya set signicantly smaller than this? 
Theorem 0.2. A Kakeya set K  F n has at least cnqn elements. 
Proof. Let K be a Kakeya set. If K is smaller than the conclusion, let P be a 
polynomial vanishing on K of degree &lt; q. Letd be the degree of P . Write P = Pd+Q, 
where Pd is the sum of monomials of degree d and Q is a polynomial of degree  d1. 
Let a be any non-zero vector. Choose b so that the line {at +b|t  F }is contained 
in K. Consider the polynomial in one variable R(t) := P (at + b). The polynomial 
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Crossing Numbers and Distinct Distances (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec9/</lecture_pdf_url>
      <lectureno>9</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>3 CROSSING NUMBERS AND DISTINCT DISTANCES 
Our graph G  has crossing number at most  N2t2 . But by the theorem above, 
we have 
N2 2 k(G  )E3V2M1  N6N21/2t t . 
Rearranging gives t5/2 N2 and so t N4/5 as desired. 
D 
Building on the crossing number approach introduced by Sz ekely, Solymosi-Toth 
and then Katz-Tardos improved the estimates in the distinct distance problem. Katz-
Tardos proved that for any N points in the plane, one of the points determines 
 cN.864 distances with the other points. This approach gave the best estimate in 
the distinct distance problem before the polynomial method approach. 
Using the polynomial method we will prove that the number of distinct distances 
given by N points is  cN(logN)1 . However, this approach does not bound the 
number of distances from a single point. It looks completely plausible that for any N points in the plane, one of the points determines  cN(logN)
1 (or even  
cN(logN)1/2)) distances with the other points. This would be a better theorem if 
its true. 
2. What about three dimensions? 
In the last few sections, we have had a brief but substantial introduction to in
cidence geometry in two dimensions. What happens in three dimensions? We will brainstorm some questions below. Three dimensions are more complicated, there are more questions, and its less clear which are the fundamental questions. 
Question 1. Given S points and L lines in R
3, what is the maximum possible number 
of incidences? 
It turns out that this question is equivalent to the corresponding question in R2 . 
Since R2  R3, the maximum must be at least as big in two dimensions. But given 
an arrangement of points and lines in R3, we can project to a generic plane. The 
projection gives S distinct points and L distinct lines in the plane, and it has at least 
as many incidences. To try to make the question more interesting, we may bound 
the number of points or lines in a plane. For example, we may consider the following question. 
Question 2. Given S points and L lines in R
3, with  B lines in any plane, what 
is the maximum possible number of incidences? 
Besides points and lines, R3 also contains planes. We can try to make similar 
incidence questions also using planes.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 CROSSING NUMBERS AND DISTINCT DISTANCES 
Question 3. Given S points and P planes in R3, what is the maximum possible 
number of incidences? 
This question has a simple answer. Take all P planes containing a line l, and all S 
points in l. Then the number of incidences is SP, which is the maximum possible. To 
try to make the question more interesting, we may rule out this example by bounding 
the number of planes containing any line. 
Question 4. Given S points and P planes in R3, with the restriction that any line 
lies in  B of the planes, what is the maximum possible number of incidences? 
(I dont know the answer to this question... it may be open.) 
We can combine lines and planes. 
Question 5. Given L lines and P planes in R3, what is the maximum possible 
number of pairs (l, )where the line l is contained in the plane ? 
By duality, this question is equivalent to question 1, and so it is answered by the 
Szemer edi-Trotter theorem (up to a constant factor). 
We may then combine points, lines, and planes: 
Question 6. Given S points, L lines, and P planes in R3, what is the maximum 
possible number of triples (p, l,  )with the point p in the line l in the plane ? 
(I dont know the answer to this question... it may be open.) We will come back to question 2 later on, using the polynomial method. The 
Szemer edi-Trotter theorem plays a central and fundamental role in two dimensions. There may not be any one result in three dimensions which is so central. And there 
are denitely many more questions besides the ones listed here.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>CROSSING NUMBERS AND DISTINCT DISTANCES
 
The Szemer edi-Trotter theorem plays a fundamental role in incidence geometry in 
the plane. It can be rephrased in several equivalent ways, and it helps to know the 
dierent ways. We recall three standard phrasings here. 
If S is a set of points and L is a set of lines (or curves), recall that the set 
of incidences I(S,L) = {(p, l)  S  L|p  l}. We now give three versions of 
Szemer edi-Trotter. 
Version 1. If S is a set of S points in the plane, and L is a set of L lines in the 
plane, then the number of incidences is bounded as follows: 
|I(S,L)| C(S2/3L2/3 + S + L). 
Version 2. Suppose that L is a set of L lines in the plane, and let Pk be the set of 
points that lie on  k lines of L. 
Then |Pk| C(L2k3 + Lk1). 
Version 3. Suppose that S is a set of S points in the plane, and let Lr be the set of 
lines that contain  r points of S. 
Then |Lr| C(S2r3 + Sr1). 
In an earlier lecture, we proved Version 2 using the crossing number theorem. With 
tiny modications, the same argument proves any version of the theorem. Also, any 
version above implies any other version by a short counting argument. 
1. Distinct distances 
Theorem 1.1. (Sz ekely) If we have N distinct points in the plane, then they deter
mine  cN4/5 distinct distances. In fact, there is one point p in the set so that the 
distance from p takes  cN4/5 distinct values. 
Proof. Suppose that for each point pin our set S, the set of distances {dist(p, q)}qS 
takes on  t dierent values. We assume t  cN4/5 and we will get a contradiction. 
We can choose Nt circles so that each point of the set lies in N 1 circles. We draw 
all these circles, leaving out circles with  4 points. We make a multigraph G whose 
vertices are the points of S and whose edges are arcs between consecutive points on 
one of the circles. 
This multigraph has V = N vertices. It has E  (1/2)N2 edges. (Before removing 
unpopular circles, it would have N2 N edges. We removed edges that were on the 
1</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 CROSSING NUMBERS AND DISTINCT DISTANCES 
unpopular circles, but these circles contribute a total of  4Nt  (1/200)N2 edges.) 
It has crossing number  2(Nt)2, because a pair circles intersects in  2 points. 
The multigraph Gmay have very high multiplicity. Our strategy will be to estimate 
how many high-multiplicity edges G can have, and trim edges from G to reduce the 
multiplicity. 
Lemma 1.2. The number of edges of Gwith multiplicity  M is at most C[N2M2t+ 
N logNt]. 
Proof. Consider edges from a vertex p1 to a vertex p2. Each edge is the arc of a 
circle, and the center of the circle must lie on the perpendicular bisector of p1 and 
p2. If there are many edges from p1 to p2, then there must be many points of our set 
along the perpendicular bisector. 
We dene a map from edges of our multigraph to lines, sending an edge to the 
corresponding perpendicular bisector. A line containing A points of S contributes 
 2At edges of the multigraph, each with multiplicity  A. 
Let Lj denote the set of lines in the plane which contain  2j points of S. (More 
precisely, the number of points is greater than 2j1 and at least 2j.) The number of 
edges with multiplicity at least M is bounded by 
|Lj|2 2jt. 
2j M 
The size of Lj is bounded by the Szemer edi-Trotter theorem (see Version 3 above). 
Plugging in, we get: 
 C(N223j + N2j)2j t. 
2j M 
The N223j term decays exponentially in j, and the total is  CN2M2t. The 
second term is independent of j, and we need to sum over  logN values of j, so 
the total is  CN logNt. D 
We choose M = t1/2 for a large constant . By choosing  large enough, we 
can arrange that the number of edges of multiplicity  M is at most (1 /10)N2 . 
We let G   G be the multigraph given by deleting all edges of G with multiplicity 
 M. The graph G  still has  (1/3)N2 edges, and it now has multiplicity at most 
t1/2M &lt; . 
Now we apply the crossing number theorem for multigraphs. We recall the state
ment from last lecture. 
Theorem 1.3. (Crossing number estimate for multigraphs) If G is a multigraph with 
V vertices and E edges and with multiplicity  M, and if E  100MV, then the 
2M1crossing number of G is at least cE3V .</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>The Kakeya Problem (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec33/</lecture_pdf_url>
      <lectureno>33</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 THE KAKEYA PROBLEM
2.bush argument and hair brush argument
Bush argument: We have |K|n+1/greaterorsimilarq2for a Kakeya set KFn
qand| Ti|/greaterorsimilar
n+1N2for a Kakeya set of tubes TiRn
We have already seen how Bush argument works in the nite eld case.
For the tube version the similar argument works too.
Suppose |Ti|is small, then there must be a point that is covered by many
tubes. Those tubes might have a large overlapping area around that point,
but if we consider what happens in a distance ofN
10from that point, then we
see the volume of the bush is bigger than N(the number of tubes in the bush)
Hair Brush argument: We have |K|n+2/greaterorsimilarq2for a Kakeya set KFn
qand
| Ti|n+2/greaterorsimilarN2for a Kakeya set of tubes TiRn
In the nite eld case, this argument goes like to choose the line that has
the biggest number of intersection with other lines and consider all lines that
intersect it. This will give us the bound. However it is much trickier to get
the bound for the tube version: when we consider what happens in a distance
ofN
10from our chosen tube, it turns out that tubes that have small angle to
the chosen tube might not even make it out that distance. It is possible,
though not easy, to rule out such cases and get the desired bound as was
shown by Thomas Wol in the 90s.
In 3D, the Hair Brush argument gives | Ti|5/greaterorsimilarN2. It is surprisingly hard to
improve this bound. Katz-Laba-Tao, under a minor assumption about K, improved
the bound to something like5 0+101N2 . Being stuck at this point, Thomas Wol
proposed some toy problems:
Finite eld Kakeya problem. People think that passing from RntoFn
qmight
make the problem a little bit easier while still preserving some of the avor,
as is shown in the hair brush argument.
Instead of considering tubes in dierent directions, we can take annuli with
thickness1
Nand radii between 1 and 2. In order to solve that, he used
incidence geometry, stu related to Szemer edi-Trotter theorem. That was
cool because it brought a whole dierent set of techniques to this area, so
people in harmonic analysis learned about this area of mathematics.
3.polynomial method for tube version kakeya problem
Since we have already seen the elegant proof of nite eld Kakeya problem us-
ing polynomial method, can we say anything about the tubes by using polynomial
method?</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>THE KAKEYA PROBLEM 3
Let us recall the main ideas we used when we solved the nite eld Kakeya problem:
(1) Look at the polynomial Pthat vanishes on K with smallest degree. The
degree would be signicantly smaller than q.
(2)Pmust vanish at some other places, then we have contradiction.
Now let us see what happens for tubes. Suppose Kis a Kakeya set of 1 Ntubes
TRn,|K|=Nni . Here are some ideas:
Look at the polynomial P that vanishes at all core lines with smallest degree.
But those lines can be all disjoint. Even if they are not, we can make a small
perturbation to make them so.
Look at the polynomial P that vanishes on Ti. Then P= 0 on the innite
surfaces. But the degree of Pwould be very big.
Instead of vanishing, Pis just small on Ti, with some normalization.
Z(P) bisects each tube. If it does it by cutting tubes at their mid-points,
then there is not much information. We would like it to cut tubes along their
core lines, but it seems that by requiring so we are putting innitely many
conditions on our polynomial.
Z(P) bisects each lattice cubes with size1
100that overlaps our tubes. The
polynomial ham sandwich theorem allows us to nd one with degree /lessorsimilarN1n.
Now our question is: does such a polynomial necessarily bisect some other
cubes?
We will see what we should do next in the last class on Wednesday.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>THE KAKEYA PROBLEM
In this lecture, we will discuss Kakeya Conjecture and some known results about
it.
Denition Suppose that TiRnare tubes of length Nand radius 1. {Ti}is a
Kakeya set of tubes if {V(Ti)}is1
N-separated and2
N-dense in Sn1, where V(Ti) is
the unit vector of direction of the tube Ti.
Our question is: how small can | Ti|be?
Recall that last time we gave the Besicovitch arrangement of tubes where we
managed to compress the volume of Tiby a factor of log N. We got that arrange-
ment by translating the tubes in a certain way, without performing any rotation. We
want to know whether there is a better compression.
Kakeya Conjecture (tube version). For any Kakeya set of tubes TiRn,| Ti|/greaterorequalslant
CNn( &gt;0 ).
We also have:
Kakeya Conjecture (segment version). For any Kakeya set K(a set of points that
contains a unit line segment in every direction) in Rn, H-dim(K )/greaterorequalslantn, where
H-dim( K) is the Hausdor dimension of Kandis any positive number.
Notice that the segment version will imply the tube version. The tube version has
a combinatorial avor since it involves how tubes can overlap each other.
1.the 2D case
Proposition . The Kakeya Conjecture(tube version) is true in dimension two.
Now we sketch the proof here. The avor is similar to the nite eld Kakeya
problem.
We denote by ithe angle between V(Ti) and the x-axis. Then the overlapping
area of T1andT1
2can be bounded by12. Then we get|  |/integraltext
|/summationtextTi|2=/summationtext /summationtext/integraltext
TiTj=/summationtext /summationtext|TiTj|/lessorsimilar|logN|N2
By Cauchy-Schwarz inequality, we have N2=/integraltext
(/summationtextTi)/lessorequalslant(/integraltext
|/summationtextT|2)1
2i | Ti|1
2.
Thus | Ti|/greaterorsimilarN2(logN)1.
Conjecture (Lpversion)./integraltext
|/summationtext|p/lessorsimilarNTi (what happens if all tubes are centered at zero)
This will imply the Kakeya Conjecture(tube version) by a similar argument.
1</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Taking Stock (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec16/</lecture_pdf_url>
      <lectureno>16</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>4 TAKING STOCK
prove Theorem 0.1, which holds as long as the number of 3-rich points is at least a
large constant times L3/2. Its actually not clear what happens below this threshold
(i.e. for B &lt; L1/2in the statement of the theorem). The polynomial method (as weve
been using it) stops working, but I dont know any examples with P3signicantly
larger than BL.
2.The big picture
We have mostly been talking about estimates for the incidences of lines in R2
orR3. We can usually begin on any given problem by thinking about basic facts
about incidences, such as two points lie on a unique line. These facts lead to
some basic estimates, but in many cases the basic estimates are far from sharp. To
improve them, we need some subtler facts about lines. We have followed two main
approaches.
(1) Use the topological structure of Euclidean space. This approach leads to the
crossing number lemma, the Szemer edi-Trotter theorem, and other applica-
tions.
(2) Use the algebraic structure of Euclidean space. This approach leads to the
joints theorem and Theorem 0.1 above.
How can we recongnize/guess which tool is good for which problem? In the case of
the Szemer edi-Trotter theorem, the need for topological considerations is motivated
by the example of lines in nite elds. The Szemer edi-Trotter theorem fails badly if
we let Lbe the set of all lines in F2
q. Finite elds have most of the algebraic structure
that we see in R2, but theyre very dierent topologically.
Its less clear to me how to recognize the need for algebraic structure. For example,
I still nd it kind of surprising that there is not a very dierent proof of the joints
theorem - and such a proof may indeed exist. I think one can probably demonstrate
that these theorems dont follow just from incidence axioms. (Of course Szemer edi-
Trotter also does not follow just from incidence axioms.) In practice, if a certain
question seems similar to the joints theorem or nite eld Kakeya..., then its a can-
didate for the polynomial method. Also, if its possible to do some degree reduction,
then the problem is a good candidate for the polynomial method.
So far, these two techniques have been complementary. We cant prove the Sze-
mer edi-Trotter theorem with just the polynomial method. If we try to nd a low-
degree polynomial on the points, then we get a degree which is larger than the number
of points on each line, and then we cant do anything with it. If we try to nd a
low degree polynomial that vanishes on the lines, since we are in the plane, we just
get a degree L polynomial and it doesnt lead to any interesting information about
the points. There is no possibility of doing degree reduction  any set of L lines in</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>TAKING STOCK
In todays lecture, we are going to take stock of where weve come from and discuss
where were going. What were the diculties in the problems? What were the main
things we learned? What is the next challenge?
In the last lecture, we proved the following theorem about 3-rich points for sets of
lines in R3:
Theorem 0.1. LetLbe a set of Llines in R3withBlines in any plane. If
BL1/2, then |P3(L)|/lessorsimilarBL.
The proof involved three tools that we developed ahead of time: at points and
lines, degree reduction, and Bezouts theorem. Putting it all together, it is the longest
proof we have studied so far in this course. I want to take a little time to put it in
context more. Well look at some examples. Also, well try to describe the nature of
the diculty in proving the theorem. Why does it take this much work to prove the
theorem?
We begin with a simple example. A collection of Blines in a plane can have B2
3-rich points. For example, we can take a grid with B/3 evenly spaced vertical lines,
B/3 evenly spaced horizontal lines, and B/3 evenly spaced diagonal lines. In this
grid, we get B2/20 3-rich points. Next, if we choose L/Bgeneric planes, and put
Blines in each plane, we get an arrangement of lines with BL3-rich points. We
can arrange that there will be Blines in any plane by taking each conguration
ofBlines and rotating and translating it generically.
1.What makes the theorem hard?
To get a feel for the diculty, lets consider the following much weaker corollary.
Proposition 1.1. Suppose that Lis a set of Llines in R3withL1.993-rich points.
Then, there is a plane that contains 3lines of L.
To prove the proposition, the key question is how can we nd this plane? Lets
mention one possible way of nding a plane with three lines in it. Let us look at the
incidence matrix of P3(L) with L. If we nd a triangle in the incidence matrix,
then we automatically get three lines in a plane. A triangle is a set of three lines
l1, l2, l3L, and three points x1, x2, x3P3so that each line contains exactly two
of the three points. In this case, the points x1, x2, x3lie in a unique plane which
contains all three lines.
1</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>TAKING STOCK 5
the plane has degree exactly L. This may suggest that the polynomial method is not
well suited to study questions about lines in the plane.
On the other hand, the topological methods have had only limited success in
proving estimates for the joints problem. The basic issue is that curves in R3do not
divide space into components, and so the whole set up is totally dierent. There
are papers using the topological approach to prove interesting estimates about the
joints problem  the best estimate proven this way is something like JL1.62.... The
method involves taking lines or curves in space and projecting them onto planes, and
then using the crossing number lemma to study the projections. It seems dicult
to capture all the 3-dimensional structure that were interested in with these two-
dimensional projections...
So we have studied two methods. They are useful in dierent situations  in some
sense they deal with dierent diculties. However, there are problems that involve
both types of diculties.
3.The next goal
Our next goal is the following theorem. It was conjectured by Elekes and Sharir
and proven by Katz and G.
Theorem 3.1. Suppose that Lis a set of lines in R3withL1/2lines in any plane.
Suppose that 3kL1/2. Then |Pk|/lessorsimilarL3/2k2.
This theorem involves both types of diculties. For large values of k, it is false
over nite elds. In particular, let us consider the set of all lines in F3
q. We have
|L| q4. The number of lines in each plane is q2L1/2. Each point lies in q2
lines. Therefore, taking k=q2L1/2, we have |P|=q3L3/2k3/2k . We see
indeed that our theorem is false over nite elds. The example is reminiscent of the
Szemer edi-Trotter theorem, and it suggests we need to use the topological structure
ofR3. If we try to adapt the algebraic proof of Theorem 0.1 to large k, then the
method gives the upper bound |Pk|/lessorsimilarL3/2k3/2, matching the example in nite
elds. Moreover it looks plausible that the proof of Theorem 0.1 can be extended to
nite elds, and that the same results hold there.
On the other hand, if we look for a purely topological proof, it seems hard to prove
the case k= 3 that we already proved with the polynomial method.
Our next goal is to prove this theorem by combining the polynomial method and
the topological method.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>TAKING STOCK 3
Its probably best at this moment to draw your own picture. But for completeness,
we write down the details. Suppose that x1is the lower-left vertex, x2is the right
angle, and x3is the upper-right vertex. We have ( a2, b2) = (a 1, b1+d). And (a 3, b3) =
(a2+e, b2). But because the diagonal line is at a 45 degree angle, we see that the
triangle is isosceles and so e=d. A short computation shows that a1+b1, a2+
b2, a3+b3make a 3-term arithmetic progression. /square
Therefore, we probably need a dierent idea to locate a plane with three lines in it.
We can formulate this issue more precisely using the axioms of incidence theory (for
points, lines, planes in three dimensions). In these axioms, we have a set of points,
and each line or plane is a subset of the points, and the whole structure obeys a list
of axioms. We dont give the whole list of axioms here, but we give the avor by
mentioning two examples. 1. For any two points, there is a unique line containing
the two points. 2. If three points dont all lie on a line, then there is a unique
plane containing the three points. Etc. Now we may ask whether Theorem 0.1 or
Proposition 1.1 hold more generally in the axioms of incidence theory. I believe that
the answer is no and that Suks construction can be modied to prove the following
Conjecture 1.4. Fix any  &gt;0. Then for arbitrarily large numbers L, the following
holds: there is a set of points, lines, and planes obeying the incidence axioms, and a
subset Lof the lines, so that |L|=L,|P(L)| L23 and yet each plane contains
2lines of L.
Theorem 0.1 depends on some other structure about lines in R3which is not
captured in the incidence axioms. What structure is it? Our proof is based on
algebraic structure.
Theres a fairly short proof of Proposition 1.1 using reguli. If LhasL1.993-rich
points, then it follows from Problem Set 2 that there is a regulus or plane containing
/greaterorsimilarL.99lines of L. Since the lines inside a regulus cannot make any 3-rich points,
its not too hard to push a bit farther and prove that there is a plane containing
/greaterorsimilarL.99lines of L. Reguli provide an additional structure which is not included in the
incidence axioms. Basically this structure amounts to including degree 2 surfaces as
well as planes.
The technique of reguli cannot easily push all the way down to L3/23-rich points.
To try to nd a regulus with many lines, we can look at the intersection matrix of
the lines of L. If this matrix has a 3 Aminor of all 1s, then we can nd Alines
which lie in a common plane, lie in a common regulus, or pass through a common
point. But by Browns construction, the intersection matrix may have no 3 3 minor
of all 1s and still have L5/31s. Its hard to rule out that we may have L5/33-rich
points points but the intersection matrix may have no 3 3 minor of all 1s.
In our proof with the polynomial method, we include in the story not just surfaces
of degree 2 but surfaces of all degrees. With this algebraic structure, we are able to</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 TAKING STOCK
We can try to nd a triangle in the incidence matrix. What do we know about the
incidence matrix. By hypothesis, it has dimensions LPwithPL1.99, and each
point lies in at least three lines. Also, any two lines intersect in at most one point.
Just based on this information, does the matrix need to have a triangle? The answer
to this question is no. It comes from an interesting example that was explained to
me by Andrew Suk.
Proposition 1.2. Fix any  &gt;0. For all suciently large L, we can nd a set Lof
Llines in R2R3and a set of 3-rich points PP(L)so that |P| L23 and yet
the incidence matrix of PandLcontains no triangle.
The construction is based on an important example of Behrend about 3-term arith-
metic progressions. Recall that an arithmetric progression of length ris a sequence
of numbers a, a+d, a+2d, ..., a +(r1)d. Behrends example is concerned with the
question, how large is the largest subset of the integers from 1 to N with no 3-term
arithmetric progression?
Theorem 1.3. (Behrend, 1946) Fix any  &gt;0. For any Nsuciently large, there is
a subset of [1...N]withN1elements and with no 3-term arithmetic progression.
Well discuss Behrends construction some time later... Using it, we now give the
proof of Proposition 1.2.
Proof. We describe the lines and the points. The lines are vertical, horizontal, and
diagonal lines in a grid. We take vertical lines x=afora= 1...S. We take horizontal
linesy=bforb= 1...S. And we take diagonal lines xy=cforc=S, ..., S . We
have a total of L= 4S+ 1 lines. We let Xdenote the SSgrid of lattice points
{(a, b)Z2|1a, bS}. Each point of Xlies in exactly three lines of L. The set
Xis the set of all 3-rich points of L. It has size S2L2, but the incidence matrix of
XwithLcontains many triangles. We will pare down Xslightly to a subset PX
so that the incidence matrix of PwithLcontains no triangles. The key idea of the
proof is that Behrends construction lets us do this paring.
By Behrends construction, we can nd a subset P0[S/2, ...,3S/2] so that |P0| 
S1and yet P0contains no 3-term arithmetic progression. We dene the set P:=
{(a, b)X|a+bP0}. For each d[S/2, ...,3S/2], the set of (a, b )Xso that
a+b=dhasS/2 elements, and so |P| (1/2)S2cL2.
Consider a triangle in the incidence matrix of XandL. The horizontal lines are
pairwise disjoint, as are the vertical lines and the diagonal lines. Therefore, the
triangle must consist of one horizontal line, one vertical line, and one diagonal line.
Letxi= (a i, bi)Xbe the vertices of the triangle. We have to show that the three
vertices are not all in P. It suces to show that di=ai+biform a 3-term arithmetic
progression. This follows by the geometry of the triangle.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>The Berlekamp-Welch Algorithm (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec2/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>THE BERLEKAMP-WELCH ALGORITHM
Suppose that we have a polynomial Pof fairly low degree over a nite eld F. The
data is corrupted, leaving a function F:FF, and we know that F(x) =P(x)
for a certain fraction of xF. We want to understand whether we can recover P
fromFwith an ecient algorithm. In particular, our main goal is to explain the
Berlekamp-Welch algorithm. We present here the following case of the Berlekamp-
Welch result. (Were not trying to be as general as possible, but just to get a avor
of the subject and see the key ideas in the proof.)
Theorem 0.1. (Berlekamp-Welch, 1986) Suppose that
Fhasqelements,
the degree of Pis&lt; q/100, and
F(x) =P(x)for at least (51/100)q values of x.
Under these assumptions, there is an ecient algorithm to recover PfromF.
The ideas depend on the following elementary but fundamental vanishing lemma
for polynomials.
Lemma 0.2. IfP(x)is a polynomial of degree D, andPvanishes at D+1distinct
points, then Pis the zero polynomial.
We will recall the proof of this lemma later in the lecture.
One application is that a polynomial Pof degree Dcan be recovered if we know
its values at any D+1 points. Let Sbe a set of D+1 points, S={x F 1, ..., x D+1}  .
LetV1(D) be the vector space of polynomials in one variable of degree D. Consider
the evaluation map ESwhich evaluates a given polynomial at the points of S:
ES(P) := (P (x1), ..., P (xD+1)).
The evaluation map ES:V(D)DF+11 is a linear map. By the vanishing lemma,
the kernel of ESis zero. Since the domain and range have the same dimension,
ESis an isomorphism. Therefore, Pcan be recovered from its values on the set S.
Moreover, recovering Pamounts to solving a system of linear equations, so it can be
done eciently.
There are at least (51/ 100)q points xwhere F(x) =P(x). If we knew which points
they were, we could recover Pby this interpolation procedure, because the degree
ofPis&lt; q/100. The whole point is that we dont know where Fis still correct and
where Fhas been corrupted.
1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 THE BERLEKAMP-WELCH ALGORITHM
With the same proof idea, we can prove a simple divisibility lemma for polynomials
in two variables.
Lemma 2.2. IfR(x, y)is a polynomial of two variables, and P(x)is a polynomial in
one variable, and R(x, P(x))is the zero polynomial, then R(x, y) = (y P(x))R1(x, y)
for some polynomial R1.
Proof. LetR(x, y) =/summationtextD
j=0aj(x)yj, where aj(x) is a polynomial in x. Now, we can
write any polynomial R(x, y) in the following form:
R(x, y) = (y P(x))(bD1(x)yD1+...+b0(x)) +r(x),
where the bj(x) and r(x) are polynomials in x. The proof is basically the same as
above. First we choose the polynomial bD1(x) in order to get the yDterm correct.
None of the lower coecients inuence the yDterm, so we are still free to choose
them. Next, we choose bD2to get the yD1term correct, etc. We choose b0to get
theyterm correct, and we choose rto get the units term correct.
ButR(x, P(x)) isr(x), sor(x) is the zero polynomial. This gives the required
factoring of R(x, y). /square
As a corollary, we can quickly prove the last claim about the polynomial R(x, y) in
the Berlekamp-Welch algorithm. We know that R(x, P(x)) is the zero polynomial,
soR(x, y) = (y P(x))R1(x, y). Because R(x, y) has degree 1 in y, it follows that
R1must have degree 0 in y: in other words, R1=R1(x) is a polynomial in xonly.
SoR(x, y) = (y P(x))R1(x). At each eE,R(x, F(x)) vanishes, but F(x)P(x)
doesnt, and so R1(e) = 0. Using the divisibility lemma in one variable, we see that
R(x, y) = (y P(x))/producttext
eE(xe)R2(x). Any polynomial of this form vanishes on
the graph of F. Since Ris a polynomial of minimal degree, it follows that R2(x) is
just a constant c= 0.
Our last divisibility lemma is closely related to Bezouts theorem. The formulation
of the last lemma depended on the special form of the polynomial yP(x), but
Bezouts theorem says something similar about two arbitrary polynomials. Here is
one formulation of Bezouts theorem.
Theorem 2.3. Suppose that P(x, y)andQ(x, y)are polynomials. Let Z(P, Q)be
the set of common zeroes of PandQ. In other words,
Z(P, Q) :={(x, y)F2|P(x, y) =Q(x, y) = 0}.
Then either
(1)Z(P, Q)has at most (degP )(degQ )points, or
(2)PandQhave a non-trivial common factor. In other words, P=R(x, y)P1(x, y)
andQ=R(x, y)Q1(x, y)for some polynomial R(x, y)with degree 1./ne}ationslash</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>THE BERLEKAMP-WELCH ALGORITHM 5
This is an important theorem that we will prove and discuss more during the
course. With a little extra trick, it recovers the last divisibility theorem as a special
case. Its an interesting problem to try to prove the Bezout theorem by generalizing
the last proof.
The arguments above are also related to the proof that there is unique factorization
in the ring of polynomials F[x1, ..., x n] for any number of variables.
3.Correcting polynomials from badly corrupted data
In the Berlekamp-Welch algorithm, we considered corrupted data Fwhich was
correct a little more than half the time. If Fis correct only half the time, then its
impossible to recover the polynomial Peven in theory. For example, start with two
low degree polynomials P1andP2, and arrange for Fto agree with P1half the time
and with P2half the time. There is no way to tell if the original polynomial was P1
orP2. Following this observation, it may seem that data Fwhich is correct only 1
% of the time would not be very useful. Surprisingly, it turns out that a great deal
of information can be recovered from such data. In the mid 90s, Sudan generalized
the algorithm of Berlekamp-Welch to deal with highly corrupted data. For example,
he proved the following result.
Theorem 3.1. (Sudan, 1997) Suppose that Fis a eld with qelements, and that F:
FFis any function. There is an ecient algorithm that lists all the polynomials
of degree (1/200)q1/2that agree with Fat least 1 % of the time.
We have the tools to follow most of the steps of Sudans argument. We again
consider the graph of FinF2. We nd a low-degree polynomial Q(x, y) that vanishes
on the graph. This time we consider all the polynomials of two variables. If we let
V(d) be the space of polynomials in two variables of degree d, then the dimension
ofV(d) is/parenleftbigd+2/parenrightbig
. The graph of Fhasqelements. As long as/parenleftbigd+2
2 2/parenrightbig
&gt; q, we can nd
a polynomial Q(x, y) of degree dthat vanishes on the graph. So we can nd a
non-zero Qwith degree d2q1/2.
Suppose that Phas degree (1/200)q1/2, and that P(x) =F(x) for at least
q/100 values of x. We claim that Q(x, P(x)) is the zero polynomial. This follows
for the same reason as above. We know that Q(x, F(x)) is zero for every x. So
Q(x, P(x)) has at least q/100 zeroes. But Q(x, P(x)) is a polynomial of degree at
most (degQ )(degP )&lt;2q1/2(1/200)q1/2=q/100. Therefore Q(x, P(x)) is identically
zero.
By the divisibility lemma in the last section, we see that yP(x) divides Q(x, y).
There is a polynomial time algorithm that factors Qinto irreducible factors. This
step is not at all obvious, and it requires dierent ideas. Now we can recover all the
good polynomials Pby examining the factors of Qfor factors of the form ( yP(x)).</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 THE BERLEKAMP-WELCH ALGORITHM
1.The algorithm
Now we turn to the algorithm. We will consider the graph of F. To set conventions,
the graph of Fis the set
{(x, y)F2|y=F(x)}.
We are hoping to nd some nice algebraic structure hidden in the graph of F. To
do so, we will nd a low degree polynomial R(x, y) which vanishes on the graph of
F. It turns out to be a good idea to consider polynomials of the form R(x, y) =
R0(x) +R1(x)y. We may/will talk more about this choice later. Lets dene W(d)
to be the vector space of polynomials of the form R0(x) +R1(x)ywhere R0andR1
have degree d. The dimension of W(d) is 2d+ 2. The graph of Fhasqelements.
As long as 2d + 2&gt; q, there is a non-zero polynomial in W(d) which vanishes on
the graph of F. In particular, there is such a polynomial of degree dq/2. Finding
such a polynomial just involves linear algebra, so we can nd it in polynomial time.
In fact, with a little more work we can nd a polynomial that vanishes on the graph
ofFof minimal degree. Let us dene R(x, y) to be a lowest-degree polynomial of
the form R(x, y) =R0(x) +R1(x)ythat vanishes on the graph of F. We know that
the degree of R0andR1isq/2.
The key observation in the whole argument is that Ralso vanishes on the graph
ofP.
Claim 1.1. The polynomial Rvanishes on the graph of P. In fact, R(x, P(x))is
the zero polynomial.
Proof. We know that Rvanishes on the graph of F.
Therefore, R(x, F(x)) = 0 for all x.
Since F(x) =P(x) for most x, we see that R(x, P(x)) = 0 for at least (51 /100)q
values of x.
NowR(x, P(x)) =R0(x) +R1(x)P(x) is a polynomial in xof degree &lt; q/2 +
q/100 = (51 /100)q. By the vanishing lemma, this polynomial is identically zero. /square
We can now describe how to recover the polynomial P. We just proved that
R0(x) +R1(x)P(x) is the zero polynomial. In other words, R1(x)P(x) =R0(x).
SoR0is divisible by R1, and Pis equal to R1/R0.
This nishes the BW algorithm, but its interesting to explore a little more about
the minimal degree polynomial R(x, y).
We let EFbe the set {eF|F(x) =P(x)}. We call Ethe set of error locations.
It turns out that the zero set of Ris exactly the graph of Ptogether with a vertical
line{x=e}for each error location e. (Picture?)
Claim 1.2. For each eE,R(x, y)vanishes on the line x=e./ne}ationslash</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>THE BERLEKAMP-WELCH ALGORITHM 3
Proof. FixeE. We consider R(e, y) =R0(e) +R1(e)y. We want to prove that
R(e, y) is the zero polynomial in y- in other words that R0(e) =R1(e) = 0. We
know that R(e, F(e)) = 0 and R(e, P(e)) = 0. Since F(e) =P(e), we see that the
linear polynomial R0(e) +R1(e)yvanishes at two dierent values of y. So the linear
polynomial must vanish. /square
In fact, we can say exactly what the minimal degree polynomial R(x, y) is.
Claim 1.3. R(x, y) =c[yP(x)]/producttext
eE(xe), for some non-zero constant cF.
From this last claim it follows that Rvanishes exactly on the graph of Ptogether
with the vertical lines at the error locations. From this information, we can easily
identify the set E, giving another way to recover the polynomial P.
The proof of this claim involves a fundamental idea/argument. The argument rst
appears in the proof of the vanishing lemma, so we begin by giving this proof. Then
we develop the idea a bit further to prove a divisibility lemma which leads to the
claim.
2.Vanishing and divisibility lemmas
Vanishing lemma. IfP(x) is a polynomial of degree D, andPvanishes at D+1
distinct points, then Pis the zero polynomial.
Proof of the vanishing lemma. We go by induction on D. The case D= 0 is
trivial. The heart of the matter is in the following divisibility lemma.
Lemma 2.1. IfP(x)is any polynomial and P(x1) = 0 for some x1F, then
P(x) = (x x1)P1(x)for some polynomial P1.
Proof. Suppose P(x) =/summationtextD
j=0ajxj. We can write any degree Dpolynomial Pin the
following form:
P(x) = (x x1)(bD1
D1x+...+b0) +r.
To see this, rst we choose the coecient bD1in order to get the xDterm correct.
None of the lower coecients inuence the xDterm, so we are still free to choose
them. Next, we choose bD1D2to get the xterm correct, etc. We choose b0to get
thexterm correct, and we choose rto get the units term correct.
But now, since P(x1) = 0, we must have r= 0, and our factoring is done. /square
We return to the vanishing lemma. Suppose that Pvanishes at x1, ..., x D+1distinct
points. By the divisibility lemma, we see that P(x) = (x x1)P1(x), where P1(x)
has degree D1. But P1must vanish at x2, ..., x D+1. By induction, P1= 0, and
we are done. This nishes the proof of the vanishing lemma./ne}ationslash</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Besictovitch&#8217;s Construction (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec32/</lecture_pdf_url>
      <lectureno>32</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Bezout Theorem (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec13/</lecture_pdf_url>
      <lectureno>13</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>2 BEZOUT THEOREM
IfXZ(P, Q  ), then Iis in the kernel of EX, and so we can think of EXas a
map from StoFcn(X,F). IfXZ(P, Q) is nite, then EXis surjective, and so
dimS  |X|. /square
Our goal is to bound the dimension of Sby (degP )(degQ ). In order to do this,
we will mod out by Pand then by Q, and keep track of dimensions of the objects
at each step.
LetIbe the ideal of F[x, y] generated by P. Let R=F[x, y]/I. The dimensions
ofRandIare both innite, but we can get valuable information by considering
polynomials of degree d. Let VdF[x, y] be the polynomials of degree d. Let
Id=IVd, and let Rd=Vd/IdR. We will consider the dimensions of these spaces
as functions of d.
The dimension of Vdis/parenleftbigd+2
2/parenrightbig
, as we have seen.
Lemma 1.3. The dimension of IdisdimVdD+2
dD=2for all dD.
Proof. Multiplication by Pgives a linear map from/parenleftbig
Vd/parenrightbig
DtoId. We claim this linear
map is an isomorphism. The kernel of the map is zero. Any element in Idcan be
written as PQfor some Q, and we must have degQ dD, so that the map is
surjective. /square
The dimension of RdisdimV ddimI d=/parenleftbigd+2
2/parenrightbig

fordD./parenleftbigdD+2
2/parenrightbig
=Dd+ (3/2DD2),
Now let Jbe the ideal of Rgenerated by Q. Let S=R/J, and note that this is
the same ring Sdened above. Let Jd=JRdandSd=Rd/Jd.
Lemma 1.4. The dimension of JdisdimR dE.
Proof. Multiplication by Qgives a map from RdEtoJd. We claim that this map
is injective. Suppose r1RdEis in the kernel of the map. Let P1VdEbe
a polynomial representing r1. We see that QP1is inI, soQP1=PP2for some
polynomial P2. By unique factorization, we see that Pdivides P1. But then P1I
andr1= 0. /square
(Exercise: Do we get equality in this lemma?)
The dimension of SdisdimR ddimJ ddimR ddimR dE. IfdD+E, then
dimR dimR =Dd+ (3/2DD2 2
d dE )D(dE) + (3/2DD) =DE.
Since this holds for ev/bracketleftbig
eryd, we conclude th/bracketrightbig
atd/bracketleftbig
imSDEand so |Z(P, Q/bracketrightbig
)| DE.
1.1.Polynomials with prescribed values. Now we return to Lemma 1.2 at the
beginning of the last section:</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>BEZOUT THEOREM
One of the most fundamental results about the degrees of polynomial surfaces is
the Bezout theorem, which bounds the size of the intersection of polynomial surfaces.
The simplest version is the following:
Theorem 0.1. (Bezout in the plane) Suppose Fis a eld and P, Qare polynomials in
F[x, y]with no common factor (of degree 1). Let Z(P, Q) :={(x, y)F2|P(x, y) =
Q(x, y) = 0}. Then the number of points in Z(P, Q)is(degP )(degQ ).
There are several approaches to proving the Bezout theorem. I found one approach
that feels closely related to the methods weve been studying. (It appears in Joe
Harriss book Algebraic Geometry, a First Course, exercise 13.17.)
The proof uses the unique factorization of polynomials. We recall exactly what
this means.
For any eld F, the ring of polynomials over Finnvariables, F[x1, ..., x n] obeys
unique factorization. The units in this ring are exactly the non-zero elements of
F. A non-zero polynomial Pis called irreducible if whenever P=P1P2, one of
P1, P2is a unit. Unique factorization says that if Pcan be written as a product of
irreducibles in two dierent ways, say P=/producttext
iPi=/producttext
jQj, then there are the same
number of factors in each product, and we can reorder the indices so that Qi=ciPi
where cFi\ {0}.
There are a number of variations on the statement of the Bezout theorem, and we
mention them later.
1.A proof of Bezout in the plane
  LetIbe the ideal generated by P, Q, and let S=F[x, y]/I. We can roughly think
ofSas the ring of polynomial functions on Z(P, Q), and it follows from this that
|Z(P, Q)| dimS. (We think of Sas a vector space over Fin order to dene its
dimension.)
Lemma 1.1. |Z(P, Q)| dimS.
Proof. For any set XF2letEXbe the evaluation (or restriction) map from F[x, y]
toFcn(X,F). IfXis a nite set, then EXis surjective. We state this as a lemma,
and well prove it later.
Lemma 1.2. IfXFnis any nite set, and f:XFis any function, then there
is a polynomial which agrees with fonX.
1</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>BEZOUT THEOREM 3
Lemma 1.5. IfXFnis any nite set, and f:XFis any function, then there
is a polynomial Pof degree  |X| 1which agrees with fonX.
Proof. For each pX, we will construct a polynomial PpwithPp(p) = 1 and Pp= 0
onX\p. Fix p. For each qX\p, letLqbe a polynomial that vanishes at qbut
not at p. Then dene Pp=c/producttext
qX\pLq. We see that Pp(q) = 0 for each qX\p,
and that Pp(p) = 0. By choosing the constant c, we can arrange that Pp(p) = 1. The
degree of Ppis|X| 1.
Finally, for an arbitrary function f, we dene P=/summationtext
pXf(p)Pp. /square
2.Statements of the Bezout theorem
The Bezout theorem is usually stated as an equality (by algebraic geometers). It
roughly says that if PandQhave no common factor, then the number of points
inZ(P, Q) is equal to (degP )(degQ ). To make this work we need to work over an
algebraically closed eld and we need to work over projective space, and we need to
count intersections with multiplicity.
For example, lets try to consider two circles x2+y2= 100 and (x 5)2+y2= 100.
Initially, we consider x, yinR, where we can easily visualize the circles. They appear
to intersect in two points. Where are the other two points? What if we allow x, y
to be complex numbers? In fact this doesnt lead to any more intersection points.
But if we work over complex projective space, we get two more interesection points
at innity. Now what if we slide the circles apart so that they become tangent and
then disjoint. In R2, the number of intersection points goes from 2 to 1 to 0. When
the circles become disjoint over R2they develop two points of intersection in C2\R2.
At the moment of tangency, there is only one intersection point in C2, plus two
intersection points at innity. But this one intersection point at the tangency has
multiplicity 2. Counting with multiplicity, there are still exactly four intersection
points.
The full statement of the equality Bezout theorem requires some work to dene
the multiplicities of the intersections. Because the statement is more complicated the
full proof is rather longer than this. But the inequality version is what we will need
in our applications. In my opinion, the inequality version of the Bezout theorem is
somewhat underrated. It takes only a fraction of the eort to state and prove it, and
it still has many applications.
3.The Hilbert polynomial
To give context, we mention without proof some important related concepts. (I
dont really know this area myself. I hope there are not errors. Anyway, we wont
use any of these statements later.)/\e}atio\slash</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>6 BEZOUT THEOREM
Fix a value hj. The set X0intersects the plane xn=hjatLpoints, (y 1,j, hj), ...,(yL,j, hj)
withyFn1k,j . By Lemma 1.5, we can nd a degree Lpolynomial Pjinn1
variables so that Pj(yk,j) =f(yk,j) for each yk,j.
Now we want to nd a polynomial Pinnvariables with degree dso that
P(y, h j) =Pj(y) for all yand all jfrom 1 to dL. Lets expand out PjandP:
Pj(y) =/summationdisplay
cI(j)yI,where Iis an exponent in (n-1) variables of degree at most L.
I
Now we will choose Pto have the following form:
P(y, x n) =/summationdisplay
PI(xn)yI,where |I| LanddegP IdL.
I
It suces to choose PIso that PI(hj) =cI(j) for each j= 1, ..., dL. We can do
this by applying Lemma 1.5 again. /square
This nishes the proof of Theorem 4.1. /square
Exercise: Figure out what happens in nite elds. Check that the result is still
true if degP, degQ &lt; |F|or if the theorem is phrased carefully.
Finally, we discuss/explore what might be true more generally in higher dimen-
sions. Suppose that we have some ideals I F jin [x1, ..., x n]. Suppose that Ijhas
dimension mjand degree Dj. In other words, if Rj,d=Vd/Ij,d, then
dimR j,d=Dj(mj!)1dmj+ lower order terms ,for all dsuciently large .
LetIbe the ideal generated by Ij. Suppose that it has dimension mand degree
D. Now we may pose the following question:
Question 1. If(nm) =j(nmj), then is D
The condition on the dime/summationtext
nsions is similar to asking t/producttext
jDj?
hatPandQhave no common
factor in the planar version of Bezout.
It would be cool to know whether this is true, and also to see if there is a proof in
the spirit of the arguments above.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>4 BEZOUT THEOREM
Lets look back at the proof of the Bezout theorem in the plane. Recall that Iis
the ideal generated by PandR=F[x, y]/I. A key observation was the formula for
the dimension of Rd:
dimR d=Dd+ (3/2DD2),fordD.
In general, for any ideal IinF[x1, ..., x n], we can dene R=F[x1, ..., x n]/Iand
Rd=Vd/Id, and we can study the dimension of Rd. Another basic example is given
by the ideal I= 0. In this case, R=F[x1, ..., x n], and so we have seen that
dimR d=/parenleftbiggd+n/parenrightbigg
= (1/n!)dn+ lower order terms .n
In general, the dimension of Rdis always given by a polynomial, called the Hilbert
polynomial, for all dsuciently large.
m
dimR d=hI(d) =/summationdisplay
ajdj,fordd0.
j=0
The leading term of the Hilbert polynomial, amdmis particularly interesting. In
the rst example above, the leading term was Dd. In the second example, the leading
term was (1 /n!)dn. In general, mwill be the dimension of Z(I) and m!amwill be the
degree of Z(I). (We have not dened dimension and degree anywhere else. These
can be taken as denitions, and they are equivalent to other denitions in algebraic
geometry...)
In the polynomial method, it was very important to observe that in ndimensions,
the space of polynomials of degree dhas dimension growing like dn. In the Hilbert
polynomial perspective, this feature can be taken as the denition of the dimension
of a variety Z(I).
4.The Bezout theorem in higher dimensions
The Bezout theorem can be generalized to higher dimensions. The full statement
gets harder to prove. In our applications, we will need the following minor general-
ization. Let Fbe an innite eld.
Theorem 4.1. IfP, QF[x, y, z ]have no common factor (of degree 1), then the
number of lines in Z(P, Q)is(degP )(degQ ).
 Proof. We dene Ito be the ideal generated by PandQ, and we dene Sto be the
ringF  [x, y, z ]/I. If the ring Scontains many lines, then it must be large in some
sense. But if the degrees of PandQare small, then Smust be small in some sense.
Let us make this precise. Let VdF[x, y, z ] be the polynomials of degree d. Let</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>BEZOUT THEOREM 5
I d=IV d, and Sd=Vd/Id. On the one hand, we will bound the dimension of Sd
from above using the degrees of PandQ:
dimS d(degP )(degQ )d+c(P, Q).
On the other hand, if Z(P, Q) contains Llines, then we will bound the dimension
ofSdfrom below as follows:
dimS dLdc(L).
Given these two bounds, taking d , we see that L(degP )(degQ ).
Now we turn to the upper bounds on Sd.
We closely follow the argument in the planar case. Let D=degP andE=degQ.
Iis the ideal generated by P, andRisF[x, y, z ]/I.Jis the ideal of Rgenerated by
Q.S=R/J.
The dimension of Idis equal to dimV dD=dD+3
3fordD.
The dimension of RdisdimV d+
ddimI3 dD+3 2d=/parenleftbig
/parenleftbig
33/parenrightbig
= (1/2)Dd + lower order terms.
The dimension of JdisdimR dE= (1/2)D/parenrightbig
(d/parenleftbig
E)2/parenrightbig
+ lower order terms.
The dimension of SdisdimR ddimJ ddimR ddimR dE=DEd+ lower order terms.
In other words, dimS d=DEd+c, where cis a constant that depends on P, Qbut
not on d.
Now we turn to the lower bounds on the size of Sdrelated to the lines in Z(P, Q).
For any set XF3, letEXbe the restriction map from VdtoFcn(X,F).
Lemma 4.2. IfXis a union of Llines in Fn, then the rank of EX:VdFcn(X,F)
isLdc(L). (Recall that Fis an innite eld.)
We will come back to the proof of this lemma. For now, we use this lemma. If X
Z(P, Q  ), then Iis in the kernel of EX, and so EXis a map from SdtoFcn(X,F). In
particular, the dimension of Sdis at least the rank of the map EX:VdFcn(X,F).
IfZ(P, Q) contains Llines, then Lemma 4.2 implies that the dimension of Sdis at
leastLdc(L).
Now we turn to the proof of Lemma 4.2
Proof. Fixd. After a linear change of variables, we can assume that each line is
transverse to planes of the form xn=h. Choose dLvalues h1, ..., h dLso that
each plane xn=hjintersects the Llines in Ldistinct points. Let X0Xbe these
L(dL) points.
We claim that for any function f:X0F, there is a degree dpolynomial that
agrees with fonX0. This will imply that rankE X:VdFcn(X,F) is at least
|X0|=LdL2.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Introduction (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/18-s997-the-polynomial-method-fall-2012/resources/mit18_s997f12_lec1/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>4 INTRODUCTION 
The sets Nikodym constructed have full Hausdor dimension, as do all known 
constructions. This suggests the following conjecture: 
Conjecture 2.2. Every Nikodym set N  [0, 1]n has Hausdor dimension n. 
This conjecture turns out to be related to many deep problems in analysis, and 
it has come to play an important role. (There is also a more famous cousin, the 
Kakeya conjecture). Although they may look rather arbitrary at rst, the Nikodym 
and Kakeya conjectures underlie a variety of important and natural problems in Fourier analysis, PDE, and number theory. A lot of eort has gone into studying the problem, and we are still far from resolving it. Faced with the dicult problem, 
mathematicians have looked at cousin problems and toy problems that might give 
some insight. For example, Tom Wol formulated a nite eld version. 
Let F be a nite eld with q elements. A set N  F
n is called a Nikodym set if, 
for each point x  Fn, there is an ane line L(x) so that 
 The point x lies in L(x). 
 Except for x, the line L(x) lies in N. 
The analogue of the Nikodym problem is to ask how many points there must be 
in a Nikodym set. The nite eld Nikodym conjecture says that every Nikodym set must have at least c
nqn points. For a while, the two problems seemed about equally 
hard. About ve years ago, Dvir proved the nite eld Nikodym conjecture. The 
proof was only a page long and it shocked a lot of mathematicians in the area. The 
proof uses the polynomial method, somewhat in the spirit of the Berlekamp-Welch algorithm. 
Here is a sketch of the proof. Suppose that N is a small Nikodym set, with only 
n(2n)nqelements. By dimension counting, we can then nd a non-zero polynomial 
P that vanishes on N with degree at most ( q/2). Fix a point x  Fn, and consider 
the line L(x). By the denition of a Nikodym set, at least q 1 points of L(x) lie 
in N. Therefore, P must vanish on q 1 points of L(x). Since the degree of P is 
&lt; q 1, P must vanish on the whole line L(x), in particular P (x) = 0. Now x was 
arbitrary so P (x) = 0 at every point x  Fn . Given that P vanishes at every point 
and that the degree of P is &lt; q, its not hard to show that P is the zero polynomial, 
giving a contradiction. 
Filling in all details of the proof takes two more short paragraphs, and well do it 
later. Previously, people tried hard to prove the result without this polynomial trick, and it seems to be extremely dicult. The situation raises a lot of questions. Do polynomials really play such an important role in this problem? If so, why? What does the method have to do with the problem? Well come back to these kinds of 
questions a number of times throughout the notes. 
People tried to adapt the polynomial method to attack the original Nikodym 
conjecture, but there are serious diculties. The polynomial method hasnt yet led</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>6 INTRODUCTION 
4. Number Theory 
The polynomial method is also connected with work in number theory from the 
early 20th century. In particular, there was an important breakthrough by Thue in 
the study of diophantine equations. Thue was able to prove that many polynomial equations have only nitely many integer solutions. Here are a couple of examples. 
A. The polynomial y
3 2x3 = 1 has only nitely many integer solutions. 
B. The polynomial y4+6x2y2+7x3y+101x4 has only nitely many integer solutions. 
These are just special cases of Thues general theorem. 
Theorem 4.1. (Thue 1908) If P (x, y)is an irreducible homogeneous polynomial of 
degree  3, and A is an integer, then the equation P (x, y) = A has only nitely many 
integer solutions. 
Before Thue, people usually studied single equations or small families of equations. 
Thues theorem was much more general. Looking at irreducible polynomials is not that big a restriction, because one can study reducible polynomials by considering the 
factors. Being homogeneous is a restriction, but Siegel was able to generalize Thues 
work to develop a systematic theory of diophantine equations in two variables. 
Thues argument involved some auxiliary polynomials. In order to study a partic
ular diophantine equation, like equation A above, Thue needed an innite sequence 
of auxiliary polynomials with special properties. Thue tried to construct these poly
nomials explicitly. He was able to do it in some examples like equation A, but he couldnt do it for many other equations. Then he realized that the auxiliary polynomials needed to exist for every equation because of a simple counting argument like 
the one at the beginning of this section. This was probably the most important idea 
in Thues breakthrough. 
Reviewing Thues work at the 1974 ICM, Schmidt described it as follows: The 
idea of asserting the existence of certain polynomials rather than explicitly constructing them is the essential new idea in Thues work. As Siegel [1970] points out, a study 
of Thues papers reveals that Thue at rst tried hard to construct the polynomials 
explicity (and he could actually do so [for equations of the form y
d Bxd = A]). 
5. Goals of the course 
The polynomial method gives several strikingly short applications. The rst goal 
of the course is to study these. Ill emphasize three examples: the Berlekamp-Welch algorithm, the nite eld Nikodym and Kakeya problems, and the joints problem. 
These short proofs are hard to appreciate without context. The next goal is to learn 
the context of these results. In particular, we will learn about incidence geometry: combinatorial estimates about how lines and other basic geometric objects intersect each other.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>3 
1/2 INTRODUCTION 
Corollary 1.2. If q &gt; 104, for any function F : F  F, there is at most one 
1/2polynomial P of degree  qso that F (x) = P (x) for at least (51/100)q values of 
x. 
Proof. Suppose that P1 and P2 are such polynomials. Since P1 = F 51 % of the time 
and P2 = F 51 % of the time, it follows that P1(x) = P2(x) for  (2/100)q values of 
1/2x. So P1 P2 is a polynomial of degree  qwith at least (2 /100)q zeroes. If q is 
big enough (2/ 100)q &gt; q1/2 and so P1 P2 = 0. D 
In theory, we can recover P from F by trying all the polynomials of degree  q
until we nd the one that agrees with F 51 % of the time. But this algorithm is very 
inecient. Berlekamp and Welch found an ecient algorithm to recover P from F . 
Theorem 1.3. (Berlekamp-Welch, 1986) There is a polynomial time algorithm to 
recover P from F . 
Berlekamp and Welch consider the graph of P and the graph of F . The graph 
of P is a nice algebraic curve in F2 . The graph of F contains a lot of points from 
the graph of P , together with some error points. We are given the graph of F . We 
dont know which points lie in the graph of P and which are errors. In this cloud 
of points, we are hoping to nd a hidden algebraic structure - the graph of P . The 
main idea of Berlekamp and Welch is to consider a lowest degree polynomial R(x, y) 
that vanishes on the graph of F in F2 . (In fact, they consider the lowest degree 
polynomial of the special form R(x, y) = R0(x) + yR1(x).) As we discussed above, 
its possible to nd this polynomial R in polynomial time. Then it turns out that 
the zero set of R is exactly the graph of P together with a vertical line through each 
error. In other words, for each e  F where F (e) = P (e), the graph of R contains 
the line x = e. With the help of R we can immediately tell which values of F agree 
with P and which were corrupted. After that, its straightforward to recover P . 
2. The finite field Nikodym conjecture 
The next problem that we consider originates in geometry and analysis. 
A set N in the cube [0 , 1]n  Rn is called a Nikodym set if, for each point x  [0, 1]n , 
there is a line L(x) so that 
 The point x lies in L(x). 
 Except for x, L(x)[0, 1]n lies in N. 
For example, if I remove the line y = 1/2 from the square [0, 1]2, the result is a 
Nikodym set. If I remove a circle, then it isnt. In the 1920s, Nikodym proved the following counterintuitive result: 
Theorem 2.1. There are Nikodym sets of measure zero in each dimension n  2.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2 INTRODUCTION 
(d+n)
The dimension of V (d) is n  dn/n!. For n xed and d large, dn/n! is a good 
approximation of the dimension. Therefore, we get the following corollary. 
Corollary 0.3. For any set of s points in Fn, there is a non-zero polynomial that 
1/nvanishes on the set with degree  ns. 
Returning to our example, we see that there is a polynomial vanishing on the 
million points {(j, 2j)|j = 1, ..., 106}with degree  2000. This polynomial is much 
more ecient than the examples I came up with above. Its extremely messy and it 
would be very dicult to write down explicitly, but for simple abstract reasons we 
know that it exists. 
Here is one moral of this discussion. Suppose that we are trying to nd a poly
nomial with some special properties. One approach is to try to write down the polynomial and nd a clever formula. But this discussion gives another approach 
proving that such a polynomial exists by a dimension-counting argument. Sometimes 
this approach is more eective than any polynomial that I could craft. 
A bare outline of the polynomial method goes as follows. 
(1) Begin with a problem about some points in a vector space. 
(2) Find or consider a polynomial that vanishes at these points with degree as 
small as possible. 
(3) Use the polynomial to attack the problem. 
After this general discussion, lets mention some of the applications of this method. 
Im going to mention four applications that well study in this course. 
1. Algorithms in coding theory 
Suppose F is a nite eld with q elements and P : F  F is a polynomial of 
1/2low degree, degP  q. In the coding theory scenario, we could imagine that 
this polynomial is a piece of data that we want to send over an unreliable channel. 
In transmission, the data gets corrupted, and the other side receives a function 
F : F  F. Lets suppose that a slim majority of the data is correct: in other words 
F (x) = P (x) for at least (51 /100)q values of x. Is it possible to recover P from F ? 
If so, can we do it eciently? 
As long as q is suciently large, it is possible to recover P from F in theory 
because of a fundamental property of polynomials. 
Lemma 1.1. If P : F  F has degree  d and vanishes at more than d points, then 
P is the zero polynomial. 
(This simple lemma will have a lot of applications in our course.)</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>7 INTRODUCTION 
The third goal of the course is to prove the estimate about the distinct distance 
problem. 
The fourth goal is to explore connections between the polynomial method and 
dierent parts of mathematics. We will see some connections involving computer 
science, algebraic geometry, topology, harmonic analysis, and number theory. 
The fth goal is to mull over some philosophical questions related to the polynomial 
method. For example, what is special about polynomials? Why are polynomials 
involved in these problems?</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>INTRODUCTION
 
In the last ve years, several challenging problems in combinatorics have been 
solved in an unexpected way using polynomials. This new approach is called the 
polynomial method, and the goal of these notes is to study and explore it. 
The polynomial method has roots in some algorithms about polynomials developed 
in coding theory in the 80s and 90s. Ideas from these algorithms were then applied to mathematical problems that arent obviously related to polynomials. Some problems 
that seemed very hard can now be solved in a couple pages with this new perspective. 
The following problem is in the background of the polynomial method. Consider 
a eld F and a nite set of points S  F
n . 
Problem: Find a non-zero polynomial P that vanishes on S with degree as small 
as possible. 
For example, consider the points ( j, 2j)  R2 with j = 1, ..., 106 . What is the 
lowest degree of a (non-zero) polynomial that vanishes on all of these points? Let me 
try to nd some polynomials that vanish on these points beginning with simple ones. 
One polynomial that vanishes on all these points is ( x 1)...(x 106). It has degree 
106 . Another is (y 2)(y 4)... which also has degree 106 . I can be a little cleverer by 
choosing a linear polynomial L1 that vanishes on the rst two points, then a second 
linear polynomial that vanishes on the next two points, etc. The product of these 
linear factors has degree only 500,000. 
We can get a better perspective on the problem by thinking about the general 
situation of a nite set of points x1, ..., xs  Fn . Let V (d) be the vector space of 
polynomials of degree  d in n variables over F. Let E be the evalution map dened 
by 
E(P ) := (E (x1), ..., E(xs)). 
The map E is linear, and the kernel of E is exactly the set of polynomials of degree 
 d that vanish on the given points. Our original problem reduces to linear algebra. 
Using linear algebra, we can draw two important corollaries. 
Corollary 0.1. There is a polynomial-time algorithm to nd a minimal degree poly
nomial that vanishes on a given nite set. 
(The running time is polynomial in the number of points s, and also in the dimen
sion n. We will usually have a xed n and consider s  .) 
Corollary 0.2. If dim V (d)&gt; s, then there is a non-zero polynomial P of degree  d 
that vanishes on the given nite set. 
1</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu
18.S997 The Polynomial Method
Fall 2012
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms .</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>5 INTRODUCTION 
to any signicant progress on Nikodym-type problems in Euclidean space. But it 
has had a lot of success in combinatorial problems involving nitely many lines in Euclidean space. 
3. The distinct distance problem 
The polynomial method has led to solutions for several challenging problems in 
extremal combinatorics, as well as giving new proofs and perspectives for some important known results. We will study most of these new proofs. The result that we will spend the most time tackling is an estimate for the distinct distance problem in the plane. 
Suppose P  R
2 is a nite set with N elements. We let d(P ) denote the set of 
non-zero distances between elements of P : 
d(P ) := {|p q|}p,qP,p=q. 
(We are using the standard Euclidean distance on R2.) 
Lets consider some examples. 
)(N(1) N generic points in the plane gives |d(P )|=  N2 .2 
(2) N evenly spaced points along a line gives |d(P )|= N 1.   
(3) N points arranged in a N  N square grid gives |d(P )| N(logN)1/2 . 
In the 1940s, Erd os raised the question how small the distance set d(P ) could 
possibly be. He worked out the example of the square grid, and he conjectured that the square grid is minimal up to constant factors: in other words, any set of N points 
should have |d(P )| cN(logN)
1/2 . A number of people have proven lower bounds 
for the distinct distance problem using dierent techniques. Before the polynomial 
method, the best lower bound proved that the number of distinct distances is N.864 . 
The book The Erd os Distance Problem , by Garibaldi, Iosevich, and Singer, describes 
various approaches to the problem. Using the polynomial method, Nets Katz and I 
proved the following theorem. 
Theorem 3.1. (G.-Katz, 2010) For any set of N points in the plane, the number of 
distinct distances is at least cN(logN)1 . 
This proof is more dicult than the proof of nite eld Kakeya or joints. It will 
take us 40-60 pages all in all. There is a new ingredient coming from topology and 
a new ingredient coming from ruled surfaces in algebraic geometry. Nevertheless, 
the proof is pretty elementary, and I hope it will be accessible to a broad range of readers.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
