<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/</course_url>
    <course_title>Knowledge-Based Applications Systems</course_title>
    <course_tags>
      <list>Engineering </list>
      <list>Computer Science </list>
      <list>Artificial Intelligence </list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>Rule-Based Systems (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect06_rules/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>13</slideno>
          <text>How It Worked: Representation
Rule 27
If: 
1)the gram stain of the organism is gram
negative, and
2)the morphology of the organism is rod, and
3)the aerobicity of the organism is 
anaerobic ,
Then: 
There is suggestive evidence (.7) that the
identity of the organism is Bacteriodes . 
 Predicates on object, attribute, value triples. 
6.871  Lecture 6 13</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>The Right Abstraction
If  
the organism is gram-negative, and
the portal of entry is skin-wound, 
Then the organism is likely to be 
 Its an abstraction 
 Its the right abstraction for this task 
 Where did it come from? 
6.871  Lecture 6 23</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Architecture
INFERENCE 
ENGINE 
KNOWLEDGE 
BASE 
6.871  Lecture 6
 14</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Rule-Based Systems
6.871-- Lecture 6</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Successful?
	Appropriate task: Narrow domain, heuristic knowledge, 
articulate experts, etc. 
	The match of knowledge and representation: 
	Knowledge about of how the body works, vs. 
	Knowledge about how to diagnose it 
	Answer was a ranked list, not a single result 
	Perhaps most important: 
Having the right abstractions, the right language 
6.871  Lecture 6 10</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>What ought a rule to be?
 Independent 
 Does it make sense in isolation? 
 Single step: mental hygiene 
 Inferential: focus on the knowledge level
 Empirical association 
 Association: symptom &amp; disease 
 Empirical: noticed but not understood 
 Logic-like, but: 
 Inexact 
 Not truth-preserving 
6.871  Lecture 6 25</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>What Ought a Rule to Be?
IF the stock-price is determined, and 
the stock-earnings is determined, 
THEN the price-earnings-ratio is stock-price/stock-earnings. 
IF	 the patient is between 16 and 21, and 
the chief complaint is fatigue, and the 
patient has a mild fever 
THEN	 the disease is likely (.8) to be mono.
6.871  Lecture 6 27</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Prospector
 Like Mycin:  
 System creation as a forcing function for making 
knowledge explicit (hence accessible, testable,
communicable, etc.) 
 Unlike Mycin: 
 Network view of a knowledge base (Lecture 7) 
 An alternate model for inexact reasoning:  
Bayesian probability theory (Lecture 10)
6.871  Lecture 6 30</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Outline
M Y C I N 
 Introduction 
T a s k 
 Sample Interaction 
 Reasons for Success 
 How It Worked 
 Knowledge Representation 
 Architecture and Control Structure 
 Inexact Inference 
 Explanation 
 Interaction Help 
 Reasons for Success Revisited 
 Contributions 
P r o s p e c t o r 
 Rules Glasses 
6.871  Lecture 6 1</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Explanation
** WHY DIDNT YOU THINK THAT ORGANISM-1 
WAS NEISSERIA? 
The following rules could have been used to determine
that the identity of ORGANISM-1 is neisseria: 9. 
However, none of these succeeded in the context
of ORGANISM-1. If you woul d like an explanation for why 
any of these rules failed, please enter their numbers: 
** 9
Clause 2 of rule009 [the morp hology of the organism is 
coccus] was already known to be false for ORGANISM1, so the rule was never tried. 
6.871  Lecture 6 21</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>How It Worked: Representation
Rule 27
If: 
1)the gram stain of the organism is gram
negative, and
2)the morphology of the organism is rod, and
3)the aerobicity of the organism is
anaerobic,
Then: 
There is suggestive evidence (.7) that the
identity of the organism is Bacteriodes. 
6.871  Lecture 6 11</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Inexact Inference 
R1: A and B 
 X (.4)
R2: C and D 
 X (.3) 
A and B and C and D ? 
Desiderata : 
 Commutative 
 Asymptotic 
 Balances positive and negative 
evidence 
6.871  Lecture 6 17</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>What ought a rule to be?
Answer: 
An independent 
single-step 
inferential 
empirical association. 
6.871  Lecture 6 24</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>What are the Rules Glasses?
	Capture the expertise by dissecting it into 
individual inferences. 
	Impose your ontology by choosing your 
predicates carefully. 
	The choice of language is an important 
source of power: the right choice of 
language vastly reduces search. 
6.871  Lecture 6 32</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>MYCIN
 What was the task?
 Medical diagnosis and therapy selection for 
bacterial infections of the blood 
 Why this domain? 
 Overuse of antibiotics 
6.871  Lecture 6 2</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>What are the Rules Glasses?
	An individual inference rule is the appropriate unit of 
modularity. 
	Information can be captured as single independent 
statements, single independent inferences. 
	Expertise is the accumulation of good guesses derived 
from experience. 
	Expertise is can be captured as a set of informal, 
heuristic inferences, each of which is a simple if/then
rule. 
6.871  Lecture 6 31</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Sample Interaction: Therapy
[REC 1] My preferred therapy recommendation is as follows:
In order to cover for Items &lt;1 3 4 5 6 &gt;: 
Give: GENTAMICIN 
Dose:128 mg (1.7. Mg/kg) q8h IV (or IM) for 10 days Comments: Modify dose in renal failure 
In order to cover for Item &lt;2&gt;:
Give: CHLORAMPHENICOL
Dose:563 mg (7.5 mg.kg) q6h for 14 days
Comments: Monitor patients white count
Do you wish to see the next choice therapy?
** NO 
6.871  Lecture 6 9</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Explanation
** HOW DID YOU DECIDE THAT ORGANISM-1 
WAS AN E.COLI? 
I used rule084 to conclude that the identity of 
ORGANISM-1 is e.coli. This gave a cumulative c.f. 
of (.51). 
I used rule003 to conclude that the identity of ORGANISM-1 is e.coli. This gave a cumulative c.f. 
of (.43). 
6.871  Lecture 6 20</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Sample Interaction (contd)
The first significant organism from  this blood culture (CULTURE-1) 
will be referred to as: 
--------------ORGANISM-1-----------------
6) Enter the identity of ORGANISM-1 
** UNKNOWN 
7) Is ORGANISM-1 a rod or coccus (etc.): 
** ROD 
8) The gram stain of ORGANISM-1 
** GRAMNEG
9) HAVE THERE BEEN positive cultures yielding organisms 
about which you will NOT be seeking advice? 
** YES
6.871  Lecture 6 5</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>What Ought a Rule to Be?
IF	 There is pressure on project leader, 
Respondent is R&amp;D manager,
No increase in growth stage of life cycle, 
Increased probability of commercial success, 
Project champion di d not appear at end, 
Product not in infancy stage of life cycle, 
Top management support, 
Association between commercial  and technological aspects, 
R&amp;D perceives project mg mt commitment as high, 
There is a project champion, 
Dont know about newly enacted favo rable international regulations, 
Project champion appea red in the middle, 
Respondent is not the VP, 
Project Champion didnt appear at beginning, 
Respondent is not marketing manager, 
THEN the Project is likely to succeed. 
From Gallant and Balachandra, Using autom ated techniques to generate an expert 
system for R&amp;D project monitoring, First IFAC Intl Symp osium on Economics and AI, 
Sept. 1986. 
6.871  Lecture 6 26</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Contributions
	The adequacy of a simple model of 
uncertainty.
	Explanation as a core property of KBS
	Preview of multiple uses of knowledge
	Meta-rules and meta-knowledge 
6.871  Lecture 6 29</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Sample Interaction (contd)
9) Enter the identity of ORGANISM-2: 
** SALMONELLA (.4) E.COLI (.3)
6.871  Lecture 6
 6</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Revisited
 Perhaps most important:
Having the right abstractions, the 
right language 
6.871  Lecture 6 22 Reasons for Success,</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Sample Interaction: Explanation
Is the patients illness with ORGANISM-1 a hospital-acquired infection? 
** WHY 
[i.e. WHY is it important to determi ne whether or not the infection with 
ORGANISM-1 was acquired while the patient was hospitalized] 
[2.0] This will aid in determining the identity of ORGANISM-1. 
It has already been established that 
[2.1] the morphology of ORGANISM-1 is rod 
[2.2] the gram stain of  ORGANISM-1 is gramneg 
[2.3] the aerobicity of ORGANISM-1 is facul 
Therefore, if 
[2.4] 	 the infection with OR GANISM-1 was acquired while 
the patient was hospitalized
then 
there is weakly suggestive ev idence (.2) that the identity 
of ORGANISM-1 is pseudomonas [RULE050] 
6.871  Lecture 6 7</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Control Structure
 What kind of search? 
 Backward-chaining, depth-first 
 With what variations? 
 Generalized subgoals 
E.g. determine identity, not is identity = 
E.coli 
 Every rule relevant to goal is explored 
 Inexact inference 
6.871  Lecture 6 16</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Inexact Inference 
R1: A and B X (.4) 
R2: C and D X (.3) 
A and B and C and D ? 
A and B X (.4) 
C and D: 
increase certainty .3 more from current value 
X(.4 + .3(1 - .4)) = X(.58) 
current value new value remaining uncertainty 
6.871  Lecture 6 18</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>How It Worked: Representation
Rule 27
If: 
1)the gram stain of the organism is gram
negative, and
2)the morphology of the organism is rod, and
3)the aerobicity of the organism is 
anaerobic ,
Then: 
There is suggestive evidence (.7) that the
identity of the organism is Bacteriodes . 
6.871  Lecture 6 12</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Sample Interaction: Diagnosis
INFECTION-1 is ENDARTERITIS with BACTEREMIA 
&lt;Item 1&gt; E. COLI 
&lt;Item 2&gt; SALMONELLA (species unknown) 
&lt;Item 3&gt; KLEBSIELLA-PNEUMONIAE &lt;Item 4&gt; PSEUDOMONAS-AERUGINOSA &lt;Item 5&gt; ENTEROBACTER &lt;Item 6&gt; PROTEUS-NON-MIRABILUS 
6.871  Lecture 6 8</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Sample Interaction: Clinical 
Data
---------PATIENT-248----------
1) Patients name: (first-last) 
** CR 
2) Sex: 
** MALE 
3) Age: 
** 52
4) Have you been able to obtain pos itive microbiological information 
about a possible infection of C.R.? 
** YES 
----------INFECTION--------------
5) What is the infection? 
** ENDARTERITIS
6.871  Lecture 6 4</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Control Structure
IDENTITY 
Rule 27 
 
GRAM MORPHOLOGY AEROBICITY 
6.871  Lecture 6
 15</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Inexact Inference 
R1: A (.5) and B (.6) 
 X (.4) 
R2: C (.4) and D (.7) X (.3) 
A and B and C and D ? 
AND: min (A and B) = .5
min (C and D) = .4
R1: .5 * .4 = .2
R2: .4 * .3 = .12
Combining: .2 + .12( 1 - .2) = .30
current value new value remaining uncertainty 
6.871  Lecture 6
 19</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Why This Domain
 Overuse of antibiotics 
 Irrational use of antibiotics 
 Maldistribution of expertise 
 Domain is small and isolated
6.871  Lecture 6 3</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Contributions
	Existence proof of adequacy of rule-based 
systems 
	Knowledge can be captured as a set of 
mostly independent rules 
	Knowledge can obviate search:  looking
through the right space 
	Experts can be debriefed
6.871  Lecture 6 28</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Reasoning with Constraints (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect17_constrain/</lecture_pdf_url>
      <lectureno>17</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>Solution Strategy 4:
Intelligent Backtracking
	Like Backtracking 
	Possibly augmented with forward pruning 
	When run out of values for a variable backtrack to a 
choice related to the problem , not necessarily to the 
most recent choice 
	Why is this an issue?
	Because the order of variable assignments isnt necessarily 
the same as the topology of  the constraint network. 
	The constraint network is only a partial order 
	Variable assignments are totally ordered 
	The most recent choice could be on a parallel branch 
	How do we deal with this? 
	Dependency networks 
7</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Solution Strategy 1:
Generate and Test
 For Each Variable, Select a Value 
 Then test set of select val ues for constraint violations 
 Iterate until solution found 
Select V1 = Red, V2 = Red, V3 = Red, V4 = Red 
Test for violated constraints -&gt; Yep. 
Generate Next Candidate 
Select V1 = Red, V2 = Red, V3 = Red, V4 = Blue 
Test for violated constraints -&gt; Yep. 
Etc. 
3</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>( ) 
( ) 
/  U { }   Constraint satisfaction 
scheduling and planning 
temporal reasoning Allen 1983
VLSI design and testing Larrabee 1992
Part of other AI reasoning tasks 
diagnosis abduction 
default reasoning 
Learning Direct connection to deductive reasoning 
iff is not satisfiable Some Example Applications of SAT 
Figure by MIT OCW. 
37</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Solution Strategy 3:
Backtracking
For each variable 
Select a value 
Check for consistency with previous choices 
If not make a different choice 
If out of choices backup to previous variable 
V1 = Red 
V2 = Red, Inconsistent Try new value 
V2 = Blue 
V3 = Red, Inconsistent, Try new value 
V3 = Blue 
V4 = Red, Inconsistent, Try new value 
V4 = Blue, Inconsistent, Try new value V4 = Green V1 
R R B V3 
R B V4 
G R V2 
B 
5</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Finding a Good Schedule
	Beam Search for good assignments 
	Estimate when each task would most like to run
	(i.e. would incur optimal cost-benefit when viewed in 
isolation)
	Add up demands for each resource in this schedule
	Find the Most Contended for Resource 
	Find the task competing for this which has minimal slack 
	Assign the resource to that task 
	Propagate constraints 
	Assignment of that task 
	Unavailability of resource to other tasks 
	Repeat until done. 
19</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Why is this difficult?
	Computational Reasons:
	Coupling of variables through constraints causes a nested 
search 
	In fact, Boolean constraint satisfaction is classic NP-
complete problem 
S i z e of Problem leads to Exponential Time for Solution 
	Must resort to heuristics 
	Conceptual Reasons: 
	Large collection of different types of constraints 
	Social issues: which one(s) of the incomparable dimensions 
is to be optimized 
	Dynamism: Things Change (in particular, they break) 
20</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>2 0 
3 4 5 6 7 8 2 3 4 5 6 7 8 
500 50 var 40 var 20 var DP Calls 
Ratio of Clauses-to-Variables 1000 1500 2500 
2000 3000 3500 4000 
50% sat The 4.3 Point 
0.0 
Ratio of Clauses-to-Variables Probability 
0.2 0.4 0.6 0.8 1.0 
Figure by MIT OCW. 31</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Generating Hard Random Formulas
	Use fixed-clause-length model (Mitchell, Selman, and 
Levesque 1992) 
	Critical parameter: ratio of the number of clauses to 
the number of variables. 
	Hardest 3SAT problems at ratio = 4.3
28</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Solution Strategy 2:
Forward Pruning
L i k e  G &amp; T
	But, When choosing a variable, prune out inconsistent 
choices in connected nodes: 
Select V1= Red 
Prune V2 = Red 
Prune V3 = Red 
Prune V4 = Red 
Select V2 = Blue 
Prune V4 = Blue 
Select V3 = Blue 
Prune V4 = Blue (already done) V1 
R B V3 
G 
R B G 
R B V4 
G R V2 
B G 
4</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Resource Requirements
A B 
C D 
E F G 
H R1 
R2 
Overlap (D, E) 
Consumption (D, R1) + Consumption ( E, R1)  Amount (R1)
17</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Conflict Handling
	Notice the points of Conflict 
	Identify the causes of the Conflict
	Diagnose the form of the conflict
	Choose a repair strategy based on the form of the 
conflict 
25</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>How Hard is SAT in Practice
	Goldberg (1979) reported very good performance of 
Davis-Putnam (DP) procedure on random instances. 
	But distribution favored easy instances. (Franco and 
Paull1983) 
	Problem: Many randomly generated SAT problems 
are surprisingly easy. 
	But some are genuinely hard: 
	Job-Shop Scheduling: 10 jobs on 10 machines. 
	Proposed by Fischer and Tompson in 1963. 
	Solved by Carlier and Pinson in 1990 ! 
	Open: 15 jobs on 15 machines. 
27</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>An Example From Logic
	Boolean  Constraint Satisfaction 
(Or A B C) 
(Or (not A) C D) (Or B (not D)) (Or (not C) (not B)) 
 Each variable can be either true or false
 All disjunctions must be true 
13</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Other Constraints and Value Functions
	Delivery Dates for each job
	Start Dates for each job 
	Production compatibility 
	If A Job uses Resource 1 for st ep 1 it must use Resource 2 
for step 3. 
	Personnel restrictions (length of continuous work, 
schedule) 
	Value Function: 
	Work in process 
	Lateness penalties 
	Utilization 
18</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Basic Operations of a TMS
 Assumption Retraction, remove the in labeling from an 
assumption. Recalculates status of dependent nodes.
	Assumption Activation, add an in label to an assumption. 
Recalculates status of dependent nodes. 
	Find support of a node : list of all active assumptions 
currently supporting the node. 
	Handle Contradiction : Remove a contradiction by finding 
the assumptions supporting the two contradictory nodes and 
retracting one of them. 
	Establishing a reasoning context : Selecting a set of 
assumptions and giving those (and only those) in labels. 
11</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Dependency Maintenance
	Analyzing the failed situation is crucial 
 Understand what earlier assumptions led to the failure. 
	Truth Maintenance Systems (TMSs) solve this 
problem. 
	Retraction of Assumptions: remo ve all (and only) facts which 
actually depend on the assumption. 
	Explanation: play back the depe ndencies as a justification 
for belief 
	Failure analysis: trace a failure back to the set of 
inconsistent assumptions.
	Re-establish assumptions: bri ng back all facts that depended 
on the re-established assumption. 
	Context Swapping: allow arbitrar y sets of assumptions to be 
retracted and re-established. 
8</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>3 0 
4 5 6 7 0.2 0.4 0.6 0.8 1.0 
SAT 
Phase UNSAT 
Phase 
Transition sharpens up for higher values of N Ratio of Clauses-to-Variables Fraction of Formulae Unsatisfied A Closer Look At The 3SAT Phase Transition 
100 50 40 24 20 12 
Figure by MIT OCW. 33</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Using Continuous Values:
An Example from Electronics
V R1 
R2 I1= (V Vout) 
R1 
Vout 
I2 = Vout 
R2 
I1= I2 
V I 
R1 R2 
Vout 
34</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Precedence Constraints are Hard Constraints
Precedence (PERT) Chart
A B 
C D 
E F G 
H 
Constraints: 
EarliestStart ( B)  EarliestEnd ( A) 
EarliestEnd ( B) = EarliestStart ( B) + Delay ( B) 
LatestStart ( D) = LatestEnd (D)  Delay (D) 
LatestEnd ( B)  LatestStart (D) 
16</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Consistency of a Dependency Network
	If all antecedents of a justification are in then the 
justification is active . 
	If a node is the consequent of an active justification, 
then the node is in . 
	If a non-assumption node is not the consequent of an 
active justification, its label is out. 
	i.e., if a node has no justification, we dont believe it 
10</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>An Example Problem: Map Coloring
V1 V3 
V4 V2 Domain (V1) = Red, Blue, Green Yellow 
Domain (V2) = Red, Blue, Green, Yellow 
Domain (V3) = Red, Blue, Green, Yellow 
Domain (V4) = Red, Blue, Green, Yellow 
V1 Not Equal V3 
Not 
Not Not Equal Equal
Equal 
V2 Not Equal
V4 
2</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Solution Strategy 5:
Arc Consistency
 For each arc A pairing N1 and N2 
 For each value V1 in N1s value set 
 Check that there is a value V2 in  N2s value set consistent with V1. 
 If not Prune V1 from N1s value set. 
 For each node N1 that was changed: 
 Find all nodes N3 and Arcs A2 such that A2 connects N3 to N1 
 Recheck A2, N3, N1 
Check N1-&gt; N2 its Consistent 
Red, Green, Blue Green N3 
Delete Blue from N1 
X X X Blue, Green Check N2 -&gt; N3 
Delete Green from N2 
Check N1 -&gt; N3 
Delete Green from N1 
Check N1 -&gt; N2 
N1 N2 
12</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Solution Strategy 6: Random Sledgehammer
	Assume Boolean valued variables 
	Make a random assignment of values to variables
	Find a violated constraint 
	Pick one of  the values and change it 
	Possibly using a least constrained heuristic 
	Continue finding and fixing violated constraints 
	After exceeding a threshold of steps, try new random 
seed. 
	After exceeding a threshold of seeds, give up.
14</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Scheduling as Constraint Satisfaction
	Why is it difficult? 
	Conceptual: Large Number of c onstraints of different types 
	Social: Whose ox gets gored and who wins 
	Dynamic: Things change and break 
	Computational: Size, realistic problems are very big 
	What can we do? 
	Provide a good set of representat ions for the different types 
of constraints 
	Be dogged about collecting them 
	Be dogged about keeping them explicit 
	Provide a flexible framework (infrastructure) 
	Make scheduling reactive, incremental, iterative 
	Change driven 
	Seek small change 
	Work from current solution 
	Blackboard Style, Incremental solutions 
23</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>The Blackboard Model
	Origin in speech understanding (but not used there 
anymore) 
	Multiple Levels of Abstraction 
	Multiple sources of Knowledge 
	Scheduler chooses which activa ted knowledge source to run 
next 
	Opportunistic behavior 
	E.g. Work from a position of greatest certainty 
	E.g. Work out from the most constrained resource 
	E.g. Work out from the task with least flexibility 
	Can be a good organizing principle when multiple KSs are 
required,no fixed control strategy 
36</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Constraint Satisfaction
6.871  Lecture 17</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>Planning as CSP
	Characterize each operator in terms of the 
constraints it imposes on the situation before and
after its application 
	Characterize the world model in terms of the 
constraints it imposes on variables and their valueswithin a single situation 
	Pick a finite number of Plan Steps (n + 1 situations)
	Or proceed one layer at a time ad ding as many steps as are 
consistent 
	Reduce to a Boolean CSP 
	Good idea if bounded number of variables and values 
	Consider each assignment of a value to a variable as a 
distinct proposition
	Instantiate all the world constraints in each situation 
	Instantiate each operators constraints between each pair of 
succeeding situations 
	Crunch the resulting CSP 35</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Intuition
 At low ratios: 
 few clauses (constraints) 
 many assignments 
 easily found 
 At high ratios: 
 many clauses 
 inconsistencies easily detected 
30</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>2 0 
3 4 5 6 7 8 500 50 var 40 var 20 var DP Calls 
Ratio of Clauses-to-Variables 1000 1500 2500 
2000 3000 3500 4000 Hardness of 3SAT 
29
Figure by MIT OCW.</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Constraint Directed Scheduling
The problem consists of: 
	Orders to be satisfied 
	Decomposition of the order into tasks 
	Constraints on task ordering 
	Production equipment (with their capacities).
	Constraints on the use of producti on equipment to perform specific 
tasks. 
	Other constraints limiting the use of equipment or the timing of 
orders. 
	Some of the constraints are hard, they may not be violated
	Others are soft, they may be violated but at some cost 
	Problem is to find an assignment of each task to a time slot 
and an assignment of resources to each task such that no
hard constraints are violated and such that cost is minimized. 
15</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>What do you want to optimize?
A 
B 
Choose Your portfolio, A or B?
21</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Dependency Networks
Antecedent-1 
Consequent Antecedent-2 
Justification-1 
Justification-2 
	Each node is a fact  
	For CSP, a choice of a value for a variable 
	Each node is labeled either in or out (believed or not)
	Certain nodes are assumptions (label is supplied 
externally) 
	With each deduction, system creates a justification 
whose antecedents are all t he facts used in making 
the deduction and whose consequent is the deduced 
fact. 9</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Past the Basic Techniques
	Suppose there is also an evaluation of the solution:
	Bonuses for early completion of a schedule 
	Some resources cost more than others (relevant if tasks can 
choose between resources with different costs) 
	Some constraints are soft and may be violated with a 
penalty 
	Then we may use any of the techniques to look for an 
(the) optimal solution 
	Increased complexity and computational time 
	How valuable is the optimum vs. near miss? 
	How fragile is the optimum? 
22</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>SAT Problems
	SAT: Given a formula in propositional calculus, is 
there an assignment to its variables making it true? 
	Consider clauses in propositional logic with 3 
variables per clause: 
	Problem is NP-Complete (Cook 1971) 
(a (b ( b b d) c) c e) ........ 
Figure by MIT OCW. 
26</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>A Backtracking Problem
 Consider MarthaPatrick-Stewart, v2.0 
 Boiling corn on the cob 
 Has two ways to pick up t he corn: fingers, serving spoon 
 Has two hands: left and right 
 How to pick up the corn 
 AI to the rescue: use backtracking search. 
 What went wrong? 
6</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Schedule Repair
 Order Scheduler 
 Resource Scheduler
 Right/Left Shifter 
 Demand Swapper 
24</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>0 
0 1 /
2 3 4 5 6 7 8 9 Run Time Percent Satisfiable 200 Variable 3SAT 
Ratio of Clauses-to-Variables Percent Satisfiable Run Time 
20 40 60 80 
10 100 
32
Figure by MIT OCW.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Uncertain Reasoning, Models of Rationality (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect10_uncert/</lecture_pdf_url>
      <lectureno>10</lectureno>
      <slides>
        <slide>
          <slideno>7</slideno>
          <text>Understanding Bayes Theorem
Has it and 
tests  for it10   .95 =  9.5
Has Cancer?Test?
Test?Yes: 10
No: 990Positive: .95
Has it and 
doesnt test for  it
Doesnt 
have it 
but tests 
for it990   .05 =  49.5
Doesnt have it and 
doesnt test for  it
Number that test positive 
If you test positive your probability of having cancer is?
6.871 - Lecture 108</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Bipartite Graphs
D1
D2
D3S1
S2
S3
S4Multiple symptoms, multiple diseases
Diseases are probabilistically independent
Symptoms are conditionally independent
Symptom probabilities depend only the diseases 
causing them
Symptoms with multiple causes require joint 
probabilities P(S2|D1,D2,D3)
6.871 - Lecture 10
13</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Bayes Nets
BA
E DC
Directed Acyclic Graphs
Absence of link conditional independence
P(X1,...,Xn) = Product P(Xi|{parents (Xi)})
Specify joint probability tables over parents for each node
Probability A,B,C,D,E all true:
P(A,B,C,D,E) = P(A) * P(B|A) * P(C|A) * P(D|B,C) * P(E|C)
Probability A,C,D true; B,E false:
P(A,B,C,D,E) = P(A) * P(B|A) * P(C|A) * P(D|B,C) * P(E|C)
6.871 - Lecture 1016</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Odds Likelihood Formulation
Define odds as
Define likelihood as:O(D)=P(D)
P(D)=P(D)
1P(D)
L(S|D)=P(S|D)
P(S|D)
Derive complementary instances of Bayes Rule:
P(D|S)=P(D)P(S|D)
P(S)P(D|S)=P(D)P(S|D)
P(S)
P(D|S)
P(D|S)=P(D)P(S|D)
P(D)P(S|D)
O(D|S)=O(D)L(S|D) Bayes Rule is Then:
6.871 - Lecture 10In Logarithmic Form: Log Odds = Log Odds + Log Lik elihood
19</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Background
DS
DConditional Probability of S given D
P(S|D)=P(S&amp;D)
P(D)U
)(*)|( )&amp;( DPDSP DSP=
6.871 - Lecture 10 6</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Averaging Out and Folding Back
$16.00$28.00EMV of chance node is probability weighted sum over all 
branches
EMV of decision node is max over all branches
.8
.2
.8
.2$40.00
-$20.00
-$5.00
$100.00$32.00
-$4.00
-$4.00
$20.00$28.00
Action
State A1 A2            A3 Probabi lity
U1 40 -5 0 .8
U2 -20 100 0 .2
EMV 28 16 0 1
6.871 - Lecture 1024</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>.1 .2 .5 .2Several  Com peting Hypotheses
Each with a Probability rating.Maximum Entropy
Suppose there are several tests you can make.
Each test can change the probabilit y of some (or all) of  the 
hypotheses (using Bayes Theorem).
Each outcome of the test has a probability.
Were only interested in gathering information at this point
Which test should you make? 
Entropy = Sum  -2  P(i)  Log P(i), a standard measure
Intuition
For .1, .2, .5, .2 = 1.06
For .99, .003, .003, .004 = .058
6.871 - Lecture 10 29</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Calculating the Updated Probabilities
Initial Probabilities
P(Outcome|State) State
Outcome U1 U2
Red .4 .9
Black .6 .1
.8 .2
Joint (chain r ule)
P(Outcome &amp; State) State Marginal Probability
Outcome U1 U2 of Outcome
Red .4  .8 = .32 .9  .2 = .18 .50
Black .6  .8 = .48 .1  .2 = .02 .50
Updated Probabilities
P(State |Outcome) State
Outcome U1 U2
Red .64 .36
Black .96 .04
6.871 - Lecture 1026</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Independence, Conditional 
Independence
Independence: 
P(A&amp;B) = P(A)  P(B)
A varies the same within B as it does in the 
universe
Conditional independence within C
P(A&amp;B|C) = P(A|C)  P(B|C)
When we restrict attention to C, A and B are 
independent
6.871 - Lecture 10 9</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Illustrating Evaluation
U1 U2
R. 64 .36 .5
B. 96 .04 .5+25.60
-7.20
-3.20
+36.00+18.40
16.40
38.4037.60+32.80
-4.04
4.00-0.0418.8035.20 27.20
-.80.5
R
Ba1
a2
a1
a2$100.00$40.00
-$20.00
-$5.00
$40.00
-$20.00
-$5.00
$100.00.64
.36
.64
.36
.96
.04
.96
.04-$8.00
.5
6.871 - Lecture 10 27</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Expected Monetary Value
Suppose there are several possible outcomes
Each has a monetary payoff or penalty
Each has a probability
The Expected Monetary Value is t he sum of  the products of the 
monetary payoffs times their corresponding probabilities.
.8
.2$40
-$20
EMV = .8  $40 + .2   -$20  =  $32 +   (-$4)   =  $28
EMV is a normative notion of what a person who has no other biases 
(risk aversion, e.g.) should be willing to accept in exchange for the 
situation.  You should be indifferent to the choice of $28 or playing the 
game.
Most people have some extra biases; incorporate them in the form of a 
utility function applied to the calculated value.
A rational person should choose the course of action with highest EMV.
6.871 - Lecture 10 23</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Noisy OR
Another element in the modeling vocabulary
Assumption: only 1 disease is present at a time
Probability that all diseases cause the symptom is just the 
probability that at least 1 does
Therefore: Symptom is absent only if no disease caused it.
Reduces probability table size: if n diseases and k 
symptoms, from k2^n to nk1 -P(S2|D1,D2,D3) = (1 - P(S2|D1)) 
* (1 - P(S2|D2)) 
* (1 - P(S2|D3))  
6.871 - Lecture 1014</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Summary
Several approaches to uncertainty in AI
Bayes theorem, nets a current favorite
Some tractable Bayesian situations
A recurring theme: battling combinatorics 
through model assumptions
Decision theory and rational choice
6.871 - Lecture 1031</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Some Representations  of Uncertainty
Standard probability
too many numbers
Focus on logical, qualitative
reasoning by cases
non-monotonic reasoning
Numerical approaches retried
Certainty factors
Dempster-Schafer
Fuzzy
Bayes Networks
6.871 - Lecture 10 5</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>A Decision Making Problem
Two types of Urns: U1 and U2 (80% are U1)
U1 contains 4 red balls and 6 black balls
U2 contains nine red balls and one black ball
Urn selected at random; you are to guess type.
Courses of action:
Refuse to play  No payoff, no cost
Guess it is of type 1 $40 if right, -$20 if  wrong
Guess it is of type 2 $100 if right, -$5 if  wrong
Sample a ball $8 for the right to sample
6.871 - Lecture 10 21</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Sequential Bayesian Inference
Consider symptoms one by one
Prior probabilities P(Di)
Observe symptom Sj
Updates priors using Bayes Rule:
Repeat for other symptoms usin g the resulting posterior as 
the new prior
If symptoms are conditionally in dependent, same as doing it all 
at once
Allows  choic e of what symptom to observe (test to perform) next 
in terms of cost/benefit.P(Di)=P(Sj|Di)P(Di)
P(Sj)
6.871 - Lecture 1012</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Outline
A Problem with Mycin
Brief review of history of uncertainty in AI
Bayes Theorem
Some tractable Bayesian situations
Bayes Nets 
Decision Theory and Rational Choice
A recurring theme: battling combinatorics 
through model assumptions
6.871 - Lecture 10 2</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Example
Burglary Earthquake
Alarm Radio Report
Phone Call
P(Call|Alarm)tf
t
f.9 .01
.1 .99P(RadioReport|Earthquake)tf
t
f10
0 1
P(Alarm|B,E) t,t t,f
t
f.8 .99
.2 .01f,t f,f
.6 .01
.4 .99
16 vs. 32 probabilites
6.871 - Lecture 1017</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Decision Making
So far: how to use evidence to evaluate a situation.
In many cases, this is only the beginning
Want to take actions to improve the situation
Which action?
The one most likely to leave us in the best condition
Decision analysis helps us calculate which action that is
6.871 - Lecture 10
20</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Decision Flow Diagrams
Decision Fork
6.871 - Lecture 10Chance Fork
R
Bg1
g2
g1
g2Refus e to Play
Make an 
Observatio n-$8.00(R)
(B)(R, g1)$40.00
-$20.00
-$5.00
$100.00
$40.00
-$20.00
-$5.00
$100.00$0.00
No
Observatio n
g1
g2$40.00
-$20.00
-$5.00
$100.0022</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Examples
BADA
C
B
A and B are independent A and B are dependent
A and B are conditionally
dependent , given CA and B are conditionally
independent , given C.
6.871 - Lecture 10 10</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Polytrees
What if diseases docause or influence each other?
Are there still well behaved versions?
Polytrees: At most one path between any two nodes
Dont have to worry about double-counting
Efficient sequential updating is still possibleD1
D2D3S1
S5 S2S4
S3
6.871 - Lecture 1015</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Nave Bayes Model
DS1
SK
Single disease, multiple symptoms
N symptoms means how many probabilities?
Assume symptoms conditionally independent
now P(S1,S2|D) = P(S1|D) * P(S2|D)
Now?
6.871 - Lecture 10 11</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Maximum Entropy
For each outcome of a test calculate the change in entropy.
Weigh this by the probability of that outcome.
Sum these to get an expected change of entropy for the test.
Chose that test whic h has the greatest expected change in 
entropy.
Choos ing test most likely to  provide the most information.
Tests have different costs (somet imes quite drastic ones lik e life 
and death).
Normalize the benefits by the costs and then make choice.
6.871 - Lecture 1030</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Representations for KBS:
Uncertainty &amp; Decision Support
6.871 -- Lecture 10
6.871 - Lecture 101</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>More Problems
If CF(A) = .8 and CF(B) = .3
AC
BC
A or BC
IF A B, A C, B D, C D there will also be a 
mistake: (why?)
B
CAD
6.871 - Lecture 10 Then CF (C )  = .8 + .3 * (1 -.8) = .8 + .06 =  .86
CF (OR A B) = (Max .8 .3) = .8 and CF(C ) = .84</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Final Value of Decision Flow Diagram
R
Ba1
a2
a1
a2Refus e to Play
Make an 
Observatio n-$8.00(e1,R)
(e1,B)(e1,R, a1)$40.00
-$20.00
-$5.00
$100.00
$40.00
-$20.00
-$5.00
$100.00$0.00
No
Observatio n
a1
a2(e1,R, a1)$40.00
-$20.00
-$5.00
$100.0027.20
$28.00$28.00
6.871 - Lecture 10 28</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>A Problem with Mycin
Its notion of uncertainty seems broken
In Mycin the certainty factor for OR is Max
CF (OR A B) = (Max (Cf A) (Cf B))
Consider 
Rule-1 IF A then C, certainty factor 1
Rule-2 If B then C, certainty factor 1 
This is logically the same as
If (Or A B) then C, certainty factor 1
6.871 - Lecture 103</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>The Effect of Observation
R
Ba1
a2
a1
a2$40.00
-$20.00
-$5.00
$100.00
$40.00
-$20.00
-$5.00
$100.00U1
U2Bayes theorem used to calculate probabilities at chance 
nodes following decision nodes that provide relevant 
evidence.
P(R) = P(R|U1)  P(U1 ) + P(R|U2)  P(U2)
P(U1|R) = P(R|U1)  P(U1) / P(R)
Action
State A1 A2            A3 Probabilit y
U1 40 -5              0 .8
U2 -20 100              0 .2
EMV 28 16              0  1
P(r|u1)= .4 P(U1)=.8 P(R| u2)=.9 P(u2)=.2 P(r)=.5
P(U1|r)= .4 * .8  / .5 = .646.871 - Lecture 10
25</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Reviewing Bayes Theorem
Symptom S
1)( ) ( =iii DP that suchD states health Diseases
Conditional Probability of S given D
DS
DU
P(S|D)=P(S&amp;D)
P(D)
P(D|S)=P(S&amp;D)
P(S)P(S)=P(S&amp;D)+P(S&amp;D)
P(S)=P(D)P(S |D)+P(D)P(S |D)
P(D|S)=P(S|D)P(D)
P(S)
6.871 - Lecture 10P(Di|S)=P(S|Di)P(Di)
P(S)P(S)=P(Dj)P(S|Dj)
j
7</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Computing with Partial Information
Probability that A true and E false:BA
E DC
Graph separators (e.g. C) correspond to factorizations
General problem of finding separators is NP-hardP(A,E)= P(A,B,C,D,E
B,C,D )
= P(A)P(B|A)P(C|A)P(D|B,C)P(E|C)
B,C,D
=P(A)P(C|A)P(E|C)P(B|A)P(D|B,C)
D
B
C
Norm ally have to do 2^3 comput ations of the entire formula.
By factori ng can do 2^3 com putations of last term, 2 of second 2, 2 of fi rst
Sum over c doesnt change when D changes, etc.6.871 - Lecture 10
18</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Summary of Knowledge Representation (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect13_whatkr/</lecture_pdf_url>
      <lectureno>13</lectureno>
      <slides>
        <slide>
          <slideno>29</slideno>
          <text>Summary
	Fundamental task of KR: 
Capturing the richness of the natural 
world. 
6.871 - Lecture 13 30</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>What Should A Representation Be?
	Theres significant power in attending to 
the domain. 
	Domain independent languages are 
overlooking an important source of power. 
6.871 - Lecture 13 27</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>What Is A Knowledge 
Representation?
6.871 - Lecture 13</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>[3] Fragment of a Theory of 
Intelligent Reasoning
	What are all the inferences am I permitted 
to make? 
 Example: classical formal logic; sound 
inference
 Other answers 
	Logic: circumscription 
	Rules: plausible inference 
	Frames: good matches, expectations, defaults. 
6.871 - Lecture 13 16</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>[4] Medium for pragmatically 
efficient computation
	The pragmatics of it: How can I organize 
information to facilitate reasoning? 
 Example: 
Frames  triggers, procedural attachment, 
taxonomic hierarchies 
6.871 - Lecture 13 19</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>What Is a KR?
4) Its a medium for pragmatically efficient 
computation. 
The computational medium in which thinking is 
accomplished. 
How should I organize information to facilitate 
that thinking? 
5) Its a medium of expression and communication. 
A language we use to talk to the machine. 
6.871 - Lecture 13 5</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>[1] Its A Surrogate
 Questions: 
 A surrogate for what?   semantics
 How accurate a surrogate?  fidelity 
 More fidelity is not automatically better 
 Perfect fidelity is impossible. 
6.871 - Lecture 13 10</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>[2] Set of Ontological 
Commitments
 The commitment accumulates in layers
 EG: medical diagnosis 
f r a m e s  prototypes, defaults, taxonomy
 prototypes of what? 
 what diseases? 
6.871 - Lecture 13 13</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>What Should A Representation Be?
1) Surrogate: imperfect fidelity 
 incorrect inference is inevitable 
 take a pragmatic view of soundness/efficiency 
2) Ontological commitment 
Unavoidable 
One of the most important things a KR can supply A source of power Insufficiently explored (but this is changing) Important at the tool level 
6.871 - Lecture 13 21</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Terminology and Perspective
 Inference = getting new expressions from old 
Not limited to deductive (sound) inference.
	Knowledge Representation Technologies: 
rules, frames, logic, semantic nets, etc. 
6.871 - Lecture 13 3</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>[1] Its A Surrogate
	A stand-in for the object in the real world.
	Operations on the KR substitute for actions in 
the world. 
	Reasoning is itself a substitute for action.
	(Conversely, actions can substitute for 
reasoning). 
6.871 - Lecture 13 6</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Outline
	What Is A Representation? 
F i v e  R o l e s 
	What Should A Representation Be?
	What Consequences Does This View Have For 
Research And Practice? 
	One answer to a foundational question 
	The spirit of a representation 
 The spirit should be indulged 
	In analysis 
	In system construction 
	The central task of knowledge representation 
6.871 - Lecture 13 2</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>[1] Its A Surrogate
 Questions: 
 A surrogate for what?   semantics 
 How accurate a surrogate? 
6.871 - Lecture 13 8</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>What Should A Representation Be?
Every representation is only one of several possible approximations to 
reality. 
 there is no one right one 
 one or another may be better suited to a specific task 
 need to connect representation to  the reasoning to the task 
 Let the domain tell you: 
a good set of abstractions (ontology) 
which inferences are needed/recommended 
 Build those abstractions into the language 
 Make the recommended inferences easy 
6.871 - Lecture 13 26</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>What Should A Representation Be?
3) Theory of intelligent reasoning
Representations should inform the reasoner 
about what inferences should be encouraged
6.871 - Lecture 13 22</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>[4] Medium for pragmatically 
efficient computation
	Reasoning with KR means computing with 
it. 
	The pendulum swing 
 Heuristic adequacy (1969)
 The logicist view (circa 1974) 
 The computational imperative view (circa 
1984) 
6.871 - Lecture 13 18</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>[1] Its A Surrogate
Perfect fidelity is impossible 
 We inevitably lie. 
 Incorrect inferences are inevitable. 
Sound reasoning cant save us.
A better representation cant save us. 
 We have already sinned. 
 We may as well be pragmatic about it. 
6.871 - Lecture 13 11</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Summary
 What Is A Representation 
1. Its a surrogate, one of several approximations.
2. Its a set of ontological commitments. 
3. Its a fragment of a theory of intelligent reasoning.
4. Its a medium for pragmatically efficient computation. 
5. Its a medium of ex pression and communication.
6.871 - Lecture 13 28</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>[5] Medium of Expression and 
Communication
 Its how we say things about the world. 
 Its how we communicate with the reasoner.
 In principle, as a medium of expression: 
 How general, how precise? 
 Does it provide expressive adequacy?
 In practice, as a medium of communication:
 How transparent is it?
Can we understand whats been said?
Can we generate the right expression?
6.871 - Lecture 13 20</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>[1] Its A Surrogate
 Questions: 
 A surrogate for what?   semantics
 How accurate a surrogate?  fidelity 
6.871 - Lecture 13 9</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>What Is a KR?
1) Its a surrogate. 
A substitute for the thing itself. 
2) Its a set of ontological commitments. 
In what terms should I think about the world? 
3) Its a fragment of a theory of intelligent reasoning. 
 What is intelligence?
 What can I infer from what I know?
(i.e., which inferences are sanctioned?)
 What should I infer from what I know? 
(i.e., which inferences are recommended?) 
6.871 - Lecture 13 4</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>What Should A Representation Be?
4) Medium of pragmatically efficient computation 
 In real use: average time complexity matters. 
 Doing well most of the time on problems actually 
encountered 
 In real use: worst cases need not be fatal. 
 Coroutine-style resource-limited compn is interruptible 
 freedom from requiring guarantees 
 Representation should inform the reasoner about how 
to organize information to make the encouraged 
inferences inexpensive, on average. 
 data structures 
Ex: a-k-o assertions vs a-k-o links 
6.871 - Lecture 13 23</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Summary
	What Should A Representation Be? 
	Pragmatic in its view soundness and efficiency. 
	Strong in ontological commitment. 
	Pluralistic in defining sanctioned inferences. 
	Effective in recommending inferences and organizing 
information. 
	Efficient in the average ca se (pragmatic efficiency) 
	Effective as a medium of communication. 
	Supported by guarantees but not limited by them. 
	Focused on the world. 
	Rich in abstractions matched to the task. 
	Indulged. 
6.871 - Lecture 13 29</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>[2] Set of Ontological 
Commitments
	Surrogates are inevitably imperfect
 KR selection unavoidably makes an 
OC. 
	Commitment occurs even at the level of 
the KRTs 
 Diagnosis as rules vs. frames. 
6.871 - Lecture 13 12</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>What Should A Representation Be?
5. Medium of expression and 
communication 
 Possible vs. reasonably obvious and natural. 
6.871 - Lecture 13 24</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>[2] Set of Ontological Commitments
 The commitment accumulates in layers
 EG: medical diagnosis 
f r a m e s  prototypes, defaults, taxonomy
 prototypes of what? 
 what diseases? 
 Commitment is inevitable 
 Commitment is crucial 
6.871 - Lecture 13 15</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>[3] Fragment of a Theory of 
Intelligent Reasoning
 What are all the inferences am I permitted to make? 
 Logic: sound inference 
 Which inferences am I encouraged to make? 
 Example: Frames 
 What reasoning to do: anticipatory matching 
 Other examples 
 SN: propagation; links. 
 Rules: chaining; associations. 
 Logic: lemmas; connection graphs. 
 Combinatorial explosions 
 the need for guidance on what we should do, 
not only what we can do. 
6.871 - Lecture 13 17</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>[1] Its A Surrogate
 Questions: 
 A surrogate for what? 
 How accurate a surrogate? 
6.871 - Lecture 13 7</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>6.871 - Lecture 13 14[2] Set of Ontological Commitments
Alcoholism as disease: View comes into question
Saying that standard treatmen ts have not helped many drugs  and alcohol abusers, some 
people on the front lines of treat ment are challenging the view  of addiction as a disease 
controlled by biological factors.
The idea that alcoholism is a disease that can be treated  like other chronic medical 
conditions has been doctrine si nce the 1960s. By the 80s, the biomedical model had 
become so dominant that many researchers believed it was on ly a matter of time before 
a gene for alcoholism would be found.Now, however, some specialists are backing o ff from that stand. Wh ile biology certainly 
plays a role in addiction, they say, it isnt t he whole or even most of  the story. The social 
and environmental factors behind why people drink or take drugs, as well as their beliefs 
about how their drug of choice helps them , are just as crucial in understanding and 
treating addictions, they argue.The negative effects of stressful life event s, socioeconomic status and unemployment 
are key factors, says Emil Chiauzzi, clinical  director of addiction services for the 
Deaconess-Waltham Hospital. And people do no t become addicted only to a drug, but to 
the drug experience, the rituals involved.
4/9/06 p.1 Adapted from
Boston Globe</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>What Should A Representation Be?
	All five roles matter.
	The five roles characterize the spirit of a 
representation. 
	The spirit should be indulged, not overcome.
	Programming the representation 
	If it doesn't fit naturally, design a new one. 
6.871 - Lecture 13 25</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Causal Reasoning (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect14_causal/</lecture_pdf_url>
      <lectureno>14</lectureno>
      <slides>
        <slide>
          <slideno>11</slideno>
          <text>ABEL Representations
low bicarb 
low potassium 
high chlorine causes 
Lower-GI-fluid-loss 
high sodium 
low water volume 
water-loss constituent-of 
bicarb-loss 
sodium-loss Lower-GI-fluid-loss 
potassium-loss chloride-loss 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Multiple Levels
Aggregate Level 
X Composite node 
Focus Link 
causes 
causes 
causes causes 
causescauses Focus Link 
causes causes 
causescauses causes 
Elaboration Structure Focus Link Aggregate Level 
Detailed Level Detailed Level 
Focus 
Node Focus Node Focus Node 
Elaboration Structure 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>The Intuition
 A flooded basement
 An auto accident 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Whats In A PSP?
	A representation for factual knowledge.
	Inferential methods 
	A control structure dictating when to 
employ the inferential methods and with 
what purpose. 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Rules Model Interactions
Pattern constraints 
R1 IGN R2 Igneous(IGN) 
Same-type(R1, R2) 
Parallel(e1,e2) 
e1 e2 
Events: 
create rock1 
intrude IGN through rock1 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>ABEL: Modeling Feedback
causes 
Low pH-1 Increased 
Respiration Rate 
component of component of 
causes 
Low pCO2-1 Hi pH-3 Low pH-2 Low HCO3-1 
causes causes 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Outline
 Problem Solving Paradigms 
 What are they and what are they good for 
 Causal reasoning as a PSP 
 ABEL 
 Causal reasoning + rules + debugging
 GORDIUS 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Caveats
	A problem solving paradigm suggests control structures 
and inference mechanisms 
	but is not synonymous with them.
	A knowledge representation suggests certain data-
structures and control structures 
	but it is not synonymous with them.
	Problem solving paradigms and knowledge 
representations are knowledge level constructs, not 
mechanisms or data structures. 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>A Basic Paradigm:
Means Ends Analysis
Current
Detect
Differences
Achieve Goal
Preconditions
Reduce
Remaining
Differences
Apply Relevant
Operator
Operator Difference Table
Walk Bike Taxi Bus
&lt;1 
x
x
x
x
x
x
 x
x
Choose Relevant
Operator
1-5
5-50
50-500
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Diagnosis: A Classic Generic Task
P S P s 
 Bayesian statistics 
 Nave Bayes rule 
 Sequential Bayesian diagnosis 
 Frequency and invoking strength: Internist 
 Empirical associations: Mycin 
 Causal: ABEL 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>ABEL
 Domain? 
 Representation?
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>A Recipe
	Study how experts characterize problems 
and solution methods, especially their 
technical vocabulary 
	Mimic their representation, capture the 
abstractions 
	Mimic their problem solving mechanism
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Combining Paradigms
 Gordius: 
 Generate  test  debug 
 Rules + Causal Models 
 Whats generate and test as a PSP?
 Dendral as an example 
 What did Dendrals tester tell you? 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>ABEL
	Causal knowledge represented at multiple levels of 
description 
	Each causal relation charac terized by constraints among 
severity, duration, etc. between cause and effect 
	Each causal relation described at next more detailed 
level 
	Each disease node described using network of nodes 
and causal links at next more detailed level 
 Goal: assemble a causal explanation of all findings using 
a network of causal relations at many levels of detail.
	Models interactions between the hypothesized diseases
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>This Works Because
	There are generic task types that span many domains
	There are a modest number of problem solving 
paradigms and their knowledge representations 
	Each generic task has a variety of appropriate problem 
solving paradigms 
	Representations indicate how to look at the world: 
capture the important abstractions of the problemdomain. 
	Problem solving paradigms organize representational,
inferential and computational processes; indicate when 
and how to draw conclusions. 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>GORDIUS
 Domain/task?
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>ABEL Operations
	Elaboration : Makes connections across levels of 
detail by filling in the structure below 
	Aggregation: Makes connections across levels 
of detail by filling in the structure above 
	Component Decomposition: Relates disorders at 
the same level of detail by breaking up a node
into component parts 
	Component Summation: Relates disorders at the 
same level of detail by summing (arithmetically)
contributions of components parts. 
 Projection: Forges causal links at the same level 
of detail in the search for etiologic explanation
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Debugging
 Dependency maintenance 
 height affected by: 
 shale is produced underwater
 shale deposit depth 
 height is unchanged since deposition 
 sea level unchanged since deposition 
 Repair strategies 
 unchanged assumption 
 parameter value assumption 
 time ordering assumption 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Problem Solving Paradigms:
Causal Reasoning
6.871  Lecture 14</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>ABEL: Multiple Levels
Clinical Level 
dehydration diarrhea 
causes 
focus focus 
dehydration diarrhea Lower-GI-Loss causes causes 
focus focusfocus Intermediate Level 
dehydration diarrhea Lower-GI-Loss causesPathophysiological Level 
const-of 
Sodium-Loss 
causes 
water-Loss 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Local Matching
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Lower GI Fluid Plasma Fluid 
Na 100-110 138-148 
K 30-40 4-5 
Cl 60-90 100-110 
HCO3 30-60 24-28 
Compared to plasma:
Lower GI Fluid is rich in HCO3 and K; low in NA and Cl 
Loss of GI Fluid results in 
reduced fluid in (hypovolemia)
reduced K (hypokalemia)
reduced HCO3 (hypobicarbonatemia)
increased Cl (hyperchloremia)
increased Na (hypernatremia)
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Processes
 Deposition 
 Intrusion 
 Fault 
 Uplift/subsidence
 Tilt 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Summary
 Problem Solving Paradigms 
 What are they and what are they good for 
 Causal reasoning as a PSP 
 ABEL 
 Causal reasoning + rules + debugging
 GORDIUS 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Accounting For Multiple Causes
causes Metabolic causes 
Acidosis-1 Shock-1 diarrhea-1 
focus 
focus focus 
Metabolic 
Acidosis-1 
Component of Component of 
causes causesMetabolic Metabolic Acidosis-2 Acidosis-3 Shock-1 diarrhea-1 
6.871 - Lecture 14</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Why Concentrate on 
Paradigms?
	Special purpose programming languages for the 
paradigm can be created and reused. 
 Knowledge acquisition tools specific to the 
paradigm can be designed and reused.
	Maintainability is improved. 
	Need for "programming hacks" reduced.
	Emphasizes the search for the right level of 
abstraction. 
6.871 - Lecture 14</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Frame-Based Systems (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect09_frames/</lecture_pdf_url>
      <lectureno>9</lectureno>
      <slides>
        <slide>
          <slideno>18</slideno>
          <text>Not in the Spirit: FRL
	Where is the theory of intelligent reasoning?
	Where are the glasses? 
	Instead of knowledge representation we 
have? 
	A common mistake:  focus on mechanism 
instead of intent. 
6.871  Lecture 9 19</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>In the Spirit: Internist-1
 Doctors move from more general to more specific disorders 
 Need hierarchy of frames 
ALCOHOLIC HEPATITIS
AKO Hepatitis
Findings
Age 16-25 0 1 
Age 26-55 0 3 
Age &gt;55 0 2 
Alcohol History 2 4 
Causes Hepatatic Encephalopathy 2 2 
 Hierarchy, rooted on organ systems 
 The numbers: evoking strength and frequency 
 500 disease frames, 3500 findings 
6.871  Lecture 9 15</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Frame-Based Systems
6.871 Lecture 9</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Comparing the Technologies
Reasoning 
 Logic 
 Formal deduction 
 Results precisely determined 
 Rules 
 Chains of heuristic associations 
 Uncertainties combined 
 SI-Nets 
 Logic-based subsumption algorithm 
 Formal method and result 
F r a m e s 
 Heuristic matching of instances to prototypes 
 Ranked by closeness 
6.871  Lecture 9 23</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Not in the Spirit: FRL
	Task: a scheduler constraint propagation + 
common sense 
	Hierarchical frames; viewed as property lists (!)
	Wide variety of explicit slot types, e.g.: 
	Comments (source of value) 
 Defaults
V a l u e
	Constraints on values 
	Attached procedures 
	IfNeeded, IfAdded, IfRemoved 
	Looks like? 
6.871  Lecture 9 17</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Motivations
	A model of human cognition; the structure of 
knowledge memory; common sense reasoning 
	Explain why understanding is  
f a s t 
	anticipatory 
	persistent over changes in perspective
 tenacious: Colorless green ideas sleep furiously. 
Chomsky 
6.871  Lecture 9 7</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Motivations
	A model of human cognition; the structure of 
knowledge memory; common sense reasoning 
	Explain why understanding is 
	fast 
6.871  Lecture 9 4</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Example
Birthday Party 
6.871  Lecture 9 11 
Have students make suggestions about  frame system for birthday party; record on the board.</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Comparing the Technologies
Representation and reasoning using
Logic: bird(x) can-fly(x) 
Rules: If class of animal is bird then animal can fly (.9) 
SI-Nets: Animal Loco 
Fly 
Frames: 
Bird 
Class Animal 
Loco Fly 
6.871  Lecture 9 21</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Use
 Frames are a useful representation when 
the task is to  
6.871  Lecture 9 9</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Motivations
	A model of human cognition; the structure of 
knowledge memory; common sense reasoning 
	Explain why understanding is  
f a s t 
	anticipatory 
	persistent over changes in perspective 
6.871  Lecture 9 6</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>FRL
MEETING
AKO VALUE Activity
WHO REQUIRE EXIST x Chairman(x)
WHEN
RA-GROUP-MEETING
AKO VALUE MEETING
WHERE DEFAULT ConferenceRoom1
WHEN DEFAULT Friday
PREFER Weekday
ACTIVITY
AKO VALUE THING
WHEN IfAdded AddToCalendar
6.871  Lecture 9 18</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Frames Summary
	Inspired by human understanding and 
reasoning 
	Prototypes and matching as key concepts
	Representations evolve: Originally a 
model of human memory and cognition, 
now at times used more mechanistically 
6.871  Lecture 9 20</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Motivations and Observations
	A model of human cognition; the structure of knowledge 
memory; common sense reasoning 
	Explain why understanding is  
f a s t 
	anticipatory 
	persistent over changes in perspective 
	tenacious: Colorless green ideas sleep furiously. 
	Meaning is poorly approximated by dictionary defns.
	Memory is full of prototypical situations, richly 
interconnected. 
6.871  Lecture 9 8</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>PIPs Machinery
 Hypothesis generation vi a data-driven triggering 
 Frame moves into short term memory 
 Nearby frames become semi-active 
 Hypothesis testing via calibrating match of data &amp; frame 
 Match of frame and data 
 Sufficiency, exclusionary rules 
S c o r i n g 
 Ability to explain the findings 
 Additional data gathering to fill terminals 
 Asks questions 
6.871  Lecture 9 14</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Motivations
	A model of human cognition; the structure of 
knowledge memory; common sense reasoning 
	Explain why understanding is  
f a s t 
	anticipatory 
6.871  Lecture 9 5</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>In The Spirit: PIP
NephroticSyndrome
IS-A 
Finding
Finding
Finding
MustNotHave Sufficient ClinicalState 
Low Serum Albumin 
Heavy Proteinuria 
 
Proteinuria Absent 
Pedal edema and proteinuria &gt; 5gm/day
MayBeCausedBy Acute Glomerulonephritis MayBeCompBy Hypovolemia 
Scoring
Edema:	 Massive, symmetrical: 1.0
Not massive, symm. 0.5
Asymmetrical -0.5 

 70 Disease frames, 500 findings 
 Variety of interconnections: MustNotHave, ComplicatedBy 
6.871  Lecture 9 13</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Details
 Frames are networks 
 Top levels fixed 
 Lower levels hold specific instances of data 
 Terminals holding data have easily displaced 
defaults 
 Inferencing is matching of data to prototype 
 Subjective, approximate 
 Optional (in the original conception): 
 Hierarchy of frames, inheritance 
 Daemons:  procedures triggered when needed 
6.871  Lecture 9 10</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>A KR Should Tell You
	What to attend to: 
A Frame [represents]  
	What inferences are recommended: 
Minsky A Framework for Knowledge Representation 
6.871  Lecture 9 3</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>In The Spirit: PIP
 Motivated by data on clinical cognition:
 Quick focus on little data 
 Not easily refocused 
 Ask discriminating questions 
 Answer is an ordered list of matches
 Wanted expert level performance 
6.871  Lecture 9 12</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Internist-1: Reasoning
	Begin with lots of data
	Evoking strength determines active 
hypotheses 
 increased/decreased for present/absent 
findings
	Matching controlled by undershoot and 
overshoot 
	Reasoning strategies 
 pursue, rule out, discriminate
6.871  Lecture 9 16</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Comparing the Technologies
Granularity of unit of meaning 
 Logic 
 Axioms 
R u l e s 
 Centered around heuristic association 
 Individual inference step 
 SI-Nets 
 Organized around nouns 
 Necessary and sufficient conditions
F r a m e s 
 Organized around prototypes 
 Meaning spread throughout the network. 
6.871  Lecture 9 22</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Outline
 Minskys original motivations, observations
 Details and use 
 In the spirit: PIP and Internist-1 
 Not in the spirit: FRL 
 Frames summary 
 Comparison of KR technologies 
6.871  Lecture 9 2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Ontologies and Data Mining (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect22_ontolog/</lecture_pdf_url>
      <lectureno>22</lectureno>
      <slides>
        <slide>
          <slideno>39</slideno>
          <text>Other Examples
 Enterprise Ontology     (Edinburgh; Uschold, et al.)
 Document comparison (Xerox; Everett, et al.)</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Some Large Ontologies
Published Online Semantic 
Network135 Semantic Types, 54 semantic relations, 
975,354 conceptsUMLS 
biomedicinePublished Online Semantic Network70,000 terms
extension of WordNetSensus
text understandingPublished Online Semantic 
Network152,059 word forms in 115,424 synsetsWordNet
lexical memoryPublished Online KIF
Also LOOM, 
OWL,Protege1000 terms,
4200 assertionsSUMO
upper ontologyPartially Online: 
6000 Top ConceptsCYCL 10
5concept types, 106 
axiomsCYC
common sense</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Aspects of an Ontology
 Content
F o r m
 Is the taxonomic relationship (instance-of, subclass) 
primary?
 Are definitions of, or constraints on, terms provided?
 Is the definitional language as rich as a full logic? Is it process-centric or object-centric?
P u r p o s e
 Development</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Perspectives
 Philosophy
 Library and Information Science Natural Language Processing Artificial Intelligence
 Objectives:  Model common sense and domain 
knowledge
 Usage:  Knowledge representation and reasoning
 E.g.:  OpenMind, CYC; UMLS, ...
 Semantic Web</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>IncapacitateDestroyForce Destroy
Thermal DestroyFail
Break
Wreck
Destroy
Raze
Disable
DamageRuin
Demolish
TerminateCrush
Shatter
Smash
Mangle
Pulverize
Fry
Incinerate
MeltSquash
Shred
Eviscerate
Crunch
Topple
Mash
Devour
Puncture
SnapForce Damage
Gouge
Trample
Scratch
Crash
Pierce
Chip
Tear
Crack
Cut
Crumple
Dent
Abrade
Rip
Slice
Bend
Nick
Thermal Damage
Burn
ScorchScaldCorrupt
Damage
Disrupt
HarmRemove
DisableA direct word-to-concept ontology for the concept Incapacitate.
Figure by MIT OCW.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Ontologies
6.871:  Lecture 22</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Example Ontologies
see http://www.cs.utexas.edu/u sers/mfkb/related.html
    * ARPI Plan n in g and Sch ed uli n g  o n to lo gi es
    * Aviat io n  O n to lo g y
    * BPMO - Th e Busin es s P roc es s Ma n ag eme nt  On to log y
    * CYC (an d th e  d e riva tive  PDKB)
    * DOLCE -  a  Des cript ive  On to lo g y fo r Lin g u is tic a n d C o g ni tive  En gi n e ering .
    *  Dubl in Co re (b i b l iograp h i c orga ni za tion)   * The Ent erp rise Onto log y (for  b u sin es s e n terpr ise s)
    * On to lo g ies f or  e tho lo g y (anim al be h av ior) , e.g . Log g e rh ead T u rt le
    * F rameNet (lexical reference)    * Gen eraliz e d Up p er M o de l (for  NLP)
    * Mik roko sm os  (fo r NLP)
    * ON9  (th e CNR- ITBM On to lo g y Libra ry)
    * OWL- S - Th e OWL  (form erly DAML) Service s on tolog y.
    * On to lin g u a  O n to lo g y Libra ry    * Op e n Min d datab a s e  a nd OM CSNe t S em ant ic N et wor k
    *  Pha rmGK B - Ph armacogenetics and Ph armacogen o mic s Kn o wle d ge  B ase
    * PSL (p roces s s pe cifi cation)    *  Q oS  (comput ers  a nd ne tworks)
    * SENSUS (fo r NLP)
    * STEP (for  pr o du ct data  ex ch an ge )
    * SUMO (th e  Su gg es te d  Upp e r M e rg ed  On to log y)
    * the T wente Onto logy Collection    * UMLS  (b io me d icin e)
    * Wilkin s ' on t o log y (17t h  ce nt u ry!)
    * Word Ne t (lex ical re fe re n ce )</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text></text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Perspectives
 Philosophy
 Library and Information Science Natural Language Processing Artificial Intelligence Semantic Web
Fredrik Arvidsson, Annika Flycht-Eriksson</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Natural language requires a huge ontology 
xxxxxxxxx
(1) The left cover broke in half.
(2) The sheet of paper breaks the light beam.(3) Before doing step 3, you might want to break for coffee.</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Perspectives
 Philosophy
 Library and Information Science Natural Language Processing
 Objectives:  Model lexical and domain knowledge
 Usage:  Machine Translation, Information Extraction, 
Q/A
 E.g.: Wordnet, Sensus, Generalised Upper Model
 Artificial Intelligence
 Semantic Web</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Pragmatic Motivations
 Responding to the unexpected
 Distributed Databases Distributed Applications Communicating Agents Semantic Web
db1db2db3schema1schema2schema3Common OntologyMediator
Analysis Common OntologyDesign Common OntologyApplication 1
Application 2Key Question : What does 
he mean when he says 
&lt;&gt;?
Person</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>EXAMPLE OF EUREKA TIPS
PROBLEMTIP 27057 TIP 27118Left cover damage
The current safety cable used in the 5100 
Document Handler fails prematurely, 
causing the Left Document Handler Coverto break.The plastic jacket made the cable too 
stiff. This causes stress to be concentrated
on the cable ends, where it eventuallysnaps.When the old safety cable fails, replace it 
with the new one, which has the plastic
jacket shortened.The left cover safety cable is breaking, allowing the left cover to pivot too far,
breaking the cover.Remove the plastic sleeve from around 
the cable. Cutting the plastic off of the 
cable makes the cable more flexible,
which prevents cable breakage. Cablebreakage is a major source of damage 
to the left cover.CAUSE SOLUTION
Figure by MIT OCW.</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>Other Examples
 Enterprise Ontology     (Edinburgh; Uschold, et al.)
 Goal: improve planning via shared enterprise model
 Meta-ontology: entities, relationships, states of affairs Examples</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Natural language requires a more abstract ontology 
one.
(1) The left cover broke in half.                        BreakDamage
(2) The sheet of paper breaks the light beam. BreakInterrupt
(3) Before doing step 3, you might want to break for coffee.
BreakRecuperate
Map to concepts instead.</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>CYC Top Level Categories
Thing
Individual Object Intangible Represented Thing
Event IntangibleObject Collection Stuff
IntangibleStuff Process
InternalMachineThingRelationship
Slot
AttributeAttributeValueSomethingExisting
Intelligence
CompositeTangible&amp;IntangibleObjectTangibleObject
TangibleStuff</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Perspectives
 Philosophy
 Library and Information Science Natural Language Processing Artificial Intelligence Semantic Web
 Objectives:  Provide semantics for web resources
 Usage:  Describe resources and their contents</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Aspects of an Ontology
 Content
F o r m  P u r p o s e Development</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Perspectives
 Philosophy
 Objectives:  Classify and categorize the world
 E.g.: Aristotle  
 Library and Information Science
 Natural Language Processing Artificial Intelligence Semantic Web</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Ontology vs KB?
 Can think of an ontology as a kind of KB, but:
 Ontology serves different purpose:
 Only needs to describe vocabulary, axioms
 E.g. database schema is an ontology
K B includes:
 Specific knowledge needed for problem-solving</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>IncapacitateDestroyForce Destroy
Thermal DestroyFail
Break
Wreck
Destroy
Raze
Disable
DamageRuin
Demolish
TerminateCrush
Shatter
Smash
Mangle
Pulverize
Fry
Incinerate
MeltSquash
Shred
Eviscerate
Crunch
Topple
Mash
Devour
Puncture
SnapForce Damage
Gouge
Trample
Scratch
Crash
Pierce
Chip
Tear
Crack
Cut
Crumple
Dent
Abrade
Rip
Slice
Bend
Nick
Thermal Damage
The short circuit burns
 the drive gear.The heat from the short circuit
cracks the drive gear.
Burn
ScorchScaldCorrupt
Damage
Disrupt
HarmRemove
DisableA direct word-to-concept ontology for the concept Incapacitate.
Figure by MIT OCW.</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Natural language requires a huge ontology 
xxxxxxxxx
(1) The left cover broke in half.                        BreakDamage
(2) The sheet of paper breaks the light beam. BreakInterrupt
(3) Before doing step 3, you might want to break for coffee.
BreakRecuperate</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>Taxonomic Hierarchies
 Not always obvious what is class, instance, 
role, etc.
 E.g., what is the relationship between:
 time duration (instances e.g. 1 hr) and                
time interval (e.g. 1pm to 2pm today)?
 water and ocean ?
m a m m a l and human and a particular human ?
h u m a n and species ?
 book that is a bound volume, book that is abstract 
concept?</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>What is an Ontology?
 A formal, explicit specification of a shared 
conceptualization.
 A shared vocabulary that can be used to model a 
domain, i.e., the objects and/or concepts that 
exist, their properties and relations
 Imposition of specific set of conceptualizations on 
a domain of interest
 Tell me about analog electronics
 Tell me about digital electronics
 Definitions of terminology
 and constraints between terms
 Domain mini-theories</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>CYC
 Goal: Encode all of human common sense 
knowledge
 Mechanization: human-entered axioms
 Periodic review, reorganization, compaction, 
separation into distinct mini-theories, not 
mutually consistent
 Driven by application domains
 Often seems ad-hoc</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>CYC Ontology</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>Instead of traversing subsumption relations , logic representation  supports arbitrary 
binary relations between concepts.  Matching st arts with MidLevel c oncepts, e.g. Damage.Damage
Means
Force
HeatExtent
Partial
TotalEnd State
Deformed
Pieces
Broken Integrity
Pierced
Cut
Mid Level
Concept RoleMaterial
Friable
Flammable
Brittle
Laminar
ElasticMelt
Means
HeatExtent
Partial
TotalEnd State
DeformedMaterial
ElasticGenis
Category Level
Low LevelCategory LevelA description of logic-based ontology for Damage.
KEY
Metaproperty
Figure by MIT OCW.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Aspects of an Ontology
 Content
F o r m  P u r p o s e Development
 Is it acquired or engineered?
 If acquired, what about:
 Quality of knowledge
 Diversity of content Trust in knowledge Unpredictable use</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>UMLS
Heart DiseasesCarcinoid 
Heart Disease
Endocarditis
Myocardial 
Ischemia
ArrhythmiaCoronary 
DeseaseCoronary Aneurism
Coronary 
Arteriosclerosis
Angina PectorisAngina Pectoris 
variant
Angina unstable
Coronary Thombosis
Coronary Vasopasm
Shock CardiogenicMyocardial 
Stunning
Myocardial 
Infarction
Figure by MIT OCW.</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>CYC Examples (contd)</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Example Tools for Ontologies
see http://www.cs.utexas.edu/u sers/mfkb/related.html,
http://www.xml.com/pub/a/ 2002/11/06/ontologies.html
    * Ch im ae ra
    * CODE4
    * Gen eric Kn o wled g e-B as e Ed itor
    * Ika ru s
    * JOE (Java  O n to lo g y Edit or)
    * KAON    * KACTUS
    * OilEd
    * On toE d it    * On tos a u ru s
    * Prote ge
    * Sn oba s e
    * Stan ford Onto logy Editor
    * Sym Ont o s    * Wor
dMap</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Aspects of an Ontology
 Content
F o r m  P u r p o s e
 Knowledge sharing
 E.g. Between people, software systems, agents
 Knowledge reuse 
 E.g. When models or systems change
 General (common sense) or domain specific
 Development</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>EXAMPLE OF EUREKA TIPS
PROBLEMTIP 27057 TIP 27118Left cover damage
The current safety cable used in the 5100 
Document Handler fails prematurely, 
causing the Left Document Handler Coverto break.The plastic jacket made the cable too 
stiff. This causes stress to be concentrated
on the cable ends, where it eventuallysnaps.When the old safety cable fails, replace it 
with the new one, which has the plastic
jacket shortened.The left cover safety cable is breaking, allowing the left cover to pivot too far,
breaking the cover.Remove the plastic sleeve from around 
the cable. Cutting the plastic off of the 
cable makes the cable more flexible,
which prevents cable breakage. Cablebreakage is a major source of damage 
to the left cover.CAUSE SOLUTION
Figure by MIT OCW.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Scientific motivation: 
Understand fundamental issues about human 
conceptualizationsMotivations
 Engineering motivation:
 Every knowledge-based system is based on an 
ontology of its domain
 Explication of the ontology is a time-consuming 
component of the development process
 Why not amortize the effort and share ontologies?
 E.g. core ontologies such as space, time, quantities Engineering motivation:
 Scientific motivation:</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Building an Ontology
 Planning
 Specification - consider scope and purpose Knowledge Acquisition Conceptualization - glossary of terms, top-
down, bottom-up, middle-out
 Integration - of existing relevant ontologies Implementation  Evaluation - Clarity, Coherence, Extensibility, 
Minimal Encoding Bias, Minimal Ontological 
Commitment</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>Document Comparison Summary
 Different ways to represent the same knowledge
 Use determines representation Represent only knowledge that is needed c.f.:  Common sense reasoning, dont know use 
or what knowledge is needed.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Protg
http://protege.stanford.edu/</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Application Example
Document comparison (Xerox; Everett, et al. CACM, Feb 02)
 Goal:  Identify similar documents
 Have:  40,000 technician-authored tips for  copier repair</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>IncapacitateDestroyForce Destroy
Thermal DestroyFail
Break
Wreck
Destroy
Raze
Disable
DamageRuin
Demolish
TerminateCrush
Shatter
Smash
Mangle
Pulverize
Fry?Incinerate
MeltSquash
Shred
Eviscerate
Crunch
Topple
Mash
Devour
Puncture
SnapForce Damage
Gouge
Trample
Scratch
Crash
Pierce
Chip
Tear
Crack
Cut
Crumple
Dent
Abrade
Rip
Slice
Bend
Nick
Thermal Damage
The short circuit burns
 the drive gear.The heat from the short circuit
cracks the drive gear.
Burn
ScorchScaldCorrupt
Damage
Disrupt
HarmRemove
DisableA direct word-to-concept ontology for the concept Incapacitate.
Figure by MIT OCW.</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>IncapacitateDestroyForce Destroy
Thermal DestroyFail
Break
Wreck
Destroy
Raze
Disable
DamageRuin
Demolish
TerminateCrush
Shatter
Smash
Mangle
Pulverize
Fry
Incinerate
MeltSquash
Shred
Eviscerate
Crunch
Topple
Mash
Devour
Puncture
SnapForce Damage
Gouge
Trample
Scratch
Crash
Pierce
Chip
Tear
Crack
Cut
Crumple
Dent
Abrade
Rip
Slice
Bend
Nick
Thermal Damage
The short circuit burns
 the drive gear.The heat from the short circuit
cracks the drive gear.
Burn
ScorchScaldCorrupt
Damage
Disrupt
HarmRemove
DisableA direct word-to-concept ontology for the concept Incapacitate.
Figure by MIT OCW.</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>Success Using Ontologies?
 Domain-specific successes
 E.g. biomedicine
 More general use shows promise
 New languages
 New tools New applications Very active research community</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>CYC Examples</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Perspectives
 Philosophy
 Library and Information Science
 Objectives:  organize bibliographic world, model 
universal and domain knowledge
 Usage:  provide access points to bibliographic entities
 E.g., MARC; LCC, UDC, SAB
 Natural Language Processing
 Artificial Intelligence Semantic Web</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Aspects of an Ontology
 Content
 types of objects, relationships
 e.g. the blocks world conceptualization includes:
 Object Classes: Blocks, Robot Hands 
 Properties: shapes of blocks, color of blocks Relationships: On, Above, Below, Grasp Processes:  stacking plan for a tower
F o r m  
P u r p o s e Development</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>Other Examples
 Enterprise Ontology     (Edinburgh; Uschold, et al. AIAI, 1998)
 Document comparison (Xerox; Everett, et al. CACM, Feb 02)
 Goal:  Identify similar documents
 Have:  40,000 technician-authored tips for  copier repair Current system: analyzes 15 pairs of similar tips Examples</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Logic (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect08_logic/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>26</slideno>
          <text>Logic : Page 27When is Logic the Right Representation?
	Two Case Studies: 
	American Express Authorizer's Assistant 
	British Nationality Act 
	Goal in both cases is Policy Distribution: The systematic and 
reproducible interpretation of the intended meaning of a set of 
rules or policies. 
	Credit Authorization 
	British Nationality Law 
	Given the same data, the same conclusion should result.
	Human wisdom, common sense, and emotion are not useful or 
desirable. 
	The corpus of policies is, in pr inciple, complete and consistent.
	One can think of the policies as the axioms. 
	Solving the problem involves soundly deducing a consequence of 
the set of axioms. 
Logic : Page 27</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Logic : Page 20Examples
	Forward Chaining: 
Assert (Parent Abe Ike) 
Assert (Gender Abe male) Assert (Parent Ike Jake) 
Deduce (Grandparent Abe Jake)
Deduce (Grandfather Abe Jake)
	Backward Chaining: 
Same Facts, plus (Father Abe Ishmael). 
Goal (Grandfather Abe Jake) 
Goal (Grandparent Abe Jake) 
Goal (Parent Abe ?y) matches Ishmael, Ike 
Goal (Parent Ishmael ?y) no matches, fail backup 
Goal (Parent Ike ?y) matches Jake, rule succeeds 
Goal (Gender Abe Male) succeeds, rule succeeds. 
Logic : Page 20</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Logic : Page 1Representations for KBS:
Logic: When Sound Deduction is Required
Spring 2005 
6.871 Knowledge Based Systems 
Howard Shrobe and Kimberle Koile 
Syntax 
Proofs 
Semantics 
Sound Inference and Complete Inference 
What Properties hold? 
The Language as a Representation 
Comprehensiveness
Ambiguity
Lack of Commitment
Compromises between generality and tractability 
Some Applications in the logic spirit 
Wrap-up, What pair of glasses is this? 
Logic : Page 1</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Logic : Page 29What are the "Logic Glasses" ?
	The statement is the appropriate unit of modularity.
	Information is correctly captured in the form of single independent 
statements and single independent inferences. 
	Think about what's true and what follows from it.  Sound inference 
is all. Denotation is king. 
	Capture the logical statemen ts appropriate to the domain, 
preserving their declarative spirit. 
	Impose your ontology through the choice of predicates and 
functions. 
	The logical inference system gi ves the declarative statements a 
procedural content (namely what inference rules they cause to 
run). 
	The policies become active interpreters of the data.
	Control is secondary or to be ignored. 
Logic : Page 29</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Logic : Page 14Bogus Proof
1.	 Show (Implies (Forall (?x)  (Thereis (?y) ( P ?x ?y))) 
(Thereis (?y) (Forall (?x) ( P ?x ?y)))) 
2. | (Forall (?x) (Thereis (?y) (P ?x ?y)))	 Assumption motivated by 1 
3. | (Thereis (?y) (P b ?y)) 	 Universal Instantiation 2 
4. | (P b a)	 Existential Instantiation 3 
5. | (Forall (?w) (P ?w a)) 	 Universa l Generalization 4 
6. | (Forall (?x) (P ?x a)) 
7. | (Thereis (?z) (Forall (?x) (P ?x ?z))) 
8. | (Thereis (?y) (Forall (?x) ( P ?x ?y)))    
9.	 (Implies (Forall (?x) (Thereis (?y) ( P ?x ?y))) 
(Thereis (
Where is the bogon?
Alphabetic Variation 5 
Conditional Proof 8 (2) Existe ntial Generalization 6 
Alphabe tic Variation 7  
?y) (Forall (?x) ( P ?x  ?y)))) 
Logic : Page 14</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Logic : Page 11Derived Rules
Indirect Proof GIGO
i (Show A) i (not A)
i+1 | (not A) j A
J |  B k C (GIGO i j)
k | (not B)
l A (IP (j k) (i+1))
Cut 
i (Or A B) 
j (not A) 
k B (Cut i j) 
Modus Tolens 
i (Implies A B) 
j (not B) 
k (not A) (MT i j) 
DeMorgan's Rules Quantifier Negations
(not (or A B))  = (and (not A) (not B)) (not (For-all  (x) P)) = (There-is (x) (not P))
(not (And A B)) = (or (not A) (not B) (not (There-is (x) P)) = (For-all (x)  (not P))
Logic : Page 11</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Logic : Page 21Basics of Semantics
	A means for formally assignment "meaning" to syntax.
	More precisely:  Semantics is a way of specifying which 
inferences are sanctioned, i.e. "entailment". 
	A Model 
	Domain (a mathematical set) 
	Interpretation, a function that maps: 
	Constant symbols of the syntax to elements of the domain. 
	Function symbols of the syntax to functions over the domain. 
	Predicate symbols of the syntax to predicates over the domain (note that this 
is a mapping from a set of arguments to true or false). 
	Through the obvious compositions, a stat ement is mapped to true or false. 
	A Model of a set of axioms is a mode l that maps all the axioms to True. 
Logic : Page 21</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Logic : Page 23What Formal Properties Hold?
Decidability
	Is there an algorithm for deciding whether or not something is a 
theorem? 
	The British Museum algorithm: 
	A conceptual way to show that something is a theorem. 
	Generate all possible proofs in order of increasing length. 
	Stop when you get a proof with the intended theorem as its last line. 
	What paradigm is this?  How good is it? 
	However: 
	This doesn't solve the problem of decidability. 
	Church, Turing and others showed that the language is rich enough to 
encode the workings of a Turing machine. 
	Does this seem contradictory? 
Logic : Page 23</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Logic : Page 28Amex AA Rationale
	Human nature works against the credit authorizer:
	start-up transient to learn all the policies. 
	a conservative mindset 
	The job is high pressure, boring and not particularly well 
compensated. 
	High turnover  
	Amex goal was to get uniform behavior in accordance with 
company policies. 
	The action to take is a logical cons equence of the companys authorization 
rules. 
	Reasonably simple, logical ru les worked well for this. 
	Prototype was more complicated than needed. 
Logic : Page 28</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Logic : Page 31How Well Does It Work In Practice?
Nationality Act: 
	Negation was very tricky. 
	Counterfactuals and non-monotonicity are problems.
	Choosing the right predicates (i.e., picking the ontology) was hard 
and experimental in character. 
	Logic provided no guidance for how to do this.
Logic : Page 31</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Logic : Page 18Horn Clauses: A Restriction to Rule-like Form
Suppose that after normalization al l clauses have at most 1 positive 
statement 
(Or p (not q) (not r) (not s) (not t)) 
where any of p q r s t may contain with free variables 
Then by implication identity this is the same as:
(implies (and q r s t) p)
Or rewriting as a logical rule:
If and q, r, s, t
Then p
Logic : Page 18</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Logic : Page 24What Formal Properties Hold?
Completeness and Consistency
	Is the system consistent? 
 Yes (Hilbert and Ackerman).
	Is the system complete? 
 Yes (Godel). 
 What happens if you add some interesting axioms? For example, 
those for arithmetic (or those for List structure: cons, car, cdr).
	Godels' incompleteness theorem 
 You can't be both consistent and complete. 
	The language is rich enough to form  a statement which says "I have no 
proof". 
Logic : Page 24</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Logic : Page 19Mechanizing Logical Rules
 Two natural chaining methods: 
 Forward, data driven, antecedent. 
 Backward, goal driven, consequent. 
E x a m p l e s : 
If (and (Parent ?x ?y) (Parent ?y ?z))
Then (Grandparent ?x ?z)
If (and (Grandparent ?x ?y) (Gender ?x male)) 
Then (Grandfather ?x ?y) 
Logic : Page 19</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Logic : Page 30How well does this work in practice?
 Authorizer's assistant: 
 Often's people's purchasing patterns are idiosyncratic. 
 Holidays, vacations, etc. need to be understood.  
 These were captured fairly well in the ART rule system. 
 Speed of deduction was very important. 
 Control of reasoning was crucial. 
 Getting to the data was a critical success factor.  
 Accessing IBM "databases" was the "make or break" part. 
 Has worked enormously well in practice.  
 50% to 75% of Amex credit reque sts are automatically handled.  
 Good advice given in the rest. 
 British Nationality Act: 
 Received Mindset: logic means correct,  error free, right the first time 
 But: Exploratory logic is a perfectly reasonable mindset. 
Logic : Page 30</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Logic : Page 7Natural Deduction Rules
Propositional Rules 
And Introduction 
i A 
j B 
k(And A B) (AI i j) And Elimination 
i (And A B) 
j A ( A E i) 
Conditional Proof
i (Show (Implies P Q)) 
i+1 | P (assumption i) 
j | Q 
k (Implies P Q) (CP (j) (i+1))
Modus Ponens 
i (Implies A B) 
j A 
k B (MP i j) 
A statement can be copied from outside a box to inside the box, but not from the 
inside to the outside. Ex actly like the lexical scoping rules of a programming 
language. 
Logic : Page 7</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Logic : Page 3Why A Universal Language?
	What can you say in Mycin-like rule languages? 
	There are Contexts meaning, roughly, objects 
	Rules refer to one of them 
	You can talk about the Values of Attributes of Objects 
	You can compare Object Attribut es Values to Numeric Quantities 
	What cant you express? 
	Relationships between the values of attributes of one object and the values 
of attributes of another object. 
	The location of the infectious agent is within the bloodstream of the host. 
	Infectious agent-1 infected host-1 is 2 days earlier than infectious agent-2 
infected host-2. 
	Quantified things: 
	Every infections agent in host-1 is a coccus 
	There is an infectious agent in host-1 that is a coccus 
Logic : Page 3</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Logic : Page 17Resolution Rule
(Or P G)
(OR (Not Q) H)
If P and Q can be unified (w ith unifying substitution S) 
then it is legal to infer
(OR G H')
where G' and H' are the results of S ubstitution S into G and H (respectively).
Unifying two statements means finding a su bstitution for the variables in the two 
statements such that the two statements  are identical after the substitution is 
performed in each statement. 
(P ?x ?x) (P ?x a) (P ?x a ?x) (P ?x a ?x) 
(P a b) (P b ?y) (P b ?y ?y) (P ?y ?y a) 
Not unifiable (?x =&gt; b) Not unifiable (?x =&gt; a) 
(?y =&gt; a) (?y =&gt; a) 
Logic : Page 17</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Logic : Page 22Validity and Provability
	Consider all models of a set of Axioms 
	Consider those statements that are mapped into true in all these models 
	These are called the Valid Statements. 
	Consider the set of all statements provable by your inference 
system. 
	These are called the Theorems. 
	Two different notions! 
	We would like these to be the same sets of statements.
	If every valid statement is a theorem 
	The system is called complete 
	You can deduce what's true 
	If every theorem is a valid statement 
	The system is called consistent. 
	You can make only sound deductions. 
	A logicians day is made when a proof of soundness and 
completeness is obtained. 
Logic : Page 22</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Logic : Page 26Using Logic in Practical Applications:
	Weaker logical systems seem to be strong enough in practice to be 
useful and yet still controllable. 
	Logical Rule Languages are examples:
	A1 &amp; A2 &amp; ... &amp; An --&gt; C1 &amp; ... 
	The A's are called antecedents 
	The B's are called consequents 
	Forward Chaining: As facts are as serted, the LHS of all rules are 
checked for a consistent matching set. If so the RHS is asserted. 
	Backward chaining: If you want to prove the RHS, try to prove the 
antecedents in the LHS. 
E x a m p l e s : 
 Prolog 
 Kee's rule system 
 A R T 
 Joshua 
Logic : Page 26</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Logic : Page 12An Example Proof
1. Show (Implies (And P (Or Q R)) 
(Or (And P Q) (And P R))) 
2. | (And P (Or Q R))	 Assumption motivated by 1 
3. | P	 And Elimination 2 
4. | (Or Q R)	 And Elimination 2 
5. 	| Show (Implies Q trying for Or Elimination from 4 
(Or (And P Q) (And P R))) 
6. | | Q 	 Assumption motivated by 5 
7. | | (And P Q)	 And Introduction 3,6 
8. | | (Or (And P Q) (And P R) ) 	 Or Introduction 7 
9. 	| (Implies Q Condi tional Proof 8 (6) 
(Or (And P Q) (And P R))) 
10. | Show (Implies R trying for Or Elimination from 4 
(Or (And P Q) (And P R))) 
11. | | R	 Assumption motivated by 10 
12. | | (And P R)	 And Introduction 3,11 
13. | (Implies R Conditional Proof 13 (11) 
(Or (And P Q) (And P R))) 
14. | (Or (And P Q) (And P R))	 Or Elimination 4,9,13 
15. (Implies (And P (Or Q R))	 Conditional Proof 14 (2) 
(Or (And P Q) (And P R))) 
Logic : Page 12</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Logic : Page 4Predicate Logic Syntax Solves These Problems
	The unit of representation is the Statement which is the application 
of a predicate to a set of arguments : John Loves Mary 
	Building blocks: 
Constant Symbols, Variable Symbols,  Function Symbols, Predicate Symbols 
ATerm is: 
A Constant symbol: John 
A variable symbol: ?x 
The Application of a function symbol to set of terms: ( Brother (Cousin John))) 
	A basic Statement is: 
The application of a predicate symbol to a set of terms . 
	Compound statements are formed by connecting Basic Statements 
using: 
Boolean Connectives: And, Or, Not, Implies
Quantifiers: Forall, Thereis
Logic : Page 4</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Logic : Page 13Another Proof
1. Show (Implies (Thereis (?y ) (Forall (?x) ( P ?x ?y))) 
(Forall (?x) (Thereis (?y) ( P ?x ?y)))) 
2. | (Thereis (?y) (Forall (?x) ( P ?x ?y)))	 Assumption motivated by 1
3. | (Forall (?x) (P ?x a))	 Existential Instantiation 2
4. | (P b a)	 Universal Instantiation 3
5. | (Thereis (?w) (P b ?w))  	 Existential Generalization 4
6. | (Thereis (?y) (P b ?y))	 Alphabetic Variation 5
7. | (Forall (?z) (Thereis (?y) (P ?z ?y)))	 Universal Generalization 6
8. | (Forall (?x) (Thereis (?y) (P ?x ?y )))	 Alphabetic Variation 7 
9. 	| (Implies (Thereis (?y) (Forall (?x) ( P ?x ?y))) 
(Forall (?x) (Thereis (?y) ( P ?x ?y)))) Conditional Proof 8 (2) 
Logic : Page 13</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Logic : Page 10Quantifier Rules (2)
Existential Instantiation Existential Generalization 
i (Thereis (x) (P ... ))         i (P ... ) 
j [z/x](P ... ) (EI i) j (Thereis (x)[x/a](P ... )) (EG i) 
where z is a brand new variable where a is any term at all 
Alphabetic Variance 
i (Q (x)(P ... )) 
j (Q (z)[z/x](P ... )) (AV i) 
where Q is either quantifier a nd [z/x] is a valid substitution.
Logic : Page 10</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Logic : Page 6An Inference System
 A precise notion of Follows From 
 Deduction Rules 
 2 for each connective: An introd uction rule and an elimination rule 
 And Elimination:  From (And A B) you can deduce A 
 Modus Ponens: 
F r o m (IMPLIES P Q) and P you can deduce Q 
 Universal Instantiation: 
 (FORALL (X) (P X)) you can deduce (P A) for any A 
 Axioms: Statements that are given as a priori true 
	A Proof is: 
A Sequence of statements, such that each element is either: 
An Axiom 
An Assumption warranted by a proof rule 
Or the results of applying a deduction rule to previous statements 
 Theorem: Any conclusion of a proof. 
 Theorems are statements were forced to believe if we believe the axioms 
Logic : Page 6</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Logic : Page 9Quantifier Rules 
A Substitution of a for x in the statement (P x) is written [a/x](P x).
It means that every free occurrence of x is replaced by a in the statement (P x).
The substitution is only valid if no occurrence of a is captured (i.e. whenever a replaces a free 
occurrence of x, a should also be free in that context).
For Example:
[a/x](Forall (y)(P x y)) = (Forall (y) (P a y))
but [y/x](Forall (y)(P x y)) is not a valid substitution
Because this would give (Forall (y) (P y y)) capturing the substituted in y
Universal Instantiation 
i (Forall (x) (P ... )) j [a/x](P ... ) (UI i) Universal Generalization
i (P ... x ... )                  
j (Forall (x) (P ... x ...)) (UG i) 
where a is any term at all 
as long as [a/x] is a valid substitution.   
variable 
where the senten ce in line i contains no free variables 
introduced by existentia l instantiation and the 
x does not occur free in assumption within whose 
scope line i lies. 
Logic : Page 9</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Logic : Page 15Normal Form
Notation: 	 (Q (x) ...) means either (F or-all (x) ...) or (There-is (x) ... ) 
(F .. x ..) or (H .. x ..) is some expression including a free occurence of x 
G is some expression contai ning no free occurence of the variables of interest. 
Quantifier Rules  
(1) (Or (Q (x) (F .. x ..)) G) = (Q (x) (Or (F .. x ..) G)) 
(2) (And (Q (x) (F .. x ..)) G) = (Q (x) (And (F .. x ..) G)) 
(3) (And (For-all (x) (F .. x ..)) (For-all (x) (H .. x ..)))  = (For-a ll (x) (And (F .. x ..) (H .. x ..))) 
(4) (Or (There-is (x) (F .. x ..)) (There-is (x) (H .. x ..))) = (There-is (x) (Or (F .. x ..) (H .. x ..))) 
(5) (Or (Q1 (x) (F .. x ..)) (Q2 (x) (H .. x ..))) = (Q1 (x) (Q2 (z)  (Or (F .. x ..) (H .. z ..)))) 
(6) (And (Q1 (x) (F .. x ..)) (Q2 (x) (H .. x ..))) = (Q1 (x) (Q2 (z) (And (F .. x ..) (H .. z ..)))) 
Negation Rules 
(1) (Not (Not A)) = A 
(2) (Not (There-is (x) (F .. x .. ))) = (For-all (x) (Not (F .. x ..))) 
(3) (Not (For-all (x) (F .. x ..))) = (There-is (x) (Not (F .. x ..))) 
DeMorgan's Laws 
(1) (Not (And A B)) = (Or (Not A) (Not B)) 
(2) (Not (Or A B)) = (And (Not A) (Not B)) 
Distribution Laws 
(1) (Or (And A B) (And C D)) = (And (O r A C) (Or A D) (Or B C) (Or B D)) 
(2) (And (Or A B) (Or C D )) = (Or (And A C) (And A D) (And B C) (And B D)) 
Implication 
(Implies A B) = (Or (Not A) B) 
Logic : Page 15</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Logic : Page 8i Natural Deduction Rules (2)
Or Introduction Or Elimination 
iA i( O r  A  B ) 
j (Or A B) (OI i) 	 j (Show C) 
k | A (assumption j) 
l | C 
m | B (assumption j) n | C 
o C 	 (OE (i l n) (k m)) 
Double Negation Elimination Negation Introduction 
(not (not A)) i Show (Not A) 
j A (DNE i) 	 i+1 | A (assumption) 
k | B 
l | (not B) 
m (not A) (NI (k l) (i+1)) 
Logic : Page 8</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Logic : Page 25The Expressiveness of Logic
 Logic is intended to be a universal and therefore neutral formalism
 You pick the constants, functions and predicates to represent your ontology. 
 Logic doesnt prevent you from doing what you want. 
 Logic doesn't guide you about how to do this. 
 Logic is very expressive 
 Quantification 
 Any kinds of statements you want 
 Logic can capture ambiguity and partial information: 
 Existential quantification 
 ( T h e r e i s ( x )  ( p  x ) ) 
 Disjunction 
 ( O r  p  q ) 
Logic : Page 25</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Logic : Page 16Normal Form (2)
Order of Use of Identities: 
1. Implication
2. Negations and deMorgan 
3. Quantifers 
4. Distribution
The end result is (Q (x) (Q (y)  (And (0r S1 S2 S2) (Or (S3 S4 .  ))) 
The Ss are either positive or negative simple statements 
The outermost Qs are all Forall and the inner Qs are Thereis. 
Drop all the Thereis Qs replacing their va riables by functions of the universally 
quantified variables. 
Drop all the Forall Qs leaving the variables free. 
Get a set of quantifier free disjunctions. 
Logic : Page 16</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Logic : Page 5Syntax Examples
(Loves Bob Mary) Bob Loves Mary 
(Loves (Father Bob) (Mother Judy)) The Father of Bob 
Loves the mother of Judy 
(Implies (exercises Bob) (Healthy Bob)) If Bob exercises Bob is Healthy 
(Forall (?y) (Thereis (?x) (Loves ?x ?y))) Everybody has somebody who 
loves them 
(Thereis (?y) (Forall (?x) (Loves ?x ?y)) There is somebody whom 
everybody loves 
(Forall (?block ?robot ?t-1) 
(implies (and (cleartop ?block ?t-1)  
(handempty ?robot ?t-1)) 
(and (possible-successor ?t-2 ?t-1) 
(results-from ?t-2 (pickup ?robot ?block ?t-1)) 
(holding ?robot ?block ?t-2)))) 
at any time that the robots hand is empty and th ere is nothing on top of the block, the robot 
can pick up the block and it will be holding the block in the resulting situation. 
Logic : Page 5</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Logic : Page 2What is Logic?
A Universal" Language
A formal Inference system that preserves truth 
Not a guarantee of correct answers. 
General spirit is to pour in the axioms and grind out the theorems.
E.g. to do inference, start with axioms and grind out consequences.
To plan, put in the planning axioms and grind out the plans.  
To do diagnosis, put in the descrip tion of the device and grind out the 
diagnosis. 
A means for formally relating syntax to semantics (or denotation) or, 
put another way: The study of the relationship between inference and 
entailment . 
Logic : Page 2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Application Analysis Case Study: Case Introduction (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect04_case/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>9</slideno>
          <text>Knowledge Based Systems Can
 Distribute corporate policy
Why dont the salesman read any of the 
100 memos we sent this quarter? 
 Solve a variety of part assembly tasks.
I cant keep track of all the combinations. 
6.871  Lecture 4 10</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Knowledge Based Systems Can
	Preserve knowledge and expertise 
Corporate Memory 
	Joes getting ready to retire. 
	Embed knowledge and expertise
	Is it #*1 or ##2 to call-forward?!!
6.871  Lecture 4 5</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>The Organizational Case
 An enthusiastic, committed expert is 
available 
 Who will use it? 
 End-users are identified/identifiable
 End-users are enthusiastic 
 Do they agree that 
 the problem exists? 
 the problem is important? 
 the program solves their problem?
6.871  Lecture 4 21</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>The Technical Case
 Character of the solution: 
 useful accuracy is reachable 
 The skill is routinely taught 
 Data and cases studies are readily available
 Dead center cases 
 Extreme cases 
 Informative canonical cases 
6.871  Lecture 4 18</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Project Construction
	Nature of the solution changes
	Nature of the construction process 
changes 
6.871  Lecture 4 27</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Knowledge Based Systems Can
 Make knowledge accessible 
 Oh, HERE it is, on page 412 of volume 6. 
6.871  Lecture 4
 6</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Knowledge Based Systems Can
 Replicate knowledge and expertise
 If only we had 5 more of Sally 
6.871  Lecture 4 4</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Project Design
	Build an assistant 
Inherently low profile 
Leverages the operator 
Keeps lines of accountability clear 
	Manage expectations 
	Provide a smooth adoption path
	Provide follow-on and support 
6.871  Lecture 4 25</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Field Test and After
 Where to field test
 Who wants it and is knowledgeable enough to 
evaluate it? 
 KB development is never done
 Determine who can take over
 What will happen to the expert?
 attrition? 
 work on harder problems? 
 extend the knowledge base? 
6.871  Lecture 4 30</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>The Business Case
 Define the character of the payoff
 revenue 
 improved competitive position 
 quality 
 speed 
 uniformity 
 cost reduction 
 new, different product 
 staff retention 
 staff reduction 
6.871  Lecture 4 19</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>The Business Case
 Calibrate the size of the payoff 
 What is half the distance to the expert worth? 
 Determine the chance for leverage 
6.871  Lecture 4 20</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>The Organizational Case
	The organizational culture will support its 
use 
	The answer is worth the difficulties
	learning to use it, using it 
6.871  Lecture 4 22</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Analysis: How Is It Done?
 Who does it? 
 What do they do? 
 How do they get trained? 
 How available are they? 
 How is the task organized? 
 How accurately should it be done?
 What goes well about it now? 
 What goes badly? 
6.871  Lecture 4 12</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>If Its The First Problem
 Select one where knowledge is fairly clear
 Needs formalization, not discovery 
eg. Procedures, manuals, etc.
 Select one thats too small
 Select one that matters 
 Set up a skunkworks 
6.871  Lecture 4 23</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Rapid Prototyping: Advantages
 Handle ill-defined tasks. 
 Check problem conception. 
 Secure user buy-in. 
 Refine user requirements. 
 Refine production and integration requirements.
 Something works all the time. 
 Get management support. 
 It happens anyway. 
6.871  Lecture 4 29</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>The Technical Case
 Character of the knowledge 
 Substantial specialized knowledge/expertise required 
 accumulating relevant knowledge takes time
 Knowledge is relatively stable 
 There are recognized experts 
  but too few of them 
  or they have other tasks that are more rewarding 
(for several senses of reward) 
6.871  Lecture 4 16</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Knowledge Based Systems Can
 Leverage the expert
Why cant we use Phils time more 
productively?
 Improve practice; support the average
We can never find and train enough skilled 
people. 
6.871  Lecture 4 8</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Questions About ...
T h e  T a s k 
 Is this the right problem to solve? 
 Is it important? 
 Is it valuable? 
 Can it be done? 
 How can progress be measured? 
 How will you know if it succeeds? 
 If you build a system, will anyone use it? 
 Who, and why? 
6.871  Lecture 4 2</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Knowledge Based Systems Can
	Apply knowledge consistently over time 
Provide an environment for knowledge 
standardization and growth 
 Why cant they do it in Chicago the way they 
do it in Seattle? 
 Why does every plant have to keep re
learning this?
	E.g.American Express Authorizers Assistant 
6.871  Lecture 4 7</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Knowledge Based Systems Can
 Help avoid disaster. 
How did that slip through? 
 Help manage change? 
Fifty new products this year! A technical 
success, and a marketing disaster. 
6.871  Lecture 4 9</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Analysis: Mistakes
	What is the nature and origin of a 
mistake? 
 What kinds of things go wrong? 
W h y ? 
	too much detail 
	too much change 
	too much info to absorb 
	insufficiently trained people 
	too simple 
	too routine 
6.871  Lecture 4 13</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Project Design
Expert-level performance is difficult, so...
	Adopt an evolutionary approach 
It gets you started 
Useful wherever you stop 
6.871  Lecture 4 24</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Project Construction
	You dont know what youre trying to build 
Recall checkbook vs. supermarket 
 Not formally definable 
 Cant anticipate all contingencies 
	Cant specify procedure 
 Human performance is the metric 
 The task will change out from under you 
6.871  Lecture 4 26</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>The Technical Case
 Character of the knowledge 
 Experts are provably better than the amateur 
 Measure the difference 
 What dimension: speed, accuracy? 
 What is the right answer? 
 The experts can communicate the relevant 
knowledge 
 They can communicate it to you 
 You can become at least a talented amateur 
 One expert is enough (or, one chief expert) 
6.871  Lecture 4 17</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Rapid Prototyping
 Construction process involves 
 Intertwining of specif ication and implementation 
 Experimentation 
 Three-month prototype 
 prevents optimization 
 encourages experimentation 
 early feedback on te chnology and conception 
PROTOTYPE  ENHANCE     SPECIFY  CODE
6.871  Lecture 4 28</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Design for Evolution
	If its a success, how long will they use it for?
	If they use it, what else will they want? 
	What do you suspect will happen to the 
hardware and software infrastructure that the 
application will rely on? 
	How closely coupled to the underlying 
infrastructure will you need to be? 
	Will they let you do that? 
	Are there standard ways to do it? 
	How pervasive will these be in the end application? 
6.871  Lecture 4 31</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Analysis: Mistakes
 What are the consequences of a mistake?
 time: how much? 
 money: how much 
 image 
 If something goes wrong now? 
 who spots it 
 who fixes it 
 who gets blamed 
6.871  Lecture 4 14</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Analysis: What Is It?
 What is the task? 
 Specify in terms of input and output. 
 When is it done and why? 
 How often? 
 How fast must it be done? 
 How much does one run cost? 
 What value is produced by a run?
6.871  Lecture 4 11</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Application Case Study: 
Introduction
6.871-- Lecture 4</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Questions About ...
 The Task 
 If you build it, who will maintain it? 
 If you build it 
 Who will benefit from it? 
 Who will be threatened by it?
 The Technology 
 What can it do? 
6.871  Lecture 4 3</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>The Technical Case
 Character of the problem 
 Narrow domain of application 
 Knowledge overload 
 Many different outcomes
 Few outcomes but a lot to know 
 Task involves symbolic reasoning 
 Task uses symbolic information
 No adequate algorithmic solution
 Takes 20 minutes to a few days
 Incremental progress is possible
 Repetitive 
6.871  Lecture 4 15</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Model-Based Reasoning (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect15_mbr/</lecture_pdf_url>
      <lectureno>15</lectureno>
      <slides>
        <slide>
          <slideno>9</slideno>
          <text>Behavior Representation
	Expressions capturing relationships between values 
at terminals 
	Multi-directional 
	Constraint-like  rather than simply procedural
A
C 
B 
 To compute C:  Evaluate A + B 
6.871  Lecture 15 10</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Generation
But: Not every input influences the specified output 
 G4: Use behavior model to determine relevant inputs
 Have simulation keep dependency records 
 Trace back through these to determine candidates 
0 
1 1 
0 A 
B C 
R1: IF A=1 then C=1 
R2: IF B=1 then C=1 R3: IF A=0 and B=0 then C= 0 
6.871  Lecture 15 20</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Useful Characteristics of 
Structure Representations
H i e r a r c h i c a l 
 Possibly multiple: behavioral, physical 
 Possibly not strict: components with multiple 
functional roles 
 Object-oriented, isomorphic to the device
 Procedural objects 
 Interconnected in same topology 
 Unified: Both runnable and examinable 
6.871  Lecture 15 8</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>A Multi-Tiered Bayesian Framework
	The model has levels of detail spec ifying computations, the underlying 
resources and the mapping of computations to resources 
	Each resource has models of its state of compromise 
	The modes of the resource models are linked to the modes of the 
computational models by conditional probabilities 
	The Model forms a Bayesian Network 
Node17 Parasite: Probability 9% 
Component 1 Conditional probability = .2 
Conditional probability = .4 Conditional probability = .3 Normal: Delay: 2,4 
Delayed: Delay 4,+inf 
Accelerated: Delay -inf,2 
Located On Normal: Probability 90% 
Other: Probability 1% 
Has models Has models 
6.871  Lecture 15 44</text>
        </slide>
        <slide>
          <slideno>66</slideno>
          <text>More (detail) is Worse
	The nave approach suggests a detailed,  step by step simulation of the 
device as the first phase of the diagnosis. 
	For a reasonable circuit with internal  states, all interesting behavior exists 
over the time span of many thous ands to millions of clock cycles. 
	The nave approach fails to captur e the right functional abstractions 
	Devices: Central controller 
	Behavior: Frequency 
 Changing 
 Stable 
6.871  Lecture 15	 67</text>
        </slide>
        <slide>
          <slideno>57</slideno>
          <text>Testing
New Inputs 
New Candidates 
New Symptoms 
Old Candidates Fewer 
Coverings 
	General problem is very hard
	Basic insight: dont use members of 
candidate sets to route signals (i.e. use 
only parts believed to be good) 
6.871  Lecture 15 58</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>Corroboration Proves Nothing
 The basic intuition 
 Involved in discrepancy means suspect 
 Therefore: Involved in corroboration means 
exonerated 
 This is wrong
 Involved in corroboration only means that you 
didnt tickle this problem yet. 
 with these inputs
 with the specific observations you chose to make 
so far 
6.871  Lecture 15 36</text>
        </slide>
        <slide>
          <slideno>52</slideno>
          <text>Probing and Testing
	Purely structural 
	Follow discrepancies upstream (guided probe) 
	Split candidate space topologically 
discrepancy 
	Add behavioral information: 
	Split topologically: G&amp;T on the sub-problem 
	Predict consequences of candid ate malfunction; probe where it 
is most informative. 
6.871  Lecture 15 53</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Model Based Reasoning
6.871 - Lecture 15</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Model Based Troubleshooting
GDE 
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 3 
5 
3 5 5 40 
35 40 X 
Y 
Z A 
B 
Propagations: 
Y=25 (T2) Conflict Sets: 
Y=20 (P2 T3)
Y=25 (T1 P1) (T2 P2 T3)
Y=20 (T3 P2)
(T1 P1 T3 P2)
Assume P1 T1 working  ==&gt; Y=25 (P1 T1)
Assume P2 T3 working  ==&gt; Y=20 (P2 T3)
Assume T2 working       ==&gt;  Y= 25 (T2) 
Diagnoses: (P2) (P1 T2) ...
6.871  Lecture 15 Conflicts: (P1 T1 P2 T3) 
(P2 T2 T3) 
Diagnoses: (P2)  (T3)  (P1 T2)  (T1 T2) 33</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>3 Corroboration Example and Counter Example
3
2
2
3
3
3
2
2
3
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 6 
6 6 12 
12 
12 10F 
G 
Times-1 
Times-2 
Times-3 Max-1 Plus-1 6 
6 6 12 
6 
6 10F 
G 4 
Corroboration would exonerate Plus-2, Time-2, Time-3 since they are upstream from G which has the correct value.  In this case,  this is correct. 
Corroboration would exonerate Plus-2, Time-2, Time-3 since they are upstream from G which has the correct value.  In this case, this is not correct, since 
time-2 could be broken and produce 4 as its output. 
6.871   Lecture 15 38</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Model Based Troubleshooting
3 
5 
5 
5 
3
Z=15 (T3)
Y=20 (P2 T3)
GDE 
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 
25 
35 40 X 
Y 
Z 
Propagations: 
Y=25 (T2) A 
B 
15 20 
Assume P1 T1 working ==&gt; Y=25 (P1 T1)
Assume P2 T3 working ==&gt; Y=20 (P2 T3)
Assume T2 working       ==&gt; Y= 25 (T2)
Conflicts: (P1 T1 P2 T3) 
6.871  Lecture 15 (P2 T2 T3) 28 
Diagnoses: (P2) (T3) (P1 T2)  (T1 T2)</text>
        </slide>
        <slide>
          <slideno>62</slideno>
          <text>Model Selection and Formulation Is a Key Problem
	There are no assumption-free representations
	perhaps we can use more than one 
	Completeness and complexity conflict 
	well need to choose judiciously 
	Basic question: whence the model?
How do we know how to think about the device?
6.871  Lecture 15 63</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>An Example System Description
N H N H
Normal .6 .15 N H Normal .50 .05
Peak .1 .80 Normal .8 .3 Fast .25 .45
Off Peak .3 .05 Slow .2 .7 Slow .25 .50
A B C 
N H
Normal .60 .05
Slow .25 .45
Slower .15 .50
N H 
Normal .50 .05 
Fast .25 .45 
Slow .25 .50 
D E 
Host1 Host2 Host3 Host4 
Normal .9 
Hacked .1 Normal .85 Hacked .15 Normal .8 Hacked .2 Normal .7 Hacked .3 
6.871  Lecture 15 45</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Generation
G1: Exhaustive enumeration of components
3
40
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 15 
15 25 
Times-4 35
 5
5
40
5
3
55
165
3
6.871   Lecture 15 16</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Using Behavior Information: GDE
	GDE = General Diagnostic Engine
	Propagate not just values, but underlying 
assumptions as well 
 Assumptions are the proposition that a 
component is working according to design 
6.871  Lecture 15 24</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>When not to use it
	Some things are too difficult to infer from the models
	intermittent or flaky behavior 
	The device and range of faults is small enough to permit 
exhaustive simulation 
	The device and range of faults is small enough to 
generate an exhaustive fault dictionary 
6.871  Lecture 15 6</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Components of the Task
G i v e n 
	Observations of a device behavior (inputs, outputs) 
	a description of internal structure 
	a description of component behavior 
	Determine 
	which components could have failed so as to product the 
observed misbehavior 
	the simplest set of component failures which can explain the 
misbehavior 
	Buzzwords 
	Reasoning from design models 
	Reasoning from first principles 
	Deep reasoning 
6.871  Lecture 15 4</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Model Based Troubleshooting
GDE 
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 3 
5 
3 5 5 
25 
35 40 X 
Y 
Z 
Propagations: 
Y=25 (T2) A 
B 
15 20 
Conflict Sets: 
Z=15 (T3) 
Y=20 (P2 T3) 
(T2 T3 P2)
Assume P1 T1 working  ==&gt; Y=25 (P1 T1) 
Assume P2 T3 working  ==&gt; Y=20 (P2 T3) Assume T2 working       ==&gt;  Y= 25 (T2) 
6.871  Lecture 15 Conflicts: (P1 T1 P2 T3) 
(P2 T2 T3) 
Diagnoses: (P2)  (T3)  (P1 T2)  (T1 T2) 29</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>6.871  Lecture 15 1Computational Models are Coupled through 
Resource Models
Delay:1,3Node1 Node2
Precluded because physicality requires 
red green and yellow to all be delayed or all be acceleratedBlue delayed
Violet delayed
Red delayed, Yellow Negative Time
Red delayed, Gr een Negative Time
Green delayed, Ye llow Negative TimeConflicts:
Diagnoses:Component1
Delay:1,3Component2
Component3Component4
Component5Delay:2,4
Delay:3,4
Delay:1,2Delay:5,10Time:1,3Time:3,7
Time:9,17
Time:5,9Observed Time:27
Observed Time:6Time:4,7
Time:4,5Time:9,17Time:1,1Time:3,5
Time:9,15</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Generation
G1: Exhaustive enumeration of components
6.871  Lecture 15
 15</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>Integrating MBT and Bayesian Reasoning
 Start with each behavioral model in the normal state 
 Repeat: Check for Consist ency of the current model 
 If inconsistent, 
 Add a new node to the Bayesian network 
 This node represents the logical-and of the nodes in the conflict. 
 Its truth-value is pinned at FALSE.  
 Prune out all possible solutions which are a super-set of the conflict set. 
 Pick another set of models fr om the remaining solutions 
 If consistent, Add to the set of possible diagnoses 
 Continue until all inconsist ent sets of models are found 
 Solve the Bayesian network 
N H
Normal .6 .15 N H
Peak .1 .80 Normal .8 .3
Off Peak .3 .05 Slow .2 .7
A B N H 
Normal .50 .05 
Fast .25 .45 
Slow .25 .50 
Discrepancy Observed Here 
C 
Conflict:
A = NORMAL
B = NORMAL
N H N H C = NORMAL 
Normal .60 .05 Normal .50 .05 Least Likely Member of ConflictSlow .25 .45 Fast .25 .45 
Slower .15 .50 Slow .25 .50 Most Likely Alternative is SLOW 
6.871  Lecture 15 D E 48</text>
        </slide>
        <slide>
          <slideno>64</slideno>
          <text>The Two Different Approaches to MBT
n205 
+5V HI1 HI1 n158 
Dip 
Osc 
9.83 
04 
MHz 1 14 7 
8 n291 
2 
1 
U32 
NC 
74LS04 74LS1 
12 J 
K C HI1 
HI1 R -Q Q 
HI1 
U30 74LS1 
12 J 
K C HI1 
HI1 R -Q Q 
HI1 2.4576 Mhz H 
2.4576 Mhz L n167 
U30U25 
6.871  Lecture 15 65</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Using Behavior Information: GDE
Assumption Propagation and Set Covering
	GDE = General Diagnostic Engine 
	Propagate not just values, but underlying assumptions as well 
	Assumptions are the proposition that a component is working 
according to design 
	Construct conflict sets 
	Sets of assumptions, not all of which can be true at once 
eg: (T2 T3 P2)
(T1 T3 P1 P2)
	Explain each conflict set 
	By a set covering 
eg: (P2) (T3 P2)
6.871  Lecture 15 31</text>
        </slide>
        <slide>
          <slideno>67</slideno>
          <text>The Problems to be Faced
 Models are incomplete. 
 Observations are costly. 
 Observations are incomplete and imprecise.
 Prediction is costly. 
 Prediction is incomplete. 
6.871  Lecture 15 68</text>
        </slide>
        <slide>
          <slideno>45</slideno>
          <text>System Description as a Bayesian Network
 The Model can be viewed as a Two-Tiered Bayesian Network 
 Resources with modes 
 Computations with modes 
 Conditional probabilities linking the modes 
N H N H 
Normal .6 .15 N H Normal .50 .05 
Peak .1 .80 Normal .8 .3 Fast .25 .45 
Off Peak .3 .05 Slow .2 .7 Slow .25 .50 
A B C 
N H
.05
.45
.50 N H 
Normal .60 Normal .50 .05 
Slow .25 Fast .25 .45 
Slower .15 Slow .25 .50 
Host1 D 
Host2 E 
Host4 Host3 
Normal .9 
Hacked .1 Normal .85 Hacked .15 Normal .8 Hacked .2 Normal .7 Hacked .3 6.871  Lecture 15 46</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Interaction of Prediction and 
Observation
Observation 
Discrepancy Actual Device 
Model Observed Behavior 
Predicted Behavior 
Prediction 
6.871  Lecture 15 3</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Model Based Troubleshooting
3
5
5
5
3
Assume P1 T1 working  ==&gt; Y=25 (P1 T1)
Assume P2 T3 working  ==&gt; Y=20 (P2 T3)
Assume T2 working  ==&gt; Y= 25 (T2)
GDE 
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 
35 40 X 
Y 
Z A 
B 
Conflicts: (P1 T1 P2 T3) 
(P2 T2 T3) 
6.871  Lecture 15 Diagnoses: (P2) (T3)  (P1 T2) (T1 T2) 25</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>Fault Models
	Extend the notion of fault model to include multiple behavioral 
modes: 
	Designed behavior (i.e., the correct behavior) 
	Known faulty behaviors 
	Residual behavior (i.e. everything besides designed and known 
faults) 
	Their probabilities 
	Start with models of correct behavior 
	When conflicts exist, substitute a fault model for some member of 
the conflict set 
	Drive the choice of substitution by failure probabilities 
	best diagnosis is most likely set of behavior modes for the 
various candidates capable of  removing all discrepancies 
	i.e., best first search for conflict free set of behavior modes 
6.871  Lecture 15 40</text>
        </slide>
        <slide>
          <slideno>49</slideno>
          <text>Integrating MBT and Bayesian 
Reasoning (2)
	Repeat Finding all conflicts and adding them to the Bayesian Net. 
	Solve the network again. 
	The posterior probabilities of the underlying resource models tell 
you how likely each model is. 
	These probabilities should inform the trust-model and lead to 
Updated Priors and guide resource selection. 
	The Posterior probabilities of the computational models tell you how 
likely each model is. This should guide recovery. 
	All remaining  non-conflicting co mbination of models are possible 
diagnoses 
	Create a conjunction node for each possible diagnosis and add the 
new node to the Bayesian Network (call this a diagnosis node) 
	Finding most likely diagnoses: 
	Bias selection of next component model by current model 
probabilities
6.871  Lecture 15 50</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Outline
 Basics of the task 
 The nature of models 
 What we know how to do 
 What we dont know how to do (so well)
6.871  Lecture 15 2</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Why Model Based Diagnosis
 Familiar task that people do well 
 Compared to heuristic classification 
 Dont need new rule set needed for each device 
 Device independent 
 Free given a design description 
 Compared to traditional diagnostics 
 Diagnosis is not verification or manufacturing testing 
 Symptom directed 
 Can cover a wider range of faults 
6.871  Lecture 15 
- for determining what broke, not whether its correctly manufactured 
More focused and precise5</text>
        </slide>
        <slide>
          <slideno>58</slideno>
          <text>Difficulties
	Model based reasoning is on ly as good as the model 
	Tension between completeness of description and tractability of 
reasoning. 
	Scaling: size alone isnt the issue (but it is an issue) 
	Complex behavior is an issue 
	VCR, ALU, Pentium, PowerPC, Disk Controller 
	This requires new vocabulary, new abstractions 
	Temporally coarse descriptions are often important 
 Memory and state are hard to model 
 Temporally coarse representati ons can hide the state usefully 
6.871  Lecture 15 59</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>Fault Models
 Good News: what weve seen so far doesnt need them 
 Bad News: what weve s een so far cant use them 
Battery
Conflicts: 
Lamp 1 B,L1 
B,L2 
L1,L3 
L2,L3 
Lamp 2 
Diagnoses: 
L1,L2 
Lamp 3 
6.871  Lecture 15 39</text>
        </slide>
        <slide>
          <slideno>61</slideno>
          <text>Complexity vs Completeness
	Any simplifying assumption risks 
incompleteness 
	Make too few assumptions and
 diagnosis becomes indiscriminate 
 drown in complexity, ambiguity
6.871  Lecture 15 62</text>
        </slide>
        <slide>
          <slideno>71</slideno>
          <text>Conclusions
	General purpose paradigm (with variations)
	Largely domain independent 
	Successfully employed in  practice 
	Major research issues are in modeling, not reasoning 
methods 
	complex behavior 
	model selection
	model formulation 
6.871  Lecture 15 72</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Three Fundamental Problems
 Hypothesis Generation
 Given a symptom, which components could have 
produced it? 
 (Which are most likely to have produced it) 
 Hypothesis Testing 
 Which components could have failed to account for all 
observations? 
 Hypothesis Discrimination
 What additional information should we acquire to 
distinguish among the remaining candidates?
6.871  Lecture 15 13</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Generation
But: to be a candidate, component must have contributed to the discrepancy 
 
3
40
35 5
5
40
5 
3 
55 
165 
3 Times-1 
Times-2 
Times-3 Plus-2 Plus-1 15 
15 25 
Times-4 G2: Find all components connected to the discrepancy 
6.871  Lecture 15 17</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Generation
But: Not every input influences the specified output 
 G4: Use behavior model to determine relevant inputs
 Have simulation keep dependency records 
 Trace back through these to determine candidates 
0 
1 1 
0 A 
B C 
[1 because of R2] 
R1: IF A=1 then C=1 
R2: IF B=1 then C=1 R3: IF A=0 and B=0 then C= 0 
6.871  Lecture 15 21</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Using Behavior Information: GDE
Assumption Propagation and Set Covering
	GDE = General Diagnostic Engine 
	Propagate not just values, but underlying assumptions as well 
	Assumptions are the proposition that a component is working 
according to design 
	Construct conflict sets 
	Sets of assumptions, not all of which can be true at once 
eg: (T2 T3 P2)
(T1 T3 P1 P2)
	Explain each conflict set 
	By a set covering 
eg: (P2) (T3 P2)
B y  a minimal set covering: eg: (T3)
6.871  Lecture 15 32</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>Good News/Bad News
 The good news 
 Generates all the logically possible candidates 
 Including multiple point of failure 
 The bad news 
 Set covering is well known to be exponential
 The (slightly less) bad news 
 The number of components at any level of detail is 
relatively small 
6.871  Lecture 15 35</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Model Based
Troubleshooting
Constraint Suspension
3 
5
5
5
3 
Produces Output 35 Times 
Times 
Times Plus Plus 15 
15 25 40 
40 
35 40 
Consistent Diagnosis:
Broken takes inputs 25 and 1510 20 25 
Consistent Diagnosis:Broken takes inputs 5 and 3
Produces Output 10 
6.871  Lecture 15 No Consistent Diagnosis:Conflict between 25 &amp; 20 22</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>Corroboration Example and Counter Example
3
3
2
2
3
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 6 
6 6 12 
12 
12 10F 
G 
Corroboration would exonerate Plus-2, Time-2, Time-3 since th ey are upstream from G whic h has the correct value.  
In this case, this is correct.
Corroboration would exonerate Plus-2, Time-2, Time-3 since th ey are upstream from G whic h has the correct value.  
In this case, this is not correct, since time-2  could be broken and pr oduce 4 as its output.
6.871   Lecture 15 37</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>System Description as a MBT Model
	The Model can also be viewed as a MBT model with 
multiple models per device 
	Each model has behavioral description 
	Except the models have conditional probabilities 
N H N H 
Normal .6 .15 N H Normal .50 .05 
Peak .1 .80 Normal .8 .3 Fast .25 .45 
Off Peak .3 .05 Slow .2 .7 Slow .25 .50 
A B 
D C 
E N H 
Normal .50 .05 
Fast .25 .45 
Slow .25 .50 N H 
Normal .60 .05 Slow .25 .45 
.15 .50
Slower 
6.871  Lecture 15 47</text>
        </slide>
        <slide>
          <slideno>56</slideno>
          <text>Probing and Testing
	Purely structural 
	Follow discrepancies upstream (guided probe) 
	Split candidate space topologically 
discrepancy 
	Add behavioral information: 
	Split topologically: G&amp;T on the sub-problem 
	Predict consequences of candidate ma lfunction; probe where it is most 
informative. 
	Add failure probabilities 
	Cost-benefit calculation using maximum entropy methods 
Assumption: Computation is cheap comp ared to probing (think of chips) 
6.871  Lecture 15 57</text>
        </slide>
        <slide>
          <slideno>59</slideno>
          <text>The Model Isnt How It Is
3
5
5
5
3
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 15 
15 25 40 
40 
40 35 
6.871   Lecture 15 60</text>
        </slide>
        <slide>
          <slideno>70</slideno>
          <text>Principles of Modeling
	Components' behavioral representation should employ 
features that are easy to observe. 
	A temporally coarse description is better than no 
description. 
	A sequential circuit should be encapsulated into a single 
component whose behavior can be described in a 
temporally coarse manner. 
	Represent a failure mode if it has a high likelihood.
	Represent a failure mode if the misbehavior is drastically 
simpler than the normal behavior 
6.871  Lecture 15 71</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Model Based
Troubleshooting
34 GDE 
Times 
Times 
Times Plus Plus 3 
5 
3 5 5 40 
40 
35 40 
Conflicts: 
Diagnoses: 25 
20 
Blue or Violet Broken 
Green Broken, Yellow with masking fault 15 
15 25 
6.871  Lecture 15 Green Broken, Red with  compensating fault</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Basic Theses
	Hypothesis generation, test and discrimination are 
fundamental problems of diagnosis 
	Different amounts and types of knowledge can be 
brought to bear at each phase 
	The set of possibilities explored spans a wide range of 
potential systems within this common PSP 
	More complex devices require better abstractions.
6.871  Lecture 15 7</text>
        </slide>
        <slide>
          <slideno>50</slideno>
          <text>The Final Bayesian Network
Value =False Value =False 
51 NoGood1 Conflict: 
A 
Host1 B 
D C 
E 
Host2 Host4 Host3 Off-Peak .028 
Peak .541 Normal .432 Slow .738 Normal .262 
Slow .612 Fast .065 Normal .323 .516 
Slow .339 Normal .145 Slow .590 Fast .000 Normal .410 NoGood2 Conflict: 
C = SLOW 
Hacked=.267 
Normal = .733 Hacked=.450 Normal = .550 Hacked=.324 
Normal = .676 Hacked=.207 Normal = .793 Diagnosis-1 A = SLOW 
B = SLOW 
E = PEAK 
Diagnosis-50
6.871  Lecture 15 A = NORMAL 
B = NORMAL 
C = NORMAL 
Slower A = NORMAL 
B = NORMAL 
C = NORMAL 
D = NORMAL</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Using Behavior Information: GDE
Assumption Propagation and Set Covering
	GDE = General Diagnostic Engine
	Propagate not just values, but underlying assumptions 
as well
 Assumptions are the proposition that a component is 
working according to design 
	Construct conflict sets
 Sets of assumptions, not all of which can be true at 
once 
eg: (T2 T3 P2) 
(T1 T3 P1 P2) 
	Explain each conflict set
6.871  Lecture 15 30</text>
        </slide>
        <slide>
          <slideno>65</slideno>
          <text>The Two Different Approaches to MBT
n205 
Dip 
Osc 
9.83 
04 
MHz +5V 
1 14 7 
8 n291 74LS1 
12 J 
K C HI1 
HI1 R -Q Q HI1 
HI1 
U30 74LS1 
12 J 
K C HI1 
HI1 R -Q Q HI1 
HI1 2.4576 Mhz H 
2.4576 Mhz L n167 n158 
U30 2 
1 
U32 
NC 
74LS04 
U25 
OSC 
U25 FB01 
Buffer 
U32 U30 FD01 
Divide 
by 2 FD01 
Divide 
by 4 n291 n205 
n158 n167 U25, U32 and U30 
But 
Oscillators tend to fail 
more frequently, so U25 is more likely to 
of n291 is advised. If n167 is flat then 
form a conflict.  
be broken.  A probe 
6.871  Lecture 15 66</text>
        </slide>
        <slide>
          <slideno>63</slideno>
          <text>Another Problem: Complex Behavior
	An engineer plugs in a broken circuit board, makes a half dozen 
simple probes with an oscilloscope, and after ten minutes ends up 
swapping a chip, which fixes the problem. 
	A model-based troubleshooting program spends a day simulating 
the expected behavior of the same misbehaving board, and requests that a logic analyzer be us ed to capture a certain subset 
of the signals. After some hours of  computation, it concludes that 
any of the 40 chips or 400 wires on the board could be responsible for the misbehavior. 
W h y ? 
6.871  Lecture 15	 64</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Generation
Generators should be: 
 Complete 
 Non-redundant 
 Informed 
 G1: Exhaustive enumeration of components 
 G2: Find all components connected to the discrepancy
 G3: Find all components upstream of the discrepancy
 G4: Use behavior model to determine relevant inputs
6.871  Lecture 15 23</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Generation
 Generator provides plausible hypotheses
 Complete 
 Non-redundant 
 Informed 
6.871  Lecture 15 14</text>
        </slide>
        <slide>
          <slideno>51</slideno>
          <text>Three Fundamental Problems
	Hypothesis Generation 
	Given a symptom, which comp onents could have produced it? 
	Hypothesis Testing 
	Which components could have failed to account for all 
observations?
	Hypothesis Discrimination
	What additional information shoul d we acquire to distinguish 
among the remaining candidates? 
6.871  Lecture 15 52</text>
        </slide>
        <slide>
          <slideno>54</slideno>
          <text>Informative Probes
3
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 
35 40 X 
Y 
Z A 
5
5
5
B
3
T3 Bad P2 Bad
Probe at Y 25 25
Probe at Z
6.871  Lecture 15
 55</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Generation
But: Not every input influences the specified output 
 G4: Use behavior model to determine relevant inputs
 Have simulation keep dependency records 
 Trace back through these to determine candidates 
0 
1 1 
0 A 
B C 
6.871  Lecture 15 19</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>Applying Failure Models
B Observed: 5 
Predicted: Low = 5 
High = 10 
LH P 
Normal:3 6 
2 
.2 IN 0 
LH P 
10 0.8 
Fast: 4 OUT2 LH P 
4 
Fast: 1 
5 30 .06 OUT1 A MID 
Low = 3 High = 6 .7 
Fast: -30 .1 Slow: 7 30 Normal:5 
-30 .03 
Slow: 11 30 .07 Observed: Normal:2 0.9 
-30 .04 
Slow: 
17 
Predicted: Low = 8C High =16 
Consistent Diagnoses 
A B C MID MID Prob Explanation 
Low High 
Normal Normal Slow 3 3 .04410 C is delayed 
Slow Fast Normal 7 12 .00640 A Slow, B Masks runs negative! 
Fast Normal Slow 1 2 .00630 A Fast, C Slower 
Norma l Fast Slow 4 6 .00196 B not too fast, C slow 
Fast Slow Slow -30 0 .00042 A Fast, B Masks, C slow 
Slow Fast Fast 13 30 .00024 A Slow, B Masks, C not masking fast6.871  Lecture 15 42</text>
        </slide>
        <slide>
          <slideno>60</slideno>
          <text>The Model Isnt How It Is
 Because it shouldnt be that way 
 bridge faults, assembly error 
 Because of unexpected pathways of interaction
 eg heat, radiation 
 In practice, by our choices 
 deciding not to represent each individual wire 
segment 
 In principle: its impossible
6.871  Lecture 15 61</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Generation
But: devices have distinguishable inputs and outputs 
 G3: Find all components upstream of the discrepancy
3
40
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 15 
15 25 35 5
5
40
5 
3 
Times-4 55 
3 165 
6.871  Lecture 15 18</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>Delay:2,4Adding Failure Models
	In addition to modeling the normal behavior of each 
component, we can provide models of known 
abnormal behavior 
	Each Model can have an associated probability
	A leak Model covering unknown 
failures/compromises covers residual probabilities. 
	Diagnostic task becomes, finding most likely set(s) of 
models (one model for each component) consistent with the observations. 
	Search process is best first search with joint 
probability as the metric 
6.871  Lecture 15 Component2 Normal: Delay: 2, 4 Probability 90% 
Delayed: Delay 4, +inf Probability 9% 
Accelerated: Delay -i nf,4 Probability 1% 41</text>
        </slide>
        <slide>
          <slideno>48</slideno>
          <text>Adding the Conflict to the Bayesian Network
Truth Value =False Conditional Probability Table 
A=N Br=N C=N T F 
Conflict: T T T 1 0 
A = NORMAL T T F 0 1 
B = NORMAL T F T 0 1C = NORMAL T F F 0 1 
F T T 0 1 F T F 0 1 F F T 0 1 F F F 0 1 
N H N H
Normal .6 .15 NoGood1 
H N Normal .50 .05
Peak .1 .80 Normal .8 .3 Fast .25 .45
Off Peak .3 .05 Slow .2 .7 Slow .25 .50
49 A 
Host1 B 
D C 
E 
Host2 Host4 Host3 
Normal .9 
Hacked .1 Normal .85 Hacked .15 Normal .8 Hacked .2 Normal .7 Hacked .3 N H 
Normal .50 .05 
Fast .25 .45 
Slow .25 .50 N H 
Normal .60 .05 Slow .25 .45 
.15 .50 
6.871  Lecture 15 Slower</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Behavior Representation
	Expressions capturing relationships 
between values at terminals 
 Multi-directional 
 Constraint-like  rather than simply procedural 
A 
C 
B 
 To compute C:  Evaluate A + B 
6.871  Lecture 15 9</text>
        </slide>
        <slide>
          <slideno>68</slideno>
          <text>How to Address these Problems
	Choose the representation of pr imitive elements and connections 
so as to sacrifice completeness for efficiency. 
	Treat physically separate com ponents with indistinguishable 
failure modes as one component. 
	Treat devices whose failure r equires the same repair as one 
device. 
	Don't represent very unlikely failure modes 
	Describe signals in a way which is easy to observe. 
	Represent the likelihood of failure modes. 
	Use temporally abstract description of signals. 
	Use multiple levels of behavioral abstraction. 
6.871  Lecture 15 69</text>
        </slide>
        <slide>
          <slideno>53</slideno>
          <text>Informative Probes
3
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 
35 40 X 
Y 
Z A 
5
5
5
B
3
T3 Bad P2 Bad
Probe at Y
Probe at Z
6.871  Lecture 15
 54</text>
        </slide>
        <slide>
          <slideno>69</slideno>
          <text>Principles of Modeling
	Components in the physical representation should 
correspond to the possible repairs. 
	Components in the functional representation should 
facilitate behavioral abstraction. 
6.871  Lecture 15 70</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Behavior Representation
	Expressions capturing relationships between values 
at terminals 
	Multi-directional 
	Constraint-like  rather than simply procedural
A
C 
B 
 To compute C:  Evaluate A + B 
 To compute A:  Evaluate C - B 
6.871  Lecture 15 11</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Model Based Troubleshooting
3 
5 
5 
5 
3 GDE 
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 
25 
35 40 X 
Y 
Z 
Propagations: 
Y=25 (T2) A 
B 
15 
Z=15 (T3) 
Assume P1 T1 working ==&gt; Y=25 (P1 T1) 
Assume P2 T3 working ==&gt; Y=20 (P2 T3) Assume T2 working       ==&gt; Y= 25 (T2) 
Conflicts: (P1 T1 P2 T3) 
6.871  Lecture 15 (P2 T2 T3) 27 
Diagnoses: (P2) (T3) (P1 T2)  (T1 T2)</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Model Based Troubleshooting
3
5
5
5
3
Assume P1 T1 working  ==&gt; Y=25 (P1 T1)
Assume P2 T3 working  ==&gt; Y=20 (P2 T3)
Assume T2 working  ==&gt; Y= 25 (T2)
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 
25 
35 40 X 
Y 
Z 
Propagations: 
Y=25 (T2) A 
B GDE 
Conflicts: (P1 T1 P2 T3)
(P2 T2 T3)
 6.871  Lecture 15 26
Diagnoses: (P2) (T3)  (P1 T2) (T1 T2)</text>
        </slide>
        <slide>
          <slideno>55</slideno>
          <text>Informative Probes
3
Times-1 
Times-2 
Times-3 Plus-2 Plus-1 
35 40 X 
Y 
Z A 
5
5
5
B
3
T3 Bad P2 Bad
Probe at Y 25 25
Probe at Z 10 15
6.871  Lecture 15
 56</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Behavior Representation
	Expressions capturing relationships between 
values at terminals 
	Multi-directional 
	Constraint-like  rather than simply procedural
A
C 
B 
 To compute C:  Evaluate A + B 
 To compute A:  Evaluate C - B 
6.871  Lecture 15  To compute B:  Evaluate C - A 12</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Course Organization; Spirit of the Undertaking (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect01_intro/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>28</slideno>
          <text>The Physical Symbol System 
Hypothesis
The Knowledge Level Hypothesis: There exists a distinct 
computer systems level which is characterized by 
knowledge as the medium and the principle of rationality as the law of behavior. 
Principle of rationality: if an agent has knowledge that one 
of its actions will lead to one of its goals, then the agent will select that action. 
(Roughly: content independent of form)
6.871 - Lecture 1 29</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Course Organization
	Lectures: slide copies (typically)
	Extensive reading assignments: read them 
(really) 
	Ask questions
	Homework 
6.871 - Lecture 1 5</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Character of Knowledge
	Most of what we know knowledge is non
numeric. 
	Most of what we know is heuristic.
 Whats certain? 
 Whats the alternative? 
6.871 - Lecture 1 31</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>(Why) is this interesting?
	Applied AI leads to advances in basic 
science 
 Knowledge acquisition/learning 
 Explanation 
 Knowledge sharing 
6.871 - Lecture 1 12</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>The Knowledge Level 
Hypothesis
Knowledge: Whatever can be ascribed to 
an agent, such that its behavior can be 
computed according to the principle of 
rationality. 
 Knowledge is closely linked to rationality.
 Knowledge is competence-like notion. 
6.871 - Lecture 1 30</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>What are knowledge-based 
systems
	Wherein arises expertise?
	KEY IDEA: 
| | EXPERT  AVERAGE PERSON | | = KNOWLEDGE 
	KEY IDEA: 
explicit representation of that knowledge 
	(The barge story again) 
6.871 - Lecture 1 16</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Current State
KBS = | | Expert Knowledge  Common 
Sense | | 
6.871 - Lecture 1 33</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>The Physical Symbol System 
Hypothesis
	A physical symbol system has the necessary and
sufficient means for general intelligent action 
Physical Symbol System consists of: 
	A set of symbols 
	A set of expressions (symbol structures)
	A set of procedures that operate on expressions to 
produce other expressions: Create, Modify, Reproduce
and Destroy 
6.871 - Lecture 1 28</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Course Character
 Course continually being improved 
 Feedback of all sorts is enormously helpful 
 Question, suggestions encouraged 
6.871 - Lecture 1 4</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Intellectual Origins
	19th century: Booles logic and The Laws 
of Thought 
To see this image, please visit: 
http://images.google.com/images?q=cgboole.gif 
6.871 - Lecture 1 20</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Intellectual Origins
 What makes for expertise? 
 Can human thought be formalized? 
 (How) Can we get a machine to be smart?
 And what is AI, anyway? 
6.871 - Lecture 1 17</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Character of the problems 
attacked
	Balancing your checkbook vs. 
Getting out of the supermarket 
 Telling it what to do vs.
Telling it what to know
 Write down some relevant knowledge 
 Advice, not a procedure 
6.871 - Lecture 1 13</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Trader Is Said to Have Defrauded Irish Bank of $750 Million
Dublin, Feb. 6  A trader for the Baltimore  based treasury arm of Allfirst, 
an American retail subsidiary of Allied Irish Banks P.L.C. (news/quote), 
defrauded Irelands largest financial inst itution of $750 million over the last 
year through bogus foreign exchange trading, and he has since disappeared, the bank said today. 
The 40  year  old trader, John Rusnak, failed to show up for work on Monday morning and has not been seen si nce he was interviewed about the 
matter at Allfirst offices on Friday. The Federal Bureau of Investigation 
interviewed his wife over the weekend, and the bank believes he is still in 
the Baltimore area. 
The suspected theft would be the largest international fraud case since 
1995, when Nick Leeson gambled $1.17 billion on foreign exchange trades in Singapore and set off the collapse of Englands historic Barings Bank. 
Allied Irish is unlikely to suffer the same fate; instead the bank will see 
profits after taxes for 2001 shrink to 401 million euros from 997 million euros 
in the previous year. 
6.871 - Lecture 1 10</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Intellectual Origins
	And how do we know whether we got 
there? 
	Can a machine think? 
	Can the person next to you think?
6.871 - Lecture 1 26</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Intellectual Origins
	2000 years ago 
 Aristotle and the art of rhetoric 
 The syllogisms 
	17th century: Leibniz and the algebra of 
thought 
6.871 - Lecture 1 19</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Course Organization
Spirit of the Undertaking
6.871: Knowledge-Based Systems
Spring 2005
Randall Davis</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Intellectual Origins
	19th century: Babbage and the Analytical Engine. 
Lady Lovelace conjectured that it would weave 
algebraic patterns the way the Jacquard loom weaved patterns in textiles. 
Portrait of Charles Babbage 
To see this image please visit: 
http://images.google.com/images?q=charles_babbage.full.jpg 
6.871 - Lecture 1 21 Portrait of Lady Lovelace
http://images.google.com/images?q=ladyada-big.gifTo see this image please visit:</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Logistics
 Info sheet, syllabus 
 Personnel: 
 Lecturers: Davis (and friends) 
 Course notes: 
 1st installment ready now 
 You are responsible for what happens in lecture.
 No open laptops. 
6.871 - Lecture 1 2</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Image removed due to copyright considerations.
6.871 - Lecture 1
 22</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>What are knowledge-based 
systems
 Knowledge based vs.? 
 Wherein arises intelligence? 
 GPS and the lessons of the 60s 
 Improvements more often involve bringing to 
bear specific knowledge on selected 
subproblems of an application than 
developing a new complete theory for it. 
6.871 - Lecture 1 15</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Image removed due to copyright considerations.
6.871 - Lecture 1
 23</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Course Outline 
	Intro &amp; Background 
	The Spirit and Pragmatics of KBS
	Knowledge Representations and 
Reasoning 
	Problem Solving Paradigms
	Research Issues 
	Project Presentations 
6.871 - Lecture 1 7</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>In 1995, in Singapore
Crime Case Closed Infamous Crimes
Nick Leeson and Barings Bank
The week before Nick Leeson disappeared he had kept 
throwing up at work.
Colleagues did not know why but were soon to find out.
The ego of a 28-year-old trader on the Singapore Monetary 
Exchange and the greed and stupidity of a 233-years-old bank had combined to distroy an investment empire and in the 
process stunned the world. 
6.871 - Lecture 1 9</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Intellectual Origins
	What is it we seek to embody in the 
machine? 
 Mind? 
 Thought? 
 Intelligence?
 Rationality?
 Neuroanatomy? 
6.871 - Lecture 1 25</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Course Character
 Learning how to do it 
 Largely engineering examples 
 The need to see beneath the surface 
 Background 
 6.034 (or equivalent) 
 Considerable high level language experience 
6.871 - Lecture 1 3</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Character of the problems 
attacked
	Balancing your checkbook vs. 
Getting out of the supermarket 
 Telling it what to do vs.
Telling it what to know
 Write down some relevant knowledge 
 Advice, not a procedure 
	Knowledge leads to action,
But knowledge is more fundamental
The barge story
6.871 - Lecture 1 14</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Course Organization
 Term project: alone or in pairs (not triples)
 Tools: Joshua, KAPPA-PC, M4, GRASS 
 The nth International Workshop on KBS 
 Oral report and individual term paper 
 Clear, concise, 20-30 pp. 
 What did you learn? 
	Course grade based on term project, 
homework, lecture participation 
6.871 - Lecture 1 6</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>What is
 Thought? 
 Intelligence?
 Rationality?
 Knowledge?
6.871 - Lecture 1 27</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Character of Knowledge
	Empirical, experiential knowledge: rules of 
thumb, heuristics 
	Design knowledge: theory, model, causal 
understanding 
	Common-sense knowledge
6.871 - Lecture 1 32</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>(Why) is this interesting?
	Applied AI leads to advances in basic 
science 
 Rule-based systems
 Causal reasoning 
 Reasoning at multiple levels: Reasoning 
under uncertainty 
 Case-based reasoning 
6.871 - Lecture 1 11</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Intellectual Origins
 2000 years ago 
 Aristotle and the art of rhetoric 
 The syllogisms 
 17th century: Leibniz and the algebra of thought 
 19th century: Booles logic and The Laws of Thought 
 19th century: Babbage and the Analytical Engine 
 20th century: Shannons insi ght about switching circuits 
 20th century: Turings ideas about thought and computation 
6.871 - Lecture 1 24</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Intellectual Origins
	AI is a great intellectual adventure
 Cf cosmology, physics, biology 
	AI is the exploration of the design space of 
intelligences 
	AI is making machines that solve problems 
requiring intelligence 
	AI is applied epistemology
6.871 - Lecture 1 18</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>(Why) is this interesting?
 Knowledge-Based Systems work
 DENDRAL, MYCIN, INTERNIST-I: comparable to 
human experts 
 PROSPECTOR: $100m worth of molybdenum
 R1/XCON: from 85% to 97.5% performance 
 American Express: 20% operational savings, 
$10Ms in added revenue
D u P o n t
 Manufacturers Hanover: Inspector 
 The clever (?) paper clip 
6.871 - Lecture 1 8</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Tell it What to Know; Search (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect02_know/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>31</slideno>
          <text>A Spreadsheet is Almost Right
	The right mindset: focus on the 
knowledge 
But: 
 They are numeric and we want more 
 They have only one inference engine 
	KBS as conceptual spreadsheets
6.871 - Lecture 2 32</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>The Power of A Good Representation
6.871 - Lecture 2
 9</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>The proportional ownership of the first party shall be equal to a ratio, the 
numerator of which is: a ratio, the numera tor of which is the holding period of 
the first party multiplied by the capital contributed by the first party, and the 
denominator of which is a sum, the first term of which is the holding period of 
the first party and the second term of which is the holding period of the second 
party; and a denominator which is the sum of two terms; the first term of which 
is a ratio, the numerator of which is the holding period of the first party 
multiplied by the capital contributed by th e first party, and the denominator of 
which is a sum, the first term of which is  the holding period of the first party, the 
second term of which is the holding peri od of the second party; and the second 
term of which is a ratio, the numerator of which is the holding period of the 
second party multiplied by the capital co ntributed by the second party, and the 
denominator of which is a sum, the first term of which is the holding period of 
the first party and the second term of which is the holding period of the second 
party. 
tm 1
1* 
t t 12+ 
tm 1 t m 2 1* 2 * + t+ t 12 12 t+ t 
6.871 - Lecture 2 11</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>Planning Islands:
The Power of Recognition
d (rows) 
6.871 - Lecture 2 Problem complexity = b d 42</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>The Fundamental Problem:
Search in a Problem Space
Size = Bd Node 
B Operator 
D 
 B = branching factor 
 D = depth 
6.871 - Lecture 2 34</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Version 1
PROCEDURE READPROBLEM (REAL ARRAY P)
Read in one line of integers, the
coefficients of a polynomial, into array P.Also sets DEGREE to degree of polynomial.Example: 
23x 3 + 4 x + 5x + 7 
is entered by typing
3 4 5 7
PROCEDURE POLY-DIFF (REAL ARRAY PROBLEM)
FOR I = DEGREE TO 1 STEP 1 DO
ANSWER [I-1] = I * PROBLEM [I]
6.871 - Lecture 2 15</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>The proportional ownership of the first party shall be equal to a ratio, the 
numerator of which is: a ratio, the numera tor of which is the holding period of 
the first party multiplied by the capital contributed by the first party, and the 
denominator of which is a sum, the first term of which is the holding period of 
the first party and the second term of which is the holding period of the second 
party; and a denominator which is the sum of two terms; the first term of which 
is a ratio, the numerator of which is the holding period of the first party 
multiplied by the capital contributed by th e first party, and the denominator of 
which is a sum, the first term of which is  the holding period of the first party, the 
second term of which is the holding peri od of the second party; and the second 
term of which is a ratio, the numerator of which is the holding period of the 
second party multiplied by the capital co ntributed by the second party, and the 
denominator of which is a sum, the first term of which is the holding period of 
the first party and the second term of which is the holding period of the second 
party. 
6.871 - Lecture 2 10</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>The Checkbook Example
Cleared Cleared Uncleared Uncleared 
Deposits Checks Deposits Checks 
Bank Balance $1234.56 
Total uncleared 
deposits 725.00 
Total uncleared checks 
$248.87 
New Balance 
$1,710.69 $100.00  
$250.00 
$75.00 
$90.00  
$213.40 
$874.30 
$19.00 
$22.00 
$250.00 
$95.00 
$180.00 
$200.00 
$15.00 
$12.34 
$19.99 
$25.00 
$72.54 
$105.00 
$14.00 
$24.00 
6.871 - Lecture 2
 31</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Task: Balancing Your Checkbook
Read StatementBalance
AdjBalance = StatementBalance
until done do {read OutstandingCheck
AdjBalance=- OutstandingCheck}
until done do {read OutstandingDeposits
AdjBalance=+ OutstandingDeposits}
until done do {read Fee
AdjBalance=- Fee}
until done do {read Interest
AdjBalance=+ Interest}
if AdjBalance = CheckBookBalance
{print (It balances!); return}
else if AdjBalance &gt; CheckbookBalance
{print Hey, good news.; return}
else {print Were scrod.; return} 
6.871 - Lecture 2 29</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Version 2
PROCEDURE POLY-DIFF (REAL ARRAY PROBLEM)
FOR I = DEGREE TO 1 STEP 1 DO 
ANSWER [COEFF, I] = PROBLEM [EXPON, I] *
PROBLEM [COEFF, I]
ANSWER [EXPON, I] = PROBLEM [EXPON, I]  1 
6.871 - Lecture 2 16</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Search Basics
 Lecture 2, Part 2.
6.871 - Lecture 2
 33</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Punchlines
 Nothing is ever right the first time
 Nature of the task 
 Nature of the knowledge 
 Evolutionary development 
 Build a little 
 Test a little 
 Redesign a little 
6.871 - Lecture 2 6</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>Pruning
 Throw away unpromising nodes 
 Some risk that the answer is still there 
 Great savings in time and space 
 Breadth limited search, beam search 
d b A Node 
An Operator KEY 
-5 100 
6.871 - Lecture 2 Figure by MIT  OCW. 40</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Whats a Good Representation?
	Consider: 1996 vs. MCMXCVI
	Which would you rather use in 
arithmetic? Why?
 Makes important things obvious
 Syntax and semantics are simple, 
consistent
 Algorithms for use are simple 
6.871 - Lecture 2 7</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>The Shape of The Space
 How densely distributed are the answers? 
 How uniformly distributed are the answers? 
 How do answer quality and distance relate? 
Size = Bd Node 
B Operator 
D 
6.871 - Lecture 2 36</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Tell It What to Know
6.871 - Lecture 2</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Whats a Good Representation?
	Consider: 1996 vs. 11111001100
	Which would the computer rather use in 
arithmetic? Why? 
 Algorithms for use are simple
 And simplicity is in the eye of the 
interpreter
6.871 - Lecture 2 8</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Whats a Program?
The Minimal Number of Bits View
DO 14 I = 1,N
DO 14 J = 1,N
14 V(I,J) = (I/J)*(J/I)
#include &lt;stdio.h&gt;
main ( )
{int v[5][5];
int i,j;
for (i=1; i&lt;5; i++)
for (j=1; j&lt;5; j++)
v[i][j]=(i/j)*(j/i)}
6.871 - Lecture 2 13</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>No, really, tell it what to know
xn
 n * xn1
The mathematical know ledge is bidirectional 
Could be used for integration as well 
Even if we dont use it for that at the moment, perhaps we  should preserve the opportunity to do so 
More powerful patt ern language for capt uring the structure 
More powerful matchers for enabling dispatches 
6.871 - Lecture 2 26</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>The New Approach 
3x3 + 5x + 7
6.871 - Lecture 2
 20</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>Breadth First Search
 Never gets lost on deep or infinite path
 Always finds answer if its there 
 Requires lots of storage 
d 
6.871 - Lecture 2 A node 
b An operator 
38</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>But What About:
sin(x)
cos(x)
sin(x) + cos(x)
sin(x) * cos(x)
x2 cos( x) + sin( x) 
3x + 1 
6.871 - Lecture 2 17</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Whats a Program?
The Minimal Number of Bits View
DO 14 I = 1,N
DO 14 J = 1,N
14 V(I,J) = (I/J)*(J/I)
6.871 - Lecture 2 12</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>But What About:
sin(x)
cos(x)
sin(x) + cos(x)
sin(x) * cos(x)
6.871 - Lecture 2 47</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>An Implementation Approach: 
OOP
 Diff is a Generic Function 
 Methods for different types of expressions
 (defmethod diff ((n number)) 0) 
 (demethod diff ((x (eql x))) 1) 
 (defmethod diff ((y symbol)) 0) 
 Method for expressions does a subdispatch
(defmethod diff ((exp list))
(diff-op (first exp) (rest exp)))
 Methods for specific operators recursively call Diff
6.871 - Lecture 2 24</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Catchphrases and Punchlines
	The issue is style and pragmatics, not theory
	A program can be much more that just code. 
It can be a repository for knowledge, an environment for the development of knowledge 
	Embody the reasoning, not (just) the calculation.
	Dont tell it what to do, tell it what to know. 
 Task changes from writing a program to specifying 
the knowledge. 
	Task becomes debugging knowledge, not code. 
6.871 - Lecture 2 27</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>A Reminder
	Checkbook balancing vs. 
getting out of the supermarket 
	Character of task 
	Character of solution 
	Go past image to technical ideas and concepts
6.871 - Lecture 2 2</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>Depth First Search
 Go down before you go across 
 Maintains focus 
 Minimizes storage requirements 
 Finds answer faster sometimes 
d b A Node 
An Operator KEY 
6.871 - Lecture 2 Figure by MIT  OCW. 37</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>The Checkbook Example
Cleared Cleared Uncleared Uncleared 
Deposits Checks Deposits Checks 
Bank Balance $1234.56 $100.00 $213.40 $250.00 $12.34 
$250.00 $874.30 $95.00 $19.99 
Total uncleared $75.00 $19.00 $180.00 $25.00 
deposits $725.00 $90.00 $22.00 $200.00 $72.54 
Total uncleared $15.00 $105.00 
checks $248.87 $14.00 
$24.00 
New Balance $1,710.69 
6.871 - Lecture 2 48</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>A Spreadsheet is Almost Right
 The right mindset: focus on the knowledge
6.871 - Lecture 2
 30</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>A Small Language 
	In effect weve built a language with the right 
abstractions : 
	Expression tree 
	Dispatching on leading operator 
	Recursive descent through the expression tree
	Operators are independent, modular chunks of 
mathematical knowledge  
	Operators can be added incrementally
	There is an indexing mechanism for finding relevant 
operators given the structure of the current 
representational focus 
6.871 - Lecture 2 25</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Observations about the knowledge
 Its organized around the operators. 
 Its organized around nested sub-expressions
 Top-down tree descent is the natural approach
 The representation should reflect that. 
 The representation should facilitate that. 
6.871 - Lecture 2 22</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>Recognizing the Form of the Problem
N subproblems
Each of depth D/N
43 E.g. b = 2, d = 10, n = 5
Without Islands: 1024 With Islands: 5 * 4 = 20 
You can guess wrong
50 times and still be ahead of the game! 
d (rows) 
d Each of size bD/N 
D/N 
N planning islands 
6.871 - Lecture 2 Problem complexity = b Total size = N * b</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Purposes of This Lecture
 Explain the mindset of knowledge engineering 
 Change your mind about what a program is 
 From a buncha bits to  
 From code to  
 Change your mind about how to create them 
 Dont tell it what to do 
 Build it incrementally 
 Change your mind about what to use a computer for 
 Many things 
6.871 - Lecture 2 3</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Catchphrases and Punchlines
	One payoff: multiple uses of the same knowledge.
	Performance is only the beginning 
Solving the problem is only (a small) part of the job 
	Explanation 
	Learning
	Tutoring
6.871 - Lecture 2 28</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>The New Approach 
3x3 + 5x + 7 
Multiply coefficient times exponent and subtract one 
from exponent ? 
6.871 - Lecture 2 21</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>Summary
	All problem solving problems involve search spaces 
	Search space grow intractably 
	Many common algorithms for search are known 
	In the Knowledge Lies the Power 
	Knowledge of a heuristic metric 
	Knowledge of planning islands 
	Knowledge of relevant abstractions 
	Build representations that capture these sources of 
power 
6.871 - Lecture 2 44</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Task: Symbolic Mathematics
How can we take a derivative of
2
3x 3 + 4 x + 5x + 7
to get
9x2 + 8x + 5
6.871 - Lecture 2
 14</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>Version 2
INTEGER DEGREE, COEFF, EXPON
REAL ARRAY PROBLEM, ANSWER [1:2, 1:1000]
EXPON = 1
COEFF = 2
coefficients and exponents, putting the coefficients
in the COEFF row of P and the exponents in the EXPONrow of P. Example: This version reads in a line of pairs of integers, 
2
3x 3 + 4 x + 5x + 7 
results in EXPON row : 3 2 1 0
COEFF row: 3 4 5 7
6.871 - Lecture 2 45</text>
        </slide>
        <slide>
          <slideno>45</slideno>
          <text>Version 2
PROCEDURE POLY-DIFF (REAL ARRAY PROBLEM)
FOR I = DEGREE TO 1 STEP 1 DO
BEGIN 
ANSWER [COEFF, I] = PROBLEM [EXPON, I] *
PROBLEM [COEFF, I]
ANSWER [EXPON, I] = PROBLEM [EXPON, I]  1 
END 
6.871 - Lecture 2 46</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>Optimum Often isnt Optimum
 In the real world things go wrong 
 Robust near-optimum is usually better on average 
Optimum 
Robust 
Sub-Optimum Robust 
Sub-Optimum 
Position in Search Space Quality of Solution 
6.871 - Lecture 2 Figure by MIT  OCW. 41</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Version 3
PROCEDURE DIFF (TREE)
CASE TREE [SYMBOL] OF
BEGIN 
[^] ANS = DIFF-EXPONL (TREE)
[+] ANS = DIFF-SUM (TREE)[*] ANS = DIFF-PROD (TREE)
[SIN COS TAN] = ANS = DIFF-TRIG (TREE)
END 
PROCEDURE DIFF-SUM (TREE)
MAKE-TREE (+,DIFF(TREE[LEFTB]),DIFF(TREE[RIGHTB]))
6.871 - Lecture 2 18</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Use a Natural Representation
 Conventional mathematical notation?
( + 2 x y 3 + a z xy ) 
(* (* 2 y) sqrt(+ (^ x 3) (* x y (+ z a))))
 Use the pattern appropriate for the leading operator
6.871 - Lecture 2 23</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>Best First Search
 Requires quality metric 
 If metric is informed its very quick 
 Space requirements are intermediate 
d b 4 5 
3 6 A Node 
An Operator KEY 
6.871 - Lecture 2 Figure by MIT OCW. 39</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Punchlines
	The issue is style and pragmatics, not theory
	A program can be much more than just code. 
It can be a repository of knowledge, 
an environment for the development of knowledge 
	Embody the reasoning, not (just) the calculation
	Dont tell it what to do, tell it what to know, and how to 
use what it knows (often many different ways) 
 Task changes from writing a program to specifying 
the knowledge. 
	Task becomes debugging knowledge, not code. 
6.871 - Lecture 2 4</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>Search Spaces Grow Exponentially
Trivial Impossible 
Complexity of Problem Cost of Solution 
The marginal cost of slight improvement is prohibitive
6.871 - Lecture 2
Figure  by MIT  OCW. 35</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Version 3
PROCEDURE DIFF-PROD(TREE)
MAKE-TREE(+,
MAKE-TREE(*, DIFF(TREE[LEFTB]),
TREE[RIGHTB])
MAKE-TREE(*, DIFF(TREE[RIGHTB]),
TREE[LEFTB]))
6.871 - Lecture 2 19</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Punchlines
	One payoff: multiple uses of the same knowledge.
	Performance is only the beginning 
Solving the problem is only (a small) part of the job 
	Explanation 
	Learning 
	Tutoring 
	Suppressing detail helps
	Build a custom language
6.871 - Lecture 2 5</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Pragmatic Issues in Knowledge Acquisition&#160;(PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect12_pragmatic/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>17</slideno>
          <text>What Representation to Use?
 Medical diagnosis 
 Getting out of the supermarket
ASK YOURSELF: WHAT DO YOU KNOW? 
Then listen to the answer. 
6.871 - Lecture 12 18</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Example: Selecting an Investment
	Franks Financial Supermarket offers 7 kinds of 
investments
 stocks, index funds, bonds, commodities, 
mutual funds, rare coins, tax shelters
	There are 
	1500 stocks 
	1000 bonds 
	15 different mutual funds 
	In the mutual funds: 
	consider the tax-free money market fund 
6.871 - Lecture 12 24</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Learning by Being Programmed
00 00 00 . 2
6.871 - Lecture 12
 6</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Example: Selecting an Investment
	What factors differentiate among choices 
in that category? 
Why the tax free mm fund instead of the 
tax free bond fund? 
6.871 - Lecture 12 27</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Outline
 The intent of this lecture 
 The longstanding dream 
 What do we mean learn? 
 What this lecture is not about
 The nature of the task 
 Predictable difficulties 
 Pragmatics of debriefing 
6.871 - Lecture 12 2</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Pragmatic Techniques
 Interviews 
 Observe (Record) Performance
 Protocol Analysis 
6.871 - Lecture 12 10</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Getting The Knowledge: 
Sources
 Books 
 People 
 Finding one 
 Finding one 
 Level of aspiration 
 Finding the one 
 Confident 
 Introspective &amp; Reductionistic 
 Intrigued 
6.871 - Lecture 12 16</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Example: Selecting an Investment
	What factors suggest that choice as the 
correct one?
If your tax bracket is 42% or higher and 
you need to keep the money readily at 
hand, then the tax-free mm fund is a good 
choice.  
6.871 - Lecture 12 25</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Getting The Knowledge: Debriefing
 Signing on 
 Work from examples 
 dead center cases 
 marginal cases 
 Errors are wonderful 
 its easier to modify than specify 
 The relevance of the computer 
 mental hygiene 
 efficiency 
6.871 - Lecture 12 19</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>The Dream: Version 1
COMPA
CTDISC 
6.871 - Lecture 12
Figure by MIT OCW. 3</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>The Dream: Version 2
6.871 - Lecture 12
Figure by MIT OCW. 4</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Getting The Knowledge: Debriefing
	Meet the expert half way:
	learn the experts language 
	Talk your language 
 it will be infectious 
	Come at hard problems from several 
directions 
6.871 - Lecture 12 21</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Getting The Knowledge: Debriefing
 Be rabidly rational and reductionistic
 Be patient 
 Get interested 
6.871 - Lecture 12 20</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Example: Selecting an Investment
 Notice the vocabulary in use
If your tax bracket is 42% or higher and 
you need to keep the money readily at 
hand, then the tax-free mm fund is a good 
choice.  
 Look for chains of reasoning
6.871 - Lecture 12 26</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Nature Of The Task
 Bridging the gap 
 Building a formal a language 
 sentences, nouns, verbs,  
 rules, attributes, objects, values 
 Working from both directions 
 kinds of knowledge 
 kinds of reps 
6.871 - Lecture 12 13</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Predictable Difficulties
 The expert 
  knows more than he says
  says more than he knows
  lies to you 
  disagrees with other experts 
6.871 - Lecture 12 14</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>What This Lecture Is Not About
	The variety of cognitive science oriented 
techniques: 
 Multi-dimensional scaling
 Personal construct theory
 Ordered Trees from Recall

6.871 - Lecture 12 8</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Basic Interaction
KNOWLEDGE 
ENGINEER
SYSTEM EXPERT 
Listen
Understand
Reformulate
Explain 
6.871 - Lecture 12 11</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>What This Lecture Is Not About
	The variety of machine learning 
techniques: 
 PAC learning
 Neural nets
I D - 3
 Genetic algorithms
 Nearest neighbor 
 Knowledge discovery and data mining

6.871 - Lecture 12 7</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Modes of Learning
 Learning by being programmed 
 Learning by being told 
 Learning from selected examples 
 Learning from unselected examples
 Learning by discovery 
6.871 - Lecture 12 5</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>A Key Hard Problem
CREDIT (BLAME) ASSIGNMENT 
6.871 - Lecture 12
 9</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Knowledge Acquisition:Getting Started
 Notice the vocabulary in use: 
 What are attributes, objects and values? 
 Notice statements like 
 if X and Y, then the best choice is Z
 Look for chains of reasoning 
6.871 - Lecture 12 23</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>The Nature of the Task
KNOWLEDGE 
Knowledge Engineering 
KNOWLEDGE REPRESENTATIONS 
Rules 
Procedures 
Logic Frames 
Semantic Nets 
6.871 - Lecture 12
 12</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Predictable Difficulties
 Knowledge engineers
  rush to structure 
  need social skills 
  need AI skills 
6.871 - Lecture 12 15</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Pragmatic Knowledge 
Acquisition
6.871 - Lecture 12</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Knowledge Acquisition:Getting Started
 Determine the size and structure of the solution space
	How many categories of answers are there? 
	How many specific choices within each category? 
	Select a category, select a specific choice 
	What factors suggest that choice as the correct one?
	What factors differentiate among choices in that 
category?
6.871 - Lecture 12 22</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>What Representation to Use?
 Medical diagnosis 
 Getting out of the supermarket
6.871 - Lecture 12 17</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Origins of KBS: MACSYMA and DENDRAL (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect03_dendral/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>Goals of Project
To help applied mathematicians in solving 
problems 
4
 x 13
5 x
 = arcsin( x)  tan(arcsin( x)) + tan (arcsin( )) 
22
(1  x ) 3
6.871 - Lecture 3
 3</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Sin
	Steps 
1. Derivative divides
2. 11 specific methods
	Substantial effort in deciding which to apply 
 Largely organized around recognizing the form of the 
problem 
3. General purpose methods (e.g., search)
	Note the sequence. 
	We feel that too few AI programs employ the fact that in 
many problem domains there exist methods which solve 
a large number of problems quickly. 
6.871 - Lecture 3 12</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Macsyma Lessons
	Keep the system modular and loosely 
coupled 
 It is sometimes cheaper to translate one 
representation to another in order to solve the 
problem more efficiently 
 Use of a common language for 
communication makes this approach tractable 
(eg, dense and sparse polynomials) 
	Do not duplicate knowledge 
	leads to unmanageable system 
6.871 - Lecture 3 14</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Building the Program Advances The 
Field
	The SAINT, SIN, MACSYMA, Risch 
progression 
	Dendrals accumulation, rationalization 
and development of chemistry knowledge. 
6.871 - Lecture 3 26</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Level of Representation
IF 
There are peaks at M1 and M2 such that 
M1 + M2 = MW + 28 and 
M1 is high and M2 is high 
THEN 
The structure is one of the ketones 
6.871 - Lecture 3 23</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>sin 4 y
dyy 4cos 
4z three possible ways to deal with this: 
2 24  tan4 ydy  cot4 ydy  32 (1 + z )(1  z ) dz 
(from z = tan(y/z)) 
6.871 - Lecture 3 7</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Symbolic Mathematics: AI 
Approaches
 Slagle: SAINT 
 Moses: SIN 
 Moses and Martin: MACSYMA
 Reduce-II 
 Mathematica 
6.871 - Lecture 3 4</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>How to Proceed?
 Given: 
 Empirical Formula: C9H18O (total MW = 142) 
 Known Structure Constraints 
 Mass Spectrum 
Rel. 
Abun. 
40 50 60 70 80 90 100 110  Catalog? 
Mass 
6.871 - Lecture 3 17</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>MACSYMA: Symbolic Mathematics
 Goals of the Project
 System Description
 Lessons 
6.871 - Lecture 3 2</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Efficiency and  
If high peak at 57 and high peak at 113 
Then ketone 
If high peak at 57 and high peak at 98 
Then ether 
If high peak at 57 
Then if high peak at 113 then ketone 
Else if high peak at 98 then ether 
6.871 - Lecture 3 22</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Difficulties in Generate &amp; Test
212
-422
-9130
!!
6.871 - Lecture 3
 19</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>SAINT: Symbolic Automatic 
Integrator
4 
 x dx5 
2(1  x )2 
Try y = arcsin x, yielding: 
 sin 4 ydy4cos y 
6.871 - Lecture 3 5</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>In the Knowledge Lies the 
Power
	Lesson: 
Knowledge can obviate the need for search. 
(If you know where to look you dont have to search) 
L e s s o n 
Knowledge migrated from the tester to the generator. (Its often better to have a smart generator) 
6.871 - Lecture 3 25</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Macsyma Lessons
	Character of the problem changes as knowledge 
evolves 
	SAINT
	Worked as people appeared to: extensive search and 
backtracking 
S I N
	Almost always correct on the first guess: 
found the sources of power in the domain 
	RISCH: Algorithmic Integration 
 Guaranteed to succeed if the expression is integrable 
	Uses very special representation 
 Computationally complex and expensive 
6.871 - Lecture 3  Process not understandable to users but provably correct. 13</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Result
O 
| | 
C  C  C  C  C  C  C  C  C 
6.871 - Lecture 3 16</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>How Can the Program Plan Its 
Attack?
What should the program know?
Rules: spectrum features  molecule class
IF There are peaks at M1 and M2 such that 
M1 + M2 = MW + 28 and 
M1 is high and M2 is high 
THEN The structure is one of the ketones 
IF There is a high peak at 44 and 
there is a high peak at M1  44 
THEN The structure is one of the aldehydes 
6.871 - Lecture 3 20</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Generate and Test
|
C   H    O  
|
For C9 H18 O two possible structures are
O O 
|| || 
C   C  C  C  C  C  C  C  C   C  C  C  C  C  C  C C  C 
6.871 - Lecture 3 18</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>SAINT
	Worked like the average engineer, i.e., lots of search 
and backtracking 
	Conceived of in terms of search, worked because of that. 
The power comes from: 
	Problem decomposition 
	Methodical exploration of alternatives 
	Looking far, wide, and deep 
	Speedy tree construction, search, backtracking
	Success is just a matter of trying enough alternatives
6.871 - Lecture 3 9</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Dendral: Structure Elucidation
G i v e n : 
 Empirical Formula: C9H18O (total MW = 142) 
 Known Structure Constraints 
Abun.  
Rel. Mass Spectrum 
40 50 60 70 80 90 100 110
6.871 - Lecture 3 Mass
 15</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>sin 4 ydy4cos y 
three possible ways to deal with this: 
6.871 - Lecture 3 6</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>The Mindset Shift
SAINT will frequently [need to] explor e several paths to a solution  
because it lacks the powerful machinery that SIN possesses. 
One of the striking features of th ese programs is how little knowledge 
they require in order to obtain a solu tion.  Persson in his recent thesis 
dealing with sequence prediction seems to feel that placing a great deal 
of context dependent information in a program would be cheating.  This 
emphasis seems to be useful w hen one desires to study certain problem 
solving mechanisms in as pure a manner as possible. 
We, on the other hand, intended no such study of specific problem 
solving mechanisms, but mainly desir ed a powerful integration program 
which behaved closely to our conception of expert human integrators . 
SIN, we hope, signals a return to an examination of complex problem 
domains. -- Moses, 1963. 
[emphasis added] Note: almost always needed one (otherwise avg would be lower) 
almost always needed exactly one (otherwise avg higher) 
Cant prove that search was irrelevant, since we dont know wh ether earlier use of heuristics wo uld have helped, but we should certainly be suspicious. 
Also dont know whether it was the same one heuristic each time . (Even if it was a different one, its still interesting that ev ery problem needs one and only one heuristic. 
Great example of seeing what you wa nt to see, being mechanism driven, 
6.871 - Lecture 3 11</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>SAINT
 Steps 
 26 standard forms (1-step solutions, tables)
 8 Algorithmic transforms (eg. sum of integrals) 
 10 Heuristic transforms, of which derivative 
divides is the most successful 
 Goals evaluated on depth of integrand 
2 
 Ex.,  xex is of depth 3 
6.871 - Lecture 3 8</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>SAINT
Some interesting statistics: 
Saints Average Performance 
Unused Heuristic 
Subgoals Subgoals Level Level 
32 Author problem 6.4 2.0 3.5 1.0 
52 MIT Problems 4.7 0.8 2.9 .8 
84 Problems 5.3 1.25 3.0 .9 
6.871 - Lecture 3 10</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Knowledge Representation
 Efficiency vs. Comprehensibility
Additivity 
Modifiability 
 Level of representation
6.871 - Lecture 3 21</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>The Spirit Of The Undertaking: 
Origins In Macsyma And 
Dendral
6.871-- Lecture 3</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Representation Punchline 
Lesson: 
Use the 
Highest level
Most Transparent
Easily modified
representation you can find 
OO 
||  || 
X  C  C  C  Y X  C  C      C  Y 
OO 
|| ||X  C  C  C  Y X  C            C  C  Y 
6.871 - Lecture 3 24</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Semantic Nets (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-871-knowledge-based-applications-systems-spring-2005/resources/lect07_semcnets/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>24</slideno>
          <text>Meaning in KL-One
 
 The meaning of a concept is either
 
 A strict definition of necessary and sufficient 
conditions based on superclass[es], and role 
restrictions. 
 Or, a primitive: only necessary conditions. 
 Typically natural kinds [E.g. animal, water] 
6.871  Lecture 7 25</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Conceptual Dependencies
 
	 Expressiveness: All world knowledge?
 
	 Not an intuitive means of communication, for 
us. 
6.871  Lecture 7 18</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>KL-One Descendants
 
	 NIKL, KL-TWO, KRYPTON, KANDOR
 
	 All Structured Inheritance Networks; same basic 
ontological commitment. 
	 Decisions made about: 
 Whether roles may also be in a definition hierarchy. 
 What expressions are allowed in TBox?  In ABox? 
 Trading off the expressiveness of the language with 
efficiency of the classifier. 
6.871  Lecture 7 29</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Primitives?
 
 Whats primitive in Quillian?
 
 Why primitives? 
 Approaches to primitives:  
 Language independent: Conceptual 
 
dependencies
 
 Language [English] dependent: OWL 
6.871  Lecture 7 14</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Representations for KBS:
 
Semantic Networks
 
6.871 Lecture 7</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Links: What Do They Mean?
 
 I S - A 
	 Clyde is-a elephant
	 Elephant is-a mammal 
	 The World Wide (Non-Semantic) Web 
	 What does a hyperlink mean ? 
 What does that mean? 
 Eg: books on the web 
	 Need to think about the semantics of the network notation, to 
 
minimize the intuitive meanings of links
 
	 Similarity to semantics in logic sense 
	 Meaning arises from: 
 what the interpreter does (procedural semantics) 
 formal definitions 
6.871  Lecture 7 19</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>KL-ONE
 
	 Logic-like notation: 
 Concepts: One place logical predicates: C(x). 
	 Eg. Animal(x). 
	 Subsumption links: C1 subsumes C2 if and 
only if for all X, C2(x) --&gt; C1(x) 
 Eg. Dog(x) --&gt; Animal(x). 
 Subsumption links create a taxonomy. 
6.871  Lecture 7 23</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>( ) j S Plant 1 
PLANT Live Animal 10C1 or or 
and 
and 
and Leaf 12N1 People 12N1 
Process 
In 
Industry or Get 3 
From 3 
Food Air 
Earth or Plant or 
or Plant 2 
Use 
For 5 IN 9 
= B D 
Seed Earth 
Grow Plant 3 
Put 
For 4 
= B Plant 2 Plant 3 
1. Living structure which is not an animal, frequently with leaves, getting its food from air, water, earth. 
2. Apparatus used for any process in industry. 
3. Put seed, plant, etc. in earth for growth. = A Structure 
With 3 17C1 
= A 
= A 
Water Ob ect 12C1 = A Apparatus 13C1 
Person T8C1 
6.871  Lecture 7 Figure by MIT OCW. 9</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>KL-ONE Network
 
POLYGON 
TRIANGLE * GEOMETRIC-
ENTITY * 
SEGMENT * 
Side 
(1, NIL) 
Restr. Triangle(x)  
Polygon(x) AND 
Exists exactly 3 y s.t. 
Side(x, y) and
Segment(y). 
Side 
(3,3) 
6.871  Lecture 7 26</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Example
 
 John kissed Mary in the car
 
John Mary 
Kiss The Car 
In 
Saw Bob Bob saw John Kiss Mary 
6.871  Lecture 7
 32</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Classification
 
Place a new concept underneath the most specific
 
generalizer .	 Triangle(x) 
 
Polygon(x) and
 
Exists exactly 3 y s.t.
 
Side(x, y) and Segment(y). 
EquiTri  
Polygon and 
Exists exactly 3 y st 
Side (x, y) and Segment(y) 
and Forall y1, y2 st Segment(y1) and 
Segment(y2): *ENTITY * 
Side 
(1, NIL)POLYGON
TRIANGLEGEOMETRIC-
SEGMENT *
Restr. 
Side 
(3,3) Length(y1) = Length(y2) 
6.871  Lecture 7 27</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>What is a Semantic Net?
 
 Whats a net? 
 What a semantic net? 
 Where do the semantics come from?
 
6.871  Lecture 7 4</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Semantic Memory [Quillian, 1966] 
 
 Motivations:
 
 Claim that people use same memory structure 
for a variety of tasks 
 Wish to encode dictionary definition of words.
 
 And then: 
 Comparing and contrasting meanings of two words 
 Generating quasi-English sentences to describe the 
comparison 
6.871  Lecture 7 7</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Spreading Activation 
(A) (B) 
(C) P 
P P P P P P P P 
P P P P P P P 
P 
P P P P P P P ROBIN Robin is activated Robin primes its associates 
Robin Red Breast 
is a is a is a 
Blue Eggs Bird 
Canary 
Sings Fly Feathers Animal 
Skin Breathe ROBIN 
is a is a is a 
Blue Eggs Bird 
Canary 
Sings Fly Feathers Animal 
Skin Breathe 
ROBIN 
is a is a is a 
Blue Eggs Bird 
Canary 
Sings Fly Feathers Animal 
Skin Breathe Continued priming from Yellow Red Breast 
Yellow 
Red Breast 
Yellow 
6.871  Lecture 7 Figure by MIT OCW. 13</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>KL-ONE
 
 Distinction between individuals and generics
 
 Roles: Two place relations R(x,y). 
 E.g. Color(x,y) 
 Defined by domain and range; have their own 
taxonomy 
 Role restrictions: consist of 
 
 Value Restrictions - the class of the role fillers for 
that concept 
 Number Restrictions - min. and max. number of 
instances filling the role. 
6.871  Lecture 7 24</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Semantic Memory Formalism
 
	 Plane: A network of nodes and links fo r representing the definition of 
a word "concept" 
	 Nodes:   
	 Type nodes: Direct representation of word [one per plane] 
	 Token nodes: Denote a type node in some other plane 
	 Link types 
	 Type node A is a subclass of B 
	 A,B, and C disjunctive [conjunctive] 
	 A relates B and C 
	 A is a token associated with type node A 
	 A modifies B [an escape hatch] 
6.871  Lecture 7 8</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Summary
 
	 Semantic networks have evolved
 
 Shift in motivation from modeling cognitive
processes to addressing computational issues. 
 Shift in representation goals from 	
"all human 
memory" to certain types of knowledge separately
[eg. definitions vs. assertions, classes vs.instances] 
 Semantics of links have become less intuitive and 
more formally defined. 
 Shift in reasoning mechanisms suited to more
careful definitions of primitives. 
 Possible impact on WWW. 
6.871  Lecture 7 34</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Conceptual Dependency
	A strongly reductionist approach 
	Five primitive categories of knowledge 
	Actions [Eg. Propel, Ingest, Ptrans, Mtrans] 
	Tenses [Eg. Present, Fast, Future] 
	Objects [any noun] 
	Modifiers of actions: case frames [eg. object, subject, 
recipient] 
	Modifiers of objects 
	Combining primitives yields standard scenarios 
	building blocks world knowledge. 
6.871 - Lecture 7 15</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>SI-Nets: Epistemologically Explicit
 
	 Importance of subsumption: one concept as more 
 
general than a second concept.
 
	 Eg. Animal subsumes Dog. 
	 Allows inheritance of definitional properties 
 	Allows recognizing new concepts and instances as 
members of concepts. 
	 Subsumption is the recommended inference. 
 	(In logical inference, the mo st general unifier is the key 
computation, here its the most specific subsumer). 
6.871  Lecture 7 22</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Food 
FOOD Formor 
Meal 
= B Live = B Being 2 
= B 
and or 
Drink 
Keep Grow 
= B Into 
1. That which living being has to take in to keep it living and for growth. Things forming meals, especially other than drink. = A Thing 
Has-To 
To 7 = A 
Take 11 
= A Other-Than 
6.871  Lecture 7 Figure by MIT OCW. 10</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Questions for Semantic Nets
 
 Regarding the original motivation 
 How should we view the world? 
 What are the recommended inferences? 
 Regarding the representation formalism: 
 (What) are the(re) primitives? 
	 The primitives of a KR technology are those things the 
interpreter is programmed in advance to understand
[Brachman] 
 What knowledge can we express? 
 What does a concept mean? 
	 May be what the machine infers 
	 May be a formal answer 
 Regarding the reasoning mechanism: 
 What are the easy/automatic inferences? 
 How efficient can we make these? 
6.871  Lecture 7 5</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Expressiveness in SI Nets 
 
	 Very few cases of people actually using SI net 
languages like KL-One to encode large knowledge
bases. 
	 In general, there are problems from limited 
 
expressiveness:
 
 Cannot clearly define many important concepts in a 
domain. 
 Consider defining a right triangle, or isosceles 
triangle. 
 Consider defining a chair or a dog. 
	 Issues of different "boxes" to put knowledge in: 
	 TBox - Definitions, usually about classes. 
 ABox - "Assertions" - non-definitional properties of 
concepts and instances. 
6.871  Lecture 7 28</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Preview
 
	 Semantic networks have evolved:
 
 Shift in motivation from modeling cognitive
processes to addressing computational issues. 
 Shift in representation goals from 	
"all human 
memory" to certain types of knowledge [eg.
definitions vs. assertions, classes vs. instances] 
 Semantics of links have become less intuitive 
and more formally defined. 
 Shift in reasoning mechanisms suited to more
careful definitions of primitives. 
6.871  Lecture 7 3</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Semantic Memory Reasoning
 
	 Comparing meanings of two words: via 
spreading activation 
 Intersections in unguided breadth-first search 
	 General purpose 
	 Is this closest path the shared meaning? 
	 Describing the comparison: 
 Trace the links leading to the intersections.
 
6.871  Lecture 7 12</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Example CDs
Basic dependency
John
 PTRANS 
Combining 2 dependencies
John
 PROPEL cart 
More Complex: 
John
p I
John INGEST
doo 
o 
ice cream 
6.871 - Lecture 7 spoon 16</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Semantic Memory [Quillian, 1966]
 
	 Motivations
 
 Understand the structure of human memory, and its 
use in language understanding 
 What sort of representational format can permit the 
meanings of words to be stored, so that humanlike 
use of these meanings is possible? 
	 Psychological evidence that memory uses associative 
links in understanding words 
6.871  Lecture 7 6</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Where Field Is Today
 
	 Still much focus on structured inheritance 
networks 
	 Much focus on computational details of well-
known network formalisms. 
	 Claim: Need to return to basic investigations 
of real world knowledge for new ideas 
6.871  Lecture 7 30</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>SI-Nets: Epistemologically Explicit
 
	 Representational primitives with formal, logical 
 
meanings. 
 
	 Strict definitions of concepts: necessary and sufficient 
conditions, giving the essence of the concept's 
intension. 
 Some representations are concerned with the 
definition of terms - the T-box 
 Other representations use terminology to say whats 
true in the world at the moment - the A-box 
 A-box reasoning can use T-box reasoning as a fast 
subroutine for certain queries. 
6.871  Lecture 7 21</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Outline
 
	 Quillian's foundations: associations 
	 Implicit meanings for uniform links 
	 Knowledge-related primitives [eg. CDs]
 
	 Concern for semantics of the language
 
	 Structured inheritance networks [eg. KL
ONE] 
	 Where the field is today
 
6.871  Lecture 7 2</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Links: What Do They Mean?
 
M43
 
R1
 
E16 
R16 
C19 
R47 C19 
R47 R47
L21 T73 T22R47	
L21 T16
 C19 
R47 R47 
T73 T22 
R47 
T16 R47 
 
6.871  Lecture 7 20</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>The Semantic Web
 
	 Treat WWW Identifiers (URIs) as nodes
 
	 Create a repository of triples describing these nodes
semantically. 
 Traditional Meta-Data such as author, creation-
date 
 Non traditional meta-data such as summary or 
peer review 
	 Use this network to retrieve Web resources based on 
their semantics 
 W3C standards are being evolved for this purpose: 
 RDF (resource description format), XML syntax 
6.871  Lecture 7 33</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Linguistically Motivated Networks
 
	 The START NLP system (and some other earlier systems) 
use a triples representation 
 The link points to a relationship name and to the subject 
and object nodes. 
 Links may function as nodes
 
 Relationship names and objects participate in inheritance 
relationships 
	 More complex relationships are decomposed into triples
 
6.871  Lecture 7 31</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Semantic Memory Formalism
 
	 Expressiveness: Any word with a dictionary 
definition 
	 Meaning of a concept: two answers 
 dictionary definition in its plane. 
 "full concept": transitive closure of all links 
	 Size ?? 
	 Focus is on nodes: in use links are merely 
connections 
6.871  Lecture 7 11</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Conceptual Dependency
 
	 Motivation: Provide a canonical form for 
world knowledge expressible in any natural 
language. 
	 Why a canonical form is valuable
 
 Deciding whether two expressions have the 
same meaning. 
	 If not, how close are they? 
 Understanding complex text [eg. stories] 
6.871  Lecture 7 17</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
