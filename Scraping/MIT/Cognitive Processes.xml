<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/</course_url>
    <course_title>Cognitive Processes</course_title>
    <course_tags>
      <list>Science </list>
      <list>Cognitive Science</list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>Introduction
How We Read (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/feb4h04/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>How immediate is processing? Do we process each word fully while we are fixati ng it, or do we store 
up several words and then process them? 
"The cotton cloth is made of grows in the south."  
A reader may be momentarily garden-pathed  by that sentence, because when he or s he arrives at 
the word "cloth," it seems to be a noun phrase, "the cott on cloth" instead of "T he cotton (that) cloth is 
made of..." 
This and other evidence sugges ts that we do immediatel y process each word as we fixate it, as far as 
the sentence and text to that poi nt allows. How do we know this ? By studying the durations of 
individual fixations on a given word, researchers have found that the duration of a fixation reflects 
word frequency, appropriateness to co ntext, syntactic difficulty at th at point in the sentence, etc. 
Some of the difficulty cr eated by a given word may "sp ill over" into longer ti mes spent looking at the 
next word or two, but most problems show up immediately. 
Because the motor planning for the next eye movement reaches  a "point of no return" (can't stop the 
planned movement) about  140 ms before the actual saccade takes place, th at leaves only about 160 
ms of an average 300  ms fixation for processing t he word one is looking at and "deciding" whether to 
extend the duration of the fixation or move on. That is, for word frequency to have an effect on how 
long you look at the word , you have to have recogn ized the word (or know that you've failed to 
recognize it) within the init ial160 ms of processing.  
The time for processing in the brai n is actually even shor ter than that, because it takes about 40 ms 
to get information from th e eye to the brain: thus, the central processing ti me for the average word 
must be less than 120 ms-- including not only looking up the word mentally but also under standing its 
fit to the syntax and m eaning of the sentence. 
e. Are eye movements (plus acuity limit ations) a waste of time, in reading? 
Would we read faster a nd more effectively if we could read wi thout eye movements?  With computers 
it is possible to present each word , one at a time, in  the center of the screen so that you get perfect 
clarity without having to move your eyes. This me thod, called "RSVP" for rapid serial visual 
presentation  , has been used to study just  how fast people CAN read if they don't have to move their 
eyes. 
RSVP reading at 10 or 12 words/s is fairly comparable to reading NORMALLY: pr ovided that you give 
only one sentence in isolat ion. People can underst and the sentence,  make a quick judgment as to 
whether or not it's plausibl e, and repeat it  accurately. 
BUT: If you read a paragraph at th is rate: you seem to understand each sentenc e and get the general 
drift, but the amount you remember is small. We'll return to this issue a little later in the course. 
CONCLUSION: RSVP allows fast  skimming but only poor memory : so eye movements are not a 
waste of time. We re ad the way we do because  we need the time for memory consolidation , and 
indeed we adjust the time spen t on each word according to the word's intrinsic difficulty, and 
according to how well it fits the sentence and the discourse. 
Therefore: Speed reading? It's not possible and probably not  desirable anyway. Skimming, however, 
may be sufficient for so me purposes, and is wo rth learning how to do. 
f. Speech recodin g and readin g:</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences
Course Instructor: Professor Mary C. Potter
9.65 February 4, 20 04  Introduction; Ho w we read  HANDOUT 
I. Introduction to 9. 65 Cognitive Processes. 
II. Visual acuity, eye movements, and reading 
a. Visual acuity 
b. Eye movements and fixations 
c. Eye movements in reading 
d. Immediacy of processing?
 e. Are eye movements a w aste of time? RSVP        
f. "Speech recoding" and reading 
I. Introduction to 9.65
We cover human experim ental cognitive psychology, the study of human intellig ent processing. 
Includes high-level vision (e.g., object reco gnition), attention,  immediate and lo nger-term memory, 
learning, nature of concepts, im agery, language processi ng, mental codes, reasoning, and problem-
solving. Emphasis on experim ental methods and evidence. 
IT'S ESSENTIAL TO COME TO LABS AND THE QUIZ ZES. Note the dates on which the lab reports 
are due. There will be hand outs with an outline at the beginning of most lectur es, but they will not 
provide all the information you nee d: there will be space on the handout  to add your own notes during 
the lecture. (Thi s particular handout is more complete than most and in cludes some informati on not in 
the lecture.) 
II. Visual acuity and eye movements 
a. Visual acuity:
We see in fine detail only about the width of  our thumb held at arm's length: acuity (grain) falls off 
very rapidly in all directions, so that  we only getgross information outside a 10 degree circle. 
In the visual system, the changing gr ain of acuity corresponds to the density of photor eceptors (cones 
and rods) and retinal ganglion cells in the retina (the back of the eyeball). (C ones, which are sensitive 
over a wide range ofbrightne ss except for very low le vels of illuminat ion, are highly concentrated in 
the fovea, whereas rods, wh ich are sensitive to very low levels of light but sa turate with high levels, 
are more evenly distributed over the re tina.) Likewise, cells in  the visual cortex (in the brain) are more 
numerous in thepart that represents the fovea (close to  the center of fixation) and thinout in parts that 
represent the periphery (away from the fovea). This change in density  of representation is called the 
cortical magnifi cation factor. 
b. Eye movements and fixations:</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>There is a lot of evidence in the experimental literature that we DO recode to  speech (create the 
sounds of the words in our head) when we read: for exam ple, Van Orden showed that people can be 
misled in a task such as this. You are shown a word or phrase, and then a second  word, and you 
have to decide as fast as possible whether the second word is cons istent with the first word . For 
example: 
   "Animal"  POODLE [Yes]
   "Part of  a building"  SELLER 
   "Flower"              ROWS 
[Participants may mistakenly say Yes to homophones like se ller and rows, when they sound the same 
as cellar, rose (to which you'd say yes)] 
-Is speech recoding a ba d feature of reading?  Probably not, because a phonological representation 
may be needed for u nderstanding, for example to  hold info. in memory br iefly while we process a 
sentence. 
-Does phonological recoding-- "hearing" the sou nds of words as we read-- slow us down? Probably 
NOT, because we apparently can recode even when readin g at 12 words/s (in RSVP). 
     Petrick experiment:  
The boy's pockets were heavy with cha nge which jingled as he walked. 
CHAINS? (acoustic) COINS? (seman tic) ROPES (unrelated, but related to the ac oustic distractor)   
Positive probe CHANGE 
Results: people were slow er and made more errors  to both chains and coin s, after reading at 83 
ms/word (12 words/sec).
Scrambled sentences: more phonologic al confusions, fewer semantic.  
Is recoding to "sound" onl y true for alphabetic writ ing systems?  No ! it happens in reading Chinese 
and other logogr aphic systems. 
CONCLUSIONS: -acoustic/ phonological recoding as one reads is universa l,and happens FAST, so 
probably doesn't slow you down in reading. You just becom e more aware of the sound if reading is 
difficult or you are di stracted and not concent rating on the meaning.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>How do we manage to deal with th e 360 degree world, w hen we have such a tiny area of sharp 
vision? We move our eyes around, to fix briefly on regions that we want mo re detailed information 
about: peoples' face s, things that are mo ving, bright things, par ts of the visual fiel d that have lots of 
contours (such as corners) , and words as we read. 
Main characteristics of eye movements: 
2 kinds of eye movements: 
(1) saccade  (jump, ballistic movement):  jump from one spot to anot her, and make a FIXATION on 
each spot. This is the main way we pick up information. The eyes are attracted to poin ts in a scene 
with more information- -more "complexity." 
-the average eye fixation  lasts for 200-300 ms, and there is a 20-40 ms saccade or movement to the 
next spot, so THREE OR FO UR FIXATIONS PER SECOND. 
-can't see much while eye is moving (saccadic suppression) 
(2) pursuit movement : fix eye on a moving obj ect and follow it.  
c. Eye movements and visual acuity in reading: 
Methods for studying: 
(1) Eye tracking devices can determi ne when and to where the eyes go--and how long they stay on 
each spot. Our basic know ledge about reading comes from these studies. 
(2) Moving window (how small a window can be tolerated wi thout affecting reading?) 
(3) Mangled text at some di stance from fixation: fixati on is indicated by the *. 
xwekicnelkivn you are read*ing this text wlkedimgsmc 
-can see specific letter information fo r only 7-8 characters (l etters or spaces) to the right of fixation, 
less to the left, thoug h can get a little informat ion, including presence of a space, up to about 15 
character spaces to th e right of fixation.  
-Our eye movement pa ttern while reading is determi ned by number of characte rs, regardless of size 
of print or distance from  the page or CRT (unless ex tremely small or large). 
-We ordinarily fixate  each longish word at least once  
-If we don't directly look at a word , it is probably short and fairly predictable, like  some function words 
such as and, or, of. (About 2/3 of such word s may not be fixated.)  
-regressions (looking back) to an earlier point on 10-15% of saccades. 
-Reading rate: So, for most college students, their net reading rate is something like 5 or 6 words per 
second, or around 300 to 3 50 words per minute (although 250 wpm is common).  
d. Immediac y of processin g?</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Concepts and Prototypes (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/mar29h04/</lecture_pdf_url>
      <lectureno>14</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences 
Course Instructor: Professor Mary C. Potter 
9.65 March 29, 2004 
Concepts and Prototypes 
Handout 
Outline: 
I. Categorization: Why?  
II. How?
a. images 
b. classical view 
c. prototypes 
d. exemplars 
e. all of the above? 
III. Basic level categories of 
objects 
a. Theory 
b. Evidence
c. Basic level and typicality 
d. Conclusions 
First: write down an example that comes to mind, of each of these: 
a vegetable 
a prime number 
a precious stone  
also: draw a triangle 
(We'll get back to this later.) 
I. Categorization of 
experience: Why? 
Two terms: concept and category. I'll be using the term CONCEPT for a mental category 
that we use regularly to classify 
experiences, and CATEGORY or 
categorizing to refer to any 
classification or grouping of experiences or ideas. 
We need categories (and their associated mental concepts) in 
order to: 
-use past experience to make 
INFERENCES 
-STORE information efficiently</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>thing [lumped together in space-time? not-an-idea?] 
concrete object [mass? etc.]
manmade [might have been made with tools, deliberat ely chosen for some purpose or use...] 
device to tell time [tells time]
watch [wearable; most have strap to hold on wrist; shows minutes and hours, maybe seconds; 
made of metal; most adults in our societ y have one; range and typical price....] 
wristwatch [worn on wrist; not-a-lapel-watch; not-on-a-chain]
analog wristwatch [has hands to show ho ur, minutes, sometimes seconds; may tick]
.... [little further increase in attributes] 
Rosch hypothesized that the point at which ther e is a lot of information gain, as you moved 
down the hierarchy, would generally be the point at which you'd want to categorize. 
IN SUMMARY: 
Theory: While few categories of objects consist of physically identical members, there are some 
perceptual characteristics of objects, and some func tional properties of objects, that cluster in 
feature-space and invite categorization. 
Further, the "best" level at which to categorize--t he "Basic" level--is one at which the correlation 
of properties within the cluster is maximal,and the differences between objects in the cluster, 
and other objects, is maximal: maximally the same within, maximally different between 
clusters . 
b. Evidence : 
All the following measures correlate:   
(1) the point when there is the largest jump in feature information (when you ask subjects to list 
features true of that level of categorization) 
(2) the highest level in the hierarchy at which overlap of visual outline permits recognition 
(3) motions used in interacting with object are fa irly consistent for all objects at that level 
The convergence of all these measures on a single  level supports the basic claims of the theory 
that as you go down the hierarchy, you reach a point where the number of features common to 
the category jumps, with little addi tional gain at still lower levels. 
IF THERE IS A BASIC LEVEL, WHAT ARE IT S IMPLICATIONS FOR PROCESSING? Does the 
evidence support the predicted implications? 
Further evidence:</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>The basic level is used preferentially in categorizing: 
1. Naming: Adults name most objects at the basic level. 
2. First level perceived: it's the level used in initially recognizing a pattern. 
3. Develops first with age: 
a. Three-year olds can categorize  most accurately with basic level term. 
b. Older children sort preferentially by basic level. 
 c. Child uses that word earliest. 
4. Most important in language: 
ASL has single signs for basic level, but for superordinates may just list several basic level 
objects. 
Translations tend to exist for basic level names, more so than for other levels. 
c. Basic level and typicality:  Objects that are atypical of ba sic level objects tend to be named 
and identified at a subordinate leve l (Jolicoeur, Gluck &amp; Kosslyn '84):  
Reason: 
d. Conclusions: Basic level 
The concepts that we most readily use in thought are at some basic level. 
Just culture-specific, or universal?  
-Some of each. 
-For biological and natural objects, shared "naive" level.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>e. ALL OF THE ABOVE? Images, de finitions, prototypes, exemplars 
NOMINAL KINDS have sati sfactory definitions 
NATURAL KINDS: essences? 
ARTIFACT KINDS (manmade obje cts): designed functions? 
Prototypes and exemplars are both useful in classifying novel items and in thinking about 
categories of objects and events. 
Implicit theories . 
III. Basic level categories of objects 
a. Theory
 Our concepts are arranged in HIERARCHIES: e.g., THINGS (contrast with IDEAS), MANMADE 
ARTICLE, FURNITURE, CHAIR, DESK CHAIR, SWIVEL DESKCHAIR,... 
Such hierarchies are the basis for SEMANTIC NETWORKS, discussed in Reisberg Ch. 8 and in 
class.  
ECONOMY OF STORAGE  
PREFERRED LEVEL? 
ROSCH, Mervis, Gray, Johnson, &amp; Boyes-Br aem (1976): Basic level categories for 
objects . 
More theory : clusters  of features 
Example: self-winding ladies' analog wristwatch: most useful level of categorization? 
List attributes of objects at each level (e.g., wa tch) [in brackets are poss ible features true of 
everything at that level]</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>FURNITURE? Or, a GAME? 
c. PROTOTYPES: A way of  representing categories? 
FAMILY RESEMBLANCE structure  
GRADED MEMBERSHIP 
ROSCH and her colleagues: we represent categories  by [proto]typical exemplars, best examples 
or ideal examples (see Reisberg on Rosch). 
Typical or central instances 
EVIDENCE that typical instances play a ro le in the way we mentally represent 
categories: 
1. Sentence verification : "An X [item] is a member of category Y" 
2. Production. What first comes to mind. 
3. Picture identification : "Is this a member of category Y?"</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>b. CLASSICAL VIEW 
Definitions: necessary &amp; sufficient conditions 
bachelor 
prime number 
triangle
Can be used to make inferences: is this bachelor married?  
Usually good for combining into more complex ideas 
Some problems: 
decoy duck 
tall man 
mountain pass 
glue factory 
Specialized system or theo ry supports definitions:  
triangle ---&gt; geometry 
prime number ---&gt; mathematics 
cousin ---&gt; kinship system 
felony ---&gt; law
These kinds of categories are termed NOMINAL KINDS  
Problems for the classical view of categories : 
NATURAL KINDS (such as FI SH): no definitions  
ARTIFACT KINDS (manmade objects), such as SPOON: no definitions</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>4. Judgments about the typicality of exemplars , as in the Lab 2 list of possible pieces of 
furniture.  
5. Induction, reasoning . 
6. Tasks asking subjects to "think about" categories . 
Problems with the prototype theory: 
SUMMING UP PROTOTYPES IN CATEGORIZATION: We  use prototypicality (esp. visual/sensory) 
to help categorize new instances ra pidly, and we may instantiate more general  terms with 
specific (typical) instances when making inferences  , understanding language.  
"The fruit fell on the floor" 
By assuming that we're talking about typical members of a category, we'll usually be correct in 
our inferences--but that's not guaranteed. With a definition, inferences can be deductively valid.
d. The Exemplar Theory of concept representation : 
An alternative to the idea that we develop a representation of a typical member of a category, a 
prototype, is that we simply remember many or all of the individual experiences we've had with 
instances ("examples") of that category: e.g., all the dogs we've seen, read about, etc. To 
classify a new entity we retrieve memories of on e or more previous examplars that seem similar 
to the new entity--rather than comparing the new entity with a prototype or typical instance. 
(See text,beginning on p.279, for a full discussion of this alternative.) Note that the exemplar 
theory has most of the properties (and weakness es) of the prototype theory just discussed.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>-PUT TOGETHER information 
about a SINGLE OBJECT 
-think about RELATIONS between concepts 
SOME categorizations will have 
these useful co nsequences, and 
others will NOT. (Infinite 
number of ways to group objects.)  
We create categories of things that have relevant common properties: e.g., edible things. 
TO SUMMARIZE: Why do we categorize? To use past experience, to organize 
memories of experience in such 
a way as to reduce storage, 
and to think about relations 
between concepts. 
II. How do we mentally
represent concepts ? 
Four theories of mental representation of concepts: 
a. IMAGES
abstract ideas 
ambiguity 
conceptual combination 
negation 
In sum: Imagery plays a role in thinking and remembering, but we can dismiss the idea as a GENERAL theory of how co ncepts are represented.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Memory III: Implicit Memory (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/mar1h04/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>--------  ---------Word-completion tasks like: 
TAB__ (tabby, table). Or: 
 _SS_SS__ (assassin, assessed).  
Prior exposure to a possible completion (or, the only possible one) facilitated later completion, or 
biased toward a certain completion when many were available.  
-Similarly, a prior exposure to particular words makes them more likely to be produced in tasks 
such as producing exemplars of a category, or as  many words as possible beginning with C... 
-HM: (hippocampus removed bilaterally) 
Has good working memory, has old LT memories but can't fix or consolidate new information. 
BUT can pick up some new tasks!  Mirror tracing, rotary pursuit, recognizing mirror-reversed 
words (mirror-reading): all are pretty normal. This much was known about HM in late 60's, and 
thought to be limited to sensory-motor learning. 
But then it was discovered that he had preser ved repetition priming, word-stem completions, 
etc. And perhaps he was able to learn a complex cognitive task, the Tower of Hanoi. Furthermore, recent studies have shown that he can pick out the famous name from a pair of 
names--including names of people who became famo us after his surgery--and he can even give 
some correct reasons for what they are famous for. (He watches a lot of TV.) 
Alzheimers Disease patients (who have problems both in the hippocampus and in their temporal-
parietal lobes) learn new skills as amnesics do, but (unlike amnesics) they have impaired 
priming; whereas Huntington's disease patients  and Parkinson's disease patients, with damage 
to striatum, are impaired on skill learning but normal on priming. 
So: fact-learning, skill-learning, and "primi ng" (reactivation of existing structures) all seem to be distinct forms 
of memory. 
MEMORY 
DECLARATIVE NONDECLARATIVE 
(Explicit) (Implicit) 
Semantic Episodic 
facts events 
Medial temporal lobe,
 Diencephalon</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>-Skills 
Riding a bicycle or ironing a shirt, or speaking a language: normally, such learned skills take lots 
of practice. In using these skills, you are not aw are of having remembered  anything: there is no 
conscious retrieval process. The implicit memory just seems to be triggered when the 
appropriate cues are present.
 -Priming as implicit memory 
In priming, a recent experience activates nodes or neural structures that  make the same or a 
related process easier the next time. Semantic priming  : seeing "doctor" primes "nurse." 
Repetition priming : seeing a particular stimul us like a word, and then seeing it again: the first 
encounter can be shown to speed up the seco nd encounter, and make it more accurate. 
Jacoby &amp; Dallas (1981): compared implicit and explicit  memories for words, in a two-part 
experiment: 
Part 1: They had subjects look at a list of 60 words, answering questions such as,  
Does it contain the letter A? Does it rhyme with "bad"? Is it an animal? 
Part 2: Subjects were divided randomly into 2 groups. One group was given a list of 120 words 
(the 60 they had looked at in Part 1 and 60 new ones)  and told to say whether they recognized 
them from Part 1: that is,they had to decide whether each word was old or new. 
The other group was given a perceptual test, in which each word was presented for 35 ms, 
followed by a row of ampersands &amp;&amp;&amp;&amp;&amp;&amp;&amp; that served as a visual mask, making it hard to see 
the word. Subjects had to say what the word was. New words that hadn't been in Part 1 were 
mixed with words that had been in Part 1. The big question was what the effect of the 3 tasks in 
Part 1 would be, on each of the two Part 2 tests. 
Results:
 Part 1 task
 Phys. Rhyme Semantic New words
 -------------------------------------
Recognition | .50 .63 .87 False yes, .15 |
             |--------------------------------------| 
Perceptual | .80 .81 .82 .65 |
threshold -------------------------------------
The questions in Part 1 were graded in the depth of processing they invoked. When the task was 
to decide whether or not the word had been seen in Part 1, the best task was the semantic 
decision: is that an animal? (for example).</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>For explicit recognition, the "orienting task" ma de a large difference. But for implicit, perceptual 
"memory", although the benefit from having been presented in Part 1 was considerable 
(improvement of ~ 15%), it was notinfluenced by the type of TASK in Part 1. 
Implicit memories are not just memories too we ak to become explicit (conscious): they are 
qualitatively different from ex plicit, declarative memories. 
Perceptual tests don't show any benefit unless the original item is shown again in the same 
format--a spoken word doesn't help perception of that word in written form. Note that Reisberg 
points out that having completed_L_P_A_T won't help you later complete E_E_H_N_. 
However, a spoken word can be RECOGNIZED again in written form. Also, the perceptual effect 
seems to decay less rapidly than the ability to recognize an item as seen before in the 
experiment. 
There is often little correlation between th e words a given subject can perceive (on the 
perceptual test) and the ones that s/he can recognize, on a recognition test. 
However, the repetition effect is n't restricted to perceptual tasks. Jacoby &amp; Witherspoon 
(1982): 
Part 1: (Spoken questions by the experimenter:) "Name a musical instrument that employs a reed." (Etc.) 
Part 2: write spoken words to dictation: read/re ed. Results: more likely to write r-e-e-d than a 
control group. 
But did subjects simply remember that they'd heard that word-meaning before? No: because the 
experimenters found the same results for a group of amnesic patients--who could not explicitly 
remember the words from Part 1. 
2. Amnesia and the neuropsychology of memory : 
The amnesic syndrome is produced by lesions in the medial temporal and diencephalic parts of the brain, including the hippocampus. General in tellectual functions, including language, are 
normal--and so, more or less, is memory of ev ents before the lesion. But there is impairment, 
sometimes almost total,in the ability to retain new information--that is, when the new information is explicit, declarative information, like "Who is the vice president?" 
Anterograde amnesia : inability to remember new information. Versus retrograde amnesia : 
forgetting of information you knew before the lesion or damage to the brain. 
Damage from strokes or injuries...or alcohol, without proper vitamins, produces individuals with 
Korsakoff's syndrome: used to be a lot of the latter, before people knew how to prevent the 
syndrome. 
But it turns out that such amnesics don't lose ALL capacity to learn new material, as used to be 
thought: such patients may have a relatively intact ability to acquire new skills and new 
information, if that memory is tapped by IMPLICIT memory tests. 
-Jacoby and Witherspoon's REED finding (above). The amnesic subjects didn't remember Part 1 
explicitly, but showed as much biasing effect as did the normal subjects.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences
Course Instructor: Professor Mary C. Potter
9.65 March 1, 2004 MEMORY III: Ex plicit and implicit memory and the brain
 HANDOUT. 
Note: Chapter 6 begins with several topics that won't be discussed in 
today's lecture, but you should read about, including: 
-state-dependent learning 
-encoding specificity 
-source memory versus familiarity  as the basis for remembering 
-how familiarity without source memory can generate some phenomena such as "how to become 
famous overnight" (p.178), false belief in the truth of statements, sy stematic mistakes in 
identification of a criminal. 
-the hypothesis that a feeling of familiarity results not only from 
actual previous experience (which make s a repetition easy to process) but 
sometimes simply because something is unexpectedly easy to process 
(processing fluency) one judges that  the word or stimulus must be 
familiar (other examples in text). 
OUTLINE for lecture: 
1. Implicit versus explicit memory 
2. Amnesia and the neuropsychology of memory 
-The brain and memory: H.M. 
 -Preserved implicit memory 
1. Implicit and Explicit Memory:
Explicit (declarative) memory: 
The term "declarative memory" has been used for this kind of memory, because you can talk 
about what you remember: you can declare it.
 a. Episodic memory: memory of your perso nal history, of  when and where you encountered 
someone, learned that there is no Santa Claus, etc. 
b. Semantic memory: your general knowledge, including word meanings, knowledge of 
science, history, facts about your self and others that are not spec ific memories of a particular 
experience. 
Implicit memory:
 Implicit or "procedural" memory: no conscious retrieval,little or no ability to describe or 
become conscious of what you know. There are various forms of nondeclarative memory, not 
just a single "implicit memory system". For example:</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Skills Priming Simple Nonassociative
 &amp; Habits &amp; Percept. Classical Learning
Learning Conditioning
 Emotional Skeletal 
Responses Responses 
striatum neocortex 
amgdala cerebellum reflex 
pathways 
(From Squire &amp; Zola, 1996.)</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Memory I: Working Memory (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/feb23h04/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>-articulatory suppression (la-la-la) eliminates the confusable-sounds and long-words effect for 
written words (while reducing memory span): it  seems that articulatory  suppression prevents 
written words from using the articulatory loop, so they have to be remembered in other ways 
(other parts of the memory system). 
-BUT: if written words have to use the articulatory loop to get into the phonological store, how 
come you can judge whether words rhyme even when you are articulating something else? 
(unresolved aspect of the theory) 
What might the Articulatory Loop be good for? 
-learning a new language 
-telephone dialing 
-any task like mental arithmetic in which you have to keep track of verbalizable information 
-but NOT necessary for most language understanding: people with an impaired "loop" due to brain injury have very short memory spans for unrelated material but are only minimally 
impaired in understanding speech and have normal long-term memories. 
b. The Visuo-Spatial Sketchpad: 
The imagery system that we will discuss in detail later. Patient ELD (right hemisphere lesion).</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>iii. Central Executive: everything else 
a. The Articulatory Loop Model:
 Spoken
Words irrelevant 
speech
 Phonological
Store 
(judge rhyme)
"couch-touch" 
Articulatory
Loop "la-la-la" 
Written
 Words 
Evidence for the model: 
-phonological similarity in the phonological  store creates confusions and memory loss 
-word length effect: memory span shorter for longer words 
-unattended auditory material (especially speec h) interferes with the phonological store</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Chunks can be created on the fly:  as items are coming into STM.  E.g., a subject at CMU who 
was trained until he could remember  as many as 81 digits, dictat ed to him at 1 per second (see 
text p. 141 for how he did it). 
ST Memory holds pointers to informat ion in LTM: chunks or nodes in LTM. 
b. Transferring information from STM to LTM: 
Rehearsal theory : the longer information is active in WM , the greater the probability that it has 
been stored in LTM.  
Evidence:
-Serial position curve: primacy and recency 
 -Direct evidence for the rehearsal theory: Rundus.  
2. Problems with the standard model 
a. Rehearsal can be useless for LTM:  sheer time in WM not enough 
-Craik &amp; Watkins '73 experiment(pp. 148-149) 
b.Depth/elaboration of processing  (Craik &amp; Lockhart) 
Other problems with the standard memory model included evidence that there are multiple 
forms of short-term memory, leading to the mo re general concept of "working memory" as a 
collection of short-lasting forms of information. 
3. Baddeley's Working Memory Mode l (discussed in Ch. 1 and 5) 
Multiple forms of short-term memory: 
i. acoustic-phonological: see Articulatory Loop 
ii. imagistic/spatial: Th e Visuospatial Sketchpad</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences 
Course Instructor: Professor Mary C. Potter 
9.65 February 23, 2004 MEMORY I: Working Memory  HANDOUT  Reisberg, Ch. 5 
Architecture of Memory 
1. Standard model 
a. Limited capacity 
b. Transferring information from ST M to LTM: Rehearsal theory of memory 
2. Problems with the standard model 
a. Rehearsal theory wrong 
b. Depth of processing 
3. Baddeley's Working Memory Model 
a. Articulatory loop model 
b. Visuo-Spatial Sketchpad 
1. Standard Memory Model: 
S 
t --&gt; Sensory Storage Response 
i --&gt; LTM Short-term 
m --&gt; Registers Memory 
u _______________________\ Selective Forgetting
/ Attention 
s 
1. Iconic memory and other sensor y memories--e.g., echoic. Very br ief, close to perception itself 
in being very complete. 
2. Long-term memory: Sensory information "passes through," to be identified. Doesn't result in 
new LTM, but passes to STM, where processing can result in new LTM. Information can be 
recognized fast when first encounter ed, but then is often forgotten. 
3. Called STM, Working Memory, primary me mory...terms used interchangeably by me. 
a. Limited capacity of STM:
Unit of capacity in short-term memory: Chunk 
George MILLER found that the amount you can remember of new material coming in is 
measured in units he called "chunks": we can re member about 7 +/- 2 such chunks in short-
term memory. A chunk is a unita ry concept you have already ac quired: like a word, or (with 
unrelated letters) a letter, or any unit you alread y have encoded.  So what constitutes a chunk 
varies with your experience: case of chess (pp. 464, 466 have more about chess).</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Mental Codes I (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/apr12_14h04/</lecture_pdf_url>
      <lectureno>18</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>b. Probing a scene with line drawings  versus words: Potter &amp; Elliot. 
c. Size, value judgments: 
d. Bilinguals and the mental lexicon: Potter, So, Von Eckardt, &amp; 
Feldman (1984). 
e. Brain imaging study: 
Vandenberghe, R. Price, C., Wise, R., Josephs, O., &amp; Frackowiak, R.S. 
J. (1996). Functional anatomy of a common semantic system for 
words and pictures. Nature , 383, 254-256. PLUS Commentary by A. 
Caramazza, "Pictures, words and the brain" in the same issue, pp. 
216-217. (NOTE: you don't have  to read this article!) 
IV. Conclusions: Mental codes
1. Most of our general knowledge is represented in an abstract 
(conceptual) form, not tied to a particular sense or a particular 
(natural) language.  We use this conceptual system in looking around, thinking, conversing.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Problems: 
-simple associations don't have the power to account for our ability to 
use language 
-is a more abstract code needed? 
     -something for a natural lang uage to be mapped onto. Why do we 
need that? 
a. Natural language is ambiguous , but thoughts are NOT 
(although they may be vague)  
b. Natural language permits synonymy : but thoughts don't  
c. Second language  
d. Children and other animals 
There seems to need to be an ab stract representational system:  
(a) natural language has to map on to something, to account for the 
AMBIGUITY of language but the una mbiguity of thought--to account 
for SYNONYMY--and to allow DIFFERENT LANGUAGES to map onto one 
thought system--and to have a medium  in which to form the thoughts 
which you then express (although this isn't by itself compelling, 
because there has to be SOME initial rep. system, or you'd have an 
infinite regress). 
(b) CHILDREN and ANIMALS can ev idently think without knowing 
language. 
These are logical arguments, not em pirical demonstrations, and many 
consider that there may be some clever way to get word-nodes to do 
the necessary mental work, as in Paivio's dual-coding theory.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences 
Course Instructor: Professor Mary C. Potter 
9.65 April 12-14, 2004 HANDOUT 
Mental Codes: Pictures, Words, and Thoughts 
Outline: 
I. Theories about codes: 
A. dual coding theory 
B. conceptual coding 
II. A test: naming and categorizing pictures and words  
III. Some further issues and experiments 
IV. Conclusions 
I. Theories about codes.
What are the roles of different ment al codes in though t, and how many 
such codes are there? Earlier, we talked about concepts and how they 
are represented: images, definiti ons (necessary and sufficient 
conditions), prototypes, exemplars. Last week, I talked about mental 
imagery as a possible mental code, an d some findings that link vision 
and visual imagery in the brain. Today and Wednesday, two theories 
about the nature and architectu re of mental codes, and how 
experimental evidence can distinguish between them. 
A. Dual coding theory . PAIVIO: two codes in thinking: IMAGERY 
(visualization), and LANGUAGE (the VERBAL CODE). (Note discussion 
of Paivio's ideas in Reisberg, pp. 362-365, which you've already read.) 
 ______________    _______________ 
| | | | 
| VERBAL   |---------------&gt;|    IMAGE | 
| | | | 
|  SYSTEM   |&lt;--------------|    SYSTEM  | 
|______________|  |______________| 
Verbal code:
 1. based on associations  formed between wo rds via reading, 
talking, listening. So, is especially effective for representing temporal 
or spatial sequences : serial information. 
2. can represent abstractions</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>2. Special-purpose memories of su rface form: E.g., imagery is like 
perception. 
3. The surface  representations are what we are introspectively aware 
of. "Blackboard" or "playb ack" device in thought?</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>B. Conceptual coding theory : Potter &amp; Faulconer, 1975; Potter, 
1979. 
 ______________  
| |
| |
|  LEXICON   | 
| | 
|_____________|  
  _______________ 
| | 
|  IMAGE  | 
|  | 
| STORE | 
|______________| 
  _____________ 
| | 
| CONCEPT  | 
| | 
|  SYSTEM  | 
 |____________ |
The third code represents IDEAS (CONCEPTS) without necessarily 
clothing them in WORDS or IMAGES : the Language of Thought (Fodor) 
or mentalese (Fodor, Bever, &amp; Garr ett): it represents concepts or 
ideas. 
Explaining the data: 
(1) NAMING pictures and words  
(2) Memory advantage for pictures /imaging/concrete (not abstract) 
words 
(3) Hemispheric specialization</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>II. A test: Naming and cate gorizing pictures and words. 
Predictions from the two models: 
DEMONSTRATION: Naming versus categorizing pictures and words.
RESULTS
DEMO: Name the category of a picture, word. 
Possible problems with these experiments and the argument:  
III. Further issues and experiments. 
a. How to get an advantage for words rather than pictures: 
Sentence plus picture or word probe: Potter, Valian, &amp; Faulconer 
(1987).</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Imagery code:
 1. Sensory experiences 
2. Concrete, IMAGEABLE objects and events 
-Dual coding for concrete objects  
-associative link between image and name 
How to test? 
-written words and pictures of obje cts: hypothesized that a word 
enters the verbal system directly, a picture enters the imagery system 
directly and the verbal system only indirectly, by the name-association 
link. 
Evidence: 
(1) Takes longer to NAME a picture than to name (aloud) a written 
word (old finding) 
(2) In long-term memory, pictures  are recalled better than words. 
 (TWO CODES). IMAGING helps recall of words--but only for concrete 
words that HAVE images. So, conc rete words are remembered better 
than abstract words. 
(3) Model is consistent with know n hemispheric specialization: the L 
hemisphere is specialized for language, the R hemisphere for 
perceiving visual patterns such as faces.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>________  ________  BOTH MODELS CAN EXPLAIN THE RESULTS 
DUAL CODING MODEL
 fork fork 
| | 
| | | | 
| | | | 
________ ________ 
| Verbal |------&gt;| Image | | FORK |------&gt;| Image | 
| System |&lt;------| System | | UTENSIL|&lt;------| System | 
|________| |________| |________| |________| 
| |
 | Category 
|             Match    
"fork"  |
         "yes" or "no" 
CONCEPTUAL CODING MODEL
 fork 
| 
| | 
| | 
________ ________ 
| | | Image  | 
| Lexicon |  | Stor e  | 
|________| |________|
 | \ \  / / 
| \__\ __/__/ 
| | Concept |                    
| | System  | 
| |________|
 | | 
| Category 
|    Match                    
| | 
| "yes" or  "no"               
"fork" fork 
|
 |  | 
|  | 
________ ________ 
| | |  Image | 
|Lexicon |  |  Store | 
     |_______|       |________| 
|  \ \ /  / 
|  \__\___/__/ 
|  | Concept | 
| | System  | 
| |________| 
| |
 | Catego ry             
|  Match 
| | 
|  "yes" or "no" 
"fork"</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Memory II: Conceptual Short Term Memory (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/feb25h04/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>Before: 
basket 
Maggie wrote the letter with a ****** she had with her.
 pencil 
Maggie carried the kitten in a basket/pencil to her house. 
After: 
Maggie used a basket/pencil to write the letter.
 Maggie used a basket/pencil to carry the kitten. 
Results: 
Often, the other  (irrelevant) word can't be remembered,  right after recal ling the sentence. 
Evidently it was momentarily available and then got lost: conceptual very short-term memory. 
Conclusions: Doubleword experiments 
-Readers readily select the relevant word, ev en when the biasing context appears after the 
doublewords: indicating that both words are processed and remain available briefly. 
-The irrelevant word is apt to be forgotten. 
-These results are consistent with the claim (e.g ., Swinney, 1979) that multiple meanings of 
ambiguous words are briefly activated (with or without awareness), one meaning that fits the 
context is selected, and other meanings are forgotten. 
E.g., He walked up the steep grade...
  He got a good grade.... 
-Some form of short-term memory that includes conceptual information  about the word 
candidates is needed to account for selection, especially given that selection can be based on 
information coming as much as a second later th an the word (see the "double word" results). We 
call this form of memory CSTM (conceptual short-term memory).</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>-----------------------------------------------------CSTM Hypothesis: Claims 
-Meaningful stimuli such as words and scenes rapidly but briefly acti vate rich conceptual 
representations of stimuli such as words and scenes. 
-These fleeting representations do not show up wi th many of the standard  methods for studying 
and testing short-term memory such as the memory span 
-Nonetheless, these fleeting representations are f undamental to cognitive processing and to the 
form that long-term memory takes, because they enable the almost instantaneous discovery of 
meaningful structure in the material--such as the meaning of a sentence or the gist of a picture. 
What kinds of evidence are there for this hypothesis? 
Evidence for rapid activation of concep tual/semantic information 
-SEMANTIC PRIMING in Lexical Decision, etc. 
-EYE-TRACKER STUDIES OF READING 
-TARGET SEARCH IN SCENES 
Evidence for rapid forgetting of most unstructured material : 
Method: Rapid Serial Visual Presentation (RSVP) . To dissociate STM and CSTM, need very 
rapid presentation.  
PICTURE SEQUENCES: Search versus Memory 
-We can comprehend information comi ng in very rapidly, but we fo rget most of it. For example: 
when you look at a series of photographs pres ented at a rate of 3 to 9 a second, you can 
remember--recognize--very few afterward. 
But if told to look for a particular kind of scene, such as "a picnic" or "a baseball game" you can 
easily enough pick it out, suggesting that we can understand each picture momentarily. 
WORD LISTS</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences
Course Instructor: Professor Mary C. Potter
9.65 February 25, 2004 MEMORY II: Concep tual Short Term Memory (CSTM) HANDOUT 
A central problem with both the Standard Memory Model and Baddeley's theory of working 
memory is the neglect of long-term memory activation during processing. 
Very short-term conceptual memory : Processing on the fly 
What we retain in long-term memory depends on what gets linked up during encoding. Coding in terms of MEANING (what you already know) pr ovides many RETRIEVAL ROUTES. Therefore, 
rapid activation of relevant inform ation isessential, during encoding. 
Proposal: There is another form of short-term me mory in which lots of material from long-term 
memory is very briefly activated, enabling us to understand what's happening and to make links with our existing knowledge that result in longer-term memory.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Another example of the rapid use of sentence co ntext when reading in RSVP was given in the 
lecture on object recognition, when discussing word perception in context:  "The boy rode the 
house  around the pasture," etc. 
CONCLUSIONS 
There is a cognitively important stage of proc essing that occurs well before "short-term 
memory" (of the Baddeley articulatory loop type) an d that has associated with it a fleeting form 
of memory: conceptual  short-term memory (CSTM). 
Conventional STM, in contrast, is a largely separate system, a buffer that can maintain 
phonological representations (see Baddeley, 1986). 
CSTM is the basis for LTM. Material that becomes conceptually well-structured as it is processed 
in CSTM is likely to persist at least briefly in LTM, permitting (for exam ple) regeneration of an 
RSVP sentence in immediate recall.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Something similar happens with rapid sequences of words EVEN WHEN THE NUMBER OF WORDS 
IS WITHIN THE MEMORY SPAN. You can remember less than 3 words,on average, when short 
list are presented at a rate of 12/s. 
RSVP SENTENCES 
BUT: if the string of words forms a meaningful se ntence, then it is easy to remember even a 14
word (or longer) sentence, at 12 words a second.  
The difference is that when the material can be organized into a coherent structure, we can both 
process and remember it even at a high rate: when otherwise we would remember no more 
than 2.6 unrelated words. 
This and other evidence suggests that a lot more information is transiently available than we can 
reflect on (by the time we reflect, some of it is  lost)--like iconic memory, it seems to be there for 
only a few hundred ms. 
While the information is active, structures that literally "make sense" can be built and have a chance to survive long enough to be reflected on and to be remembered for at least a short time.  
How ARE sentences remembered? And why is immediate memor y for a sentence 
usually verbatim? 
Demo (Potter &amp; Lombardi, 1990) 
Why is recall of sentences usually  verbatim, or very close to it? 
-Not the Phonological Loop: concurrent articulation has no effect 
-Regeneration from meaning (with lexical priming) 
-Evidence: lexical intrusions 
Processing on the fly: selecting a word in a sentence 
Method: Show someone a sentence using RSVP, and at some point present two words simultaneously: but only one fits into the sent ence context. Even when reading at 8 words a 
second, the correct one of the two can be selected. Note that the relevant context sometimes followed  the doublewords.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Language: Psycholinguistics (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/mar31h04/</lecture_pdf_url>
      <lectureno>15</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>[the (dog)] [will] [chase  (that gray {cat})]  
Three components of a PS grammar: 
1. Constituent symbols: 
S sentence 
det determiner (article)  the, a, ... 
A adjective gray, small... 
N noun dog, cat... 
AUX auxiliary verb: will, do.... 
V verb chase, bite.... 
NP noun phrase e.g., det + N, det + A + N 
VP verb phrase e.g., V + NP, V + S 
PP prepositional phrase e.g., P + NP 
adverbs, etc. 
2. Phrase structure rules: 
"Rewrite" rules such as S --&gt; NP + AUX + VP 
NP --&gt; (Det) + N 
NP--&gt; NP + PP 
VP --&gt; V + S 
3. Set of terminal elements: 
Usually words--terminal in that they can't be rewritten further.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>(2) How can the set of rules represen t relations among the words WITHIN A 
SENTENCE? 
John is eager to please 
John is easy to please 
(3) How can the set of rules repr esent relations between sentences: 
John kissed Mary Mary was kissed by John 
Did John kiss Mary? 
     Who did John kiss?
 etc. 
(4) What makes some sentences AMBIGUOUS? 
They are flying planes 
     Visiting relatives can be boring 
(5) How can language be infinitely productive, yet follow rules?
(6) How can language be learned?
3. Theories of grammar: A brief evolutionary history 
(a) PHRASE STRUCTURE GRAMMAR 
Not left-to-right, but hierarchical, with a constituent analysis:</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>(b) TRANSFORMATIONAL GRAMMAR (Transformations are now called "movement 
rules") 
Distinction between Deep Structure (d-structure) and Surface Structure (s-structure)  
The dog chased the cat 
Deep: [(Art1 + N1) + (V + {Art2 + N2})] 
Who chased the cat? 
Rule: change above to [(Who) + (V + {Art2 + N2})] Did the dog chase the cat? 
Rule: Move AUX to front 
Transformations can rearrange (move) const ituents: by substitution, by displacement, by 
permutation. 
Can explain the ambiguity of th e visiting-relatives example:  
Also: difference between: John is eager to please</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Constraint: can't topica lize only part of a coor dinate structure:  
Mary, Joe went out with. 
Mary and Sue, Joe went out with. 
*Sue, Joe went out with Mary and. 
In general, coordinate structures have to  stick together and be made upof the same
category: 
John wrote a letter and a postcard 
John wrote to Mary and to Fred 
*John wrote a letter and to Fred 
Another example: 
John walked and Mary ran up the hill 
*John rang and Harry picked up Mary's sister.   
(c) OTHER DEVELOPMENTS in linguistic theory: 
Thematic (theta) roles: semantic roles that NP  subjects and (direct) objects have to fulfill, 
for a given verb. E.g., agent, object [or "pat ient" and "theme"], location, temporal info, 
instrument. 
4. Psycholinguistics: How we parse a sentence 
Parsing strategies: 
Do we actually recover the structure of  a sentence in order to understand it?
The man bit the dog</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>John is easy to please 
Traces: 
In transformational grammar, when part s of a sentence are moved around,as when 
forming a question, an inaudible, invisible "trace" may be left behind in the original 
position of the moved constituent. But what's the evidence for this "trace"?  
I wanna go home! 
But: 
*The student you wanna solve the problem just came in. 
(The asterisk, *, is a conventiona l symbol for Not Grammatical.) 
Another pair of sentences: Only one permits "wanna." 
Who do you want to go instead of you?
Who do you want to go with to the party?
Constraints on transformations 
E.g., topicalization. "The br ain, I'm fascinated by."</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences 
Course Instructor: Professor Mary C. Potter 
9.65 March 31, 2004: Language: Psycholinguistics HANDOUT 
1. Introduction 
2. What a theory of lang uage needs to explain  
3. Theories of grammar: 
a. phrase structure grammar 
b. transformational grammar  
c. others 
4. Psycholinguistics: How we parse a sentence 
1. Introduction 
Our knowledge of language can be divided in to several semi-independent topics, the 
chief of which are PHONOLOGY (roughly, the study of the rules gove rning the sounds 
and sound-sequences of the language); MORPHOLOGY--rules governing the formation 
of words and affixes to words; SYNTAX--t he structural arrangements of words in 
sentences; and SEMANTICS--the meanings conveyed by sentences.  
SYNTAX today. 
CLASSIC EXAMPLES--CHOMSKY 
Colorless green ideas sleep furiously 
Large fierce dog sleep lightly. 
Universal Grammar or UG 
2. What does a theory of language need to explain? 
(1) What makes a string of words GRAMMATICAL</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>a. is preferred because the with.. phrase is a ttached to an existing node for the whole VP. 
But, try this version of the sentence: 
The spy saw the cop with the revolver. 
Pragmatically, the more complicated "b" is required--but in fact readers momentarily 
hesitate when they arrive at "revolver, " suggesting a minimal attachment strategy. 
(Rayner, Carlson, &amp; Frazier, 1983)</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>The scouts the Indians saw killed a buffalo. 
Decide: Were both these words in the sentence?
Indians, killed 
Or: 
scouts, killed 
Possible parsing strategies: 
I scream/ice cream
HEURISTICS or STRATEGIES 
1. Word or constituent order strategies: 
a. In a N V N sentence, assume the first N is  the agent of the V a nd the second N is the 
object. 
b. Clause order: Assume first of two clauses is the main clause. 
c. If you have a function word, begin a const ituent (the, a: begin NP);(preposition, begin 
PP) 
d. When you find a relative pronoun (that, wh ich, who...) begin a new clause. (If the 
relative pronoun is omitted, which it often can  be, then processing does tend to be 
harder.) 
2. Semantic strategies: 
a. After you have the verb, look for the numbe r and kind of "arguments"or theta roles the 
verb takes:</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>3. Interpretive strategies: 
e.g., When you get a definite noun phrase ("th e book," rather than "a book"), search 
memory for the referent a nd replace with that entity. 
4. Frazier and Fodor's hypot hesis that listeners use the MINIMUM ATTACHMENT 
STRATEGY (see text): 
     a.The spy (watched {the cop}{with the binoculars}) 
     b.The spy (watched [{the cop}{with the binoculars}])</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>This constitutes a "generative" grammar because the rules must be able to generate any 
and all valid (grammatical) sentences in the language, and no invalid sentences. 
Explains: 
-What makes a sentence grammatical 
-relations among words in a sentence: who did what to whom 
-accounts for SOME ambiguity: 
[(they) (are eating{apples})] 
[(they) (are {eating apples})] 
-explains productivity (recursive) 
-explains discontinuous speech errors 
-MAY help explain how language can be acquired 
DOES NOT explain: 
-some ambiguities 
[(visiting relatives) {(can be) boring}] 
-relations between sentences: declar ative, question, negation, passive... 
-difference between sentences like "John is easy to please" and "John is  eager to please".</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Lab 2: Images, Concepts, Language (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/mar17h04/</lecture_pdf_url>
      <lectureno>13</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>Claim of the Type-Token hypothesis is that when  there are actually two distinct tokens of 
the same word type (ink...ink), and they occur close in time/space, then the brain fails to 
set up a second token, but instead assumes th at the second occurrence is just more 
evidence for the first occurrence. There's a refractory period for setting up the second 
token, but NOT a refractory period for proces sing the type information in the second 
token: it just gets added to  that of the first token.  
But: some questions: 
-what KINDS of types?
     -Written words?  
-so: just letters? 
The two stimuli seem to have to have substantial overlap. 
-what about OTHER stimuli?
     -Bavelier's work</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>-numbers: three 3 
-homophones: I/eye; eight/ate; seas/seize. 
-what about pictured objects: RB? 
To conclude: RB represents either a limitation or a design feature of the visual/word-
name representation system: you don't readily encode the same thing or highly similar 
things (at some level) twi ce within a short time period.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences 
Course Instructor: Professor Mary C. Potter 
9.65 March 17, 2004 Repetition Blindness HANDOUT 
Types, Tokens, and Repetition Blindness (RB) 
a. Types versus tokens in associatio n networks [see text, pp. 254-55, and Fig. 8.11]: 
b. Repetition blindness: Happens when you pres ent a sequence of words at a relatively 
easy-to-read rate such as 10/ s, in RSVP, and one of the words appears twice in the 
sequence (but never immediately follows it self) the second word tends to disappear 
(Kanwisher, 1987). 
When Nancy spilled the ink (li quid) there was ink all over. 
Why? 
-physical merging? 
-sensitive to timing? 
-refractory period for seeing the same thing? 
c. The type-token model of RB: Types: kinds  of things vs. Tokens: event markers, 
episodic representations.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Attention I (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/feb11h04/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>a. Filter theory of  selective attention 
Broadbent's (1958) filter theory: 
-Initial sensory representation: the S-store  or sensory store.  
-Attention imposes a "physica l" filter on selection from S-store information  
-The filtered information from the S-store is passed to the P-store (perceptual store, 
which is more stable)...infor mation decays rapidly from the S-store. Ke y experiment: 
Problems with the Broa dbent filter model:
Gray &amp; Wedderburn '60 also used 2 sets  of 3 words or syllables, e.g.:  
and Ss were able to follow "sense," as sh own by the order in wh ich they wrote down 
the words or syllables. 
Similarly, Treisman (1960)  (dichotic) found that subjects would sometimes 
spontaneously follow meaningf ul text to the other ear. (The task was to SHADOW 
[speak aloud right after hear ing it] the ear that  started out with the meaningful 
message). Both results conf lict with filter theory. 
MORAY and your name.  
Triesman's attenuation theory : Attention attenuates  ignored channel. 
b. Late selection theories of attention 
All (or a lot) of the in formation gets processed to a fair ly high level, before selection 
takes place.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Shiffrin &amp; Schneider (1977): the effect of practice on select ive attention. (See Reisberg 
chapter.) 
The target set was 1-4 le tters, and it was either consistent --same throughout the 
experiment--or varied on each trial. 
Automatic versus co ntrolled attention.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences
Course Instructor: Professor Mary C. Potter
9.65 February 11, 2004 Attention I.  HANDOUT 
1. Attention: What is it? Iconic  memory and attentional selection 
2. Theories of attention: 
a) Filter theories (early selection) 
b) Late selection theories 
c) Flexible selection 
3. Automatic vs. Controlled  attention: Stroop demo.
1. Attention: What is it?
Two senses: 
(1) alertness or arousal, awakeness 
(2) selective attention: wh at we'll talk about here  
Iconic Memory: The partial report technique 
The method for studying  this form of visual  memory illustrates the effects of selective 
attention. 
The experiment: Sperling, 1960: 
Two possibilities: 
(1) when you try to report all, you get conf used as you report (output 
interference) 
(2) you "know" abou t all 12 letters (or, at least 9 of them), but the memory 
holding all that inform ation decays rapidly--nothing to do with "output  interference" 
How to distinguish? De lay the tone signalling the row: if (1), still get 3 in the row; if 
(2), you'll lose info rmation with delay. 
Delay of tone: Results:</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Visual factors (dark versus  bright) are involved in  the very brief memory: 
These and other results suggested that ther e is a form of visual "persistence"-- iconic 
memory : a very short form of me mory that can be processed selectively, showing 
that attention can be deployed rapidly.  
Attentional selection is a gateway to further processing and memory.  But what 
determines what you attend to? 
Involuntary selective attention : 
Voluntary selective attention : DEMO    
WHY do we need to attend selectively? 
2. Theories of attention
HOW do we attend selectively?  Cherry (1953: MIT in RL E: Research Lab. of 
Electronics): "the cocktail party problem." Presented 2 messages on he adphones and 
instructed subjects to shadow  one of the messages [that is, say the words as they 
were heard]. That is, listeners were to  pay attention to one of the messages. Binaural 
(both messages to both heads) harder than dichotic  (one to each ear). 
-Easier to select if there' s a PHYSICAL (SENSORY) differ ence between two channels 
-SPATIAL LOCATION 
-Little information about NONATTENDED stimuli seems to be processed.  These findings led to the first theory of selective attention:</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>How complete is the proc essing of an unattend ed message? Semantic 
processing of unattended material? More evidence 
Lackner &amp; Garrett (1972): Ambiguous sentence attended in one ear. 
Corteen &amp; Wood ( 1972): Experiment in which subjects  were first given mild shocks 
whenever certain words--city names--were presented in a lo ng ist.  This set up a 
conditioned autonomic response , the galvanic skin response  or GSR, which measures 
changes in the resistance of th e skin with sweating. After tr aining, just seeing the city 
name increased GSR.  
Then Ss SHADOWED prose in one ear and heard a list of wo rds in the other. The list 
included the city names plus new city name s, and neutral words.  Measured  GSR. 
So: Some unattended informat ion seems to be processed at a rather high level. 
c. Flexible selection : 
The earlier the stage of proce ssing at which selection is po ssible, the faster and more 
efficient the response to th e attended channel, and the less is processed on the 
unattended channel. 
3. Automatic versus Controlled Attention 
Stroop Effect: Name the color of ink that the wo rds are written in. DEMO. 
Control cond itions:  
name colored words, na me uncolored words, name colored squares  
Why the effect?</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Attention II (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/feb17h04/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>4. The Attentional Blink (AB) 
Searching for two targets in rapid serial visual presen tation (RSVP): e.g., two letters 
among a string of digits, presented at 100 ms/item. 
Model: Chun &amp; Potter  (1995): Two stages  of processing:  
Luck, Vogel, &amp; Shapiro study: 
5. The Theory of Signal Detection : 
One important landmark in the understanding of the inferential, bet-placing character 
of perception was the Theory  of Signal Detection, some times known as TSD. This 
theory emerged from psychophysical studies of the ability to detect a faint tone or 
light. 
Absolute threshold ? 
False alarms 
The theory of signal detection [TSD] 
Criterion</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences
Course Instructor: Professor Mary C. Potter
9.65 Feb. 17, 2004 At tention II.  HANDOUT  
Assigned reading: Luck, S. J., Vogel, E. K., &amp; Shapiro, K. L. (1996, 
October 17). Word meanings can be accessed but not reported 
during the attentional  blink. Nature, 383 , 616-618. 
REMINDER: Lab I here  on Wednesday. 
1. Visual attention: Treisman &amp; Gelade's theory 
a. Feature integration theory 
b. Visual search 
c. Illusory conjunctions 
2. Lateral neglect: Involuntary selective attention 
3. The Psychological Re fractory Period (PRP) 
4. The Attentional Blink (AB) 
5. The Theory of Signal Detection 
1. Visual attention: Trei sman &amp; Gelade's theory 
a. Feature integration theory: 
b. Visual search: simple features versus conjunctions of features:
     -Feature maps 
Feature integration in the brain: The binding problem 
c. Illusory conjunctions 
Treisman &amp; Schmidt (1982).</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>2. Lateral neglect: Involu ntary selective attention 
When there is damage to th e right parietal lobe, a pers on tends to ignore stimuli 
appearing in the left visual field, and also  ignores the left half  of objects or words. 
3. The Psychological Refractory Period (PRP) 
a. Basic phenomenon  
b. Three main theories 
c. Pashler's PRP paradigm for stud ying dual task interference  
d. Why is there a bottleneck?</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>So 2 factors: sensitivity  (distance between distributions, d'  ), and bias, or criterion 
(beta).</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Visual Knowledge (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/apr5h04/</lecture_pdf_url>
      <lectureno>16</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>Zenon Pylyshyn  
The Homunculus problem: who looks at the images? 
Structural descriptions, not dense arrays 
A. What is imagery for ?
Try answering these questions: 
Which is larger, a golf ball or a tangerine?
A tiger or a Great Dane dog? 
Is the hot water tap on the L or R? 
Does a tractor have two big wheels in front? 
Which is darker (on the outside), a cucumber or a watermelon? 
-Did you feel that you used imagery to answer any of these?
So: One thing that imagery seems to be used for: 
-Retrieving subtle spatial or perceptual information from memory:  
(i) that has not been stored as such and (ii) that can't be deduced easily from other 
information. 
Other possible uses for imagery: 
-planning movements 
-understanding descriptions (e.g., form a mental model) 
-maintaining an image of the immediate environment? 
-solving certain ki nds of problems 
-planning layouts (e.g., artist) 
-getting around in the dark</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>west, northeast, west, southwest, ea st. Now draw it [back of handout]. 
C. Imagery and the brain 
Imagery and perception overlap in the brain: 
(1) Kosslyn and his colleagues: imaging ac tivates the primary visual areas in the 
cortex. Larger, smaller images generate larger, smaller areas of activation.  
(2) O'Craven &amp; Kanwisher (2001):  
 -Background: FFA (fusiform face ar ea) and PPA (parahippocampal place area) 
-task of viewing/imaging faces, or viewing/imaging places 
(3) Lesions in the brain 
 -unilateral neglect patient (damage to R hemisphere, Bisiach and colleagues)  
D. Why might it be advantageous to have more than one code?</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Y N 
Y N 
Y N 
Y N 
Y N 
Y N 
Y N 
Y N 
Y N 
Y N 
Y N 
Y N 
Y N 
Y N</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 -Cognitive Processes - Spring 2004 
MIT Department of Brain and Cognitive Sciences 
Course Instructor: Professor Mary C. Potter 
9.65 April 5, 2004 Visual Knowledge   HANDOUT 
Note: Quiz 2, covering everything since the last quiz, is on Wednesday. 
I. What is a mental code? 
II. Imagery as a mental code 
Brief history
A. What is imagery for? 
B. Relation of imagery and perception 
C. Imagery and the brain 
D. Why have more than one mental code? 
III. Memory for pictures: Boundary extension 
I. What is a "mental code"?
 -a mental code  is a hypothetical code used by the mind-brain to represent, store, 
and transform information: transforming the information includes the processes we 
call "thinking."  
-Note that a mental code has two roles: 
1) to make some information easily available 
2) to serve as an index  to other information: e.g., holding words in an acoustic 
code in STM  
II. IMAGERY as a candidate for a major code 
History of ideas about imagery, in brief: 
Greeks 
Thoughts are faint mental images  
Bishop Berkeley 
Triangles  
Jerry Fodor 
Images are ambiguous, thoughts aren't</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>1. Different time courses (short-term; longer-term)  
2. Different information is available on the surface--so suitable to different tasks. 
-analog versus digital clocks  
3. Can take advantage of reduction in  interference when performing dual tasks 
-using fingers to tally "targets" when listening to a list 
So: just how many mental codes do we have?  
We don't know for sure. 
CONCLUSION: Imagery is a well-established code distinct from at least one other
code--although there conti nue to be skeptics.  
III. Memory for pictures: Boundary extension 
Even our immediate memory for pictures is schematic rather than literal (Intraub &amp; 
Richardson, 1989). 
Change blindness: It's difficult to spot a change in a picture, unlessthe change is central to your interpretation of the picture.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>-route-planning 
-MENTAL ABACUS: highly skilled abacus user s are faster in doing arithmetic than 
someone with a hand calculator: AND can use a "mental abacus."  Stigler (1984, 
Cognitive Psychology , p. 145 ff.) 
Evidence for mental abacus: recogn izing intermediate abacus layouts 
B. Relationship of visu al imagery and perception 
-Selective interference: The Brooks experiment 
-Spatial or visual interference? Baddeley's experiment: Mental matrix task with two
types of interfering tasks: 
-blindfolded subject and pendulum (spatial, not visual) 
-detect change in brightness of a stationary light (visual, not spatial) 
Constraints on imagery: Like pe rception, it has some limitations: 
(1) Visual angle of mind's eye  (Kosslyn, 1978) 
INTERPRETATION: K: there's a specialized imagery ability that has constraints 
somewhat like those of vision itself, in this case with a limited "angle" of view. (Lab 
2)</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>(2) Imagery "acuity" 
-rabbit beside an elephant versus beside a fly:  
-Image size can be changed: zooming. 
(3) Imagery "scanning"  [see Reisberg chapter] 
-memorize map with places on it 
-scan from designated start point to a place named by the experimenter 
-critics: "demand characteristics" of experiment 
(4) Mental rotation (Shepard, etc.: See Reisberg. Understand what a linear RT 
function tells us.) 
(5) Inspecting one's image  to read off information, like perception: 
Weber and Castleman exercise in Lab 2.  
(6) Limited capacity of imaging
(In class:) Try task in which you mentally create an image in an imaginary grid of 
large squares. When I say North, draw a mental line upward on the grid, one unit, 
when I say Northeast, draw one diagonally from that point to the next square up and 
over to the right, etc.  Okay start: North, northeast,west, south, west, west, south,</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Learning (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/mar15h04/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>Continguity: Necessary  for an association? 
In rats and other animals, the association between a foodstuff and getting sick may 
be made even though the sickness does not begin until hours after the food 
has been eaten (the Garcia effect).  
This "long-distance" association is more readily made if the food the animal has eaten is different from the animal's usual diet.  
Humans: (in one study, root-beer Lifesavers), that food becomes a scapegoat: the patient is less likely to develop aversions to ordinary foods eaten at the same pre
treatment meal. (Bernstein, Webster, &amp; Bernstein, 1982) 
B. Second fundamental principle  of learning is FREQUENCY 
This supplementary principle increases the likelihood that vali d associations (such 
as causal relationships) will be strengthen ed at the expense of chance associations 
that do not reflect regularities in the world. 
Other principles of learning and memory are also relevant: at tention, elaborative 
processing 
E.g., chein-dog</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text></text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>The Rescorla-Wagner Rule 
delta V = alpha (lambda - V) 
Compound stimuli and competitive learning 
Application to blocking 
Conditioned inhibition</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Modifications  of Rescorla-Wagner  
Delta Rule  in neural-net learning 
Relation to Bayes' Theorem 
Summing up:</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences 
Course Instructor: Professor Mary C. Potter 
9.65 March 15, 2004  LEARNING: Handout 
Assigned: One chapter (2) and part of Chapter 3 from J. R. Anderson (2000). 
Learning and memory: 2nd Edition. New York: Wiley. Note: you may omit pp. 45
48; read pp. 49-57 to pick up the general ideas about conditioning; and study the rest of the chapter (including  the beginning sections, 39-44). 
Outline: 
Elementary principles of learning: 
A. Contiguity 
 B. Frequency 
C. Contingencies and blocking 
Introduction: Learning vs. memory 
Pavlov's dogs now link up with comput ational modelling and even with Bayesian 
reasoning. 
A. CONTIGUITY 
The principle of association by contiguity in time [and space]: 
E.g., flashbulb memories 
Basics of classical conditioning: 
US: Unconditioned stimulus 
UR: Unconditioned response 
CS: Conditioned stimulus 
CR: Conditioned response 
[Also: CER: Conditioned emotional response]</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Standard procedure in cl assical conditioning: 
Why form an association only when objects or events are in close temporal [and 
spatial] proximity? 
Constraints on learning : 
Is simple contiguity sufficient  for learning? 
Preparedness : Seligman (1970) (also called associative bias  ) 
For example, a rat can readily associate a sound or light with a shock (and learn 
what to do to avoid it), or can learn to avoid a food or liquid with a certain taste to 
avoid becoming nauseated, but has great di fficulty associating the taste with shock 
or the sound or light with nausea (Garcia, Hawkins, &amp; Rusiniak, 1974)</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>C. CONTINGENCY LEARNING AND BLOCKING 
Contiguity and frequency are not sufficient for learning: you need contingency 
between the two events you are associating:  
Learning reflects not only positive pairing, but also failures of pairing: that is, if you 
are exposed to A+B, the likelihood that you will learn A--&gt;B depends not only on 
the frequency of A+B, but also the frequen cy of 0+Band A+0. In effect, A has to 
predict B more often than not-A does. 
Partial reinforcement 
Blocking : If you already "know" that it is a light that predicts shock, adding in a 
tone that is also correlated with the shock will not lead to learningthat tone--&gt;shock.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Solving Problems (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/may5h04/</lecture_pdf_url>
      <lectureno>24</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences 
Course Instructor: Professor Mary C. Potter 
9.65 May 5, 2004 Solving Problems Handout 
Outline: 
Approaches to understanding problem solving: 
1. Different styles of problem-solving 
2. How and why people get stuck 
3. Prescriptive approaches 
4. Simulations of problem-solving behavior 
Introduction: Try this problem (from W. Kohler). [See overhead.] 
A circle is divided into 4 sections. One radius is labelled "y". A
rectangle is drawn in another section, in which a right triangle
is embedded: d is the length of one side of the right angle, x the
length of the other side of the right angle, and L is the length
of the third side. Given d, x, and y, how long is L? 
Scientists and mathematicians have sometimes classified themselves 
as symbol-pushers versus visualizers. Which are you? 
Now, classify yourself into one of 4 categories: 
Visualizer Symbol-pusher 
Insight solution to 
circle problem 
Formula (or no) solu-
tion to the circle..</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>These are examples in which a visual) representation may help one
to pick out the appropriate transformations to make the problem
into a more familiar one: "insight" (or, in Reisberg,
"illumination"). 
However, visualization can sometimes be misleading: as in foldinga sheet of paper 1/100 inches thick over, repeatedly: how thick
will it be after 50 folds? 
What is "insight"? A one-step recognition that a new problem is
equivalent to a familiar problem? If so, insight will depend on
the knowledge you already have. 
The 13 problem of Duncker: Why are all 6-place numbers of the form
267,267 or 591,591, etc., all divisible by 13? (8% of subjects in
Duncker's experiment solved with no further information; hints led
to a higher percentage of solutions) 
Can't have a feeling of "insight" unless the underlying principleis fully familiar and intuitively correct, once it comes to mind. 
2. How people get stuck. 
(a) Set or Einstellung: Luchin's water jars. [Lab 3, and Reisberg
p.471-473] 
(b) Duncker: "Functional fixedness." (See Reisberg. 469-471.)
Problems with real objects; tacks in a box made it less likely the
subject would think of using the box as part of the solution. 
Other problems in which an object with a standard use is not seen
as useable in another role (like pliers as a weight for a
pendulum).</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>More abstract problems can be regarded as cases of "functional
fixedness": 
"A surgeon comes across an automobile accident, takes a look at
the victim lying in the road, and exclaims..." 
Related issue: transfer of training: recognition that another
problem is analogous to one you already know the answer to. 
It is often difficult to realize that two problems have the same
underlying structure, so that if you've solved one, you can easily
solve the other. See the discussion in Reisberg, 459-463. 
3. Prescriptive approaches 
-make inferences &amp; associations 
-look for analogies -figure out subgoals -hill-climb -if stuck, look for new routes -if necessary, leave the problem and return later Question of incubation: Does your brain continue to work on the
problem while you're not consciously thinking about it? See
Reisberg, pp. 480-83 for a possible answer.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>1. Different styles of problem-solving: 
The idea of classifying people as visualizers versus symbol-
pushers is an example of this approach. 
Wertheimer, Productive thinking , 1923: 
The Altar window problem (lab) 
Wertheimer proposed that there are 3 styles of problem-solving: 
a) Use deductive logic: standard algorithms; math; logical
syllogisms. 
b) Retrieve the answer from memory: learn the steps in a proof.
Improve performance by repetition, habit, frequency, recency,
trial and error. 
c) Use productive thinking: analogies, application of knowledge
from another field, and especially "structural analysis." 
Another example that distinguishes among these styles orapproaches: 
Area of a parallelogram:</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>You start with an initial state, and you work toward a goal state,
using operators. In setting up the problem space, you may have
some path constraints. (R., p. 448.) 
At any one time you are at a given node or knowledge state in the
problem space; the knowledge state is what you have in STM. You
can either choose an operator to apply to take you to a new node--
or can retreat to a different node (recover a different set of STM
info--or look at one's external memory). 
Heuristics include: hill-climbing (which doesn't always work, as
you may have to go away from the goal at some point in the
solution), means-end analysis, and working backward from the goal
[R., pp. 450-453]. 
Newell &amp; Simon's computer simulation is consistent with protocol
analyses of subjects solving problems like the DONALD + GERALD =
ROBERT problem: Each letter is a different digit: e.g., all D's
are one digit: in this case, D = 5. The simulation predicts
(approximately) the time for each step in solution, and the order
of steps, the harder places, etc. 
D O N A L D 
+ G E R A L D 
_______________ 
R O B E R T</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>4. Simulations of problem-solving: 
Newell &amp; Simon (1972): The General Problem Solver (GPS) [Reisberg,
pp. 448-453] They proposed the following. 
A. There are just a few general characteristics of human problem
solving: 
-serial processing 
-certain elementary processes: information transfer, elementary
operations: they take of the order of 50-300 ms each 
-Inputs and outputs are held in a small-capacity STM, measured in
chunks that depend on experience 
-storing in LTM takes about 5 s per chunk --retrieval from LTM is fairly fast: e.g., 200 ms. 
B. A task environment is represented as a problem space in which
problem solving take place: a space of possible situations to be
searched. 
How do you set up the problem space? Task instructions and
display; memory for similar or analogous tasks; metaprograms forsetting up space-general task programs. 
C. The task structures the space. 
D. The structure determines the possible problem-solving program.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Object Recognition (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/feb9h04/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>-need to recognize in [almost] any position and rotational orientation 
-any size on the retina
     -any brightness
     -any illuminant color 
             -with va rious distortions or variations 
Learn by experience with each specific ob ject? To some extent, but we generalize well to 
shifts of size, orientation. 
So: we must have some way of abstractin g certain "invariants"  from an object. 
Biederman's RBC theory, in  your text (Chap. 3). 
II. Basics of vi sual perception: 
A. Gestalt principles, perceptual constancies, the Weber-Fechner Law  : 
Gestalt psychologists: Wertheimer , Koffka, Ko"hler, and others. 
The first principle: figure-ground organization : 
figure "captures" the common contour, figure has more defi nite localization, more solid 
(less filmy) color 
Other principles: 
proximity 
similarity 
good continuation 
closure : dotted lines joined 
common fate  (moving together) 
All represent "good fo rm" [Law of Pra"gnan z]: simplicity, inclus iveness, symmetry,</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Recommended: Nakayama, He, &amp; Shimojo (1995), chapter in Ko sslyn &amp; Osherson 
(Eds.), Visual cognition: Vol.  2, An invitation to cognitive science  2nd Edition. 
One illustration of this approach: th e perception of fi gure and ground. 
Principle One: only one surf ace can "own" a boundary between  it and another surface. 
Principle Two: we are bu ilt to see probable even ts, not unlikely ones.
Generic  (typical) view 
Accidental  (coincidental) view.
Hard-wired and MODULAR?
III. Higher-level vision: 
Role of TOP-DOWN CONTEXT  
Demo: 
IV. Word perception: 
a. Words in isolation: 
The Wheeler-Reicher WORD SU PERIORITY EFFECT (WSE) (see text, pp. 68-69):  It's 
easier to detect a letter  in the context of a word  than in  isolation. 
Experiment:</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>PROOF-READING 
Context experiment: Tu lving, Mandler, &amp; Baumal (1964) ga ve participants 0, 2, 4, or 8 
words of sentence context (9 was full sentence),and then a very brief word  for 0 to 140 
ms. Ascending method: first saw word at 0, then increasing  durations until recognized. 
  E.g., An apple/from the/ tree hit/ my bare/ HEAD.  
Results: 
Viewers required a longer ex posure duration to recognize final word, the shorter the 
preceding context. 
Problems:  
Subjects had multiple chance s to guess the word, as the duration increased --unlike 
normal reading. And th ey could think about the context as  long as they wished, before 
guessing the word. 
OTHER EXPERIMENTS on context: Immediate measures: 
Potter, Moryadas, Abrams, &amp; No el, 1993, used RSVP presentati on of sentences, so that 
subjects didn't have time to puzzle out what each word was, in relati on to the context. 
They showed that the context was still able to influence re cognition of a critical word 
that might or might not belong in th e context: e.g., horse/house/honse: 
a. They looked at the horse from their car. Neutral: horse or house usually read 
correctly 
b. The boy rode the hous e around the pasture. Biased against word: house often 
misread as horse. 
c. The lawn in front of the honse was overgrown. Nonword honse was often misread as 
house, rarely as horse. 
A McClelland-Rumelhart type of model could readily explain these results, but only if 
expanded to include hi gh-level knowledge as a source of top-down input once several 
alternatives are proposed by visual analysis. 
CONCLUSION ABOUT CONTEXT AND WORD PERCEPTION: 
Initial access on basis of perception  only? Context selects or confirms.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>K
 _ _ _ K --&gt; # # # # --&gt; _ _ _ _    
D
(which did you see: K or D?) 
OR:
 K
             W O R K --&gt; # # # # --&gt; _ _ _ _
 D 
-word shape doesn't matter:  WORK, work, even WoRk 
-the effect requires a very clear glimpse,  followed by patterned masking--not dim or 
indistinct, followed by a blank field 
-you still get some benefit from pronounceable "pseud owords": REET , MAVE as 
compared with random, nonpronounc eable strings:  RTEE, AEVM. 
Explanations of these effects require that, at the brie f moment of perception, possible 
words CONSTRAIN what letters are seen: te ntative letter assignme nts constrain each 
other.
 C C
 T E T E THE vs. CAT: 
T T H OR A? (Fig. 3.6 in text) 
In Chapter 3 several examples  of simple network models ar e described to give you an 
idea about how the visual syst em might place its bets effect ively,  even when reading 
rapidly or in imperfect visual conditions . The  McCLELLAND-RUMELHART Interactive 
Activation Model (an in fluential early model) is also described. 
b. Word perception in context 
Normally we don't read words in isolation, but in sentence or paragraph CONTEXT.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences
Course Instructor: Professor Mary C. Potter
9.65 February 9, 2004 Obje ct recognition HANDOUT 
I. Why is object recognition difficult? 
II. Basics of visual perception 
A. Gestalt principles, constancy 
B. Computational appr oaches: e.g., perception of  
surfaces
III. Higher-level vision : Object recognition 
IV. Word perception 
Today: Visual perception, le ading to higher-level vision : object recognition, word 
perception.  
I. Why is object recognition difficult? 
For example, what's this? 
This example illus trates the ambiguity of  perception, and its interpretive nature.We 
combine information from our senses with our knowledge of  what's likely, especially 
what's likely in context. 
The early visual system extracts information th at is likely to be co rrelated with actual 
objects in the environment--u nder these generally true a ssumptions about objects: 
-continuous boundaries 
-surfaces that chan ge texture and color and bri ghtness relatively smoo thly, if the surface 
is continuous, but change  sharply when the surf ace is discontinuous. 
-move as a unit 
-rigid (or they deform  in a regular way). 
Why simple solutions don't wo rk in object recognition 
SEPARATING OBJECTS IN  A SCENE: difficult 
TEMPLATE-MATCHING (once a single object ha s been segregated)--w hy this often won't 
work</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>regularity. 
The perceptual constancies : 
The Gestalt psycholo gists and their followers also emph asized the RELATI ONAL character 
of perception: we see relative (not absolute ) brightness, so that a white piece of paper 
still seems white in a dim room , when the light intensity refl ected from it may be lower 
than that of a black piece of  paper in a bright light.  
This is perceptual CONSTANC Y--perception "correcting" fo r the brightness or color of 
illumination, correcting for th e angle at which we view something, the object's size on 
the retina as a function of distance, etc. 
Perceptual constancy is not perfect, howeve r: we do notice changes. Just how much 
change does there have to be, before we notice it?  
The Weber-Fechner Law : Fechner's Law: S = k log I, where S is the psychological 
sensation, I is the physical measure, e.g., intensity of lig ht, and k is a constant that 
differs for different physical dimensions.  Th is law is a good descr iptive generalization, 
but it tends not to hold at the extremes  of any dimension. 
The perceived "strength" of a sensation such as the bright ness of a light grows as a 
RATIO of the light's physical intensity to that of the light  you are comparing it with.  
Substituting a 100 watt bulb  for a 50 watt bulb makes a very noticable difference, 
whereas going from 200 to 250 wa tts is much le ss noticeable. 
This ratio law reflects a compromise betwee n perfect constancy (w hich would leave us 
unable to detect a shadow, fo r example) and a perfect correlation between light energy 
and perceived brightness (whi ch would make the same ob ject look too extremely 
different as lighting changed). 
To sum up , the Gestalt psycho logists focused on the abstra ct, inferential character of 
perception: we don't "see" what our reti na sees, but instead perception is the 
consequence of a comple x set of processes.  
B. Computational approaches to object perception : 
A more unified, computationa l account of the many phenom ena described by Gestaltists 
and other visual scientists. 
David Marr 
An important goal is to discover CONSTR AINTS or assumptions made by the visual 
system: to resolve AMBIGUITY.  
One example: perception of surfaces .</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Memory V: Associative Memory (PDF)</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-65-cognitive-processes-spring-2004/resources/mar10h04/</lecture_pdf_url>
      <lectureno>11</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>Content-addressing: 
Some kinds of information CA NNOT BE USED EFFECTIVELY as a retrieval address, even 
though the information is in me mory.  E.g., word for a family  relationship (for example, 
grandmother , cousin ) that ends with w? 
2. Network models of semantic memory 
The idea that memory consis ts of associations between mental entities underlies 
associative models  of human memory.  In such mo dels the contents of memory 
consist of mental representations of it ems and their associ ative connections.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>________________ 9.65 - Cognitive Processes - Spring 2004
MIT Department of Brain and Cognitive Sciences
Course Instructor: Professor Mary C. Potter
9.65 March 10, 2004 Memory  V: AssociativeMemory  HANDOUT 
NOTE: that LAB 2 IS ON WEDNESDAY NEXT WEEK . Pick up a 
copy of the Anderson re ading for next Monday. 
Assigned: Chap. 8. 
Outline: 
1. Meaning and Long-term Memory 
2. Network Models of Semantic Memory 
a. Quillian's network mode l of semantic memory 
b. Spreading activation 
c. Anderson's ACT 
-the fan effect and the paradox of the expert 
3. Nodes, Links, and Connectionism 
1. Meaning and Long-term Memory 
To review: Much of memory seem s to be structured associativ ely. In the next lecture on 
learning, you'll read about the conditions under which associative links are formed. 
Today, we focus on the way as sociations are STRUCTURED. It turns out that, in general, 
multiple links to already we ll-structured inform ation gives the greatest chance of 
retaining the information.   How do we knowthat? 
Earlier in the course we discussed Craik and Lockhart's theory that Depth of Processing 
determines LTM. Another experiment, by Cr aik and Tulving (1975) on the effect of 
different tasks to be performe d on a series of words.  
-decide whether the test word would fit in a sent ence, such as "He met a 
______________ on the street": FRIEND (versus TABLE) 
-is this word in capi tal letters? friend 
-does this word rhyme with WEIGHT? FRIEND  
Differential later memory fo r the words. INTENTION to remember the words doesn't 
matter much. 
SUMMING UP THE ROLE OF ME ANINGFULNESS IN LT MEMO RY: What gets linked up 
during encoding determines what gets reme mbered.  And coding in terms of meaning 
provides the most distinctive encoding, the largest set of connections to already-known 
information, and therefore the most RETRIEVAL ROUTES.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>-time and location  make a proposition an episode, rather than a semantic "fact" 
Processing assumptions 
Needed: more complex accounts of the structure of information.  
3. Nodes, Links, and Connectionism 
Background: Perceptrons: 
No way to represent "e xclusive OR" (XOR): 
Need hidden units 
Connectionism or Parallel Distributed Processing (PDP)
Units  and associative links ( connections ) 
Distributed information
PDP framework: 
1. Set of processing units 
2. State of activati on over these units 
3. Pattern of connec tivity among units</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Economy of storage 
Problems: 
c. Anderson's ACT : 
Propositions, not just single concepts. 
&gt;From Anderson, 2000: 
John bought some candy because he was hungry. 
The fan effect 
Paradox of the expert 
Networks connecting concepts?  E. g., Anderson, certain labelled links: 
-isa 
-has 
-relation:  verbs/actions as relations between an agent  and an object .</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>a. Quillian's network mo del of semantic memory 
Using the terminology of graph theory, item s are commonly called nodes  and 
connections between them are called links . 
  breathes          
     animal----has skin  
       reproduces 
        feathers      swims 
           wings----bird  fish----scales 
flies gills 
    predator            eats worms pink 
eagle robin salmon 
Amer.symbol  red breast edible 
From Quillian (1966) and Collins &amp; Quillian (1969). 
has (or hasa ) links (features or properties), isa links (superordinate, subordinate)  
b. Spreading activation 
Experiments by Coll ins and Quillian (1969) 
Hierarchical structure</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>4. An activation function for each unit--either a threshold (f ires or doesn't), or a smooth, 
continuous function such as a sigmoid. 
5. Learning rule: modification by experi ence, by changes in weights that connect 
processing units, as a resu lt of FEEDBACK (BACKPROP). 
6. Environment of the system  (e.g., where do the inputs come from, wh at sorts of 
outputs).  
Many differences be tween the real CNS and the PDP models 
The two most important advanc es of the PDP models are: 
(a) the demonstration that one can get "intelligent" performanc e out of simple units in a
network just by adjusting the strength (weight) of the conne ction of one to another.  
(b) the very same units can participate in  representing many different pieces of 
information.
Vital to this kind of model are HIDDEN UNITS. 
Frequency</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
