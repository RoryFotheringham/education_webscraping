<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/</course_url>
    <course_title>Statistical Learning Theory and Applications</course_title>
    <course_tags>
      <list>Science </list>
      <list>Mathematics </list>
      <list>Probability and Statistics </list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>Generalization Bounds
Introduction to Stability</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec14/</lecture_pdf_url>
      <lectureno>14</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 14: Generalization Bounds and 
Stability  
Alex Rakhlin 
 
Description 
We introduce the notion of gene ralization bounds, which allow us to have confidence in 
the functions our algorithm s are finding. W e introduce the notion of algorithm ic stability, 
and explore the connection between algorith mic stability and generalization bounds.  
Suggested Reading 
 V. N. Vapni k. Statistical Learning Theory.  Wiley, 1998.  
 F. Cucker and S. Sm ale. On The Mathematical Foundations of 
Learning.  Bulletin of the Am erican Mathem atical Society, 2002.  
 O. Bousquet and A. Elisseeff. Stability and Generaliz ation.  Journal of 
Machine Learning Research.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Manifold Regularization</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec6/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 6: Manifold Regularization  
Andr ea Caponnetto  
 
Description 
We first analyze the lim its of learning in high dim ension. He nce, we stress the difference 
between hig h dimensional am bient s pace and intrinsic geometry as sociated to the 
marginal distribution. We obser ve that, in the sem i-supervis ed setting, unlabeled data 
could be used to exploit low di mensionality  of the intrinsic geom etry. In order to 
formalize th ese in tuition s we brief ly introdu ce th e manifold Laplacian a nd Graph 
Laplacian. Finally, we introduce a new cla ss of regularization algorithm s, aim ed at 
enforcing smoothness relative to  the intrins ic geometry.  
Suggested Reading 
 M. Belkin, P . Niyogi. Semi-supervised Learning on Riemannian 
Manifolds.  Machine Learning, 56, S pecial  Issue on Clustering, 209-239, 
2004.  
 M. Belkin, P . Niyogi, V. Sindhwani. On Manifold Regularization.  
AISTATS 2005.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Ranking</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec9/</lecture_pdf_url>
      <lectureno>9</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 9: Ranking  
Giorgos Zacharia  
 
Suggested Reading 
 NIPS 2002 Workshop: Beyond Classifica tion and Regression: Learning 
Rankings, Pref erence s, Equality P redicates, and Other Struc tures  
 Proceedings of the NIPS 2005 W orkshop on Learning to ran k</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Multiclass</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec8/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 08: Multiclass Classification 
Ryan Rifkin 
 
Description 
We consider the prob lem of m ulticlas s class ification. W e have seen  that regularization-
based approaches (RLSC, SVM) perform  very well on binary classifi cation tasks, and we 
hope to extend this benefit to the m ulticlass scenario. W e advance the hypothesis that a 
simple "one- vs-all" sch eme is an extrem ely ef fective app roach to m ulticla ss 
class ificatio n. W e review a number of other app roaches, and  present exp erimental 
comparisons.  
Suggested Reading 
  Rifkin and Klautau, In Defense of One-Vs-All Classification , subm itted to Journa l of 
Machine Learning Research.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Uniform Convergence Over Function Classes</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec16/</lecture_pdf_url>
      <lectureno>16</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 16:  
Alex Rakhlin 
 
Description 
We relate consistency or em pirical risk m inimization (ERM) with uniform  convergence 
in probability over function classes. We  prove generalization bounds for ERM in a 
bounded RKHS.  
Suggested Reading 
 V. N. Vapni k. The Nature of Statistical Learning Theory.  Springer, 
1995.  
 Cucker and Sm ale. On the mathematical foundations of learning.  
Bulletin of the Am erican Mathem atical Society, 2002.  
 Ding-Xuan Zhou. Capa city of Reproducing Kernel Spaces in Learning 
Theory.  to appear in IEEE Trans. on Info. Theory, 2003.  
 V. N. Vapni k and A. Ya. Chervonenkis. Necessa ry and Sufficient 
conditions for the unifo rm converg ence of the means to th eir 
expectations.  Probability Theory and Applications, 26, 532-553 1981.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Active Learning</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/class22/</lecture_pdf_url>
      <lectureno>22</lectureno>
      <slides>
        <slide>
          <slideno>34</slideno>
          <text>Active learning rule
vt
stu
{Goal: Filter to label just those points in the error region.
but t, and thus t unknown!
Define labeling region:
Tradeoff in choosing threshold st:
If too high, may wait too long for an error.
If too low, resulting update is too small.
makes 
constant.
But t unknown!  L</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>[2] Region of uncertainty
Number of labels needed depends on H and also on P.
Special case: H = {linear separators in Rd}, P = uniform 
distribution over unit sphere. 
Theorem [Balcan, Beygelzimer &amp; Langford ICML 06]:  
(d2log 1/ ) labels are needed to reach a hypothesis with error 
rate &lt;  .
Supervised learning: (d/)l a b e l s .
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>Label upper bounding technique
[Dasgupta NIPS05]
(h0= target hypothesis)
Proof technique: analyze how many labels until the diameter of 
the remaining version space is at most  .h0H
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>[3] Query-by-committee
Elegant scheme which decreases volume in a manner which is 
sensitive to the data distribution.
Bayesian setting: given a prior on H
H1= H
For t = 1, 2, 
receive an unlabeled point xtdrawn from P
[informally: is there a lot of disagreement about xtin Ht?]
choose two hypotheses h,h randomly from ( , Ht)
if h(xt) h(xt): ask for xts label
set Ht+1
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Mistake bound
a
{k
{x : |a x| k} =Theorem 2: In the supervised setting, the modified 
Perceptron converges to generalization error  after 
(d log 1/ )mistakes.
Lemma (band) :For any fixed a: kak=1,  1 and for x~U on S:
Apply to |vtx| and |u x| 2|vtxt||uxt|is
large enough in expectation (using size of t).</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>Label bound
Theorem [DKM05]: In the active learning setting, the 
modified Perceptron, using the adaptive filtering rule, will 
converge to generalization error  after (d log 1/ )
labels.
Corollary [DKM05] : The total errors (labeled and 
unlabeled) will be (d log 1/ ).</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Active learning motivation
Machine learning applications, e.g.
Medical diagnosis
Document/webpage classification
Speech recognition
Unlabeled data is abundant, but labels are expensive.
Active learning is a useful model here.
Allows for intelligent choices of which examples to label.
Label-complexity : the number of labeled examples required to 
learn via active learning 
can be much lower than the PAC sample complexity!</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>Proof technique
Proof outline:  We show the following lemmas hold with 
sufficient probability:
Lemma 1. stdoes not decrease too quickly: 
Lemma 2. We query labels on a constant fraction of t.
Lemma 3. With constant probability the update is good .
By algorithm, ~1/R labels are mistakes.  R = (1).
Can thus bound labels and total errors by mistakes .</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>current version space Data and 
hypothesis spaces, superimposed:
(both are the surface of the unit sphere in R
d)
region of uncertainty in data spaceAlgorithm [CAL92]:
of the unlabeled points which lie in the region of uncertainty, 
pick one at random to query.
Slide credit: S. Dasgupta[2] Region of uncertainty</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Perceptron
Perceptron update: vt+1= vt+ ytxt
error does not decrease monotonically.
uvt
xtvt+1</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Fast online active learning
[Dasgupta, Kalai &amp; M, COLT 05]
A lower bound for Perceptron in active learning context of 
(1/2)labels .
A modified Perceptron update with a (d log 1/ )mistake
bound.
An active learning rule and a label bound of (d log 1/ ).
A bound of (d log 1/ )on total errors (labeled or not).</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Online learning: related work
Standard (supervised) Perceptron: a simple online
algorithm:
If ytSGN(vtxt), then: Filtering rule
vt+1= vt+ ytxt Update step
Distribution-free mistake bound O(1/ 2), if exists margin .
Theorem [Baum89]: Perceptron, given sequential labeled 
examples from the uniform distribution, can converge to 
generalization error after (d/2) mistakes.</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>A fuller picture
For non-homogenous linear separators in R2: some bad target 
hypotheses which require 1/ labels,
but most require just O(log 1/ ) labels
good
bad
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Problem
Many results in this framework, even for complicated 
hypothesis classes.
[Baum and Lang, 1991] tried fitting a neural net to handwritten characters.
Synthetic instances created were incomprehensible to humans!
[Lewis and Gale, 1992] tried training text classifiers.
an artificial text created by a le arning algorithm is unlikely to 
be a legitimate natural language expression, and probably would be uninterpretable by a human teacher.
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>Example: the 1-d line
Searchability index lies in range: (h) 1
Theorem [D05]:           # labels needed 
Example : Threshold functions on the line
w+ -
Result := 1/2 for any target hypothesis and any input 
distribution
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Supervised learning
Given access to labeled data (drawn iid from an unknown underlying 
distribution P), want to learn a classi fier chosen from hypothesis class H, 
with misclassification rate &lt; . 
Sample complexity characterized by d = VC dimension of H.
If data is separable, need roughly d/ labeled samples.
Slide credit: Sanjoy Dasgupta</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>OPT
Fact: Under this framework, any algorithm requires 
(d log 1/ )labels to output a hypothesis within 
generalization error at most .
Proof idea: Can pack (1/ )d spherical
caps of radius  on surface of unit
ball in Rd. The bound is just the 
number of bits to write the answer.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Can adaptive querying really help?
[CAL92, D04]: Threshold functions on the real line 
hw(x) = 1(x w),     H = {hw: w R}
Start with 1/ unlabeled points
Binary search  need just log 1/ labels, from which the rest can be 
inferred! Exponential improvement in sample complexity.w+ -
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>[3] Query-by-committee
For t = 1, 2, 
receive an unlabeled point xtdrawn from P
choose two hypotheses h,h randomly from ( , Ht)
if h(xt) h(xt): ask for xts label
set Ht+1
Observation: the probability of getting pair (h,h) in the inner 
loop (when a query is made) is proportional to (h) (h) d(h,h).
Htvs.
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Problem framework
u
vt
tTarget:
Current hypothesis:
Error region:Assumptions:
Separability
u is through originx~Uniform on S
error rate:
t</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Lower bound on labels for Perceptron
Theorem [DKM05]: The Perceptron algorithm, using any 
active learning rule, requires (1/2)labels to reach 
generalization error  w.r.t. the uniform distribution.
Proof idea: Lemma: For small t, the Perceptron update will 
increase t unless kvtk
is large: (1/sin t). But, kvtkgrowth rate:
So need t 1/sin2t.
Under uniform,
ttsin t.uvt
xtvt+1</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>Active learning rule
vt
stu
{Choose threshold stadaptively: 
Start high. 
Halve , if no error in Rconsecutive labels.
Start with threshold sthigh: 
After Rconsecutive labeled points,
if no errors: L</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>Lower bounds on label complexity
For linear separators in R1, need just log 1/ labels.
Theorem [D04]: when H = {non-homogeneous linear separators in 
R2}:  some target hypotheses require 1/ labels to be queried!
h3h2
h0h1
fraction of distributionNeed 1/ labels to distinguish 
between h0, h1, h2, , h1/!Consider anydistribution 
over the circle in R2.
Slide credit: S. DasguptaLeads to analagous bound: 
(1/) for homogeneous linear 
separators in Rd.</text>
        </slide>
        <slide>
          <slideno>48</slideno>
          <text>Open problem: efficient, general AL
[M, COLT Open Problem 06]: Efficient algorithms for 
active learning under general input distributions, D.
Other open variants:
Input distribution, D,is unknown to learner.
Agnostic case, certain scenarios ([Kriinen, NIPS 
Foundations of Active Learning workshop 05]: negative   
result for general agnostic setting).
Add the online constraint: memory and time complexity 
(of the online update) must not scale with number of seen labels or mistakes.
Same goal, other concept classes , or a general concept 
learner.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Active learning
In many situations unlabeled data  is easy to come by, but there 
is a charge for each label.
What is the minimum number of labels needed to achieve the 
target error rate?
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>AC Milan vs. Inter Milan</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>A modified Perceptron update
Standard Perceptron update:
vt+1= vt+ ytxt
Instead, weight the update by confidence w.r.t. current 
hypothesis vt:
vt+1= vt+ 2yt|vtxt|xt (v1 = y0x0)   
(similar to update in [Blum et al.96] for noise-tolerant learning)
Unlike Perceptron:
Error decreases monotonically:
cos( t+1) = u vt+1= u vt+ 2 |vtxt||uxt|
u vt= cos( t)
kvtk=1 (due to factor of 2)</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>[DKM05] in context
samples        mistakes         labels       total errors     online?
PAC
complexity
[Long03][Long95]
Perceptron
[Baum97]
CAL
[BBL06]
QBC
[FSST97]
[DKM05](d/ )  
(d/ )
(d/ 3)
(1/2)(d/ 2)
(1/2) (1/2) 9
((d2/) 
log 1/ )(d2 log 1/ ) ( d2 log 1/ )

(d/  log 1/ ) ( d  log 1/ ) ( d  log 1/ )

(d/  log 1/ ) ( d  log 1/ ) ( d  log 1/ ) ( d  log 1/ )
9</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>Geometry of hypothesis space
H = any hypothesis class, of VC dimension d &lt; .
P= underlying distribution of data.
(i) Non-Bayesian setting: no probability measure on H
(ii) But there is a natural (pseudo) metric: d(h,h) = P(h(x) h(x))
(iii) Each point x defines a cut through HhhH
x
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Mistake bound
Theorem [DKM05]: In the supervised setting, the modified 
Perceptron converges to generalization error  after 
(d log 1/ )mistakes.
Proof idea: The exponential convergence follows from a 
multiplicative decrease in t:
On an update, 
Lower bound 2|vtxt||uxt|, with high probability, using 
distributional assumption.</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Online active learning
Under Bayesian assumptions, QBC can learn a half-space 
through the origin to generalization error , using 
(d log 1/ )labels.
But not online: space required, and time complexity of 
the update both scale with number of seen mistakes!
Online algorithms:
See unlabeled data streaming by, one point at a time
Can query current points label, at a cost
Can only maintain current hypothesis (memory bound)</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>A view of the hypothesis space
H = {non-homogeneous linear separators in R2}
All-positive
hypothesis
All-negativehypothesisGood region
Bad regions
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Active learning variants
There are several models of active learning: 
Query learning (a.k.a. Membership queries)
Selective sampling
Active model selection 
Experiment design
Various evaluation frameworks :
Regret minimization
Minimize label-complexity to reach fixed error rate
Label-efficiency (fixed label budget)
We focus on classification , though regression AL exists too.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>[2] Region of uncertainty
current version space
Suppose data lies 
on circle in R2; 
hypotheses are linear separators.
(spaces X, H superimposed)
region of uncertainty in data spaceCurrent version space: portion of H consistent with labels so far.
Region of uncertainty = part of data space about which there is still some uncertainty (ie. disagreement within version space)
++
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Membership queries
Earliest model of active learning in theory work [Angluin 1992]
X = space of possible inputs, like {0,1}n
H = class of hypotheses
Target concept h*H to be identified exactly .
You can ask for the label of any point in X: no unlabeled data .
H0= H
For t = 1,2,
pick a point x X and query its label h*(x)
let Ht= all hypotheses in Ht-1consistent with (x, h*(x))
What is the minimum number of membership queries needed to 
reduce H to just {h*}?
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>[3] Query-by-committee
[Seung, Opper, Sompolinsky, 1992; Freund, Seung, Shamir, Tishby 1997]
First idea: Try to rapidly reduce volume of version space?
Problem: doesnt take data distribution into account.
H:
Which pair of hypotheses is closest? Depends on data distribution P.
Distance measure on H: d(h,h) = P(h(x) h(x))
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>Open problem: efficient, general AL
[M, COLT Open Problem 06]: Efficient algorithms for 
active learning under general input distributions, D.
Current UBs for general distributions are based on 
intractable schemes!
Provide an algorithm such that w.h.p.:
1. After Llabel queries, algorithm's hypothesis vobeys:
PxD[v(x)  u(x)] &lt; .
2. L is at most the PAC sample complexity, and for a general 
class of input distributions, Lis significantly lower .
3. Total running time is at most poly(d, 1/ ).
Specific variant: homogeneous linear separators, realizable case, 
D known to learner.</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>A modified Perceptron update
Perceptron update: vt+1= vt+ ytxt
Modified Perceptron update:  vt+1= vt+2 yt|vtxt| xt
uvt
xtvt+1 vt+1
vtvt+1</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Active Learning
9.520 Class 22, 03 May 2006
Claire Monteleoni
MIT CSAIL</text>
        </slide>
        <slide>
          <slideno>45</slideno>
          <text>Searchability index [D05]
Accuracy 
Data distribution P
Amount of unlabeled dataEach hypothesis h H has a 
searchability index (h)
Searchability index lies in the range:  (h) 1
Upper bound. For any H of VC-dim d&lt;, there is an active 
learning scheme* which identifies (within accuracy  ) any 
h H, with a label complexity of at most:                             
Lower bound . For any h H, any active learning scheme for the 
neighborhood B(h, (h)) has a label complexity of at least: 
[When (h)  : active learning helps a lot.]
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>49</slideno>
          <text>Other open problems
Extensions to DKM05:
Relax distributional assumptions.
Uniform is sufficient but not necessary for proof.
Relax realizable assumption.
Analyze margin version
for exponential convergence, without d dependence.
Testing issue: Testing the final hypothesis takes 1/ labels! 
Is testing an inherent part of active learning?
Cost-sensitive labels
Bridging theory and practice.
How to benchmark AL algorithms?</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Outline
Motivation
Historical framework: query learning
Current framework: selective sampling
Some recent results 
Open problems</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>[3] Query-by-committee
Label bound, Theorem [FSST97] : 
For H = {linear separators in Rd}, P = uniform distribution, then (d 
log 1/ )labels to reach a hypothesis with error &lt; .
Implementation: need to rand omly pick h according to ( , Ht).
e.g. H = {linear separators in Rd}, = uniform distribution:
HtHow do you pick a 
random point from a convex body?
Slide credit: S. DasguptaSee e.g. [Gilad-Bachrach, Navot &amp; Tishby NIPS 05]</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>[1] Uncertainty sampling
Maintain a single hypothesis, based on labels seen so far.
Query the point about which this hypothesis is most uncertain.
Problem: confidence of a single  hypothesis may not accurately 
represent the true diversity of opinion in the hypothesis class.
X
--
---
--
+
++
++--
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>50</slideno>
          <text>Thank you!</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>More general hypothesis classes
For a general hypothesis class with VC dimension d, is a 
generalized binary search possible?
Random choice of queries d/ labels
Perfect binary search d log 1/ labels
Where in this large range does the label complexity of active learning lie?
Weve already handled linear separators in 1-d
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>X = {0,1}n
H = AND-of-positive-literals, like x1x3x10
S = { }  (set of AND positions)
For i = 1 to n:
ask for the label of (1,,1,0,1,,1) [0 at position i]
if negative: S = S {i}
Total: n queries 
General idea: synthesize highly informative points.
Each query cuts the version space -- the set of consistent hypotheses -
-i n  h a l f .
Slide credit: S. DasguptaMembership queries: example</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Selective sampling, online constraints
Sequential selective sampling framework:
Unlabeled examples, xt, are received one at a time, 
sampled i.i.d. from the input distribution.
Learner makes a prediction at each time-step. 
A noiseless oracle to label yt, can be queried at a cost.
Goal: minimize number of labels to reach error .
is the error rate (w.r.t. the target) on the input distribution.
Online constraints:
Space:  Learner cannot store all previously seen examples (and 
then perform batch learning).
Time: Running time of learners belief update step should not 
scale with number of seen examples/mistakes.</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>Searchability index [D05]
Accuracy 
Data distribution P
Amount of unlabeled dataEach hypothesis h H has a 
searchability index (h)
(h)  min(pos mass of h, neg mass of h), but never &lt; (h)  1, bigger is better
 1/21/4
1/5

1/41/5Example: linear separators in R2, data on a circle: 
1/31/3
All positive 
hypothesisH
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>[3] Query-by-committee
First idea: Try to rapidly reduce volume of version space?
Problem: doesnt take data distribution into account.
H:To keep things simple, say d(h,h) Euclidean distance in this 
picture.
Error is likely to 
remain large!
Slide credit: S. Dasgupta</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Selective sampling
[Cohn, Atlas &amp; Ladner, 1992]
Selective sampling:
Given: pool (or stream ) of unlabeled examples, x,drawn i.i.d. 
from input distribution.
Learner may request labels on examples in the pool/stream.
(Noiseless) oracle access to correct labels, y.
Constant cost per label
The error of any classifier h is measured on distribution P:
err(h) = P(h(x) y)
Goal: minimize label-complexity to learn the concept to a 
fixed accuracy.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Math Camp 2: Probability Theory</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/mathcamp01/</lecture_pdf_url>
      <lectureno>&#160;</lectureno>
      <slides>
        <slide>
          <slideno>45</slideno>
          <text>Existence and uniqueness of minimum
Let f : IRn  IR be a strictly convex function. 
The function f is said to be coercive if 
lim f(x) = + . 
x+ 
Strictly convex and coercive functions have exactly one 
local (global) minimum.</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>Convex Functions
A function f : IRn  IR is convex if: 
For any x1 and x2in the domain of f, for any   [0, 1], 
f(x1+ (1  )x2)  f(x1) + (1  )f(x2). 
A function is strictly convex if we replace   with &lt;.</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Completeness
A sequence of functions fn is fundamental if  &gt; 0 N 
such that 
n and m &gt; N , (f n, fm) &lt; . 
A metric space is complete if all fundamental sequences 
converge to a point in the space. 
C, L1, and L2 are complete. That C2 is not complete, 
instead, can be seen through a counterexample.</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>A Strictly Convex Function
0 1 2 3 4 5 6 7 8 9 
3 2 1 0 1 2
 3</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>The vectors
e1 = (1, 0, 0, ...., 0) 
e2 = (0, 1, 0, ...., 0) 
                               
en = (0, 0, 0, ...., 1) 
form an orthonormal basis in IRn . 
2. The space l2 with elements x = (x1, x2, ..., x n, ....), y = 
(y1, y2, ..., y n, ....), ..., where 
  
2 xi &lt; , yi 2 &lt; , ..., ..., 
i=1 i=1 
becomes an innite-dimensional Euclidean space when 
equipped with the dot product 
 
(x, y) = xiyi. 
i=1</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>Optimizing a Convex Function Over a
Convex and a Non-Convex Set
f(x,y) = -x + -y 
Global Optima Local Optimum</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Examples
1. IRn is a real n-space, the set of n-tuples x = (x1, ..., x n), 
y = (y1, ..., y n). If we dene the dot product as 
n 
(x, y) = xiyi 
i=1 
we get Euclidean n-space. The corresponding norms 
and distances in IRn are 
 n  2x = xi 
i=1 
 n 
(x, y) = x  y =  (xi  yi)2 . 
i=1</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>A Convex Function
1 0.5 0 0.5 1 1.5 2 2.5 3 3.5 4 
3 2 1 0 1 2
 3</text>
        </slide>
        <slide>
          <slideno>48</slideno>
          <text>Geometric intuition
The fact that I does not vanish in the interior of the
domain implies that the constrained minimum  x
must lie 
on the domains boundary (the level curve ( x) = m).
Therefore, at the point  x
the component of I along the
tangent to the curve  = m vanishes.
But since the tangent to  = m is orthogonal to , we
have that at the point ,  and I are parallel, or  x
I()  ().  x
  x</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Linear space
A set L of elements x, y, z, ... is a linear space if the fol
lowing three axioms are satised: 
1. Any two elements x, y  L uniquely determine a third 
element in x + y  L called the sum of x and y such 
that 
(a) x + y = y + x (commutativity) 
(b) (x + y) + z = x + (y + z) (associativity)
(c) An element 0  L exists for which x + 0 = x for all 
x  L 
(d) For every x  L there exists an element x  L 
with the property x + (x) = 0</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Linear functional
A functional, F, is a function that maps another function 
to a real-value 
F : f  IR.
A linear functional dened on a linear space L, satises the 
following two properties 
1. Additive: F(f + g) = F(f) + F(g) for all f, g  L
2. Homogeneous: F(f) = F(f)</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>About the primer
Goal To briey review concepts in functional analysis that
will be used throughout the course. The following 
concepts will be described 
1. Function spaces 
2. Metric spaces
3. Dense subsets
4. Linear spaces
5. Linear functionals 
The denitions and concepts come primarily from Introductory Real 
Analysis by Kolmogorov and Fomin (highly recommended).</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Function space
A function space is a space made of functions. Each 
function in the space can be thought of as a point. Ex
amples: 
1. C[a, b], the set of all real-valued continuous functions 
in the interval [ a, b]; 
2. L1[a, b], the set of all real-valued functions whose ab
solute value is integrable in the interval [ a, b]; 
3. L2[a, b], the set of all real-valued functions square inte
grable in the interval [ a, b] 
Note that the functions in 2 and 3 are not necessarily 
continuous!</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Metric space
By a metric space is meant a pair (X, ) consisting of a 
space X and a distance , a single-valued, nonnegative, 
real function (x, y) dened for all x, y  X which has the 
following three properties: 
1. (x, y) = 0 i x = y; 
2. (x, y) = (y, x); 
3. Triangle inequality: (x, z)  (x, y) + (y, z)</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Examples
1. The set of all rational points is dense in the real line.
2. The set of all polynomials with rational coecients is 
dense in C[a, b]. 
3. The RKHS induced by the gaussian kernel on [ a, b] in 
dense in L2[a, b] 
Note: A hypothesis space that is dense in L2 is a desired 
property of any approximation scheme.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>3. The set of all functions satisfying the criteria
f2(x)dx &lt;  
with distance 
(f1(x), f2(x)) = (f 1(x) f2(x))2dx 
is the metric space L2(IR). 
4. The set of all probability densities with Kullback-Leibler
divergence 
p1(x)(p1(x), p2(x)) = ln p1(x)dx p2(x)
is not a metric space. The divergence is not symmetric 
(p1(x), p2(x)) = (p2(x), p1(x)).</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Evaluation functionals in Hilbert space
The evaluation functional is not bounded in the familiar 
Hilbert space L2([0, 1]), no such M exists and in fact ele
ments of L2([0, 1]) are not even dened pointwise. 
0 1 2 3 4 5 6 f(x) 
0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2
x</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Incompleteness of C2 (cont.) 
Clearly,
 1/2  1/2  1/2 
(f(t)(t))2dt  (f(t)n(t))2dt + ( n(t)(t))2dt . 
Now the l.h.s. term is strictly positive, because f(t) is not 
continuous, while for n  we have 
(f(t)n(t))2dt 0. 
Therefore, contrary to what assumed, n cannot converge 
to  in the metric of C2.</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Separable
A metric space is said to be separable if it has a countable 
everywhere dense subset. 
Examples:
1. The spaces IR1, IRn , L2[a, b], and C[a, b] are all separa
ble. 
2. The set of real numbers is separable since the set of 
rational numbers is a countable subset of the reals and 
the set of rationals is is everywhere dense.</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>Local condition on the minimum
If the convex function f is dierentiable, its gradient f is 
null on the minimum x0. 
Even if the gradient does not exist, the subgradient f 
always exists. 
The subgradient of f in x is dened by
f(x) = {w IRn|x IRn, f(x ) f(x) + w (x x)}, 
On the minimum x0, it holds 
0 f(x0),</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Examples
1. The set of all real numbers with distance
(x, y) = |x  y|
is the metric space IR1.
2. The set of all ordered n-tuples
x = (x1, ..., x n)
of real numbers with distance
 n 
(x, y) =  (xi  yi)2 
i=1 
is the metric space IRn .</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Euclidean space
A Euclidean space is a linear (vector) space E in which a 
dot product is dened. A real valued function ( ,) is a dot 
product i f, g, h  E and   IR 
1. (f, g ) = (g, f ); 
2. (f + g, h) = (f, h) + (g, h ) and (f, g ) = (f, g); 
3. (f, f )  0 and (f, f ) = 0 i f = 0. 
A Euclidean space becomes a normed linear space when 
equipped with the norm 
f = (f, f ).</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Completion of a metric space
Given a metric space IR with closure IR, a complete metric 
  space IR is called a completion of IR if IR  IR and 
 IR = IR .
Examples
1. The space of real numbers is the completion of the 
space of rational numbers. 
2. L2is the completion of the functional space C2.</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>Riesz Representation Theorem
For every bounded linear functional F on a Hilbert space 
H, there is a unique v  Hsuch that 
F[x] = ( x, v)H, x  H</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Examples (cont.)
A norm in L1[a, b] can be established by dening 
 b 
f = |f(t)|dt. 
a 
The distance between two functions is then measured as
 b 
(f, g) = |g(t) f(t)|dt. 
a 
With this metric, L1[a, b] is denoted as L1.</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Examples
1. Let IRn be a real n-space with elements x = (x1, ..., x n), 
and a = (a1, ..., a n) be a xed element in IRn . Then 
n 
F(x) = aixi 
i=1 
is a linear functional 
2. The integral 
 b 
F[f(x)] = f(x)p(x)dx 
a 
is a linear functional 
3. Evaluation functional: another linear functional is the</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Measuring distances in a normed space
In a normed space N, the distance  between f and g, or 
a metric , can be dened as 
(f, g) = g f.
Note that f, g, h  N 
1. (f, g) = 0 i f = g. 
2. (f, g) = (g, f). 
3. (f, h)  (f, g) + (g, h).</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>2. Any number  and any element x  L uniquely deter
mine an element x  L called the product such that 
(a) (x) = (x)
(b) 1x = x 
3. Addition and multiplication follow two distributive laws 
(a)( + )x = x + x 
(b)(x + y) = x + y</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Incompleteness of C2 
Consider the sequence of functions ( n = 1, 2, ...)
 
 1 if  1  t &lt; 1/n  
n(t) = nt if  1/n  t &lt; 1/n   1 if 1/n  t  1 
and assume that n converges to a continuous function  
in the metric of C2. Let 
1 if  1  t &lt; 0 f(t) = 1 if 0  t  1</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>Evaluation functionals
A linear evaluation functional is a linear functional Ft that 
evaluates each function in the space at the point t, or 
Ft[f] = f(t) 
Ft[f + g] = f(t) + g(t). 
The functional is bounded if there exists a M s.t. 
|Ft[f]| = |f(t)|  MfHil t 
for all f where    Hil is the norm in the Hilbert space.</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>Convex and Non-convex sets
Convex Sets Non-Convex Sets</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Cauchy-Schwartz inequality
Let H be an Euclidean space. Then f, g H, it holds 
|(f, g)|   f g 
Sketch of the proof. The case f g is trivial, hence let 
us assume the opposite is true. For all x IR, 
20 &lt; (f + xg, f + xg) = x 2 g2+ 2x (f, g) + f, 
since the quadratic polynomial of x above has no zeroes, 
the discriminant  must be negative 
20 &gt; /4 = (f, g )2  f2 g.</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Hilbert space
A Hilbert space is a Euclidean space that is complete ,
separable , and generally innite-dimensional .
A Hilbert space is a set H of elements f, g, ... for which
1. H is a Euclidean space equipped with a scalar product
2. H is complete with respect to metric (f, g) = f  g
3. H is separable (contains a countable everywhere dense 
subset) 
4. (generally) H is innite-dimensional. 
l2 and L2 are examples of Hilbert spaces.</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>Convex sets
A set X  IRn is convex if 
x1, x2  X,   [0, 1], x1+ (1  )x2  X. 
A set is convex if, given any two points in the set, the line 
segment connecting them lies entirely inside the set.</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Orthogonal systems and bases
A set of nonzero vectors {x} in a Euclidean space E is 
said to be an orthogonal system if 
(x, x) = 0 for  =  
and an orthonormal system if 
(x, x) = 0 for  =  
(x, x) = 1 for  = . 
An orthogonal system {x} is called an orthogonal basis 
if it is complete (the smallest closed subspace containing 
{x} is the whole space E). A complete orthonormal sys
tem is called an orthonormal basis .</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>Lagrange multipliers technique
Lagrange multipliers technique allows the reduction of the 
constrained minimization problem 
Minimize I(x)
subject to (x)  m (for some m)
to the unconstrained minimization problem 
Minimize J(x) = I(x) + (x) (for some   0)</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Normed space
A normed space is a linear (vector) space N in which a 
norm is dened. A nonnegative function   is a norm i 
f, g N and  IR 
1. f 0 and f= 0 i f = 0;
2. f + g  f+ g; 
3. f= || f. 
Note, if all conditions are satised except f= 0 i f = 0 
then the space has a seminorm instead of a norm.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Math Camp 1: Functional analysis</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>Evaluation functionals in Hilbert space
In the following pictures the two functions have the same
norm but they are very dierent on sets of zero measure
function 1 function 2 
0.5 
1 
0 
1.5 
0.5 
2 1 
10 8 6 4 2 0 2 4 6 8 10 10 8 6 4 2 0 2 4 6 8 10f(x) 
x x 1 2.5 
2 
0.5 
1.5 
0 
1 f(x)0.5</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>Why We Like Convex Functions
Unconstrained convex functions (convex functions where 
the domain is all of IRn) are easy to minimize. Convex 
functions are dierentiable almost everywhere. Directional derivatives always exist. If we cannot improve our solution 
by moving locally, we are at the optimum. If we cannot 
nd a direction that improves our solution, we are at the 
optimum.</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>Why We Like Convex Sets
Convex functions over convex sets (a convex domain) are 
also easy to minimize. If the set and the functions are both 
convex, if we cannot nd a direction which we are able to 
move in which decreases the function, we are done. Local 
optima are global optima.</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>An important example of orthogonal bases in this space 
is the following set of functions 
2nt 2nt
1, cos , sin (n = 1, 2, ...).
b  a b  a</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Dense
A point x  IR is called a contact point of a set A  IR if 
every ball centered at x contains at least one point of A. 
The set of all contact points of a set A denoted by A is 
called the closure of A. 
Let A and B be subspaces of a metric space IR. A is said 
to be dense in B if B  A. In particular A is said to be 
everywhere dense in IR if = R. A</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Example: continuous functions
A norm in C[a, b] can be established by dening 
f = max |f(t)|. 
atb 
The distance between two functions is then measured as
(f, g) = max |g(t) f(t)|.
atb 
With this metric, C[a, b] is denoted as C.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Dirac delta function
t[f()] = f(t).
Which can be written
 b 
t[f()] = f(x)(x  t)dx. 
a 
4. Evaluation functional: a positive denite kernel in a 
RKHS 
Ft[f()] = ( Kt, f) = f(t). 
This is simply the reproducing property of the RKHS.</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>The simplest orthonormal basis in l2 consists of vectors
e1 = (1, 0, 0, 0, ...) 
e2 = (0, 1, 0, 0, ...) 
e3 = (0, 0, 1, 0, ...) 
e4 = (0, 0, 0, 1, ...) 
                               
there are an innite number of these bases.
3. The space C2[a, b] consisting of all continuous functions 
on [a, b] equipped with the dot product 
 b 
(f, g) = f(t)g(t)dt 
a 
is another example of Euclidean space.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>6. Norms and semi-norms of linear spaces
7. Euclidean spaces 
8. Orthogonality and bases 
9. Separable spaces 
10. Complete metric spaces 
11. Hilbert spaces 
12. Riesz representation theorem
13. Convex functions 
14. Lagrange multipliers</text>
        </slide>
        <slide>
          <slideno>49</slideno>
          <text>Geometric intuition (Cont)
We thus introduce a parameter   0, called Lagrange 
multiplier , and consider the problem of nding the uncon
strained minimum x of 
J(x) = I(x) + (x) 
as a function of . 
By setting J = 0, we actually look for the points where 
I and  are parallel. The idea is to nd all such points 
and then check which of them lie on the curve  = m.</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>A Non-Convex Function
0 1 2 3 4 5 6 7 8 9 10 
3 2 1 0 1 2
 3</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Examples (cont.)
A norm in C2[a, b] and L2[a, b] can be established by dening 
 b 1/2 
f = f2(t)dt . 
a 
The distance between two functions now becomes
 b 1/2 
(f, g) = (g (t) f(t))2dt . 
a 
With this metric, C2[a, b] and L2[a, b] are denoted as C2 
and L2 respectively.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Online Learning</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec12/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 12: Online Learning  
Andr ea Caponnetto, Sanmay Das  
 
Description 
To introduce the general setting of online learning. To descri be an online version of the 
RLS algorithm  and analyze its perfo rmance. To discuss converge nce results of the 
class ical Perceptron algo rithm . To introduce the ''experts' ' framework and prove m istake 
bounds in that fram ewor k. To show the re lationship between online learning and the 
theory of learning in games.  
Suggested Reading 
 Duda, Hart, Stork. Patte rn Classific ation.  Wiley Interscience 2001.  
 Smale, Yao. Online Lea rning Algorithms.  to appear on Foundations of 
Com putatio nal Ma thematic s.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Unsupervised Learning Techniques</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec7/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 7: Unsupervised Learning 
Techniques  
Andr ea Caponnetto  
 
Description 
To introduce som e methods for unsupervised learning: Gaussian Mixtures, K-Means, 
ISOMAP, HLLE, Laplacian Eigenm aps.  
Suggested Reading 
 Hastie, Tibshirani, Friedm an. The El ements o f Statis tical Learning: 
Data Minin g, Inference, and Prediction.  Springer 2001.  
 Tenenbaum , de Silva, Langford. A Global Geo metric Framew ork for 
Nonlinear Dimensiona lity Reduct ion. Science 22 Decem ber 2000; Vol. 
290. no. 5500, pp. 2319 - 2323.  
 Donoho, Grim es. Hessian eigenmap s: Locally linear embed ding 
techniques for high-dimensional data.  2003.  
 M. Belkin, P . Niyogi. Laplacian Eigenmaps for Dimensionality 
Reduction and Data Representation.  Neural Com putation, June 2003; 
15 (6):1373-1396.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Stability of Tikhonov Regularization</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec15/</lecture_pdf_url>
      <lectureno>15</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 15: S tability of Tikhonov 
Regularization 
Alex Rakhlin 
 
Description 
We briefly review the genera lization bounds of last lecture before turning to our m ain 
goal -- using the stability approach to  prove generalization bounds for Tikhonov 
regularization in RKHS. In order to apply the bounds, we  need to prove that Tikhonov 
regularization is uniformly stable with be ta=O(1/n), and also to bound the loss function. 
In the pro cess, we will g ain addition al insight into the m athem atics of  optim ization a nd 
RKHS.  
Suggested Reading 
 O. Bousquet and A. Elisseeff. Stability and Generaliz ation.  Journal of 
Machine Learning Research, to appear, 2002.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Reproducing Kernel Hilbert Spaces</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec3/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 3: Repr oducing Kernel Hilbert 
Spaces  
Andr ea Caponnetto  
 
Description 
We introduce a particularly useful fam ily of hypothesis spaces called Reproducing 
Kernel Hilbert Spaces (RKHS) that have a ke y role in the theory of learning. W e first 
provide the necessary background in functional analysis and then define RKHS using the 
reproducing property. W e then derive the ge neral solution of Ti khonov regularization in 
RKHS.  
Suggested Reading 
 Aronszajn. Theory of reproducing kernels.  Transactions of the 
American Mathem atical Society, 686, 337-404, 1950.  
 Cucker and Sm ale. On the mathematical foundations of learning.  
Bulletin of the Am erican Mathem atical Society, 2002.  
 Evgeniou, Pontil and Poggio. Regulariz ation Netw orks and Support 
Vector Machines  Advances in Computational Mathem atics, 2000.  
 Girosi, F. An Equivalence betw een Sparse Approximation and 
Support Vector Machines.  Neural Com putation, Vol. 10, 1455-1480, 
1998. (Appendix A)  
 Wahba, G. Spline Models for Obse rvational Da ta Serie s in Applied 
Mathem atics, Vol. 59, SIAM, 1990. (Chapter 1)</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Uniform Convergence for Classification
VC-dimension</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec17/</lecture_pdf_url>
      <lectureno>17</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 09:  
Sayan Mukherjee 
 
Description 
Necessary and sufficient requirem ents for uni form convergence for both real-valued loss 
functions and classificati on are introduced. VC entropy, VC dim ension, e mpirical 
covering numbers, and V-gamma dim ension are introduced and explained.  
Suggested Reading 
 N. Alon, S. Ben-David, N. Cesa -Bianchi, and D. Haussler Scale-sens itive 
Dimensions , Uniform Convergence, and Learnability. Journal of the 
ACM, 44(4):615-631, 1997.  
 V. N. Vapni k. The Nature of Statistical Learning Theory.  Springer, 
1995.  
 Cucker and Sm ale. On the mathematical foundations of learning.  
Bulletin of the Am erican Mathem atical Society, 2002.  
 V. N. Vapni k and A. Ya. Chervonenkis. Necessa ry and Sufficient 
conditions for the unifo rm converg ence of the means to th eir 
expectations.  Probability Theory and Its Applications,26, 532-553 1981.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Math Camp 1: Functional Analysis</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/mathcamp02/</lecture_pdf_url>
      <lectureno>&#160;</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>Probability measure
Probability measure is a positive measure  on the mea
surable space (, ) such that () = 1.
(, , ) is called a probability space .
A random variable is a measurable function X :   I R.
We can now dene probability of an event
P (event A) =  
{x : IA(x)= 1}.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Measure
A measure  is a function dened on a -algebra  over a 
set  with values in [0, ] such that 
1. The empty set has measure zero: () = 0
2. Countable additivity:	 if E1, E2, E3, ... is a countable 
sequence of pairwise disjoint sets in , 



&#13;
 
Ei 

= (Ei) 
i=1 i=1 
The triple (, , ) is called a measure space .</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Convergence
Recall that a sequence xn converges to the limit x 
xn x  
if for any  &gt; 0 there exists an N such that xn  x &lt;  for | |
n &gt; N .
We say that the sequence of random variables Xn con
verges to X in probability 
PXn X  
if 
P (Xn  X 0  )  | | 
for every  &gt; 0.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Math Camp 2: Probability Theory
Sasha Rakhlin</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Useful Probability Inequalities
If X is a sum of independent variables, then X is better 
approximated by I E(X) than predicted by Chebyshevs in
equality. In fact, its exponentially close! 
Hoedings inequality:
Let X1, ..., Xn be independent bounded random variables, 
ai  Xi  bi for any i  1...n. Let Sn = n then for i=1 Xi, 
any t &gt; 0, 
 
2t2  
Pr(Sn  I E(Sn) t)  2exp 
in 
=1(bi  ai)2| |</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Law of Large Numbers. Central Limit
Theorem
Weak LLN: if X1, X2, X3, ... is an innite sequence of i.i.d. 
random variables with nite variance 2, then 
X1+ + Xn PXn =    I EX1 n  
In other words, for any positive number , we have 
lim P Xn  I EX1  
= 0. n 
CLT: 
Xn    
lim Pr /n  z = (z) n 
where  is the cdf of N(0, 1).</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Playing with Expectations
Fix a function f, loss V , and dataset S = {z1, ..., zn}. The 
1empirical loss of f on this data is IS[f] = n n
i=1 V (f, zi). 
The expected error of f is I[f] = I EzV (f, z). What is the 
expected empirical error with respect to a draw of a set S 
of size n? 
1 n
I ESIS[f] =  
I ESV (f, zi) = I ESV (f, z1) n i=1</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Expectation and variance
Given a random variable X   the expectation is
I EX  Xd. 
Similarly the variance of the random variable 2(X) is 
var(X)  I E(X  I EX)2 .</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Useful Probability Inequalities
Chebyshevs inequality (second moment): if X is arbitrary 
random variable and t &gt; 0, 
var(X)
Pr(X  I E(X) . | |  t)  t2 
Cauchy-Schwarz inequality: if I E(X2) and I E(Y 2) are nite, 
then 
|I E(XY )
I E(X2)I E(Y 2). |</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Useful Probability Inequalities
Jensens inequality: if  is a convex function, then 
(I E( X))  I E((X)). 
For X  0, 
I E(X) =   
Pr(X  t)dt. 
0 
Markovs inequality: if X  0, then 
I E(X)Pr(X  t)  ,
t 
where t  0.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Lebesgue measure
The Lebesgue measure  is the unique complete translation-
invariant measure on a -algebra containing the intervals 
in I R such that ([0, 1]) = 1.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>-algebra
A -algebra  over a set  is a collection of subsets of  
that is closed under countable set operations: 
1.	  . 
2.	E   then so is the complement of E.
3. If	F is any countable collection of sets in , then the 
union of all the sets E in F is also in .</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Remark about sup 
Note that the statement 
1
n
with prob. at least 1  , f  F, I Ef | f (zi)|n i=1 
is dierent from the statement 
1 n
f  F,
with prob. at least 1  , I Ef | f (zi)|. n i=1 
The second statement is an instance of CLT, while the rst 
statement is more complicated to prove and only holds for 
some certain function classes.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Convergence in probability and almost
surely
Any event with probability 1 is said to happen almost 
surely. A sequence of real random variables Xn converges 
almost surely to a random variable X i 
P  
lim Xn = X 
= 1. n 
Convergence almost surely implies convergence in proba
bility.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>The Course at a Glance</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec1/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 1: The Course at a Glance 
Tomaso Poggio 
 
Description 
We introduce and m otivate the m ain them e of the course, setting the problem  of learning 
from exam ples as the pr oblem  of approxim ating a m ultivaria te function f rom sparse data. 
We present an overview of the theoretical pa rt of the course and sketch the connection 
between classical Regulariza tion Theory and its algorithm s -- including Support Vector 
Machines -- and Learnin g Theory, th e two cornerstones of the course. W e mention 
theoretical developm ents during the last fe w months that provide a new perspective on 
the foundations of the theory. W e briefly desc ribe several dif ferent applications ranging 
from  vision to com puter graphics , to finance and neuroscience.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>The Learning Problem in Perspective</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec2/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 2: The Learning Pr oblem In 
Perspective  
Tomaso Poggio  
 
Description 
We introduce the problem of learning from  sparse exam ples. We introduce key term s and 
concepts such as loss functions, em pirical ri sk, true risk, generalization error, hypothesis 
spaces, app roxim ation error and sam ple error. We introduce two key requirem ents on 
learning algorithm s: stability and consistenc y. We then describe T ikhonov regularization 
-- which in our course is the algorithm with the m agic.  
Suggested Reading 
 Cucker and Sm ale. On the mathematical foundations of learning.  
Bulletin of the Am erican Mathem atical Society, 2002.  
 Evgeniou, Pontil and Poggio. Regulariz ation Netw orks and Support 
Vector Machines  Advances in Computational Mathem atics, 2000.  
 Vapnik. The Nature of Statis tical Learning Theory.  Wiley &amp; Sons, 
1995.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Boosting and Bagging</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec10/</lecture_pdf_url>
      <lectureno>10</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 10:  
Sasha Rakhlin 
 
Description 
We introduce bagging and boosting algorithm s. We discuss the bias-variance tradeoff. 
The gradient descent view of boosting is introduced and a bound on the perform ance of 
Adaboost is proved.  
Suggested Reading 
 Yoav Freund and Robert E. Schapire. A short introduction to boosting.  
Journal of Japanese Society for Artificial Intellig ence, 14(5):771-780, 
Septem ber, 1999  
 Other boosting review articles here</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Support Vector Machines for Classification</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec5/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 5: Support Vector  Machines for  
Classification  
Ryan Rifkin  
 
Description 
We derive S VMs from  a geom etric perspective as well as the regularization perspective. 
Optim ality a nd duality is  introdu ced to dem onstrate how larg e SVMs can be solved. A  
comparison is m ade between SVMs and RLSC . We introduce Regularized Least Squares 
regression and classification.  
Suggested Reading 
 Rifkin. Everything Old Is New Aga in: A Fresh Look at Historical 
Approaches in Machine Learning.  MIT Ph.D. Thesis, 2002. &lt;  
 Evgeniou, Pontil and Poggio. Regulariz ation Netw orks and Support 
Vector Machines  Advances in Computational Mathem atics, 2000.  
 V. N. Vapni k. The Nature of Statistical Learning Theory.  Springer, 
1995.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Regression and Least-Squares Classification</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec4/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 4: Regr ession and Least-Squar es 
Classification  
Ryan Rifkin  
 
Description 
We introduce Regularized Least Squares regres sion and classification. We then introduce 
SVMs for classification and regression. A ll the above are in stances of Tikhonov 
regularization.  
Suggested Reading 
 Rifkin. Everything Old Is New Aga in: A Fresh Look at Historical 
Approaches in Machine Learning.  MIT Ph.D. Thesis, 2002.  
 Evgeniou, Pontil and Poggio. Regulariz ation Netw orks and Support 
Vector Machines  Advances in Computational Mathem atics, 2000.  
 V. N. Vapni k. The Nature of Statistical Learning Theory.  Springer, 
1995.</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Neuroscience</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/9-520-statistical-learning-theory-and-applications-spring-2006/resources/lec18/</lecture_pdf_url>
      <lectureno>18</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Lectur e 18: Thomas Serr e 
 
Supplementary reading list 
T. Serre. Learning a dictionary of shape-components in visual cortex: 
Comparison with neurons, humans and machines, PhD Thesis, May 2006  
T. Serre, L. Wolf and T. Poggio. Object recognition with features inspired by 
visual cortex. In: Proceedings of 2005 IEEE Computer So ciety Co nference on 
Computer Visio n and Pattern Recognitio n (CVPR 200 5), IEEE Computer Society 
Press, San Diego, June 2005  
T. Serre, M. Kouh, C. C adieu, U. Knoblich, G. Krei man and T. Poggio. A theory 
of object recognition: comput ations and circuits in the feedforward path of the 
ventral stream in primate visual cort ex, CBCL Paper #259/AI Memo #2005-036, 
Massachusetts Institute of Tec hnology, Cambridge, MA, December, 2005</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
