<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/</course_url>
    <course_title>Introduction to Convex Optimization</course_title>
    <course_tags>
      <list>Engineering </list>
      <list>Mathematics </list>
      <list>Systems Engineering </list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>Disciplined convex programming and CVX
Convex optimization solvers; modeling systems; disciplined convex programming; CVX.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec19/</lecture_pdf_url>
      <lectureno>19</lectureno>
      <slides>
        <slide>
          <slideno>16</slideno>
          <text>Objectives and constraints
 objective canbe 
 minimize(convex expression) 
 maximize(concave expression)
 omitted(feasibilityproblem)
constraints canbe  
 convex expression &lt;= concave expression 
 concave expression &gt;= convex expression 
 affine expression == affine expression 
 omitted(unconstrainedproblem) 
Disciplined Convex Programming and CVX 17</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>CVX
usesDCP  
 runs in Matlab, between the cvx_begin and cvx_end commands
 relies onSDPT3 orSeDuMi(LP/SOCP/SDP) solvers 
 refer to user guide, online help for more info 
 the CVX example library has more than a hundred examples 
Disciplined Convex Programming and CVX 7</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Some current modeling systems
	AMPL&amp;GAMS(proprietary) 
	developed in the 1980s, still widely used in traditional OR 
	no support for convex optimization 
	YALMIP(YetAnotherLMIParser) 
	rst matlab-based object-oriented modeling system with special
support for convex optimization
	can use many dierent solvers; can handle some nonconvex problems 
	CVXMOD/CVXOPT(in alpha) 
	python based, completely GPLed 
	cone and custom solvers 
CVX  
	matlab based, GPL, uses SDPT3/SeDuMi 
Disciplined Convex Programming and CVX 5</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Example
	optimal value of LP, f(c) = inf{cT x |Ax b}, is concave function of c 
	by duality(assuming feasibility of Ax b)we have 
f(c) = sup{T b |AT + c =0, 0} 
dene f in CVX as  
function cvx_optval = lp_opt_val(A,b,c)
cvx_begin
variable lambda(length(b));
maximize(-lambda*b);
subject to
A*lambda + c == 0; lambda &gt;= 0;
cvx_end
	in lp opt val(A,b,c) A, b must be constant; c can be ane 
expression 
Disciplined Convex Programming and CVX 25</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Disciplined convex programming
	describe objective and constraints using expressions formed from 
	a set ofbasic atoms(convex, concavefunctions) 
	a restricted set of operations or rules(thatpreserve convexity) 
	modeling system keeps track of ane, convex, concave expressions 
rules ensure that  
	expressions recognized as convex(concave) are convex(concave)
	but, some convex(concave) expressions are not recognized as convex 
(concave) 
	problems described using DCP are convex by construction 
Disciplined Convex Programming and CVX 6</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Transforming problems to standard form
	youve seen lots of tricks for transforming a problem into an equivalent 
one thathasastandardform(e.g.,LP,SDP) 
	these tricks greatly extend the applicability of standard solvers 
	writing code to carry out this transformation is often painful 
	modeling systems can partly automate this step 
Disciplined Convex Programming and CVX 3</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Dening functions via incompletely specied problems
	suppose f0,...,fm are convex in (x,z) 
	let (x) be optimal value of convex problem, with variable z and 
parameter x 
minimize	f0(x,z) 
subject to	fi(x,z) 0,i =1,...,m 
A1x + A2z = b 
	is a convex function  
	problem above sometimes called incompletely specied since x isnt 
(yet)given 
	an incompletely specied concave maximization problem denes a 
concavefunction 
Disciplined Convex Programming and CVX 20</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>CVX functions via incompletely specied problems
implementin cvx with 
function cvx_optval = phi(x)
cvx_begin
variable z;
minimize(f0(x, z))
subject to
f1(x, z) &lt;= 0; ...
A1*x + A2*z == b;
cvx_end
	function phi will work for numeric x (bysolving the problem) 
	function phi can also be used inside a CVX specication, wherever a 
convex function can be used 
Disciplined Convex Programming and CVX 21</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Variables and ane expressions
 declare variables with variable name[(dims)] [attributes] 
 variable x(3); 
 variable C(4,3); 
 variable S(3,3) symmetric; 
 variable D(3,3) diagonal; 
 variables y z; 
 form ane expressions 
 A = randn(4, 3); 
 variables x(3) y(4); 
 3*x + 4 
 A*x -y 
 x(2:3) 
 sum(x) 
Disciplined Convex Programming and CVX 10</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>A more complex example
f(x)= x + x1.5 + x2.5, with dom f = R+, is a convex, monotone  
increasing function
itsinverse g = f1 is concave, monotone increasing, with dom g = R+
  
 there is no closed form expression for g 
 g(y) is optimal value of problem 
maximize t 
subject to t+ + t1.5 + t2.5 
+ + y
(fory&lt; 0, this problem is infeasible, so optimal value is )
Disciplined Convex Programming and CVX 23</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Dening new functions
 can make a new function using existing atoms 
 example: the convex deadzone function 


 0, x ||1 
f(x) = max{|x|1,0}=  x 1, x&gt; 1
  1 x, x&lt; 1 
create a le deadzone.m with the code  
function y = deadzone(x)
y = max(abs(x) -1, 0)
deadzone makes sense both within and outside of CVX  
Disciplined Convex Programming and CVX 19</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>a typical modeling system Modeling systems
 automates most of the transformation to standard form; supports 
 declaring optimization variables 
 describing the objective function 
 describing the constraints 
 choosing(and conguring) the solver 
 when given a problem instance, calls the solver 
 interpretsand returnsthesolversstatus(optimal,infeasible, ...) 
 (when solved)transforms the solution back to original form 
Disciplined Convex Programming and CVX 4</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>CVX hints/warnings
	watch out for = (assignment) versus== (equalityconstraint) 
	X &gt;= 0, with matrix X, is an elementwise inequality 
	X &gt;= semidefinite(n) means: X is elementwise larger than some 
positive semidenite matrix(whichislikely not whatyou want) 
	writing subject to is unnecessary(but canlook nicer) 
	make sure you include brackets around objective functions 
	yes: minimize(c*x) 
	no: minimize c*x 
	doubleinequalitieslike 0 &lt;= x &lt;= 1 dont work; 
use 0 &lt;= x; x &lt;= 1 instead 
	log, exp, entropy-type functions not yet implemented in CVX 
Disciplined Convex Programming and CVX	 26</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>/bracketleftBigg /bracketrightBigg Using the semidenite cone
variables: X (symmetric matrix),z (vector),t (scalar) 
constants: A and B (matrices) 
 X == semidefinite(n) 
 means X Sn (orX 0)+ 
 A*X*A -X == B*semidefinite(n)*B 
 means Z 0 so that AXAT X = BZBT 
 [X z; z t] == semidefinite(n+1) 
Xz  means T 0 
zt 
Disciplined Convex Programming and CVX 16</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>More involved example
A = randn(5);
A = A*A;
cvx_begin
variable X(5, 5) symmetric;
variable y;
minimize(norm(X) -10*sqrt(y))
subject to
X -A == semidefinite(5);
X(2,5) == 2*y;
X(3,1) &gt;= 0.8;
y &lt;= 4;
cvx_end
Disciplined Convex Programming and CVX 18</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>EE364aReview 
Disciplined Convex Programming and CVX
	convex optimization solvers 
	modeling systems 
	disciplined convex programming 
CVX  
1</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Example: Constrained norm minimization
A = randn(5, 3);
b = randn(5, 1);
cvx_begin
variable x(3);
minimize(norm(A*x -b, 1))
subject to
-0.5 &lt;= x;
x &lt;= 0.3;
cvx_end
 between cvx_begin and cvx_end, x is a CVX variable 
 statement subject to does nothing, but can be added for readability
 inequalities are intepreted elementwise 
Disciplined Convex Programming and CVX 8</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>What CVX does
after cvx_end,CVX 
	transforms problem into an LP 
calls solver SDPT3  
 overwrites(object) x with(numeric) optimal value 
	assigns problem optimal value to cvx_optval 
	assignsproblem status(whichhereis Solved)to cvx_status 
(hadproblembeeninfeasible,cvx_status wouldbe Infeasible and x 
wouldbe NaN) 
Disciplined Convex Programming and CVX 9</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>/braceleftBigg Some functions
function meaning attributes 
norm(x, p)
 cvx xp 
2square(x)
 x cvx 
(x+)2square_pos(x)
 cvx, nondecr 
pos(x)
 cvx, nondecr x+ 
sum_largest(x,k)
 cvx, nondecr x[1] ++ x[k] 
sqrt(x)
 ccv, nondecr x (x 0) 
inv_pos(x)
 1/x (x&gt; 0) cvx, nonincr 
max(x)
 max{x1,...,xn} cvx, nondecr 
quad_over_lin(x,y)
x2/y (y&gt; 0) cvx, nonincr in y 
lambda_max(X)
 max(X) (X = XT ) cvx 
x2 , |x|1 huber(x)
 cvx 
2|x|1, |x|&gt; 1 
Disciplined Convex Programming and CVX 11</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Rejected examples
u,	v, x, y are scalar variables 
neither convex nor concave:  
	square(x) -square(y) 
	norm(A*x -y) -0.1*norm(x, 1) 
	rejected due to limited DCP ruleset: 
	sqrt(sum(square(x))) (is convex;could use norm(x)) 
	square(1 + x^2) (is convex;could use square_pos(1 + x^2), or 
1 + 2*pow_pos(x, 2) + pow_pos(x, 4)) 
Disciplined Convex Programming and CVX 14</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Composition rules
 can combine atoms using valid composition rules, e.g.: 
 a convex function of an ane function is convex 
 the negative of a convex function is concave 
 a convex, nondecreasing function of a convex function is convex 
 a concave, nondecreasing function of a concave function is concave
 for convex h, h(g1,...,gk) is recognized as convex if, for each i, 
 gi is ane, or 
 gi is convex and h is nondecreasing in its ith arg, or 
 gi is concave and h is nonincreasing in its ith arg 
 for concave h, h(g1,...,gk) is recognized as concave if, for each i, 
 gi is ane, or 
 gi is convex and h is nonincreasing in ith arg, or 
 gi is concave and h is nondecreasing in ith arg 
Disciplined Convex Programming and CVX 12</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>implement as 
function cvx_optval = g(y)
cvx_begin
variable t;
maximize(t)
subject to
pos(t) + pow_pos(t, 1.5) + pow_pos(t, 2.5) &lt;= y;
cvx_end
	use it as an ordinary function, as in g(14.3), or within CVX as a 
concavefunction: 
cvx_begin
variables x y;
minimize(quad_over_lin(x, y) + 4*x + 5*y)
subject to
g(x) + 2*g(y) &gt;= 2;
cvx_end
Disciplined Convex Programming and CVX 24</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Valid (recognized) examples
u, v, x, y are scalar variables; X is a symmetric 3 3 variable
convex:  
 norm(A*x -y) + 0.1*norm(x, 1) 
 quad_over_lin(u -v, 1 -square(v)) 
 lambda_max(2*X -4*eye(3)) 
 norm(2*X -3, fro) 
concave:  
 min(1 + 2*u, 1 -max(2, v)) 
 sqrt(v) -4.55*inv_pos(u -v) 
Disciplined Convex Programming and CVX 13</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Simple example: Two element max
	create le max2.m containing 
function cvx_optval = max2(x, y)
cvx_begin
variable t;
minimize(t)
subject to
x &lt;= t;
y &lt;= t;
cvx_end
	the constraints dene the epigraph of the max function 
	could add logic to return max(x,y) when x, y are numeric 
(otherwise, an LP is solved to evaluate the max oftwo numbers!) 
Disciplined Convex Programming and CVX 22</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Sets
	some constraints are more naturally expressed with convex sets 
	sets in CVX work by creating unnamed variables constrained to the set
	examples: 
	semidefinite(n) 
	nonnegative(n) 
	simplex(n) 
	lorentz(n) 
	semidefinite(n), say, returns an unnamed(symmetric matrix) 
variable that is constrained to be positive semidenite 
Disciplined Convex Programming and CVX 15</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Convex optimization solvers
LP solvers  
 lots available(GLPK,Excel,Matlabs linprog, ...)
cone solvers
  
 typically handle(combinations of) LP,SOCP,SDP cones 
 several available(SDPT3,SeDuMi,CSDP, ...) 
 general convex solvers 
 someavailable(CVXOPT,MOSEK, ...) 
 plus lots of special purpose or application specic solvers 
 could write your own 
(wellstudy, and write, solvers later in the quarter) 
Disciplined Convex Programming and CVX 2</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Statistical estimation
Maximum likelihood and MAP estimation; detector design; experiment design.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec07/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
7. Statistical estimation
 maximum likelihood estimation 
 optimaldetectordesign 
 experimentdesign 
71</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Linear measurements with IID noise
linear measurement model 
yi = aiT x + vi,i =1,...,m 
 x  Rn is vector of unknown parameters 
 vi is IID measurement noise, with density p(z) 
 Rm /producttextm T yi is measurement: y hasdensity px(y)= i=1 p(yi ai x) 
maximum likelihood estimate: any solution x of 
/summationtextmmaximize l(x)= i=1 log p(yi aiTx) 
(y is observed value) 
Statistical estimation 73</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>/bracketleftbigg	 /bracketrightbigg detection probability matrix:
/bracketleftbig/bracketrightbig 1 Pfp Pfn D	= Tp Tq = Pfp 1 Pfn 
	Pfp is probability of selecting hypothesis 2 if X isgeneratedby 
distribution1(falsepositive) 
	Pfn is probability of selecting hypothesis 1 if X isgeneratedby 
distribution2(false negative) 
multicriterion formulation of detector design 
minimize(w.r.t. R2 )	(Pfp,Pfn) = ((Tp)2,(Tq)1)+
subject to	 t1k + t2k =1,k =1,...,n 
tik  0,i =1,2,k =1,...,n 
variable T  R2n 
Statistical estimation	 78</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>/parenleftbigvector optimization formulation 
minimize(w.r.t. Sn ) E = /summationtextp T/parenrightbig1 
+ k=1 mkvkvk 
subject to mk  0,m1 +  + mp = m 
mk  Z 
 variables are mk (#vectors ai equal to vk) 
 dicult in general, due to integer constraint 
relaxed experiment design 
assume m  p, use k = mk/mas(continuous) real variable 
/summationtextp Tminimize(w.r.t. Sn ) E = (1/m) /parenleftbig
kvkv/parenrightbig1 
+ k=1 k 
subject to   0, 1T =1 
 common scalarizations: minimize logdet E, tr E, max(E),... 
 can add other convex constraints, e.g., bound experiment cost cT  B 
Statistical estimation 712</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>example (p= 20) 
1
0.5= 0.5 
2= 
design uses two vectors, on boundary of ellipse dened by optimal W
Statistical estimation 714</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>D-optimal design 
minimize logdet /parenleftbig/summationtext
kp 
=1 kvkvkT/parenrightbig1 
subject to   0, 1T =1 
interpretation: minimizes volume of condence ellipsoids 
dual problem 
maximize logdet W + nlog n 
subject to vkTWvk  1,k =1,...,p 
interpretation: {x |xTWx  1}is minimum volume ellipsoid centered at 
origin, that includes all test vectors vk 
complementary slackness: for , W primal and dual optimal 
k(1 vkTWvk)=0,k =1,...,p 
optimal experiment uses vectors vk on boundary of ellipsoid dened by W 
Statistical estimation 713</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Parametric distribution estimation
	distribution estimation problem: estimate probability density p(y) of a 
random variable from observed values 
	parametric distribution estimation: choose from a family of densities 
px(y), indexed by a parameter x 
maximum likelihood estimation 
maximize(over x) log px(y) 
	y is observed value 
	l(x) = log px(y) is called log-likelihood function 
	can add constraints x  C explicitly, or dene px(y)=0 for x  C 
	a convex optimization problem if log px(y) is concave in x for xed y 
Statistical estimation	 72</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>/summationdisplay /summationdisplay Logistic regression 
random variable y {0,1}withdistribution 
exp(aTu + b) p= prob(y = 1) = 1 + exp(aTu + b) 
 a, b areparameters; u  Rn are(observable) explanatory variables 
 estimation problem: estimate a, b from m observations (ui,yi) 
log-likelihood function (fory1 =  = yk =1, yk+1 =  = ym =0): 
  
kTm /productdisplay exp(aui + b) /productdisplay 1 l(a,b) = log   
1 + exp(aTui + b) 1 + exp(aTui + b)i=1 i=k+1 
k m 
= (a T ui + b)  log(1 + exp(a T ui + b)) 
i=1 i=1 
concavein a, b 
Statistical estimation 75</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>/braceleftbigg scalarization (with weight&gt; 0) 
minimize (Tp)2 + (Tq)1 
subject to t1k + t2k =1,tik  0,i =1,2,k =1,...,n 
an LP with a simple analytical solution 
(1,0) pk  qk(t1k,t2k)= (0,1) pk &lt;qk 
	a deterministic detector, given by a likelihood ratio test 
	if pk = qk for some k, any value 0  t1k  1, t1k =1 t2k is optimal 
(i.e., Pareto-optimal detectors include non-deterministic detectors) 
minimax detector 
minimize max{Pfp,Pfn}= max{(Tp)2,(Tq)1}
subject to t1k + t2k =1,tik  0,i =1,2,k =1,...,n
an LP; solution is usually not deterministic 
Statistical estimation	 79</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>/summationdisplay /summationdisplay 
/summationdisplay Experiment design
m linear measurements yi = aiTx + wi, i =1,...,m of unknown x  Rn 
 measurement errors wi areIID N(0,1) 
 ML(least-squares) estimateis 
/parenleftBigg/parenrightBigg1m m 
x= aia T
i yiai 
i=1 i=1 
 error e = xx has zero mean and covariance 
/parenleftBigg/parenrightBigg1m 
E = E ee T = aia T
i 
i=1 
condence ellipsoids are given by {x |(x x)TE1(x x)  } 
experiment design: choose ai {v1,...,vp}(a set of possible test 
vectors) to make E small 
Statistical estimation 711</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>example   
0.70 0.10
 0.20 0.10 
  P =  0.05 0.70  
0.05 0.10 
1 
0.8 
0.6 
0.4 
0.2 
0 
Pfp Pfn 
1 
2 
3 4 
0 0.2 0.4 0.6 0.8 1 
solutions1,2,3(and endpoints) aredeterministic; 4is minimaxdetector 
Statistical estimation 710</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>/parenleftBigg /parenleftBigg /parenrightBigg/parenrightBigg /summationdisplay derivation of dual ofpage713 
rst reformulate primal problem with new variable X: 
minimize logdet X1 
subject to X = /summationtext
kp 
=1 kvkvkT ,  0, 1T =1 
p 
L(X,,Z,z,) = log det X1+tr ZX  kvkvkT z T+(1T1) 
k=1 
 minimize over X by setting gradient to zero: X1 + Z =0 
 minimum over k is  unless vkTZvk zk +  =0 
dualproblem 
maximize n + log det Z  
subject to vkTZvk  , k =1,...,p 
change variable W = Z/, and optimize over  to get dual of page 713 
Statistical estimation 715</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>example (n =1, m = 50 measurements)
prob(y = 1)
1 
0.8 
0.6 
0.4 
0.2 
0 
0 2 4 6 8 10 u 
 circles show 50 points (ui,yi) 
 solid curve is ML estimate of p= exp(au + b)/(1 + exp(au + b)) 
Statistical estimation 76</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>(Binary) hypothesis testing
detection (hypothesis testing) problem 
given observation of a random variable X {1,...,n}, choose between: 
	hypothesis1: X wasgeneratedby distribution p=(p1,...,pn) 
	hypothesis2: X wasgeneratedby distribution q =(q1,...,qn) 
randomized detector 
	a nonnegative matrix T  R2n, with 1TT = 1T 
	if we observe X = k, we choose hypothesis 1 with probability t1k, 
hypothesis 2 with probability t2k 
	if all elements of T are 0 or 1, it is called a deterministic detector 
Statistical estimation	 77</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>/summationdisplay 
/summationdisplay 
/braceleftbigg examples 
 Gaussian noise N(0,2): p(z) = (22)1/2ez 2/(22), 
m m 1 Tl(x)=  log(22)  (ai x yi)2 
2 22 
i=1 
ML estimate is LS solution 
 Laplacian noise: p(z) = (1/(2a))e|z|/a, 
m1 l(x)= mlog(2a)  |aiT x yi| a i=1
ML estimate is 1-norm solution
 uniform noise on [a,a]: 
mlog(2a) |aiTx yi|a, i =1,...,m l(x)=  otherwise
ML estimate is any x with |aiTx yi|a
Statistical estimation 74</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Filter design and equalization
FIR filters; general and symmetric lowpass filter design; Chebyshev equalization; magnitude design via spectral factorization.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec09/</lecture_pdf_url>
      <lectureno>9</lectureno>
      <slides>
        <slide>
          <slideno>31</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>G() |G()|
110
010
110
0 0.5 1 1.5 2 2.5 3
 
0 0.5 1 1.5 2 2.5 3 3 2 1 0 1 2 3 

design 30th order FIR equalizer with G() ei10 
Filter design 21</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Chebychev equalizer design:
 minimize max G() e i10 
equalized system impulse response gg(t)
1 
0.8 
0.6 
0.4 
0.2 
0 
0.2 
0 5 10 15 20 25 30 35 
t 
Filter design 22</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>equalized frequency response magnitude |G|
110
010|Ge()|
110
0 0.5 1 1.5 2 2.5 3 
 
equalized frequency response phase  GGe()
1 
2 
3 
0 0.5 1 1.5 2 2.5 3 0 1 2 3  
 
Filter design 25</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>example 
 linear phase lter, n = 21 
 passband [0,0.12]; stopband [0.24,]
 max ripple 1 =1.012 (0.1dB) 
 design for maximum stopband attenuation
impulse response h: h(t)
0.2 
0.1 
0 
0.1 
0.2 
0 2 4 6 8 10 12 14 16 18 20 
t 
Filter design 14</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Linear phase lters 
suppose 
n =2N +1 is odd  
 impulse response is symmetric about midpoint: 
ht = hn1t,t =0,...,n 1 
then 
H()= h0 + h1e i ++ hn1e i(n1)  
= e iN (2h0 cos N +2h1 cos(N1) ++ hN)  
 iN = e H() 
Filter design 8</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Equalizer design example
unequalized system G is 10th order FIR:
g(t)
1 
0.8 
0.6 
0.4 
0.2 
0 
0.2 
0.4 
0 1 2 3 4 5 6 7 8 9 
t 
Filter design 20</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Filter magnitude specications
transfer function magnitude spec has form 
L() |H()|U(), [0,] 
where L,U : RR+ are given 
lower bound is not convex in lter coecients h  
 arises in many applications, e.g., audio, spectrum shaping 
 can change variables to solve via convex optimization 
Filter design 26</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>example: 1/f (pinknoise) lter(i.e., D()=1/),n = 50, 
log-Chebychev design over 0.01   |H()| 2
110
010
110
2101 010 10
 
optimal t: 0.5dB 
Filter design 31</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>term eiN represents N-sample delay  
 H() is real 
|H()|= |H()| 
 called linear phase lter( H() islinear exceptforjumps of ) 
Filter design 9</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Autocorrelation coecients
autocorrelation coecients associated with impulse response 
h =(h0,...,hn1) Rn are 
rt = 
hh+t 
 
(we takehk =0 for k&lt; 0 or k n) 
 rt = rt; rt =0 for |t|n 
 hence suces to specify r =(r0,...,rn1) Rn 
Filter design 27</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Spectral factorization
question: when is r Rn the autocorrelation coecients of some h Rn? 
answer: (spectral factorization theorem)if and only if R() 0 for all  
	spectral factorization condition is convex in r 
many algorithms for spectral factorization, i.e., nding an h s.t. 	
R()= |H()|2 
magnitude design via autocorrelation coecients: 
	use r as variable(instead of h) 
 add spectral factorization condition R() 0 for all  
 optimize over r 
	use spectral factorization to recover h 
Filter design 29</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Filter design 
FIR lters  
 Chebychev design 
 linear phase lter design 
 equalizer design 
 lter magnitude specications 
1</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>lter frequency response: H : RC
H()= h0 + h1e i ++ hn1e i(n1)  
n1	 n1
=
 ht cos t + i
ht sin t
t=0	 t=0 
(EEtradition uses j= 1 instead of i)  
	H is periodic and conjugate symmetric, so only need to know/specify 
for 0   
FIR lter design problem: choose h so it and H satisfy/optimize specs
Filter design 3</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>frequency response magnitude(i.e., H()):
 ||
110
010
0 0.5 1 1.5 2 2.5 3 |H()|
110
210
310
 
frequency responsephase(i.e.,  H()): 
3 
2 H()
0 0.5 1 1.5 2 2.5 3 3 2 1 0 1 
  
Filter design 5</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Linear phase lowpass lter design 
 sample frequency 
	can assume wlog H(0) &gt; 0, so ripple spec is 
1/1 H(k) 1 
design for maximum stopband attenuation: 
minimize	2 
subject to	1/1 H(k) 1, 0 k p 
2 H(k) 2,s k  
Filter design 12</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Lowpass lter specications
1
1/1
2 
p s  
 
idea: 
 pass frequencies in passband [0,p] 
 block frequencies in stopband [s,] 
Filter design 10</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>log-Chebychev magnitude design
choose h to minimize 
max 20 log10 H()20 log10 D()
 | ||	 | 
	D is desired transfer function magnitude 
(D() &gt; 0 for all ) 
	nd minimaxlogarithmic(dB) t 
reformulate as 
minimize t 
subject to D()2/tR() tD()2 , 0   
	convex in variables r, t 
	constraint includes spectral factorization condition 
Filter design 30</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>FIR lters 
nite impulse response(FIR) lter: 
n1
y(t)= 
hu(t ),t Z 
=0 
(sequence)u : ZR is input signal  
(sequence)y : ZR is output signal  
 hi are called lter coecients 
 n is lter order or length 
Filter design 2</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Chebychev design via SOCP: 
minimize t 
subject to A(k)hb(k)t, k =1,...,m 
where 
1 cos k cos(n1)k  
A(k) = 
0 sin k sin(n1)k  

Hdes(k)  
b(k) = Hdes(k) 
 
h0  
. h =  .. 
hn1 
Filter design 7</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>passband ripple 1 is given 
 an LP in variables h, 2 
 known(and used) since1960s 
 can add other constraints, e.g., |hi| 
variations and extensions: 
 x 2, minimize 1 (convex, but not LP) 
 x 1 and 2, minimize s (quasiconvex) 
 x 1 and 2, minimize order n (quasiconvex) 
Filter design 13</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>extensions: 
 canimpose(convex)	constraints 
	can mix time-and frequency-domain specications 
	can equalize multiple systems, i.e., choose H so 
G(k)H Gdes,k =1,...,K 
	can equalize multi-input multi-output systems 
(i.e., G and H are matrices) 
	extends to multidimensional systems, e.g., image processing 
Filter design 19</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>time-domain equalization: optimize impulse response gof equalized 
system 
e.g., with Gdes()= eiD , 

1 t = D gdes(t)= 0 t = D 
sample design: 
minimize maxtg(t) =D || 
subject to g(D)=1
an LP  
 can use 
tg(t)2 or 
t|g(t)|=D =D 
Filter design 18</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>frequency response magnitude(i.e., H()):
 ||
110
010
0 0.5 1 1.5 2 2.5 3 |H()|
110
210
310
 
frequency responsephase(i.e.,  H()): 
0 0.5 1 1.5 2 2.5 3 3 2 1 0 1 2 3 
  H()
Filter design 15</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Fourier transform of autocorrelation coecients is
n1 
 =1 t
alwayshave R()0 forall    
canexpressmagnitudespecicationas  i
 2
R()=
 2rt cos t = H()
|
|
 e
r = r0 +
L()2 R() U()2 , [0,] 
... convex in r 
Filter design 28</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Chebychev design
minimize max H() Hdes()
[0,]|	 | 
	h is optimization variable 
Hdes : RC is(given) desired transfer function 	 
	convex problem 
	can add constraints, e.g., |hi|1 
sample(discretize) frequency: 
minimize max 
k=1,...,m |H(k) Hdes(k)| 
	sample points 0 1 &lt;  &lt;m  are xed(e.g., k = k/m) 
	m n (common rule-of-thumb: m = 15n) 
	yields approximation(relaxation) ofproblem above 
Filter design 6</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>example: (lowpass)FIR lter, order n = 21
impulse response h:
h(t)
0.2 
0.1 
0 
0.1 
0.2 
0 2 4 6 8 10 12 14 16 18 20
t 
Filter design 4</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>equalized frequency response magnitude |G|
110|Ge()|
010
110
0 0.5 1 1.5 2 2.5 3 
 
equalized frequency response phase  G
3 
2 
0 0.5 1 1.5 2 2.5 3  Ge()
 1 
0 
1 
2 
3 
 
Filter design 23</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Chebychev equalizer design: 
minimize max G() Gdes()
[0,] 
convex; SOCP after sampling frequency 
Filter design 17</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Equalizer design
G() H() 
equalization: given 
 G (unequalized frequencyresponse) 
	Gdes (desired frequencyresponse) 
design(FIR equalizer) H so that G= GH Gdes 
common choice: Gdes()= eiD (delay)  
i.e., equalizationisdeconvolution(up todelay) 
 can add constraints on H, e.g., limits on |hi|or max |H()| 
Filter design 16</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>time-domain equalizer design:
minimize max g(t)
=10 t|| 
equalized system impulse response gg(t)
1 
0.8 
0.6 
0.4 
0.2 
0 
0.2 
0 5 10 15 20 25 30 35 
t 
Filter design 24</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>specications: 
	maximum passband ripple (20 log10 1 in dB): 
1/1 |H()|1, 0  p 
	minimum stopband attenuation (20 log10 2 in dB): 
|H()|2,s   
Filter design 11</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>l1 methods for convex-cardinality problems (cont.)
Total variation reconstruction; iterated re-weighted l1; rank minimization and dual spectral norm heuristic.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec12/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>Example(6.3.3inBVbook) 
signal x  R2000 and corrupted signal xcor  R2000 
2 
1 
0 
1 2 
0 500 1000 1500 2000 xcor x
2
1
0
1
2 0 500 1000 1500 2000 
i
Prof.S.Boyd,EE364b,StanfordUniversity 2</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>for  =0.1357 (knee ofthe tradeo curve) we nd 
 /negationslash range(X),range(FFT ) =6.8 
 ddiag(D)/diag(D) =0.07 
 i.e., we have recovered the factor model from the empirical covariance
Prof.S.Boyd,EE364b,StanfordUniversity 20</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>8 10 Rank(X)
Trace approximation results 
216 10
14 
012 10 i (X) 
210
6 
44 10
2 2 1 0 2 1 010 10 10 10 10 10
 
Prof.S.Boyd,EE364b,StanfordUniversity 19</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Total variation reconstruction
	t xcor with piecewise constant x, no more than k jumps 
	convex-cardinality problem: minimize xxcor2 subjectto 
card(Dx) k (D is rst order dierence matrix) 
	heuristic: minimize xxcor2 + Dx1; vary  to adjust number of 
jumps 
	Dx1 is total variation of signal x
	method is called total variation reconstruction 
	unlike 2 based reconstruction, TVR lters high frequency noise out 
whilepreserving sharpjumps 
Prof.S.Boyd,EE364b,StanfordUniversity 1</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>TV heuristic and iterated TV heuristic
left: TV with  =10; right: iteratedTV, 5 iterations,  =0.005
1 
0.8 
0.6 
0.4 
0.2 
0 
0.2 
0.4 
0.6 
0.8 
1 1 
0.8 
0.6 
0.4 
0.2 
0 
0.2 
0.4 
0.6 
0.8 
1 
50 100 150 200 250 300 50 100 150 200 250 300 
t t 
Prof.S.Boyd,EE364b,StanfordUniversity 14</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>e.g., via KL divergence 
C = {|logdet(1/2  + Tr(1/2  n  } 1/2	1/2)
 traceheuristic: 
minimize	Tr X 
subjectto	X  0,D  0 diagonal 
X + D C 
with	variables d  Rn , X  Sn 
Prof.S.Boyd,EE364b,StanfordUniversity 17</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Factor modeling
	given matrix   Sn 
+, nd approximation of form = FFT + D, where 
F  Rnr , D is diagonal nonnegative 
	gives underlying factor model(with r factors) 
x = Fz + v, v N(0,D),z N(0,I) 
	model with fewest factors: 
minimize Rank X 
subjectto X  0,D  0 diagonal 
X + D C 
with variables D, X  Sn
C is convex set of acceptable approximations to 
Prof.S.Boyd,EE364b,StanfordUniversity 16</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>TV reconstruction
original TV reconstruction 
1.5 1.5 
1 1 
0.5 0.5 
0 0 
0.5 0.5
0 0
5 5 
10 30 10 30 
15 25 15 25 
20 20 20 20 
15 1525 25 
10 10 30 305 5 
35 35 
. . . not bad for 8 more variables than measurements! 
Prof.S.Boyd,EE364b,StanfordUniversity 6</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Sparse solution of linear inequalities
	minimize card(x)overpolyhedron {x |Ax  b}, A  R10050 
	1 heuristic nds x  R50 with card(x)=44 
	iterated weighted 1 heuristic nds x with card(x)=36 
(globalsolution, via branch &amp; bound, is card(x)=32) 
1 2 3 4 5 6 
iteration 
Prof.S.Boyd,EE364b,StanfordUniversity 0 10 20 30 40 50 card(x) 
iterated 1 1 
11</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Total variation reconstruction 
for three values of  
2 0 2 x
0 500 1000 1500 2000
2 0 2 x
0 500 1000 1500 2000
0 500 1000 1500 2000
i
2 0 2 x 
Prof.S.Boyd,EE364b,StanfordUniversity 3</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Example 
 x = Fz + v, z N(0,I), v N(0,D), D diagonal; F  R203 
  is empirical covariance matrix from N =3000 samples 
	set of acceptable approximations 
C = {|1/2()1/2 } 
 traceheuristic 
minimize Tr X 
subjectto X  0,d  0 
1/2(X + diag(d))1/2  
Prof.S.Boyd,EE364b,StanfordUniversity 18</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Iterated weighted 1 heuristic 
	to minimize card(x)over x C 
w	:= 1 
repeat
minimize diag(w)x1 over x C
wi := 1/(+ |xi|)
	rstiterationisbasic 1 heuristic 
	increases relative weight on small xi 
	typically converges in 5 or fewer steps 
	oftengives a modestimprovement(i.e., reduction in card(x))over 
basic 1 heuristic 
Prof.S.Boyd,EE364b,StanfordUniversity 8</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Interpretation
	wlog we can take x  0 (bywriting x = x+ x, x+,x  0, and 
replacing card(x)with card(x+)+card(x)) 
	well use approximation card(z) log(1+z/), where &gt; 0, z  R+ 
	using this approximation, weget(nonconvex) problem 
minimize in 
=1 log(1+xi/) 
subjectto x C,x  0 
	well nd a local solution by linearizing objective at current point, 
n n	 n (k)    xi xlog(1+xi/) log(1+x(
ik)/)+ (i
k)+ xi=1 i=1	 i=1 i 
Prof.S.Boyd,EE364b,StanfordUniversity 9</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>and solving resulting convex problem 
minimize 
in 
=1 wixi 
subjectto x C,x  0 
with wi =1/(+ xi), to get next iterate 
 repeat until convergence to get a local solution 
Prof.S.Boyd,EE364b,StanfordUniversity 10</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Example: 2D total variation reconstruction
 x  Rn are values of pixels on N  N grid(N =31, so n =961) 
 assumption: x has relatively fewbig changesin value(i.e.,boundaries)
 wehave m =120 linear measurements, y = Fx (Fij N(0,1)) 
 as convex-cardinality problem: 
minimize card(xi,j xi+1,j)+card(xi,j xi,j+1) 
subjectto y = Fx 
 1 heuristic(objectiveis a2D version of total variation) 
minimize |xi,j xi+1,j|+ |xi,j xi,j+1| 
subjectto y = Fx 
Prof.S.Boyd,EE364b,StanfordUniversity 5</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>1-normMethodsfor
Convex-CardinalityProblems
PartII 
 total variation 
 iterated weighted 1 heuristic 
 matrix rank constraints 
Prof.S.Boyd,EE364b,StanfordUniversity</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Time series and true coecients
y(t)
3 
1 
0.82 
0.6 
0.41 
0.2 
00
0.2
 b(t) 
0.4 1 a(t)0.6 
2 0.8 
1 
3 0 50 100 150 200 250 300 50 100 150 200 250 300 
t t 
Prof.S.Boyd,EE364b,StanfordUniversity 13</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Extension to matrices
	Rank is natural analog of card for matrices 
	convex-rank problem: convex, except for Rank in objective or 
constraints 
	rank problem reduces to card problem when matrices are diagonal:
Rank(diag(x))= card(x) 
	analog of 1 heuristic: use nuclear norm, X = i i(X) 
(sum ofsingular values; dual of spectral norm) 
	for X  0, reduces to Tr X (forx  0, x1 reducesto 1T x) 
Prof.S.Boyd,EE364b,StanfordUniversity 15</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>2 reconstruction 
original 2 reconstruction 
1.5 1.5 
1 1 
0.5 0.5 
0 0 
0.5 0.5 
0 0 
5 5 
10 30 10 30 
15 25 15 25 
20 20 20 20 
25 15 25 15 
10 10 30 5 30 5 
35 35 
. . . this is what youd expect with 8 more variables than measurements
Prof.S.Boyd,EE364b,StanfordUniversity 7</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>2 reconstruction 
for three values of  
2
x x x
0
2 0 500 1000 1500 2000 
2
0
2 0 500 1000 1500 2000 
2 
0 
2 0 500 1000 1500 2000 
i
Prof.S.Boyd,EE364b,StanfordUniversity 4</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Detecting changes in time series model
	AR(2) scalar time-series model 
y(t +2) = a(t)y(t +1)+ b(t)y(t)+v(t),v(t)IID N(0,0.52) 
 assumption: a(t)and b(t)are piecewise constant, change infrequently
 given y(t), t =1,...,T , estimate a(t), b(t), t =1,...,T 2 
 heuristic: minimize over variables a(t), b(t), t =1,...,T 1 
T 2(y(t +2) a(t)y(t +1) b(t)y(t))2 
t=1 T 2 + t=1 (|a(t +1) a(t)|+ |b(t +1) b(t)|) 
 vary	 to trade o t versus number of changes in a, b 
Prof.S.Boyd,EE364b,StanfordUniversity 12</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Introduction
Mathematical optimization; least-squares and linear programming; convex optimization; course goals and topics; nonlinear optimization.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec01/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>1</slideno>
          <text>Mathematical optimization
(mathematical) optimization problem 
minimize f0(x)
subject to fi(x)  bi,i =1,...,m
 x =(x1,...,xn): optimization variables 
 f0 : Rn  R: objective function 
 fi : Rn  R, i =1,...,m: constraint functions 
optimal solution x has smallest value of f0 among all vectors that 
satisfy the constraints 
Introduction 12</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Course goals and topics
goals 
1. recognize/formulateproblems(such as theilluminationproblem) as 
convex optimization problems 
2. develop codeforproblems of moderate size(1000lamps,5000patches) 
3. characterizeoptimal solution(optimalpowerdistribution),givelimitsof 
performance, etc. 
topics 
1. convex sets, functions, optimization problems 
2. examples and applications 
3. algorithms 
Introduction 113</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Solving optimization problems
general optimization problem 
	very dicult to solve 
	methods involve some compromise, e.g., very long computation time, or 
not always nding the solution 
exceptions: certain problem classes can be solved eciently and reliably 
	least-squaresproblems 
	linearprogrammingproblems 
	convex optimization problems 
Introduction	 14</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>additional constraints: doesadding 1or2belowcomplicate theproblem? 
1.	no more than half of total power is in any 10 lamps 
2.	nomore thanhalf of thelampsareon(pj &gt; 0) 
	answer:with(1),still easy tosolve; with(2),extremely dicult 
	moral: (untrained) intuition doesnt always work; without the proper 
background very easy problems can appear quite similar to very dicult 
problems 
Introduction	 112</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Example 
m lampsilluminating n (small, at) patches 
intensity Ik atpatch k depends linearly on lamp powers pj: 
m 
2Ik =  
akjpj,akj = rkj max{cos kj,0} 
j=1 
problem: achieve desired illumination Ides with bounded lamp powers 
minimize maxk=1,...,n |log Ik log Ides| 
subject to 0  pj  pmax,j=1,...,m lamp power pj 
illumination Ik rkj 
kj 
Introduction 19</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Brief history of convex optimization
theory(convex analysis): ca19001970 
algorithms 
	1947: simplexalgorithmforlinearprogramming(Dantzig) 
	1960s:early interior-pointmethods(Fiacco&amp;McCormick,Dikin, ...) 
	1970s: ellipsoid method and other subgradient methods 
	1980s: polynomial-time interior-point methods for linear programming 
(Karmarkar1984) 
	late 1980snow: polynomial-time interior-point methods for nonlinear 
convex optimization(Nesterov&amp;Nemirovski1994) 
applications 
	before 1990: mostly in operations research; few in engineering 
	since1990: many newapplicationsinengineering(control,signal 
processing,communications,circuitdesign, ...); newproblemclasses 
(semidenite andsecond-order cone programming, robust optimization) 
Introduction	 115</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079  / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Linearprogramming
minimize cTx 
subject to aiTx  bi,i =1,...,m 
solvinglinearprograms 
	no analytical formula for solution 
	reliable and ecient algorithms and software 
	computation time proportional to n2m if m  n; less with structure 
	a mature technology 
usinglinearprogramming 
	not as easy to recognize as least-squares problems 
	a few standard tricks used to convert problems into linear programs 
(e.g.,problemsinvolving 1 -or -norms,piecewise-linearfunctions) 
Introduction	 16</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Least-squares
minimize Axb2
2 
solvingleast-squaresproblems 
	analytical solution: x  =(ATA)1ATb 
	reliable and ecient algorithms and software 
	computation time proportional to n2k (A  Rkn);less if structured 
	a mature technology 
usingleast-squares 
	least-squares problems are easy to recognize 
	afewstandard techniquesincreaseexibility(e.g., including weights, 
adding regularization terms) 
Introduction	 15</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
1. Introduction
 mathematical optimization 
 least-squares and linear programming 
 convex optimization 
 example 
 course goals and topics 
 nonlinear optimization 
 brief history of convex optimization 
11</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>solving convex optimization problems 
	no analytical solution 
	reliable and ecient algorithms 
	computation time(roughly) proportional to max{n3,n2m,F}, where F 
is cost of evaluating fis and their rst and second derivatives 
	almost a technology 
using convex optimization 
	often dicult to recognize 
	many tricks for transforming problems into convex form 
	surprisingly many problems can be solved via convex optimization 
Introduction	 18</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Convex optimization problem
minimize f0(x)
subject to fi(x)  bi,i =1,...,m
 objective and constraint functions are convex: 
fi(x+ y)  fi(x)+ fi(y)
if +  =1,   0,   0
 includes least-squares problems and linear programs as special cases 
Introduction 17</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>5. use convex optimization: problem is equivalent to 
minimize f0(p) = maxk=1,...,n h(Ik/Ides) 
subject to 0  pj  pmax,j=1,...,m 
with h(u) = max{u,1/u} h(u)
5
4
3
2
1
0
0 1 2 3 4 u
f0 is convex because maximum of convex functions is convex 
exact solution obtained with eort  modestfactor  least-squares eort 
Introduction 111</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Examples 
portfolio optimization 
 variables: amounts invested in dierent assets 
 constraints: budget, max./min. investment per asset, minimum return 
 objective: overall risk or return variance 
device sizing in electronic circuits 
 variables: device widths and lengths 
 constraints: manufacturing limits, timing requirements, maximum area 
 objective: power consumption 
data tting 
 variables: model parameters 
 constraints:priorinformation,parameterlimits 
 objective: measure of mist or prediction error 
Introduction 13</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>how to solve? 
1. use uniform power: pj = p, vary p 
2. use least-squares: 
minimize 
kn 
=1(Ik Ides)2 
round pj if pj &gt;pmax or pj &lt; 0 
3. use weighted least-squares: 
minimize n
k=1(Ik Ides)2 + m
j=1 wj(pj pmax/2)2 
iteratively adjust weights wj until 0  pj  pmax 
4. use linear programming: 
minimize maxk=1,...,n |Ik Ides| 
subject to 0  pj  pmax,j=1,...,m 
which can be solved via linear programming 
of course these are approximate(suboptimal) solutions 
Introduction 110</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Nonlinear optimization
traditional techniques for general nonconvex problems involve compromises 
local optimization methods (nonlinearprogramming) 
 nd a point that minimizes f0 among feasible points near it 
 fast, can handle large problems 
 requireinitialguess 
 providenoinformationaboutdistance to(global) optimum 
global optimization methods 
 nd the(global) solution 
 worst-case complexity grows exponentially with problem size 
these algorithms are often based on solving convex subproblems 
Introduction 114</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Numerical linear algebra background
Basic linear algebra operations; factor-solve methods; sparse matrix methods.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec15/</lecture_pdf_url>
      <lectureno>15</lectureno>
      <slides>
        <slide>
          <slideno>15</slideno>
          <text>Underdetermined linear equations 
if A  Rpn with p&lt;n, rank A = p, 
{x |Ax = b}= {Fz +x |z  Rnp} 
	xis(any) particular solution 
	columns of F  Rn(np) span nullspace of A 
	there exist several numerical methods for computing F 
(QRfactorization,rectangularLUfactorization, ...) 
Numerical linear algebra background	 916</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>vector-vector operations (x, y  Rn) 
 innerproduct xTy: 2n 1 ops(or 2n if n islarge) 
 sum x + y, scalar multiplication x: n ops 
matrix-vectorproduct y = Ax with A  Rmn 
 m(2n 1) ops(or 2mn if n large) 
 2N if A is sparse with N nonzero elements 
 2p(n + m) if A is given as A = UVT , U  Rmp , V  Rnp 
matrix-matrixproduct C = AB with A  Rmn , B  Rnp 
 mp(2n 1) ops(or 2mnp if n large) 
 lessif A and/or B are sparse 
 (1/2)m(m + 1)(2n 1)  m2n if m = p and C symmetric 
Numerical linear algebra background 93</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>example: A diagonal, B,C dense 
	method 1: form D = A+ BC, then solve Dx = b 
cost: (2/3)n3 +2pn2 
	method2(viamatrixinversionlemma): solve 
(I + CA1B)y = CA1b, (2) 
then compute x = A1bA1By
total costisdominatedby(2): 2p2n + (2/3)p3 (i.e.,linearin n)
Numerical linear algebra background	 915</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>sparseLUfactorization
A = P1LUP2 
	adding permutation matrix P2 oers possibility of sparser L, U (hence, 
cheaper factor and solve steps) 
	P1 and P2 chosen(heuristically) toyield sparse L, U 
	choice of P1 and P2 depends on sparsity pattern and values of A 
	cost is usually much less than (2/3)n3; exact value depends in a 
complicated way on n, number of zeros in A, sparsity pattern 
Numerical linear algebra background	 98</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>LUfactorization 
every nonsingular matrix A can be factored as 
A = PLU 
with P a permutation matrix, L lower triangular, U upper triangular 
cost: (2/3)n3 ops 
Solving linear equations by LU factorization. 
given a set of linear equations Ax = b, with A nonsingular. 
1. LU factorization. Factor A as A = PLU ((2/3)n 3 ops). 
2. Permutation. Solve Pz1= b (0 ops). 
3. Forward substitution. Solve Lz2= z1 (n 2 ops). 
4. Backward substitution. Solve Ux = z2 (n 2 ops). 
cost: (2/3)n3 +2n2  (2/3)n3 forlarge n 
Numerical linear algebra background 97</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Structured matrix plus low rank term
(A+ BC)x = b 
 A  Rnn , B  Rnp , C  Rpn 
 assume A has structure(Ax = b easy to solve) 
rst write as    
AB x b = C I y 0 
now apply block elimination: solve 
(I + CA1B)y = CA1b, 
then solve Ax = bBy 
this proves the matrixinversionlemma: if A and A+ BC nonsingular, 
(A+ BC)1 = A1 A1B(I + CA1B)1CA1
Numerical linear algebra background 914</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>sparseCholeskyfactorization 
A = PLLTPT 
	adding permutation matrix P oers possibility of sparser L 
	P chosen(heuristically) toyield sparse L 
	choice of P only depends on sparsity pattern of A (unlike sparse LU) 
	cost is usually much less than (1/3)n3; exact value depends in a 
complicated way on n, number of zeros in A, sparsity pattern 
Numerical linear algebra background	 910</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>orthogonal matrices: A1 = AT 
	2n2 ops to compute x = ATb forgeneral A 
	less with structure, e.g.,if A = I 2uuT with u2 =1, we can 
compute x = ATb = b2(uTb)u in 4n ops 
permutation matrices: 
1 j= i aij = 0 otherwise 
where  =(1,2,...,n) is a permutation of (1,2,...,n) 
	interpretation: Ax =(x1,...,xn) 
 satises A1 = AT, hence cost of solving Ax = b is 0 ops 
example: 
    
0 1 0 0 0 1 
A =  0 0 1  , A1 = AT =  1 0 0  
1 0 0 0 1 0 
Numerical linear algebra background	 95</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Choleskyfactorization 
everypositivedenite A can be factored as 
A = LLT 
with L lower triangular 
cost: (1/3)n3 ops 
Solving linear equations by Cholesky factorization. 
given a set of linear equations Ax = b, with A  Sn .++
1. Cholesky factorization. Factor A as A = LLT ((1/3)n 3 ops). 
2. Forward substitution. Solve Lz1= b (n 2 ops). 
3. Backward substitution. Solve LTx = z1 (n 2 ops). 
cost: (1/3)n3 +2n2  (1/3)n3 forlarge n 
Numerical linear algebra background 99</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>The factor-solve method for solving Ax = b
	factor A as aproduct of simple matrices(usually 2 or3): 
A = A1A2  Ak 
(Ai diagonal, upper or lower triangular, etc)
A1
	compute x = A1b = A
k 1  A
21 
1 b by solving k easy equations 
A1x1 = b, A2x2 = x1, ..., Akx = xk1 
cost of factorization step usually dominates cost of solve step 
equations with multiple righthand sides 
Ax1 = b1, Ax2 = b2, ..., Axm = bm 
cost: one factorization plus m solves 
Numerical linear algebra background	 96</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>dominant terms in op count 
	step 1: f + n2s (f is cost of factoring A11; s is cost of solve step) 
	step 2: 2n22n1 (cost dominated by product ofA21 and A1A12)11 
 step 3: (2/3)n23 
total: f + n2s +2n22n1 + (2/3)n23 
examples 
	general A11 (f = (2/3)n13 , s =2n12): no gain over standardmethod 
#ops = (2/3)n 3
1 +2n 2
1n2 +2n 2
2n1 + (2/3)n 3
2 = (2/3)(n1 + n2)3 
	block elimination is useful for structured A11 (f  n13) 
for example,diagonal(f =0, s = n1): #ops 2n22n1 + (2/3)n3
2 
Numerical linear algebra background	 913</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Equations with structured sub-blocks
A11 A12 x1 b1 =	 (1) A21 A22 x2 b2 
	variables x1  Rn1 , x2  Rn2;blocks Aij  Rninj 
=	A1 	if A11 is nonsingular, can eliminate x1: x1 11 (b1 A12x2); 
to compute x2, solve 
(A22 A21A1A12)x2 = b2 A21A1b1 11	 11 
Solving linear equations by block elimination. 
given a nonsingular set of linear equations(1), with A11 nonsingular. 
1.Form A1A12 and A1b1.11	 11 
2.Form S = A22  A21A1A12 and b = b2  A21A1b1.11	 11 
3.Determine x2 by solving Sx2=b. 
4.Determine x1 by solving A11x1= b1  A12x2. 
Numerical linear algebra background	 912</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>LDLTfactorization
every nonsingular symmetric matrix A can be factored as 
A = PLDLTPT 
with P a permutation matrix, L lower triangular, D block diagonal with 
1  1 or 2  2 diagonalblocks 
cost: (1/3)n3 
	cost of solving symmetric sets of linear equations by LDLT factorization: 
(1/3)n3 +2n2  (1/3)n3 forlarge n 
	for sparse A, can choose P to yield sparse L; cost  (1/3)n3 
Numerical linear algebra background	 911</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Matrix structure and algorithm complexity
cost(execution time) of solving Ax = b with A  Rnn 
	for general methods, grows as n3 
	lessif A isstructured(banded,sparse,Toeplitz, ...) 
op counts 
	op(oating-point operation): one addition, subtraction, 
multiplication, or division of two oating-point numbers 
	to estimate complexity of an algorithm: express number of ops as a 
(polynomial)function of the problem dimensions, and simplify by 
keeping only the leading terms 
	not an accurate predictor of computation time on modern computers 
	useful as a rough estimate of complexity 
Numerical linear algebra background	 92</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Linear equations that are easy to solve
diagonal matrices (aij =0 if i  n ops = j): 
x = A1b =(b1/a11,...,bn/ann) 
lower triangular (aij =0 if j&gt;i): n2 ops 
x1 := b1/a11
x2 := (b2 a21x1)/a22
x3 := (b3 a31x1 a32x2)/a33
... 
xn := (bn an1x1 an2x2  an,n1xn1)/ann 
called forward substitution 
upper triangular (aij =0 if j&lt;i): n2 ops via backward substitution 
Numerical linear algebra background 94</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
9. Numerical linear algebra background
 matrix structure and algorithm complexity 
 solving linear equations with factored matrices 
 LU,Cholesky,LDLTfactorization 
 block elimination and the matrix inversion lemma 
 solving underdetermined equations 
91</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Duality
Lagrange dual function and problem; examples and applications.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec05/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>29</slideno>
          <text>Semideniteprogram
primal SDP (Fi,G  Sk) 
minimize cTx 
subject to x1F1 +  + xnFn  G 
 Lagrange multiplier is matrix Z  Sk 
 Lagrangian L(x,Z)= cTx + tr (Z(x1F1 +  + xnFn G)) 
 dualfunction 
tr(GZ) tr(FiZ)+ ci =0,i =1,...,n g(Z) = inf L(x,Z)= 
x  otherwise 
dual SDP 
maximize tr(GZ)
subject to Z  0, tr(FiZ)+ ci =0,i =1,...,n
p  = d ifprimalSDPis strictly feasible(x with x1F1 +  + xnFn  G) 
Duality 530</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Least-norm solution of linear equations
minimize xTx 
subject to Ax = b 
dualfunction 
 Lagrangianis L(x,)= xTx + T(Axb) 
	to minimize L over x, set gradient equal to zero: 
xL(x,)=2x + AT =0 = x = (1/2)AT 
	plug inin L to obtain g: 
g()= L((1/2)AT,)=  1 TAAT 	bT 4 
a concave function of  
lowerboundproperty: p  (1/4)TAAT bT for all  
Duality	 54</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Lagrange dual and conjugate function
minimize f0(x)
subject to Ax  b, Cx = d
dualfunction 
g(,) = inf  
f0(x)+(AT+ CT)T x bTdT  
xdom f0 
= f0  (ATCT) bTdT 
 recall denition of conjugate f(y) = supxdom f(yTx f(x)) 
 simplies derivation of dual if conjugate of f0 iskown 
example: entropy maximization 
n n 
f0(x)= xi log xi,f0  (y)= eyi1 
i=1 i=1 
Duality 58</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Karush-Kuhn-Tucker(KKT) conditions
thefollowing four conditions are calledKKT conditions(for aproblem with 
dierentiable fi, hi): 
1. primal constraints: fi(x)  0, i =1,...,m, hi(x)=0, i =1,...,p 
2. dual constraints:   0 
3. complementary slackness: ifi(x)=0, i =1,...,m 
4. gradient of Lagrangian with respect to x vanishes: 
m p 
f0(x)+ ifi(x)+ ihi(x)=0 
i=1 i=1 
from page 517: if strong duality holds and x, ,  are optimal, then they 
must satisfy the KKT conditions 
Duality 518</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>local sensitivity: if(in addition) p (u,v) is dierentiable at (0,0), then
 
i = p(0,0) ,  = p(0,0) 
uii vi 
proof(for 
i): from globalsensitivity result, 
p(0,0) p (tei,0) p (0,0) = lim   
ui t0 t i 
p(0,0) = lim p (tei,0) p (0,0)  
iui t0 t 
hence, equality 
p (u) for aproblem with one(inequality) 
constraint: u 
p  (u) u = 0 
p (0)  u
Duality 523</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Introducing new variables and equality constraints
minimize f0(Ax+ b) 
  dual function is constant: g = infx L(x) = infx f0(Ax+ b)= p 
 we have strong duality, but dual is quite useless 
reformulated problem and its dual 
minimize f0(y) maximize bT f0 () 
subject to Ax+ by =0 subject to AT =0 
dualfunctionfollowsfrom 
g() = inf (f0(y) T y+ TAx+ bT) 
x,y 
f0 ()+ bTAT =0 =  otherwise 
Duality 525</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Two-waypartitioning
minimize xTWx 
subject to xi 2 =1,i =1,...,n 
	a nonconvex problem; feasible set contains 2n discretepoints 
	interpretation:partition {1,...,n}in two sets; Wij is cost of assigning 
i, j to the same set; Wij is cost of assigning to dierent sets 
dualfunction 
g() = inf (x TWx+ i(xi 2 1)) = inf x T(W + diag())x 1T 
x	 x 
i 
1TW + diag()  0 =  otherwise 
lowerboundproperty: p  1T if W + diag()  0 
example:  = min(W)1 givesbound p   nmin(W) 
Duality	 57</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Perturbation and sensitivity analysis
(unperturbed) optimization problem and its dual 
minimize f0(x) maximize g(,) 
subject to fi(x)  0,i =1,...,m subject to   0 
hi(x)=0,i =1,...,p 
perturbed problem and its dual 
min.	f0(x) max. g(,) uTvT 
s.t.	fi(x)  ui,i =1,...,m s.t.   0
hi(x)= vi,i =1,...,p
	x is primal variable; u, v areparameters 
	p (u,v) is optimal value as a function of u, v 
	we are interested in information about p (u,v) that we can obtain from 
the solution of the unperturbed problem and its dual 
Duality	 521</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>InequalityformLP
primalproblem 
minimize cTx 
subject to Ax  b 
dualfunction 
g() = inf  
(c + AT)T x bT  
= bTAT+ c =0 
x  otherwise 
dualproblem 
maximize bT 
subject to AT+ c =0,  0 
 from Slaters condition: p  = d if Ax b for some x
 infact, p  = d except when primal and dual are infeasible 
Duality 512</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>StandardformLP
minimize cTx 
subject to Ax = b, x  0 
dualfunction 
 Lagrangianis 
L(x,,)= c T x + T(Axb) T x 
= bT +(c + AT )T x 
 L is ane in x,hence 
bTAT + c =0 g(,) = inf L(x,,)= 
x  otherwise 
g is linear on ane domain {(,) |AT + c =0}, hence concave 
lowerboundproperty: p  bT if AT + c  0 
Duality 55</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>global sensitivity result 
assume strong duality holds for unperturbed problem, and that  ,  are 
dual optimal for unperturbed problem 
apply weak duality to perturbed problem: 
p  (u,v)	 g(  ,  ) u T  v T  
= p  (0,0) u T  v T  
sensitivityinterpretation 
	if 
i large: p  increases greatly if we tighten constraint i (ui &lt; 0) 
	if 
i small: p  does not decrease much if we loosen constraint i (ui &gt; 0) 
	if i large and positive: p  increases greatly if we take vi &lt; 0; 
if i large and negative: p  increases greatly if we take vi &gt; 0 
	if i small and positive: p  does not decrease much if we take vi &gt; 0; 
if i small and negative: p  does not decrease much if we take vi &lt; 0 
Duality	 522</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>A nonconvex problem with strong duality
minimize xTAx+2bTx 
subject to xTx  1 
A  0, hence nonconvex 
dualfunction: g() = infx(xT(A+ I)x +2bTx ) 
 unboundedbelowif A+ I  0 orif A+ I  0 and b R(A+ I) 
 minimizedby x = (A+ I)b otherwise: g()= bT(A+ I)b 
dualproblem and equivalent SDP: 
maximize	bT(A+ I)b maximize t  
subject to	A+ I  0 A+ I b 
b R(A+ I) subject to bT t  0 
strong duality althoughprimalproblemisnotconvex(noteasy toshow) 
Duality	 514</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Problems with generalized inequalities 
minimize	f0(x) 
subject to	fi(x) Ki 0,i =1,...,m 
hi(x)=0,i =1,...,p 
Ki is generalized inequality on Rki 
denitions are parallel to scalar case: 
 Lagrange multiplier for fi(x) Ki 0 is vector i  Rki 
 Lagrangian L	: Rn  Rk1    Rkm  Rp  R, is dened as 
m	 p 
L(x,1, ,m,)= f0(x)+ iTfi(x)+ ihi(x) 
i=1 i=1 
	dualfunction g : Rk1    Rkm  Rp  R, is dened as 
g(1,...,m,) = inf L(x,1, ,m,) 
xD 
Duality	 528</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Lagrangedualfunction
Lagrangedualfunction: g : Rm  Rp  R, 
g(,) = inf L(x,,) 
xD 
m p 
= inf f0(x)+ ifi(x)+ ihi(x) 
xD i=1 i=1 
g is concave, can be  for some ,  
lowerboundproperty: if   0, then g(,)  p 
proof: if xis feasible and   0, then 
f0(x)  L(x,,)  inf L(x,,)= g(,) 
xD 
minimizing over all feasible xgives p   g(,) 
Duality 53</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Lagrangian 
standardformproblem (not necessarilyconvex) 
minimize f0(x) 
subject to fi(x)  0,i =1,...,m 
hi(x)=0,i =1,...,p 
variable x  Rn,domain D, optimal value p  
Lagrangian: L : Rn  Rm  Rp  R, with dom L = D Rm  Rp , 
m p 
L(x,,)= f0(x)+ ifi(x)+ ihi(x) 
i=1 i=1 
 weighted sum of objective and constraint functions 
 i is Lagrange multiplier associated with fi(x)  0 
 i is Lagrange multiplier associated with hi(x)=0 
Duality 52</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Complementary slackness
assume strong duality holds, x  is primal optimal, (,) is dual optimal 
m p 
f0(x  )= g(  ,  ) = inf f0(x)+ i fi(x)+ i hi(x) 
x 
i=1 i=1 
m p 
 f0(x  )+ i fi(x  )+ i hi(x  ) 
i=1 i=1 
 f0(x  ) 
hence, the two inequalities hold with equality 
 x  minimizes L(x,,) 
 ifi(x )=0 for i =1,...,m (known as complementaryslackness): 
 
i &gt; 0= fi(x  )=0,fi(x  ) &lt; 0= i =0 
Duality 517</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>KKT conditions for convex problem
if x, , satisfy KKT for a convex problem, then they are optimal: 
  from complementary slackness: f0(x)= L(x, ,) 
 from4th condition(and convexity): g()= L(,) , x, 
hence, f0(x)= g(),
if Slaters condition is satised:
x is optimal if and only if there exist ,  that satisfy KKT conditions
 recall that Slater implies strong duality, and dual optimum is attained 
 generalizes optimality condition f0(x)=0 for unconstrained problem 
Duality 519</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Geometricinterpretation 
for simplicity, consider problem with one constraint f1(x)  0 
interpretation of dual function: 
g()= inf (t + u), where G = {(f1(x),f0(x)) |x D} 
(u,t)G 
G 
p  
g() u + t = g() t 
u G 
p  
d  t 
u 
 u+ t = g() is(non-vertical) supporting hyperplane to G 
 hyperplaneintersects t-axis at t = g() 
Duality 515</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Thedualproblem 
Lagrangedualproblem 
maximize g(,) 
subject to   0 
 nds best lower bound on p , obtained from Lagrange dual function 
 a convex optimization problem; optimal value denoted d 
 ,  aredualfeasibleif   0, (,)  dom g 
 often simplied by making implicit constraint (,)  dom g explicit 
example: standardformLP anditsdual(page55) 
minimize	cTx maximize bT 
subject to	Ax = b subject to AT + c  0 
x  0 
Duality	 59</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>norm approximation problem: minimize Axb 
minimize y 
subject to y = Axb 
can look up conjugate of , or derive dual directly 
g() = inf (y+ T yTAx+ bT) 
x,y 
bT + infy(y+ Ty) AT =0 =  otherwise 
bTAT =0,   1 =  otherwise 
(seepage54) 
dual of norm approximation problem 
maximize bT 
subject to AT =0,   1 
Duality 526</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>lowerboundproperty: if i K 0, then g(1,...,m,)  pi 
proof: if xis feasible and  K 0, then i 
m	 p 
f0(x)  f0(x)+ T
i fi(x)+ ihi(x) 
i=1 i=1 
 inf L(x,1,...,m,) 
xD 
= g(1,...,m,) 
minimizing over all feasible xgives p   g(1,...,m,) 
dualproblem 
maximize g(1,...,m,) 
subject to i K 0,i =1,...,m i 
	weakduality: p   d always 
	strong duality: p  = d for convex problem with constraint qualication 
(for example, Slaters: primal problem is strictlyfeasible) 
Duality	 529</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Weak and strong duality 
weakduality: d  p  
	alwaysholds(for convex and nonconvexproblems) 
	can be used to nd nontrivial lower bounds for dicult problems 
for example, solving the SDP 
maximize 1T 
subject to W + diag()  0 
gives a lower bound for the two-way partitioning problem on page 57 
strongduality: d = p  
	does not hold in general 
	(usually)holds for convex problems 
	conditions that guarantee strong duality in convex problems are called 
constraintqualications 
Duality	 510</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Duality and problem reformulations
	equivalent formulations of a problem can lead to very dierent duals 
	reformulating the primal problem can be useful when the dual is dicult 
to derive, or uninteresting 
common reformulations 
	introduce new variables and equality constraints 
	make explicit constraints implicit or vice-versa 
	transform objective or constraint functions 
e.g., replace f0(x) by (f0(x)) with  convex,increasing 
Duality	 524</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
5. Duality 
 Lagrangedualproblem 
 weak and strong duality 
 geometricinterpretation 
 optimality conditions 
 perturbation and sensitivity analysis 
 examples 
 generalizedinequalities 
51</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Implicit constraints
LP with box constraints: primal and dual problem 
minimize cTx maximize bT 1T1 1T2
subject to Ax = b subject to c + AT + 1 2 =0
1  x  1 1  0,2  0
reformulation with box constraints made implicit 
cTx 1  x  1 minimize f0(x)=  otherwise 
subject to Ax = b 
dualfunction 
g()= inf (c T x + T(Axb)) 
1/precedesequalx/precedesequal1 
= bT AT + c1 
dualproblem: maximize bT AT + c1 
Duality 527</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Equality constrained norm minimization
minimize x 
subject to Ax = b 
dualfunction 
g() = inf (xTAx+ bT)= bT AT  1 
x  otherwise 
where v = sup/bardblu/bardbl1 uTv is dual norm of  
proof: follows from infx(xyTx)=0 if y  1,  otherwise 
 if y  1, then xyTx  0 for all x, with equality if x =0 
 if y &gt; 1, choose x = tu where u 1, uTy = y &gt; 1: 
xy T x = t(uy)  as t  
lowerboundproperty: p   bT if AT  1 
Duality 56</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Slaters constraint qualication
strong duality holds for a convex problem 
minimize	f0(x) 
subject to	fi(x)  0,i =1,...,m 
Ax = b 
if it is strictly feasible, i.e., 
x  int D : fi(x) &lt; 0,i =1,...,m, Ax = b 
	alsoguarantees that thedual optimumisattained(if p  &gt; ) 
	can be sharpened: e.g., can replace int D with relint D (interior 
relative to ane hull); linear inequalities do not need to hold with strict 
inequality, . . . 
	there exist many other types of constraint qualications 
Duality	 511</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Quadraticprogram 
primalproblem (assumeP  Sn )++
minimize xTPx 
subject to Ax  b 
dualfunction 
g() = inf  
x TPx+ T(Axb)  
=  1 TAP1ATbT 
x 4 
dualproblem 
maximize (1/4)TAP1ATbT 
subject to   0 
 from Slaters condition: p  = d if Ax b for some x
 infact, p  = d always 
Duality 513</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>epigraph variation: sameinterpretationif G is replaced with 
A = {(u,t) |f1(x)  u,f0(x)  t for some x D} 
t 
u + t = g() A 
p  
g() 
u 
strongduality 
 holds if there is a non-vertical supporting hyperplane to A at (0,p ) 
 for convex problem, A is convex, hence has supp. hyperplane at (0,p ) 
 Slaters condition: if there exist (t) A with  u,  u&lt; 0, then supporting 
hyperplanes at (0,p ) must be non-vertical 
Duality 516</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>example: water-lling (assumei &gt; 0)
minimize  n
i=1 log(xi + i) 
subject to x  0, 1Tx =1 
x is optimal i x  0, 1Tx =1, and there exist   Rn ,   R such that 
1   0,ixi =0, + i =  xi + i 
 if &lt; 1/i: i =0 and xi =1/i 
 if   1/i: i =  1/i and xi =0 
 determine  from 1Tx = n
i=1 max{0,1/i}=1 
interpretation 
 n patches; level of patch i is at height i 1/  
xi  ood area with unit amount of water 
i 
 resulting levelis 1/ 
i 
Duality 520</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Approximation and fitting
Norm approximation; regularization; robust optimization.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec06/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>9</slideno>
          <text>Scalarizedproblem 
minimize Axb+ x 
	solutionfor &gt; 0 traces out optimal trade-o curve 
other common method: minimize Axb2 + x2 with &gt; 0  
Tikhonov regularization 
minimize Axb
can be solved as a least-squares problem 2
2 2+ x2 
2  A	 b  
minimize  
I x  0 2
solution x  =(ATA+ I)1ATb 
Approximation and tting	 610</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Least-normproblems
minimize x
subject to Ax = b 
(A Rmn with m n,  is a norm on Rn) 
interpretations of solution x =argminAx=b x: 
geometric: x is point in ane set {x Ax = b}with minimum 	
distance to 0 |
 	estimation: b = Ax are(perfect) measurements of x; x is smallest 
(most plausible)estimate consistent with measurements 
	design: x aredesign variables(inputs); b are required results(outputs) 
 x issmallest(mostecient) design thatsatisesrequirements 
Approximation and tting	 67</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Robust approximation
minimize Axbwith uncertain A 
two approaches: 
stochastic: assume A is random, minimize E Axb  
worst-case: set Aof possible values of A, minimize supAA Axb  
tractable only in special cases(certain norms , distributions, sets A) 
12 example: A(u)= A0 + uA1 
10 
xnom minimizes A0x b22 
8  
xstoch minimizes E A(u)x b22  6 
with u uniform on [1,1] 
4 
xwc minimizes sup1u1 A(u)x b2  2 2 
gure shows r(u)= A(u)x b2 0 
u r(u)
xnom 
xstoch 
xwc 
2 1 0 1 2 
Approximation and tting 617</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>examples 
 least-squares approximation(2): solution satises normalequations 
ATAx = ATb
(x  =(ATA)1ATb if rank A = n)
 Chebyshev approximation(): can be solvedas an LP 
minimize t 
subject to t1 Axb t1 
 sum of absolute residuals approximation(1): can be solvedas an LP 
minimize 1Ty 
subject to y Axb y 
Approximation and tting 63</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>examples 
	least-squares solution oflinear equations(2): 
can be solved via optimality conditions 
2x + AT =0, Ax = b 
	minimum sum of absolute values(1): can be solvedas an LP 
minimize 1Ty 
subject to y x y, Ax = b 
tends to produce sparse solution x 
extension: least-penalty problem 
minimize (x1)++ (xn)  
subject to Ax = b 
 : RR is convex penalty function 
Approximation and tting	 68</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Regularized approximation
minimize(w.r.t. R2 ) (Axb,x)+
A	Rmn , norms on Rm and Rn canbedierent 
interpretation: nd good approximation Ax b with small x 
	estimation: linear measurement model y = Ax+ v, with prior 
knowledge that xis small 
	optimaldesign: small x is cheaper or more ecient, or the linear 
model y = Ax is only valid for small x 
	robust approximation: good approximation Ax b with small x is 
less sensitive to errors in A than good approximation with large x 
Approximation and tting	 69</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>example: histogram of residuals 
r(u)= (A0 + u1A1 + u2A2)x b2 
with u uniformly distributed on unit disk, for three values of x 
0 1 2 3 4 5 
r(u) 
 xls minimizes A0x b2 
 xtik minimizes A0x b22 + x22 (Tikhonov solution) 
 xwc minimizes sup/bardblu/bardbl21 A0x b22 + x22 
Approximation and tting 620 xls xtik xrls frequency 
0 0.05 0.1 0.15 0.2 0.25</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>example (m =100, n =30): histogram ofresiduals for penalties
(u)= |u|,(u)= u 2 ,(u)= max{0,|u|a},(u)= log(1u 2) 
40 
0 Deadzonep =2 p =1
2 1 0 1 2
10
0 
2 1 0 1 2 
20 
0 
2 1 0 1 2 Log barrier 
0 10 
2 1 0 1 2 r 
shape of penalty function has large eect on distribution of residuals
Approximation and tting 65</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
6. Approximation and tting
 norm approximation 
 least-normproblems 
 regularized approximation 
 robust approximation 
61</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>0 0.5 quadratic smoothing example 
0.5 
0.50 
0 1000 2000 3000 4000 
0.5 x
0
x
0.5
0 1000 2000 3000 4000
x
0
0.5 
0.5 0 1000 2000 3000 4000 
0.5 xcor 
0.5 0.5 
0 1000 2000 3000 4000 0 1000 2000 3000 4000 
i i 
original signal x and noisy three solutions on trade-o curve 
signal xcor xxcor2 versus quad(x) x
0
Approximation and tting 614</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Optimalinputdesign 
linear dynamical system with impulse response h: 
t 
y(t)= h()u(t ),t =0,1,...,N 
=0 
inputdesignproblem: multicriterion problem with 3 objectives 
1. tracking error with desired output ydes: Jtrack = N (y(t)ydes(t))2 
t=0N2. input magnitude: Jmag = t=0 u(t)2 
3. input variation: Jder = N1(u(t +1) u(t))2 
t=0 
track desired output using a small and slowly varying input signal 
regularizedleast-squaresformulation 
minimize Jtrack + Jder + Jmag 
for xed ,, a least-squares problem in u(0), ..., u(N) 
Approximation and tting 611</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>stochastic robust LS with A = A+U, U random, E U =0, E UTU = P
 minimize E (A+ U)x b
 explicit expression for objective: 2
2
E Axb
2
2

 22
= E  
Axb+ Ux 
TUTUx 2
2
22
= Axb 
Axb + E x
+
x
TPx
 = 
 hence, robust LS problem is equivalent to LS problem
minimize
 
Axb2
2
+ P1/2
x
22
 for P = I, get Tikhonov regularized problem
 minimize Axb2
2
+ x
22
Approximation and tting 618</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>0 0 total variation reconstruction example 
2 
0 500 1000 1500 2000 0xi
2
1
2 
2 
0 500 1000 1500 2000 0 1
xi
2 0 500 1000 1500 2000 
22 
21 
0 2 500 i 1000 1500 2000 0 2 
500 
i 1000 1500 2000 
original signal x and noisy three solutions on trade-o curve 
signal xcor x xcor2 versus quad(x) 
quadratic smoothing smooths out noise and sharp transitions in signal 
Approximation and tting 615 xcor 
xi
0
1
 x</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>0 5 
0 example: 3 solutions on optimal trade-o curve u(t) (top) =0, small ;(middle)  =0,larger ;(bottom) large  
1 
0.5 y(t) 0
5 0.5 
1 10 0 50 100 150 200 0 50 100 150 200 
t t 4 1
2
 0.5 y(t) u(t)
0
0.5 2 
1 4 0 50 100 150 200 0 50 100 150 200 y(t) t t 4 1 
2 0.5 
0.5 2
1
 4 0 50 100 150 200 0 50 100 150 200 
t t 
Approximation and tting 612 u(t)
0
 0</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Norm approximation 
minimize Axb 
(A Rmn with m n,  is a norm on Rm) 
interpretations of solution x =argminx Axb: 
geometric: Ax ispointin R(A)closest to b  
estimation: linear measurement model  
y = Ax+ v
y are measurements, x is unknown, v is measurement error
given y = b, best guess of x is x 
 optimaldesign: x aredesign variables(input), Ax is result(output) 
 x is design that best approximates desired result b 
Approximation and tting 62</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Penalty function approximation 
minimize (r1)++ (rm)  
subject to r = Axb 
(A Rmn ,  : RR is a convex penalty function) 
examples 
2  quadratic: (u)= u
deadzone-linear quadratic log barrier 
1.5 1 0.5 0 0.5 1 1.5 0 0.5 1 1.5 2 
deadzone-linear with width a:  
(u)= max{0,|u|a}
(u)
 log-barrier with limit a: 
u 
(u)=	a2 log(1(u/a)2) |u|&lt;a
 otherwise
Approximation and tting	 64</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>replaements
 c Huberpenaltyfunction (withparameterM)
u	 uhub(u)= 2	||M 
M(2|u|M) |u|&gt;M 
lineargrowthforlarge u makes approximation less sensitive to outliers 
1.5 1 0.5 0 0.5 1 1.5 0 0.5 1 1.5 2 
f(t) 20
10
0
hub(u) 
10
20 
10 5 0 5 10 u	 t 
	left: Huber penalty for M =1 
	right: ane function f(t)= + t tted to 42 points ti, yi (circles) 
usingquadratic(dashed) andHuber(solid) penalty 
Approximation and tting	 66</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>worst-case robust LS with A= {A+ u1A1 +  + upAp |u2 1} 
minimize supAA Axb2 =sup/bardblu/bardbl21 P(x)u + q(x)2 
2 2 
 where P(x)= A1xA2x Apx , q(x)= Axb  
 from page 514, strong duality holds between the following problems 
maximize Pu+ q2 minimize t + 2   subject to u22 1 I Pq 
subject to  PT I 0  0 
qT 0 t 
 hence, robust LS problem is equivalent to SDP 
minimize t +    I P(x) q(x) 
subject to  P(x)T I 0  0 
q(x)T 0 t 
Approximation and tting 619</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>x
0 500 1000 1500 2000 0 2 
0 500 1000 1500 2000 2 1 1 2 
2 
0 2
0 500 1000 1500 2000 0x
22
2
1
0
x
0
1
2 2 0 500 1000 1500 2000 0 500 1000 1500 2000
i i
original signal x and noisy three solutions on trade-o curve 
signal xcor xxcor2 versus tv(x) xcor x
total variation smoothing preserves sharp transitions in signal
Approximation and tting 616</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Signal reconstruction
minimize(w.r.t. R2	xcor2,(x)) +) (x
	x Rn is unknown signal 
	xcor = x + v is(known) corrupted version of x, with additive noise v 
	variable x(reconstructedsignal) is estimate of x 
 : Rn R is regularization function or smoothing objective  
examples: quadratic smoothing, total variation smoothing: 
n1	 n1 
quad(x)= (xi+1 xi)2 ,tv(x)= |xi+1 xi|
i=1 i=1 
Approximation and tting	 613</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Convex optimization problems
Convex optimization problems; linear and quadratic programs; second-order cone and semidefinite programs; quasiconvex optimization problems; vector and multicriterion optimization.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec04/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>example
minimize f0(x)= x2
1 + x2
2 
subject to f1(x)= x1/(1+x2
2)0 
h1(x)=(x1 + x2)2 =0 
	f0 is convex; feasible set {(x1,x2)|x1 = x2 0}is convex 
	notaconvexproblem(according toourdenition): f1 is not convex, h1 
is not ane 
	equivalent(butnotidentical) totheconvexproblem 
minimize x12 + x22 
subject to x1 0 
x1 + x2 =0 
Convex optimization problems	 47</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Linearprogram(LP) 
minimize cTx + d 
subject to Gx h 
Ax = b 
 convex problem with ane objective and constraint functions 
 feasible set is a polyhedron 
P x  c 
Convex optimization problems 417</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Robustlinearprogramming
the parameters in optimization problems are often uncertain, e.g., in an LP 
minimize cTx 
subject to aT
i x bi,i =1,...,m, 
there can be uncertainty in c, ai, bi 
twocommonapproaches tohandling uncertainty(in ai, for simplicity) 
	deterministic model: constraints must hold for all ai Ei 
minimize cTx
subject to aiTx bi for all ai Ei, i =1,...,m,
	stochastic model: ai is random variable; constraints must hold with 
probability  
minimize cTx 
subject to prob(aiTx bi), i =1,...,m 
Convex optimization problems	 426</text>
        </slide>
        <slide>
          <slideno>43</slideno>
          <text>Risk return trade-o in portfolio optimization
minimize(w.r.t. R2 pTx,xTx)+) (
subject to 1Tx =1,x 0 
 x Rn isinvestmentportfolio; xi is fraction invested in asset i 
 pRn is vector of relative asset price changes; modeled as a random 
variable with mean p, covariance 
pTx = E r is expected return; xTx = var r is return variance
  
example 
15% 1 mean return
10%
5%
allocation x
0.5
0 
0% 0% 10% 20% x(1) x(4) x(2) x(3) 
0% 10% 20% 
standard deviation of return standard deviation of return 
Convex optimization problems 444</text>
        </slide>
        <slide>
          <slideno>42</slideno>
          <text>Regularizedleast-squares
0 5 10 15 20 25 F2 (x) =  x  2
2 O minimize(w.r.t. R2 ) (Axb2 
22)+ 2,x
0 10 20 30 40 50
F1(x)= Axb2 
2
examplefor A R10010; heavy line is formed by Pareto optimal points 
Convex optimization problems 443</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>formulation as a GP
minimize w1h1 +    + wNhN 
subject to w1 
maxwi 1, wminw 1 
i 1, i = 1,. . . ,N 
h1 
maxhi 1, hminh1 
i 1, i = 1,. . . ,N 
S1 
maxw 1 
i hi 1, Sminwih1 
i 1, i = 1,. . . ,N 
6iF1 
maxw 1 
i h2 
i 1, i = 1,. . . ,N 
1y	y1 1max
note 
	we write wmin wi wmax and hmin hi hmax 
wmin/wi 1,wi/wmax 1,hmin/hi 1,hi/hmax 1 
	we write Smin hi/wi Smax as 
Sminwi/hi 1,hi/(wiSmax)1 
Convex optimization problems	 433</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>(Generalized) linear-fractionalprogram
minimize f0(x) 
subject to Gx h 
Ax = b 
linear-fractionalprogram 
cTx + d	Tf0(x)= eTx + f, dom f0(x)= {x |ex + f&gt; 0} 
 a quasiconvex optimization problem; can be solved by bisection 
 alsoequivalent totheLP(variables y, z) 
minimize	cTy+ dz 
subject to	Gy hz 
Ay = bz 
eTy+ fz =1 
z 0 
Convex optimization problems	 420</text>
        </slide>
        <slide>
          <slideno>46</slideno>
          <text>risk-return trade-o of page 444
minimize pTx + xTx 
subject to 1Tx =1,x 0 
for xed &gt; 0, a quadratic program 
Convex optimization problems 447</text>
        </slide>
        <slide>
          <slideno>39</slideno>
          <text>Vector optimization
general vector optimization problem 
minimize(w.r.t. K)	f0(x) 
subject to	 fi(x)0,i =1,...,m 
hi(x)0,i =1,...,p 
vector objective f0 : Rn Rq, minimized w.r.t. proper cone K Rq 
convex vector optimization problem 
minimize(w.r.t. K)	f0(x) 
subject to	 fi(x)0,i =1,...,m 
Ax = b 
with f0 K-convex, f1, ..., fm convex 
Convex optimization problems	 440</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>epigraphform: standard form convex problem is equivalent to 
minimize(over x, t) t 
subject to f0(x)t 0 
fi(x)0,i =1,...,m 
Ax = b 
 minimizing over some variables 
minimize f0(x1,x2)
subject to fi(x1)0,i =1,...,m
is equivalent to 
minimize f 0(x1)
subject to fi(x1)0,i =1,...,m
where f 0(x1)=infx2 f0(x1,x2) 
Convex optimization problems 413</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Quadratically constrainedquadraticprogram(QCQP)
minimize (1/2)xTP0x + q0 Tx + r0 
subject to (1/2)xTPix + qiTx + ri 0,i =1,...,m 
Ax = b 
 Pi S+n ; objective and constraints are convex quadratic 
 if P1,...,Pm Sn , feasible region is intersection of m ellipsoids and ++
an ane set 
Convex optimization problems 424</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Optimal and locally optimal points
x is feasible if x dom f0 and it satises the constraints 
afeasible x is optimal if f0(x)= p  ; Xopt is the set of optimal points 
x is locally optimal if there is an R&gt; 0 such that x is optimal for 
minimize(over z) f0(z)
subject to fi(z)0,i =1,...,m, hi(z)=0,i =1,...,p
z	x2 R 
examples (withn =1, m = p=0) 
 	f0(x)=1/x, dom f0 = R++: p =0, no optimal point 
 	f0(x)= logx, dom f0 = R++: p =  
 	f0(x)= xlogx, dom f0 = R++: p = 1/e, x =1/eis optimal 
f0(x)= x3 3x, p  = , local optimum at x =1  
Convex optimization problems	 43</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>generalizedlinear-fractionalprogram
ciTx + di Tf0(x)= max T , dom f0(x)= {xei x+fi &gt; 0,i =1,...,r}
i=1,...,r ei x + fi |
a quasiconvex optimization problem; can be solved by bisection 
example: Von Neumann model of a growing economy 
maximize(over x, x+) mini=1,...,n x + 
i /xi 
subject to x+ 0, Bx+ Ax 
 x,x+ Rn: activity levels of n sectors, in current and next period 
 (Ax)i, (Bx+)i: produced, resp. consumed, amounts of good i 
+  xi /xi: growth rate of sector i 
allocate activity to maximize growth rate of slowest growing sector 
Convex optimization problems 421</text>
        </slide>
        <slide>
          <slideno>44</slideno>
          <text>Scalarization
to nd Pareto optimal points: choose  K 0 and solve scalar problem 
minimize	Tf0(x) 
subject to	fi(x)0,i =1,...,m 
hi(x)=0,i =1,...,p 
if x is optimal for scalar problem, 
then it is Pareto-optimal for vector 
optimizationproblem O 
f0(x1) 
1 
f0(x2) 2 f0(x3) 
forconvexvectoroptimizationproblems,can nd(almost)allPareto 
optimal points by varying  K 0 
Convex optimization problems	 445</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Second-order cone programming
minimize	fTx 
subject to	Aix + bi2 cT
i x + di,i =1,...,m 
Fx = g 
(Ai Rnin ,	F Rpn) 
	inequalities are called second-order cone(SOC) constraints: 
(Aix + bi,c iT x + di)second-order cone in Rni+1 
 for ni =0, reduces to an LP; if ci =0, reduces to a QCQP 
 more general than QCQP and LP 
Convex optimization problems	 425</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>unconstrainedproblem: x is optimal if and only if 
x dom f0, f0(x)=0 
 equality constrained problem 
minimize f0(x) subject to Ax = b 
x is optimal if and only if there exists a  such that 
x dom f0, Ax = b, f0(x)+AT =0 
 minimization over nonnegative orthant 
minimize f0(x) subject to x 0
x is optimal if and only if
f0(x)i 0 xi =0 x dom f0,x 0, f0(x)i xi &gt; 0 =0 
Convex optimization problems 410</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Examples 
least-squares 
minimize Axb2 
2 
analytical solution x  = Ab (A ispseudo-inverse)  
	can add linear constraints, e.g., l x u 
linear program with random cost 
minimize cTx + xTx = E cTx + var(cTx) 
subject to Gx h, Ax = b 
c	is random vector with mean cand covariance   
hence, cTx is random variable with mean cTx and variance xTx  
	&gt; 0 is risk aversion parameter; controls the trade-o between 
expected cost and variance(risk) 
Convex optimization problems	 423</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Geometric program in convex form
change variables to yi =logxi, and take logarithm of cost, constraints 
 monomial	f(x)= cx 1 a1  xnan transforms to 
logf(ey1 ,...,eyn)= a T y+ b (b =logc) 
K a1ka2k ank  posynomial f(x)= k=1 ckx1 x2  xn transforms to 
K 
alogf(ey1 ,...,eyn)=log  
e kTy+bk (bk =logck) 
k=1 
 geometric program transforms to convex problem 
minimize	log K
k=1 exp(aT 
0ky+ b0k) 
K	 Tsubject to	log k=1 exp(aiky+ bik) 0,i =1,...,m 
Gy + d =0 
Convex optimization problems	 430</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
4. Convex optimization problems
 optimization problem in standard form 
 convex optimization problems 
 quasiconvex optimization 
 linear optimization 
 quadratic optimization 
 geometricprogramming 
 generalized inequality constraints 
 semideniteprogramming 
 vector optimization 
41</text>
        </slide>
        <slide>
          <slideno>41</slideno>
          <text>Multicriterion optimization 
vector optimization problem with K = Rq 
+ 
f0(x)=(F1(x),...,Fq(x)) 
	q dierent objectives Fi; roughly speaking we want all Fis to be small 
  feasible	x is optimal if 
y feasible =  f0(x  )f0(y)
if there exists an optimal point, the objectives are noncompeting
	feasible xpo is Pareto optimal if 
y feasible,f0(y)f0(xpo)= f0(xpo)= f0(y)  
if there are multiple Pareto optimal values, there is a trade-o between 
the objectives 
Convex optimization problems	 442</text>
        </slide>
        <slide>
          <slideno>40</slideno>
          <text>Optimal and Pareto optimal points
set of achievable objective values 
O= {f0(x)|x feasible} 
 feasible x is optimal if f0(x)is a minimum value of O 
 feasible x is Pareto optimal if f0(x)is a minimal value of O 
O 
f0(x  ) O 
f0(xpo) 
x is optimal xpo is Pareto optimal 
Convex optimization problems 441</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>introducing equality constraints 
minimize f0(A0x + b0)
subject to fi(Aix + bi)0,i =1,...,m
is equivalent to 
minimize(over x, yi) f0(y0) 
subject to fi(yi)0,i =1,...,m 
yi = Aix + bi,i =0,1,...,m 
 introducing slack variables for linear inequalities 
minimize f0(x)
subject to aiTx bi,i =1,...,m
is equivalent to 
minimize(over x, s) f0(x) 
subject to aT
i x + si = bi,i =1,...,m 
si 0,i =1,...m 
Convex optimization problems 412</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>deterministic approach via SOCP 
 choose an ellipsoid as Ei: 
Ei = {ai + Piu |u2 1} (ai Rn ,Pi Rnn)
centeris ai, semi-axes determined by singular values/vectors of Pi
robustLP
  
minimize cTx 
subject to aiTx bi ai Ei,i =1,...,m 
is equivalent to the SOCP
minimize cTx
subject to aiTx + PiTx2 bi,i =1,...,m
(followsfromsup/badblu/badbl21(ai + Piu)Tx = aiTx + PiTx2) 
Convex optimization problems 427</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>objective and constraint functions 
	total weight w1h1 +  + wNhN isposynomial 
	aspect ratio hi/wi and inverse aspect ratio wi/hi are monomials 
maximum stress in segment i isgivenby 6iF/(wih2 
i), a monomial  
	the vertical deection yi and slope vi of central axis at the right end of 
segment i are dened recursively as 
F vi = 12(i1/2) Ewih3 
i + vi+1 
F yi = 6(i1/3) Ewih3 + vi+1 + yi+1 
i 
for i = N,N 1,..., 1, with vN+1 = yN+1 =0 (E is Youngs modulus) 
vi and yi are posynomial functions of w, h 
Convex optimization problems	 432</text>
        </slide>
        <slide>
          <slideno>33</slideno>
          <text>Minimizing spectral radius of nonnegative matrix 
Perron-Frobenius eigenvalue pf (A) 
existsfor(elementwise) positive A Rnn  
 a real, positive eigenvalue of A, equal to spectral radius maxi |i(A)| 
 determines asymptoticgrowth(decay) rate of Ak: Ak pf k as k  
 alternative characterization: pf(A)=inf{ |Av v for some v 0} 
minimizing spectral radius of matrix of posynomials 
 minimize pf (A(x)), where the elements A(x)ij are posynomials of x 
 equivalentgeometricprogram: 
minimize  
subject to n A(x)ijvj/(vi)1,i =1,...,n j=1 
variables , v, x 
Convex optimization problems 434</text>
        </slide>
        <slide>
          <slideno>35</slideno>
          <text>Semideniteprogram(SDP)
minimize cTx 
subject to x1F1 + x2F2 ++ xnFn + G 0  
Ax = b 
with Fi, G Sk 
 inequality constraintis calledlinear matrixinequality(LMI) 
 includes problems with multiple LMI constraints: for example, 
x1F1 ++ xnFn + G0,x1F1 ++ xnFn + G0   
is equivalent to single LMI 
F1 0 F2 0 Fn 0 G0 x1 +x2 ++xn + 0 F1 0 F2 0 Fn 0 G0 
Convex optimization problems 436</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Quadraticprogram(QP) 
minimize (1/2)xTPx+ qTx + r 
subject to Gx h 
Ax = b 
 P Sn , so objective is convex quadratic +
 minimize a convex quadratic function over a polyhedron 
P x  f0(x  ) 
Convex optimization problems 422</text>
        </slide>
        <slide>
          <slideno>38</slideno>
          <text>Matrix norm minimization
minimize A(x)2 =  
max(A(x)TA(x)) 1/2 
where A(x)= A0 + x1A1 ++ xnAn (withgivenAi Rpq)  
equivalentSDP 
minimize t 
subject to A(tI
x)T A
tI (x) 0 
 variables x Rn , t R 
constraintfollowsfrom  
A2 t ATA t2I, t 0  
 tI A  AT tI 0 
Convex optimization problems 439</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Convex optimization problem 
standard form convex optimization problem 
minimize	f0(x) 
subject to	fi(x)0,i =1,...,m 
aiTx = bi,i =1,...,p 
 f0, f1, ..., fm are convex; equality constraints are ane 
 problemis quasiconvex if f0 isquasiconvex(and f1, ..., fm convex) 
often written as 
minimize	f0(x) 
subject to	fi(x)0,i =1,...,m 
Ax = b 
importantproperty:feasible set of a convex optimizationproblemis convex 
Convex optimization problems	 46</text>
        </slide>
        <slide>
          <slideno>36</slideno>
          <text>LP and SOCP as SDP
LP and equivalent SDP 
LP:	minimize cTx SDP: minimize cTx 
subject to Ax b subject to diag(Axb)0 
(note dierent interpretation of generalized inequality) 
SOCP	and equivalent SDP 
SOCP:	minimize fTx
subject to Aix + bi2 ciTx + di,i =1,...,m
SDP:	minimize fTx 
(ciTx + di)IAix + bisubject to (Aix + bi)T cT
i x + di 0,i =1,...,m 
Convex optimization problems	 437</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Chebyshev center of a polyhedron
Chebyshev center of 
P= {x |aiT x	bi,i =1,...,m} 
is center of largest inscribed ball 
B= {xc + u	|u2 r} xcxhehbceb
	aiTx bi for all x Bif and only if 
sup{aiT(xc + u)|u2 r}= aiT xc + rai2 bi 
 hence, xc,	r can be determined by solving the LP 
maximize r 
subject to aiTxc + rai2 bi,i =1,...,m 
Convex optimization problems	 419</text>
        </slide>
        <slide>
          <slideno>47</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Geometricprogramming 
monomialfunction 
f(x)= cx a1x a2 x an , dom f = Rn 
12 n ++  
with c&gt; 0; exponent i can be any real number 
posynomialfunction: sum of monomials 
K 
f(x)= ckx1 a1kx2 a2k xnank , dom f = R++ n  
k=1 
geometricprogram(GP) 
minimize f0(x) 
subject to fi(x)1,i =1,...,m 
hi(x)=1,i =1,...,p 
with fi posynomial, hi monomial 
Convex optimization problems 429</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Optimality criterion for dierentiable f0
x is optimal if and only if it is feasible and 
f0(x)T(yx)0 for all feasible y 
f0(x) 
X x 
if nonzero, f0(x)denes a supporting hyperplane to feasible set X at x 
Convex optimization problems 49</text>
        </slide>
        <slide>
          <slideno>34</slideno>
          <text>Generalized inequality constraints 
convex problem with generalized inequality constraints 
minimize	f0(x) 
subject to	fi(x)Ki 0,i =1,...,m 
Ax = b 
f0 : Rn R convex; fi : Rn Rki Ki-convex w.r.t. proper cone Ki  	 
	sameproperties as standard convexproblem(convexfeasible set,local 
optimum is global, etc.) 
conicformproblem: special case with ane objective and constraints 
minimize	cTx 
subject to	Fx+ g K 0 
Ax = b 
extendslinearprogramming(K = Rm)to nonpolyhedral cones + 
Convex optimization problems	 435</text>
        </slide>
        <slide>
          <slideno>37</slideno>
          <text>Eigenvalue minimization 
minimize max(A(x)) 
where A(x)= A0 + x1A1 ++ xnAn (withgivenAi Sk) 
equivalentSDP 
minimize t 
subject to A(x)tI 
	variables x Rn , t R 
followsfrom  
max(A)t  A tI 
Convex optimization problems	 438</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Design of cantilever beam
F segment 4 segment 3 segment 2 segment 1 
 N segments with unit lengths, rectangular cross-sections of size wi hi 
 given vertical force F applied at the right end 
designproblem 
minimize total weight 
subject to upper &amp; lower bounds on wi, hi 
upper bound &amp; lower bounds on aspect ratios hi/wi 
upper bound on stress in each segment 
upper bound on vertical deection at the end of the beam 
variables: wi, hi for i =1,...,N 
Convex optimization problems 431</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>stochastic approach via SOCP 
	assume ai is Gaussian with mean ai, covariance i (ai N(ai,i)) 
aT
i x is Gaussian r.v. with mean aT
i x, variance xTix;hence  
i	x prob(aiT x bi)= bi aT 
i 1/2 x2 
 x t2where (x)=(1/
2) e/2 dt is CDF of N(0,1)  
robustLP  
minimize cTx 
subject to prob(aiTx bi), i =1,...,m, 
with  1/2, is equivalent to the SOCP 
minimize cTx 
subject to aiTx +1()1
i/2 x2 bi,i =1,...,m 
Convex optimization problems	 428</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Implicit constraints
the standard form optimization problem has an implicit constraint 
m p 
x D= dom fi  dom hi, 
i=0 i=1 
 we call Dthe domain of the problem 
 the constraints fi(x)0, hi(x)=0 are the explicit constraints 
 aproblemis unconstrained ifithas no explicit constraints(m = p=0) 
example: 
minimize f0(x)=  
ik 
=1 log(bi aiTx) 
is an unconstrained problem with implicit constraints aiTx&lt;bi 
Convex optimization problems 44</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Equivalent convex problems
twoproblems are(informally) equivalent if the solution of one is readily 
obtained from the solution of the other, and vice-versa 
some common transformations that preserve convexity: 
 eliminating equality constraints 
minimize f0(x) 
subject to fi(x)0,i =1,...,m 
Ax = b 
is equivalent to
minimize(over z) f0(Fz + x0)
subject to fi(Fz + x0)0,i =1,...,m
where F and x0 are such that
Ax = b x = Fz + x0 for some z  
Convex optimization problems 411</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Optimization problem in standard form
minimize	f0(x) 
subject to	fi(x)0,i =1,...,m 
hi(x)=0,i =1,...,p 
	x Rn is the optimization variable 
f0 : Rn R is the objective or cost function 	 
fi : Rn R, i =1,...,m, are the inequality constraint functions 	 
hi	: Rn R are the equality constraint functions 	 
optimal value: 
 p	=inf{f0(x)|fi(x)0,i =1,...,m, hi(x)=0,i =1,...,p} 
 	p = ifproblemisinfeasible(no x satises the constraints) 
  p = 	if problem is unbounded below 
Convex optimization problems	 42</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Examples 
dietproblem: choosequantities x1, ..., xn of n foods 
 one unit of food j costs cj, contains amount aij of nutrient i 
 healthy diet requires nutrient i in quantity at least bi 
to nd cheapest healthy diet, 
minimize cTx 
subject to Ax b, x 0 
piecewise-linear minimization 
minimize maxi=1,...,m(aiTx + bi) 
equivalent to an LP 
minimize t 
subject to aiTx + bi t, i =1,...,m 
Convex optimization problems 418</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Feasibilityproblem
nd	 x 
subject to	fi(x)0,i =1,...,m 
hi(x)=0,i =1,...,p 
can be considered a special case of the general problem with f0(x)=0: 
minimize	0 
subject to	fi(x)0,i =1,...,m 
hi(x)=0,i =1,...,p 
  p =0 if	constraints are feasible; any feasible x is optimal 
  p = if constraints are infeasible 
Convex optimization problems	 45</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>convex representation of sublevel sets of f0
if f0 is quasiconvex, there exists a family of functions t such that:
 t(x)is convex in x for xed t 
 t-sublevel set of f0 is 0-sublevel set of t, i.e., 
f0(x)t t(x)0  
example 
p(x)f0(x)= q(x) 
with p convex, q concave, and p(x)0, q(x)&gt; 0 on dom f0 
can take t(x)= p(x)tq(x): 
 for t 0, t convexin x 
 p(x)/q(x)t if and only if t(x)0 
Convex optimization problems 415</text>
        </slide>
        <slide>
          <slideno>45</slideno>
          <text>Scalarization for multicriterion problems 
to nd Pareto optimal points, minimize positive weighted sum 
Tf0(x)= 1F1(x)++ qFq(x)  
examples 
 regularized least-squares problem of page 443 
20 
take  =(1,)with &gt; 0 15 
10 2 
2 
 = 1  x 
2
2
22
minimize Axb
+ x
5 
for xed , a LS problem 
00 5 10 15 20 
Axb
2
2
Convex optimization problems 446</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>quasiconvex optimization via convex feasibility problems 
t(x)0,fi(x)0,i =1,...,m, Ax = b (1) 
	for xed t, a convex feasibility problem in x 
if feasible, we can conclude that t p  ;ifinfeasible, t p   
Bisection method for quasiconvex optimization 
  given l  p , u  p ,tolerance &gt; 0. 
repeat 
1.	t := (l + u)/2. 
2.Solvethe convexfeasibilityproblem(1). 
3. if (1)is feasible, u := t; else l := t. 
until u l  . 
requires exactly log2((u l)/)iterations(where u, l are initial values) 
Convex optimization problems	 416</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Local and global optima
any locally optimalpoint of a convexproblemis(globally) optimal 
proof: suppose x is locally optimal and y is optimal with f0(y)&lt;f0(x) 
x locally optimal means there is an R&gt; 0 such that 
z feasible, z x2 R =  f0(z)f0(x) 
consider z = y+(1 )x with  = R/(2yx2) 
yx2 &gt;R, so 0 &lt; &lt; 1/2 
 z is a convex combination of two feasible points, hence also feasible 
z x2 = R/2 and 
f0(z)f0(x)+(1)f0(y)&lt;f0(x)
which contradicts our assumption that x is locally optimal
Convex optimization problems 48</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Quasiconvex optimization
minimize f0(x) 
subject to fi(x)0,i =1,...,m 
Ax = b 
with f0 : Rn R quasiconvex, f1, ..., fm convex 
canhavelocally optimalpoints thatarenot(globally) optimal 
(x, f0(x)) 
Convex optimization problems 414</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Geometric problems
Projection; extremal volume ellipsoids; centering; classification; placement and location problems.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec08/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>Maximum volume inscribed ellipsoid 
maximum volume ellipsoid Einside a convex set C Rn 
 parametrize Eas E= {Bu+ d |u2 1}; w.l.o.g. assume B Sn 
++ 
 vol Eis proportional to det B; can compute Eby solving 
maximize logdet B 
subject to sup/bardblu/bardbl21 IC(Bu+ d) 0 
(whereIC(x)=0 for x C and IC(x)= for x  C)
convex,butevaluating theconstraintcanbehard(forgeneral C)
polyhedron {x |aiT x bi,i =1,...,m}: 
maximize logdet B 
subject to Bai2 + aiT d bi,i =1,...,m 
(constraintfollowsfromsup/bardblu/bardbl21 aT (Bu+ d)= Bai2 + aT d)i i 
Geometric problems 83</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Eciency of ellipsoidal approximations
C Rn convex, bounded, with nonempty interior 
 Lowner-John ellipsoid, shrunk by a factor n,liesinside C 
 maximum volume inscribed ellipsoid, expanded by a factor n, covers C 
example (fortwopolyhedrainR2) 
factor n can be improved to n if C is symmetric 
Geometric problems 84</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>quadraticdiscrimination: f(z)= zT Pz + qT z + r
x T Pxi + q T xi + r 1,y T Pyi + q T yi + r 1i i 
can add additional constraints(e.g., P I to separate by an ellipsoid) 
polynomialdiscrimination: F(z) are all monomials up to a given degree 
separation by ellipsoid separation by 4th degree polynomial 
Geometric problems 814</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
8. Geometric problems
	extremal volume ellipsoids 
	centering 
classication  
	placement and facility location 
81</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Analytic center of a set of inequalities
the analytic center of set of convex inequalities and linear equations 
fi(x) 0,i =1,...,m, Fx = g 
is dened as the optimal point of 
minimize  m log(fi(x)) i=1 
subject to Fx = g 
	moreeasily computed thanMVE orChebyshevcenter(seelater) 
	notjustaproperty of thefeasibleset:twosetsofinequalitiescan 
describe the same set, but have dierent analytic centers 
Geometric problems	 86</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Centering
some possible denitions of center of a convex set C: 
	center oflargestinscribedball(Chebyshev center) 
forpolyhedron, canbe computed vialinearprogramming(page419) 
	center of maximum volumeinscribed ellipsoid(page83) 
xchebxcheb xmve 
MVE center is invariant under ane coordinate transformations 
Geometric problems	 85</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Approximate linear separation of non-separable sets
minimize	1T u + 1T v 
subject to	aT xi + b 1 ui,i =1,...,N 
aT yi + b 1+ vi,i =1,...,M 
u 0,v 0 
 anLPin	a, b, u, v 
 at optimum, ui = max{0,1 aT xi b}, vi = max{0,1+ aT yi + b} 
 can be interpreted as a heuristic for minimizing #misclassied points 
Geometric problems	 811</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Support vector classier 
minimize	a2 + (1T u + 1T v) 
subject to	aT xi + b 1 ui,i =1,...,N 
aT yi + b 1+ vi,i =1,...,M 
u 0,v 0 
produces point on trade-o curve between inverse of margin 2/a2 and 
classication error, measured by total slack 1T u + 1T v 
same example as previous page, 
with  =0.1: 
Geometric problems	 812</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Nonlineardiscrimination
separate two sets of points by a nonlinear function: 
f(xi) &gt; 0,i =1,...,N, f(yi) &lt; 0,i =1,...,M 
 choose a linearly parametrized family of functions 
f(z)= T F(z)
F =(F1,...,Fk): Rn Rk arebasisfunctions
 
	solve a set of linear inequalities in : 
T F(xi) 1,i =1,...,N, T F(yi) 1,i =1,...,M 
Geometric problems	 813</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Robustlineardiscrimination
(Euclidean)distancebetweenhyperplanes 
H1 = {z |a T z + b =1} 
H2 = {z |a T z + b = 1} 
is dist(H1,H2)=2/a2 
to separate two sets of points by maximum margin, 
minimize (1/2)a2 
subject to aT xi + b 1, 
aT yi + b 1, 
(after squaringobjective) a QP in a, b i = 1,. . . ,N 
i = 1,. . . ,M (1) 
Geometric problems 89</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Minimum volume ellipsoid around a set
Lowner-John ellipsoid of a set C: minimum volume ellipsoid Es.t. C E 
 parametrize Eas E |Av+ b2 1}; w.l.o.g. assume A Sn = {v ++ 
vol Eis proportional to det A1; to compute minimum volume ellipsoid,  
minimize(over A, b) logdet A1
subject to supvC Av+ b2 1
convex,butevaluating theconstraintcanbehard(forgeneral C)
nite set C = {x1,...,xm}: 
minimize(over A, b) logdet A1 
subject to Axi + b2 1,i =1,...,m 
also gives Lowner-John ellipsoid for polyhedron conv{x1,...,xm} 
Geometric problems 82</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>example: minimize (i,j)A h(xi xj2), with 6 free points, 27 links 
optimalplacementfor h(z)= z, h(z)= z2 , h(z)= z4 
1 0 1 1 0 1 
1 0 1 1 0 1 
1 0 1 1 0 1 
histograms of connection lengths xi xj2 
6
4
 4
5
3
 3
4
3
 2
 2
2
1
 1
1
0
 0 000.511.52 0 0.5 1 1.50 0.5 1 1.5 
Geometric problems 816</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Lagrangedual of maximum margin separationproblem(1) 
maximize 1T + 1T  
N M subject to 2  i=1 ixi  i=1 iyi 
2 1 (2) 
1T  = 1T ,  0,0 
from duality, optimal value is inverse of maximum margin of separation 
interpretation 
 change variables to i = i/1T , i = i/1T , t =1/(1T + 1T ) 
 invert objective to minimize 1/(1T + 1T )= t 
minimize t 
N M subject to  i=1 ixi  i=1 iyi 
2 t 
 0, 1T  =1, 0, 1T  =1 
optimal value is distance between convex hulls 
Geometric problems 810</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Placement and facility location
N	points with coordinates xi R2 (orR3)  
	somepositions xi are given; the other xis are variables 
	for each pair of points, a cost function fij(xi,xj) 
placementproblem 
minimize i/negationslashfij(xi,xj)=j 
variables are positions of free points 
interpretations 
	points representplants or warehouses; fij is transportation cost between 
facilities i and j 
	points represent cells on an IC; fij represents wirelength 
Geometric problems	 815</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Lineardiscrimination
separate two sets of points {x1,...,xN }, {y1,...,yM }by a hyperplane: 
a T xi + b&gt; 0,i =1,...,N, a T yi + b&lt; 0,i =1,...,M 
homogeneousin a, b, hence equivalent to 
a T xi + b 1,i =1,...,N, a T yi + b 1,i =1,...,M 
a set of linear inequalities in a, b 
Geometric problems 88</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>analytic center of linear inequalities aiT x bi, i =1,...,m 
xac is minimizer of 
m  xac 
(x)=  log(bi aiT x) 
i=1 
inner and outer ellipsoids from analytic center: 
Einner {x |aiT x bi,i =1,...,m}Eouter 
where 
Einner = {x |(x xac)T  2(xac)(x xac) 1}
Eouter = {x |(x xac)T  2(xac)(x xac) m(m 1)}
Geometric problems 87</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Stochastic programming
Stochastic programming; &#8220;certainty equivalent&#8221; problem; violation/shortfall constraints and penalties; Monte Carlo sampling methods; validation.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec13/</lecture_pdf_url>
      <lectureno>13</lectureno>
      <slides>
        <slide>
          <slideno>12</slideno>
          <text>Out-of-sample validation
 a practical method to check if N is large enough 
 use a second set of samples(validation set) val ,...,val , with 1 M
probabilities val ,...,val (usuallyM  N)
1 M 
(originalset of samples called training set) 
 evaluate 
M 
Fval (x  )= val fi(x  ,val ),i =0,...,m i mcs j mcsj 
j=1 
 if Fi(x mcs ) Fi val (x mcs ), our condence that x mcs   x  is enhanced 
 if not, increase N and re-compute x  
mcs 
EE364A  Stochastic Programming 13</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Example
 we consider problem 
minimize F0(x)= E maxi(Ax+ b)i 
subjectto F1(x)= E maxi(Cx+ d)i  0 
with optimization variable x  Rn
A  Rmn , b  Rm , C  Rkn , d  Rk are random
 we consider instance with n =10, m =20, k =5 
 certainty-equivalent optimal value yields lower bound 19.1 
 we use Monte Carlo sampling with N =10, 100, 1000 
 validation set uses M =10000 
EE364A  Stochastic Programming 14</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Stochastic programming
	objective and constraint functions fi(x,)depend on optimization 
variable x and a random variable  
	 models 
	parameter variation and uncertainty 
	random variation in implementation, manufacture, operation 
	value of  is not known, but its distribution is 
	goal: choose x sothat 
 constraints are satised on average, or with high probability
 objective is small on average, or with high probability
EE364A  Stochastic Programming	 2</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>training set stochastic solution
100 150 200 250 300 
validation set stochastic solution
100 150 200 250 300 
validation set CE solution 
100 150 200 250 300 
EE364A  Stochastic Programming 18</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Finite event set
 suppose  {1,...,N }, with j = Prob( = j) 
 sometime called scenarios; often we have j =1/N 
 stochasticprogrammingproblembecomes 
Nminimize F0(x)= j=1 jf0(x,j) Nsubjectto Fi(x)= j=1 jfi(x,j) 0,i =1,...,m 
 a(standard) convex problem if fi convexin x 
 computational complexity grows linearly in the number of scenarios N
EE364A  Stochastic Programming 10</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Certainty-equivalent problem 
	certainty-equivalent (a.k.a. mean eld)problem: 
minimize f0(x,E )
subjectto fi(x,E ) 0,i =1,...,m
	roughly speaking: ignore parameter variation 
	if fi convexin  for each x,then 
	fi(x,E ) E fi(x,) 
	so optimal value of certainty-equivalent problem is lower bound on 
optimal value of stochastic problem 
EE364A  Stochastic Programming	 5</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Minimum average loss prediction 
	(x,y) Rn  R have somejointdistribution 
	nd weight vector w  Rn for which wT x is a good estimator of y 
	choose w to minimize expected value of a convex loss function l 
J(w)= E l(w T x y) 
	l(u)= u2: mean-square error 
	l(u)= |u|: mean-absolute error 
	wedo notknowjointdistribution,but wehaveindependent samples 
(trainingdata) 
(xi,yi),i =1,...,N 
EE364A  Stochastic Programming	 19</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Expected violation/shortfall constraints/penalties
 replace E fi(x,) 0 with 
 E fi(x,)+   (LHS is expectedviolation) 
 E (maxi fi(x,)+)  (LHS is expectedworst violation) 
 variation: add violation/shortfall penalty to objective 
mminimize E (f0(x,)+ i=1 cifi(x,)+)
where ci &gt; 0 are penalty rates for violating constraints
 these are convex problems if fi are convex in x 
EE364A  Stochastic Programming 7</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Example with analytic form for Fi
 f(x)= Axb
2
2
, with A, b random
 F(x)= E f(x)= xT Px2qT x + r, where
P = E(AT A),q = E(AT b),r = E(b
2
2
)
	only need second moments of (A,b) 
	stochastic constraint E f(x) 0 can be expressed as standard 
quadraticinequality 
EE364A  Stochastic Programming	 4</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Monte Carlo sampling method
	ageneral methodfor(approximately) solving stochasticprogramming 
problem 
	generate N samples(realizations) 1,...,N , with associated 
probabilities 1,...,N (usuallyj =1/N) 
	form sample average approximations 
N 
Fi(x)= jfi(x,j),i =0,...,m 
j=1 
 these areRVs(via 1,...,N )with mean E fi(x,)
EE364A  Stochastic Programming	 11</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Example
 n =10; N =1000 training samples; M =10000 validation samples 
	l(u)=(u)+ +4(u) (under-predicting4 more expensive) 
training set prediction errors 
200
150
100
50
0
0.2 0.1 0 0.1 0.2 0.3 0.4 
validation set prediction errors 
2000
1500
1000
500
0
0.2 0.1 0 0.1 0.2 0.3 0.4 
EE364A  Stochastic Programming	 21</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>MonteCarlo sampling method(called training): 
choose w to minimize sample average loss 
N1 wsa =argmin l(w T xi yi) 
w N i=1 
with associated sample average loss Jsa 
	validatepredictor y  wT x on a dierent set of M samples: sa 
M1	T val val Jval = Ml(wsaxi yi ) 
i=1 
	if Jsa  Jval (andM is large enough), we say predictor generalizes 
EE364A  Stochastic Programming	 20</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Stochastic programming
	basic stochastic programming problem: 
minimize F0(x)= E f0(x,)
subjectto Fi(x)= E fi(x,) 0,i =1,...,m
	variableis x 
	problem data are fi, distribution of  
	if fi(x,)are convex in x for each  
	Fi are convex 
	hence stochastic programming problem is convex 
	Fi have analytical expressions in only a few cases; 
in other cases we will solve the problem approximately 
EE364A  Stochastic Programming	 3</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Stochastic programming
 stochasticprogramming 
 certainty equivalent problem 
 violation/shortfall constraints and penalties 
 Monte Carlo sampling methods 
 validation 
sources: Nemirovsky &amp; Shapiro 
EE364A  Stochastic Programming 1</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>now solve nite event problem 
minimize F0(x)
subjectto Fi(x) 0,i =1,...,m
	  	solution x mcs and optimal value F0(x mcs)are random variables 
(hopefullyclose to x  and p , optimal value of original problem) 
	theory says 
 (withsome technical conditions) as N , x   x  
mcs 
  	E F0(x mcs) p 
EE364A  Stochastic Programming	 12</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Solving stochastic programming problems
	analytical solution in special cases, e.g., when expectations can be 
found analytically 
	 entersquadratically in fi 
	 takes on nitely many values 
	general case: approximatesolutionvia(MonteCarlo) sampling 
EE364A  Stochastic Programming	 9</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Problem instance
 probleminstancehas n =10, m =5, d log-normal 
 certainty-equivalent problem yields upper bound 170.7 
 we use Monte Carlo sampling with N =2000 training samples
 validated with M =10000 validation samples 
training 
validation 
CE(using d) 
CE validation F0 
155.7
155.1
170.7
141.1
EE364A  Stochastic Programming 17</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Production planning with uncertain demand
	manufacturequantities q =(q1,...,qm)of m nishedproducts 
	purchase raw materials in quantities r =(r1,...,rn)with costs 
c =(c1,...,cn), so total cost is cT r 
	manufacturing process requires r  Aq 
Aij is amount of raw material i needed per unit of nished product j 
	productdemand d =(d1,...,dm)is random, with known distribution 
	product prices are p=(p1,...,pm), so total revenue is pT min(d,q) 
	maximize(expected) net revenue(over optimization variables q, r):
maximize E pT min(d,q)cT r 
subjectto r  Aq, q  0,r  0 
EE364A  Stochastic Programming	 16</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Chance constraints and percentile optimization
	chance constraints ( is condence level): 
Prob(fi(x,) 0)   
 convex in some cases 
 generally interestedin	 =0.9, 0.95, 0.99 
  =0.999 meaningless(unlessyoure sure aboutthedistributiontails) 
 percentile optimization( is -percentile): 
minimize  
subjectto Prob(f0(x,) )  
 convex or quasi-convex in some cases 
 these topics covered next lecture 
EE364A  Stochastic Programming	 8</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Stochastic programming example
 minimize E Axb1; Aij uniform on Aij ij; bi uniform on bi i 
 objective PDFs for stochastic optimal and certainty-equivalent solutions 
 lowerboundfromCEproblem: 5.96 
0 2 4 6 8 10 12 14 16 18 stochastic solution 
certainty equivalent solution
0 2 4 6 8 10 12 14 16 18
EE364A  Stochastic Programming 6</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>F0 (training) 
F0 (validation) 
F1 (training) 
F1 (validation) 
we conclude: N =10
51.8
56.0
0
1.3
N =100
54.0
54.8
0
0.7
N =1000
55.4
55.2
0
0.03
 N =10 is too few samples 
 N =100 is better, but not enough
 N =1000 is probably ne 
EE364A  Stochastic Programming 15</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Interior-point methods
Barrier method; sequential unconstrained minimization; self-concordance complexity analysis.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec18/</lecture_pdf_url>
      <lectureno>18</lectureno>
      <slides>
        <slide>
          <slideno>29</slideno>
          <text>102 Examples
second-order cone program (50 variables, 50 SOC constraints in R6)
Newton iterations 
0 40 80 120 102
dualitygap
100
102
104
 = 50  = 200  = 
0 20 40 60 80 20 60 100 140 180 
Newton iterations  
semideniteprogram (100 variables, LMI constraint in S100) 
140 106
 2
Newton iterations 
0 20 40 60 80 100 120 20 60 100 100
102
104
 =  = 50  = 150 dualitygap
106
 2
0 20 40 60 80 100 
Newton iterations  
Interior-point methods 1230</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>polynomial-time complexity of barrier method 
for  =1+1/m:  
N = O m log m/t(0) 
 
number of Newton iterations for xed gap reduction is O(m)  
	multiply with cost of oneNewtoniteration(apolynomialfunction of 
problem dimensions), to get bound on number of ops 
this choice of  optimizes worst-case complexity; in practice we choose  
xed( =10,..., 20) 
Interior-point methods	 1222</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>sum of infeasibilities phase I method 
minimize 1Ts 
subject to s 0,fi(x)si,i =1,...,m 
Ax = b 
for infeasible problems, produces a solution that satises many more 
inequalities than basic phase I method 
example (infeasible set of 100 linear inequalities in 50variables) 
60 60 number
40
20
number
40
20
0 0 1 0.50 0.511.5 1 0.50 0.511.5 
bi  aiTxmax bi  aiTxsum 
left: basic phase I solution; satises 39 inequalities 
right: sum of infeasibilities phase I solution; satises 79 solutions 
Interior-point methods 1217</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Generalizedinequalities
minimize	f0(x) 
subject to	fi(x)Ki 0,i =1,...,m 
Ax = b 
f0 convex, fi : Rn Rki , i =1,...,m, convex with respect to proper  
cones Ki	Rki 
	fi twice continuously dierentiable 
	A Rpn with rank A = p 
 	we assume p is nite and attained 
	we assume problem is strictly feasible; hence strong duality holds and 
dual optimum is attained 
examples of greatest interest: SOCP, SDP 
Interior-point methods	 1223</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>logarithmicbarrierfunction
m 
(x)=  log(fi(x)), dom  = {x |f1(x)&lt; 0,...,fm(x)&lt; 0}
i=1 
 convex(followsfrom composition rules) 
 twice continuously dierentiable, with derivatives 
m  1
(x)= fi(x)fi(x)
i=1 
m m  1  1  2(x)= fi(x)2 fi(x)fi(x)T + fi(x) 2fi(x) 
i=1 i=1 
Interior-point methods 125</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>102 Examples 
inequalityformLP (m =100 inequalities, n =50 variables) 
140 
 =  = 50  = 150 
0 20 40 60 80 104 80 
0 0 40 80 120 160 200 
Newton iterations  
starts with x on centralpath(t(0) =1,dualitygap 100)Newton iterations 
 
terminates when t =108 (gap106)  
 centering uses Newtons method with backtracking 
 total number of Newton iterations not very sensitive for  10 
Interior-point methods 1213 120
100
dualitygap
100
102
60
40
106
 2 20</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>example: family of linear inequalities Ax b + b 
 data chosen to be strictly feasible for &gt; 0,infeasiblefor  0 
 use basic phase I, terminate when s&lt; 0 or dual objective is positive Newton iterations
Infeasible Feasible 
0 20 40 60 80 100 
1 0.5 0 0.5 1 Newton iterations
0 20 40 60 80 100 
Newton iterations 
0 20 40 60 80 100 
100 102 104 106 106 104 102 100 
  
number of iterations roughly proportional to log(1/)||
Interior-point methods 1218</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Convergence analysis 
number of outer(centering) iterations: exactly 
log(m/(t(0))) 
log 
plus theinitial centering step(tocompute x (t(0))) 
centeringproblem 
minimize tf0(x)+(x) 
see convergence analysis of Newtons method 
tf0 +  must have closed sublevel sets for t t(0)  
 classical analysis requires strong convexity, Lipschitz condition 
 analysis via self-concordance requires self-concordance of tf0 +  
Interior-point methods 1212</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Logarithmic barrier and central path
logarithmicbarrier for f1(x)K1 0, ..., fm(x)Km 0: 
m 
(x)=  i(fi(x)), dom  = {x |fi(x)Ki 0,i =1,...,m}
i=1 
 i isgeneralizedlogarithmfor Ki, with degree i 
  is convex, twice continuously dierentiable 
centralpath: {x (t)|t&gt; 0}where x (t)solves 
minimize tf0(x)+(x) 
subject to Ax = b 
Interior-point methods 1226</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Logarithmicbarrier 
reformulation of(1) viaindicatorfunction: 
minimize f0(x)+ m
i=1 I(fi(x)) 
subject to Ax = b 
where I(u)=0 if u 0, I(u)= otherwise(indicatorfunction of R) 
approximation via logarithmic barrier 
minimize f0(x)(1/t) m log(fi(x)) i=1 
subject to Ax = b 
10 
	an equality constrained problem 
5 	for t&gt; 0, (1/t)log(u)is a 
smooth approximation of I 0 
	approximation improves as t  
5 3 2 1 0 1 u 
Interior-point methods	 124</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>family of standard LPs (A Rm2m) 
minimize cTx 
subject to Ax = b, x 0 
m =10,..., 1000; for each m, solve 100 randomly generated instances Newton iterations
35 
30 
25 
20 
15 
101 102 103 
m 
number of iterations grows very slowly as m ranges over a 100 :1 ratio 
Interior-point methods 1215</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>total number of Newton iterations (excludingrst centering step) 
log(m/(t(0))) m( 1log)#Newtoniterations N = log	  + c N
5 104 
4 104 
3 104 
2 104 
1 104 
0 gure shows N for typical values of , c, 
m =100,m =105 
t(0) 
1	 1.1 1.2

 conrms trade-o in choice of  
 inpractice,	#iterations is in the tens; not very sensitive for  10 
Interior-point methods	 1221</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
12. Interior-point methods 
	inequality constrained minimization 
	logarithmic barrier function and central path 
barrier method  
	feasibility and phase I methods 
	complexity analysis via self-concordance 
	generalizedinequalities 
121</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Complexity analysis via self-concordance
same assumptions as on page 122, plus: 
	sublevel sets(of f0, on the feasible set) are bounded 
	tf0 +  is self-concordant with closed sublevel sets 
second condition 
	holds for LP, QP, QCQP 
	may require reformulating the problem, e.g., 
minimize in 
=1 xi logxi	 minimize in 
=1 xi logxi 
subject to Fx g	 subject to Fx g, x 0 
	needed for complexity analysis; barrier method works even when 
self-concordance assumption does not apply 
Interior-point methods	 1219</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Barrier method
given strictlyfeasible x, t := t(0) &gt; 0, &gt; 1,tolerance &gt; 0. 
repeat 
1.	Centering step. Compute x (t) by minimizing tf0+ , subject to Ax = b. 
2.	Update. x := x (t). 
3.	Stopping criterion. quit if m/t&lt;. 
4.	Increase t. t := t. 
 	terminates with f0(x)p  (stoppingcriterion follows from 
f0(x (t))p  m/t) 
	centering usually done using Newtons method, starting at current x 
	choice of  involves a trade-o: large  means fewer outer iterations, 
moreinner(Newton) iterations; typical values:  =1020 
several heuristics for choice of t(0)  
Interior-point methods	 1211</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Force eld interpretation
centeringproblem (for problem with no equalityconstraints) 
minimize tf0(x) m log(fi(x)) i=1 
force eld interpretation 
 tf0(x)is potential of force eld F0(x)= tf0(x) 
log(fi(x))is potential of force eld Fi(x)=(1/fi(x))fi(x) 
the forces balance at x (t): 
m 
F0(x  (t))+ Fi(x  (t))=0 
i=1 
Interior-point methods 129</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Centralpath
for t&gt; 0,dene x (t)as the solution of  
minimize tf0(x)+(x) 
subject to Ax = b 
(for now, assumex (t)exists and is unique for each t&gt; 0) 
 centralpathis {x (t)|t&gt; 0} 
example: central path for an LP 
 x (10) c 
minimize cTx 
subject to aiTx bi,i =1,..., 6 
x 
hyperplane cTx = cTx (t)is tangent to 
level curve of  through x (t) 
Interior-point methods 126</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Inequality constrained minimization
minimize	f0(x) 
subject to	fi(x)0,i =1,...,m (1) 
Ax = b 
 fi convex, twice continuously dierentiable 
 A Rpn with rank A = p 
  we assume p is nite and attained 
	we assume problem is strictly feasible: there exists xwith 
xdom f0,fi(x)&lt; 0,i =1,...,m, Ax= b 
hence, strong duality holds and dual optimum is attained 
Interior-point methods	 122</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Newton iterations per centering step: from self-concordance theory
#Newtoniterations  tf0(x)+(x)tf0(x+)(x+)+ c  
bound on eort of computing x+ = x (t)starting at x = x (t)  
 , c are constants(depend only onNewton algorithmparameters) 
fromduality(with  = (t),  = (t)):  
tf0(x)+(x)tf0(x +)(x +) 
m 
= tf0(x)tf0(x +)+ log(tifi(x +))m log 
i=1 
m 
 tf0(x)tf0(x +)t ifi(x +)m m log 
i=1 
 tf0(x)tg(,)m m log 
= m( 1log) 
Interior-point methods 1220</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Feasibility and phase I methods 
feasibilityproblem: nd x such that 
fi(x)0,i =1,...,m, Ax = b (2) 
phaseI: computes strictly feasible starting point for barrier method 
basic phase I method 
minimize(over x, s) s 
subject to fi(x)s, i =1,...,m (3) 
Ax = b 
 if x, s feasible, with s&lt; 0, then x is strictly feasiblefor(2) 
  if optimal value pof(3) ispositive, thenproblem(2) isinfeasible 
  if p=0 and attained, thenproblem(2) isfeasible(butnotstrictly); 
if p=0 and notattained, thenproblem(2) isinfeasible 
Interior-point methods 1216</text>
        </slide>
        <slide>
          <slideno>32</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>example
minimize cTx 
subject to aT
i x bi,i =1,...,m 
 objective force eld is constant: F0(x)= tc 
 constraint force eld decays as inverse distance to constraint hyperplane: 
Fi(x)= a
ai
T , Fi(x)2 = dist(1 
x, Hi) bi i x 
where Hi = {x |aiTx = bi} 
c 
3c 
t =1 t =3 
Interior-point methods 1210</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>example: semidenite programming (withFi Sp) 
minimize cTx 
subject to F (x)= in 
=1 xiFi + G 0
logarithmicbarrier: (x)=logdet(F (x)1)
  
centralpath: x (t)minimizes tcTx logdet(F (x));hence  
tci tr(FiF (x  (t))1)=0,i =1,...,n 
dual point on central path: Z(t)= (1/t)F (x (t))1 isfeasiblefor  
maximize tr(GZ) 
subject to tr(FiZ)+ci =0,i =1,...,n 
Z 0 
duality gap on central path: cTx (t)tr(GZ(t))= p/t  
Interior-point methods 1228</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>Primal-dual interior-point methods
more ecient than barrier method when high accuracy is needed 
	update primal and dual variables at each iteration; no distinction 
between inner and outer iterations 
	often exhibit superlinear asymptotic convergence 
	search directions can be interpreted as Newton directions for modied 
KKT conditions 
	can start at infeasible points 
	cost per iteration same as barrier method 
Interior-point methods	 1232</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>geometricprogram (m =100 inequalities and n =50 variables)
5minimize log k=1 exp(a0T
kx + b0k) 
subject to log 
k5
=1 exp(aikT x + bik) 0,i =1,...,m duality gap 
 = 2  = 50  = 150 106 104 102 100 102 
0 20 40 60 80 100 120
Newton iterations 
Interior-point methods 1214</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Examples
	LP, QP, QCQP, GP 
	entropy maximization with linear inequality constraints 
minimize 
in 
=1 xi logxi 
subject to Fx g 
Ax = b 
with dom f0 = Rn 
++ 
	dierentiability may require reformulating the problem, e.g., 
piecewise-linear minimization or -norm approximation via LP 
	SDPs and SOCPs are better handled as problems with generalized 
inequalities(seelater) 
Interior-point methods	 123</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Dual points on central path 
x = x (t)if there exists w Rp , 
m 
tf0(x)+ Dfi(x)T i(fi(x))+AT w =0 
i=1 
(Dfi(x)Rkin is derivative matrix of fi) 
therefore, x (t)minimizesLagrangian L(x,(t),(t)), where  
 
i(t)=1 
t i(fi(x  (t))),  (t)= w 
t 
from properties of i: 
i(t)K 0, with duality gap i 
m 
f0(x  (t))g(  (t),  (t))=(1/t) i 
i=1 
Interior-point methods 1227</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Barrier method
given strictlyfeasible x, t := t(0) &gt; 0, &gt; 1,tolerance &gt; 0. 
repeat 
1. Centering step. Compute x (t) by minimizing tf0+ , subject to Ax = b. 
 2. Update. x := x (t). 
3. Stopping criterion. quit if (P
ii)/t&lt;. 
4. Increase t. t := t. 
only dierenceisdualitygap m/t on central path is replaced by i/t  i 
number of outer iterations:  
log(( i i)/(t(0))) 
log 
 complexity analysis via self-concordance applies to SDP, SOCP 
Interior-point methods 1229</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>properties (without proof): fory K 0, 
(y)K 0,y T (y)=  
nonnegative orthant Rn : (y)= n logyi  + i=1 
(y)=(1/y1,..., 1/yn),y T (y)= n 
	positive semidenite cone S+n : (Y )=logdetY 
(Y )= Y 1 , tr(Y (Y ))= n 
 second-order cone K = {y Rn+1 |(y12 +  + yn2 )1/2 yn+1}: 
  

.y1 
2	  .. T   (y)= ,y (y)=2 yn2
+1 y12  yn 2  yn  
yn+1 
Interior-point methods	 1225</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>family of SDPs (A Sn , x Rn) 
minimize 1Tx 
subject to A + diag(x)0 
n =10,..., 1000, for each n solve 100 randomlygeneratedinstances Newton iterations
35 
30 
25 
20 
15 
101 102 103 
n 
Interior-point methods 1231</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Dual points on central path 
x =	x (t)if there exists a w such that 
m 
tf0(x)+  
f1 
i(x)fi(x)+AT w =0, Ax = b 
i=1 
therefore, x (t)minimizes the Lagrangian  
m 
L(x,  (t),  (t))= f0(x)+ i (t)fi(x)+  (t)T(Ax b) 
i=1 
where we dene i(t)=1/(tfi(x (t))and (t)= w/t 
 this conrms the intuitive idea that f0(x (t))p  if t : 
p 	 g(  (t),  (t)) 
= L(x  (t),  (t),  (t)) 
= f0(x  (t))m/t 
Interior-point methods	 127</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Interpretation via KKT conditions
x = x (t),  = (t),  = (t)satisfy 
1. primal constraints: fi(x)0, i =1,...,m, Ax = b 
2. dual constraints:  0 
3. approximate complementary slackness: ifi(x)=1/t, i =1,...,m 
4. gradient of Lagrangian with respect to x vanishes: 
m 
f0(x)+ ifi(x)+AT =0 
i=1 
dierence with KKT is that condition 3 replaces ifi(x)=0 
Interior-point methods 128</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Generalized logarithm for proper cone
 : Rq R is generalized logarithm for proper cone K Rq if: 
dom  = int K and 2(y)0 for y K 0  
 (sy)= (y)+ logs for y K 0, s&gt; 0 ( is the degree of ) 
examples 
nonnegative orthant K = Rn : (y)= n logyi, with degree  = n  + i=1 
 positive semidenite cone K = S+n : 
(Y )=logdetY ( = n) 
 second-order cone K = {y Rn+1 |(y12 +  + y2 )1/2 yn+1}:n
(y)=log(y 2 2 2 )( =2) n+1 y1  yn
Interior-point methods 1224</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Miscellaneous applications
Multi-period processor speed scheduling; minimum time optimal control; grasp force optimization; optimal broadcast transmitter power allocation; phased-array antenna beamforming; optimal receiver location.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec10/</lecture_pdf_url>
      <lectureno>10</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>Minimum-time optimal control 
 linear dynamical system: 
xt+1 = Axt + But,t =0,1,...,K, x0 = x init 
 inputs constraints: 
umin ut	umax,t =0,1,...,K 
	minimum time to reach state xdes: 
f(u0,...,uK) = min {T |xt = xdes for T t K +1} 
6</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>tar = 30 
10 50 
 
 
|y()| 
sidelobe level 
20</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Optimal broadcast transmitter power allocation
 m transmitters, mn receivers all at same frequency 
 transmitter i wants to transmit to n receiverslabeled (i,j), j=1,...,n 
 Aijk is path gain from transmitter k to receiver (i,j) 
 Nij is(self) noisepower of receiver (i,j) 
 variables: transmitter powers pk, k =1,...,m 
transmitter i transmitter k 
receiver (i,j) 
13</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Example
12</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>at receiver (i,j): 
 signalpower: 
Sij = Aijipi 
 noiseplusinterferencepower: 
Iij = Aijkpk + Nij 
k/negationslash=i 
 signal tointerference/noiseratio(SINR): Sij/Iij 
problem:	choose pi to maximize smallest SINR: 
Aijipimaximize min  
i,j k/negationslashAijkpk + Nij =i 
subject to 0 pi pmax 
. . .a(generalized) linearfractionalprogram 
14</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>(signal)receiver power from ai: x ai2 ( 2.1) 
 (interfering)receiver power from bi: x bi  ( 2.1)2 
 worst signal to interference ratio, over all frequencies, is 
 
S/I = min x ai2 
i x bi2 
 what receiver location x maximizesS/I? 
23</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex optimization examples 
 multi-period processor speed scheduling 
 minimum time optimal control 
 grasp force optimization 
 optimal broadcast transmitter power allocation 
 phased-array antenna beamforming 
 optimal receiver location 
1</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>state transfer time f is quasiconvex function of (u0,...,uK): 
f(u0,u1,...,uK) T 
if and only if for all t = T,...,K +1 
xt = At x init + At1Bu0 ++ But1 = xdes  
i.e., sublevel sets are ane 
minimum-time optimal control problem: 
minimize f(u0,u1,...,uK)
subject to umin ut umax,t =0,...,K
with variables u0,...,uK 
a quasiconvex problem; can be solved via bisection 
7</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Optimal and uniform schedules 
uniform schedule: Sti = Wi/(Di Ai + 1);gives Eunif = 204.3  
 ti;gives optimal schedule: S E = 167.1 
optimal uniform 
6 6 
5 5 
4 4 
0 2 4 6 8 10 12 14 16 18 st
3 
2 
1 
0 
0 2 4 6 8 10 12 14 16 18 
s t3 
2 
1 
0 
t
 t
5</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>0.5 2 2.5 3 With vibration modes 
 no analytical solution 
 a quasiconvex problem; solved using bisection 
1 
2 0 2 4 6 8 10 12 14 16 18 20 
t 
(ut ) 2 (ut ) 1 
1 
2 0 2 4 6 8 10 12 14 16 18 20 
1.5 t 
0.1 
1 0.5 
0 
0.5 
0.05 
0 
0.05 
0.1 
0 
2 0 2 4 6 8 10 12 14 16 18 20 
t 
10 (xt )3</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Phased-array antenna beamforming
(xi, yi) 
 
	omnidirectional antenna elements at positions (x1,y1), ..., (xn,yn) 
unit plane wave incident from angle  inducesin ith element a signal 	
j(xi cos +yi sin t)e
(j	= 1,frequency , wavelength 2) 
15</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Grasp force optimization
 choose K grasping forces on object 
 resist external wrench 
 respect friction cone constraints 
 minimize maximum grasp force 
 convexproblem(second-order coneprogram): 
minimize maxi f(i)2 max contact force 
subject to  
i Q(i)f(i) = fext force equillibrium 
i p(i) (Q(i)f(i))= ext torque equillibrium 
if3(i)   
f1(i)2 + f2(i)2 1/2 
friction cone contraints 
variables f(i) R3 , i =1,...,K (contactforces) 
11</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Minimum-time control example
u1 
u2 
 force (ut)1 moves object modeled as3 masses(2 vibration modes) 
 force (ut)2 used for active vibration suppression 
 goal: move object to commanded position as quickly as possible, with 
|(ut)1|1, |(ut)2|0.1,t =0,...,K 
8</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Multi-period processor speed scheduling
processor adjusts its speed st [smin,smax] in each of T timeperiods  
T energy consumed in period t is (st); total energy is E = (st)  t=1 
 n jobs 
 jobi available at t = Ai; must nish by deadline t = Di 
 jobi requires total work Wi 0 
 ti 0 isfractionofprocessoreortallocated tojob i inperiod t 
Di 
1Tt =1, tist Wi 
t=Ai 
 choose speeds st and allocations ti to minimize total energy E 
2</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Optimal receiver location 
	N transmitterfrequencies 1,...,N 
transmitters at locations ai,bi R2 usefrequency i  
	transmitters at a1, a2, ..., aN are the wanted ones 
	transmitters at b1, b2, ..., bN areinterfering 
receiver at position x R2  
 b3 
a3  
a2   b2 
x 
a1  
 b1 
22</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Minimum energy processor speed scheduling 
 work with variables Sti = tist 
n Di 
st = Sti, Sti Wi 
i=1 t=Ai 
 solve convex problem 
Tminimize E = t=1 (st)
subject to smin s
nt smax ,t =1,...,T
st = i=1 Sti,t =1,...,T Di Sti Wi,i =1,...,n t=Ai 
 a convex problem when  is convex 
 can recover t as  = (1/s
t)S 
ti ti 
3</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>minimize sidelobe level (discretize angles) 
minimize maxi y(i)||
subject to y(tar)=1 
(max over angles outside beam) 
can be cast as SOCP 
minimize t 
subject to y(i)t ||
y(tar)=1 
19</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>S/I is quasiconcave on {x |S/I 1}, i.e., on 
{x |x ai2 x bi2,i =1,...,N} 
a1  a2  a3   b3 
 b2 
 b1 
can use bisection; every iteration is a convex quadratic feasibility problem
24</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Extensions 
convex(&amp;quasiconvex) extensions: 
 y(0)=0 (nullindirection0) 
 w is real(amplitude only shading) 
|wi|1 (attenuation onlyshading) 
 minimize 2 
in 
=1 |wi|2 (thermalnoise power in y) 
 minimize beamwidth given a maximum sidelobe level 
nonconvex extension: 
 maximize number of zero weights 
21</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>tar = 30 
10 50 
 
 
|y()| 
sidelobe level 
18</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Sidelobe level minimization 
make |y()|smallfor |tar|&gt; 
(tar: target direction; 2: beamwidth) 
via least-squares (discretize angles) 
minimize i y(i)2||
subject to y(tar)=1 
(sum is over angles outside beam) 
least-squaresproblem withtwo(real) linear equality constraints 
17</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>(xt )3
Ignoring vibration modes 
 treat object as single mass; apply only u1 
 analytical(bang-bang) solution 
1 
2 0 2 4 6 8 10 12 14 16 18 20 0 0.5 1 1.5 2 2.5 3 
t 
(ut ) 1 (ut ) 2 0.5 
0 
0.5 
1 
2 0 2 4 6 8 10 12 14 16 18 20 
t 
0.1 
0.05 
0 
0.05 
0.1 
2 0 2 4 6 8 10 12 14 16 18 20 
t 
9</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Example 
 T = 16 periods, n = 12 jobs 
smin =1, smax =6, (st)= s2  t 
 jobs shown as bars over[Ai,Di] with area Wi 
40 
12
35
1030 
25 
0 2 4 6 8 10 12 14 16 18 t (st )
20 
15 
10 
5 
0 
job i
8 
6 
4 
2 
0 
0 1 2 3 4 5 6 7 
st t 
4</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>demodulate to get output ej(xi cos +yi sin ) C  
	linearly combine with complex weights wi: 
n 
y()= wiej(xi cos +yi sin ) 
i=1 
	y() is(complex) antenna array gain pattern 
	|y()|gives sensitivity of array as function of incident angle  
	depends on design variables Re w, Im w 
(calledantenna array weights or shading coecients) 
design problem: choose w to achieve desired gain pattern 
16</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Unconstrained minimization
Gradient and steepest descent methods; Newton method; self-concordance complexity analysis.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec16/</lecture_pdf_url>
      <lectureno>16</lectureno>
      <slides>
        <slide>
          <slideno>9</slideno>
          <text>aprobleminR100
500
f(x)= c T x 
log(bi a T
i x) 
i=1 
104
0 50 100 150 200
k f(x (k) ) p  
exact l.s. 
backtracking l.s. 
104 102 100 102 
linear convergence, i.e., a straight line on a semilog plot
Unconstrained minimization 1010</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Strong convexity and implications
f is strongly convex on S if there exists an m&gt; 0 such that 
2f(x) mI for all x  S 
implications 
 for x,y  S, 
f(y) f(x)+f(x)T(y x)+ m x y2
22 
hence, S isbounded 
 p  &gt; , and for x  S, 
f(x)p   1 f(x)2
22m
useful as stopping criterion(ifyouknow m)
Unconstrained minimization 104</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>examples 
 Euclidean norm: xsd = f(x) 
 quadratic norm xP =(xTPx)1/2 (P  Sn ): P 1f(x)++xsd = 
 1-norm: xsd = (f(x)/xi)ei, where |f(x)/xi|= f(x) 
unit balls and normalized steepest descent directions for a quadratic norm 
and the 1-norm: 
xnsd f(x) 
f(x) 
xnsd 
Unconstrained minimization 1012</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Steepest descent method 
normalized steepest descent direction (atx, for norm ): 
xnsd =argmin{f(x)T v |v =1} 
interpretation: for small v, f(x + v) f(x)+f(x)Tv; 
direction xnsd is unit-norm step with most negative directional derivative 
(unnormalized) steepest descent direction 
xsd = f(x)xnsd 
satises f(x)Tsd = f(x)2 
 
steepest descent method 
 general descent method with x =xsd 
 convergence properties similar to gradient descent 
Unconstrained minimization 1011</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>dampedNewtonphase (f(x)2  ) 
 most iterations require backtracking steps 
 function value decreases by at least  
 if p  &gt; , this phase ends after at most (f(x(0))p )/ iterations 
quadratically convergent phase (f(x)2 &lt;) 
 all iterations use step size t =1 
 f(x)2 converges to zero quadratically: if f(x(k))2 &lt;, then 
L  L 2lk 12lk 
f(x l)2  f(x k)2  ,l  k 2m2 2m2 2 
Unconstrained minimization 1019</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>Implementation
main eort in each iteration: evaluate derivatives and solve Newton system 
Hx = g 
where H = 2f(x), g = f(x) 
viaCholeskyfactorization 
H = LLT , xnt = LTL1 g, (x)= L1 g2 
 cost (1/3)n3 ops for unstructured system 
 cost  (1/3)n3 if H sparse,banded 
Unconstrained minimization 1029</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Convergence analysis for self-concordant functions
summary: there exist constants   (0, 1/4], &gt; 0 such that 
 if (x)&gt;, then 
f(x(k+1))f(x(k)) 
 if (x) , then 
2(x(k+1)) 
2(x(k))2 
( and  only depend on backtracking parameters , ) 
complexitybound: number of Newton iterations bounded by 
f(x(0))p  
+log2 log2(1/) 
for  =0.1,  =0.8,  =1010, bound evaluates to 375(f(x(0))p )+6 
Unconstrained minimization 1027</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>conclusion: number of iterations until f(x)p    is bounded above by
f(x(0))p  
+log2 log2(0/) 
	, 0 are constants that depend on m, L, x(0) 
	second termissmall(oftheorderof 6)and almost constant for 
practicalpurposes 
	in practice, constants m, L (hence, 0)are usually unknown 
	providesqualitativeinsightin convergenceproperties(i.e., explains two 
algorithmphases) 
Unconstrained minimization	 1020</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Examples
exampleinR2 (page109) 
105 
x(0) 
x(1) 
f(x (k)) p
100 
105 
1010 
1015 
0 1 2 3 4 5 
k 
 backtrackingparameters  =0.1,  =0.7 
 converges in only 5 steps 
 quadratic local convergence 
Unconstrained minimization 1021</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>exampleinR10000 (with sparseai)
10000 100000
f(x)=  
log(1xi2)  
log(bi aiT x) 
i=1 i=1 
105 f(x (k) ) p  
105 100 
0 5 10 15 20 
k 
 backtrackingparameters  =0.01,  =0.5. 
 performance similar as for small examples 
Unconstrained minimization 1023</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
10. Unconstrained minimization
 terminology and assumptions 
 gradient descent method 
 steepest descent method 
 Newtons method 
 self-concordantfunctions 
 implementation 
101</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>xnt is steepest descent direction at x in local Hessian norm 
u2f(x) = 
u T2f(x)u1/2 
x 
x + xnt x + xnsd 
dashed lines are contour lines of f; ellipse is {x + v |vT2f(x)v =1} 
arrow shows f(x) 
Unconstrained minimization 1015</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>nonquadratic example 
f(x1,x2)= e x1+3x20.1 + e x13x20.1 + e x10.1 
x(0) 
x(1) x(2) x(0) 
x(1) 
backtracking line search exact line search
Unconstrained minimization 109</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Classical convergence analysis
assumptions 
 f strongly convex on S with constant m 
2f is Lipschitz continuous on S, with constant L&gt; 0: 
2f(x)2f(y)2  Lx y2 
(L measures how well f can be approximated by a quadratic function) 
outline: there exist constants   (0,m2/L), &gt; 0 such that 
 if f(x)2  , then f(x(k+1))f(x(k)) 
 if f(x)2 &lt;, then 
L f(x(k+1))2   L f(x(k))2 2 
2m2 2m2
Unconstrained minimization 1018</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Newtondecrement
(x)= 
f(x)T2f(x)1f(x)1/2 
a measure of the proximity of x to x 
properties 
 gives an estimate of f(x)p , using quadratic approximation f: 
1 (x)2f(x)inf f(y)= 
y 
2 
 equal to the norm of the Newton step in the quadratic Hessian norm 
(x)= 
xntT 2f(x)xnt1/2 
 directional derivative in the Newton direction: f(x)Txnt = (x)2 
 aneinvariant(unlike f(x)2) 
Unconstrained minimization 1016</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Self-concordantfunctions
denition 
	convex f : R  R is self-concordant if |f  (x)|2f  (x)3/2 for all 
x  dom f 
	f : Rn  R is self-concordant if g(t)= f(x + tv)is self-concordant for 
all x  dom f, v  Rn 
examples on R 
	linear and quadratic functions 
	negativelogarithm f(x)= logx 
	negative entropy plus negative logarithm: f(x)= x logx logx 
aneinvariance: if f : R  R is s.c., then f(y)= f(ay + b)is s.c.: 
f (y)3f  (ay + b),f (y)2f  (ay + b) = a	 = a 
Unconstrained minimization	 1025</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Gradient descent method 
general descent method with x = f(x) 
given a starting point x  dom f. 
repeat 
1. x := f(x). 
2. Line search. Choose step size t via exact or backtracking line search. 
3. Update. x := x + tx. 
until stopping criterion is satised. 
 stopping criterion usually of the form f(x)2   
 convergence result: for strongly convex f, 
f(x(k))p   c k(f(x(0))p  )
c  (0, 1) depends on m, x(0), line search type
 very simple, but often very slow; rarely used in practice 
Unconstrained minimization 107</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>numerical example: 150 randomly generated instances of 
Tminimize f(x)= m
i=1 log(bi ai x) 
25 
20 
: m =100, n =50
/square: m =1000, n =500
: m =1000, n =50
iterations
15
10
5 
0 05 101520253035 
f(x(0)) p 
 number of iterations much smaller than 375(f(x(0))p )+6 
 bound of the form c(f(x(0))p )+6with smaller c (empirically)valid 
Unconstrained minimization 1028</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Self-concordance
shortcomings of classical convergence analysis 
	depends on unknown constants(m, L, ...) 
	bound is not anely invariant, although Newtons method is 
convergence analysis via self-concordance (Nesterov and Nemirovski) 
	does not depend on any unknown constants 
	gives ane-invariant bound 
	applies tospecial classof convexfunctions(self-concordantfunctions) 
	developed to analyze polynomial-time interior-point methods for convex 
optimization 
Unconstrained minimization	 1024</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Initial point and sublevel set 
algorithms in this chapter require a starting point x(0) such that 
 x(0)  dom f 
 sublevel set S = {x |f(x) f(x(0))}is closed 
2nd condition is hard to verify, except when all sublevel sets are closed: 
 equivalent to condition that epi f is closed 
 trueif dom f = Rn 
 trueif f(x) as x  bddom f 
examples of dierentiable functions with closed sublevel sets: 
f(x)=log(
exp(a
T 
i x + bi)), f(x)= 
 log(bi 
a
T 
i x) m m 
Unconstrained minimization 103 i=1 i=1</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>example of dense Newton system with structure
n
f(x)= 
i(xi)+0(Ax + b),H = D + ATH0A 
i=1 
 assume A  Rpn, dense, with p  n 
 D diagonal with diagonal elements i  (xi); H0 = 20(Ax + b) 
method1: form H, solve via dense Cholesky factorization: (cost (1/3)n3) 
method2 (page 915): factorH0 = L0L0 T; write Newton system as 
Dx + ATL0w = g, LT 
0 Ax w =0 
eliminate x from rst equation; compute w and x from 
(I + LT 
0 AD1ATL0)w = LT 
0 AD1 g, Dx = g ATL0w 
cost: 2p2n (dominated bycomputation of LT 
0 AD1ATL0) 
Unconstrained minimization 1030</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Newton step 
xnt = 2f(x)1f(x) 
interpretations 
	x +xnt minimizes second order approximation 
f(x + v)= f(x)+f(x)T v +21 v T2f(x)v 
	x +xnt solves linearized optimality condition 
f(x + v)f(x + v)= f(x)+2f(x)v =0 
f bf 
(x, f(x)) 
(x + xnt, f(x + xnt)) f  bf  
(x, f  (x)) (x + xnt, f  (x + xnt)) 
Unconstrained minimization	 1014</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Unconstrained minimization
minimize f(x) 
 f convex,twice continuously	dierentiable(hence dom f open) 
  we assume optimal value p	=infx f(x)is attained(and nite) 
unconstrained minimization methods 
	produce sequence of points x(k)  dom f, k =0, 1,... with 
f(x(k)) p  
	can be interpreted as iterative methods for solving optimality condition 
f(x  )=0 
Unconstrained minimization	 102</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>quadraticprobleminR2 
f(x)=(1/2)(x 2
1 + x22) (&gt; 0) 
with exact line search, starting at x(0) =(, 1): 
 1k   1k 
x(
1 k) =  ,x(
2 k) =   +1  +1 
 very slow if   1 or   1 
 examplefor  =10: x2 x(0) 
x(1) 0 4 
4
10 0 10 x1 
Unconstrained minimization 108</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Descent methods
x(k+1) = x(k)+ t(k)x(k) with f(x(k+1))&lt;f(x(k)) 
	other notations: x+ = x + tx, x := x + tx 
	x is the step, or search direction; t is the step size, or step length 
	from convexity, f(x+)&lt;f(x)implies f(x)Tx&lt; 0 
(i.e., x is a descent direction) 
General descent method. 
given a starting point x  dom f. 
repeat 
1. Determine a descent direction x. 
2.	Line search. Choose a step size t&gt; 0. 
3.	Update. x := x + tx. 
until stopping criterion is satised. 
Unconstrained minimization	 105</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>choice of norm for steepest descent
x(0) 
x(1) x(2) x(0) 
x(1) x(2) 
	steepest descent with backtracking line search for two quadratic norms 
	ellipses show {x |x x(k)P =1} 
	equivalent interpretation of steepest descent with quadratic norm P: 
gradient descent after change of variables x= P 1/2x 
shows choice of P has strong eect on speed of convergence 
Unconstrained minimization	 1013</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Self-concordant calculus
properties 
 preserved under positive scaling   1, and sum 
 preserved under composition with ane function 
 if g is convex with dom g = R++ and |g  (x)|3g  (x)/x then 
f(x)=log(g(x))logx 
is self-concordant 
examples: properties can be used to show that the following are s.c. 
 f(x)= m
i=1 log(bi aiTx)on {x |aiTx&lt;bi,i =1,...,m} 
 f(X)= logdetX on Sn 
++ 
 f(x)= log(y2 xTx)on {(x,y)|x2 &lt;y} 
Unconstrained minimization 1026</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Line search types 
exact line search: t =argmint&gt;0 f(x + tx)
backtracking line search (withparameters  (0, 1/2),   (0, 1))
	starting at t =1, repeat t := t until 
f(x + tx)&lt;f(x)+tf(x)Tx 
 graphical interpretation: backtrack until t  t0 
t = 0	 t0 f(x + tx) 
f(x)+ tf(x)Tx f(x)+ tf(x)Tx 
t 
Unconstrained minimization	 106</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>exampleinR100 (page1010) 
2 105 
exact line search 
1.5 100 
backtracking backtracking 
1010 exact line search 
0.5 step size t (k)
105
 1
1015 0 0 2 4 6 8 10 0 2 4 6 
k k 
 backtrackingparameters  =0.01,  =0.5 
 backtracking line search almost as fast as exact l.s. (andmuch simpler) 
 clearly shows two phases in algorithm 
Unconstrained minimization 1022 f(x (k)) p
8</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Newtons method
given a starting point x  dom f,tolerance &gt; 0. 
repeat 
1. Compute the Newton step and decrement. 
xnt := 2f(x)1f(x); 2:= f(x)T2f(x)1f(x). 
2. Stopping criterion. quit if 2/2  . 
3. Line search. Choose step size t by backtracking line search. 
4. Update. x := x + txnt. 
aneinvariant, i.e., independent of linear changes of coordinates: 
Newtoniteratesfor f(y)= f(Ty)with starting point y(0) = T 1x(0) are 
y(k) = T 1 x(k) 
Unconstrained minimization 1017</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Convex sets
Convex sets and cones; some common and important examples; operations that preserve convexity.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec02/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>18</slideno>
          <text>Separatinghyperplanetheorem
if C and D are disjoint convex sets, then there exists a =0, b such that 
a T x  b for x  C, a T x  b for x  D 
aTx  b aTx  b 
a D 
C 
thehyperplane {x |aTx = b}separates C and D 
strict separation requires additional assumptions(e.g., C is closed, D is a 
singleton) 
Convex sets 219</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Minimum and minimal elements
K is not in general a linear ordering: we can have x K y and y K x 
x  S is the minimum element of S with respect to K if 
y  S = x K y 
x  S is a minimal element of S with respect to K if 
y  S, y K x = y = x 
example (K = R+2 ) 
x1 is the minimum element of S1 
x2 is a minimal element of S2 x1 x2 S1 S2 
Convex sets 218</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>generalizedinequality dened by a proper cone K: 
x K y  yx  K, x K y  yx  int K 
examples 
= Rn 
+  componentwiseinequality(K
 )
x Rn 
 matrixinequality(K = Sn 
++y  xi  yi,i =1,...,n
)
X Sn 
these two types are so common that we drop the subscript in K 
properties: many properties of K are similar to  on R, e.g., 
x K y, u K v = x + u K y+ v + Y  Y X positive semidenite
Convex sets 217</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Dual cones and generalized inequalities 
dual cone of a cone K: 
K  = {y |y T x  0 for all x  K} 
examples 
 K = Rn : K = Rn 
+ + 
 K = Sn : K = Sn 
+ + 
 K = {(x,t) |x2  t}: K = {(x,t) |x2  t} 
 K = {(x,t) |x1  t}: K = {(x,t) |x  t} 
rst three examples are self-dual cones
dual cones ofproper cones areproper,hencedenegeneralizedinequalities:
y K 0  y T x  0 for all x K 0 
Convex sets 221</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Intersection
theintersection of(any number of) convex setsis convex 
example: 
S = {x  Rm ||p(t)|1 for |t|/3} 
where p(t)= x1 cos t + x2 cos2t +  + xm cos mt 
for m =2: 
2 
1 
1 
S 
2 1 0 1 2 0
0 /3 2/3  
x2p(t)
1
0 
1 
2 
t x1 
Convex sets 212</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Norm balls and norm cones 
norm: afunction  that satises 
x 0; x =0 if and only if x =0 
tx = |t|x for t  R 
x + yx+ y 
notation:  isgeneral(unspecied) norm; symb is particular norm 
normball with center xc and radius r: {x |x xc r} 
1 
norm cone: {(x,t) |x t} 
0.5 
Euclidean norm cone is called second-
order cone 10 
1 
0 0 
x2 1 1 x1 t
norm balls and cones are convex 
Convex sets 28</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Operations that preserve convexity
practical methods for establishing convexity of a set C 
1. apply denition 
x1,x2  C, 0    1= x1 + (1 )x2  C 
2. show that C is obtainedfrom simple convex sets(hyperplanes, 
halfspaces,normballs, ...) by operationsthatpreserveconvexity 
 intersection 
 anefunctions 
 perspectivefunction 
 linear-fractionalfunctions 
Convex sets 211</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
2. Convex sets
 ane and convex sets 
 some important examples 
 operations that preserve convexity 
 generalizedinequalities 
 separating and supporting hyperplanes 
 dual cones and generalized inequalities 
21</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Euclidean balls and ellipsoids 
(Euclidean) ball with center xc and radius r: 
B(xc,r)= {x |x xc2  r}= {xc + ru |u2  1} 
ellipsoid: set of the form 
{x |(x xc)TP1(x xc)  1} 
with P  Sn (i.e., P symmetricpositivedenite) ++ 
xc 
other representation: {xc + Au |u2  1}with A square and nonsingular 
Convex sets 27</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Convex combination and convex hull
convex combination of x1,. . ., xk: any point x of the form 
x = 1x1 + 2x2 +  + kxk 
with 1 +  + k =1, i  0 
convexhull conv S: set of all convex combinations of points in S 
Convex sets 24</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Anefunction
suppose f	: Rn  Rm is ane(f(x)= Ax+ b with A  Rmn , b  Rm) 
	the image of a convex set under f is convex 
S  Rn convex = f(S)= {f(x) |x  S}convex 
	theinverseimage f1(C) of a convex set under f is convex 
C  Rm convex = f1(C)= {x  Rn |f(x)  C}convex 
examples 
	scaling, translation, projection 
	solution set of linear matrix inequality {x |x1A1 +  + xmAm  B} 
(withAi,B  Sp) 
	hyperbolic cone {x |xTPx  (cTx)2,cTx  0}(withP  Sn )+
Convex sets	 213</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Perspective and linear-fractional function
perspectivefunction P : Rn+1  Rn: 
P(x,t)= x/t, dom P = {(x,t) |t&gt; 0} 
images and inverse images of convex sets under perspective are convex 
linear-fractionalfunction f : Rn  Rm: 
f(x)= Ax+ b, dom f = {x |c T x + d&gt; 0} cTx + d
images and inverse images of convex sets under linear-fractional functions 
are convex 
Convex sets 214</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Convex cone
conic(nonnegative) combination of x1 and x2: any point of the form 
x = 1x1 + 2x2 
with 1  0, 2  0 
0 x1 
x2 
convex cone: set that contains all conic combinations of points in the set
Convex sets 25</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>optimalproductionfrontier 
	dierent production methods use dierent amounts of resources x  Rn 
	production set P: resource vectors x for allpossibleproduction methods 
	ecient(Pareto optimal) methods correspond to resource vectors x 
that are minimal w.r.t. Rn 
+ 
fuel 
example (n =2)
x1, x2, x3 are ecient; x4, x5 are not
x3 x2 x5 x4 x1 
 P 
labor 
Convex sets	 223</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Polyhedra
solution set of nitely many linear inequalities and equalities 
Ax  b, Cx = d 
(A  Rmn , C  Rpn ,  is componentwise inequality) 
a1 
a5 a2 
a4 P 
a3 
polyhedron is intersection of nite number of halfspaces and hyperplanes 
Convex sets 29</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Positive semidenite cone 
notation: 
 Sn is set of symmetric n  n matrices 
	S+ n = {X  Sn |X  0}: positive semidenite n  n matrices 
X  Sn  z TXz  0 for all z+ 
Sn is a convex cone + 
 S++ n = {X  Sn	|X  0}:positivedenite n  n matrices 
1 
example: xy  S2	0.5 
+yz 
0 z
1 
1 
0 0.5 
y 10 x 
Convex sets	 210</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Supporting hyperplane theorem
supportinghyperplane to set C atboundarypoint x0: 
{x |a T x = a T x0} 
where a Tx  Tx0 for all x  C =0 and a a
C a 
x0 
supporting hyperplane theorem: if C is convex, then there exists a 
supporting hyperplane at every boundary point of C 
Convex sets 220</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>Minimum and minimal elements via dual inequalities
minimum element w.r.t. K 
x is minimum element of S i for all 
 K 0, x is the unique minimizer 
of Tz over S 
minimal element w.r.t. K 
	if x minimizes Tz over S for some  K 0, then x is minimal x S 
Sx1 
x2 1 
2 
	if x is a minimal element of a convex set S, then there exists a nonzero 
 K 0 such that x minimizes Tz over S 
Convex sets	 222</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Hyperplanes and halfspaces 
hyperplane: set of the form {x |aTx = b}(a =0) 
a 
x0 
x 
aTx = b 
halfspace: set of the form {x |aT x  b}(a =0) 
a 
a T x  b 
a T x  b x0 
 a is the normal vector 
 hyperplanes are ane and convex; halfspaces are convex 
Convex sets 26</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Ane set
line through x1, x2: all points
x = x1 + (1 )x2 (  R)
 =1.2 x1
 =1
 =0.6 
x2 
 =0 
 = 0.2 
ane set: contains the line through any two distinct points in the set
example: solution set of linear equations {x |Ax = b}
(conversely, everyane set can be expressed as solution set of system of
linear equations)
Convex sets 22</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>example of a linear-fractional function 
1 f(x)= x x1 + x2 +1 
1 1 
f(C)Cx2
x2
0
 0
1 1 1 0 1 1 0 1 x1 x1 
Convex sets 215</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Convex set
line segment between x1 and x2: all points 
x = x1 + (1 )x2 
with 0    1 
convex set: contains line segment between any two points in the set 
x1,x2  C, 0    1= x1 + (1 )x2  C 
examples (one convex, two nonconvex sets) 
Convex sets 23</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Generalizedinequalities
a convex cone K  Rn is a proper cone if 
 K is closed(containsitsboundary) 
 K is solid(has nonempty interior) 
 K ispointed(contains noline) 
examples 
 nonnegative orthant K = Rn = {x  Rn |xi  0,i =1,...,n}+ 
 positive semidenite cone K = Sn 
+ 
 nonnegative polynomials on [0,1]: 
K = {x  Rn |x1 + x2t + x3t2 +  + xntn1  0 for t  [0,1]} 
Convex sets 216</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Chance constrained optimization
Chance constraints and percentile optimization; chance constraints for log-concave distributions; convex approximation of chance constraints.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec14/</lecture_pdf_url>
      <lectureno>14</lectureno>
      <slides>
        <slide>
          <slideno>15</slideno>
          <text>TraditionalChebyshevbound
	dropping subscript + we get more conservative constraint 
E i(fi(x,)/i +1)2 i(1) 
which we can write as 
2E fi(x,)+(1/i)E fi(x,)2 + i 0 
 minimizing over i	gives i =  
E fi(x,)2/ 1/2 ; yields constraint 
E fi(x,)+  
E fi(x,)2 1/2 0
which depends only on rst and second moments of fi
EE364A  Chance Constrained Optimization	 16</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Interpretation via conditional value-at-risk
	write conservative approximation as 
E(fi(x,)+i)+ 
1 i 0 
	LHS is convex in (x,i), so minimum over i, 
E(fi(x,)+i)+inf	 i i&gt;0 1
is convex in x
	thisis CVaR(fi(x,);)(can showi &gt; 0 canbedropped) 
	so convex approximation replaces VaR(fi(x,);)0 with 
CVaR(fi(x,);)0 which is convex in x 
EE364A  Chance Constrained Optimization	 14</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Chebyshev approximation: 
maximize cTx
subjectto E(max(Axb)+)2 /(1)
+
with variables x Rn ,  R 
	optimal values of these approximate problems are lower bounds for 
originalproblem 
EE364A  Chance Constrained Optimization	 20</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>write constraint as  
E i(fi(x,)/i)i(1) 
	(perspectivefunction)v(u/v)is convex in (u,v)for v&gt; 0,
nondecreasing in u
	so composition i(fi(x,)/i)is convex in (x,i)for i &gt; 0 
	hence constraint above is convex in x and i 
	so we can optimize over x and i &gt; 0 via convex optimization 
	yields a convex stochastic optimization problem that is a conservative 
approximation of the chance-constrained problem 
	well look at some special cases 
EE364A  Chance Constrained Optimization	 12</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Example
	maximize alinear revenuefunction(say) subjectto randomlinear 
constraints holding with probability : 
maximize cTx 
subjectto Prob(max(Axb)0)  
with variable	x Rn; A Rmn , b Rm random(Gaussian) 
	Markov/CVaR approximation: 
maximize cTx 
subjectto E(max(Axb)+)+ (1)
with variables x Rn ,  R
EE364A  Chance Constrained Optimization	 19</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>CVaRinterpretation 
(for continuous distributions) 
in CVaR denition,  = VaR(z;):  
d 0=( +1/(1)E(z )+)=11/(1)Prob(z )d 
so Prob(z )=1 
 conditional tail expectation(or expected shortfall) 
E(z|z   )= E(  +(z   )|z   ) 
=   + E((z   )+)/Prob(z   ) 
= CVaR(z;) 
EE364A  Chance Constrained Optimization 4</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Example
 n =10 assets,  =0.05, C= {x |x 0.1}
 compare 
 optimalportfolio 
 optimal portfolio w/o loss risk constraint 
 uniformportfolio (1/n)1 
portfolio 
optimal 
w/o loss constraint 
uniform E pTx 
7.51
10.66
3.41
Prob(pTx 0) 
5.0%
20.3%
18.9%
EE364A  Chance Constrained Optimization 9</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Chance constraints and percentile optimization
	chance constraints ( is condence level): 
Prob(fi(x,)0)  
 convexin some cases(later) 
 generally interestedin	 =0.9, 0.95, 0.99 
  =0.999 meaningless(unlessyoure sure aboutthedistributiontails) 
 percentile optimization( is -percentile): 
minimize  
subjectto Prob(f0(x,)) 
 convex orquasi-convexin some cases(later) 
EE364A  Chance Constrained Optimization	 2</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>PDF of max(Axb)for Markov approximation solution
25 20 15 10 5 0 5 10 15
EE364A  Chance Constrained Optimization 22</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>problem is	
maximize E pTx 
subjectto	Prob(pTx 0)  
1Tx =1, x C 
 canbe expressed as convexproblem(provided  1/2)
maximize	pTx 
subjectto	pTx 1(1)1/2x2 
1Tx =1, x C
(an SOCPwhen Cispolyhedron)
EE364A  Chance Constrained Optimization	 8</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Chebyshev chance constraint bound
 taking (u)=(u +1)
2
+
yields Chebyshev bound: for any i &gt; 0,
Prob(fi(x,)&gt; 0) E(fi(x,)/i +1)
 convex approximation constraint 2
+
E i(fi(x,)/i +1)
2
+
i(1)
can be written as 
E(fi(x,)+i)2+
/i i(1)
EE364A  Chance Constrained Optimization 15</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Convex approximation of chance constraint bound
	assume fi(x,)is convex in x 
suppose  : RR is nonnegative convex nondecreasing, with (0)=1 	 
	for any i &gt; 0, (z/i)1(z&gt; 0) for all z, so 
E (fi(x,)/i)Prob(fi(x,)&gt; 0) 
	hence(convex) constraint 
E (fi(x,)/i)1
ensures chance constraint Prob(fi(x,)0)  holds
	this holds for any i &gt; 0; we now show how to optimize over i 
EE364A  Chance Constrained Optimization	 11</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Example
fi(x)= aTx b, where a is random with E a = a, E aaT =  
	traditional Chebyshev approximation of chance constraint is 
aT x b+ 1/2  
x Tx 2baT x + b21/2 0 
can write as second-order cone constraint  
aT x b+ 1/2(z,y)2 0 
with z =1/2x b1/2a, y = b  
1aT1a1/2 
	can interpret as certainty-equivalent constraint, with norm term as 
extra margin 
EE364A  Chance Constrained Optimization	 17</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>returndistributions:
20 15 10 5 0 5 10 15 20 25 30 optimal 
w/o loss constraint
20 15 10 5 0 5 10 15 20 25 30 
uniform
20 15 10 5 0 5 10 15 20 25
 30
EE364A  Chance Constrained Optimization 10</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Markov chance constraint bound
	taking (u)=(u +1)+ gives Markov bound: for any i &gt; 0, 
Prob(fi(x,)&gt; 0) E(fi(x,)/i +1)+ 
 convex approximation constraint 
E i(fi(x,)/i +1)+ i(1) 
can be written as 
E(fi(x,)+i)+ i(1) 
 we can optimize over x and i 0 
EE364A  Chance Constrained Optimization	 13</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Value-at-risk and conditional value-at-risk
	value-at-risk of random variable z, at level : 
VaR(z;)=inf{ |Prob(z )} 
	chance constraint Prob(fi(x,)0)  same as
VaR(fi(x,);)0
conditional value-at-risk:  
CVaR(z;)=inf ( +1/(1)E(z )+) 
 
 CVaR(z;)	VaR(z;)(more on this later) 
EE364A  Chance Constrained Optimization	 3</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Portfolio optimization example
	x Rn gives portfolio allocation; xi is(fractional) positionin asset i 
x must satisfy 1Tx =1, x C(convex portfolio constraint set)  
portfolio return(say,inpercent) is pTx, where pN(p,)  
(a more realistic model isp log-normal) 
	maximize expected return subject to limit on probability of loss 
EE364A  Chance Constrained Optimization	 7</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Chance constraints for log-concave distributions 
	suppose 
	 haslog-concavedensity p() 
 C = {(x,)|f(x,)0}is convex in (x,)
then 
  
Prob(f(x,)0) = 1((x,)C)p()d 
is log-concave, since integrand is 
	so chance constraint Prob(f(x,)0)  can be expressed as 
convex constraint 
logProb(f(x,)0) log 
EE364A  Chance Constrained Optimization	 5</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Cherno chance constraint bound
	taking (u)= expu yields Cherno bound: for any i &gt; 0, 
Prob(fi(x,)&gt; 0) E exp(fi(x,)/i) 
 convex approximation constraint 
E i exp(fi(x,)/i)i(1) 
can be written as 
logE exp(fi(x,)/i)log(1) 
(LHS is cumulant generatingfunction of fi(x,), evaluated at 1/i) 
EE364A  Chance Constrained Optimization	 18</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Linear inequality with normally distributed parameter 
	consider aTx b, with a N(a,) 
then aTx b N(aTx b,xTx)  
hence 	
ax Prob(a T x b)= b
xTT
x 
and so  
Prob(a T x b)  baT x 1()1/2 x2
a second-order cone constraint for  0.5 (i.e., 1()0)
EE364A  Chance Constrained Optimization	 6</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Chance constrained optimization
 chance constraints and percentile optimization
 chance constraints for log-concave distributions
 convex approximation of chance constraints 
sources: Rockafellar &amp; Uryasev, Nemirovsky &amp; Shapiro 
EE364A  Chance Constrained Optimization 1</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>instance with n =5, m =10,  =0.9 
	solve approximations with sampling method with N =1000 training 
samples, validate with M =10000 samples 
	compare to solution of deterministic problem 
maximize cTx 
subjectto E Ax E b 
	estimates of Prob(max(Axb)0) ontraining/validationdata
Tcx 
Markov 3.60 
Chebyshev 3.43 
deterministic 7.98 train
0.97
0.97
0.04
validate
0.96
0.96
0.03
EE364A  Chance Constrained Optimization	 21</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Convex functions
Convex functions; common examples; operations that preserve convexity; quasiconvex and log-convex functions.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec03/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>19</slideno>
          <text>Perspective
the perspective of a function f : Rn R is the function g : Rn RR, 	 
g(x,t)= tf(x/t), dom g = {(x,t)|x/t dom f, t&gt; 0} 
g is convex if f is convex 
examples 
f(x)= xTx is convex; hence g(x,t)= xTx/t is convex for t&gt; 0  
	negativelogarithm f(x)= logx is convex; hence relative entropy 
g(x,t)= tlogt tlogx is convex on R2 
++ 
	if f is convex, then 
g(x)=(c T x + d)f  
(Ax+ b)/(c T x + d) 
is convex on {x |cTx + d&gt; 0, (Ax+ b)/(cTx + d)dom f}
Convex functions	 320</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>Convexity with respect to generalized inequalities
f : Rn Rm is K-convexif dom f is convex and 
f(x+(1 )y)K f(x)+(1)f(y)
for x, y dom f, 0  1 
example f : Sm Sm , f(X)= X2 is Sm -convex +
proof: for xed z Rm , zTX2z = Xz22 is convex in X, i.e., 
z T(X +(1 )Y)2 z zTX2 z +(1 )z TY2 z 
for X,Y Sm , 0  1 
therefore (X +(1 )Y)2 X2 +(1 )Y2 
Convex functions 331</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Properties 
modiedJenseninequality: forquasiconvex f 
0  1=  f(x+(1 )y)max{f(x),f(y)} 
rst-order condition: dierentiable f with cvx domain is quasiconvex i 
= f(y)f(x) f(x)T(yx)0 
x f(x) 
sums of quasiconvex functions are not necessarily quasiconvex 
Convex functions 326</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Operations that preserve convexity
practical methods for establishing convexity of a function 
1.	verify denition(oftensimpliedby restricting toaline) 
2.	for twice dierentiable functions, show 2f(x)0 
3. show that f is obtained from simple convex functions by operations 
that preserve convexity 
	nonnegative weighted sum 
	composition with ane function 
	pointwise maximum and supremum 
	composition
minimization
  
	perspective 
Convex functions	 313</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Restriction of a convex function to a line
f : Rn R is convex if and only if the function g : RR,  
g(t)= f(x + tv), dom g = {t |x + tv dom f} 
is convex(in t)for any x dom f, v Rn 
can check convexity of f by checking convexity of functions of one variable 
example. f : Sn R with f(X)=logdetX, dom f = S++ n 
g(t)=logdet(X + tV ) = logdetX +logdet(I + tX1/2VX1/2) 
n 
= logdetX + log(1+ti) 
i=1 
where i are the eigenvalues of X1/2VX1/2 
g is concave in t (for anychoice of X 0, V);hence f is concave 
Convex functions 35</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Examples on Rn andRmn 
ane functions are convex and concave; all norms are convex 
examples on Rn 
anefunction f(x)= aTx + b  
 norms: xp =( n |xi|p)1/p for p1; x =maxk |xk|i=1 
examples on Rmn (mn matrices) 
anefunction  
mn 
f(X)= tr(ATX)+b = AijXij + b 
i=1 j=1 
 spectral(maximum singular value) norm 
f(X)= X2 = max(X)=(max(XTX))1/2 
Convex functions 34</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Examples
|x|is quasiconvex on R 
	ceil(x)=inf{z Z |z x}isquasilinear 
	logx is quasilinear on R++ 
f(x1,x2)= x1x2 is quasiconcave on R2 	++ 
linear-fractionalfunction  
aTx + b f(x)= cTx + d, dom f = {x |c T x + d&gt; 0} 
isquasilinear 
distance ratio  
f(x)= 
x
x 
a
b
22 , dom f = {x |x a2 x b2} 
isquasiconvex 
Convex functions	 324</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Pointwise supremum 
if f(x,y)is convex in x for each y A, then 
g(x)= sup f(x,y) 
yA 
is convex 
examples 
 support function of a set	C: SC(x)= supyC yTx is convex 
	distance to farthest point in a set C: 
f(x)= sup 
yC x y 
 maximum eigenvalue of symmetric matrix: for X Sn , 
max(X)= sup y TXy 
/badbly/badbl2=1 
Convex functions	 316</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Properties of log-concave functions
 twicedierentiable f with convex domain is log-concave if and only if 
f(x) 2f(x)f(x)f(x)T
for all x dom f
 product of log-concave functions is log-concave 
 sum of log-concave functions is not always log-concave 
 integration: if f : Rn Rm R is log-concave, then 
g(x)= f(x,y)dy 
islog-concave(noteasy toshow) 
Convex functions 328</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Pointwise maximum
if f1, ..., fm are convex, then f(x)= max{f1(x),...,fm(x)}is convex 
examples 
piecewise-linearfunction: f(x)= maxi=1,...,m(aiTx + bi)is convex  
 sum of r largest components of x Rn: 
f(x)= x[1]+ x[2]++ x[r]  
is convex(x[i] is ith largest component of x) 
proof: 
f(x)= max{xi1 + xi2 +  + xir |1 i1 &lt;i2 &lt;  &lt;ir n} 
Convex functions 315</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>The conjugate function 
the conjugate of a function f is 
f  (y)= sup (y T x f(x)) 
xdom f 
f(x) 
(0, f  (y)) xy 
x 
f is convex(evenif f is not)  
 will be useful in chapter 5 
Convex functions 321</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
3. Convex functions
 basic properties and examples 
 operations that preserve convexity 
 the conjugate function 
 quasiconvexfunctions 
 log-concave and log-convex functions 
 convexity with respect to generalized inequalities 
31</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>internal rate of return
 cash ow x =(x0,...,xn); xi ispaymentinperiod i (to us ifxi &gt; 0) 
 we assume x0 &lt; 0 and x0 + x1 +  + xn &gt; 0 
 present value of cash ow x, for interest rate r: 
n 
PV(x,r)= (1+r)i xi 
i=0 
 internal rate of return is smallest interest rate for which PV(x,r)=0: 
IRR(x)=inf{r 0 |PV(x,r)=0} 
IRR is quasiconcave: superlevel set is intersection of halfspaces 
n 
IRR(x)R (1+r)i xi 0 for 0 r R  
i=0 
Convex functions 325</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>First-order condition
f is dierentiable if dom f is open and the gradient 
f(x) f(x) f(x) = , ,..., f(x)x1 x2 xn 
exists at each x dom f 
1st-order condition: dierentiable f with convex domain is convex i 
f(y)f(x)+f(x)T(yx) for all x,y dom f 
(x, f(x)) f(y) 
f(x)+ f(x)T(y x)
rst-order approximation of f is global underestimator 
Convex functions 37</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>examples 
	negativelogarithm f(x)= logx 
f  (y) = sup (xy +logx) 
x&gt;0 
1log(y)	y&lt; 0 = 	 otherwise 
strictly convex quadratic f(x)=(1/2)xTQx with QSn 	++ 
f  (y) = sup (y T x (1/2)x TQx) 
x 
1 = y TQ1 y2
Convex functions	 322</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Extended-value extension
extended-value extension fof f is 
f(x)= f(x), dom f, f(x)= dom f x 	 ,x  
often simplies notation; for example, the condition 
0  	1= f(x+(1 )y)f(x)+(1)f(y)  
(as an inequalityin R{}), means the same as the two conditions 
dom f	is convex  
	for x,y dom f, 
0  1=  f(x+(1 )y)f(x)+(1)f(y) 
Convex functions	 36</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Examples on R
convex: 
	ane: ax + b on R, for any a,b R 
	exponential: eax, for any a R 
powers: x on R++,for  1 or  0  
	powers of absolute value: |x|p on R,for p1 
	negative entropy: xlogx on R++ 
concave: 
	ane: ax + b on R, for any a,b R 
	powers: x on R++,for 0  1 
	logarithm: logx on R++ 
Convex functions	 33</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>consequences of integration property 
 convolution f g oflog-concavefunctions f, g islog-concave 
(f g)(x)= f(x y)g(y)dy 
 if C Rn convex and y is a random variable with log-concave pdf then 
f(x)= prob(x + y C) 
islog-concave
proof: write f(x)as integral of product of log-concave functions
f(x)= g(x + y)p(y)dy, g(u)= 1 u C 
0 u  C, 
p is pdf of y 
Convex functions 329</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>example: yield function
Y(x)= prob(x + w S) 
 x Rn: nominal parameter values for product 
 w Rn: random variations of parameters in manufactured product 
 S: set of acceptable values 
if S is convex and w has a log-concave pdf, then 
 Y islog-concave 
 yield regions {x |Y(x)}are convex 
Convex functions 330</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Denition
f : Rn R is convex if dom f is a convex set and 
f(x+(1 )y)f(x)+(1)f(y) 
for all x,y dom f, 0  1 
(x, f(x)) (y, f(y)) 
 f is concave if f is convex 
 f is strictly convex if dom f is convex and 
f(x+(1 )y)&lt;f(x)+(1)f(y)
for x,y dom f, x =y, 0 &lt; &lt; 1
Convex functions 32</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Positive weighted sum &amp; composition with ane function
nonnegative multiple: f is convex if f is convex,  0 
sum: f1 + f2 convexif f1,f2 convex(extends toinnitesums,integrals) 
composition with ane function: f(Ax+ b)is convex if f is convex 
examples 
 log barrierforlinearinequalities 
m 
f(x)=  log(bi a T
i x), dom f = {x |aiTx&lt;bi,i =1,...,m}
i=1 
 (any)norm of ane function: f(x)= Ax+ b 
Convex functions 314</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Vector composition
composition of g : Rn Rk and h : Rk R:  
f(x)= h(g(x))= h(g1(x),g2(x),...,gk(x)) 
gi convex, h convex, hnondecreasing in each argument f is convex if gi concave, h convex, hnonincreasing in each argument 
proof(for n =1,dierentiable g,h) 
f  (x)= g  (x)T  2h(g(x))g  (x)+h(g(x))T g  (x) 
examples 
m loggi(x)is concave if gi are concave and positive  i=1 
m  log i=1 expgi(x)is convex if gi are convex 
Convex functions 318</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Epigraph and sublevel set
-sublevel set of f : Rn R:
C = {x dom f |f(x)} 
sublevel sets of convexfunctions are convex(converseisfalse) 
epigraph of f : Rn R:
epi f = {(x,t)Rn+1 |x dom f, f(x)t} 
epi f 
f 
f is convex if and only if epi f is a convex set 
Convex functions 311</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Examples 
quadraticfunction: f(x)=(1/2)xTPx+ qTx + r (withP Sn) 
f(x)= Px+ q,  2f(x)= P 
convexif P 0 
least-squares objective: f(x)= Axb2 
2 
f(x)=2AT(Axb),  2f(x)=2ATA 
convex(for any A) 
quadratic-over-linear: f(x,y)= x2/y 2 
  T 1 
 2f(x,y)= y2 
3 y
x y
x 0 
0 
2 2 
1 0 
convexfor y&gt; 0 y 0 2 x f(x,y)
Convex functions 39</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>log-sum-exp: f(x)=log 
kn 
=1 expxk is convex
 2f(x)= 1T1 
z diag(z)(1T1 
z)2zz T (zk =expxk)
to show 2f(x)0, we must verify that vT2f(x)v 0 for all v:
T (  
k zkvk2)(  
k zk)(  
k vkzk)2 
v  2f(x)v =(  
k zk)2 0 
since (  
k vkzk)2 (  
k zkvk2)(  
k zk)(fromCauchy-Schwarzinequality)
geometric mean: f(x)=( 
kn 
=1 xk)1/n on Rn is concave ++ 
(similar proofas for log-sum-exp) 
Convex functions 310</text>
        </slide>
        <slide>
          <slideno>26</slideno>
          <text>Log-concave and log-convex functions
apositivefunction f islog-concaveif logf is concave: 
f(x+(1 )y)f(x)f(y)1 for 0  1 
f islog-convexif logf is convex 
 powers: xa on R++ islog-convexfor a 0,log-concavefor a 0 
 many common probability densities are log-concave, e.g., normal: 
1 1(xx)T1(xx)f(x)=  e 2
(2)n det 
 cumulativeGaussiandistributionfunction  islog-concave 
(x)=1 x 
e u 2/2 du 
2  
Convex functions 327</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>Composition with scalar functions
composition of g : Rn R and h : RR:  
f(x)= h(g(x)) 
g convex, h convex, hnondecreasing f is convex if g concave, h convex, hnonincreasing 
 proof(for n =1,dierentiable g,h) 
f  (x)= h  (g(x))g  (x)2 + h  (g(x))g  (x) 
note: monotonicity must hold for extended-value extension h  
examples 
 expg(x)is convex if g is convex 
 1/g(x)is convex if g is concave and positive 
Convex functions 317</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Quasiconvexfunctions
f : Rn R isquasiconvexif dom f is convex and the sublevel sets 
S = {x dom f |f(x)} 
are convex for all  
  
a bc
 f isquasiconcaveif f isquasiconvex 
 f is quasilinear if it is quasiconvex and quasiconcave 
Convex functions 323</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Jensensinequality
basicinequality: if f is convex, then for 0  1, 
f(x+(1 )y)f(x)+(1)f(y) 
extension: if f is convex, then 
f(E z)E f(z) 
for any random variable z 
basic inequality is special case with discrete distribution 
prob(z = x)= , prob(z = y)=1 
Convex functions 312</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Minimization
if f(x,y)is convex in (x,y)and C is a convex set, then 
g(x)= inf f(x,y) 
yC 
is convex 
examples 
f(x,y)= xTAx+2xTBy+ yTCy with  
AB 
BT C 0,C 0 
minimizing over y gives g(x)=infy f(x,y)= xT(ABC1BT)x 
g is convex, hence Schur complement ABC1BT 0 
 distance to a set: dist(x,S)=infyS x yis convex if S is convex 
Convex functions 319</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Second-order conditions
f is twicedierentiable if dom f is open and the Hessian 2f(x)Sn , 
2f(x)ij = 2f(x) ,	i,j =1,...,n, 	xixj 
exists at each x dom f 
2nd-order conditions: fortwicedierentiable f with convex domain 
	f is convex if and only if 
 2f(x)0 for all x dom f 
 if 2f(x)0 for all x dom f, then f is strictly convex 
Convex functions	 38</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>Equality constrained minimization
Elimination method; Newton method; infeasible Newton method.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec17/</lecture_pdf_url>
      <lectureno>17</lectureno>
      <slides>
        <slide>
          <slideno>10</slideno>
          <text>Infeasible start Newton method
given startingpoint x 	dom f, ,tolerance &gt; 0,   (0, 1/2),   (0, 1). 
repeat 
1. Compute primal and dual Newton steps xnt, nt. 
2. Backtracking line search on r2. 
t := 1. 
while r(x + txnt, + tnt)2 &gt; (1t)r(x,)2, t := t. 
3. Update. x := x + txnt,  :=  + tnt. 
until Ax = b and r(x,)2  . 
 not a descent method: f(x(k+1))&gt;f(x(k))ispossible 
	directional derivative of r(y)2 indirection y =(xnt,nt)is 
d r(y+ ty)2 = r(y)2dt 
t=0 
Equality constrained minimization	 1111</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Newtons method and elimination
Newtons method for reduced problem 
minimize f(z)= f(Fz +x) 
 variables z  Rnp 
 xsatises Ax= b; rank F = n p and AF =0 
 Newtons method for f, started at z(0),generatesiterates z(k) 
Newtons method with equality constraints 
when started at x(0) = Fz(0)+x, iterates are 
x(k+1) = Fz(k)+x 
hence, dont need separate convergence analysis 
Equality constrained minimization 119</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>complexity per iteration of three methods is identical 
1. use block elimination to solve KKT system 
 
diag(x)2 AT  
x  
diag(x)11  
= A 0 w 0
reduces to solving Adiag(x)2ATw = b
2. solve Newton system Adiag(AT)2AT = b+ Adiag(AT)11 
3. use block elimination to solve KKT system 
 
diag(x)2 AT  
x  
diag(x)11  
= A 0  Axb 
reduces to solving Adiag(x)2ATw =2Axb 
conclusion: in each case, solve ADATw = h with D positivediagonal 
Equality constrained minimization 1115</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>Equality constrained minimization 
minimize f(x) 
subject to Ax = b 
 f convex, twice continuously dierentiable 
 A  Rpn with rank A = p 
  we assume p is nite and attained 
optimality conditions: x  is optimal i there exists a  such that 
f(x  )+AT  =0, Ax  = b 
Equality constrained minimization 112</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>Convex Optimization  Boyd &amp; Vandenberghe 
11. Equality constrained minimization 
 equality constrained minimization 
 eliminating equality constraints 
 Newtons method with equality constraints 
 infeasible start Newton method 
 implementation 
111</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Solving KKT systems
 
HAT  
v   
g  
=  A 0	 w h 
solution methods 
 LDLTfactorization 
	elimination(if H nonsingular) 
AH1AT w = hAH1 g, Hv = (g+ AT w) 
	elimination with singular H: write as 
 
H + ATQA AT  
v   
g+ ATQh  
=  A 0 w h 
with Q 0 for which H + ATQA  0, and apply elimination 
Equality constrained minimization	 1112</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Eliminating equality constraints
represent solution of {x |Ax = b}as 
{x |Ax = b}= {Fz +x |z  Rnp} 
 xis(any) particular solution 
 range of F 	Rn(np) is nullspace of A (rank F = np and AF =0) 
reduced or eliminated problem 
minimize f(Fz +x) 
 an unconstrained problem with variable z  Rnp 
	from solution z , obtain x  and  as 
x  = Fz  +x,   = (AAT)1Af(x  ) 
Equality constrained minimization	 114</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Newton step at infeasible points
2nd interpretation of page 116 extends to infeasible x (i.e., Ax	b)= 
linearizing	optimality conditions at infeasible x (withx  dom f)gives 
 
2f(x) AT  
xnt  
=   
f(x)  
(1) A 0 w Axb 
primal-dualinterpretation 
	write optimality condition as r(y)=0, where 
y =(x,),r(y)=(f(x)+AT,Axb) 
	linearizing r(y)=0 gives r(y+y) r(y)+Dr(y)y =0: 
 
2f(x) AT  
xnt   
f(x)+AT  
=  A 0 nt	 Axb 
same as(1)	with w =  +nt 
Equality constrained minimization	 1110</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Newton step
Newton step xnt of f atfeasible x is given by solution v of 
 
2f(x) AT  
v  
f(x)  
= A 0 w	 0 
interpretations 
	xnt solves second order approximation(with variable v) 
minimize f(x + v)= f(x)+f(x)Tv +(1/2)vT2f(x)v 
subject to A(x + v)= b 
	xnt equations follow from linearizing optimality conditions 
f(x + v)+AT w f(x)+2f(x)v + AT w =0,A(x + v)= b 
Equality constrained minimization	 116</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Equality constrained analytic centering
primalproblem: minimize n
i=1 logxi subject to Ax = b 
dualproblem: maximize bT + n
i=1 log(AT)i + n 
three methods for an example with A  R100500, dierent starting points 
1. Newton method with equality constraints(requires x(0)  0, Ax(0) = b) f(x (k) ) p  
1010 105 100 105 
0 5 10 15 20 k 
Equality constrained minimization 1113</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>equality constrained quadratic minimization (withP  Sn )+
minimize (1/2)xTPx+ qTx + r 
subject to Ax = b 
optimality condition: 
 
PAT  
x   
q  
= A 0 	b 
 coecient matrix is called KKT matrix 
	KKT matrix is nonsingular if and only if 
Ax =0,x =0 = x TPx&gt; 0 
 equivalent condition for nonsingularity: P + ATA  0 
Equality constrained minimization	 113</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>example: optimal allocation with resource constraint 
minimize f1(x1)+f2(x2)+ + fn(xn) 
subject to x1 + x2 +  + xn = b 
eliminate xn = bx1  xn1, i.e., choose 
 I  
x= ben,F = 1T  Rn(n1) 
reducedproblem: 
minimize f1(x1)+ + fn1(xn1)+fn(bx1  xn1) 
(variablesx1, ..., xn1) 
Equality constrained minimization 115</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>2. Newtonmethod applied todualproblem(requires AT(0)  0)
p  g( (k) ) 
1010 105 100 105 
0 2 4 6 8 10 k 
3. infeasible startNewton method(requires x(0)  0)
r(x (k) ,  (k) ) 2 
1015 1010 105 100 105 1010 
0 5 10 15 20 25 k 
Equality constrained minimization 1114</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Network ow optimization
minimize 
in 
=1 i(xi) 
subject to Ax = b 
 directed graph with n arcs, p+1 nodes 
 xi: ow through arc i; i: cost ow function for arc i (withi  (x)&gt; 0) 
 node-incidence matrix A R(p+1)n dened as 
Aij
=



1 arc j leaves node i 
1 arc j enters node i 
0 otherwise 
 reduced node-incidence matrix A  Rpn is Awith last row removed 
 b  Rp is(reduced) source vector 
 rank A = p if graph is connected 
Equality constrained minimization 1116</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Newtondecrement
T(x)= 
xnt2f(x)xnt1/2 = 
f(x)Txnt1/2 
properties 
 gives an estimate of f(x)p  using quadratic approximation f: 
1 (x)2 
Ay=b 2 f(x) inf f(y)= 
 directionalderivativeinNewtondirection: 
d f(x + txnt)= (x)2 
dt 
t=0 
 ingeneral, (x)= 
f(x)T2f(x)1f(x)1/2 
Equality constrained minimization 117</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>solution by block elimination 
 eliminate X from rst equation: X = X 
jp 
=1 wjXAjX 
 substitute X in second equation 
p
tr(AiXAjX)wj = bi,i =1,...,p (2) 
j=1 
a dense positive denite set of linear equations with variable w  Rp 
op count(dominant terms) using Cholesky factorization X = LLT: 
 form p products LTAjL: (3/2)pn3 
 form p(p+1)/2 innerproducts tr((LTAiL)(LTAjL)): (1/2)p2n2 
 solve(2) viaCholesky factorization: (1/3)p3 
Equality constrained minimization 1119</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>KKT system
 
HAT  
v   
g  
=  A 0 w	 h 
 H = diag(  
1(x1),...,  
n(xn)),positivediagonal 
	solve via elimination: 
AH1AT w = hAH1 g, Hv = (g+ AT w) 
sparsity pattern of coecient matrix is given by graph connectivity 
(AH1AT)ij	0  (AAT)ij =0 = 
 nodes i and j are connected by an arc 
Equality constrained minimization	 1117</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Analytic center of linear matrix inequality
minimize logdetX 
subject to tr(AiX)= bi, i = 1,. . . ,p 
variable X  Sn 
optimality conditions 
p
Newton equation at feasible X:  
j=1 X   0, (X  )1
+
 j Ai =0, tr(AiX  )= bi,i =1,...,p
p
 follows from linear approximation (X +X)1  X1 X1XX1 
 n(n +1)/2+p variables X, w  
j=1 
Equality constrained minimization 1118 X1XX1
+
 wjAi = X1 , tr(AiX)=0,i =1,...,p</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Newtons method with equality constraints
given startingpoint x  dom f with Ax = b,tolerance &gt; 0. 
repeat 
1. Compute the Newton step and decrement xnt, (x). 
2. Stopping criterion. quit if 2/2  . 
3. Line search. Choose step size t by backtracking line search. 
4. Update. x := x + txnt. 
 a feasible descent method: x(k) feasible and f(x(k+1))&lt;f(x(k)) 
 aneinvariant 
Equality constrained minimization 118</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
    <lecture>
      <lecture_title>l1 methods for convex-cardinality problems
Convex-cardinality problems and examples; l1 heuristic; interpretation as relaxation.</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/6-079-introduction-to-convex-optimization-fall-2009/resources/mit6_079f09_lec11/</lecture_pdf_url>
      <lectureno>11</lectureno>
      <slides>
        <slide>
          <slideno>26</slideno>
          <text>Sparse signal reconstruction
	convex-cardinalityproblem: 
minimize Axy2 
subjectto card(x) k 
	1 heuristic: 
minimize Axy2
subjectto x1  
(calledLASSO)
	another form: minimize Axy2 + x1 
(calledbasispursuitdenoising) 
Prof.S.Boyd,EE364b,StanfordUniversity 26</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Boolean LP as convex-cardinality problem
 BooleanLP: 
minimize cT x 
subjectto Ax  b, xi {0,1} 
includes many famous(hard) problems, e.g., 3-SAT, traveling salesman 
	can be expressed as 
minimize cT x 
subjectto Ax  b, card(x)+card(1x) n
since card(x)+card(1x) n  xi {0,1}
 conclusion: general convex-cardinality problem is hard 
Prof.S.Boyd,EE364b,StanfordUniversity 5</text>
        </slide>
        <slide>
          <slideno>31</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
6.079 / 6.975 Introduction to Convex Optimization 
Fall 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.</text>
        </slide>
        <slide>
          <slideno>19</slideno>
          <text>Polishing
	use 1 heuristic to nd xwith required sparsity 
	x the sparsity pattern of x
	re-solvethe(convex) optimizationproblem with this sparsitypatternto 
obtain nal(heuristic) solution 
Prof.S.Boyd,EE364b,StanfordUniversity 19</text>
        </slide>
        <slide>
          <slideno>16</slideno>
          <text>1-norm heuristic
	replace card(z)with z1, or add regularization term z1 to 
objective 
	&gt; 0 is parameter used to achieve desired sparsity 
(whencard appears in constraint, or as term in objective) 
	more sophisticated versions use i wi|zi|or i wi(zi)+ + i vi(zi), 
where w, v are positive weights 
Prof.S.Boyd,EE364b,StanfordUniversity 16</text>
        </slide>
        <slide>
          <slideno>24</slideno>
          <text>Regressor selection
minimize Axb2 
subjectto card(x) k 
	heuristic: 
	minimize Axb2 + x1 
	nd smallest value of  thatgives card(x) k 
	x associated sparsitypattern(i.e., subset of selected regressors) and 
nd x that minimizes Axb2 
Prof.S.Boyd,EE364b,StanfordUniversity 24</text>
        </slide>
        <slide>
          <slideno>22</slideno>
          <text>Interpretation via convex envelope
	convex envelope fenv of a function f on set C is the largest convex 
function that is an underestimator of f on C 
	epi(fenv)= Co(epi(f)) 
	fenv =(f) (withsome technical conditions) 
	for x scalar, |x|is the convex envelope of card(x)on [1,1] 
	for x  Rn scalar, (1/R)x1 is convex envelope of card(x)on 
{z |z  R} 
Prof.S.Boyd,EE364b,StanfordUniversity 22</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>1-norm heuristics for cardinality problems 
	cardinality problems arise often, but are hard to solve exactly 
	a simple heuristic, that relies on 1-norm, seems to work well 
	used for many years, in many elds 
	sparsedesign 
	LASSO, robust estimation in statistics 
	support vector machine(SVM) in machinelearning 
	total variation reconstruction in signal processing, geophysics 
	compressed sensing 
	new theoretical results guarantee the method works, at least for a few 
problems 
Prof.S.Boyd,EE364b,StanfordUniversity 1</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>General convex-cardinality problems 
a convex-cardinalityproblem is one that would be convex, except for 
appearance of card in objective or constraints 
examples(with C, f convex): 
 convex minimum cardinality problem: 
minimize card(x) 
subjectto x C 
 convex problem with cardinality constraint: 
minimize f(x)
subjectto x C, card(x) k
Prof.S.Boyd,EE364b,StanfordUniversity 3</text>
        </slide>
        <slide>
          <slideno>27</slideno>
          <text>Example
	signal x  Rn with n =1000, card(x)=30 
	m =200 (random)noisy measurements: y = Ax+ v, v N(0,21), 
Aij N(0,1) 
	left: original; right: 1 reconstruction with  =103 
1 1 
0.8 0.8 
0.6 0.6 
0.4 0.4 
0.2 0.2 
0 0 
0.2 0.2 
0.4 0.4 
0.6 0.6 
0.8 0.8 
1 1 
100 200 300 400 500 600 700 800 900 1000	 100 200 300 400 500 600 700 800 900 1000 
Prof.S.Boyd,EE364b,StanfordUniversity 27</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Sparse design
minimize card(x) 
subjectto x C 
	nd sparsest design vector x that satises a set of specications 
	zero values of x simplify design, or correspond to components that 
arent even needed 
	examples: 
	FIR lterdesign(zerocoecientsreducerequiredhardware) 
	antenna array beamforming(zero coecients correspond to unneeded 
antenna elements) 
	trussdesign(zero coecients correspond tobarsthat are not needed) 
	wire sizing(zero coecients correspond to wiresthat are not needed) 
Prof.S.Boyd,EE364b,StanfordUniversity 6</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>Sparse signal reconstruction
 estimate signal x,given 
 noisy measurement y = Ax+v, v N(0,2I)(A isknown; v is not) 
 priorinformation card(x) k 
 maximum likelihood estimate xml is solution of 
minimize Axy2 
subjectto card(x) k 
Prof.S.Boyd,EE364b,StanfordUniversity 8</text>
        </slide>
        <slide>
          <slideno>28</slideno>
          <text>2 reconstruction; minimizes Axy2 + x2, where  =103 
 left: original; right: 2 reconstruction 
1
0.8 
0.6 
0.4 
0.2 
0 
0.2 
0.4 
0.6 
0.8 
1 1
0.8 
0.6 
0.4 
0.2 
0 
0.2 
0.4 
0.6 
0.8 
1 
100
 200 300
 400
 500 600
 700 800 900
 1000 100 200 300 400 500 600 700 800 900 1000
Prof.S.Boyd,EE364b,StanfordUniversity 28</text>
        </slide>
        <slide>
          <slideno>29</slideno>
          <text>Some recent theoretical results
	suppose y = Ax, A  Rmn , card(x) k 
	to reconstruct x, clearly need m  k 
	if m  n and A is full rank, we can reconstruct x without cardinality 
assumption 
	whendoesthe 1 heuristic(minimizing x1 subjectto Ax = y) 
reconstruct x (exactly)? 
Prof.S.Boyd,EE364b,StanfordUniversity 29</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Cardinality
	the cardinality of x  Rn,denoted card(x), is the number of nonzero 
components of x 
0 x =0 	card is separable; for scalar x, card(x)= 1 x =0 
	card is quasiconcave on Rn (but notRn)since + 
card(x + y) min{card(x),card(y)} 
holdsfor x,y  0 
	but otherwise has no convexity properties 
	arises in many problems 
Prof.S.Boyd,EE364b,StanfordUniversity 2</text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>Portfolio investment with linear and xed costs 
 we use budget B topurchase(dollar) amount xi  0 of stock i 
 trading fee is xed cost plus linear cost: card(x)+T x 
 budget constraint is 1T x + card(x)+T x  B 
 mean return on investment is T x; variance is xT x 
 minimizeinvestment variance(risk) with mean return  Rmin: 
minimize xT x 
subjectto T x  Rmin,x  0 
1T x + card(x)+T x  B 
Prof.S.Boyd,EE364b,StanfordUniversity 13</text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Piecewise linear tting
 t xcor by a piecewise linear signal xwith k orfewerkinks 
	as convex-cardinality problem: 
minimize xxcor2 
subjectto card(x) k 
where   12 1 
  12 1 	   =  ... ...	...  
12 1 
Prof.S.Boyd,EE364b,StanfordUniversity 15</text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>Linear classier with fewest errors
 givendata	(x1,y1),..., (xm,ym) Rn {1,1} 
 we seeklinear(ane) classier y  sign(wT x + v) 
 classication error corresponds to yi(wT x + v) 0 
	to nd w, v that give fewest classication errors: 
minimize card(t) 
subjectto yi(wT xi + v)+ti  1,i =1,...,m
with variables w, v, t (we use homogeneityin w, v here)
Prof.S.Boyd,EE364b,StanfordUniversity 11</text>
        </slide>
        <slide>
          <slideno>18</slideno>
          <text>Example: Cardinality constrained problem
 start with(hard) cardinality constrainedproblem(f, C convex) 
minimize f(x)
subjectto x C, card(x) k
 apply heuristictoget(easy) 1-constrainedproblem 
minimize f(x)
subjectto x C, x1  
or 1-regularizedproblem 
minimize f(x)+x1 
subjectto x C 
,  adjusted so that card(x) k 
Prof.S.Boyd,EE364b,StanfordUniversity 18</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>Minimum number of violations
	set of convex inequalities 
f1(x) 0, ...,fm(x) 0,x C 
	choose x to minimize the number of violated inequalities: 
minimize card(t) 
subjectto fi(x) ti,i =1,...,m 
x C,t  0 
	determining whether zeroinequalities canbe violatedis(easy) convex 
feasibilityproblem 
Prof.S.Boyd,EE364b,StanfordUniversity 10</text>
        </slide>
        <slide>
          <slideno>25</slideno>
          <text>Example (6.4 in BV book) 
 A  R1020 , x  R20 , b  R10 
 dashed curve: exact optimal(via enumeration) 
 solid curve: 1 heuristic with polishing card(x)
10 
8 
6 
4 
2 
0 0 1 2 3 4 
/bardblAx  b/bardbl2 
Prof.S.Boyd,EE364b,StanfordUniversity 25</text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Piecewise constant tting
 t corrupted xcor by apiecewise constant signal xwith k orfewerjumps 
 problemisconvexoncelocation(indices) ofjumpsare xed 
 xis piecewise constant with  k jumps card(Dx) k, where 
  
1 1 
 1 1  
 R(n1)n   D =  ... ...  
1 1 
 as convex-cardinality problem: 
minimize xxcor2 
subjectto card(Dx) k 
Prof.S.Boyd,EE364b,StanfordUniversity 14</text>
        </slide>
        <slide>
          <slideno>30</slideno>
          <text>recent results by Cand`es, Donoho, Romberg, Tao, . . . 
	(for some choices ofA)if m  (Clogn)k, 1 heuristic reconstructs x 
exactly, with overwhelming probability 
	C is absolute constant; valid Asinclude 
	Aij N(0,2) 
	Ax gives Fourier transform of x at m frequencies, chosen from 
uniformdistribution 
Prof.S.Boyd,EE364b,StanfordUniversity 30</text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Smallest set of mutually infeasible inequalities
	given a set of mutually infeasible convex inequalities 
f1(x) 0,...,fm(x) 0 
	nd smallest(cardinality) subset of thesethatisinfeasible 
m 	certicate of infeasibility is g()=infx( i=1 ifi(x)) 1,   0 
	to nd smallest cardinality infeasible subset, we solve 
minimize card() 
subjectto g() 1,  0
(assumingsome constraint qualications)
Prof.S.Boyd,EE364b,StanfordUniversity 12</text>
        </slide>
        <slide>
          <slideno>20</slideno>
          <text>Interpretation as convex relaxation
 start with 
minimize card(x)
subjectto x C, x  R
 equivalent to mixed Boolean convex problem 
minimize 1T z 
subjectto |xi|Rzi,i =1,...,n 
x C,zi {0,1},i =1,...,n 
with variables x, z 
Prof.S.Boyd,EE364b,StanfordUniversity 20</text>
        </slide>
        <slide>
          <slideno>21</slideno>
          <text>now relax	zi {0,1}to zi  [0,1] to obtain 
minimize	1T z 
subjectto	|xi|Rzi,i =1,...,n 
x C 
0  zi  1,i =1,...,n 
which is equivalent to 
minimize (1/R)x1 
subjectto x C 
the 1 heuristic 
 optimal value of this problem is lower bound on original problem
Prof.S.Boyd,EE364b,StanfordUniversity 21</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>Estimation with outliers 
 we have measurements yi = aT
i x + vi + wi, i =1,...,m 
 noises vi N(0,2)areindependent 
 only assumption on w is sparsity: card(w) k 
B = {i |0}is set of bad measurements or outliers
 wi = 
 maximum likelihood estimate of x found by solving 
minimize  
i/negationslashB(yi aiT x)2 
subjectto |B|k 
with variables x and B{1,...,m} 
 equivalentto 
minimize yAxw22 
subjectto card(w) k 
Prof.S.Boyd,EE364b,StanfordUniversity 9</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>1-normMethodsfor
Convex-CardinalityProblems
 problems involving cardinality 
 the 1-normheuristic 
 convex relaxation and convex envelope interpretations 
 examples 
 recent results 
Prof.S.Boyd,EE364b,StanfordUniversity</text>
        </slide>
        <slide>
          <slideno>17</slideno>
          <text>Example: Minimum cardinality problem 
	start with(hard) minimum cardinalityproblem 
minimize card(x) 
subjectto x C
(C convex)
 apply heuristictoget(easy) 1-norm minimization problem 
minimize x1 
subjectto x C 
Prof.S.Boyd,EE364b,StanfordUniversity 17</text>
        </slide>
        <slide>
          <slideno>23</slideno>
          <text>Weighted and asymmetric 1 heuristics 
	minimize card(x)over convex set C 
	suppose we know lower and upper bounds on xi over C 
x C = li  xi  ui 
(best values for these can be found bysolving 2n convexproblems)
	if ui &lt; 0 or li &gt; 0,then card(xi)=1 (i.e., xi =0)for all x C 
	assuming li &lt; 0, ui &gt; 0, convex relaxation and convex envelope 
interpretations suggest using 
n	  	(xi)+ (xi) + ui lii=1 
as surrogate(and alsolowerbound) for card(x) 
Prof.S.Boyd,EE364b,StanfordUniversity 23</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Solving convex-cardinality problems 
convex-cardinality problem with x  Rn 
	if we x the sparsity pattern of x (i.e., which entries are zero/nonzero) 
we get a convex problem 
	by solving 2n convex problems associated with all possible sparsity 
patterns, we can solve convex-cardinality problem 
(possiblypracticalforn  10; not practical for n&gt; 15 orso ...) 
	general convex-cardinalityproblemis(NP-) hard 
	can solve globally by branch-and-bound 
	can workforparticularprobleminstances(with someluck) 
	in worst case reducesto checking all(or many of) 2n sparsitypatterns 
Prof.S.Boyd,EE364b,StanfordUniversity 4</text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Sparse modeling / regressor selection
t vector b  Rm as a linear combination of k regressors(chosenfrom n 
possible regressors) 
minimize Axb2 
subjectto card(x) k 
 gives k-term model 
 chooses subset of k regressorsthat(together) best torexplain b 
n  cansolve(inprinciple) by trying all choices k 
 variations: 
 minimize card(x)subjectto Axb2   
 minimize Axb2 + card(x) 
Prof.S.Boyd,EE364b,StanfordUniversity 7</text>
        </slide>
      </slides>
      <videos/>
    </lecture>
  </lectures>
</doc>
