<doc>
  <source>MIT</source>
  <date>28/01/2023</date>
  <course>
    <course_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/</course_url>
    <course_title>Introduction to Statistical Methods in Economics</course_title>
    <course_tags>
      <list>Mathematics </list>
      <list>Probability and Statistics </list>
      <list>Economics </list>
    </course_tags>
  </course>
  <lectures>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec03/</lecture_pdf_url>
      <lectureno>3</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; 
&#65533;&#8226; Ai that candidate i wins thepresidential elections(without conditioning on nomination) 
&#8226; Bi that candidate i wins the nomination of her/his party 
&#8226; Ck that the nominee of party k wins the election 
We can now usetheprobabilities which areimpliedby the assetforthe corresponding eventto answerthe 
question what the market &#8221;thinks&#8221; which candidate of either party has the highest probability of winning 
the presidential elections if nominated P (Ai|Bi)-i.e. nominating which candidate would give each party 
the highest chances of winning the presidency. 
We can(relatively) safely assume that a candidate whois not nominatedby thepartyhas no chances of 
winning the presidency, so that 
Ai &#8834; Bi =&#8658; Ai &#8745;Bi = Ai 
so that 
P (Ai &#8745;Bi) P (Ai)P (Ai|Bi)= = P (Bi) P (Bi) 
sothat we only havetoplug inthepricesforthe corresponding assets. Based on assetprices onFebruary 
6 ontheIntradepolitical markets, wegetthefollowing numbers(inthelast columnI reportthe values 
from Mankiw&#8217;s original blog entry, as of November 2006). 
candidate P (Ai) P (Bi) P (Ai|Bi) P&#732;Nov&#65533;06(Ai|Bi)
Clinton 28.7% 45.2% 63.5% 51%
Huckabee 0.5% 2.0% 25.0% NA
McCain 34.4% 93.0% 37.0% 63%
Obama 35.0% 53.0% 66.0% 88%
Paul 0.4% 1.2% 33% NA
Romney 1.2% 2.6% 46.2% 50%
In order to distinguish it from the conditional probabilities P (A|Bi),P (A)is also called the marginal 
probability of A. The relationship between marginal and conditionalprobabilitiesisgivenby theLaw of 
Total Probability: 
Theorem1 (Law of Total Probability) Supposethat B1,...,Bn is a partition of the sample space S 
such that P (Bi)&gt; 0 for every i =1,...,n. Then 
n 
P (A)= P (A|Bi)P (Bi) 
i=1 
for any event B. 
Proof: From the de&#64257;nition of a conditional probability, P (A|Bi)P (Bi)= P (A &#8745;Bi)for any event Bi. 
Since B1,...,Bn isapartitionof thesamplespace,(A &#8745;B1),..., (A &#8745;Bn)are disjoint and exhaustive for 
A -i.e. constitute a partition for A. Therefore,by the axiom(P3) onprobabilities of unions ofdisjoint 
sets, n
i=1 P (A &#8745;Bi)= P (A)&#65533; 
Example8 Inmedicaldatawecanoften &#64257;nd thatpatientstreatedby older,and moreexperienced,heart 
surgeons have in fact higher post-operative death rates than those operated by younger surgeons -say 
we observe a death rate of 6.0% for experienced surgeons, and onlyl 5.5% for unexperienced surgeons. 
6 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text> A B = A ' 
A B = S ' S 3 Conditional Probability 
Suppose the occurrence of A a&#64256;ectsthe occurrence(or non-occurrence) of B and vice versa. How do we 
describe the probability of B given knowledge about A? -We already argued heuristically that if the 
events are independent, then A does not reveal any information about B. But what if it does? How do 
we change probabilities as a result? 
Example6 If we throw a fair die, and I tell you that in fact the outcome was an even number, i.e that 
the event B = {2, 4, 6} occurred. What&#8217;s the probability of having rolled a 6? Since there are only three 
equallylikelypossibilitiesin B, 6 being one of them, we&#8217;d intuitively expect the answer to be 1
3 . Here we 
basically simpli&#64257;ed the sample space, to S&#732;= B = {2, 4, 6}, and calculated the simple probability for the 
rede&#64257;nedproblem. 
De&#64257;nition3 Suppose A and B are events de&#64257;ned on S such that P (B)&gt; 0. The conditionalprobability 
of A given that B occurredisgivenby 
P (A &#8745;B)P (A|B)= P (B) 
Intuitively, the numerator rede&#64257;nes which outcomes in A arepossible once B is known to have occurred, 
the denominator does the same thing for the whole sample space. 
Figure 1: The Event A Conditional on B 
Remark1 Conditional probability and independence: if A and B areindependent, 
P (AB) P (A)P (B)P (A|B)= = = P (A)P (B) P (B) 
so B occurring tells us nothing about A, so the conditional probability is the same as the unconditional 
probability. 
Example7 ThisexampleisadaptedfromGregMankiw&#8217;sblog:2 OnplatformslikeIntrade,youcantrade 
assets which pay 1$ if agiven event(e.g. Yankees win theWorldSeries) occurs. If the market works as 
it should, the prices of this type of assets at a given time t can be interpreted as probabilities given the 
information traders have at that point in time. On the political market on Intrade, you can trade assets 
for the events 
2http://gregmankiw.blogspot.com/2006/11/bayes-likes-obama 
5 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>2 Many people &#64257;nd these probabilities very high, but it&#8217;s usually because one is tempted to start thinking 
about the problem by calculating the probability that any of your n friends has the same birthday as you. 
You can convince yourself that this probability is 
&#65533; &#65533;n &#65533;&#65533;n 
P (A&#732;)=1&#8722; 1&#8722; 1 364 =1&#8722; 365 365 
for which our list looks di&#64256;erent: The reason for this discrepancy is that in the previous situation, A also 
n P (A) 
5 0.014 
10 0.027 
15 0.040 
20 0.053 
25 0.066 
30 0.079 
50 0.128 
366 0.634 
contained all pairs among your n friends, and that number went up very quickly. 
Independent Events 
Intuitively, we want to de&#64257;ne a notion that for two di&#64256;erent events A and B the occurrence of A does 
not &#8221;a&#64256;ect&#8221; the likelihood of the occurrence of B, e.g. if we toss a coin two times, the outcome of the 
second toss should not be in&#64258;uenced in any way by the outcome of the &#64257;rst. In order to keep notation 
simple, we will from now on denote 
P (A &#8745;B)= P (AB) 
De&#64257;nition1 The events A and B are said to be independent if 
P (A &#8745;B)= P (A)P (B) 
From this you can see that independence is merely a property of the probability distribution, not neces&#173;
sarily ofthephysical natureoftheevents. Sowhileinsomeexamples(e.g. theseriesof cointosses) we 
have a good intuition for independence, in most cases we&#8217;ll have no choice but need to check the formal 
condition. 
Example4 Say we roll a fair die once, what are the probabilities for the events 
A = {2, 4, 6} 
B = {1, 2, 3, 4} 
n(A)and their intersection? Counting outcomes, P (A)= n(S) =3
6 =1
2, and similarly, P (B)=46 =2
3. The 
probability of the intersection of events is 
21 P (AB)= P ({2, 4})= = = P (A)P (B)63 
so the events are independent even though they resulted from the same roll. 
Inordertoseehowindependencedependscrucially ontheunderlyingprobabilitydistribution, nowsuppose 
3 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Since in any event, exactly 4 projectiles reach their target, the sample space S consists of all combinations 
of 4 missiles out of 16. Therefore the number of elements of S is given by the binomial coe&#64259;cient 
&#65533; &#65533; 
16 16! n(S)= = 4 12!4! 
Inordertoevaluatetheprobability,oneapproachistousethecomplementrule. Theevent complementary 
to A =&#8221;Atleast onenuclearwarheadhitstarget&#8221;is AC =&#8221;All missileshitting thetarget areconventional&#8221;, 
and the outcomes in AC aregivenby all combinations of4 missiles out of8(the conventional ones), so 
that &#65533;&#65533; 
n(AC )8 8! = = 4 4!4! 
Therefore, 
12!4!8! 12! 8! 1 8&#183; 7&#183; 6&#183; 5 25 P (A)=1&#8722;P (AC )=1&#8722; =1&#8722; =1&#8722; = 16!4!4! 16! 4! 16&#183; 15&#183; 14&#183; 13 1 26 
So it turns out that this probability is extremely close to one -I&#8217;m not sure whether you would have 
expected this, but despite being politically incorrect, this example shows that our intuitions may fail easily 
in combinatoric problems, last but not least because of the high numbers of possibilities. 
Example3 The famous birthday &#8221;paradox&#8221; is about a (once) popular party game: given you have a 
group of n friends, whatistheprobabilitythat atleast apairofthemhasthesamebirthday(assuming 
that all birthdays are equally likely, which is actually only approximately true empirically)? Again, let&#8217;s 
look at the complementary event AC that each of your n friends has a di&#64256;erent birthday: since this 
corresponds to drawing n out of 365 without replacement, we can use the corresponding formula 
365! n(AC )= (365&#8722;n)! 
so that we can calculate the probability P (A)of at least two of your friends having the same birthday: 
P (A)=1&#8722;P (AC )=1&#8722; n(AC ) =1&#8722; 365! 
n(S) (365&#8722;n)!365n 
Thisformulais notyetparticularly easy to read, solet&#8217;sjust writedowntheprobabilitiesindecimalsfor 
a few values of n: 
n 
5 
10 
15 
20 
25 
30 
50 
366 P (A) 
0.027 
0.117 
0.253 
0.411 
0.569 
0.706 
0.97 
1 
2 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 3 
Konrad Menzel 
February 10, 2009 
Counting Rules and Probabilities 
Recall thatwith simpleprobabilities,each outcomeisequallylikely,andfora &#64257;nitesamplespace,wecan 
give the probability of an event A as 
n(A)P (A)= n(S) 
We&#8217;ll now see how to make good use of counting rules to calculate these probabilities. 
Example1 Draw two cards from a deck of 52 cards with replacement, assuming that each cardispicked 
with equal probability. What is the possibility of drawing two di&#64256;erent cards? 
S = {(A&#9827;,A&#9827;), (A&#9827;,A&#9824;),...}=&#8658; n(S)=522 
The event &#8221;two di&#64256;erent cards&#8221; consists of 
52! A = {(A&#9827;,A&#9824;), (A&#9827;,A&#9829;),...}=&#8658; n(A)= =52&#183; 51 (52&#8722;2)! 
so that 
n(A) 52! 51 P (A)= = = &#8776; 0.98 n(S) (52&#8722;2)!(52)2 52 
Alternatively, we could have used proposition 1 on probabilities: 
1 51 P (A)=1&#8722;P (AC )=1&#8722;P (&#8221;two cards are same&#8221;)=1&#8722;P (&#8221;2ndcard sameas1st&#8221;) =1&#8722; = 52 52 
In some other examples, computing the probability of an event through its complement may simplify the 
calculation a lot. 
Example2 Suppose Oceania attacks the capital of Eurasia1 with 16 missiles, 8 of which carry a nuclear 
warhead. Suppose the Eurasian army can track all 16 projectiles and has 12 missiles each of which 
can intercept one incoming missile with absolute certainty, but can&#8217;t tell which of the missiles carry a 
conventional load. What is the combinatorial probability that Eurasia cannot avert disaster and at least 
one of the nuclear warheads reaches its target? What would be your intuitive guess? 
1The names are taken from Orwell&#8217;s novel &#8221;1984&#8221;, so this is not supposed to be a real-world example. 
1 </text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>&#65533;4 Conditional Independence (not covered in lecture) 
We can extend the de&#64257;nition of independence to conditional probabilities: 
De&#64257;nition4 Two events A and B are said to be independent conditional on event C if the conditional 
probabilities satisfy 
P (AB|C)= P (A|C)P (B|C) 
Thisde&#64257;nitioncorrespondsexactly tothat of unconditionalindependencewhich welooked atbefore,only 
that we restrict ourselves to the new sample space S&#65533; = C. The notion of conditional independence is 
going toplay animportant rolelater onin econometrics, soitdeserves a special mention. As atechnical 
point,itisimportanttonoticethatconditionalindependencedoesnotimply unconditionalindependence, 
or vice versa. In other words, whether two events are independent depends crucially on what else we 
are conditioning on. I mentioned this in passing in the last lecture, and I&#8217;m now going to provide the 
following example as an illustration: 
Example9 Let&#8217;s look again at a roll of a fair die, i.e. S = {1, 2, 3, 4, 5, 6}, where each outcome occurs 
withprobability1
6. 
(1) Making two independent events dependent: Consider the events A = {1, 2, 3, 4} and B = {2, 4, 6}. 
We already saw in a previous example that these events are independent: 
43 1 P (A)P (B)= P ({1, 2, 3, 4})P ({2, 4, 6})= &#183; = = P ({2, 4})= P (AB)66 3 
Now let event C = {3, 6}. Then 
P (AC) P ({3})1 P ({6}) P (BC)P (A|C)= = = = = = P (B|C)P (C) P ({3, 6})2 P (C) P (C) 
However, 
P (&#8709;)P (AB|C)= =0 &#65533;= P (A|C)P (B|C)P (C) 
i.e. A and B are not independent conditional on C since their intersections with C aredisjoint. 
(2) Making two dependent events independent: Let D = {2, 3, 4}and E = {2, 4, 6}. We can check that 
D and E are dependent: we can see that P (D)= P (E)=1
2. However, 
11 P (DE)= P ({2, 4})= = = P (D)P (E)34 
But if we condition on F = {3, 4, 5, 6}, 
P ({4}) 1 P (DE|F )= = P ({3, 4, 5, 6})4 
whereas 
P ({3, 4}) P ({4, 6}) 111 P (D|F )P (E|F )= &#183; = &#183; = P ({3, 4, 5, 6}) P ({3, 4, 5, 6}) 22 4 
so that by conditioning on F , D and E becameindependent. 
8 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533;thatthediehadbeenmanipulated sothat P (6)= 3
8 1
8 . , whereas for all other numbers n =1,..., 5, P (n)= 
Then,by axiom(P3) on addingprobabilities ofdisjoint events, 
1135 41 P (A)= + + = ,P (B)= = 8888 82 
and 21 5 P (AB)= = &lt;P (A)P (B)= 84 16 
One interpretation of independence is the following: suppose we know that B has occurred, does that 
knowledge change our beliefs about the likelihood of A (andvice versa)? We&#8217;ll formalize this in the next 
section, and it will turn out that if A and B are independent, there is nothing about event A tobelearnt 
fromtheknowledgethat B occurred. 
Proposition1 If A and B are independent, then A and BC are also independent. 
Proof: Since we can partition A into the disjoint events AB and ABC , we can write 
(P 3) Indep. P (ABC )= P (A)&#8722;P (AB)= P (A)&#8722;P (A)P (B)= P (A)(1&#8722;P (B))= P (A)P (BC ) 
proving independence &#65533;
We can now extend the de&#64257;nition of independence to more than two events:
De&#64257;nition2 A collection of events A1,A2,... are independent if for any subset Ai1 ,Ai2 ,... of these
events(allindicesbeingdi&#64256;erent)
P (Ai1 &#8745;Ai2 &#8745;...)= P (Ai1 )&#183; P (Ai2 )&#183; ... 
E.g. for three events A,B,C, 
P (AB)= P (A)P (B),P (AC)= P (A)P (C),P (BC)= P (B)P (C) 
and 
P (ABC)= P (A)P (B)P (C) 
Example5 Let the sample space be S = {s1,s2,s3,s4}, and P (si)= 1
4 for all outcomes. Then each of 
the events 
A = {s1,s2},B = {s1,s3},C = {s1,s4} 
occurs with probability 1
2 . The probability for the event A &#8745;B is 
1 P (AB)= P ({s1})= = P (A)P (B)4 
andlikewiseforany otherpairof events, sotheeventsare pairwise independent. However, taken together, 
the full collection is not independent since 
11 P (ABC)= P ({s1})= = = P (A)P (B)P (C)48 
Intuitively, once we know that both A and B occurred, we know for sure that C occurred. 
4 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Does this mean that the surgeons&#8217; skill decreases with age? Probably not -let&#8217;s suppose there are four 
di&#64256;erent types of procedures a surgeon may have to perform -single, double, triple, and quadruple bypass 
(the terminology refers to the number of coronary arteries that have to be bypassed arti&#64257;cially). The 
complexity of the procedure and the risk to the patient increase in the number of bypasses, and it might 
also be that the patients who are generally &#8221;sicker&#8221; may tend to require a more complicated procedure. 
Suppose we are told that for each procedure, patients of the experienced surgeon face signi&#64257;cantly lower 
death rates, but that the overall patient mortality is lower for unexperienced surgeons. In light of the law 
of total probability, how does that &#64257;t together? Let&#8217;s look at an example (these numbers are of course 
made up): 
Unexperienced Experienced 
Procedure Death Rate Percentage of Cases Death Rate Percentage of Cases 
Single Bypass 4.0% 50.0% 2.0% 25.0% 
Double Bypass 6.0% 40.0% 4.0% 25.0% 
Triple Bypass 10.0% 9.0% 6.0% 25.0% 
Quadruple Bypass 20.0% 1.0% 12.0% 25.0% 
Total 5.5% 100.0% 6% 100.0% 
In the notation of the Law of Total Probability, the overall death rate P (A) for, say, experienced 
surgeons can be computed from the death rate conditional on procedure Bi, P (A|Bi), and the base 
rates/proportionsP (Bi)of cases corresponding to each procedure. 
We can see that since experienced surgeons are assigned a disproportionately large share of risky cases 
(presumably because you need more experience for these), their average (better: marginal) death rate is 
higherthanthat of unexperienced surgeons, eventhough theyperformbetter conditional oneach treatment 
category. This phenomenon is often referred to as a composition e&#64256;ect. 
So what is the practical importance of each type of probabilities? If you were to choose among surgeons 
for a bypass operation, the type of procedure should only depend on your health status, not whether the 
surgeonis experienced or not, sointhat situationyou should only care aboutthe conditional probabilities. 
It&#8217;s harder to come up with a good use for the marginal death rates. 
Inmoststatistical analysis,you&#8217;dinfactbeinterestedin conditional death rates(e.g. ifyouareinterested 
in the e&#64256;ect of experience on mortality), and the variable &#8221;type of procedure&#8221; would be treated as what 
statisticians call a confoundingfactor. A classical problem in statistics and econometrics is that often 
many of the relevant confounding factors are not observed, and you&#8217;ll learn about &#8221;tricks&#8221; of dealing with 
thatproblem. 
Remark2 Another closely related concept is that of conditionalindependence, whichisgoing tobe very 
important in Econometrics. Two events A and B are said to be independent conditional on event C if 
P (AB|C)= P (A|C)P (B|C) 
It is important to note that 
&#8226; unconditionalindependencedoes not imply conditional independence 
&#8226; conditionalindependencedoes not imply unconditional independence 
i.e. whether A and B are independent depends crucially on what we are conditioning on. There&#8217;ll be an 
exercise with a counterexample on the next problem set. 
7 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec07/</lecture_pdf_url>
      <lectureno>7</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 
&#65533; 
&#65533; &#65533; 1000 &#65533; &#65533; 
= &#955;e&#8722;&#955;x 1&#8722;e &#8722;&#955;(1000&#8722;x) dx 
0 &#65533; 1000 
= &#955; &#65533; 
e &#8722;&#955;x &#8722;e &#8722;1000&#955;&#65533; 
dx 
0 
=1&#8722;e &#8722;1000&#955; &#8722;1000&#955;e&#8722;1000&#955; =1&#8722;(1+1000&#955;)e &#8722;1000&#955; 
Again, events over continuous bivariate random variables correspond to areas in the plane, and we &#64257;nd 
probabilities by integrating the density over those areas. 
2 Joint c.d.f. of 2 Random Variables X,Y 
I&#8217;lljustgivede&#64257;nitions. We are notgoing to usethis alotinthis class,butyou shouldhave seenthis. 
De&#64257;nition1 The joint c.d.f. for random variables (X,Y) is de&#64257;ned as the function FXY (x,y) for 
(x,y)&#8712; R2 
FXY (x,y)= P(X &#8804; x,Y &#8804; y) 
We computeprobabilitiesfromjoint c.d.f.s asfollows 
P(a &#8804; X &#8804; b,c &#8804; Y &#8804; d)= F(b,d)&#8722;F(a,d)&#8722;F(b,c)+F(a,c) 
We have to add in the last term because in a sense, it got subtracted o&#64256; twice before. 
Joint c.d.f.s are related to p.d.f.s in the following way: for continuous random variables, 
y x 
FXY (x,y)= fXY (u,v)dudv 
&#8722;&#8734; &#8722;&#8734; 
&#8706;2 
fXY (x,y)= FXY (x,y)&#8706;y&#8706;x 
In the discrete case, 
FXY (x,y)= fXY (u,v) 
u&#8804;xv&#8804;y 
3 Marginal p.d.f.s 
If wehave a joint distribution, we may want to recover distribution of one variable X. 
If X and Y are discrete random variables withjointp.d.f. FXY ,then 
fX(x)= fXY (x,y) 
all y 
fY (y)= fXY (x,y) 
all x 
If X and Y are continuous, we&#8217;ll essentially replace summation by integration, so that 
&#65533; &#8734; 
fX(x)= fXY (x,y)dy 
&#8722;&#8734; &#65533; &#8734; 
fY (y)= fXY (x,y)dx 
&#8722;&#8734; 
(1) 
4 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; 
&#65533; 
4 Example3 Thisexampleisbased onreal-worlddataextra-marital a&#64256;airscollectedby the Redbook mag&#173;
azinein1977.1 Inthe survey,individuals were askedto ratetheir marriage on a scalefrom1(unhappy) 
to3(happy), and to reportthe number of extra-marital a&#64256;airs,dividedby the number ofyears married. 
Fornowlet&#8217;slook atthejointdistributionof &#8221;marriagequality&#8221;, X, with duration of marriage in years, 
Y.Wecanstartfromthe &#8221;cell&#8221; probabilitiesgivenby thejointp.d.f.,and then&#64257;llinthemarginalp.d.f.s
on the left and at the bottom of the table:
Itisinteresting to notethat, eventhough the marginaldistributions are relatively even,thejointdistribu-
Y 
fXY 1 8 12 fX 
1 4.66% 11.48% 12.98% 29.12% 
X 2 5.16% 14.81% 12.31% 32.28% 
3 13.48% 16.47% 8.65% 38.60% 
fY 23.30% 42.76% 33.94% 100.00% 
tionseemstobeconcentratedalong thebottomleft/top rightdiagonal,withthejointp.d.f. taking much 
lower values in the top-left and bottom-right corners of the table. 
Example4 Recalltheexamplewiththetwosparkplugsfromlasttime. Thejointp.d.f. was 
&#955;2e&#8722;&#955;(x+y) if x &#8805; 0 and y &#8805; 0 fXY (x,y)= 0 otherwise 
The marginal density of X is 
&#65533; &#8734; &#8734; 
fX(x)= fXY (x,y)dy = &#955;2 e &#8722;&#955;(x+y)dy 
&#8722;&#8734; 0 &#65533; &#8734; 
= &#955;e&#8722;&#955;x &#955;e&#8722;&#955;ydy = &#955;e&#8722;&#955;x[1&#8722;0] = &#955;e&#8722;&#955;x 
0 
Similarly, 
fY (y)= &#955;e&#8722;&#955;y 
Independence 
Recall that we said that two events A and B wereindependentif P(AB)= P(A)P(B). Now we&#8217;ll de&#64257;ne 
a similar notion for random variables. 
De&#64257;nition2 We say that the random variables X and Y are independent iffor any regions A,B &#8834; R, 
P(X &#8712; A,Y &#8712; B)= P(X &#8712; A)P(Y &#8712; B) 
Note that this requirement is very strict: we are looking at events of the type X &#8712; A and Y &#8712; B and 
requirethat all pairs of them are mutually independent. 
This de&#64257;nition is not very practical per se, because it may be di&#64259;cult to check, however if X and Y are 
independent,itfollowsfromthede&#64257;nitionthatinparticular 
FXY (x,y)= P(X &#8804; x,Y &#8804; y)= P(X &#8804; x)P(Y &#8804; y)= FX(x)FY (y) 
From this, it is possible to derive the following condition which is usually much easier to verify 
1Data available at http://pages.stern.nyu.edu/ wgreene/Text/Edition6/tablelist6.htm 
5 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533; 
&#65533; 
&#65533; Example6 Recalltheexamplewiththetwosparkplugsfromlasttime. Thejointp.d.f. was 
&#955;2e&#8722;&#955;(x+y) if x &#8805; 0 and y &#8805; 0 fXY (x,y)= 0 otherwise 
and in the last section we derived the marginal p.d.f.s 
fX(x)= &#955;e&#8722;&#955;x 
fY (y)= &#955;e&#8722;&#955;y 
Therefore,theproductis 
fX(x)fY (y)= &#955;2 e &#8722;&#955;x e &#8722;&#955;y = fXY (x,y) 
so that the lives of spark plug 1 and 2 are independent. 
Remark1 The condition onthejoint and marginaldensitiesforindependence canbe restated asfollows 
for continuous random variables: Whenever we canfactor thejointp.d.f. into 
fXY (x,y)= g(x)h(y) 
where g(&#183;)depends only on x and h(&#183;)depends only on y,then X and Y are independent. In particular, 
we don&#8217;t have to calculate the marginal densities explicitly. 
Example7 Say, wehave ajointp.d.f. 
ce &#8722;(x+2y) if x &#8805; 0,y &#8805; 0 fXY (x,y)= 0 otherwise 
Then we can choose e.g. g(x)= ce&#8722;x and h(y)= e&#8722;2y, and even though these aren&#8217;t proper densities, 
this is enough to show that X and Y areindependent. 
Example8 Suppose wehavethejointp.d.f. 
cx2y if x2 &#8804; y &#8804; 1 fXY (x,y)= 0 otherwise 
Can X and Y beindependent?
Eventhoughineithercase(i.e. whether x 2 &#8804; y &#8804; 1 holds or whether it doesn&#8217;t) the p.d.f. factors into
functions of x and y (forthe zeropart,that&#8217;striviallytrue), we can alsoseethatthesupportof X depends
on the value of Y, and therefore, X and Y can&#8217;t be independent -e.g. if X &#8805; 21 , we must have Y &#8805; 1
4 ,
so that &#65533; &#65533; &#65533; &#65533;&#65533; &#65533;
1 1 1 1 PX &#8805; ,Y &#8804; =0 &lt;P X &#8805; PY &#8804; 2 4 2 4 
Notethatthejointsupportof tworandomvariableshastoberectangular(possibly all of R2)inorder 
for X and Y to be independent: if it&#8217;s not, for some realizations of X, certain values of Y would be ruled 
out which could occur otherwise. But if that were true, knowing X doesgive usinformation about Y, so 
they can&#8217;t be independent. However, this condition on the support alone does not imply independence. 
7 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Fxy 
1 
x y &#65533; (-111, 45) (-104, 45) 
(-104, 41) (-111, 41) 
375 mi. 276 mi. 
Casper , WY Wyoming 40 mi. 
(x,y) 
Figure1: TheUFO at(x,y)can be seen    Image by MIT OpenCourseWare.
from Casper, WY
A)of the stateisproportional tothe areaof A. Therefore, we don&#8217;t have to do any integration, but &#64257;nding 
the probability reduces to a purely geometric exercise. We can calculate the probability as 
Area(&#8221;less than 40 miles from Casper&#8221;) 402&#960; P(&#8221;less than 40miles from Casper&#8221;) = = &#8776; 4.9% Area(&#8221;All of Wyoming&#8221;) 375&#183; 276 
You should notice that for the uniform distribution, there is often no need to perform complicated inte&#173;
gration, but you may be able to treat everything as a purely geometric problem. 
Unlike in the last example, typically, there&#8217;s no way around integrating the density function in order to 
obtain probabilities, since any nonconstant density re-weights di&#64256;erent regions in terms of probability 
mass. We&#8217;ll do this in the clean, systematic fashion in the following example: 
Example2 Suppose you have 2 spark plugs in your lawn mower, and let X be the life of spark plug 1, 
and Y the life of spark plug 2. Suppose we can describe the distribution by 
&#955;2e&#8722;&#955;(x+y) if x &#8805; 0 and y &#8805; 0 fXY (x,y)= 0 otherwise 
Figure2 onpage2 shows whatthejointdensitylookslike. 
2 Figure 2: Joint Density of Lives X and       Image by MIT OpenCourseWare.
Yof Sparkplugs 1 and 2</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; In fact, this density can be derived from the assumption that the spark plugs fail independently of one 
another at a &#64257;xed rate &#955;, which doesn&#8217;t change over their lifetime. 
If the lawn mower is going to work as long as either spark plug works, what is the probability that the 
lawn mower fails within 1000 hours? 
1000 1000 y 
x F 
Figure 3: The Event &#8220;Lawn Mower Fails before 1000 hrs.&#8221; in &#64257;rst situation 
&#65533; 1000 &#65533; 1000 
P(X &#8804; 1000,Y &#8804; 1000) = &#955;2 e &#8722;&#955;(x+y)dydx 
0 0 &#65533; 1000 &#65533; 1000 
= &#955;2 e &#8722;&#955;x e &#8722;&#955;ydydx 
0 0 &#65533; 1000 &#65533; 1000 
= &#955;e&#8722;&#955;x &#955;e&#8722;&#955;ydy dx 
0 0 &#65533; 1000 
= &#955;e&#8722;&#955;x &#65533; 
1&#8722;e &#8722;1000&#955;&#65533; 
dx 
0 &#65533; &#65533;2 =1&#8722;e &#8722;1000&#955;
Whatisthatprobability if thesecond sparkplug isonly usedif the &#64257;rstonefails,i.e. howdowecalculate 
P(X + Y &#8804; 1000)? Note that this only changes the &#8220;event&#8221; we care about, i.e. the region of R2 we 
1000 
1000 y f 
x 
Figure 4: The Event &#8220;Lawn Mower Fails      Image by MIT OpenCourseWare.
before 1000 hrs.&#8221; in second situation 
integrate over, but we still integrate the same density. 
&#65533; 1000 &#65533; 1000&#8722;x 
P(X + Y &#8804; 1000) = &#955;2 e &#8722;&#955;x e &#8722;&#955;ydy dx 
0 0 &#65533; 1000 &#65533; 1000&#8722;x 
= &#955;e&#8722;&#955;x &#955;e&#8722;&#955;ydy dx 
0 0 
3 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; &#65533; &#65533; Proposition1 X and Y areindependentif and onlyiftheirjoint and marginalp.d.f.s satisfy 
fXY (x,y)= fX(x)fY (y) 
Proof: For discrete random variables, this follows directly from applying the de&#64257;nition to A = {x} 
and B = {y}. For continuous random variables, we can show that if X and Y are independent, we can 
di&#64256;erentiate the equation 
FXY (x,y)= FX(x)FY (y) 
on both sides in order to obtain 
&#8706;2 &#8706;2 &#8706; fXY (x,y)= FXY (x,y)= [FX(x)FY (y)]= fX(x)FY (y)= fX(x)fY (y)&#8706;y&#8706;x &#8706;y&#8706;x &#8706;y 
Conversely,iftheproduct ofthe marginalp.d.f.s equalsthejointp.d.f., we canintegrate 
P(X &#8712; A,Y &#8712; B)= fXY (x,y)dydx = fX(x)fY (y)dydx 
AB AB 
= fX(x)dx fY (y)dy 
A B 
so that the condition on the marginals implies independence, and we&#8217;ve proven both directions of the 
equivalence &#65533; 
Example5 Going back to the data on extra-marital a&#64256;airs, remember that we calculated the marginal 
p.d.f.s of reported &#8221;marriage quality&#8221;, X, and years married, Y as 
fX(1)=29.12%,fX(2)=32.28%,fX(3)=38.60% 
and 
fY (1)=23.30%,fY (8)=42.76%,fY (12)= 33.94% 
What should thejointdistributionlooklikeif the two random variables wereinfactindependent? E.g. 
f&#732; XY (3,1) = fX(3)fY (1)=38.60%&#183; 23.30% =8.99% 
The actual value of the joint p.d.f. at that point was 13.48, so that apparently, the two variables are 
not independent. We can now &#64257;ll in the remainder of the table under the assumption of independence: 
Comparing this to our last table we see some systematic discrepancies -in particular, the constructed 
Y 
f&#732; XY 1 8 12 fX 
1 6.78% 12.45% 9.88% 29.12% 
X 2 7.52% 14.81% 10.96% 32.28% 
3 8.99% 16.50% 13.10% 38.60% 
fY 23.30% 42.76% 33.94% 100.00% 
jointp.d.f. f&#732; XY is not as strongly concentrated on the diagonal, which seemed to be a noteworthy feature 
of the actualjointp.d.f.. 
But does this really mean that X and Y are not independent? One caveat is that we calculated the 
probabilities in the joint p.d.f. from a sample of &#8221;draws&#8221; from the underlying distribution, so there is 
some uncertainty over how accurately we could measure the true cell probabilities. In the last part of the 
class, we will see a method of testing formally whether the di&#64256;erences between the &#8221;constructed&#8221; and the 
actual p.d.f. are large enough to suggest that the random variables X and Y areinfact not independent. 
6 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; &#65533; 
&#65533; 
&#65533; 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 7 
Konrad Menzel 
February 26, 2009 
1 Joint Distributions of 2 Random Variables X,Y (ctd.) 
1.1 Continuous Random Variables 
If X and Y are continuous random variables de&#64257;ned over the same sample space S.Thejointp.d.f. of 
(X,Y),fXY (x,y)is a function such that for any subset A ofthe(x,y)plane, 
P((X,Y)&#8712; A)= fXY (x,y)dxdy 
A 
As in the single-variable case, this density must satisfy 
fXY (x,y)&#8805; 0 for each(x,y)&#8712; R2 
and &#65533; &#8734;&#8734; 
fXY (x,y)dxdy =1 
&#8722;&#8734; &#8722;&#8734; 
Notethat 
&#8226; any single point has probability zero 
&#8226; any one-dimensional curve on the plane has probability zero 
Example1 A UFO appears at a random location over Wyoming, which -ignoring the curvature of the 
Earth -can be described quite accurately as a rectangle of 276 times 375 miles. The position of the UFO 
is uniformly distributed over the entire state, and can be expressed as a random longitude X (ranging 
from -111 to -104 degrees) and latitude Y (withvalues between 41 and 45 degrees). 
This means thatthejointdensity of the coordinatesisgivenby 
1 
fXY (x,y)= 28 if &#8722;111 &#8804; x &#8804;&#8722;104 and 41 &#8804; y &#8804; 45 
0 otherwise 
If the UFO can be seen from a distance of up to 40 miles, what is the probability that it can be seen from 
Casper,WY(whichis roughlyin the middle of the state)? 
Let&#8217;s look at the problem graphically: This suggests that the set of locations for which the UFO can be 
seen from Casper can be described as a circle with a 40-mile radius around Casper. Also, for the uniform 
density, the probability of the UFO showing up in a region A (i.e. the integral of a constant density over 
1 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec15/</lecture_pdf_url>
      <lectureno>15</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>We say that X&#175;n convergesinprobability to &#181;. 
Proof: We use our previous result that 
1 &#963;2 &#175;Var( Xn)= Var(Xi)= n n 
By Chebyshev&#8217;sInequality 
&#65533; &#175;&#65533; Var( X&#175;n) &#963;2 n&#8594;&#8734;P |Xn &#8722;&#181;|&gt;&#949; &#8804; = &#8722;&#8594; 0 &#949;2 n&#949;2 
This statement says that for large samples, the sample mean is unlikely to be far away from the 
expectationoftherandomvariable. Foragivenn and agivenvariance &#963;2,wecandirectly useChebyshev&#8217;s 
Inequality to bound the probability that the sample mean is more than a given distance away from &#181;. Xbar_n
&#8722;.5 0 .5 1 1.5
0 50 100 150 200 
n 
Figure 1: 10 sequences of average number of heads in n coin tosses -dashed lines are &#177;&#8730;1
2n 
Example3 Standardization of Units of Measurement (see Stigler&#8217;s book): in the middle ages, often 
every city was using a di&#64256;erent measure of &#8221;foot&#8221;, &#8221;inch&#8221;, &#8221;yard&#8221;, etc. depending on how long the ruler&#8217;s 
corresponding limb was. This means that there is a lot of variation in the units, which complicates trade 
and gives rise to many legal disputes, say whether a given bundle of cloth was really 20 yards long. 
One clever idea people came up with was the following: to determine the length of a rod of 16 feet, you 
takearandomsampleof16individuals(inthiscasetherulewasthe &#64257;rst16peopletoexitthechurch 
on Sunday morning), and add up the length of their feet to obtain a measurement of 16 feet, then divide 
that length by 16. See Figure 2. According to the formula for the variance of an average for 16 
observations, this should decrease the variance of the new measurement unit by 1 
16 . 
Ifthere were no systematicdi&#64256;erencesinfoot sizes(orthe church-goingpopulation) acrossdi&#64256;erent 
places, this should make it much easier for merchants from di&#64256;erent places to trade with each other. 
2.1.3 Example: The &#8221;Wisdom of Crowds&#8221; 
Suppose that a population of size n chooses among 2 candidates for public o&#64259;ce, where the candidate 
with a simple majority of the vote wins. We&#8217;ll look at the random variable Xi which equals 1 if voter i 
6 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; &#949;2 
&#949;2 
&#949;2 &#949;2 
E[x] -&#949; E[x] + &#949; E[x] 
2.1.2 Law of Large Numbers 
De&#64257;nition3 The sample mean is the arithmetic average of n random variables (or realizations) from 
a random sample of size n. We denote it 
n 1 1&#175;Xn = (X1 + ... + Xn)= Xi n n i=1 
&#175; Note that since the Xis are random variables, Xn is also a random variable. 
The expectation of the sample mean is 
n n 1 1&#175;E[Xn]= E Xi = E[Xi]= E[X1] n n i=1 i=1 
If X1,...,Xn are independent, the variance of the sample mean can be calculated as 
n n &#65533;&#65533; 1 1 1&#175;Var Xn =Var Xi = Var(Xi)= Var(X1)2 n n n i=1 i=1 
Whatif the Xisarei.i.d. normal, Xi &#8764; N(&#181;,&#963;2)?Weknowthatalinearcombinationofnormalsisagain 
normal with the appropriate variance and mean, so 
&#175;1 &#963;2Xn &#8764; N &#181;, n 
Since the variance decreases as we increase n, the mean will eventually be very close to E[Xi]with a 
very high probability. This is essentially what the Law of Large Numbers says: 
Theorem1 (Law of Large Numbers) Suppose X1,...,Xn isasequenceofi.i.d. drawswith E[Xi]= &#181; 
and Var(Xi)= &#963;2&#8734; for all i. Then for any &#949;&gt; 0 (typicallya small value), the sample mean satis&#64257;es 
&#175; lim P |Xn &#8722;&#181;|&gt;&#949; =0 
n 
5 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>&#65533; &#65533; &#175;
&#65533; &#65533; Again,sincetherolesofthecandidatescanbeexchangedforthenoisevoters,thedistributionissymmetric 
around the mean, and we can use the bound on the probabilities derived above 
&#175;1 Var( Xn)&#8804; PXn &lt; 2 &#949;2 
&#175; However, now we can see that Var( Xn) doesn&#8217;t go to zero anymore as n &#8594;&#8734; since the &#64257;rst term 
&#175; Var(E[Xn|&#64258;y]) doesn&#8217;t depend on n at all.
In numbers, if &#949; =15%(sixtimeslargerthanintheprevious calculation),thebound equals
1 49 560 &#175;PXn &lt; &#8804; + 2 81 81n 
so that the bound is far above 1
2 no matter how large n is. Note that since this is only an upper bound, 
this doesn&#8217;t really tell us how likely the event really is, but it is clear that since the variance doesn&#8217;t 
decrease to zero, the &#8221;noise&#8221; voters will always have a strong in&#64258;uence on the election result. 
HeretheLawofLargenumbersfailsbecausethe&#64258;yincidenta&#64256;ectsall &#8221;noise&#8221;votersatthesametime, 
so X1,...,Xn are no longer independent. The independence assumption is important because the reason 
why the law of large numbers usually works is that the &#8221;noise&#8221; averages out across many observations. 
If onecomponentofthe &#8221;noise&#8221; iscommonto(oratleasthighly correlated across) all observations,the 
variance contribution of this component -in our example the 49 term in the bound on the probability &#173;81 
does not disappear even if the sample is very large. 
9 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 15 
Konrad Menzel 
April 7, 2009 
1 Special Distributions (continued) 
1.1 The Poisson Distribution 
Often, we may be interested in how often a certain event occurs in a given interval. 
Example1 In airline safety, we may want to have some notion of how &#8221;safe&#8221; an airplane model is. The 
following data are from the website www.airsafe.com, and give the total number of &#64258;ights and number of 
fatal events involving aircraft of a given type up to December 2006. 
Model Flights Events 
Airbus A300 10.35M 9 
Airbus A310 3.94M 6 
Airbus A320/319/321 30.08M 7 
Airbus A340 1.49M 0 
Boeing 727 76.40M 48 
Boeing 737 127.35M 64 
Boeing 747 17.39M 28 
Boeing 757 16.67M 7 
Boeing 767 13.33M 6 
Boeing 777 2.0M 0 
Boeing DC9 61.69M 43 
Boeing DC10 8.75M 15 
Boeing MD11 1.69M 3 
Boeing MD80/MD90 37.27M 14 
Concorde 0.09M 1 
Wecanseeimmediately that sometypesof aircrafthavehadfeweraccidentsthanotherssimplybecause 
they haven&#8217;t been in service for long or were only produced in small numbers. In order to be able to make 
a more meaningful comparison, we need a better way of describing the distribution of the number of fatal 
events. 
Random variables of this type are commonly referred to as countdata, and an often used distribution to 
describethemisthe Poisson distribution 
1 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; De&#64257;nition1 X is said to follow Poisson distribution with arrival rate &#955;, X &#8764; P(&#955;),ifithasthep.d.f. 
&#65533; &#8722;&#955; 
fX(x)=	&#955;x 
xe 
! if x &#8712;{0,1,2,...} 
0 otherwise 
Notethatinparticular, X isdiscrete. 
Property1 For a Poisson random variable X, 
E[X]= &#955; 
Var(X)= &#955; 
In order to see why the Poisson distribution is a plausible candidate for the distribution of a count 
variable, let&#8217;s do the following thought experiment: Suppose 
&#8226; the probability that the event happens in a time window of length n 1 is pn = n&#955; . 
&#8226; we also assume that the event happening at any given instant is independent across time. 
We then let the partition of subintervals grow &#64257;ner by letting n go to in&#64257;nity. If the probability of two 
occurrencesinthesameshrinking subintervalgoestozero,and wethen countthenumber of subintervals 
in which the event occurs at least once we get the total number of occurrences. Notice that this will be 
a binomial random variable with parameters p = n&#955; and n. 
Proposition1 For the binomial random variable Xn &#8764; B n, n&#955; , as n &#8594;&#8734;, the p.d.f. converges to 
n &#955; &#65533;x &#955; &#65533;n&#8722;x e&#8722;&#955;&#955;x 
lim fXn (x)=lim 1&#8722; = 
n n x n n x! 
Proof: Wecantakethelimitof theproductastheproduct oflimits, and evaluateeach termseparately: 
By awell-knownresultfromcalculus(e.g. candoTaylorexpansionsonboth sides), 
&#65533;&#65533;n&#955; lim 1&#8722; = e&#8722;&#955; 
n n 
So we are left with the term 
&#65533; &#65533;&#65533;&#65533;x &#65533;&#65533; &#8722;x &#65533;&#65533;x n &#955; &#955; n! &#955; Tn = 1&#8722; = x n n x!(n &#8722;x)! n &#8722;&#955; 
for which we can show 
n(n &#8722;1)... (n &#8722;k +1)&#955;x &#955;x n n &#8722;1 n &#8722;x +1 &#955;x 
lim Tn =lim	 = lim &#183; ... = &#183; 1 
n n x!(n &#8722;&#955;)x x! n n &#8722;&#955;n &#8722;&#955; n &#8722;&#955; x! 
sinceboth x and &#955; are &#64257;xed and therefore become small compared to n. Putting thepiecestogether,we 
get the expression stated in the proposition &#65533; 
Example2 A classic example (classic in the history of statistics at least) for count data are records 
on the number of soldiers in the 19th century Prussian cavalry that died after being kicked by a horse. 
As found by the Russian statistician Ladislaus Bortkiewicz in 1898, the Poisson distribution gives a 
2 </text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>&#65533; &#65533; &#175;
&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#175;&#65533; &#175;&#65533; &#65533; &#175;&#65533; Now note that since noise voters don&#8217;t favor either candidate, the distribution is symmetric around &#181;, so 
that 
&#175; &#175; P(Xn &#8722;&#181;&gt;&#949;)= P(Xn &#8722;&#181;&lt; &#8722;&#949;) 
Since &#181; = 1
2 + &#949;, the probability of candidate B losing can be obtained as 
Var( X&#175;n)&#8805; 2&#949;2P(X&#175;n &#8722;&#181;&lt; &#8722;&#949;)&#8660; PX&#175;n &lt; 1 Var( Xn)1&#8722;2&#949; &#8804; = 2 &#949;2 4n&#949;2 
Let&#8217;s try a few values: Say, 2&#949; =5%,howlargedoes n have to be in order to keep the probability of 
electing candidate B below 5%? -The bound becomes 
1 90% 90 &#175;PXn &lt; &#8804; = 2 4(5%)2nn 
so n &#8805; 1800 &#8776; 95 is su&#64259;cient to keep the probability of electing for the wrong candidate below 5% even 19 
if 95% of the electorate take their decision at random.
Thisphenomenonisknownasthe &#8221;wisdomof thecrowds:&#8221; thestochastic &#8221;noise&#8221; intheelectionoutcome
introduced by the uninformed voters averages out in large samples, and in the end only the systematic
&#8221;signal&#8221; from the informed voters decides the outcome of the election.
Notice that, like in the Law of Large Numbers, we assumed that individuals&#8217; votes were independent. 
What happens if we drop independence? 
Suppose that during the televised debate between the candidates, there is a &#64258;y in the TV studio which 
randomlylandsoneitherA orB&#8217;sface(with equalprobability 1
2 )and spendssometimecrawling around, 
causing a lot of embarrassment to that candidate. The informed voters don&#8217;t change their behavior, but 
the uninformed voters vote for the candidate with the &#64258;y with probability 31 , and with probability 2
3 for 
his opponent. 
&#175; By the law of iterated expectations, the mean of Xn is 
1 1&#175; &#175;+ E[Xn|&#64258;y lands on B] &#181; = E[Xn|&#64258;y lands on A] 2 2 
1 1 1 2 1 = 2&#949;+(1 &#8722;2&#949;) + 2&#949;+(1 &#8722;2&#949;) = + &#949; 2 3 2 3 2 
sothe meanisthe same asbefore. However,the variancedoes change: by theANOVAidentity(condi&#173;
tional variance) 
Var( Xn) = Var E[Xn|&#64258;y] + E Var( Xn|&#64258;y) 
We can calculate 
&#175; &#175;2(1&#8722;2&#949;)Var( Xn|&#64258;y on A) = Var( Xn|&#64258;y onB) = 9n 
114&#175;E[Xn|&#64258;y onA] = 2&#949;+(1 &#8722;2&#949;) = + &#949; 333 
222&#175;E[Xn|&#64258;y onB] = 2&#949;+(1&#8722;2&#949;) = + &#949; 333 
sothat 
&#65533;&#65533;2 
&#175;11 2(1&#8722;2&#949;)Var( Xn)= &#8722; &#949; + 63 9n 
8 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; The basic idea is that we&#8217;ll &#64257;nd approximations to the p.d.f. which get closer and closer to the &#8221;truth&#8221; 
as we increase the size n of the sample. The two main results are: 
1. the Law of Large Numbers: for large n, the sample mean will with all likelihood be &#8221;close&#8221; to the 
expectation E[X]of the random variable. 
2. the Central Limit Theorem: the p.d.f. of the standardized sample mean (&#8221;standardized&#8221; in the 
senseof thelastlecture: zeromeanand unitvariance) willbecomearbitrarily closetothep.d.f. of 
a standard normal random variable. 
Formally, the asymptotic results state what will happen as n &#8594;&#8734;,butforpracticalpurposes(i.e. for 
&#64257;nite n), theyalso imply that for n large enough, the approximations will be reasonably accurate. 
2.1 The Law of Large Numbers 
2.1.1 Chebyshev&#8217;s Inequality 
Chebyshev&#8217;s Inequality is a formal result which gives a bound on the probability of the realization of a 
random variable being &#8221;far away&#8221; from the expectation. 
Proposition2 Let X be a random variable with Var(X)&lt; &#8734;. Then for any &#949;&gt; 0, 
Var(X)P (|X &#8722;E[X]|&#8805;&#949;)&#8804; &#949;2 
Proof: Let the p.d.f. of X begivenby fX(x). We&#8217;ll show that 
Var(X)&#8805; &#949;2P (|X &#8722;E[X]|&#8805;&#949;) 
By the de&#64257;nition of the variance, 
&#8734; 
Var(X) = (t &#8722;E[X])2fX(t)dt 
&#8722;&#8734; &#65533; E[X]+&#949; &#65533; E[X]&#8722;&#949; &#65533; &#8734; 
= (t &#8722;E[X])2fX(t)dt+ (t &#8722;E[X])2fX(t)dt+ (t &#8722;E[X])2fX(t)dt 
E[X]&#8722;&#949; &#8722;&#8734; E[X]+&#949; 
Each of the three integrals is positive, and in addition, for any t &#8804; E[X]&#8722;&#949; or t &#8805; E[X]+&#949; 
(t &#8722;E[X])2 &#8805; &#949;2 
Therefore,wecanjustdrop the &#64257;rstintegral andget 
&#65533; E[X]&#8722;&#949; &#65533; &#8734; 
Var(X) &#8805; (t &#8722;E[X])2fX(t)dt+ (t &#8722;E[X])2fX(t)dt 
&#8722;&#8734; E[X]+&#949; 
&#65533; E[X]+&#949; &#65533; &#8734; 
&#8805; &#949;2 fX(t)dt+ &#949;2 fX(t)dt 
&#8722;&#8734; E[X]+&#949; 
= &#949;2P (|X &#8722;E[X]|&#8805;&#949;) 
Therefore, we canjustdividethroughby &#949;2 to get the result &#65533; 
Remember that we said at an earlier point in this class that the variance of a random variable is a 
measure of its &#8221;dispersion.&#8221; Chebyshev&#8217;s Inequality makes this statement literal by relating the variance 
totheprobability of observing &#8221;extreme&#8221; realizations(i.e. valuesthatarefarawayfromthemean) of 
the random variable X. 
4 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533; 
&#65533; &#65533; h! 
Figure2: Woodcutby K&#168;obel(1535) of16peopledetermining thelegalde&#64257;nition of a rod of16feet. 
favors candidate A, and 0 otherwise. Candidate A wins if his vote share 
n 1 1&#175;Xn = &#8805; n 2 i=1 
Candidate A is objectively the better choice, but this is only known to a proportion 2&#949;&gt; 0 who 
will vote for candidate A for sure, i.e. P(Xi =1) =1for i =1,..., 2n&#949;. The remainder 1&#8722;2&#949; of the 
population doesn&#8217;t have any substantial information about either candidates and casts votes at random 
with no preference for either candidate, i.e. P(Xi =1) = P(Xi =0) = 21 for i =2n&#949;,...,n. The vote 
&#175; share Xn for candidate A is given by 
n n1 1&#175;Xn = Xi = &#949;+ Xi n n i=1 i=2n&#949; 
Therefore, the expected vote share for candidate A is 
1 1 &#181; =2&#949;+ (1&#8722;2&#949;)= + &#949; 2 2 
and the variance is, by results for the binomial distribution, 
1 &#65533; 1 &#65533; 
1&#8722; &#963;2 =(1&#8722;2&#949;)2 2 =1&#8722;2&#949; 
n 4n 
&#175; By the same argument in the proof of Chebyshev&#8217;s Inequality, we can start from the variance of Xn 
in order to derive bounds on the probabilities 
&#65533; &#181;&#8722;&#949; &#65533; &#181;+&#949; &#65533; &#8734; 
Var( X&#175;n) = (t &#8722;&#181;)2dt+ (t &#8722;&#181;)2dt+ (t &#8722;&#181;)2dt 
&#8722;&#8734; &#181;&#8722;&#949; &#181;+&#949; 
&#8805; &#949;2 &#65533; 
P(X&#175;n &#8722;&#181;&gt;&#949;)+P(X&#175;n &#8722;&#181;&lt; &#8722;&#949;) &#65533; 
7 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533; &#65533; 
2 surprisingly good approximation to the observed frequencies of horsekick deaths over the course of a year 
in a given corps of the Prussian army. 
So how do we compare the observed frequencies to a Poisson p.d.f. which, after all, depends on the 
unknown arrival rate &#955;? As a preview to our upcoming discussion of estimation later in this class, 
a plausible candidate for &#955; would be a value of the parameter in the p.d.f. which predicts the same 
expected number of horsekick deaths that we observe in the sample. So for X &#8764; P(&#955;), what is E[X]? 
Well, as we argued above, a Poisson random variable is the limit of Binomial random variables Xn &#8764; 
B n, &#955; , where we let the number of trials n go to in&#64257;nity. By our previous discussion of the Binomial n 
distribution, E[Xn]= n n&#955; = &#955;, regardless of n. Hence, without directly evaluating the in&#64257;nite series 
E[X]= &#65533; 
x=0 x &#955;x 
x! &#8722;&#955; , we can say that E[X]= &#955;. In the data set on horsekick deaths, the sample mean &#8734; e 
0 .1 .2 .3 .4 .5 
0 1 2 3 4 5 6 
Source: Andrews, D.F. (1985): Data: a Collection of Problems from Many Fields, Springer by corps and year, 1875&#8722;1894 Deaths from Horsekicks in the Prussian Army 
Frequency Poisson Distribution 
(by year andcorps) is &#955;&#710;=0.7, and we can now plot the sample frequencies against the theoretical values 
of the Poisson p.d.f. for an arrival rate of &#955; =0.7 in &#64257;gure 2. The two distributions look strikingly 
similar, and this fact is often referred to as the &#8221;Law of Small Numbers.&#8221; 
Asymptotic Theory 
Until now, we&#8217;ve assumed that we know the p.d.f. (or that we can &#64257;nd it), know parameters (such 
as &#181; and &#963;2 for normal, &#955; for exponential etc.), and then make probability statements based on that 
knowledge. 
In the next part of the class, we won&#8217;t pretend that we have that information, but we&#8217;ll construct 
functions of random variables -which are going to be the estimators -which, along with our knowledge 
of probability, will allow us to infer something about thee underlying distribution. 
A particular estimator which plays an important rule in statistics is the sample mean, which typically 
approximates the expectation of a random variable in a sense we&#8217;ll discuss in a few minutes. 
De&#64257;nition2 A random sample of size n is a sequence X1,...,Xn of n random variables which are 
i.i.d., i.e. the Xi&#8217;s are independent and have same p.d.f. fX(x). 
We also often refer to the realizations of the random variables as the random sample.
The main point of this lecture is going to be that if we have a random sample with n large, we actually
don&#8217;t need to know a lot about the distribution of Xi (e.g. don&#8217;t need to know fXi(x)in order to be able
to describe the distribution of the sample mean fairly accurately.
3 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec21/</lecture_pdf_url>
      <lectureno>21</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; 
&#65533; 
&#65533; In the notation of the Neyman-Pearson Lemma, x can be any of the 23 possible combinations ofpieces 
of evidence. Using theassumptionofindependence, we canthereforelistallpossible combinationsof clues 
with their respective likelihood under each hypothesis and the likelihood ratio. I already ordered the list by 
the likelihood ratios in the third column. In the last column, I added 
&#945;(k)= f0(x) 
r(x)&#8804;k 
the cumulative sum over the ordered list of combinations x. 
guilty fA(x) not guilty f0(x) likelihood ratio r(x)= f0(x) &#945;(k)fA(x) 
1. all three clues 216/1000 9/1000 0.0417 9/1000 
2. no alibi,found purse 144/1000 21/1000 0.1458 30/1000 
3. ran,no alibi 324/1000 81/1000 0.25 111/1000 
4. no alibi 216/1000 189/1000 0.875 300/1000 
5. ran,found purse 24/1000 21/1000 0.875 321/1000 
6. found purse 16/1000 49/1000 3.0625 370/1000 
7. ran 36/1000 189/1000 5.25 559/1000 
8. none of the clues 24/1000 441/1000 18.375 1 
The jury convicting the defendant only if there is at least 95% con&#64257;dence that the charge is true 
correspondsto aprobability offalse conviction(i.e. ifthedefendantisinfactinnocent) ofless than5%. 
In the terminology of hypothesis test, the sentence corresponds to a rejection of the null hypothesis that 
the defendant is innocent using the most powerful test of size &#945; =5%. 
Looking at the values of &#945;(k) in the last column of the table, we can read o&#64256; that including more than 
the &#64257;rst two combinations of the evidence raises the probability of a false conviction &#945; to more than 5%. 
Therefore,thejury should convictthedefendantifhedoesn&#8217;thavean alibi and the emptypurse wasfound 
nearhishome, regardless whetherhe ran whenhe sawthepolice. Inprinciple,thejury couldin addition 
randomize whenthedefendant ran,had no alibi,but nopurse wasfound(thatis case3): ifinthat case, 
thejury convictedthedefendant withprobability 50&#8722;30 &#8776; 1, the probability of a false conviction would be 81 4
exactly equal to5%,but this wouldprobably notbe considered an acceptablepracticein criminaljustice. 
Example 5 We can now showthat atestbased onthe meanisinfact mostpowerfulinthe normal case.
Suppose Xi &#8764; N(&#181;,4), and we test H0 : &#181; =0 against HA : &#181; =1, where we observe an i.i.d. sample
X =(X1,...,X25)of 25 observations.
Since the observations are i.i.d. normal, the likelihood ratio evaluated at the observed sample is given by
(Xi&#8722;0)2 
2&#183;4f(X|&#181;=0) 25 &#8730;
21 
&#960;2 e&#8722; 
r(X)= = (Xi&#8722;1)2f(X|&#181;=1) 1 2&#183;4 i=1 &#8730;
2&#960;2 e&#8722; 
25 
12 2 = e8 [(Xi &#8722;2Xi+1)&#8722;(Xi )] 
i=1 
25 1 P25 25 1 &#175;= e 8 &#8722;4 i=1 Xi = e 8 &#8722;100 X25 
We can see that r(X)depends on the sample only through the sample mean X&#175;25 and is strictly decreasing 
in X&#175;25. Therefore, the critical region of a most powerful test takes the form 
CX(k)= {x : r(x)&#8804; k} 
6 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>1 
1 n = 4 
n = 25 
n = 100 
&#945; &#946; &#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; 1 0 k 2 X1 + X2 
1 0 X n 
4 k Don't reject 
Don't reject Cx : reject 
Cx : reject 
Now we can calculate the probabilities of type I and type II error 
k&#8722;0 k&#175; &#945; = P(X&gt;k|&#181; =0) =1&#8722;&#934; =&#934; &#8722; 2/5 2/5 
k&#8722;1&#175; &#946; = P(X &#8804; k|&#181; =1) =&#934; 2/5 
Therefore, &#64257;xing any one of &#945;,&#946;,k determines the other two, and that choice involves a speci&#64257;c tradeo&#64256; 
between the probability of type I and type II error -if we increase k, the signi&#64257;cance level &#945; goesdown, 
but so does power 1&#8722;&#946;. Speci&#64257;cally, if we choose k = 53 , &#945; &#8776; 6.7%, and &#946; &#8776; 15.87%. 
For di&#64256;erent sample sizes, we can graph the trade-o&#64256; between the probability of type I and type II error 
through the choice of k asfollows: 
A low value of k would give high power, but also a high signi&#64257;cance level, so that increasing k would 
2 move us to the left along the frontier. 
How should we choose k? Recall that in the usual setting, the &#64257;rst priority is to control the probability 
&#945; of false rejections, so we&#8217;ll choose k to keep the probability of a type I error at an acceptably low level, 
usually 5% or 1%. 
Of course, as n &#8594; &#8734;, for &#64257;xed &#945;, the power of the test, 1&#8722;&#946; goes to 1. As a convention, we usually say 
that a rejection at the signi&#64257;cance level &#945; = 5% is &#8221;signi&#64257;cant&#8221;, whereas a rejection at &#945; = 1% is &#8221;highly 
signi&#64257;cant.&#8221; Image by MIT OpenCourseWare.
Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; &#946;(&#65533;2) &#946;(&#65533;1) 
&#65533;2 &#65533;1 k1 k2 0 f(X1 | (&#65533;1) f(Xn | (&#65533;2) 
&#945; 
&#65533; 1 
1 -&#946;(&#65533;) 
0 
1 Evaluation and Construction of Tests 
Asinourdiscussionof estimation,we &#64257;rstintroduced thegeneralideaand sawafewexamples. Nowwe 
will see how to choose among tests and how to construct them from scratch. 
1.1 Properties of Tests 
For any test we care about its level of signi&#64257;cance &#945; = P(type I)and its power 1 &#8722;&#946; =1&#8722;P(typeII).
If H0 and HA areboth simplehypotheses, &#945; and &#946; arewell-de&#64257;nedforgiven &#945;,and wecansimply choose
the test with the highest 1 &#8722;&#946;,the most powerful test.
If HA is composite, and H0 is simple, we need a metric for comparing power functions 1 &#8722; &#946;(&#952;)=
1 &#8722; P(typeII|&#952;) for a given size &#945;. A test is uniformly most powerful (UMP) when it is at least as
powerful at every &#952; &#8712; HA as any other test of the same size. In general, a UMP test need not exist.
Example 3 Sometimes it is possible to &#64257;nd a uniformly most powerful test: Suppose Xi &#8764; N(&#181;,4), and 
we are interested in testing 
H0 : &#181;=0 against HA : &#181;&gt; 0 
&#175; Recall that the most powerful test for H0 : &#181; =0 against HA : &#181; =1 took the form of reject if X&gt;k, 
the general form of the test does not change no matter what &#181;A as long as &#181;A &gt;&#181;0. Therefore a most 
&#175; powerful test for H0 : &#181;=0 against HA : &#181;&gt; 0 will also take the form &#8221;reject if Xn &gt;k.&#8221; 
For the following important result, denote f0(x)= f0(x1,...,xn) the joint p.d.f. of the sample 
X1,...,Xn under the simple null hypothesis H0 : &#181;= &#181;0, and fA(x)thejointp.d.f. of thesampleunder 
HA : &#181; = &#181;A. 
Proposition 1 (Neyman-Pearson Lemma) In testing f0 against fA (where both H0 and HA are 
simple hypotheses), the critical region 
f0(x)C(k)= x : &lt;k fA(x) 
is most powerful for any choice of k &#8805; 0. 
Note that the choice of k depends on the speci&#64257;ed signi&#64257;cance level &#945; of the test. This means that the 
most powerful test rejects if for the sample X1,...,Xn,the likelihood ratio 
f0(X1,...,Xn) r(X1,...,Xn)= fA(X1,...,Xn) 
4 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Example 2 In the previous example, the maintained hypothesis was that &#181;&#8712;{0,1}, but this is a highly 
arti&#64257;cial assumption, and usually we have no reason to believe that this is the case. 
Suppose that as before X1,...,X25 is an i.i.d. sample with Xi &#8764; N(&#181;,4), but now we want to test 
H0 : &#181;=0 against HA : &#181;&#65533;=0 
Now HA is a two-sided composite hypothesis(i.e. underthealternative &#181; could take several values, some 
on the left, some on the right of &#181;0). Also we&#8217;ll again look at a test that&#8217;s only based on the sample mean, 
&#175;X25 -what should the critical region now look like?
Intuitively, it makes sense to reject H0 for both large and small values of X&#175;, i.e. we are unlikely to
see values in either tail if the null hypothesis is true, and the alternative hypothesis states that we are
interested in evidence that &#181; is either greater or smaller than 0.
&#65533; o 
C x &#945; 
2 &#945; 
2 f(&#65533; | &#65533; o) = f(Xn | &#65533; o) 
Therefore, we are going to choose two values k1 and k2 such  Image by MIT OpenCourseWare.
that
&#65533; &#65533;&#65533;&#65533; &#65533;&#65533; 
&#175; &#175;k2 k1&#945; = P(X25 &gt;k2|&#181;=0)+P(X25 &lt;k1|&#181;=0) =1&#8722;&#934; +&#934; 2/5 2/5 
Whatis &#946;? Sincethe alternativedoes notspecify a singleprobability law,but rather a continuum of them, 
&#946; is not well-de&#64257;ned, i.e. for &#64257;xed &#181;, 
&#65533; &#65533; &#65533;&#65533; &#65533; &#65533; 
&#175; &#175;k2 &#8722;&#181; k1 &#8722;&#181;&#946;(&#181;)= P(X25 &gt;k2|&#181;)+P(X25 &lt;k1|&#181;)=1&#8722;&#934; +&#934; 2/5 2/5 
Usually for a desired signi&#64257;cance level &#945;, we choose k1,k2 symmetrically about the value postulated by 
the null hypothesis (note that since the normal distribution is single-peaked and symmetric, this makes 
the critical region as large as possible. 
The last example should remind you of the way we constructed con&#64257;dence intervals for &#181; from a 
normal population with known variance: the above procedure is in fact identical to the following: 
1. construct a 1 &#8722;&#945; con&#64257;denceinterval[A(X),B(X)]for &#181; (case 1, see notes for last class) 
2. reject H0 if &#181;0 =0 &#8712;/[A(X),B(X)] 
Sinceweconstructtheinterval[A(X),B(X)]insuchaway that P&#952;(A(X)&lt;&#952; &lt;B(X))=1&#8722;&#945; implicitly 
under the null assumptions, so that 
P(&#952;0 &#8712;/[A(X),B(X)]|H0 : &#952; = &#952;0)= &#945; 
3 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>   
         
n N 1, 4 under H25 A &#65533;&#65533;&#65533;14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 21 
Konrad Menzel 
May 5, 2009 
Constructing Hypothesis Tests 
If Xi has support SX, then the sample X =(X1,...,Xn)has support Sn The critical region of a test 
is a region CX &#8834; Sn of the support of the sample for which we reject the null. X. 
X 
The following example illustrates most of the important issues in a standard setting, so you should 
look at this carefully and make sure that you know how to apply the same steps to similar problems. 
Example 1 Suppose X1,...,Xn are i.i.d. with Xi &#8764; N(&#181;,4), and weareinterestedintesting H0 : &#181; =0 
against HA : &#181;=1. Let&#8217;s &#64257;rst look at the case n =2: 
X1 X2 
&#65533;A 
&#65533; o Reject : Cx 
Don't reject 
1 1 
k k 
We could design a test which rejects for values of X1 +X2 which are &#8221;too large&#8221; to be compatible with 
&#181;=0. We can also represent this rejection region on a line: 
This representation is much easier to use if n is large, so it&#8217;s hard to visualize the rejection region in 
terms of X1,...,Xn directly. However, by condensing the picture from n to a single dimension we may 
loose the ability of specifying really odd-shaped critical regions, but typically those won&#8217;t be interesting for 
practical purposes anyway. 
&#175; So in this example, we will base our testing procedure on a test statistic Tn(X1,...,Xn)= Xn and reject
for large values of Tn.
How do we choose k? -we&#8217;ll have to trade o&#64256; the two types of error. Suppose now that n =25, and since
Xi &#8764; N(&#181;,4),
4N0,25 Tn :=X&#175;&#8764; &#65533;&#65533;underH0
1 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; is low, i.e. the data is much more likely to have been generated under HA. 
Reject Fo(x) 
FA(x) 
Cx(k) r(x)= 
k 
&#65533;A &#65533;o 
The most powerful test given in the Neyman-Pearson Lemma explicitly solves the trade-o&#64256; between 
size &#65533; 
&#945; = P(reject|H0)= f0(x)dx 
C(k) 
andpower 
1&#8722;&#946; = P(reject|HA)= fA(x)dx 
C(k) 
at every point x in the sample space (where the integrals are over many dimensions, e.g. typically 
f0(x)x &#8712; Rn). Fromtheexpressionsfor &#945; and1&#8722;&#946; wecanseethatthelikelihood ratio fA(x) gives the &#8221;price&#8221; 
ofincluding x with the critical region in terms of how much we &#8221;pay&#8221; in terms of size &#945; relativetothe 
gain in power from including the point in the critical region CX. 
Therefore, we should start constructing the critical region by including the &#8221;cheapest&#8221; points x -i.e. 
thosewith asmalllikelihood ratio. Thenwecangodownthelistof x ordered according tothelikelihood 
ratio and continue including more points until the size &#945; ofthetestisdowntothedesiredlevel. 
Example 4 A criminal defendant (D) is on trial for a purse snatching. In order to convict, the jury 
must believe that there is a 95% chance that the charge is true. 
There arethreepotentialpieces of evidencetheprosecutor may or may nothavebeen abletoproduce, and 
inagivencasethejury takesadecisiontoconvictbased only onwhich out of thethreecluesitispresented 
with. Below are the potential pieces of evidence, assumed to be mutually independent, the probability of 
observing each piece given the defendant is guilty, and the probability of observing each piece given the 
defendant is not guilty 
guilty not guilty likelihood ratio 
1. D ran when he saw police coming 0.6 0.3 1/2 
2. D has no alibi 0.9 0.3 1/3 
3. Empty purse found near D&#8217;s home 0.4 0.1 1/4 
5 Image by MIT OpenCourseWare.</text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec18/</lecture_pdf_url>
      <lectureno>18</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>Thenthe method of moments(MoM) estimator &#952;&#710;can be obtained by solving the equations 
&#181;j(&#952;&#710;)= Xnj j=1,...,k 
for &#952;. 
Example3 Suppose X1,...,Xn isani.i.d. samplefromaPoissondistributionwith unknownparameter 
&#955;,i.e. X &#8764;P(&#955;). The distribution has only one unknown parameter, and the &#64257;rst population moment is 
givenby 
&#181;1(&#955;)= E&#955;[X]= &#955; 
Therefore, the MoM estimator is given by 
n
n &#65533; 
i=1 &#955;&#710;= &#181;1(&#955;&#710;)&#8801;X&#175;n =1 Xi 
What if we used more moments than necessary to estimate the parameter? -We also know that for 
A doubleexponential randomvariablehasp.d.f. Example4 
&#65533; thePoissondistribution 
E&#955;[X2]=Var&#955;(X)+E&#955;[X]2 = &#955;+ &#955;2 
1 fY (y)= &#955;e&#8722;&#955;|y&#8722;&#181;| 
2 
so we have to estimate two parameters (&#955;,&#181;). We can look up in a statistics book that 
E[Y]= &#181; E[Y2]=Var(Y)+E[Y]2 =2 2+ &#181;&#955;2 
so the method of moments estimator solves 
&#175;Y = &#181;&#710;
2 2Y2 = +&#710;&#181; 
&#955;&#710;2 
so that, solving for (&#710;&#181;),&#955;,&#710;
&#175; &#710;
 &#181;&#710;= Y, &#955; = &#8730;
2&#65533;
Y2 &#8722;(Y&#175;)2&#65533;&#8722;1/2 
2.2 Maximum Likelihood Estimation 
While the method of moments only tries to match a selected number of moments of the population to 
their sample counterparts, we might alternatively construct an estimator which makes the population 
distribution as a whole match the sample distribution as closely as possible. This is what the maximum 
likelihood estimator of aparameter &#952; does,whichisloosely speaking,thevaluewhich &#8221;mostlikely&#8221; would 
have generated the observed sample: 
Suppose we have an i.i.d. sample Y1,...,Yn wherethep.d.f. of Y isgivenby fY (y&#952;), which is known up |
totheparameter &#952;. TheMaximumLikelihood estimator(MLE)is afunction &#952;&#710;of the data maximizing 
the jointp.d.f. of the data under &#952;. 
More speci&#64257;cally, we de&#64257;ne the likelihood of the sample as 
n
L(&#952;)= f(y1,...,yn|&#952;)= f(yi&#952;)|
i=1 
3 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 18 
Konrad Menzel 
April 23, 2009 
1 Properties of Estimators (continued) 
1.1 Standard Error 
Often we also want to make statements about the precision of the estimator -we can always state the 
value of the estimate, but how con&#64257;dent are we that it is actually close to the true parameter? 
De&#64257;nition1 The standard error &#963;(&#952;&#710;) of anestimateisthe standarddeviation(or estimated standard 
deviation) of the estimator, 
SE(&#952;&#710;)= Var(&#952;&#710;(X1,...,Xn)) 
Should recall that an estimator is a function of the random variables, and therefore a random variable 
for which we can calculate expectation, variance and other moments. 
Example1 The mean X&#175;n of an i.i.d. sample X1,...,Xn where Var(Xi)= &#963;2 has variance &#963;
n 2 . There&#173;
fore, the standard error is &#963;&#175;SE(Xn)= &#8730;n 
If we don&#8217;t know &#963;2, we calculate the estimated standard error 
SE&#710;(X&#175;n)= &#8730;&#963;&#710;
n 
The standard error is a way of comparing the precision of estimators, and we&#8217;d obviously favor the 
estimator which has the smaller variance/standard error. 
De&#64257;nition2 If &#952;&#710;A and &#952;&#710;B are unbiased estimators for &#952;,i.e. E&#952;0 [&#952;&#710;A]= E&#952;0 [&#952;&#710;B]= &#952;0, then we say that 
&#952;&#710;A is e&#64259;cient relative to &#952;&#710;B if 
Var(&#952;&#710;B)&#8805;Var(&#952;&#710;A) 
Sometimes we look at an entire class of estimators &#920; = {&#952;&#710;1,&#952;&#710;2,...}, and we say that &#952;&#710;A is e&#64259;cient in 
that class if it has the lowest variance of all members of &#920;. 
Example2 Supposethat X and Y are scores from two di&#64256;erent Math tests. You are interested in some 
underlying &#8221;math ability&#8221;, and the two scores are noisy (and possibly correlated) measurements with 
E[X]= E[Y]= &#181;, Var(X)= X, Var(Y)= &#963;Y 2 , and Cov(X,Y)= . Instead of using only one of the &#963;2 &#963;XY 
measurements, you decide to combine them into a weighted average pX +(1&#8722;p)Y instead. What is the 
1 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; 
&#65533; 
&#65533; 
&#65533;
&#65533;expectation of this weighted average? Which value of p minimizes the variance of the weighted average?
We can interpret this as an estimation problem in which we want to estimate &#181; using a sample of only
two observations. Since all weighted averages of X and Y have mean &#181;, we&#8217;ll try to &#64257;nd the e&#64259;cient
estimator.
From the formula of the variance of a sum of random variables,
&#963;2 &#963;2Var(pX +(1 &#8722;p)Y)= p 2
X +2p(1&#8722;p)&#963;XY +(1 &#8722;p)2
Y 
In order to &#64257;nd the optimal p, we set the &#64257;rst derivative equal to zero, i.e. 
0= X +2(1 &#8722;2p)&#963;XY &#8722;2(1&#8722;p)&#963;22p&#963;2 
Y 
X +&#963;2Solvingfor p, we get, assuming that &#963;2 
Y &gt; 2&#963;XY (notice that this is also the su&#64259;cient condition for 
a local minimum) 
&#8727; &#963;Y 2 &#8722;&#963;XY Var(Y)&#8722;Cov(X,Y) Cov(Y &#8722;X,Y) p = = = &#963;2 Var(Y &#8722;X) Var(Y &#8722;X)X &#8722;2&#963;XY + &#963;2 
Y 
2 
Y &#8727; &#963;Note that if X and Y are uncorrelated, the e&#64259;cient estimator puts weight p on X whichis = 2 
X2 
Y&#963;+&#963;
greater the lower the variance of X is relative to that of Y. 
2 Methods for Constructing Estimators 
2.1 Method of Moments 
Thismethod wasproposedby theBritish statisticianKarlPearsonin1894: supposewehavetoestimate 
k parameters of a distribution. then we can look at the &#64257;rst k sample moments ofthedata, 
n
n i=1 1&#175;Xn = Xi 
n
n i=1 
. . . 1 X2 
i X2 = n 
n
n i=1 
and equatethemtothecorresponding population moments foragivenparametervalue, calculated under 
thedistribution, 1 Xk 
i Xk = n 
&#8734; 
&#181;1(&#952;)= E&#952;[Xi]&#8801; xfX(x;&#952;)dx 
&#8722;&#8734; 
. . . 
&#8734; 
&#181;k(&#952;) = E&#952;[Xik]&#8801; kfX(x&#952;)dx | x 
&#8722;&#8734; 
(1) 
2 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; 
&#65533; &#65533;
&#65533; &#65533; &#65533; 
&#65533;&#65533; &#65533; 
&#65533; 
&#65533; &#65533; 
&#65533; &#65533; Usually it is much easier to maximize the logarithm of the likelihood function, 
n
logf(yi&#952;) L(&#952;)=log(L(&#952;)) | = 
i=1 
Note that since the logarithm is a strictly increasing function, L(&#952;)and L(&#952;) will be maximized at the 
same value. 
Proposition1 The expectation of the log-likelihood under the parameter &#952;0, 
E&#952;0 [L(&#952;)]= E[logf(Y&#952;)] |
is maximized at the true parameter &#952;0. 
Proof: Since the true density over which we take the expectation is f(y&#952;0), we can show that |
E&#952;0 [L(Y|&#952;)&#8722;L(Y|&#952;0)]&#8804;0 for all values of &#952; using Jensen&#8217;s Inequality and the fact that log(&#183;)is concave 
f(Y|&#952;)&#65533;&#65533; 
&#952;0) E&#952;0 [L(Y|&#952;)&#8722;L(Y|&#952;0)] = E&#952;0 [logf(Y|&#952;)&#8722;logf(Y|&#952;0)]= E&#952;0 log f(Y|
&#8734;f(y|&#952;)&#65533;&#65533; 
=log &#65533;&#65533;f(y|&#952;) 
|&#952;0) |&#952;0)&#8804; log f(y&#952;0)dy | E&#952;0 f(y f(y&#8722;&#8734; 
&#8734; 
= log f(y&#952;)dy =log(1) =0 
&#8722;&#8734; |
since f(y|&#952;)isadensityand thereforeintegratesto1. Therefore E&#952;0 [L(Y|&#952;0)]&#8805;E&#952;0 [L(Y|&#952;)]forallvalues 
of &#952;, so that &#952;0 maximizesthefunction &#65533; 
Since by the Law of Large Numbers, the log likelihood for and i.i.d. sample 
1 n
n i=1 logf(Yi&#952;) p E[logf(Y&#952;)] |&#8594; |
n&#65533; we&#8217;d think that maximizing theloglikelihoodforalargei.i.d. sampleshould thereforegiveusaparameter 
&#8221;close&#8221; to &#952;0. 
Example5 Suppose X &#8764;N(&#181;0,&#963;02), and we want to estimate the parameters &#181; and &#963;2 from an i.i.d. 
sample X1,...,Xn. The likelihood function is 
1 &#8722;(Xi&#8722;&#181;)2 
L(&#952;) 2&#963;2 &#8730;
2&#960;&#963; = e 
i=1 
It turns out that it&#8217;s much easier to maximize the log-likelihood, 
n &#65533; 1 (Xi&#8722;&#181;)2 
&#8722;logL(&#952;) log 2&#963;2 &#8730;
2&#960;&#963; = e 
i=1 
&#65533;n21 ( ) X&#8722;&#181;i &#8730; &#8722; 22&#963; 2&#960;&#963; 
&#65533; log 
n= 
i=1 
n 1 log(2&#960;&#963;2)&#8722;2 = &#8722; 2&#963;2 (Xi &#8722;&#181;)2 
i=1 
4 </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>&#8226;	Undercertainregularity conditions,MLE&#8217;swillhave anasymptotically normaldistribution(this 
comes essentially from an application of the Central Limit Theorem) 
Is Maximum Likelihood always the best thing to do? -not necessarily 
&#8226; may bebiased 
&#8226; often hard to compute 
&#8226;	might be sensitive to incorrect assumptions on underlying distribution 
6 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>In order to &#64257;nd the maximum, we take the derivatives with respect to &#181; and &#963;2, and set them equal to 
zero: n	 n1	 1 &#65533;
Xi 0= &#65533;
2(Xi &#8722;&#181;&#710;)&#181;&#710;=
2&#963;&#65533;2 i=1 &#8660; n i=1
Similarly, 
n	 n nn 2&#960; 1	 1 &#65533; 
&#181;)2 1 &#65533; 
Xn)2+ &#65533;
(Xi &#8722;&#181;&#710;)2 &#963;2 = &#8722;22&#960;&#963;&#65533;2 2&#65533;
&#963;&#65533;2&#65533;2 
i=1 &#8660;&#65533;
n i=1 (Xi &#8722;&#710;= n i=1 (Xi &#8722; &#175; 0= 
Recall that wealready showed thatthisestimatorisnot unbiasedfor &#963;02,soingeneral,MaximumLikelihood 
Estimators need not be unbiased. 
Example6 Going back to the example with the uniform distribution, suppose X &#8764;U[0,&#952;], and we are 
interested in estimating &#952;. For the method of moments estimator, you can see that 
&#952; &#181;1(&#952;)= E&#952;[X]= 2 
so equating this with the sample mean, we obtain 
&#952;&#710;MoM =2X&#175;n 
What is the maximum likelihood estimator? Clearly, we wouldn&#8217;t pick any &#952;&#710;&#8804;max{X1,...,Xn}because 
a sample with realizations greater than &#952;&#710;has zero probability under &#952;&#710;. Formally, the likelihood is 
L(&#952;)= &#65533;&#65533;
&#952; 1 &#65533;n if0 &#8804;Xi &#8804;&#952; for all i =1,...,n 
0 otherwise 
We can see that any value of &#952; &#8804;max{X1,...,Xn}can&#8217;t be a maximum because L(&#952;)is zero for all those 
points. Also, for &#952; &#8805;max{X1,...,Xn}the likelihood function is strictly decreasing in &#952;, and therefore, 
it is maximized at 
&#952;&#710;MLE =max{X1,...,Xn} 
Note that since Xi &lt;&#952;0 with probability 1, the Maximum Likelihood estimator is also going to be less 
than &#952;0 with probability one, so it&#8217;s not unbiased. More speci&#64257;cally, the p.d.f. of X(n) isgivenby 
&#65533; 
n &#65533;
1 y &#65533;n&#8722;1 
if0 &#8804;y &#8804;&#952;0fX(n) (y)= n[FX(y)]n&#8722;1fX(y)=	 &#952;0 &#952;0 &#952;0 
0 otherwise 
so that 
&#8734;&#65533;	 &#65533;&#952;0 &#65533;y &#65533;n n E[X(n)]= yfX(n) (y)dy = n dy = &#952;0&#952;0 n +1 &#8722;&#8734; 0 
We could easily construct an unbiased estimator &#952;&#732;= n+1 X(n). n 
2.3 Properties of the MLE 
Thefollowing isjust a summary of maintheoretical results onMLE(won&#8217;tdoproofsfor now) 
&#8226; If there is an e&#64259;cient estimator in the class of consistent estimators, MLE will produce it. 
5 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec23/</lecture_pdf_url>
      <lectureno>23</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; &#65533; Setting 1&#8722;&#946; &#8805;0.99, we get the condition 
&#8730;n &#8722;1.645 &#8805;&#934;&#8722;1(0.99) =2.326 n &#8805;3.9712 &#8776;15.77 &#8660;
This type of power calculations is frequently done when planning a statistical experiment or survey 
-e.g. in order to determine how many patients to include in a drug test in order to be able to detect 
an e&#64256;ect of a certain size. Often it is very costly to treat or survey a large number of individuals, 
so we&#8217;d like to know beforehand how large the experiment should be so that we will be able to detect 
any meaningful change with su&#64259;ciently high probability. 
Example 2 Suppose we are still in the same setting as in the previous example, but didn&#8217;t know the 
variance. Instead, we have an estimate S2 =1.5. How would you perform a test? As we argued earlier, 
the statistic &#175;Xn &#8722;&#181;0T := S/&#8730;n &#8764;tn&#8722;1 
is student-t distributed with n &#8722;1 degrees of freedom if the true mean is in fact &#181;0. Therefore we reject 
H0 if 
&#175;Xn &#8722;7 T = 
S/&#8730;
10 &lt;t9(5%) 
Plugginginthevaluesfromtheproblem, T = &#8722;&#8730;
10
..
58 
/10 &#8776;&#8722;2.066,whichissmallerthan t9(0.05) = &#8722;1.83. 
Example 3 Let Xi &#8764;Bernoulli(p), i =1,2,3. I.e. we are &#64258;ipping a bent coin three times independently, 
and Xi =1 if it comes up heads, otherwise Xi =0. We want to test H0 : p = 31 
32 . against HA : p = 
Since both hypotheses are simple, can use likelihood ratio test 
&#65533;3 &#65533; 1 &#65533;Xi &#65533; 2 &#65533;1&#8722;Xi 23&#8722;P3 Xi P i=1 3 T = f0(X)= i=1 3 3 = P =23&#8722;2 i=1 Xi 
fA(X) &#65533;3 2 &#65533;Xi 1 &#65533;1&#8722;Xi 2 i3
=1 Xi 
i=1 3 3 
Therefore, we reject if 
3 
23&#8722;2 PXi &#65533;3 
i=1 &#8804;k &#8660;(3&#8722;2 Xi)log2&#8804;logk 
i=1 
which is equivalent to X&#175;3 &#8805;21 &#8722; log k . In order to determine k, let&#8217;s list the possible values of X&#175;3 and 6 log 2 
their probabilities under H0 and HA, respectively: 
&#175;X3 Prob. under H0 Prob. under HA cumul. prob. under H0 
1 1 8 1 
27 27 27 2 6 12 7 
3 27 27 27 1 12 6 19 
3 27 27 27 
0 8 1 127 27 
So if we want the size of the test equal to &#945; = 1 , we could reject if and only if X&#175;3 &gt; 2 , or equivalently 27 3 
we can pick k = 21 . The power of this test is equal to 
8&#175; 1&#8722;&#946; = P(X3 =1|HA)=27 &#8776;29.63% 
2 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533;	 &#65533; 
&#65533;Example 4 Suppose we have one single observation generated by either 
f0(x)=	2x if0 &#8804;x &#8804;1 or fA(x)= 2&#8722;2x if0 &#8804;x &#8804;1 
0 otherwise 0 otherwise 
&#8226;	Find thetestingprocedurewhich minimizesthesumof &#945;+&#946; -dowerejectif X =0.6? Since we only 
have one observation X, it&#8217;s not too complicated to write the critical region directly in terms of X, 
andthereisnothing tobegainedby trying to &#64257;nd somecleverstatistic(though of courseNeyman-
Pearson would still work here). By looking at a graph of the densities, we can convince ourselves 
that the test should reject for small values of X&lt;k for some critical level k. The probability of 
type I and type II error is, respectively, 
&#65533; k 
&#945;(k)= P(rejectH0)= 2xdx = k2 |
0 
for 0 &#8804;k &#8804;1, and 
&#65533; 1 
&#946;(k)= P(don&#8217;t reject|HA)= 
k (2&#8722;2x)dx =2(1&#8722;k)&#8722;1+k2 =1&#8722;k(2&#8722;k) 
Therefore, minimizing the sum of the error probabilities over k, 
min {&#945;(k)+&#946;(k)}=min {k2 +1 &#8722;k(2&#8722;k)}=min {2k2 +1 &#8722;2k}
k k	 k 
Setting the &#64257;rst derivative of the minimand to zero, 
1 0 =4k&#8722;2 &#8660;k =2 
Therefore we should reject if X&lt; 21 , and &#945; = &#946; = 41 . Therefore, we would in particular not reject 
H0 for X =0.6. 
&#8226;	Among all tests such that &#945; &#8804;0.1, &#64257;nd the test with the smallest &#946;. What is &#946;? Would you reject if 
X =0.4? -&#64257;rst we&#8217;ll solve &#945;(k)=0.1 for k. Using the formula from above, k&#175;= &#8730;
0.1. Therefore, 
&#946;(k&#175;)=1&#8722;2k&#175;+ k&#175;2 =1.1&#8722;2&#8730;
0.1 &#8776;46.75% 
Since k = &#8730;
0.1 &#8776;0.316 &lt; 0.4, we don&#8217;t reject H0 for X =0.4. 
Example 5 Suppose we observe an i.i.d. sample X1,...,Xn, where Xi &#8764;U[0,&#952;], and we want to test 
H0 : &#952; = &#952;0 against HA : &#952; = &#952;0,&#952; &gt; 0 
There are two options: we can either construct a 1&#8722;&#945; con&#64257;denceintervalfor &#952; and reject if it doesn&#8217;t 
cover &#952;0. Alternatively, we could construct a GLRT test statistic 
L(&#952;0)T = max&#952;&#8712;R+ L(&#952;) 
Thelikelihoodfunctionisgivenby 
n &#65533;&#65533; &#65533;n &#65533;	 1 for0 &#8804;Xi &#8804;&#952;,i =1,...,n L(&#952;)=	 fX(Xi|&#952;)= 0 &#952; 
otherwise 
i=1 
3 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 
&#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 23 
Konrad Menzel 
May 12, 2009 
Examples 
Example 1 Assume thatbabies&#8217; weights(inpounds) atbirth aredistributed according to X &#8764;N(7,1). 
Now suppose that if an obstetrician gave expecting mothers poor advice on diet, this would cause babies 
to be on average 1 pound lighter (but have same variance). For a sample of 10 live births, we observe 
&#175;X10 =6.2. 
&#8226;	How do we construct a 5% test of the null that the obstetrician is not giving bad advice against the 
alternative that he is? We have 
H0 : &#181;=7 against HA : &#181;=6 
We showed that for the normal distribution, it is optimal to base this simple test only on the sample 
&#175;	 &#175; &#175; mean, X10, so that T(x)= x&#175;10. Under H0, X10 &#8764;N(7,0.1) and under HA, X10 &#8764;N(6,0.1). The 
test rejects H0 if X&#175;10 &lt;k. We therefore have to pick k in a way that makes sure that the test has 
size5%,i.e. 
0.05 = P(X&#175;10 &lt;k|&#181;=7) =&#934; k&#8730;&#8722;
0.17 
where &#934;()is the standard normal c.d.f.. Therefore, we can obtain k by inverting this equation &#183;
1.645 k =7+&#8730;
0.01&#934;&#8722;1(0.05) &#8776;7&#8722;&#8730;
10 &#8776;6.48 
Therefore, we reject, since X&#175;10 =6.2 &lt; 6.48 = k. 
&#8226;	What is the power of this test? 
&#175;P(X10 &lt; 6.48&#181;=6) =&#934;6.48&#8722;6 &#8776;&#934;(1.518) &#8776;93.55% | &#8730;
0.1 
&#8226;	Suppose we wanted a test with power of at least 99%, what would be the minimum number n of 
newborn babies we&#8217;d have to observe? The only thing that changes with n is the variance of the 
sample mean, so from the &#64257;rst part of this example, the critical value is kn = 1.645 7&#8722;&#8730;n , whereas the 
&#175; power of a test based on Xn and critical value kn is 
&#175; 1&#8722;&#946; = P(Xn &lt;kn|&#181;=6) =&#934; &#65533;&#8730;n &#8722;1.645 
1 </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>1 
Fn(x) F(x) 
x 
Fn(x) F(x) 
x Dn Largest 
difference 
&#65533; We are interested in the inference problem in which we have a random sample X1,...,Xn from 
an unknown family of distributions and want to test whether it has been generated by a particular 
distribution with c.d.f. F(x)(e.g. F(x)=&#934;(x) for the standard normal distribution). Since there are 
no speci&#64257;c parameters for which we can do any of the tests outlined in the previous discussion, the idea 
for a test is to check whether Fn(x)does not deviate &#8221;too much&#8221; from F(x). 
2.3 The Kolmogorov-Smirnov Test 
In order to test whether an observed sample was generated by a distribution F(x), we reject for large 
values of the Kolmogorov-Smirnov statistic which is de&#64257;ned as 
Dn =sup Fn(x)&#8722;F(x)
x | | 
wheresupx F(x)denotesthesupremum,i.e. thesmallestupperbound on {F(x): x &#8712;R}-forcontinuous 
functions on compact sets, this is the same as the maximum, but since the Kolmogorov-Smirnov statistic 
involvesthe sampledistributionfunction whichhasjumps of size n1 , and the supremum is taken over the 
entire real line, it may in fact not be attained at any particular value of x. 
The critical values ofthe statistic canbe obtainedfromits  Image by MIT OpenCourseWare.
asymptotic (i.e. for large n) distribution 
function &#8734;
22 xG(Dn)= lim P(Dn &lt;x)=1&#8722;2(&#8722;1)n&#8722;1 e&#8722;2n 
n&#8594;&#8734; 
i=1 
The argument leading to this expression is not at all obvious and very technical since it involves distribu&#173;
tions overfunctions ratherthan real numbers(randomfunctions are usually called stochasticprocesses). 
6 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533;
&#65533;The denominator of T is given by the likelihood evaluated at the maximizer, which is the maximum 
likelihood estimator, &#952;&#710;MLE = X(n) =max{X1,...,Xn}, so that 
&#65533; &#65533;n 
max L(&#952;)= L(&#952;&#710;MLE)= 1 
&#952;&#8712;R+ X(n) 
Therefore, 
L(&#952;0) &#65533; X(n) &#65533;n 
T = = max&#952;&#8712;R+ L(&#952;) &#952;0 
In order to &#64257;nd the critical value k of the statistic which makes the size of the test equal to the desired 
level, we&#8217;d have to &#64257;gure out the distribution under the null &#952; = &#952;0 -could look this up in the section on 
order statistics. 
As an aside, even though we said earlier that for large n, the GLRT statistic is &#967;2-distributed under the 
null, this turns out not to be true for this particular example because the density has a discontinuity at 
the true parameter value. 
2 Other Special Tests 
2.1 Two-Sample Tests 
Suppose we have two i.i.d. samples X1,...,Xn1 and Z1,...,Zn2 ,potentially of di&#64256;erent sizes n1 and n2, 
and may be from two di&#64256;erent distributions. 
&#8764; N(&#181;X,&#963;2Xi X) 
Zi &#8764; N(&#181;Z,&#963;2 
Z) 
Two types of hypothesis tests we might want to do are 
1. H0 : &#181;X = &#181;Z against HA : &#181;X = &#181;Z, or 
0 : &#963;2 &#963;2 
A : &#963;2 &#963;22. H&#65533;
X = Z against H&#65533;
X = Z 
How should we test these hypotheses? 
1. Here, we will only consider the case in which &#963;2 and &#963;2 areknown(seethebookfor adiscussion X Z
of the other case). Under H0 : &#181;X = &#181;Z,
&#175;&#175;
T = &#65533; X &#8722;Z &#8764;N(0,1) 
&#963;2 &#963;2 
X Z+ n1 n2 
Intuitively, T shouldbelarge(in absolute value) ifthe nullis nottrue. Therefore, a size &#945; test of 
H0 against HA rejects H0 if 
|T|&gt; &#8722;&#934;&#8722;1 &#65533; &#945;&#65533; 
2 
2. For the test on the variances, need to recall distributional results: 
(n1 &#8722;1)s2 
&#8764;&#967;2 (n2 &#8722;1)s2 
&#8764;&#967;2 X Z 
&#963;2 n1&#8722;1, and &#963;2 n2&#8722;1 
X Z 
4 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>Since the calculation of the c.d.f. requires that we compute an in&#64257;nite series, using the formula is not 
straightforward. However, most statistics texts tabulate the most common critical values. 
Example 7 Suppose we toss four coins repeatedly, say 160 times and want to test at the signi&#64257;cance 
level &#945; =0.2 whether the sample was generated by a B(4,0.5) distribution. Let&#8217;s say we observed the 
following sample frequencies: 
Then the Kolmogorov-Smirnov statistic equals 
numberofheads 0 1 2 3 4 
sample frequency 10 33 61 43 13 
cumulative sample frequency Fn() 10 43 104 147 160 &#183;
cumulativefrequency under H0 F() 10 50 110 150 160 &#183;
di&#64256;erences 0 7 6 3 0 
1 7 max{0.7,6,3,0}=160 &#8776;0.044 Dn = 160 
1.07 Using the asymptotic formula from the book, C0.20 = &#8730;
160 &#8776;0.85. Since 0.44 &lt; 0.85, we don&#8217;t reject the 
null at the 20% level. 
2.4 2-Sample Kolmogorov-Smirnov Test 
Suppose we have two independent random samples, X1,...,Xm and Y1,...,Yn from unknown families of 
distributions, and we want to test whether both samples were generated by the same distribution. The 
idea is that we should test whether Fn(x)and Gn(x)are not &#8221;too far&#8221; apart. 
We can construct a test statistic 
D =sup Fn(x)&#8722;Gn(x)
x | | 
and reject the null for large values of D. A good asymptotic approximation for the critical value for a 
size &#945; testis &#65533; &#65533; &#65533; 1 1 1 &#945; reject if D &gt; &#8722;2 m + n log 2 
2.5 Pearson&#8217;s &#967; 2 Test 
Suppose each Xi from a sample of n i.i.d. observations is classi&#64257;ed into one of k categories, A1,...,Ak. 
Let p1,...,pk be the probabilities of each category, and f1,...,fk be the observed frequencies. Suppose 
we wanttotestthejointhypothesis 
H0 : p1 = &#960;1,p2 = &#960;2,...,pk = &#960;k 
against the alternative that at least two or more of these equalities don&#8217;t hold (note that since the 
probabilities have to add up to one, it can&#8217;t be that exactly one equality is violated). We can use the 
statistic 
k &#65533; (fi &#8722;n&#960;i)2 
T = n&#960;ii=1 
and reject for large values of T. In order to determine the appropriate critical value, we&#8217;d have to 
knowhow T is distributed. Unfortunately this distribution depends on the underlying model. However, 
under H0 the distribution is asymptotically independent of model, and for large samples nT &#8764;&#967;2 
k&#8722;1 
approximately. As a rule of thumb, the chi-squared approximation works well if n &#8805;4k. 
7 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>x 
321nF 
1
7 
01 
6
7 
5
7
4
7
3
7
2
7 (x) 
-1 0.5independently of another. Also recall that a ratio of independent chi-squares divided by their 
degrees of freedom is distributed F, 
(n1 &#8722;1)s 2 
&#963;2 X 
X /(n1 &#8722;1)
/(n2 &#8722;1) &#8764;Fn1&#8722;1,n2&#8722;1
 S&#65533; = (n2&#8722;1)s2 
Z 
&#963;2 
We clearly don&#8217;t know &#963;2 and &#963;2 
X = &#963;2, but under H0 : &#963;2 , this expression simpli&#64257;es to X Z Z
2 
XS&#732;= s
2sZ 
&#732; Therefore, a size &#945; test rejects if S&gt;F&#732;n1&#8722;1,n2&#8722;1(1&#8722;&#945;/2) or S&lt;Fn1&#8722;1,n2&#8722;1(&#945;/2). 
2.2 Nonparametric Inference 
So far, we have mostly considered problems where the data generating process is of form f(x&#952;)(family |
of distributions) and known up to a &#64257;nite dimensional parameter &#952;. Testing in that setting is called 
parametricinference. 
As exceptions, we noted in estimation that sample means, variances and other moments had favorable 
properties for estimation of means, variances and higher-order moments of any distribution. 
Since the entire distribution of a random variable can be characterized by its c.d.f., it may seem like a 
goodidea to estimate the c.d.f. from thedata withoutimposing any restrictions(except thatit should 
be a valid c.d.f. of course, i.e. monotone and continuous from the right). 
The sampledistributionfunction Fn(x)isgivenby Z 
jFn(x)= for X(j) &#8804;x&lt;X(j+1) n 
where X(j) is the jth order statistic(remember that thisis the jth smallest value in the sample), and 
X(0) &#8801;&#8722;&#8734;and X(n+1) &#8801;&#8734;. 
Example 6 For a sample {&#8722;1,3,1,1,.5,2,0}, the ordered sample is {&#8722;1,0,0.5,1,1,2,3}, and we can 
graph the sample distribution function Fn(x): 
5 Image by MIT OpenCourseWare.</text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec11/</lecture_pdf_url>
      <lectureno>11</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; 
&#65533; Themedianand theexpected valueof arandomvariable X coincideif thedistributionof X issymmetric 
around m(X),i.e. fX (m(X)&#8722;x)= fX (m(x)+x), but neednot be the same in general. 
Example4 Say X hasp.d.f. 
12 
fX (x)=	9 x if0 &#8804;x &#8804;3 
0 otherwise 
The expected value is 
&#65533; 3 &#65533; 3 &#65533; &#65533;31 1 1 4 81 9 t t2dt = t3dt = t= = =2.25 
0 &#183; 9 9 0 36 0 36 4 
In order to obtain the median, let&#8217;s &#64257;rst calculate the c.d.f. of X 
&#65533; x &#65533;x 31 2 1 3 x FX (x)= tdt = t= 9 27 27 0	 0 
Therefore, solving FX (m)= 21 for m gives 
27	 33 m = 2 &#8660;m = &#8730;
2 &#8776;2.38 &gt; 2.25 3
Therefore, the median of this distribution is greater than the mean. 
Note that the median may not be unique: 
Example5 Let X be the result of rolling a fair die once. Then for any number m &#8712;(3, 4], P (X&lt;m)= 
P (X &#8804;3) = 1 . Therefore any value in that interval is a median. 2 
3.2 Properties of Expectations 
Property1 If X = c, where c is a constant, then 
E[X]= c 
Property2 If Y = aX + b, then 
E[Y ]= aE[X]+b 
Proof: Let&#8217;s only look at the continuous case: if X is a continuous random variable with p.d.f. fX (x), 
then the expectation of Y isgivenby 
&#65533; &#8734;	 &#65533; &#65533; &#8734; 
E[Y ]= (ax + b)fX (x)dx = a xfX (x)dx + b fX (x)dx = aE[X]+b 1&#183; 
&#8722;&#8734;	 &#8722;&#8734; &#8722;&#8734; 
so as we can see, the linearity of integrals translates directly to linearity of expectations&#65533; 
Property3 For Y = a1X1 + a2X2 + ... + anXn + b, 
E[Y ]= a1E[X1]+a2E[X2]+... + anE[Xn]+b 
This is the most general statement of the linearity of expectations, and we will use this property over 
and over in the remainder of this class. 
6 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533; &#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; 
&#65533; 
&#65533; 
&#65533; 
&#65533; &#65533; Example6 Above, we calculated the expectation of X B(n,p), E[X]= np by summing over the &#8764;
possible outcomes of X. But from the last result we can see that there is an easier way of obtaining the 
same result: since X is the number of successes from a sequence of n trials, we can code the outcome of 
each trial as Z1,Z2,...,Zn, where Zi =1 if the ith trial was a success and Zi =0 otherwise. 
E[Zi]=1p +0 (1&#8722;p)= p &#183; &#183; 
and therefore, 
n n n 
E[X]= E Zi = E[Zi]= p = np 
i=1 i=1 i=1 
Property4 IF X and Y are independent, then 
E[XY ]= E[X]E[Y ] 
If X and Y are not independent, this will generally not be true. 
3.3 Expectations of Functions of Random Variables 
LetY = r(X). Last week,wesawhowwecouldderivethep.d.f. of Y if weknew fX (x). Forexpectations, 
this problem is much simpler since we are only looking at one single characteristic of the distribution. 
The expectation of Y = r(X)isgivenby 
r(x)fX (x) if X discrete E[Y ]= E[r(X)]= &#65533; &#8734;x 
&#8722;&#8734; r(t)fX (t)dt if X continuous 
Example7 Suppose Y = X1/2 where the p.d.f. of X isgivenby 
2x if0 &lt;x&lt; 1 fX (x)= 0 otherwise 
&#65533; 1 &#65533; 1 &#65533; &#65533;1 
5/2E[Y ]= t1/2fX (t)dt =2 t3/2dt =22 4 x = 5 50 0 0 
The same principle works for functions of 2 or more random variables 
Example8 Suppose we are interested in the function Z = X2 + Y 2 of two random variables X and Y 
withjointp.d.f. 
fXY (x,y)=1 if0 &#8804;x,y &#8804;1 
0 otherwise 
Then &#65533; &#8734; &#65533; &#8734; 
E[Z] = (x 2 + y 2)fXY (x,y)dxdy 
&#8722;&#8734; &#8722;&#8734; &#65533; 11 
= (x 2 + y 2)dxdy 
00 &#65533; 1 &#65533; &#65533;11 = x 3 + y 2 x dy 30 0 &#65533; 1 1 = + y 2 dy 30 &#65533; &#65533;111 3 112 = y + y = + = 33 3330 
7 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>0 .2 .4 .6 
1 2 3 4 5 6 7 8 9 
uniform density old units times 2 
old units times 4 
Figure 1: E&#64256;ect of a Change of Measurement Units on the Uniform 
This invariance idea may seem like a very arti&#64257;cial way of obtaining a distribution, since there is no 
obvious connection to the measurements X nor the measurement units. However, the resulting p.d.f. 
seems to give a good approximation to &#8221;real-world data&#8221; which falls into the category -as e.g. numbers 
representing measurements of some kind which appear in the New York Times. The following graph 
shows the &#8221;theoretical&#8221; density together with a histogram of the &#64257;rst digit of GDP measured in local 
currency units(i.e. YenforJapan,C$forCanada,etc.) forthe77 countriesincludedin &#8221;WorldinFigures 
2007&#8221; pocket book from The Economist. Summarizing, this example took a radically di&#64256;erent approach 0 .1 .2 .3 
1 2 3 4 5 6 7 8 9 
gdp density 
Figure2: Distribution ofFirstDigit ofGDPinLocalCurrency Units andTheoreticalDensity(Numbers 
from The Economist, Pocket World in Figures 2007) 
to determining the distribution of a given function of two random variables X and Y : here we started 
out not knowing the p.d.f.s of X and Y , but then imposed that whatever the resulting distribution was 
going to be, it had to be invariant with respect to a change of units -i.e. the realization of Y . The 
concept of &#8221;invariance&#8221; plays a major role in advanced statistics, but for the purpose of this class, we 
4 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 2 Example2 We could now think of an auction which is di&#64256;erent from the &#64257;rst one in that the buyer 
submitting the highest bid still gets to buy the painting, but only has to pay the amount o&#64256;ered by the 
second-highestbidder(thisauctionformatismorecommonthanthe &#64257;rst,andit&#8217;sknownasanEnglish, 
or second-price auction). If the submitted bids are random variables C1,...,Cn, the revenue Y of the 
seller now has p.d.f. 
fY (y)=2 nFC (y)[1&#8722;FC (y)]n&#8722;2fC (y)2 
Notice that I used di&#64256;erent letters for the bids, since it is known from economic theory that the same 
bidders should submit di&#64256;erent bids under the two di&#64256;erent auction formats. 
Digression: The Distribution of the &#8221;First Digit of Anything&#8221; 
(skippedinlecture) 
Here&#8217;s a somewhat cute but non-standard problem, for which we are not going to use the methods we 
saw earlier. So this is de&#64257;nitely something you can skip for problem sets or exam preparation, but I&#8217;d 
still like to go over it. 
What is the distribution of the &#64257;rst digit of a number we basically don&#8217;t know anything about? To 
be more precise, let X be a measurement of any kind, for which we don&#8217;t know what it represents, 
nor in what units 1 it is measured -e.g. we could leaf through a newspaper and collect any numbers Y 
representing ameasurementof somekind(incomes,stockindices,populationetc.). Whatisthep.d.f. of 
the &#64257;rst digit of a number of that kind if we don&#8217;t know anything else about where it comes from? I.e. 
how do we derive the p.d.f. of the &#64257;rst decimal of the random variable Z = XY if all we know that X &#183; 
and Y are positive, but can be anything? 
A &#64257;rstguessmightbethatthedistributionof the &#64257;rstdigitis(discrete) uniform,sincethisdistribution 
intuitively does not seem to contain much &#8221;information&#8221; about the numbers nor their units. However, if 
wetakeauniformdistributionand changetheunits(e.g. doubleorquadrupleall numbersintheassumed 
underlying distribution), the distribution of &#64257;rst digits doesn&#8217;t remain uniform. E.g. if the true numbers 
are X &#8764;U[1, 10],4X &#8764;U[0, 40], so that for the &#64257;rst digit Y of4X hasp.d.f. 
&#9127; 1 1 &#9128; 40 + 4 if y &#8712;{1, 2, 3}
fY (y)= 1 
40 if y &#8712;{4, 5, 6, 7, 8, 9}&#9129; 0 otherwise 
Or,inpictures,Soaminimal requirementforthedistributionof the &#64257;rstdigitsshouldbethatitdoesn&#8217;t
change if we change the units of measurement.
Whatwearelookingforisinfactarandomvariable X forwhich thedistributionof X doesn&#8217;tchangefor
changes of the scale, i.e. aX for a&gt; 0. This is true if we assume that Z =log(X)&#8764;U[log(1), log(10)],
since for a scale shift,
&#65533; &#65533; z z+1 &#8722;log z z +1 log a aP (z &#8804;aX &#8804;z +1) = Pa &#8804;X &#8804; a log(10a)&#8722;log(a) = 
= log(z +1) &#8722;log(z)= z +1) log(10)&#8722;log(1) P (z &#8804;X &#8804;
Then the &#64257;rst digit Y of Z has p.d.f. 
&#65533; 
fY (y)= log(z+1)&#8722;log(z) 
log(10) 
0 if y &#8712;{1, 2, 3, . . . , 9}
otherwise 
3 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; 
&#65533; 
&#65533; 
&#65533; won&#8217;t go beyond this example. 
3 Expected Values and Median 
GivenarandomvariableX with ap.d.f. fX (x),we&#8217;dliketosummarizethemostimportantcharacteristics 
of the entiredistributions withouthaving togivethe entiredensity function. The expected valuetells us 
basically where the distribution of X is centered. 
3.1 De&#64257;nitions 
De&#64257;nition1 If X is a discrete random variable, the expected value of X,denoted E[X]isgivenby 
E[X]:= xfX (x) 
x 
if this sum is &#64257;nite. If X is continuous, the expected value is de&#64257;ned as 
&#65533; &#8734; 
E[X]= xfX (x)dx 
&#8722;&#8734; 
if the integral is &#64257;nite. 
Example3 What is the expectation of a binomial random variable, i.e. X &#8764;B(n,p)? 
n &#65533;&#65533; 
E[X]= xnp x(1&#8722;p)n&#8722;x 
x 
x=0 
n 
= &#65533; 
x!(nn!
&#8722;x
x)!p x(1&#8722;p)n&#8722;x 
x=1 
n (n &#8722;1)! x&#8722;1(1&#8722;p)(n&#8722;1)&#8722;(x&#8722;1) = np p(x &#8722;1)!((n &#8722;1)&#8722;(x &#8722;1))!x=1 
n&#8722;1 &#65533; &#65533; 
n &#8722;1 = np x &#8722;1 p x(1&#8722;p)n&#8722;1&#8722;x 
x=0 
= np 1&#183; 
where in the second row, we can ignore the summand corresponding to x =0 since it&#8217;s zero, in the third 
row, we pull n out of the binomial coe&#64259;cient, and in the following step, we switch the summation index 
fromx to x&#8722;1. Finally,if wepull np out,thesummandsarethebinomialprobabilitiesfor X&#732;&#8764;B(n&#8722;1,p), 
and therefore they sum to one. 
Note that a random variable which takes in&#64257;nitely many di&#64256;erent value may not have a &#64257;nite ex&#173;
pectation, in which case the expectation is not de&#64257;ned. You should also notice that even though the 
expectationgivesasenseof the &#8221;location&#8221; of adistribution,itisingeneral nota &#8221;typical&#8221; valueforthe 
random variable: e.g. the expected value of a die roll is 1
6 (1+2+3 +4 +5+6) =321 , which is not a 
possible outcome. 
An alternative measure of the position of a distribution is the median: 
De&#64257;nition2 The median m(X)of a random variable X is a real number such that 
1 P (X&lt;m)= 2 
5 </text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>dividends it pays at any instant in time t develop according to e0.1T , i.e. there is a random growth rate
G1 which takes values 0% withprobability 90%, and 10% withprobability 10%, respectively. Alternatively,
you can hold a government bond which will e0.02t interest at every instant t in the future, i.e. G2 =2%
for sure.
You value one dollar you receive t periods from now as much as e&#8722;0.15t dollars you can have right now,
but invest in one of the two assets anyway. I.e. in general you value an asset whose returns grow at rate
g for sure as
&#65533; &#8734; 
V (g)= e(g&#8722;r)tdt =0&#8722;1 =1 
0 g &#8722;rr &#8722;g 
The expected growth rate of dividends for the risky stock is 
E[G1]=0.90%+0.110% =1% &lt; 2% = E[G2] &#183; &#183; 
However, your valuation for the stock is 
1 1 90 10 40 E[V (G1)]=0.9 +0.1 = + = =8 0.15&#8722;0 0.15&#8722;0.115 5 5 
whereas you value the bond as 
1 100 200 200 E[V (G2)]= = = &lt; = E[V (G1)] 0.15&#8722;0.02 13 26 25 
Intuitively, uncertainty over the growth rates means that even though 90% of the start-ups don&#8217;t develop 
(or even fail), the 10% which are successful do so spectacularly as to compensate for the investments 
which turn bad. Formally, the function V (g) is convex in growth rates, so that by Jensen&#8217;s inequality 
investors should value risk in growth rates -though typically not in levels. 
11 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; 
&#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; 
&#65533; 
&#65533; &#65533; Proof: Wecansplitthe experimentintotwoparts,(a) oneof the Xi&#8217;shastotakethevalue y according 
to the density fX (y), and (b) given the value y, the other draws in the sequence have to be grouped 
around y in a way that makes y the kth smallest value in the sample. 
Part(b) is abinomial experimentin which the n trials correspond to the n draws of X1,...,Xn, and we 
de&#64257;ne a &#8221;success&#8221; in the ith round astheevent(Xi &#8804;y). Since draws are independent and correspond to 
the same p.d.f. the parameter p in the binomial distribution is equal to FX (y). y being smaller or equal 
tothe kth smallest value corresponds to atleast k &#8221;successes&#8221; in the binomial experiment, and therefore 
the corresponding c.d.f. is 
n &#65533;&#65533; 
FYk (y)= n [FX (y)]l[1&#8722;FX (y)]n&#8722;l 
l 
l=k 
We can now obtain the p.d.f. by di&#64256;erentiating the c.d.f. with respect to y, using the product and the 
chain rule 
d fYk (y)= FYk (y)dy 
n &#65533;&#65533; n &#65533;&#65533; 
= nl[FX (y)]l&#8722;1[1&#8722;FX (y)]n&#8722;lfX (y)&#8722; n (n &#8722;l)[FX (y)]l[1&#8722;FX (y)]n&#8722;l&#8722;1fX (y)= T1 &#8722;T2l l 
l=k l=k 
This expression looks complicated, but it turns out to be essentially a telescopic sum, so that most 
summands will drop out. Noting that for the second term, the summand corresponding to l = n is zero, 
we can rewrite it as 
n&#8722;1 &#65533;&#65533; n &#65533; &#65533; 
T2 = n
l (n&#8722;l)[FX (y)]l[1&#8722;FX (y)]n&#8722;l&#8722;1fX (y)= l &#8722;n 
1(n&#8722;l+1)[FX (y)]l&#8722;1[1&#8722;FX (y)]n&#8722;lfX (y) 
l=k l=k+1 
replacing the running index l with l &#8722;1. Since for the &#64257;rst term, 
n n!l n! n l &#183; l = l!(n &#8722;l)! =(l &#8722;1)!(n &#8722;l +1)!(n &#8722;l +1) = l &#8722;1(n &#8722;l +1) 
The &#64257;rst term becomes 
n &#65533; &#65533; 
T1 = l &#8722;n 
1(n &#8722;l +1)[FX (y)]l&#8722;1[1&#8722;FX (y)]n&#8722;lfX (y) 
l=k 
so that the density equals the l = k term of the sum de&#64257;ning T1 since it is the only one which doesn&#8217;t 
get canceled out when we subtract T2. Therefore 
k &#65533; &#65533; 
fYk (y)= T1 &#8722;T2 = l &#8722;n 
1(n &#8722;l +1)[FX (y)]l&#8722;1[1&#8722;FX (y)]n&#8722;lfX (y) 
l=k 
= k!(n &#8722;n
k ! 
+1)!(n &#8722;k +1)[FX (y)]k&#8722;1[1&#8722;FX (y)]n&#8722;kfX (y) 
= kn [FX (y)]k&#8722;1[1&#8722;FX (y)]n&#8722;kfX (y)k 
which is the result we were going to prove &#65533;</text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>For linear functions of a random variable X ofthetype Y = aX +b, we saw above that E[aX +b]= 
aE[X]+ b. This doesn&#8217;t work for nonlinear functions of a random variable. A particulary important 
result on this is Jensen&#8217;sInequality : 
u(X) 
x 
X2 X1 E(X) E[u(X)] 
u(E[X]) 
Figure 3: Example with a discrete distribution   Image by MIT OpenCourseWare.
over{x1,x2}
Proposition2 (Jensen&#8217;s Inequality) Let X be a random variable, and u(x) be a convex function. 
Then 
E[u(X)]&#8805;u (E[X]) 
The inequality is strict if u() is strictly convex and X takes at least two di&#64256;erent values with positive &#183;
probability. 
Proof: We can de&#64257;ne a linear function 
r(x)= u(E[X])+u &#65533;(E[X])(x &#8722;E[X]) 
whichistangentto u(x)whichpassesthroughthepoint(E[X],u(E[X])). Since u()is convex, &#183;
u(x)&#8805;r(x) for all x 
Inparticular, &#65533; &#8734; &#65533; &#8734; 
E[u(X)]= u(t)fX (t)dt &#8805; r(t)fX (t)dt = E[r(X)] 
&#8722;&#8734; &#8722;&#8734; 
Since r(x) is linear by construction, we can use property 2 on expectations of linear functions with 
a = u&#65533;(E[X])and b = u(E[X])&#8722;u&#65533;(E[X])E[X]to obtain 
E[r(X)]= E[aX + b]= aE[X]+b = u &#65533;(E[X])E[X]+u(E[X])&#8722;u &#65533;(E[X])E[X]= u(E[X]) 
Putting this together with the inequality derived before, 
E[u(X)]&#8805;E[r(X)]= u(E[X]) 
which completes the proof &#65533; 
Notice that, since for a concave function v(x), its negative&#8722;v(x)is convex, Jensen&#8217;s Inequality also 
implies that for a concave function v(&#183;), 
E[v(X)]&#8804;v(E[X]) 
8 </text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>u (x) 
x 
E [x] r (x) 
&#65533; 
&#65533; &#65533; 
&#65533; &#65533; Figure4: r(x)is always less than u(x) 
Example9 (Risk Aversion): Suppose you buy a laptop for 1,200 dollars which comes with a limited 
warranty for the &#64257;rst year. During that &#64257;rst year, there is a probability p =10% that you spill a cup of 
co&#64256;ee overthelaptop(orhave a similar accident, whichis allyour ownfault) andhaveto replacethe 
entire motherboard, which will cost 1100 dollars. This repair is not covered by the limited warranty, but 
you may purchase an extended service plan for 115 dollars. Should you buy this additional &#8221;insurance&#8221;? 
Withoutthe additionalinsurance, we canthink of thetotal cost ofyourlaptop as a random variable which 
takes values X =1, 200 withprobability 1&#8722;p, and X =1, 200+1, 100 =2, 300 withprobability p (there 
are di&#64256;erent ways of setting up this problem, but let&#8217;s keep things simple for now). With the extended 
service plan, your laptop will cost you Y =1, 200+115 =1, 315 dollars for sure. 
Ifyouonly careabouttheexpected valueof thelaptop,then E[X]=2, 300p+1, 200(1&#8722;p)=1, 200+1, 100p. 
This is greater than E[Y ] =1, 315 if p &#8805;10.45%. But since we said that p =10%, would it still be a 
good idea to buy the service plan? -Economists typically assume that when people take decisions under 
uncertainty, they do not care about the expected amount of money W they can spend, but that they 
experience a utility u(W ) over a dollar amount, for which the additional value of an additional dollar 
increases in the total amount consumed. That means that we assume that u() is a concave function in &#183;
costs, say 
u(c)=4, 800&#8722;c 
where I assume that our initial wealth is 4, 800, and we can spend 4, 800&#8722;C, where C is the total &#8221;cost&#8221; 
of the laptop. Then the expected utility from not having the service plan is 
E[u(C1)]=0.94, 800&#8722;1, 200+0.14, 800&#8722;2, 300 =0.960+0.150 =59 &#183; &#183; 
whereas with the insurance plan, 
E[u(C2)]= 4, 800&#8722;1, 315 &gt; 3, 481 =59 
In fact, you would be willing to spend up to 4, 800&#8722;3, 481 = 119 dollars for the insurance, whereas the 
expected additional cost is only 1, 100p =110 dollars. This 9-dollar di&#64256;erence in what we are willing to 
pay for the insurance is referred to as the risk-premium comes from the fact that u() is concave. By &#183;
Jensen&#8217;sinequality,thisrisk-premiumispositiveif u()is concave, and wesay thatthistypeofpreferences &#183;
exhibits risk aversion. 
Example10 The following example is known as the St. Petersburg Paradox, and it gives an example 
of a random variable which doesn&#8217;t have a &#64257;nite expectation. 
We are o&#64256;ered the following gamble: suppose a fair coin is tossed over and over until the &#64257;rst head 
9 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>&#65533; 
&#65533; &#65533; appears. You get 2 dollars when heads appears on the &#64257;rst &#64258;ip, 22 dollars if it appears on the second,
and, more generally, 2k dollars if the &#64257;rst head appears on the xth &#64258;ip.
How much would you pay to play this game? -in principle, you should be willing to pay your expected
winnings, so let&#8217;s do the calculation: the probability that exactly x &#64258;ips are required equals
11 fX (x)= P (x &#8722;1tails, 1heads) = =2&#8722;x 
2x&#8722;1 2 
Therefore, expected winnings Y can be calculated as 
&#8734; &#8734; &#65533;&#65533;x &#8734; &#65533; &#65533; 2 &#65533; 
E[Y ]= 2xfX (x)=2 = 1= &#8734; 
x=1 x=1 x=1 
Therefore, there is no upper bound on expected winnings. 
Doesthismeanthatwe&#8217;d seepeoplewilling topay anin&#64257;niteamountforthistypeofbet? -certainly not: 
typically people would o&#64256;er at most around 25 dollars to play the game. This paradox can be resolved in 
di&#64256;erent ways: 
&#8226;	people do not actually care about the expected amount of money, but their valuation of money 
decreases in the total amount they already have, i.e. people maximize some concave function u()&#183;
of winnings, as in the previous example. 
&#8226;	with very smallprobabilities,theamountyouwinisextremelyhigh -i.e. inthetrillions,quadrillions 
etc. ofdollars,and wewould notbelievethatinthiscase,ouropponentcouldliveup tohispromise, 
so in fact there would be some ceiling as to how much we could at best hope to win from this bet. 
In order to make the link back to Jensen&#8217;s inequality, let&#8217;s also calculate the expected number of coin &#64258;ips 
in the game for a coin which comes up heads with probability p = a 1 : 
&#8734; &#8734; &#65533;&#65533;x&#8722;1 &#65533;&#65533; 
G&#65533; 
a a a a E[X]= &#65533; 
xa &#8722;x =1 &#65533; 1 1 1 x =: 
x=1 x=1 
where G&#65533;(a)is, as you can easily check, the &#64257;rst derivative with respect to a 1 of 
&#65533;&#65533; &#8734; &#65533;&#65533;x1 1 1 G = = a a x=1 1&#8722;a 1 
Therefore, by taking the derivative of the new expression for G &#65533; 
a 1 &#65533; 
, we get that 
1 1 11 E[X]= G&#65533; = &#65533; &#65533;2a a a 11&#8722;a 
and since in our example, 1
1 = 21 , the expected number of &#64258;ips is 2. 
Hence, the 25 dollars many people are still willing to bet are far more than 2E[X] =22 =4 dollarsyou&#8217;d 
get from the average number of &#64258;ips. The explanation for this is once more Jensen&#8217;s inequality, and the 
factthat u(x)=2x is an(extremely) convexfunction of x. 
Example11 Supposeyoucanchoosebetweentwoassets:the &#64257;rstisthestock of anobscureonlinestart&#173;
up which makes it possible for people to search web sites for free. It is very risky in that with probability 
90% dividends are constant at e0t =1, and with 10% probability, the company&#8217;s name is Google, and the 
10 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; &#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 11 
Konrad Menzel 
March 17, 2009 
OrderStatistics 
Let X1,...,Xn be independent random variables with identical p.d.f.s fX1 (x)= ... = fXn (x) -we&#8217;ll 
generally call such a sequence &#8221;independent and identically distributed&#8221;, which is typically abbreviated 
as iid. We are interested in the function 
Yn =max{X1,...,Xn} 
i.e. Yn is the largest value in the sample. 
We can derive the c.d.f. of Yn using independence 
FYn (y)= P (Yn &#8804;y)= P (X1 &#8804;y,X2 &#8804;y,...,Xn &#8804;y) 
= P (X1 &#8804;y)P (X2 &#8804;y)...P (Xn &#8804;y) 
= FX1 (y)FX2 (y)...FXn (y) 
=[FX (y)]n 
Using the chain rule, we can obtain the p.d.f. of the maximum, 
d n&#8722;1fYn (y)= FYn (y)= n [FX (y)]fX (y)dy 
Example1 An old painting is sold at an auction. n identical bidders submit their bids B1,...,Bn 
independently, and the marginal c.d.f. of the bids is FB (b). The potential buyer who submitted the 
highestbidgetstobuythepainting andhastopayhisbid(thistypeofauctioniscalledDutch,or &#64257;rst 
price auction). Then the revenue of the seller of the painting has p.d.f. is 
n&#8722;1fY (y)= fmax{B1 ,...,Bn}(y)= n [FB (y)]fB (y) 
Now we can generalize this to other ranks in the sample, e.g. 
Yn&#8722;1 = &#8221;The 2nd highest value in X1,...,Xn &#8221; 
This random variableis calledthe(n &#8722;1)th order statistic of X1,...,Xn, and we can state its p.d.f. 
Proposition1 Let X1,...,Xn be an iid sequence of random variables with p.d.f. fX (f) and c.d.f. 
FX (x). Then the kth order statistic Yk hasp.d.f. 
fYk (y)= kn [FX (y)]k&#8722;1[1&#8722;FX (y)]n&#8722;kfX (y)k 
1 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec12/</lecture_pdf_url>
      <lectureno>12</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 
&#65533; 
&#65533; and 1 30 E[X2]= ((&#8722;2)2 +02 +12 +32 +42)= =6 5 5 
Therefore, &#65533;&#65533;26 150&#8722;36 1824 Var(Y)=16 6&#8722; =16 = &#8776; 73 5 25 25 
Example4 Suppose Y &#8764; B(n,p). Since Y can be written as the sum of outcomes from n independent 
trials, 
1 with probability pY = X1 + ... + Xn,where Xi = 0 with probability 1&#8722;p 
we can calculate 
Var(Y)=Var(X1)+... +Var(Xn) 
So what is the variance of Xi? Clearly, 
E[Xi]= p 
also, 
E[Xi 2]=1&#183; p+0 &#183; (1&#8722;p)= p 
Therefore,byproperty3 
Var(Xi)= E[Xi 2]&#8722;E[Xi]2 = p&#8722;p 2 = p(1&#8722;p) 
Therefore 
n 
Var(Y)= Var(Xi)= np(1&#8722;p) 
i=1 
Since the variance is an expectation, we can directly apply results on expectations of functions of 
random variables directly to the variance of a function of random variables: if Y = r(X), 
&#65533; &#8734; &#65533;&#65533; &#8734; &#65533;2 
Var(Y)= E[Y2]&#8722;E[Y]2 = E[r(X)2]&#8722;E[r(X)]2 = r(t)2fX (t)dt&#8722; r(t)dt 
&#8722;&#8734; &#8722;&#8734; 
2.1 Higher-Order Moments 
We saw that the expected value is a measure of the location of a distribution, whereas the variance 
measuresits dispersion. We may look at other moments of the random variable in order to characterize 
its distribution, e.g. whether it&#8217;s symmetric, has fat tails etc. 
De&#64257;nition3 The r-th moment of X isgivenby 
&#181;r &#65533; = E[Xr] 
and the r-th central moment is de&#64257;ned as 
&#181;r = E[(X &#8722;E[X])r] 
4 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533; &#65533; 
&#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; 
&#65533; &#65533; 2 Variance 
The variance is a measure of the dispersion of a random variable. 
De&#64257;nition2 The variance of a random variable X isgivenby 
2Var(X)= E (X &#8722;E[X])
Sometimes we also denote the variance by &#963;2(X)=Var(X). 
Property1 Var(X)=0 if and only if P(X = c)=1 for some constant c. 
Property2 If Y = aX + b, then 
VarY = a 2Var(X) 
Proof: Again, we&#8217;ll only look at the continuous case. Using our previous results on expectations 
&#65533; &#8734; &#65533; &#8734; 
Var(Y) = (aX + b&#8722;E[aX + b])2fX (x)dx = (ax &#8722;aE[X])2fX (x)dx 
&#8722;&#8734; &#8722;&#8734; &#65533; &#8734; 
= a 2 (x &#8722;E[X])2fX (x)dx = a 2Var(X) 
&#8722;&#8734; 
It is often convenient for the measure of dispersion to have the same units as the random variable. 
However, this last result implies that the unit of Var(X)will be the square of the unit of X. Therefore, 
we often use the standarddeviation &#963;(X)instead, 
&#963;(X):= Var(X) 
Property3 
Var(X)= E[X2]&#8722;E[X]2 
Proof: 
Var(X)= E (X &#8722;E[X])2 = E X2 &#8722;2XE[X]+E[X]2 
= E[X2]&#8722;2E[X]E[X]+E[X]2 = E[X2]&#8722;E[X]2 
Property4 If Y = a1X1 + a2X2 + ... + anXn + b and X1,...,Xn are independent, then 
Var(Y)= a 2Var(X1)+a 2Var(X2)+... + a 2 Var(Xn)1 2 n
Example3 Suppose X is a discrete random variable with p.d.f. 
1 if x &#8712;{&#8722;2,0,1,3,4}fX (x)= 5 
0 otherwise 
If we de&#64257;ne Y =4X &#8722;7, what is the variance of Y? 
Var(Y)=42Var(X)=16 E[X2]&#8722;E[X]2 
We can now calculate 1 6 E[X]= (&#8722;2+0+1+3+4) = 5 5 
3 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Intuitively,themedianisbased only on ordinal propertiesof therandomvariablewhich arepreserved 
by any strictly increasing transformation. 
We also saw that expectations were linear in the sense that the expectation of a linear function of 
multiple random variables was shown to be equal to that same linear function of the expectations. For 
medians this is no longer true as the following example shows: 
Example1 Suppose X1 and X2 are discrete random variables which are from the same marginal distri&#173;
bution &#9127; 
&#9128; 0.6 if x =0 
fX (x)= 0.4 if x =1 &#9129; 0 otherwise 
and independent of each other. Then Y = X1 + X2 can take the values 0, 1, and 2, and has p.d.f. 
&#9127; 
&#9130; 0.36 if x =0 &#9130; &#9128; 0.48 if y =1 fY (y)= &#9130; 0.16 if y =2 &#9130; &#9129; 0 otherwise 
The median of X1 and X2 is zero, however median(Y)=1 &#65533;0+0 =median(X1)+median(X2). = 
More generally, the quantiles of averages may also di&#64256;er from averages of quantiles. The following 
example gives another very practical interpretation of this insight (thanks to Aleksandr Tamarkin for 
providing the following numerical example): 
Example2 Say you are taking the GRE, a standardized test which consists of three components, verbal 
X1, analytic X2, and quantitative X3. Your score is above the 90th percentile for each section of the test. 
Does this mean that you are also above the 90th percentile for the overall score? The general answer is 
no. 
Suppose, including yourself, there are 100 test takers, and the distribution of scores is as follows: 84 
test takers don&#8217;t get a single point in any section, you got 250 points in each of the three sections, and 
there are three other types of test takers, each with somewhat savant-like insular abilities in only one 
of the three areas. More speci&#64257;cally, 5 people are extremely verbally gifted and score 800 on the verbal 
part, but 0 everywhere else, another 5 get 800 on the analytic part, and yet another 5 get 800 on the 
quantitativepart,but zeroin all other sections. In sum,thejointdistribution of scoresis(note thatthis 
is very far from the typical distribution of GRE scores...) 
&#9127; 
&#9130; 0.84 (x1,x2,x3)=(0,0,0) &#9130; &#9130; &#9130; &#9130; 0.01 (x1,x2,x3)=(250,250,250)(you) &#9130; &#9128; 0.05 (x1,x2,x3)=(800,0,0) fX1 ,X2,X3 (x1,x2,x3)= &#9130; 0.05 (x1,x2,x3)=(0,800,0) &#9130; &#9130; &#9130; &#9130; 0.05 (x1,x2,x3)=(0,0,800) &#9130; &#9129; 0 otherwise 
So you are at least at the 95th percentile for each part, but for 15 other test takers, the total score 
is 800, whereas yours is only 750, so you are only at the 85th percentile with respect to the overall score 
across the three sections. 
2 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Theexpectationisthereforealsoreferredtoasthe &#64257;rstmoment of thedistributionof X,and thevariance 
asits second central moment. 
Other frequently used characteristics of a distribution are 
&#181;3 = E[(X &#8722;E[X])3] 
which is called the skewness of the distribution of X, and 
&#181;4 = E[(X &#8722;E[X])4] 
the kurtosis of X. Ahighkurtosis correspondstothedistributionhaving alot ofprobability massinthe 
tails. 
5 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; &#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 12 
Konrad Menzel 
March 19, 2009 
Properties of Medians and Percentiles 
We de&#64257;ned the median of a random variable via 
1 P(X&lt; median(X))= 2 
When X is discrete or has point masses that generate jumps in the c.d.f., this de&#64257;nition may not be 
useful, so in the more general case, we de&#64257;ne the median as 
1 median(X):= min m &#8712; R : P(X &#8804; m)&#8805; 2 
The change with respect to the narrower de&#64257;nition is that if the c.d.f. has a discontinuity which makes 
it &#8221;leap&#8221; over the value1
2,just locate the median at the point of that discontinuity. We can also de&#64257;ne 
other percentiles of the distribution of X: 
De&#64257;nition1 For a random variable X, the &#945; quantileisgivenby 
q(X,&#945;):= min{q &#8712; R : P(X &#8804; q &#8805; &#945;} 
We also call q(X,p/100) the pthpercentile. 
Note that following this de&#64257;nition, the median corresponds to the 50th percentile. Other frequently 
usedquantiles aredeciles(p=10,20,30,..., 90) andquartiles(p=25,50,75). 
Now we won&#8217;t spend as muchtime onproperties ofquantiles as wedidfor expectations,butI&#8217;djust 
liketopoint outtwoimportant waysin which the medianbehaves very di&#64256;erently fromthe expectation: 
For one, we saw from Jensen&#8217;s Inequality that for a function u(X), the expectationE[u(X)]depends 
a lot on the curvature of u(x)inthe regions wheretheprobability mass of X lies. Generally, the median 
median(u(X))will also be di&#64256;erent from u(median(X)), but there is a notable exception: 
Proposition1 Suppose u(x)is strictly increasing in the support of X. Then 
median(u(X))= u(median(X)) 
Proof: The median of X satis&#64257;es P(X&lt; median(X)) = 1
2. Since u(x) is strictly increas&#173;
ing, the event X&lt;m is identical to the event u(X) &lt;u(m) for any &#64257;xed number m. Therefore, 
P(u(X) &lt;u(median(X)) = P(X&lt; median(X)) 1
2= , so that u(median(X)) is indeed the median of 
u(X)&#65533; 
1 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec19/</lecture_pdf_url>
      <lectureno>19</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>&#65533;2.1 Important Cases 
1. &#952;&#710;is normally distributed, Var(&#952;&#710;)&#8801;&#963;2 is known: can form con&#64257;dence interval &#952;&#710;
[A(X),B(X)]= &#65533;
&#952;&#710;&#8722;&#65533;
&#963;&#952; 2
&#710;&#934;&#8722;1 &#65533;
1&#8722; &#945;&#65533; 
,&#952;&#710;+ &#65533;
&#963;&#952; 2
&#710;&#934;&#8722;1 &#65533;
1&#8722; &#945;&#65533;&#65533; 
2 2 
2. &#952;&#710;is normally distributed, Var(&#952;&#710;)unknown, but have estimator S&#710;2 =Var(&#952;&#710;): con&#64257;dence interval is 
givenby 
[A(X),B(X)]= &#65533;
&#952;&#710;&#8722;&#65533;
S&#710;2tn&#8722;1 &#65533;
1&#8722; &#945; 
2 &#65533; 
,&#952;&#710;+ &#65533;
S&#710;2tn&#8722;1 &#65533;
1&#8722; &#945; 
2 &#65533;&#65533; 
where tn&#8722;1(p)isthe pth percentile of a t-distribution with n &#8722;1 degrees of freedom. 
3. &#952;&#710;is not normal, but n&gt; 30 or so: it turns out that all estimators we&#8217;ve seen (except for the 
maximum of the sample for the uniform distribution) will be asymptotically normal by the central 
limittheorem(itisnot always straightforwardhow we applytheCLTin agiven case). So we&#8217;ll 
construct con&#64257;dence intervals the same way as in case 2. 
4. &#952;&#710;not normal, n small:if thep.d.f. of &#952;&#710;isknown,canformcon&#64257;denceintervalsfrom &#64257;rstprinciples 
(as in the last example). If the p.d.f. of &#952;&#710;is not known, there is nothing we can do. 
The reason for using the t-distribution in the second case is the following: since &#952;&#710;&#8764;N &#65533; 
&#181;, &#963;
n 2 &#65533; 
, 
&#952;&#710;&#8722;&#181; 
&#963;/&#8730;n &#8764;N(0,1) 
On the other hand, we can check that 
(n &#8722;1)S&#710;2 
&#963;2 &#8764;&#967;n2 
&#8722;1 
since in this setting, S&#710;can usually be written as a sum of squared normal residuals with mean zero and 
variance &#963;2 . Therefore, 
&#952;&#710;&#8722;&#181;&#952;&#710;&#8722;&#181; &#963;/&#8730;n N(0,1) tn&#8722;1 &#65533; 
&#710;= &#65533; 
(n&#8722;1) S&#710;2 &#8764;&#65533;
&#967;2 &#8764;
S2/n &#963;2 /&#8730;n &#8722;1 n&#8722;1 
Alsonotethatinthegeneralcase4(andinthelast exampleinvolving auniform), wedid notrequire 
that the statistic &#952;&#710;(X1,...,Xn)be an unbiased or consistent estimator of anything,butitjusthad tobe 
strictly monotonic in the true parameter. However, the way we constructed con&#64257;dence intervals for the 
normal cases(with or withoutknowledge of the variance of &#952;&#710;, the estimator has to be unbiased, and in 
case3(n large), it would have to be consistent. 
6 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>so equating this with the sample mean, we obtain 
&#952;&#710;MoM =2X&#175;n 
What is the maximum likelihood estimator? Clearly, we wouldn&#8217;t pick any &#952;&#710;&#8804;max{X1,...,Xn}because 
a sample with realizations greater than &#952;&#710;has zero probability under &#952;&#710;. Formally, the likelihood is 
&#65533;&#65533; 1 &#65533;n if0 &#8804;Xi &#8804;&#952; for all i =1,...,n L(&#952;)= &#952; 
0 otherwise 
We can see that any value of &#952; &#8804;max{X1,...,Xn}can&#8217;t be a maximum because L(&#952;)is zero for all those 
points. Also, for &#952; &#8805;max{X1,...,Xn}the likelihood function is strictly decreasing in &#952;, and therefore, 
it is maximized at 
&#952;&#710;MLE =max{X1,...,Xn} 
Note that since Xi &lt;&#952;0 with probability 1, the Maximum Likelihood estimator is also going to be less 
than &#952;0 with probability one, so it&#8217;s not unbiased. More speci&#64257;cally, the p.d.f. of X(n) isgivenby 
&#65533; 
n &#65533; 
1 y &#65533;n&#8722;1 
fX(n) (y)= n[FX(y)]n&#8722;1fX(y)= &#952;0 &#952;0 &#952;0 if0 &#8804;y &#8804;&#952;0 
0 otherwise 
so that &#65533; &#8734; &#65533; &#952;0 &#65533; y &#65533;n n E[X(n)]= 
&#8722;&#8734; yfX(n) (y)dy = 
0 n&#952;0 n +1 dy = &#952;0 
We could easily construct an unbiased estimator &#952;&#732;= n+1 X(n). n 
1.1 Properties of the MLE 
Thefollowing isjust a summary of maintheoretical results onMLE(won&#8217;tdoproofsfor now) 
&#8226;	If there is an e&#64259;cient estimator in the class of consistent estimators, MLE will produce it. 
&#8226;	Undercertainregularity conditions,MLE&#8217;swillhave anasymptotically normaldistribution(this 
comes essentially from an application of the Central Limit Theorem) 
Is Maximum Likelihood always the best thing to do? -not necessarily 
&#8226; may bebiased
&#8226; often hard to compute
&#8226;	might be sensitive to incorrect assumptions on underlying distribution 
2 Con&#64257;dence Intervals 
In order to combineinformation about the value of the estimate anditsprecision(as e.g. givenbyits 
standard error), what is often done is to report an interval around the estimate which is likely going to 
contain the actual value. 
2 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Example4 Suppose &#952;&#710;&#8764;N(&#952;0,&#963;2), and we want to construct a 1&#8722;&#945; con&#64257;dence interval. If z1&#8722;&#945;/2 is 
the 1&#8722;&#945; &#945; 
2 quantile of the standard normal distribution, i.e. &#934;(z1&#8722;&#945;/2)=1&#8722;2 , then we can check that 
CI =[&#952;&#710;&#8722;&#963;z1&#8722;&#945;/2,&#952;&#710;+ &#963;z1&#8722;&#945;/2] 
covers &#952;0 withprobability 
&#65533; 
&#710; &#710;&#65533;&#65533; 
&#952;0 &#8722;&#952;&#710;&#65533; 
P&#952;0 &#952; &#8722;&#963;z1&#8722;&#945;/2 &#8804;&#952;0&#952; + &#963;z1&#8722;&#945;/2 = P&#952;0 &#8722;z1&#8722;&#945;/2 &#8804; &#963; &#8804;z1&#8722;&#945;/2 
= &#934;(z1&#8722;&#945;/2)&#8722;&#934;(&#8722;z1&#8722;&#945;/2) 
&#945;&#945; = = 1&#8722;2 &#8722;21&#8722;&#945; 
since &#952;0
&#963; &#8722;&#952;&#710;is the standardization of &#952;&#710;, and therefore follows a standard normal distribution.
So if we want a 95% con&#64257;dence interval, z1&#8722;&#945;/2 = z0.975 =1.96, so the con&#64257;dence interval is given by
&#952;&#710;&#177;1.96&#963;.
This is the most commonly used way of obtaining con&#64257;dence intervals, so you should make sure that you
understand how this works.
Example5 Poll results are often reported with a &#8221;margin of error&#8221;. E.g. the Gallup report for April
18 1 saysthat 46% of voters would vote for Clinton over McCain, 44% would vote for McCain, and 10%
would choose neither or had no opinion. These results were based on 4,385 interviews, and the report
goes on to state that &#8221;For results based on the total sample of national adults, one can say with 95%
con&#64257;dence that the maximum margin of sampling error is 2 percentage points.&#8221;
What does this mean? -if the true vote share of a candidate is p, the variance of the average share in a
sampleof n voters would be Var( X&#175;n)= p(1
n &#8722;p) , andyoucanverify thatthisvarianceishighestfor p=0.5.
&#175;&#65533; 
0.5&#183;0.5So for a sample of 4,385 interviewees, the maximal standard deviation is &#65533;
Var( Xn)&#8804; 4385 &#8776;0.76%. 
By theCentralLimitTheorem, X&#175;n is approximately normally distributed, and we already saw that for a 
normaldistribution,95% of theprobability massiswithin1.96 standarddeviationsof themean. Therefore 
&#175; &#175; theinterval [Xn &#8722;1.960.76%,Xn &#8722;1.960.76%] will cover the true vote share with probability greater &#183; &#183; 
than 95%. For smaller subgroups of voters, the margin of error becomes larger. 
Example6 A lab carries out a chemical analysis on blood to be used as evidence in a trial. To be 
acceptable as evidence, a 90% con&#64257;dence interval for the amount of some substance should have length 
less than 0.001g/ml. The machine used for the analysis gives readings which are normally distributed 
around the true value with standard deviation &#963; =0.005g/ml. How many readings do we need in order 
to make sure that the 90% con&#64257;dence interval is shorter than 0.001g/ml? 
The width of a 90% CIis 
&#963; 0.005 0.01645 l =2&#8730;n &#934;&#8722;1(0.95) &#8776;2 &#8730;n 1.645 = &#8730;n 
Therefore, in order for l &#8804;0.001, we need n &#8805;16.452 =270.6025, so we&#8217;d need atleast271(independent) 
readings. 
The following example illustrates one way of constructing a con&#64257;dence interval when the distribution 
of the estimator is not normal. 
1http://www.gallup.com/poll/106630/Gallulp-Daily-Clinton-Moves-Within-Points-Obama.aspx 
4 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Example3 Supposethe captain of aNavygunboathasto establish abeachhead on a stretch of shoreline, 
but &#64257;rst has to make sure that a battery on the beach -which can&#8217;t be seen directly from the sea -is 
destroyed, or at least severely damaged. 
The boat already took some &#64257;re from the coast, and based on the direction the projectiles came from, the 
captain has an estimate &#952;&#710;of the position of the battery, which is normally distributed with variance &#963;&#946; 2 
around the true position &#952;0. 
The captain can &#64257;re a volley of missiles on a range of the beach, making sure that everything in that 
range gets destroyed. How can the captain determine what range of the shore to &#64257;re at so that he can be 
95% sure that the battery will be destroyed so that it will be safe to land troops? 
Shoreline Actual position of battery Estimated position of battery 
CI "estimated f( &#952;)"  f(&#952;)
 (&#952;) + 1.96&#963;  (&#952;) + 1.96&#963; (&#952;) &#952;0 
For the normal distribution, we know that 95% of the probability mass     Image by MIT OpenCourseWare.
is within 1.96 standard devia&#173;
tions on either side of the mean. So if the captain orders to &#64257;re at the range CI = [&#952;&#710;&#8722;1.96&#963;,&#952;&#710;+1.96&#963;], 
the probability that &#952;&#710;will be such that &#952;0 &#8712;CI equals95%. 
Sowhileearlieronwewereonlylookingforasinglefunction &#952;&#710;(X1,...,Xn)whichgivesavaluecloseto 
theactualparametervalue &#952;0,wewill nowtrytoconstructtwofunctions A(X1,...,Xn)&lt;B(X1,...,Xn) 
such that the two functions enclose the true parameter with probability greater or equal to some pre&#173;
speci&#64257;edlevel. 
De&#64257;nition1 A1&#8722;&#945; con&#64257;denceintervalfortheparameter &#952;0 isaninterval [A(X1,...,Xn),B(X1,...,Xn)] 
depending on two data-dependent functions A()and B()such that &#183; &#183;
P&#952;0 (A(X1,...,Xn)&#8804;&#952;0 &#8804;B(X1,...,Xn))=1&#8722;&#945;
Typically, these functions are not unique, but by convention, we choose A and B suchthat &#945; 
2 proba&#173;
bility falls on each side of the interval. 
For a realization of the con&#64257;dence interval, [A(x1,...,xn),B(x1,...,xn)], it doesn&#8217;t make sense to 
say that P(A(x1,...,xn)&#8804;&#952;0 &#8804;B(x1,...,xn))=1&#8722;&#945;, since now both the limits of the interval and 
the true parameter are just real numbers, so given a realization of the sample, the estimated interval 
eithercovers &#952;0 (withprobability1,ifyouwill),oritdoesn&#8217;t. Weshouldbeclearthatitisthecon&#64257;dence 
interval(i.e. thefunctions A()and B())which are random given the true parameter, not &#952;0. &#183; &#183;
The following is the most common case for which we&#8217;d like to construct a con&#64257;dence interval. 
3 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533;Example7 Suppose X1,...,Xn are i.i.d. with Xi &#8764;U[0,&#952;], and we want to construct a 90% con&#64257;dence 
intervalfor &#952;0. Let 
&#952;&#710;= max{X1,...,Xn}= X(n) 
the nth order statistic (as we showed last time, this is also the maximum-likelihood estimator). Even 
though, as we saw, &#952;&#710;is not unbiased for &#952;, we can use it to construct a con&#64257;dence interval for &#952;. 
From results for order statistics, we saw that the c.d.f. of &#952;&#710;is given by the c.d.f. of &#952;&#710;isgivenby 
&#9127;
0&#9130;&#65533;n &#952; &#8804;0 &#9128;&#65533; 
&#952;F&#952;&#710;(&#952;)= if0 &lt;&#952; &#8804;&#952;0 &#9130;&#9129; 1 &#952;0 
if &#952;&gt;&#952;0 
where we plugged in the c.d.f. of a U[0,&#952;0]random variable, F(x)= &#952;x 
0 .
In order to obtain the functions for A and B, let us &#64257;rst &#64257;nd constants a and b such that
P&#952;0 (a &#8804;&#952;&#710;&#8804;b)= F&#952;&#710;(b)&#8722;F&#952;&#710;(b)=0.95&#8722;0.05 =0.9 
We can &#64257;nd a and b by solving 
F&#952;&#710;(a)=0.05 and F&#952;&#710;(b)=0.95 
n nso that we obtain a = &#8730;
0.05&#952;0 and b = &#8730;
0.95&#952;0. This doesn&#8217;t give us a con&#64257;dence interval yet, since 
looking at the de&#64257;nition of a CI, we want the true parameter &#952;0 in the middle of the inequalities, and the 
functions on either side depend only on the data and other known quantities. 
However, we can rewrite 
&#65533; 
n&#65533;&#65533; 
&#952;&#710; &#952;&#710;&#65533; 
0.9= P&#952;0 &#710; = P&#952;0 &#8730;
0.05&#952;0 &#8804;&#710;&#8730;
0.95&#952;0 = P&#952;0 &#8730;
0.95 &#8804;&#952;0 &#8804;&#8730;
0.05 (a &#8804;&#952; &#8804;b) &#952; &#8804; n
n n
Therefore 
&#65533; max{X1,...,Xn} max{X1,...,Xn}&#65533; 
[A,B]=[A(X1,...,Xn),B(X1,...,Xn)]= n, n&#8730;
0.95 &#8730;
0.05 
is a 90% con&#64257;dence interval for &#952;0. Notice that in this case, the bounds of the con&#64257;dence intervals depend 
on the data only through the estimator &#952;&#710;(X1,...,Xn). This need not be true in general. 
Let&#8217;s recap how we arrived at the con&#64257;dence interval: 
1. &#64257;rst get estimator &#952;&#710;(X1,...,Xn)and the distribution of &#952;&#710;. 
2. &#64257;nd a(&#952;),b(&#952;)such that
P(a(&#952;)&#8804;&#952;&#710;&#8804;b(&#952;))=1&#8722;&#945;
3. rewrite the event by solving for &#952; 
P(A(X)&#8804;&#952; &#8804;B(X))=1&#8722;&#945; 
4. evaluate A(X),B(X)for the observed sample X1,...,Xn 
5. the1 &#8722;&#945; con&#64257;denceintervalisthengivenby 
CI =[A(X1,...,Xn),B(X1,...,Xn)] 
5 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 19 
Konrad Menzel 
April 28, 2009 
Maximum Likelihood Estimation: Further Examples 
Example1 Suppose X &#8764;N(&#181;0,&#963;02), and we want to estimate the parameters &#181; and &#963;2 from an i.i.d. 
sample X1,...,Xn. The likelihood function is 
n&#65533; 1 (Xi&#8722;&#181;)2 
L(&#952;)= e&#8722; 2&#963;2 &#8730;
2&#960;&#963; i=1 
It turns out that it&#8217;s much easier to maximize the log-likelihood, 
n&#65533; 
(Xi&#8722;&#181;)2 &#65533; 
logL(&#952;)= &#65533; 
log &#8730;
21 
&#960;&#963; e&#8722; 2&#963;2 
i=1 
n
= &#65533;&#65533; 
log 1 (Xi &#8722;&#181;)2 &#65533; 
&#8730;
2&#960;&#963; &#8722; 2&#963;2 
i=1 
n
= &#8722; n 
2log(2&#960;&#963;2)&#8722; 1 &#65533;
(Xi &#8722;&#181;)2 
2&#963;2 
i=1 
In order to &#64257;nd the maximum, we take the derivatives with respect to &#181; and &#963;2, and set them equal to 
zero: n n1 &#65533; 1 &#65533;
0= 
2&#963;&#65533;2 i=1 2(Xi &#8722;&#181;&#710;)&#8660;&#181;&#710;= n i=1 Xi 
Similarly, 
n n nn 2&#960; 1 &#65533; 1 &#65533; 1 &#65533; &#175; 0= &#8722;22&#960;&#963;&#65533;2 +
2&#65533;
&#963;&#65533;2&#65533;2 
i=1 (Xi &#8722;&#181;&#710;)2 &#8660;&#963;&#65533;2 = n i=1 (Xi &#8722;&#181;&#710;)2 = n i=1 (Xi &#8722;Xn)2 
Recall that wealready showed thatthisestimatorisnot unbiasedfor &#963;02,soingeneral,MaximumLikelihood 
Estimators need not be unbiased. 
Example2 Going back to the example with the uniform distribution, suppose X &#8764;U[0,&#952;], and we are 
interested in estimating &#952;. For the method of moments estimator, you can see that 
&#952; &#181;1(&#952;)= E&#952;[X]= 2 
1 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec16/</lecture_pdf_url>
      <lectureno>16</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>&#65533; 3. for 2 or more random variables, 
E[a1X1 + ... + anXn + b]= a1E[X1]+... + anE[Xn]+b 
4. if X and Y are independent,then
E[XY]= E[X]E[Y]
&#8226; expectation is measure of location of distribution of X. 
&#8226; expectation of function Y = u(X)(discrete case: replace integralwith sum) 
&#8734; 
E[Y]= u(x)fX(x)dx 
&#8722;&#8734; 
&#8226;	Jensen&#8217;s Inequality: if u(&#183;)is convex,then
E[u(X)]&#8805;u(E[X])
2.2.2 Variance 
De&#64257;ned as 
Var(X)= E &#65533; 
(X &#8722;E[X])2&#65533; 
Measure of dispersion of X. 
Important properties of variances 
1. for a constant a,
Var(a)=0
2. can write variance as
Var(X)= E[X2]&#8722;E[X]2
3. for a linear function of independent random variables X1,...,Xn, 
Var(a1X1 + ... + anXn + b)= a12Var(X1)+... + an2 Var(Xn)+b 
4. more generally for any random variables X1,X2, 
Var(a1X1 + a2X2)= a 2
1Var(X1)+2a1a2Cov(X1,X2)+a 2
2Var(X2) 
2.2.3 Covariance and Correlation 
Covariance de&#64257;ned as 
Cov(X,Y)= E[(Y &#8722;E[Y])(X &#8722;E[X])] 
Properties of covariances 
Cov(X,X) = Var(X) 
Cov(X,Y) = Cov(Y,X) 
Cov(X,Y)= E[XY]&#8722;E[X]E[Y] 
Cov(aX + b,cY + d)= acCov(X,Y) 
3 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; 
&#65533; &#65533; 
&#65533; &#65533; 
&#65533; 
&#65533; &#65533; 
&#65533; 
&#65533; 2. 2-step method if X continuous: Step 1: obtain c.d.f. FY (y) 
FY (y)= P(u(X)&#8804;y)= fX(x)dx 
{x:u(x)&#8804;y} 
Step 2: di&#64256;erentiate c.d.f. in order to obtain p.d.f.: 
d fY (y)= FY (y)dy 
3. changeof variablesformulaif(a) X continuous, and(b) u()is one-to-one: &#183;
&#65533; d &#65533; 
fY (y)= fX(s(y)) s(y) &#65533; dy &#65533; 
A few important examples which we discussed were: 
&#8226;	Convolution Formula: if X and Y areindependent,then Z = X + Y hasp.d.f. 
&#8734; 
fZ(z)= fY (z &#8722;w)fX(w)dw 
&#8722;&#8734; 
Note: if densities of X and/or Y are zero somewhere, be careful with integration limits! 
&#8226;	Integral Transformation: if X continuous, then the random variable Y = FX(X), where FX(&#183;)is 
the c.d.f. of X is uniformly distributed. 
&#8226;	Order Statistics: if X1,...,Xn i.i.d.,then kth lowest value Yk hasp.d.f. 
fYk(y)= k nFX(y)k&#8722;1 (1&#8722;FX(y))n&#8722;k fX(y)k 
2.2 Expectations 
2.2.1 Expectation 
De&#64257;nition of expectation of X 
&#8226;	if X discrete, 
E[X]= xfX(x) 
x 
&#8226;	if X continuous, 
&#8734; 
E[X]= xfX(x)dx 
&#8722;&#8734; 
Important properties of expectations 
1. for constant a,
E[a]= a
2. for linear function of X, Y = aX + b,
E[Y]= aE[X]+b
2 </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; &#175;&#65533; 
&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 3 2.4.3 Central Limit Theorem 
&#8226; look at distribution of standardized sample mean 
&#8226; Central Limit Theorem: for an i.i.d. sample with Var(Xi)&lt; &#8734;, 
lim P &#8730;nXn 
&#963; &#8722;&#181; &#8804;x =&#934;(x) 
n&#8594;&#8734; 
where&#934;()isthe normal c.d.f. &#183;
&#8226; saw graphs illustrating the DeMoivre-Laplace theorem for binomial random variables. 
Sample Problems 
Example 1 Spring 2003 Exam, Problem 3 
Mr Bayson, a third grade teacher in the Baldwin School in Cambridge is up for promotion, and the 
likelihood of it happening will depend in part on his students&#8217; performance on the MCAS exam. He has 
ten students and the exam will have ten questions on it. Suppose that each student has a 60% chance 
of correctly answering each questions, and that answers on all questions are independent. What is the 
probability that his top scoring student scores at least nine out of ten? What is the probability that his 
bottom-scoring student scores at least three out of ten? 
Answer:
You should notice that this question has two parts: (1) determining the distribution of individual test
scores,and(2) &#64257;nding thec.d.f.softhemaximumandtheminimum.
Sinceeach student&#8217;sexamscore X isthenumberof successesout of10independenttrials,itisabinomial
random variable, X &#8764;B(10,0.6), for which we know the p.d.f.
&#9127; 
&#9128; 10 0.6x0.410&#8722;x if x &#8712;{0,1,..., 10}fX(x)= x &#9129; 0 otherwise 
In general, the maximum Y1 of an i.i.d. sample X1,...,Xn where the c.d.f. of Xi is FX(x)has c.d.f. 
FY1 (y)= FX(y)n 
and the minimum Y2 has c.d.f. 
FY2 (y)=1&#8722;(1&#8722;FX(y))n 
The probability that a given student scores less than 9 is 
FX(9) =1&#8722;P(X =9)&#8722;P(X =10) =1&#8722; 10 0.690.4+ 10 0.610 
9 10 
239 310 23 =1&#8722;10&#183; 5&#183; 
10 +510 =1&#8722; 5 &#183; 0.69 
Therefore, the probability that the top student scores at least 9 out of 10 is 
&#65533; &#65533;10 
1&#8722;FY1 (9)=1&#8722;[FX(9)]10 =1&#8722; 1&#8722; 23 0.69 &#8776;37.79% 5 
6 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; 
&#65533; 
&#65533; &#65533; 
&#65533; If X and Y areindependent,Cov(X,Y)=0. 
Correlation coe&#64259;cient de&#64257;ned as 
Cov(X,Y)&#65533;(X,Y)= &#65533; 
Var(X)Var(Y) 
&#65533;(X&lt;Y)&#8712;[&#8722;1,1], and |&#65533;(X,Y)|=1 if and only if Y is a deterministic linear function of X. 
2.2.4 Conditional Expectation 
Conditional expectation random variable de&#64257;nedby 
&#8734; 
E[YX]= yfY|X(yX)dy |
&#8722;&#8734; |
Two important results on conditional expectations: 
&#8226;	Law of Iterated Expectations
E[E[YX]]= E[Y]
 |
ConditionalVariance &#8226; 
Var(Y)=Var(E[YX])+E[Var(YX)] | |
2.3 Special Distributions 
2.3.1 Summary 
Lookedfollowing distributions 
&#8226; Uniform: X &#8764;U[a,b]if p.d.f. of X is 
fX(x)=	b&#8722;1 
a if a &#8804;x &#8804;b 
0 otherwise 
&#8226; Binomial: X &#8764;B(n,p)if p.d.f. of X is 
&#9127; 
fX(x)= &#9128; n
x px(1&#8722;p)n&#8722;x if x &#8712;{0,1,...,n} 
&#9129; 0	 otherwise 
&#8226; Exponential: X &#8764;E(&#955;)if X hasp.d.f. 
&#955;e&#8722;&#955;x if x &#8805;0 fX(x)= 0 otherwise 
Normal: X &#8764;N(&#181;,&#963;2)if p.d.f. is &#8226; 
1 (x&#8722;&#181;)2 
fX(x)= e&#8722;2&#963;2 &#8730;
2&#960;&#963; 
&#8226; Poisson:	X &#8764;P(&#955;)if p.d.f. is 
&#65533; &#8722;&#955; 
fX(x)=	&#955;x 
xe 
! if x &#8712;{0,1,2,...}
0 otherwise 
Should know or be able to calculate mean and variance for each distribution. Also showed relationships 
between Binomial and Poisson, and Binomial and Normal. 
4 </text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>groups. To do so, he constructed a model of &#64257;ghts and injuries where the number of chance meetings 
between two rival groups in a season follows a P(5)(Poisson with &#955; =5) distribution. Furthermore, he 
assumed that at least one injury occurs in every &#64257;ght and that, in fact, any number of injuries up to ten 
are all equally likely. 
(a) Given those assumptions, what is the expected number of injuries that two rival groups in&#64258;ict on 
each other in a given year? What is the variance of that quantity? 
(b) Suppose instead that a &#64257;ght only happened with probability one-half when a chance meeting of two 
rivalgroups occurred(you may assumeindependence of chance meetings). How wouldyour answers 
topart(a) change? 
Answer: 
(a) Let us use X to refer to the number of &#64257;ghts in a season and Y to refer to the number of in&#173;
juries. Here we&#8217;ll assume that a chance meeting necessarily results in a &#64257;ght. We have E(Y)= 
E(E(YX)) = E(5.5X) =5.5E(X) =5.5(5) = 27.5. And we have Var(Y)= E(Var(YX))+ |
E(102 |
Var(E(Y|X))= &#8722;1 X)+Var(5.5X). [Note that the variance of the number of injuries in a 12 
&#64257;ghtis 102 &#8722;1 , and thus the variance of the number of injuries in X &#64257;ghtsis 102 &#8722;1 X if thedistribu&#173;12 12 
tionofinjuriesisindependent across&#64257;ghts.] Continuing along,wehave E(102 &#8722;1 X)+Var(5.5X)= 12 99 121 99 121 E(X)+Var(X)= (5)+(5)=192.5.12 4 12 4 
(b) Let us use Z to refer to the number of chance encounters. We have E(Y)= E(E(E(YX)Z))= ||
E(E(5.5XZ))= E(5.5(E(XZ)))= E(5.521 Z)=2.75E(Z)=2.75(5) = 13.75. For the variance, | |
99 E(X)+121 Var(X), but now we can still say that Var(Y)= E(Var(Y|X))+Var(E(Y|X))= 12 4 
E(X) and Var(X) will have changed from part a. It is not hard to see that E(X) is half of 
its previous value (so that now it is 2.5), and we can use the fact that XZ is a binomial with |
p = .5 and Z trials to write the variance of X as Var(X)= E(Var(XZ))+ Var(E(XZ)) = | |
E(Z(.5)(1&#8722;.5))+Var(.5Z)= .25E(Z)+.25Var(Z)= .25(5)+ .25(5) = 2.5. So going back, we 
99 121 99 121 have Var(Y)= 12 4 12 4E(X)+Var(X)= (2.5)+ (2.5) =96.25. 
8 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533; &#65533; 25 The probability that a given student scores at least 3 out of 10 is 
1&#8722;FX(2)=1&#8722;P(X =0)&#8722;P(X =1)&#8722;P(X =2) =1&#8722;0.410&#8722;100.60.49 &#8722;450.62 0.48 =1&#8722; 1876 0.48 &#183;&#183; &#183;&#183;
Therefore, the probability that the bottom student scores at least 3 out of ten is 
1&#8722;FY (2)=[1&#8722;FX(2)]10 &#8776;60.39% 
Example 2 Spring 2007 Exam, Problem 3 
If X &#8764;N(&#181;,&#963;2), we say that Y = eX has a lognormal distribution, Y &#8764;L(&#181;,&#963;2). 
(a) Find the p.d.f. of Y 
(b) Suppose you have $100,000 to invest and you have access to an investment whose return R1 is 
distributed L(&#181;,&#963;2). Its mean e&#181;+&#963;2/2 is 1.10, and its variance e2(&#181;+&#963;2) e2&#181;+&#963;2 is 0.01. What &#8722;
is the probability that your wealth at the end of one period of investment ($100,000R1)isgreater 
than 110,000? 
(c) With the sameparameter values asin(b), whatistheprobability thatyour wealth atthe end of two 
independent periods of investment is greater than $115,000? 
Answer: 
(a) Thistransformationisone-to-one,sowecanusethechangeofvariablesformula. NotethatX canbe 
any real number,sothesupport of Y is(0,&#8734;). Theinversetransformationis X =ln(Y),whichhas 
dX 1 . Thus, using the change of variables formula, we have fY (y)= 11 exp(&#8722;1 (ln(y)&#8722;&#181;)2)dY = X y &#8730;
2&#960;&#963; 2 &#963; 
for y&gt; 0 and fY (y)=0 otherwise. 
(b) It is useful to begin by solving for &#181; and &#963;2 . We can factor the expression for the variance as 
e2&#181;+&#963;2 (e&#963;2 &#8722;1), or[e&#181;+ 21 &#963;2 &#963;2 ]2(e&#8722;1). Plugging in from the expression for the mean and using the 
fact that the variance is .01, wehave(1.10)2(e&#963;2 &#8722;1) = .01. Solvingfor &#963; yields &#963; &#8776;.090722098. 
We can then go back and see that &#181; &#8776;.09119493. 
Now let&#8217;s &#64257;nd out the probability that your wealth at the end of one period is greater than 
$110,000. We have P(100000R1 &gt; 110000) = P(R1 &gt; 1.1) = P(ln(R1)&gt; ln(1.1)) = P(ln(R
&#963; 1)&#8722;&#181; &gt; 
ln(1.
&#963; 1)&#8722;&#181;) =1 &#8722;&#934;(ln(1.
&#963; 1)&#8722;&#181;) &#8776;1 &#8722;&#934;(.045361051) &#8776;1 &#8722;.5181 = .4819, where you can use the 
normal probability tables to get the value of the standard normal c.d.f. 
(c) P(100000R1R2 &gt; 115000) = P(R1R2 &gt; 1.15) = P(ln(R1)+ln(R2) &gt; ln(1.15)). Note that 
ln(R1) and ln(R2) are independent normals, and so their sum is also normal. The mean is the 
sum of the means and the variance is the sum of the variances. Using tildes to refer to the new 
mean, variance, and standard deviation here, we thus have &#732;.18238986, &#732;&#963;2 .016460998, and &#181; &#8776; &#8776;
&#963;&#732;&#8776;.128300421. So continuing along with the earlier calculation, we have P(ln(R1)+ln(R2) &gt; 
ln(1.15)) = P(ln(R1)+ln(R2)&#8722;&#181;&#732;&gt; ln(1.15)&#8722;&#181;&#732;)=1&#8722;&#934;(ln(1.15)&#8722;&#181;&#732;)&#8776;1&#8722;&#934;(&#8722;.3322508) &#8776;1&#8722;.3698 = &#963;&#732; &#963;&#732; &#963;&#732;
.6302. 
Example 3 Spring 2007 Exam, Problem 4 
Mikael Priks, a Swedish economist, has been studying various economic issues surrounding soccer hooli&#173;
ganism using detailed data on hooligan activity, &#64257;ghts, injuries, etc., collected by the Swedish police and 
self-reportedby oneof thegangs,the &#8221;FirmanBoys&#8221; (seewww.lrz-muenchen.de/ces/mikael.htm). Inone 
paper he sought to analyze the determinants of the likelihood and severity of &#64257;ghts between rival hooligan 
7 </text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>&#65533; &#65533; Sample Problems 
Spring 2003 Exam, Problem 3 Mr Bayson, a third grade teacher in the Baldwin School in Cam&#173;
bridge is up for promotion, and the likelihood of it happening will depend in part on his students&#8217; 
performance on the MCAS exam. He has ten students and the exam will have ten questions on it. Sup&#173;
pose that each student has a 60% chance of correctly answering each questions, and that answers on all 
questions are independent. What is the probability that his top scoring student scores at least nine out 
of ten? What is the probability that his bottom-scoring student scores at least three out of ten? 
Spring 2007 Exam, Problem 3 If X &#8764;N(&#181;,&#963;2), we saythat Y = eX has a lognormal distribution, 
Y &#8764;L(&#181;,&#963;2). 
(a) Find the p.d.f. of Y 
(b) Suppose you have $100,000 to invest and you have access to an investment whose return R1 is 
distributed L(&#181;,&#963;2). Its mean e&#181;+&#963;2 /2 is 1.10, and its variance e2(&#181;+&#963;2) &#8722;e2&#181;+&#963;2 is 0.01. What 
istheprobability thatyour wealth atthe end of oneperiod ofinvestment($100,000R1)isgreater 
than110,000? 
(c) Withthe sameparameter values asin(b), whatis theprobability thatyour wealth at the end of 
two independent periods of investment is greater than $115,000? 
Spring 2007 Exam, Problem 4 Mikael Priks, a Swedish economist, has been studying various eco&#173;
nomicissuessurrounding soccerhooliganismusingdetaileddataonhooliganactivity, &#64257;ghts,injuries,etc., 
collectedby theSwedishpoliceand self-reportedby oneofthegangs,the &#8221;FirmanBoys&#8221; (seewww.lrz&#173;
muenchen.de/ces/mikael.htm). In onepaperhe soughtto analyzethedeterminants of thelikelihood and 
severity of &#64257;ghts between rival hooligan groups. To do so, he constructed a model of &#64257;ghts and injuries 
where the number of chance meetings between two rival groups in a season follows a P(5)(Poisson with 
&#955; = 5) distribution. Furthermore, he assumed that at least one injury occurs in every &#64257;ght and that, in 
fact, any number of injuries up to ten are all equally likely. 
(a) Given those assumptions, what is the expected number of injuries that two rival groups in&#64258;ict on 
each other in a given year? What is the variance of that quantity? 
(b) Suppose instead that a &#64257;ght only happened with probability one-half when a chance meeting of 
tworivalgroups occurred(you may assumeindependence of chance meetings). How wouldyour 
answerstopart(a) change? 
9 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; 2.3.2 Normal Distribution 
Should know how to standardize random variables: 
X &#8722;E[X]Z = &#65533; 
Var(X) 
I will give you a copy of the tabulated c.d.f. of the standard normal, so should know how to read the 
tables. 
Important results on normal distribution: 
1. normal p.d.f. is symmetric about the mean 
2. linear functions of normal random variables are again normally distributed: if X &#8764;N(&#181;,&#963;2),then 
Y = aX + b &#8764;N(a&#181; + b,a2&#963;2). 
3. sums of independent normal random variables are normally distributed 
4. Central Limit Theorem: standardized sample mean for i.i.d. sample X1,...,Xn approximately 
follows a standard normal distribution for large n. 
2.4 Asymptotic Theory 
2.4.1 General Idea 
&#8226; always assume i.i.d. sample X1,...,Xn
&#8226; only deal with sample mean
n 1&#175;Xn = Xi n i=1 
&#8226;	exact value/distribution often hard or even impossible to derive given our knowledge about distri&#173;
bution of Xi 
&#8226;	thought experiment &#8221;n &#8594;&#8734;&#8221; supposed to give approximations forlarge n 
2.4.2 Law of Large Numbers 
&#8226;	Chebyshev&#8217;s Inequality: for any &#949;&gt; 0,
Var(X)
P(|X &#8722;E[X]|&gt;&#949;)&#8804; &#949;2 
&#8226;	Law of Large Numbers: if Xi,...,Xn i.i.d., then for all &#949;&gt; 0
&#175;
 lim P(|Xn &#8722;E[X]|&gt;&#949;)=0 
n&#8594;&#8734; 
&#8226;	independenceassumptionimportant(e.g. correlated eventin &#8221;wisdomof crowds&#8221; example. 
&#8226;	needVar(Xi)&lt; &#8734;, so LLN doesn&#8217;t work with very fat tailed distributions. 
5 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 16 
Konrad Menzel
April 9, 2009
1 General Exam Policies 
&#8226;	Exam 2 will be in class next Tuesday, April 14, starting at 9:00 sharp 
&#8226;	relevant material: in &#64257;rst place topics we covered since last exam, but of course should feel com&#173;
fortable with densities, probabilities and other concepts from the &#64257;rst third of the semester 
&#8226;	more text problems than on problem sets, but less tedious calculations 
&#8226;	will hand out normal probability tables with exam, so don&#8217;t have to bring your own 
&#8226;	essentially same format as in &#64257;rst exam 
&#8226;	bring calculators 
&#8226;	closed books, closed notes
have about 85 minutes to do exam
 &#8226; 
&#8226;	I&#8217;ll give partial credit, so try to get started with all problems 
2 Review 
2.1 Functions of Random Variables 
General set-up: 
&#8226;	know p.d.f. of X, fX(x)(discrete or continuous) 
&#8226;	Y is a known function of X, Y = u(X) 
&#8226;	interested in &#64257;nding p.d.f. fY (y) 
Thewayhowweobtainthep.d.f. fY (y)dependsonwhetherX iscontinuousordiscrete,and whether 
thefunction u()is one-to-one. Three methods &#183;
1.	if X discrete: 
fY (y)= fX(x) 
{x:u(x)=y} 
1 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec08/</lecture_pdf_url>
      <lectureno>8</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; 
&#65533; &#65533; 
&#65533; 
&#65533; &#8226; probability density function(PDF) fX (x)isde&#64257;nedby 
P (X = x)= fX (x) if X is discrete 
P (X &#8712; A)= fX (t)dt 
A 
&#8226; the cumulativedistributionfunction(CDF) FX (x)isde&#64257;nedby 
FX (x)= P (X &#8804; x) 
As an important example for a discrete random variable, we spent some time looking at the Binomial 
distribution, which describes the number X of &#8221;successes&#8221; in a sequence of N independent trials, with 
a success probability equal to p foreachtrial. Thep.d.fforthebinomialdistributionwas(youshould 
know this for the exam) 
fX (x)= P (X = x)= Np x(1&#8722;p)N&#8722;x 
x 
Relationship between CDF and PDF 
Getting from the PDF to the CDF 
&#8226; if X is discrete, add up 
FX (x)= fX (xi) 
xi&#8804;x 
&#8226; if X is continuous, integrate 
x 
FX (x)= P (X &#8804; x)= fX (t)dt 
&#8722;&#8734; 
Getting from the CDF to the PDF 
&#8226;	if X isdiscrete,
fX (x)= FX (x +)&#8722;FX (x &#8722;)
&#8226;	if X is continuous
F &#65533; d
fX (x)= X (x)= FX (x)dx 
Also, recall main properties of CDF 
&#8226; 0 &#8804;FX (x)&#8804; 1 for all x &#8712; R 
&#8226; FX (x)nondecreasing in x 
&#8226; FX (x)continuous from the right 
&#8226; FX (x)is continuous everywhere if and only if X is continuous 
5 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>2 fZ|X 0 Z 
1 2 
1 
X 2 
3 61.13% 15.42% 23.42% 
75.25% 11.86% 12.88% 
85.36% 8.63% 6.04% 
Putting the conditional c.d.f.s for the values of X =1, 2, 3 together in a table, we get 
Why isthisexerciseinteresting? -whileinthetablewiththejointp.d.f.,theoverallpicturewasnotvery 
clear, we canseethatforlower values of marriagequality X,the conditional p.d.f. putshigherprobability 
mass on higher numbers of a&#64256;airs. 
Does this mean that dissatisfaction with marriage causes extra-marital a&#64256;airs? Certainly not: we could 
just do the reverse exercise, and lookat the conditional p.d.f. of reported satisfaction with marriage, X, 
given the number of a&#64256;airs, Z. E.g. 
fXZ (1, 0) 17.80% fX|Z (1, 0) = = =23.72% fZ (0) 75.04% 
or, summarizing the conditional p.d.f.s in a table:
Weseethattheconditionalp.d.f. of X given a larger number of a&#64256;airs, Z,puts moreprobability on lower
Z 
fX|Z 0 1 2 
1 23.72% 38.54% 51.24% 
X 2 32.37% 32.88% 31.25% 
3 43.91% 28.58% 17.51% 
satisfaction with the marriage. So we could as well read the numbers as extra-marital a&#64256;airs ruining the
relationship. This is often referred to as &#8221;reverse causality&#8221;: even though we may believe that A causes
B, B may at the same time cause A.
Therefore, even though the conditional distributions shift in a way which is compatible with either story,
wecan&#8217;tinterprettherelationship as &#8221;causal&#8221; ineitherdirection,becauseboth storiesareequallyplausible,
and presumably in reality, there is some truth to either of them.
Review 
I don&#8217;t expect you to memorize any of the examples we did in class, however, especially for &#8221;text&#8221; 
problems they can be extremely helpful as &#8221;models&#8221; for particular situations/problems. Often you can 
&#64257;nd a solution strategy to a given question by seeing analogies to examples we discussed in the lecture. 
1. Probability 
Sample Space, Set Theory and Basic Operations 
won&#8217;tdiscussthis 
2 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 3.	k draws without replacement, orderdoesn&#8217;t matter(combination): N
k = (N&#8722;N
k!
)!k! possi&#173;
bilities(e.g. inbinomialdistribution,countthenumberof alldi&#64256;erent sequencesof &#8221;successes&#8221; 
which give the same overall number of successes). 
&#8226;	partitions: number of ways of allocating N objects across k groups, identities of objects don&#8217;t 
matter (e.g. number of di&#64256;erent allocations a &#64257;ve identical blue balls to four urns): in general 
N + k &#8722;1 possibilities, will discuss this below k &#8722;1 
&#8226;	we saw that in one way or another, all these counting rules derive from the multiplication rule, 
where sometimes we had to divide by the number of di&#64256;erent possibilities of obtaining the same 
event(e.g. di&#64256;erent orders ofdrawing the same combination). 
Independence,ConditionalProbability,Bayes&#8217; Theorem 
&#8226;	A and B areindependentif P (AB)= P (A)P (B) 
&#8226;	conditionalprobability P (A|B)= P (AB) if P (B)&gt; 0P (B) 
&#8226;	P (A|B)= P (A)if, and only if, A and B areindependent 
&#8226;	law of total probability: if B1,...,Bn partition of S, 
P (A)= P (A|B1)P (B1)+... + P (A|Bn)P (Bn) 
The law of total probability links conditional to marginal probabilities, i.e. how to relate P (A) 
to P (A|B1),...,P (A|Bn). Classical application: aggregating over subpopulations/subcases, e.g. 
death rates over di&#64256;erent types of bypass surgery. 
&#8226;	Bayes&#8217; Theorem(simpleformulation): if P (B)&gt; 0,then 
P (B|A)P (A) P (B|A)P (A)P (A|B)= = P (B) P (B|A)P (A)+P (B|AC )P (AC ) 
Bayes&#8217; Theorem tells us how to switch the order of conditioning, i.e. how to go from P (B|A) 
to P (A|B). Classical application: update beliefs about event A givendata B, e.g. medical test 
example. 
&#8226;	&#8221;base rates&#8221; matter a lot 
For the exam, you should know these relationships by heart. 
2. Random Variables and Distribution Functions 
&#8226;	random variables give numerical characterization of random events. 
&#8226;	random variable X is a function from the sample space S to the real numbers R. 
&#8226;	probability function on S induces a probability distribution of X in R, 
P (X &#8712; A)= P {s &#8712; S : X(x)&#8712; A} 
4 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>&#65533; 
&#65533; 
&#65533; &#65533; By independence,thejointp.d.f. is 
1 if r &#8712; [10, 12] and g &#8712; [8.5, 11] fGR(g,r)= fG(g)fR(r)= 5 
0 otherwise 
The probability of the event R &#8804; G can be calculated as 
&#65533; 11 &#65533; max{g,10} 1 &#65533; 11 max{g &#8722;10, 0} &#65533; 11 g &#8722;10 g2 &#65533;11 21 1 P (R &#8804; G)= drdg =	 dg = dg = &#8722;2g = &#8722;2= 5 5	 5 10 10 10 8.510 8.5 10	 10 
Example4 One of your classmates asked how one can solve the following problem: how many di&#64256;erent 
ways are there to allocate N indistinguishable blackboardsto k di&#64256;erent classrooms? This corresponds to 
choosing a partition of blackboards over k classes. We can do the calculation as follows: 
&#8226;	introduce k &#8722;1 &#8221;separators&#8221; Z1,Z2 ...,Zk&#8722;1, which we mix with the blackboards B1,B2,...,BN 
&#8226;	represent each allocationofblackboardstoroomsasareordering of B1,B2,...,BN ,Z1,Z2,...,Zk&#8722;1. 
The blackboards before the &#64257;rst Z to appear in the sequence are those which we are going to put up 
in the &#64257;rst classroom, the boards up to the second &#8221;separator&#8221; go into room 2, etc. If the sequence 
is e.g. Z5,B7,B2,B5,Z4,B9,..., then there is going to be no blackboards in room 1, boards 7, 2, 
and 5 go to room 2 etc. 
&#8226;	the number of di&#64256;erent orderings of the sequence is (N +(k &#8722;1))! 
&#8226;	sinceblackboards and separators are equivalent(classrooms aren&#8217;t), wehavetodivideby the number 
ofpermutations of eachtheblackboards(N! permutations), and the separators((k &#8722;1)! permuta&#173;
tions). 
&#8226;	putting all pieces together, we have 
(N + k &#8722;1)! N + k &#8722;1 p = = N!(k &#8722;1)! k &#8722;1 
possible allocations. 
8 </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>3 JointDistributions 
Looked at 
&#8226; joint PDF forX and Y (discrete or continuous) 
&#8226; marginal distribution of X with PDF 
&#65533; &#8734; 
fX (x)= fXY (x,y)dy 
&#8722;&#8734; 
&#8226; independence of random variables, most importantly 
fXY (x,y)= fX (x)fY (y) for all(x,y)&#8712; R2 
if and only if X and Y areindependent 
&#8226; conditional distribution of Y given X, 
fXY (x,y)fY |X (y|x)= fY (y) 
Random Problems 
Example2 (Spring 2003 Exam) A Monet expert is given a painting purported to be a lost Monet. 
He is asked to assess the chances that it is genuine and has the following information: 
&#8226; In general, only 1% of the &#8221;found&#8221; paintings he receives turn out to be genuine, an event we&#8217;ll call 
G 
&#8226; &#8221;Found&#8221; paintings have a di&#64256;erent frequency of use of certain pigments than genuine Monets do: 
(a) cadmium yellow Y appearsin 20% &#8221;found&#8221; paintings, but only 10% genuine ones 
(b) raw umber U appearsin 80% of &#8221;found&#8221; paintings, but only 40% of genuine ones 
(c) burnt sienna S appearsin 40% of &#8221;found&#8221;, but 60% ofgenuinepaintings 
&#8226; This particular painting uses burnt sienna, but not cadmium yellow or raw umber. 
What is the probability that this particular painting is genuine? Do we have to make any additional 
assumptions to answer the question? 
This problem has the following structure: the problem seems to tell us what colors (&#8221;data&#8221; SY C UC )
are how likely to appear given that thepaintingisgenuine(&#8221;state of the world&#8221; G),i.e. P (B|A). But
we actually want to know how likely the painting is genuine given the colors that were used in it, i.e.
P (A|B). So we are trying to switch the order of conditioning, so we&#8217;ll try to use Bayes&#8217; Theorem.
Let&#8217;s &#64257;rst compile the information contained in the problem:
P (Y ) =0.2 
P (Y |G) =0.1 
P (U) =0.8 
P (U|G) =0.4 
P (S) =0.4 
P (S|G) =0.6 
6 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533;
&#65533;and 
P (G)=0.01 
But what do we need to apply Bayes&#8217; theorem? -the theorem tells us that 
P (G|SY C UC )= P (SY C UC |G)P (G) 
P (SY C UC ) 
However, know only marginal probability of each color, but would need joint probabilities(both condi&#173;
tional on G and unconditional). 
Therefore we have to make an additional assumption at this point, and the simplest way to attack this 
is to assume that the use of pigments is independent across the three colors, both unconditionally and 
conditional on G,i.e. 
P (SY C UC |G)= P (S|G)P (Y C |G)P (UC |G)=0.6&#183; 0.9&#183; 0.6 
and 
P (SY C UC )= P (S)P (Y C )P (UC )=0.4&#183; 0.8&#183; 0.2 
Using Bayes&#8217; theorem we get therefore that under the independence assumption 
0.6&#183; 0.9&#183; 0.6&#183; 0.01 81 P (G|SY C UC )= = 0.4&#183; 0.8&#183; 0.2 1600 
To see how much this assumption mattered, can invent a di&#64256;erent dependence structure among the 
di&#64256;erent types of pigments: suppose that for genuine Monets, every painting using sienna S also uses 
umbra U for sure. Then, by the de&#64257;nition of conditional probabilities 
P (SY C UC |G)&#8804; P (SUC |G)= P (UC |SG)P (S|G)=0&#183; 0.6 =0 
so that for a true Monet, it is impossible to &#64257;nd sienna S, but not umbra, therefore we&#8217;d know for sure
that thepaintinginquestions can&#8217;tbe aMonet(note that since ourpaintinghad this combination,it
has to be possible for &#8221;found&#8221; paintings in general).
So, summing up, this problem did not give us enough information to answer the question.
Example3 (Exam Fall 1998) Recycling is collected at my house sometime between 10am and noon, 
and any particular minute is as likely as any other. Garbage is collected sometime between 8:30am 
and 11:00am, again with any particular instant as likely as any other. The two collection times are 
independent. 
(a) Whatisthejointp.d.f. ofthetwocollectiontimes, R and G? 
(b) What is the probability that the recycling is collected before garbage? 
The marginal distribution of R is(continuous) uniform withdensity 
fR(r)= 1
2if r &#8712; [10, 12] 
0 otherwise 
The marginal distribution of G is discrete with p.d.f. 
2
5 fG(g)= if g &#8712; [8.5, 11] 
0 otherwise 
7 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 8 
Konrad Menzel 
March 3, 2009 
Conditional p.d.f.s 
De&#64257;nition1 The conditionalp.d.f. of Y given X is 
fXY (x,y)fY |X (y|x)= fX (x) 
Notethatif X and Y arediscrete, 
P (Y = y|X = x)fY |X (y|x)= P (X = x) 
whichjust correspondsto the conditionalprobability of the event corresponding to X = x given Y = y 
as de&#64257;ned two weeks ago. 
Notethat 
&#8226;	for a particular value of the conditioning variable, the conditional p.d.f. has all the properties of a 
usualp.d.f. (i.e. positive,integratesto1) 
&#8226;	the de&#64257;nition generalizes to any number of random variables on either side 
Example1 Let&#8217;s go back to the data on extra-marital a&#64256;airs, and look at the variables we are actually 
most interested in: the number of a&#64256;airs during the last year, Z, and self-reported &#8221;quality&#8221; of the 
marriage, X. The joint p.d.f. is given by Since three quarters of respondents reported not having had 
Z 
fXZ 0 1 2 fX 
1 17.80% 4.49% 6.82% 29.12% 
X 2 24.29% 3.83% 4.16% 32.28% 
3 32.95% 3.33% 2.33% 38.60% 
fZ 75.04% 11.65% 13.31% 100.00% 
an a&#64256;air, it might be more instructive to look at the p.d.f. of the number of a&#64256;airs Z conditional on the 
rating of marriage quality. Conditional on the low rating, X =1, we have 
fXZ (1, 0) 17.80% fZ|X (0|1) = = =61.13% fX (1) 29.12% 
1 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533; &#65533; &#13;
 &#65533; De&#64257;nition of probability 
(P1) P (A)&#8805; 0 for all A &#8834; S 
(P2) P (S)=1 
(P3) if A1,A2,... is a sequence of disjoint sets, 
&#8734; &#8734; 
P Ai = P (Ai) 
i=1 i=1 
Special Case: Simple Probabilities 
&#8226;	S &#64257;nite 
&#8226;	P (A)= n(A) where n(B)denotes the number of outcomes in set B n(S) 
Properties of Probability Functions 
&#8226;	P (AC )=1&#8722;P (A) 
&#8226;	P (&#8709;)=0 
&#8226;	if A &#8834; B,then P (A)&#8804; P (B) 
&#8226;	0 &#8804; P (A)&#8804; 1 for any event A &#8834; S 
&#8226;	P (A &#8746;B)= P (A)+P (B)&#8722;P (A &#8745;B) 
CalculatingProbabilities 
Try to attack problems in this order 
(i) de&#64257;ne sample space and the event of interest in terms of outcomes 
(ii) for simple probabilities, make sure that you de&#64257;ned the sample space in a way that makes each 
outcome equally likely 
(iii) if you are stuck, start writing out outcomes in sample space explicitly 
CountingRules 
&#8226;	basic set-up: have set X1,...,XN of N objects 
&#8226;	multiplication rule: have to be able to factor an experiment into k parts such that the number of 
outcomes mi ineach of themdoesnotdepend ontheoutcomesintheotherparts. Sometimestricky 
(e.g. chess example). 
&#8226; several di&#64256;erent ways of drawing k objectsfromthe set(should rememberthoseforthe exam): 
1.	k draws with replacement, order matters: Nk possibilities 
2. k draws without replacement, order matters (special case: permutation, k = N): (NN
&#8722;! 
k)! 
possibilities 
3 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec20/</lecture_pdf_url>
      <lectureno>20</lectureno>
      <slides>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>a type I error of a given test, 
&#945; = P(Type Ierror) = P(rejectH0)|
is called the signi&#64257;cancelevel (or also thesize)of the test. If we write 
&#946; = P(Type IIerror) = P(don&#8217;t rejectHA)|
then1 &#8722;&#946; isthe power ofthetest. 
Usually we&#8217;ll &#64257;x the signi&#64257;cance level of the test, e.g. at 5%, and then try to construct a test that 
has maximal power given that signi&#64257;cance level. So in a sense we prefer to err on not rejecting the null 
hypothesis. 
The logic behind this is a little counter-intuitive at &#64257;rst, but it comes from the empirical problem 
of generalizing from a few observations to an entire population or a scienti&#64257;c law: even though we may 
only have observed instances which conform with our hypothesis about the population, it is su&#64259;cient to 
observe one which doesn&#8217;t in order to disprove it. Therefore we can use empirical evidence only to reject 
a hypothesis, but never to con&#64257;rm it. The following is a famous example by the philosopher Bertand 
Russell: 
&#8221;Domestic animals expect food when they see the person who usually feeds them. We know 
that all these rather crude expectations of uniformity are liable to be misleading. The man 
who has fed the chicken every day throughout its life at last wrings its neck instead, showing 
that more re&#64257;ned views as to the uniformity of nature would have been useful to the chicken. 
[..] Themerefactthatsomethinghashappened acertainnumberof timescausesanimalsand 
men to expect that it will happen again. Thus our instincts certainly cause us to believe that 
the sun will rise to-morrow, but we may be in no better a position than the chicken which 
unexpectedly hasitsneck wrung.&#8221; (Russell,The Problemsof Philosophy) 
Therefore, if we want to present evidence that e.g. a certain drug signi&#64257;cantly improves a patient&#8217;s 
condition, we de&#64257;ne the null hypothesis as H0: &#8221;the drug has no e&#64256;ect on the patient&#8217;s condition.&#8221; 
Rejecting this hypothesis means that we have strong evidence for an e&#64256;ect of the drug. I.e. we always 
choose the null hypothesis as the statement we actually want to disprove. 
As another illustration, we could think of the criminal justice system: in a process, both parties 
presentdata(evidence) inordertoproduceadecision &#8221;guilty&#8221; or &#8221;notguilty,&#8221; andthejury canagain 
maketwoerrors:falsely convicting aninnocentperson(TypeI error),or not convicting acriminal(Type 
II error). Most modern legal systems base criminal trials on the presumption of innocence, i.e. the 
accusedisassumed tobe &#8221;innocentuntilprovenguilty&#8221;,orinotherwords,theburdenofproofisonthe 
prosecution whichhastoproduce evidenceto convincethejudge/jury thatthe accusedisinfactguilty. 
Note that decisions taken according to hypothesis tests need not be optimal in the sense that we 
ignore our ex ante probabilities for the null vs. the alternative hypothesis being true, and do not take 
into account the respective costs of making type I or type II errors. For criminal justice, proponents 
of preemption often argue that in many contexts -e.g. terrorism -a type II error may be prohibitively 
costly,sothatthelegal systemshould allowforexceptionsof thepresumptionofinnocenceinsomecases. 
In sum, we&#8217;d like to formulate a rule which maps each possible outcome of the sample X1,...,Xn to 
a decision &#8221;reject&#8221; or &#8221;do not reject.&#8221; 
4 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 20 
Konrad Menzel 
April 30, 2009 
Con&#64257;denceIntervals(continued) 
The following example illustrates one way of constructing a con&#64257;dence interval when the distribution of 
the estimator is not normal. 
Example 1 Suppose X1,...,Xn are i.i.d. with Xi &#8764;U[0,&#952;], and we want to construct a 90% con&#64257;dence 
intervalfor &#952;0. Let 
&#952;&#710;= max{X1,...,Xn}= X(n) 
the nth order statistic (as we showed last time, this is also the maximum-likelihood estimator). Even 
though, as we saw, &#952;&#710;is not unbiased for &#952;, we can use it to construct a con&#64257;dence interval for &#952;. 
From results for order statistics, we saw that the c.d.f. of &#952;&#710;is given by the c.d.f. of &#952;&#710;isgivenby 
&#9127;
0 &#952; &#8804;0 &#9130;&#9128;&#65533; 
&#952; &#65533;n 
F&#952;&#710;(&#952;)= &#952;0 if0 &lt;&#952; &#8804;&#952;0 &#9130;&#9129; 1 if &#952;&gt;&#952;0 
where we plugged in the c.d.f. of a U[0,&#952;0]random variable, F(x)= &#952;x 
0 .
In order to obtain the functions for A and B, let us &#64257;rst &#64257;nd constants a and b such that
P&#952;0 (a &#8804;&#952;&#710;&#8804;b)= F&#952;&#710;(b)&#8722;F&#952;&#710;(b)=0.95&#8722;0.05 =0.9 
We can &#64257;nd a and b by solving 
F&#952;&#710;(a)=0.05 and F&#952;&#710;(b)=0.95 
n nso that we obtain a = &#8730;
0.05&#952;0 and b = &#8730;
0.95&#952;0. This doesn&#8217;t give us a con&#64257;dence interval yet, since 
looking at the de&#64257;nition of a CI, we want the true parameter &#952;0 in the middle of the inequalities, and the 
functions on either side depend only on the data and other known quantities. 
However, we can rewrite 
&#65533; 
n&#65533; 
&#952;&#710; &#952;&#710;&#65533; 
0.9= P&#952;0 (a &#8804;&#952;&#710;&#8804;b)= &#8730;
0.05&#952;0 &#8804;&#710;&#8730;
0.95&#952;0 &#65533; 
= P&#952;0 nP&#952;0 n&#952; &#8804; n&#8730;
0.95 &#8804;&#952;0 &#8804;&#8730;
0.05 
Therefore 
&#65533; max{X1,...,Xn} max{X1,...,Xn}&#65533; 
[A,B]=[A(X1,...,Xn),B(X1,...,Xn)]= n, n&#8730;
0.95 &#8730;
0.05 
is a 90% con&#64257;dence interval for &#952;0. Notice that in this case, the bounds of the con&#64257;dence intervals depend 
on the data only through the estimator &#952;&#710;(X1,...,Xn). This need not be true in general. 
1 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533;
&#65533;Let&#8217;s recap how we arrived at the con&#64257;dence interval: 
1. &#64257;rst get estimator/statistic &#952;&#710;(X1,...,Xn)and the distribution of &#952;&#710;. 
2. &#64257;nd a(&#952;),b(&#952;)such that
P(a(&#952;)&#8804;&#952;&#710;&#8804;b(&#952;))=1&#8722;&#945;
3. rewrite the event by solving for &#952;
P(A(X)&#8804;&#952; &#8804;B(X))= P(A(&#952;&#710;)&#8804;&#952; &#8804;B(&#952;&#710;))=1&#8722;&#945;
4. evaluate A(X),B(X)for the observed sample X1,...,Xn 
5. the1 &#8722;&#945; con&#64257;denceintervalisthengivenby
CI =[A(X1,...,Xn),B(X1,...,Xn)]
1.1 Important Cases 
1. &#952;&#710;is normally distributed, Var(&#952;&#710;)&#8801;&#963;2 is known: can form con&#64257;dence interval &#952;&#710;
[A(X),B(X)]= &#65533;
&#952;&#710;&#8722;&#65533;
&#963;&#952; 2&#934;&#8722;1 &#65533;
1&#8722; &#945; 
2 &#65533; 
,&#952;&#710;+ &#65533;
&#963;&#952; 2
&#710;&#934;&#8722;1 &#65533;
1&#8722; &#945; 
2 &#65533;&#65533; 
&#710;
2. &#952;&#710;is normally distributed, Var(&#952;&#710;)unknown, but have estimator S&#710;2 =Var(&#952;&#710;): con&#64257;dence interval is 
givenby
[A(X),B(X)]= &#65533;
&#952;&#710;&#8722; &#65533;
S&#710;2tn&#8722;1 &#65533;
1&#8722; &#945; 
2 &#65533; 
,&#952;&#710;+ &#65533;
S&#710;2tn&#8722;1 &#65533;
1&#8722; &#945; 
2 &#65533;&#65533;
where tn&#8722;1(p)isthe pth percentile of a t-distribution with n &#8722;1 degrees of freedom. 
3. &#952;&#710;is not normal, but n&gt; 30 or so: it turns out that all estimators we&#8217;ve seen (except for the 
maximum of the sample for the uniform distribution) will be asymptotically normal by the central 
limittheorem(itisnot always straightforwardhow we applytheCLTin agiven case). So we&#8217;ll 
construct con&#64257;dence intervals the same way as in case 2. 
4. &#952;&#710;not normal, n small:if thep.d.f. of &#952;&#710;isknown,canformcon&#64257;denceintervalsfrom &#64257;rstprinciples 
(as in the last example). If the p.d.f. of &#952;&#710;is not known, there is nothing we can do. 
The reason for using the t-distribution in the second case is the following: since &#952;&#710;&#8764;N &#65533; 
&#181;, &#963;2 &#65533; 
,n 
&#952;&#710;&#8722;&#181; 
&#963;/&#8730;n &#8764;N(0,1) 
On the other hand, we can check that 
(n &#8722;1)S&#710;2 
&#8764;&#967;2 
&#963;2 n&#8722;1 
since in this setting, S&#710;can usually be written as a sum of squared normal residuals with mean zero and 
variance &#963;2 . Therefore, 
&#952;&#710;&#8722;&#181;&#952;&#710;&#8722;&#181; = &#963;/&#8730; n N(0,1) tn&#8722;1 &#65533;
S&#710;2/n &#65533; 
(n&#8722;1) S&#710;2 &#8764;&#65533;
&#967;2 &#8764;
&#963;2 /&#8730;n &#8722;1 n&#8722;1 
2 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533;Alsonotethatinthegeneralcase4(andinthelast exampleinvolving auniform), wedid notrequire 
that the statistic &#952;&#710;(X1,...,Xn)be an unbiased or consistent estimator of anything,butitjusthad tobe 
strictly monotonic in the true parameter. However, the way we constructed con&#64257;dence intervals for the 
normal cases(with or withoutknowledge of the variance of &#952;&#710;, the estimator has to be unbiased, and in 
case3(n large), it would have to be consistent. 
2 Hypothesis Testing 
2.1 Main Idea 
Idea: given a random sample from a population, is there enough evidence to contradict some assertion 
about the population? Let&#8217;s &#64257;rst de&#64257;ne a number of important concepts: 
a hypothesis is an assumption about the distribution of a random variable in a population &#8226; 
the maintainedhypothesis is a hypothesis which cannot be tested, but which we will assume to be &#8226; 
true no matter what. 
a testablehypothesis is a hypothesis which can and will be tested using evidence from a random &#8226; 
sample 
the nullhypothesis isthehypothesistobetested &#8226; 
the alternativehypothesis are otherpossible assumptions aboutthepopulation otherthanthe null &#8226; 
The testing problem can be stated as whether the parameter &#952;0 corresponding to the density f(x&#952;0)|
which our sample X1,...,Xn is drawn from belongs to a certain set of possible parameter values, &#920;0. 
We usually write the null hypothesis as 
H0 : &#952; &#8712;&#920;0 
which we test against the alternative 
HA : &#952; &#8712;&#920;A 
where&#920;0 &#8745;&#920;A = &#8709;. 
If&#920;0 = {&#952;0}contains only a single parameter value, we say that the hypothesis is simple.A composite 
hypothesis is given by a set &#920; containing multiple points, or an entire range of values. 
Example 2 In the most common setup, H0 is simple, and HA composite, e.g. X &#8764;N(&#181;,&#963;02), where &#963;02 
is known, and we want to test whether &#181; =0. In this setting, the maintained hypothesis is that the Xis 
are i.i.d. normal and Var(Xi)= &#963;02 . The null hypothesis is H0 : &#181;=0 (simple), andwe test against the 
alternativehypothesis HA : &#181;=0 (composite). 
In order to test the hypothesis we have to gather data, and then either accept or reject the null 
hypothesis based on the data. However, since our data will always be only a sample from the entire 
population, there is always a possibility that we will make a mistake in our decision: The probability of 
True State of Nature 
H0 true H0 false 
reject H0 Type I error correct 
Decision 
not reject H0 correct Type II error 
3 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec17/</lecture_pdf_url>
      <lectureno>17</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; 
&#65533; 
&#65533; &#65533; &#65533; 
&#65533; 
&#65533; 
&#65533; 3 General Properties of Estimators 
We will denote the expectation of X under the parameter &#952; -i.e. the expectation of X if the true 
parameter is equal to &#952; -by 
&#8734; 
E&#952;[X]= xfX(x&#952;)dx |
&#8722;&#8734; 
Similarly, I&#8217;ll write the variance under the parameter &#952; as 
Var&#952;(X)= &#65533; &#8734; 
(x &#8722;E&#952;[X])2fX(x|&#952;)dx 
&#8722;&#8734; 
The bias of an estimator is the di&#64256;erence between its expectation and the true parameter, 
Bias(&#952;&#710;)= E&#952;0 [&#952;&#710;]&#8722;&#952;0 
Of course, we&#8217;d like an estimator to get the parameter right on average, so that ideally, the bias should 
be zero. 
De&#64257;nition2 An estimator &#952;&#710;= &#952;&#710;(X1,...,Xn)is unbiased for &#952; if 
E&#952;0 [&#952;&#710;]= &#952;0 
for all values of &#952;0. 
Example6 Suppose X1,...,Xn is an i.i.d. sample from a N(&#181;,&#963;2) distribution. We already saw last 
week that the expectation of the sample mean 
&#175; E&#181;,&#963;2 [Xn]= E&#181;,&#963;2 [X]= &#181; 
&#175; for any value of &#181;, so that Xn is an unbiased estimator for the mean &#181; of a normal distribution. 
Example7 Suppose we want to estimate the variance parameter &#963;2 for X &#8764;N(&#181;,&#963;2) with unknown 
mean &#181; from an i.i.d. random sample X1,...,Xn. Since &#963;2 = E[(X &#8722;E[X])2], an intuitively appealing 
estimator would be n 
&#963;&#710;2 =1 (Xi &#8722;X&#175;)2 
n i=1 
(where we substituted the sample mean for the actual expectation). What is the expectation of this esti&#173;
mator if the true parameters of the distribution are (&#181;0,&#963;02)? 
Recall that E[X2]= E[X]2 +Var(X), so that 
n 
E[&#710;&#963;2]= E 1(Xi 2 &#8722;2XiX&#175;+ X&#175;2) n i=1 
n 1 E[X2 X&#175;2] = i &#8722; 
i=1 
n n 
1 = E[Xi 2]&#8722;E[X&#175;2] n i=1 
n &#65533; &#65533; 
&#963;2 
n n = 1(&#181; 2 + &#963;2)&#8722; &#181; 2 +1 
i=1 
&#963;2 n &#8722;1 &#963;2 = &#181; 2 + &#963;2 &#8722;&#181; 2 &#8722; n = n 
6 </text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>so this estimator is unbiased. However, for any sample size n, the distribution of the estimator is the 
same as that for Xi &#8764;N(&#181;,&#963;), so e.g. for &#949; = &#963;0, the probability 
P(|&#952;&#732;(X1,...,Xn)&#8722;&#181;0|&lt;&#963;0)= P(&#65533; &#181;0 &#8722;&#963;0 &#8804;Xn &#8804;&#181;0 + &#65533; &#963;0) 
= P &#8722;1 &lt;Xn &#8722;&#181;0 &lt; 1= P(&#8722;1 &lt;Z&lt; 1) &#963;0 
= &#934;(1)&#8722;&#934;(&#8722;1) &#8776;0.6825 &lt;&lt; 1 
for all n, where the standardization Z := Xn
&#963;&#8722;
0 &#181;0 follows a N(0,1) distribution. By this argument, &#952;&#732;is 
unbiased,but not consistent. 
8 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; &#65533; Xbar_n 
0 .2 .4 .6 .8 1 
Xbar_n 
&#8722;1.5 &#8722;1 &#8722;.5 0 .5 1 
0 100 200 300 400 500 0 100 200 300 400 500 
n n 
&#175; &#175; Figure1:Numberofheadsin n coin tosses: sample mean Xn (left)and standardized samplemean &#8730;nXn 
(right) 
of two independent draws was in the same family of distributions, the distribution of the sample mean 
would still change a lot for arbitrarily large values of n, and can therefore not lead to a stable limit. This 
should motivate why itisplausiblethatthedistribution of the mean approachesthe normaldistribution 
inthelimit. 
Example1 Suppose X1,...,Xn are i.i.d. random variables where Xi &#8764;U[0,1] is uniform, so the p.d.f. 
is &#65533; 
fX(x)=1 if0 &#8804;x &#8804;1 
0 otherwise 
We can now use the convolution formula from lecture 10 to compute the p.d.f. for the partial sums 
Sk = X1 + X2 + ... + Sk 
For k =2, weget(needtobe careful aboutintegrationlimits) 
&#8734; min{s2,1}
fS2 (s2)= fX(s2 &#8722;w)fX(w)dw = 1dw
max{s2&#8722;1,0}
 &#8722;&#8734; &#9127; 
&#9128; s2 if0 &#8804;s2 &#8804;1 
= min{s2,1}&#8722;max{s2 &#8722;1,0}=2&#8722;s2 if1 &#8804;s2 &#8804;2 &#9129; 0 otherwise 
Now, the next calculations become more tedious because we always have to keep track of the integration 
limits and the kink points in the density. After some calculations, I get for k =3 
&#9127; 2 &#9130; if0 &#8804;&#65533; &#9130; s 
2 3 s3 &#8804;1 &#9128; 3 
fS3 (s3)= &#8734; 
fS2 (s3 &#8722;w)fX(w)dw = &#8722;2 +3s3 &#8722;s32 if1 &#8804;s3 &#8804;2 
&#9130; &#9130; 9
2 &#8722;3s3 + 1
2 s2
3 if2 &#8804;s3 &#8804;3 &#8722;&#8734; &#9129; 0 otherwise 
By the rule on expectations of sums of random variables, 
k E[Sk]= kE[X1]= 2 
2 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533; 
&#65533; Also, since X1,X2,...,Xk are independent, we can use the rule on the variance of the sum 
Var(Sk) = Var(X1 + X2 + ... + Xk)=Var(X1)+Var(X2)+... +Var(Xk) 
&#65533; 1 &#65533; &#65533;2 &#65533; &#65533; 1 111 k = kVar(X1)= k t &#8722;2 dt = k 3 &#8722;2+4 =12 0 
Therefore, the standardization Zk of SK isgivenby 
Sk &#8722;k 
2Zk = &#65533; 
k 
12 
We can therefore calculate the densities of the standardizations Z1,Z2,Z3 using the change of variables 
formula(notice that thederivativeisjust equal to 12 )k 
1
fZ1 (z)=	&#8730;
12 if &#8722;&#8730;
3 &#8804;z &#8804;&#8730;
3 
0 otherwise &#9127; 
&#9130; &#9128; &#8730;1
6 + 6 z if &#8722;&#8730;
6 &#8804;z &#8804;0 
fZ2 (z)= 1 z if0 &#8804;&#9130; &#8730;
6 &#8722;6 z &#8804;&#8730;
6 
&#9129; 0 otherwise 
&#9127;&#65533; &#65533;2 &#9130; + &#9130; 13 z if &#8722;3 &#8804;z &#8804;&#8722;1 &#9130; 42 2 
fZ3 (z)= &#9128; 3
8 &#65533;&#8722;z 
8 2
2 &#65533; if &#8722;1 &#8804;z &#8804;1 
&#9130; &#9130; 219 
43 z + z 
8 if1 &#8804;z &#8804;3 &#9130; 8 &#8722;&#9129; 0	 otherwise 
Now let&#8217;s check how this looks graphically: 
Central Limit Theorem for uniform r.v.s density 
0 .1.2.3.4 
&#8722;4 &#8722;2 0 2 4 
z 
Density for Z_1 Density for Z_2 
Density for Z_3 Standard Normal Density 
The p.d.f. for standardized sums of uniform random variables looks very similar to the standard 
normal p.d.f. for a sum over as few as 3 independent draws -which is quite surprising since the uniform 
density itself doesn&#8217;t look at all like that of a normal random variable. 
3 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533; 
&#65533;
&#65533; &#65533; Therefore &#963;&#710;2 is not an unbiased estimator for &#963;2, but we can easily construct an unbiased estimator &#963;&#732;2 
n 
&#963;&#732;2 = n &#8722;1
1 (Xi &#8722;X&#175;n)2 
i=1 
Where does this bias come from? Broadly speaking, the reason is that inside the square we are replacing 
&#175; &#181; with a (noisy) estimate &#181;&#710;= Xn. You can check on your own that if &#181;0 was known, the estimator 
&#963;&#710;2 = 1 n (Xi &#8722;&#181;0)2 would be unbiased for &#963;. n i=1
Having to estimate the mean uses up one &#8221;degree of freedom&#8221; in the data -e.g. if we only had a sample 
of one observation, the estimated mean would be equal to that observation, and the &#8221;naive&#8221; estimator of 
the variance would give us &#963;&#710;2 =0, which is clearly not the right answer. 
Unbiasedness may not be the only thing we care about, since the estimator being equal to the true 
parameter on average doesn&#8217;t mean that in for a given sample, the estimate is actually going to be close 
tothetrueparameter. 
De&#64257;nition3 For a sample X1,...,Xn, we say that &#952;&#710;is a consistent estimatorfor &#952; if as we increase 
n, the estimator convergesinprobability to &#952;0, i.e. for all &#949;&gt; 0, 
lim P&#952;0 |&#952;&#710;(X1,...,Xn)&#8722;&#952;0|&lt;&#949; =1 
n&#8594;&#8734; 
for all values of &#952;0. 
In words, in a su&#64259;ciently large sample, a consistent estimator will be within a small distance from the 
true parameter with high probability. Notice that unbiasedness and consistency are two very di&#64256;erent 
concepts which overlap, but neither implies the other: 
Example8 Back to one of our estimators for the uniform distribution, X &#8764;U[0,&#952;0]. If we look at 
&#952;&#710;1 =max{X1,...,Xn} 
we can easily see that &#952;&#710;1 is not unbiased for &#952;, because due to the nature of the uniform distribution, all 
possiblevaluesofXi arelessthan &#952;0. Therefore,nomatterhowlarge n is, P(max{X1,...,Xn}&lt;&#952;0)=1. 
Therefore the expectation E&#952;0 [&#952;&#710;1] &lt;&#952;0. However, &#952;&#710;1 is consistent for &#952;0: We can easily see that for a 
single observation X from the uniform, the c.d.f. is FX(x)= &#952;x 
0 . Since Yn := max{X1,...,Xn}is the 
nth order statistic of the sample, we get from our previous discussion that for 0 &#8804; 1, FYn (y)= &#65533;&#65533;n y &#8804;
(FX(y))n = &#952;y 
0 . Since &#952;&#710;1 &lt;&#952;0 with probability 1, we can therefore calculate for any sample size n 
and any &#949;&gt; 0 &#65533; &#65533;n 
P(&#710; &gt;&#949;)= P(Yn &lt;&#952;0 &#8722;&#949;)= &#952;0 &#8722;&#949; n|&#952;1 &#8722;&#952;0|&#952;0 &#8801;p 
&#952;0&#8722;&#949;where p := &#952;0 &lt; 1 since &#949;&gt; 0. Therefore,theprobability of adeviationfrom &#952;0 by morethan &#949; vanishes 
as we increase n, and &#952;&#710;1 is therefore consistent. 
Example9 By the Law of Large Numbers, the sample mean converges in probability to E[X]= &#181;.
Therefore, for an i.i.d. sample X1,...,Xn of N(&#181;,&#963;2)random variables, the sample mean is a consistent
estimatorfor &#181;.
Alternatively, let&#8217;s look at an &#8221;unreasonable&#8221; estimator &#952;&#732;(X1,...,Xn)= Xn. Then
E[&#952;&#732;(X1,...,Xn)]= E[Xn]= &#181; 
7 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; 
&#65533; &#65533; 
&#65533; &#65533; 
&#65533; De&#64257;nition1 An estimator &#952;&#710;of &#952; isastatistic(i.e. afunctionof X1,...,Xn), 
&#952;&#710;= &#952;&#710;(X1,...,Xn) 
A realization &#952;&#710;(x1,...,xn)of the estimator in a sample is called an estimate of &#952;. 
Notice that, as a function of the random sample, the estimator is a proper random variable, so we 
will in general be interested in describing its distribution in terms of the p.d.f., and moments of its 
distribution. 
Example4 Suppose, X &#8764;Bernoulli(&#952;0),i.e. X is a zero/one random variable which takes the value 1 
withprobability &#952; andhasp.d.f. 
&#9127; 
&#9128; &#952;0 if x =1 
fX(x)= 1&#8722;&#952;0 if x =0 &#9129; 0 otherwise 
How do we estimate &#952;0? 
Could use sample mean 
n1 &#952;&#710;(X1,...,Xn)= Xi n i=1 
e.g. from 5 Bernoulli trials 1,0,0,1,1 
3 &#952;&#710;(1,0,0,1,1) = 5 
Since the estimator &#952;&#710;for a sample of 5 observations is a random variable, we can derive its p.d.f.: recall &#65533;5thatfor S5 &#8801; i=1 Xi , S5 &#8764;B(5,&#952;0). Applying the methods for &#64257;nding p.d.f.s of functions of discrete 
random variables to &#952;&#710;= S5 , we get 5 &#9127; 
(t)= &#9128; 
55 
t&#952;05t(1&#8722;&#952;0)5(1&#8722;t) if t &#8712; &#65533; 
0, 51
52 
53 
54 ,1 &#65533; 
, , ,f&#952;&#710;&#9129; 0 otherwise 
Inparticular,thedistribution of the estimatordepends onthetrueprobability &#952;0 -which can be anywhere 
intheinterval[0,1] -butcanonly take6di&#64256;erentdiscretevalues. 
Example5 If X &#8764;U[0,&#952;]is uniform over an interval depending on the parameter, the p.d.f. is 
&#952; 1 if0 &#8804;x &#8804;&#952; fX(x)= 0 otherwise 
How could we estimate &#952;? Could use e.g. 
&#952;&#710;1 = max{X1,...,Xn} 
&#952;&#710;2 =2X&#175;n 
Say, we sampled three observations from the distribution, 0.2,0.6,0.4. Then &#952;&#710;1 =0.6 and &#952;&#710;2 =0.8, so 
the two estimators give di&#64256;erent answers on the same parameter. How should we choose among those 
di&#64256;erent estimators? -We&#8217;ll get back to this in a moment. 
How do you come up with these functions &#952;&#710;(X1,...,Xn)? &#8226; 
How can we determine whether these estimators are reasonable? &#8226; 
&#8226; How should we choose between two or more estimators for the same parameter? 
5 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; &#175;&#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 17 
Konrad Menzel 
April 16, 2009 
The Central Limit Theorem 
Remember that last week, we saw the DeMoivre-Laplace theorem for Binomial random variables, which 
essentially said that for large values of n, the standardization of the random variable Y &#8764;B(n,p), 
Z = Y&#8722;E[Y] follows approximately a standard normal distribution. Since a binomial is a sum of i.i.d. &#8730;
nVar(Y) 
zero/one random variables Xi (countingthe number of &#8221;trials&#8221; resulting in a &#8221;success&#8221;), we can think of 
Y as the sample mean of X1,...,Xn. n 
ThereforetheDeMoivre-Laplacetheoremisinfactalsoaresult onthestandardized meanofi.i.d. zero/one 
random variables. The Central Limit Theorem generalizes this to sample means of i.i.d. sequences from 
any other distribution with &#64257;nite variance. 
Theorem1 (Central Limit Theorem) Suppose X1,...,Xn is a random sample of size n fromagiven 
distribution with mean &#181; and variance &#963;2 &lt; &#8734;. Then for any &#64257;xed number x, 
lim P &#8730;nXn 
&#963; &#8722;&#181; &#8804;x =&#934;(x) 
n&#8594;&#8734; 
&#175; We say that &#8730;nXn convergesindistribution (some people also say&#8221;converges in law&#8221;) to a normal with 
mean &#181; and variance &#963;2, or in symbols: 
&#175;d &#8730;n(Xn &#8722;&#181;</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 2 While the last example is a little deceptive in that the normal approximation looks quite good for n 
as small as3(atleast optically), with n &#8594;&#8734;, we usually mean n &#8776;40 or larger for the approximation 
to be reasonably accurate. 
Summarizing, the Central Limit Theorem is particularly useful when we don&#8217;t want to compute the 
true p.d.f. of the sample mean. There are two situations in which this happens 
&#8226;	We can&#8217;t compute the actual p.d.f. because we don&#8217;t know the exact distribution of the Xi&#8217;s 
&#8226;	we don&#8217;t want to compute the actual p.d.f. because the computations are too tedious -which is 
almost invariably true for the general convolution formula (see last example), but also for many 
discrete examples(seeBinomial examplefromlastlecture). 
Estimation 
Sofarinthis class, we startedby assuming that weknewtheparameters of thedistribution of a random
variable -e.g. weknewthat X &#8764;P(&#955;)-and thencalculatedprobabilitiesand otherpropertiesof random
samples from that distribution. Now we are going to look at the reverse problem:
Assume that we have an i.i.d. sample of observations from a distribution with unknown parameters &#952;,
how do we get a &#8221;reasonable&#8221; answer which value of &#952; in the family of distributions we are looking at
may havegeneratedthedata.
Example2 If for a given coin we don&#8217;t know the probability for heads in a single toss, we could toss 
&#65533; Heads it many times. Then we&#8217;d think that the fraction of heads, p&#710;= may be a &#8221;good guess&#8221; for the &#65533; Tosses 
probability P(Heads)in a sense to be de&#64257;ned later. 
A parameter is a constantindexing afamily ofdistributionsgivenby thep.d.f.s f(x&#952;), where we denote |
parameters generally as &#952;1,...,&#952;k. 
Example3 for the binomial distribution, &#8226; 
&#9127; 
fX(xn,p)= &#9128; n
x px(1&#8722;p)n&#8722;x for x =0,1,...,n |&#9129; 0	 otherwise 
the parameters are the number of trials n and the success rate p. 
&#8226;	for the normal distribution, 
1 (x&#8722;&#181;)2 
fX(x&#181;,&#963;)= e&#8722;| &#8730;
2&#960;&#963; 2&#963;2
so that parameters are mean &#181; and standard deviation &#963;
&#8226;	the Poisson distribution has one parameter &#955; 
&#65533; e &#8722;&#955;&#955;x for x =0,1,2,... fX(x|&#955;)= 0 x! 
otherwise 
Much of statistics is concerned with determining which member of a known family of distributions gives 
the correct probability distribution of an observed process or phenomenon. In symbols, we want to &#64257;nd 
the parameter value &#952;0 such that X &#8764;f(x|&#952;0). Thisistheproblemof &#8221;estimating theparameterswhich 
characterizethedistribution.&#8221; 
We&#8217;ll always start o&#64256; a random sample X1,...,Xn, and we&#8217;ll always assume that 
X &#8764;f(x|&#952;0)for unknown &#952;0 &#8712;&#920; 
4 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec22/</lecture_pdf_url>
      <lectureno>22</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>&#65533;	 &#65533; is student-t distributed with n &#8722;1 degrees of freedom if the true mean is in fact &#181;0. Therefore we reject 
H0 if 
&#175;
T = Xn &#8722;7 &lt;t9(5%) 
S/&#8730;
10 
Plugginginthevaluesfromtheproblem, T = &#8722;&#8730;
10
..
58 
/10 &#8776;&#8722;2.066,whichissmallerthan t9(0.05) = &#8722;1.83. 
Example 4 Let Xi &#8764;Bernoulli(p), i =1,2,3. I.e. we are &#64258;ipping a bent coin three times independently, 
and Xi =1 if it comes up heads, otherwise Xi =0. We want to test H0 : p = 31 against HA : p = 32 . 
Since both hypotheses are simple, can use likelihood ratio test 
&#65533;3 &#65533;&#65533;Xi &#65533;&#65533;1&#8722;Xi P3 
3 T = f0(X)= i=1 31 
32 
=23&#8722;
Pi=1 Xi 
=23&#8722;2P
i=1 Xi 
fA(X) &#65533;3 &#65533; 2&#65533;Xi &#65533; 1&#65533;1&#8722;Xi Xi 3 
i=1 2i=1 3	 3 
Therefore, we reject if 
3 
23&#8722;2P
i3
=1 Xi &#8804;k (3&#8722;2 &#65533; 
Xi)log2&#8804;logk &#8660;
i=1 
which is equivalent to X&#175;3 &#8805;21 &#8722; logk . In order to determine k, let&#8217;s list the possible values of X&#175;3 and 6log2
their probabilities under H0 and HA, respectively: 
&#175;X3 Prob. under H0 Prob. under HA cumul. prob. under H0 
1 1 8 1 
27 27 27 2 6 12 7 
3 27 27 27 1 12 6 19 
3 27 27 27 
0 8	 1 127	 27 
So if we want the size of the test equal to &#945; = 27	 31 , we could reject if and only if X&#175;3 &gt; 2, or equivalently 
we can pick k = 21 . The power of this test is equal to 
8&#175; 1&#8722;&#946; = P(X3 =1|HA)=27 &#8776;29.63% 
Example 5 Suppose we have one single observation generated by either 
f0(x)=	2x if0 &#8804;x &#8804;1 or fA(x)= 2&#8722;2x if0 &#8804;x &#8804;1 
0 otherwise 0 otherwise 
&#8226;	Find thetestingprocedurewhich minimizesthesumof &#945;+&#946; -dowerejectif X =0.6? Since we only 
have one observation X, it&#8217;s not too complicated the critical region directly in terms of X, and there 
is nothing to be gained by trying to &#64257;nd some clever statistic (though of course Neyman-Pearson 
would still work here). By looking at a graph of the densities, we can convince ourselves that the 
test should reject for small values of X. The probability of type I and type II error is, respectively, 
&#65533; k 
&#945;(k)= P(rejectH0)= 2xdx = k2|
0 
for 0 &#8804;k &#8804;1, and 
&#65533; 1 
&#946;(k)= P(don&#8217;t reject|HA)= 
k (2&#8722;2x)dx =2(1&#8722;k)&#8722;1+k2 =1&#8722;k(2&#8722;k) 
5 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; &#65533; 
&#65533; 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 22 
Konrad Menzel 
May 7, 2009 
Proposition 1 (Neyman-Pearson Lemma) In testing f0 against fA (where both H0 and HA are 
simple hypotheses), the critical region 
f0(x)C(k)= x : &lt;k fA(x) 
is most powerful for any choice of k &#8805;0. 
Note that the choice of k depends on the speci&#64257;ed signi&#64257;cance level &#945; of the test. This means that the 
most powerful test rejects if for the sample X1,...,Xn,the likelihood ratio 
f0(X1,...,Xn) r(X1,...,Xn)= fA(X1,...,Xn) 
is low, i.e. the data is much more likely to have been generated under HA. 
Reject Fo(x) 
FA(x) 
Cx(k) r(x)= 
k 
&#65533;A &#65533;o 
The most powerful test given in the Neyman-Pearson Lemma    Image by MIT OpenCourseWare.
explicitly solves the trade-o&#64256; between 
size &#65533; 
&#945; = P(reject H0) = f0(x)dx |
C(k) 
andpower 
1&#8722;&#946; = P(reject|HA)= fA(x)dx 
C(k) 
1 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 
&#65533; 2 Examples 
Example 2 Assume thatbabies&#8217; weights(inpounds) atbirth aredistributed according to X &#8764;N(7,1). 
Now suppose that if an obstetrician gave expecting mothers poor advice on diet, this would cause babies 
to be on average 1 pound lighter (but have same variance). For a sample of 10 live births, we observe 
&#175;X10 =6.2. 
&#8226;	How do we construct a 5% test of the null that the obstetrician is not giving bad advice against the 
alternative that he is? We have 
H0 : &#181;=7 against HA : &#181;=6 
We showed that for the normal distribution, it is optimal to base this simple test only on the sample 
&#175;	 &#175; &#175; mean, X10, so that T(x)= x&#175;10. Under H0, X10 &#8764;N(7,0.1) and under HA, X10 &#8764;N(6,0.1). The 
test rejects H0 if X&#175;10 &lt;k. We therefore have to pick k in a way that makes sure that the test has 
size5%,i.e. 
0.05 = P(X&#175;10 &lt;k&#181;=7) =&#934; k&#8722;7 | &#8730;
0.1 
where &#934;()is the standard normal c.d.f.. Therefore, we can obtain k by inverting this equation &#183;
1.645 k =7+&#8730;
0.01&#934;&#8722;1(0.05) &#8776;7&#8722;&#8730;
10 &#8776;6.48 
Therefore, we reject, since X&#175;10 =6.2 &lt; 6.48 = k. 
&#8226;	What is the power of this test? 
&#175;P( &#181;=6) =&#934;6.48&#8722;6 X10 &lt; 6.48| &#8730;
0.1 &#8776;&#934;(1.518) &#8776;93.55% 
&#8226;	Suppose we wanted a test with power of at least 99%, what would be the minimum number n of 
newborn babies we&#8217;d have to observe? The only thing that changes with n is the variance of the 
sample mean, so from the &#64257;rst part of this example, the critical value is kn = 1.645 7&#8722;&#8730;n , whereas the 
&#175; power of a test based on Xn and critical value kn is 
&#175; 1&#8722;&#946; = P(Xn &lt;kn|&#181;=6) =&#934; &#65533;&#8730;n &#8722;1.645 
Setting 1&#8722;&#946; &#8805;0.99, we get the condition 
&#8730;n &#8722;1.645 &#8805;&#934;&#8722;1(0.99) =2.326 n &#8805;3.9712 &#8776;15.77 &#8660;
This type of power calculations is frequently done when planning a statistical experiment or survey 
-e.g. in order to determine how many patients to include in a drug test in order to be able to detect 
an e&#64256;ect of a certain size. Often it is very costly to treat or survey a large number of individuals, 
so we&#8217;d like to know beforehand how large the experiment should be so that we will be able to detect 
any meaningful change with su&#64259;ciently high probability. 
Example 3 Suppose we are still in the same setting as in the previous example, but didn&#8217;t know the 
variance. Instead, we have an estimate S2 =1.5. How would you perform a test? As we argued earlier, 
the statistic &#175;Xn &#8722;&#181;0T := S/&#8730;n &#8764;tn&#8722;1 
4 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; at every point x in the sample space (where the integrals are over many dimensions, e.g. typically 
f0(x)x &#8712;Rn). Fromtheexpressionsfor &#945; and1&#8722;&#946; wecanseethatthelikelihood ratio fA(x) gives the &#8221;price&#8221; 
ofincluding x with the critical region in terms of how much we &#8221;pay&#8221; in terms of size &#945; relativetothe 
gain in power from including the point in the critical region CX. 
Therefore, we should start constructing the critical region by including the &#8221;cheapest&#8221; points x -i.e. 
thosewith asmalllikelihood ratio. Thenwecangodownthelistof x ordered according tothelikelihood 
ratio and continue including more points until the size &#945; ofthetestisdowntothedesiredlevel. 
Example 1 A criminal defendant (D) is on trial for a purse snatching. In order to convict, the jury 
must believe that there is a 95% chance that the charge is true. 
There arethreepotentialpieces of evidencetheprosecutor may or may nothavebeen abletoproduce, and 
inagivencasethejury takesadecisiontoconvictbased only onwhich out of thethreecluesitispresented 
with. Below are the potential pieces of evidence, assumed to be mutually independent, the probability of 
observing each piece given the defendant is guilty, and the probability of observing each piece given the 
defendant is not guilty 
guilty not guilty likelihood ratio 
1. D ran when he saw police coming 0.6 0.3 1/2 
2. D has no alibi 0.9 0.3 1/3 
3. Empty purse found near D&#8217;s home 0.4 0.1 1/4 
In the notation of the Neyman-Pearson Lemma, x can be any of the 23 possible combinations ofpieces 
of evidence. Using theassumptionofindependence, we canthereforelistallpossible combinationsof clues 
with their respective likelihood under each hypothesis and the likelihood ratio. I already ordered the list by 
the likelihood ratios in the third column. In the last column, I added 
&#945;(k)= f0(x) 
r(x)&#8804;k 
the cumulative sum over the ordered list of combinations x. 
guilty fA(x) not guilty f0(x) likelihood ratio r(x)= f0(x) &#945;(k)fA(x) 
1. all three clues 216/1000 9/1000 0.0417 9/1000 
2. no alibi,found purse 144/1000 21/1000 0.1458 30/1000 
3. ran,no alibi 324/1000 81/1000 0.25 111/1000 
4. no alibi 216/1000 189/1000 0.875 300/1000 
5. ran,found purse 24/1000 21/1000 0.875 321/1000 
6. found purse 16/1000 49/1000 3.0625 370/1000 
7. ran 36/1000 189/1000 5.25 559/1000 
8. none of the clues 24/1000 441/1000 18.375 1 
The jury convicting the defendant only if there is at least 95% con&#64257;dence that the charge is true 
correspondsto aprobability offalse conviction(i.e. ifthedefendantisinfactinnocent) ofless than5%. 
In the terminology of hypothesis test, the sentence corresponds to a rejection of the null hypothesis that 
the defendant is innocent using the most powerful test of size &#945; =5%. 
Looking at the values of &#945;(k) in the last column of the table, we can read o&#64256; that including more than 
2 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>1 the &#64257;rst two combinations of the evidence raises the probability of a false conviction &#945; to more than 5%. 
Therefore,thejury should convictthedefendantifhedoesn&#8217;thavean alibi and the emptypurse wasfound 
nearhishome, regardless whetherhe ran whenhe sawthepolice. Inprinciple,thejury couldin addition 
randomize whenthedefendant ran,had no alibi,but nopurse wasfound(thatis case3): ifinthat case, 
thejury convictedthedefendant withprobability 50&#8722;30 1 
81 &#8776;4, the probability of a false conviction would be 
exactly equal to5%,but this wouldprobably notbe considered an acceptablepracticein criminaljustice. 
Construction of Tests 
In general there is no straightforward answer to how we should construct an optimal test. The Neyman&#173;
PearsonLemmagaveusasimplerecipeforamostpowerful test of onesimplehypothesisagainst another, 
but in most real-world applications, the alternative hypothesis is composite. The following is a list of 
recommendationswhichdo not alwayslead toauniformly mostpowerful test(which sometimesdoesnot 
even exist), but usually yield reasonable procedures: 
1. if both H0 and HA are simple, the Neyman-Pearson Lemma tells us to construct a statistic
f0(x)
T(x)= fA(x) 
and reject if T(X)&gt;k for some appropriately chosen value k (typicallyk is chosen in a way that 
makes sure that the test has size &#945;). This test is also called the likelihood ratio test (LRT). 
2. if H0 : &#952; = &#952;0 is simple and HA : &#952; &#8712; &#920;A is composite and 2-sided, we construct a 1 &#8722;&#945; 
con&#64257;dence interval [A(X),B(X)] (usually symmetric) using an estimator &#952;&#710;. We then reject if 
&#952;0 &#8712;/[A(X),B(X)]. This gives us a test of size &#945; for H0. 
3. if H0 : &#952; = &#952;0 is simple and HA : &#952; &#8712;&#920;A is composite and one-sided, we construct a symmetric 
1&#8722;2&#945; con&#64257;denceintervalfor &#952; and reject only if the null value is outside the con&#64257;dence interval 
and in the relevant tail in order to obtain a size &#945; test. 
4.	either H0 : &#952; &#8712;&#920;0 or HA : &#952; &#8712;&#920;A composite(orboth): de&#64257;nethe statistic 
T(x)= max&#952;&#8712;&#920;0 L(&#952;) = max&#952;&#8712;&#920;0 f(x|&#952;) 
max&#952;&#8712;&#920;A&#8746;&#920;0 L(&#952;) max&#952;&#8712;&#920;A&#8746;&#920;0 f(x|&#952;) 
and reject if T(X)&lt;k for some appropriately chosen constant k. This type of test is called the 
generalized likelihood ratio test (GLRT). 
Since we haven&#8217;t discussed the last case yet, some remarks are in order: 
&#8226;	the test makes sense because T(X)will tend to be small if the data don&#8217;t support H0 
&#8226;	densities are alwayspositive, so the statistic willbebetween0 and1(thisisbecause the set over 
which the density is maximized in the denominator contains the set over which we maximize in the 
numerator) 
&#8226;	we need to know the exact distribution of the test statistic under the null hypothesis, so that we 
can &#64257;nd an appropriate critical value k. For most distributions we have that in large samples 
&#8722;2logT(X)&#8764;&#967;2 
p 
where p=dim(&#920;0 &#8746;&#920;A)&#8722;dim(&#920;0). 
&#8226;	the GLRT does not necessarily share the optimality properties of the LRT, in fact in this setting 
with a composite alternative hypothesis a uniformly most powerful test often does not even exist. 
3 </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>&#65533;Therefore, minimizing the sum of the error probabilities over k,
min {&#945;(k)+&#946;(k)}=min {k2 +1 &#8722;k(2&#8722;k)}=min {2k2 +1 &#8722;2k}
k k	 k 
Setting the &#64257;rst derivative of the minimand to zero, 
1 0 =4k&#8722;2 &#8660;k =2 
Therefore we should reject if X&lt; 21, and &#945; = &#946; = 41 . Therefore, we would in particular not reject 
H0 for X =0.6. 
&#8226;	Among all tests such that &#945; &#8804;0.1, &#64257;nd the test with the smallest &#946;. What is &#946;? Would you reject if 
X =0.4? -&#64257;rst we&#8217;ll solve &#945;(k)=0.1 for k. Using the formula from above, k&#175;= &#8730;
0.1. Therefore, 
&#175; &#946;(k&#175;)=1&#8722;2k&#175;+ k2 =1.1&#8722;2&#8730;
0.1 &#8776;46.75% 
Since k = &#8730;
0.1 &#8776;0.316 &lt; 0.4, we don&#8217;t reject H0 for X =0.4. 
Example 6 Suppose we observe an i.i.d. sample X1,...,Xn, where Xi &#8764;U[0,&#952;], and we want to test 
H0 : &#952; = &#952;0 against HA : &#952; = &#952;0,&#952; &gt; 0 
There are two options: we can either construct a 1&#8722;&#945; con&#64257;denceintervalfor &#952; and reject if it doesn&#8217;t 
cover &#952;0. Alternatively, we could construct a GLRT test statistic 
L(&#952;0)T = max&#952;&#8712;R+ L(&#952;) 
Thelikelihoodfunctionisgivenby 
n &#65533;&#65533; &#65533;n &#65533;	 1 for0 &#8804;Xi &#8804;&#952;,i =1,...,n L(&#952;)= fX(Xi|&#952;)= 0 &#952;</text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec24/</lecture_pdf_url>
      <lectureno>24</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; &#65533; &#65533; Therefore, 
n &#65533;&#65533;Yi &#65533;&#65533;1&#8722;Yi &#65533;&#65533;Pn Yi &#65533;&#65533;Pn (1&#8722;Yi) &#65533; k k k i=1 k i=1
= 1&#8722; L(&#952;)= 1&#8722;&#952; &#952; &#952; &#952; i=1 
Taking logs, 
n &#65533;&#65533; n &#65533;&#65533; &#65533; k &#65533; k L(&#952;)=logL(&#952;)= Yi log 1&#8722; + n &#8722; Yi log &#952; &#952; i=1 i=1 
Setting the derivative with respect to &#952; to zero, 
( &#65533;n
i=1 Yi) k (n &#8722; &#65533;n
i=1 Yi) k n n 
0= k &#952;2 &#8722; k &#952;2 &#8660; Yi k = n &#8722; Yi (&#952;&#8722;k)1&#8722;&#952; &#952; i=1 i=1 
Solving for &#952;,
nk k
&#952;&#710;ML = &#65533;n = n &#8722; i=1 Yi 1&#8722;Y&#175;n 
Notice that this estimator works even if k&gt;&#952;. 
2. Hypothesis Testing Supposethat X1,...,Xn form a random sample from a normal distribution 
with an unknown mean &#181; and a known variance &#963;2 equal to1. 
(a) State the critical region that yields the most powerful test of 
H0 : &#181;=0 
HA : &#181;=1 
at the 5% signi&#64257;cance level. Calculate the power of this test. 
(b) State the critical region that yields the most powerful test of 
H0 : &#181;=1
HA : &#181;=0
at the 5% signi&#64257;cance level. 
&#175; (c) Forwhat valuesof n and Xn willyouacceptthehypothesisthat &#181; =0inpart (a) and simultaneously 
acceptthehypothesisthat &#181;=1inpart (b)? 
(d) State the critical region that yields the uniformly most powerful test of 
H0 : &#181;=0 
HA : &#181;&gt; 1 
at the 5% signi&#64257;cance level. State the formula for, and then graph the power function 1&#8722;&#946;(&#181;) of this 
test. 
(e) How are the critical regions of the tests in parts (a) and (d) related? How are the probabilities of 
committing a type II error related? 
Answers: 
5 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 
&#65533; 
&#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; &#8226;	in case(ii) form statistic 
2
T =(n1 &#8722;1)&#710;sX
(n2 &#8722;1)&#710;s2 
Z 
whichis F(n1&#8722;1,n2&#8722;1)distributed underthenullhypothesis,and werejectif either T &lt;F&#8722;1 &#945; 
&#65533;&#65533;	 2 
orif T &gt;F&#8722;1 1&#8722;&#945; 
2 . 
SampleQuestions(Spring2000Exam) 
1. Method of Moments The random variables X1,...,Xn are independent draws from a continuous 
uniformdistributionwith support[0,&#952;]. Youknowfromyoutimein14.30 thatyoucanuseeithermethod 
of moments or maximum likelihood to derive an estimator for &#952; from the sample of Xi. But you want a 
small challenge, so you de&#64257;ne new random variables Y1,...,Yn suchthat 
Yi =0 if Xi &#8804;k 
1 if Xi &gt;k 
where k is a constant determined by and known to you. you can estimate &#952; only using Y1,...,Yn. 
(a) Assume k &#8712;(0,&#952;). Use thee method of moments to derive an estimator for &#952; as a function of the Yi. 
Also explain why you need k tobeintheinterval(0,&#952;). 
(b) Nowassume k &#8712;(0,&#8734;)and that k maybegreaterthanorlessthantheunknownparameter &#952;.What 
can you say about the relationship between k and &#952; if you observe a random sample with Y&#175;n =0? 
(c) Derive the maximum likelihood estimator for &#952; (remember that you can stillonly use Y1,...,Yn for 
the estimation). 
Answers: 
(a) Since &#952; isone-dimensional, onlyhavetouse &#64257;rstmoment of Yi.Thepopulationexpectationisgiven 
by 
k E&#952;[Yi]= P&#952;(Xi &#8805;k)=max 1&#8722; ,0 &#952;
If k&lt;&#952;, the method of moments estimator is obtained by solving 
Y&#175;n = E&#952;[Yi]=1&#8722; k
&#952;&#710;&#8660;&#952;&#710;=1&#8722; k
Y&#175;n 
(b) If k&gt;&#952;, E&#952;[Yi]= P(Xi &#8805;k) =max 1&#8722;k
&#952;,0 = 0 does not depend on &#952; anymore. If we don&#8217;t 
know whether k is greater or less than &#952;, we can use the same reasoning as in the construction of 
the method of moments estimator to bound the parameter &#952; setting 
k k k Y&#175;n = max 1&#8722;
&#952;&#710;,0 &#8805;1&#8722;
&#952;&#710;&#8660;&#952;&#710;&#8804; Y&#175;n1&#8722; 
If Y&#175;n =0 for a large sample, k islikely tobegreaterthan &#952;. 
(c) In order to derive the likelihood function, note that 
k P&#952;(Yi =1) = P&#952;(Xi &#8805;k)=1&#8722;&#952; 
4 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#8226;	testing procedure: reject H0 if T(X)&#8712;C 
The choice of C determines
&#945; = P(type Ierror) = P(rejectH0)
|
&#946; = P(type IIerror) = P(don&#8217;t rejectHA)|
alpha is called the size, and 1 &#8722;&#946; the power ofthetest. 
&#8226;	for two tests with same size &#945;, prefer test with greater power 1 &#8722;&#946; 
&#8226;	if &#946; = &#946;(&#952;)would prefer test with lower &#946;(&#952;)for all values of &#952;, uniformly most powerful test 
&#8226;	H0 and HA both simple: by Neyman-Pearson Lemma, most powerful test is of form &#8221;reject if 
f(x|&#952;0 ) &lt;k&#8221; f(X|&#952;A) 
&#8226;	test of the form &#8221;reject if g(T(X))&lt;g(k) for some monotone function identical to test &#8221;reject if 
T(X)&lt;k&#8221; 
Construction of tests depends on form of hypotheses H0 and HA: 
1. both H0 and HA simple: likelihood ratio test
f0(x)
T(x)= fA(x) 
and reject if T(X)&lt;k for some appropriately chosen value k (mostpowerfulbyNeyman-Pearson 
Lemma) 
2. H0 : &#952; = &#952;0 simple, HA : &#952; &#8712;&#920;A composite and 2-sided: construct a 1 &#8722;&#945; con&#64257;denceinterval 
[A(X),B(X)]and reject if &#952;0 &#8712;/[A(X),B(X)] 
3. H0 : &#952; = &#952;0 simple, HA : &#952;&gt;&#952;0 composite and one-sided: construct a 1 &#8722;2&#945; con&#64257;denceinterval 
[A(X),B(X)]for &#952; and reject if &#952;0 &lt;A(X). 
4.	general case: Generalized Likelihood Ratio Test statistic 
T(x)= max&#952;&#8712;&#920;0 L(&#952;) = max&#952;&#8712;&#920;0 f(x|&#952;) 
max&#952;&#8712;&#920;A&#8746;&#920;0 L(&#952;) max&#952;&#8712;&#920;A&#8746;&#920;0 f(x|&#952;) 
and reject if T(X)&lt;k for some appropriately chosen constant k 
Two-SampleTests 
have two independent samples X1,...,Xn1 and Z1,...,Zn2 where Xi &#8764;N(&#181;X,&#963;2 ) and Zi &#8764; &#8226;	X
N(&#181;Z,&#963;2 )i.i.d. Z
&#963;2 &#963;2 &#8226;	wanttotest either(i) H0 : &#181;X = &#181;Z vs. HA : &#181;X &#65533;= &#181;Z or (ii)H0 : &#963;X 2 = Z vs. HA : &#963;X 2 &#65533;= Z 
&#8226;	in case(i) form statistic 
&#175; &#175; Xn1 &#8722;Zn2T = &#65533; 
&#963;2 &#963;2 
X Z+ n1 n2 
whichis N(0,1) under the null hypothesis. 
3 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; 
&#8226;	&#65533;
&#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 24 
Konrad Menzel
May 14, 2009
Review 
PointEstimation 
Estimatorfunction &#952;&#710;(X1,...,Xn)of the sample &#8226; 
bias of estimator is &#8226; 
Bias(&#952;&#710;)= E&#952;0 [&#952;&#710;]&#8722;&#952;0 
&#8226;	standard error of estimator given by 
&#963;(&#952;&#710;)= Var(&#952;&#710;)
Important criteria for assessing estimators are
Unbiasedness
 &#8226; 
&#8226;	E&#64259;ciency 
&#8226; Consistency
Methods for constructing Estimators:
1. Method of Moments:
mth population moment is E&#952;[Xim]= &#181;m(&#952;)
&#8226;	mth sample moment is Xm = n 1 
in 
=1 Xim 
compute &#64257;rst k moments, equate Xm = ! &#181;m(&#952;&#710;)for m =1,...,k, and solve for the estimate &#952;&#710;. &#8226; 
2.	Maximum Likelihood 
&#8226;	write down likelihood function for the sample X1,...,Xn, 
n 
L(&#952;)= f(X1,...,Xn&#952;)= f(Xi&#952;) |
i=1 |
&#8226;	&#64257;nd value of &#952; which maximizes L(&#952;)or log(L(&#952;)). 
&#8226;	usually &#64257;nd maximum by setting &#64257;rst derivative to zero, but if support of random variable 
depends on &#952; may not be di&#64256;erentiable, so you should rather try to see what function looks 
like, and where the maximum should be. 
1 </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>&#65533;
&#65533; &#65533; &#65533; 
&#65533; &#65533; &#175;&#65533; &#65533; (a) According to the Neyman-Pearson lemma, the most powerful test is based on the likelihood ratio 
&#65533;n 1&#65533; 1 n 2 &#65533;&#65533; n &#65533; 
f(xi&#181;=0) &#8730;
2&#960; exp 2 i=1 xi n &#65533; 
r(x)= &#65533;i
n =1 |= 1&#65533; 1 &#8722;
&#65533;n (xi &#8722;1)2 &#65533; = exp 2 &#8722; xi 
i=1 f(xi|&#181; =1) &#8730;
2&#960; exp 2 i=1 i=1 &#8722;
The most powerful test rejects if the likelihood ratio is less than the critical value, or equivalently,
if X&#175;n &gt;k for some appropriately chosen value of k (onthe examit&#8217;s su&#64259;cienttopoint outthat we
already derived this in class).
Since under the null hypothesis, X&#175;n &#8764;N(0,1/n),
PX&#175;n &gt;k &#65533; &#181;=0 =1&#8722;&#934;(&#8730;nk) 
so choosing k = &#934;&#8722;1
&#8730;(1
n &#8722;&#945;) gives a test of size 5%. The power of this test is given by 
PXn &gt;k &#181;=1 =1&#8722;&#934;(&#8730;n(k&#8722;1)) 
(b) By similarreasoning asinpart (a),themostpowerful test rejectsif X&#175;n &lt;k&#65533;,where k&#65533;=1+&#934;&#8722;
&#8730;1 
n (&#945;) . 
(c) We&#8217;ll accept in both tests if 
&#175; k&#65533;&#8804;X&#175;n &#8804;k &#8660;&#8730;n +&#934;&#8722;1(&#945;)&#8804;&#8730;nXn &#8804;&#934;&#8722;1(1&#8722;&#945;) 
&#175; For su&#64259;ciently large n, there will be no values of Xn for which none of the tests rejects. 
(d) Thistestisthe same asinpart (a), because for any value of &#181;&gt; 1, the likelihood ratio is a strictly 
decreasing function in the sample mean X&#175;n, and the critical value k for a size &#945; testisdetermined 
only by the distribution under the null hypothesis, which is the same as in part (a). 
(e) The critical regions arethe same,buttheprobability of atypeII errorinpart(d) is smaller, since 
all alternatives are further away from the null than &#181;=1. 
6 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533;	 &#65533; &#65533;	 &#65533; 
&#65533;	 &#65533; &#65533;	 &#65533; Con&#64257;denceIntervals 
&#8226;	&#64257;nd functions of data A(X1,...,X2)and B(X1,...,Xn)such that
P&#952;0 (A(X1,...,Xn)&#8804;&#952;0 &#8804;B(X1,...,Xn))=1&#8722;&#945;
&#8226;	then[A(X1,...,Xn),B(X1,...,Xn)]is a1&#8722;&#945; con&#64257;denceintervalfor &#952; 
&#8226; for given signi&#64257;cance level 1&#8722;&#945; many possible valid con&#64257;dence intervals.
In order to construct con&#64257;dence intervals, usually proceed as follows:
1.	&#64257;nd a(&#952;0)and b(&#952;0)such that 
P&#952;0 (a(&#952;0)&#8804;T(X1,...,Xn)&#8804;b(&#952;0))=1&#8722;&#945;
for some statistic T(X1,...,Xn)(typicallywill use an estimator &#952;&#710;here).
2. rewrite the event inside the probability in form
P(A(X1,...,Xn)&#8804;&#952;0 &#8804;B(X1,...,Xn))=1&#8722;&#945;
3.	evaluate A()and B()at the sample values X1,...,Xn to obtain con&#64257;dence interval &#183; &#183;
Some important cases:
&#952;&#710;unbiased and normally distributed, Var(&#952;&#710;)known:
 &#8226; 
[A(X1,...,Xn),B(X1,...,Xn)]= &#952;&#710;+&#934;&#8722;1 &#65533; &#945;&#65533; &#65533; &#945;&#65533; 
Var(&#952;&#710;),&#952;&#710;+&#934;&#8722;1 1&#8722; Var(&#952;&#710;)2	 2 
&#952;&#710;unbiased and normally distributed, Var(&#952;&#710;)not known, but have estimator S&#710;: &#8226; 
[A(X1,...,Xn),B(X1,...,Xn)]= &#952;&#710;+ tn&#8722;1 &#65533; &#945;&#65533; &#65533; &#945;&#65533; 
Var(&#952;&#710;),&#952;&#710;+ tn&#8722;1 1&#8722; Var(&#952;&#710;)2	 2 
&#952;&#710;not normal, n&gt; 30 or so: most estimators we have seen so far turn out to be asymptotically &#8226; 
normally distributed, so we&#8217;ll use that approximation and calculate con&#64257;dence intervals as in the 
previouscase. Whetherornotweknowthevariance,weusethet-distributionasaway ofpenalizing 
the CI for using approximation. 
&#952;&#710;not normal, n small:if(a) weknowthep.d.f. of &#952;&#710;,canconstructCIsfrom &#64257;rstprinciples. if(b) &#8226; 
we don&#8217;t know the p.d.f., there&#8217;s nothing we can do. 
HypothesisTesting 
&#8226;	hypotheses H0 : &#952; &#8712;&#920;0 against HA : &#952; &#8712;&#920;A 
&#8226;	test statistic T(X)some function of data which takes di&#64256;erent distributions under the null and the 
alternative 
&#8226;	critical region C: regions of realizations of T(X)for which we reject the null hypothesis 
2 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec14/</lecture_pdf_url>
      <lectureno>14</lectureno>
      <slides>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; This result is also known as the ANOVA identity, where ANOVA stands for Analysis of Variance. In 
particular, since Var(Y|X)&#8805;0,itfollowsthat 
Var(Y)&#8805;E[Var(Y|X)] 
which can, loosely speaking, be read as &#8221;knowing X decreases the variance of Y.&#8221; 
Proof: We can rewrite 
&#65533; &#65533;&#65533;&#65533; &#65533;&#65533; &#65533;&#65533; 
Var(E[Y|X])+E[Var(Y|X)] = E[E[Y|X]2]&#8722;(E[E[Y|X]])2 + EE[Y2|X] &#8722;EE[Y|X]2 
= E[E[Y|X]2]&#8722;E[Y]2 + E[Y2]&#8722;E[E[Y|X]2] 
= E[Y2]&#8722;E[Y]2 =Var(Y) 
wherethe &#64257;rstequality usesthepropertyVarX = E[X2]&#8722;E[X]2,thesecond step usesthelawofiterated 
expectations, and in the last step the &#64257;rst and last term cancel, which completes the argument &#65533; 
Example4 Each year, a &#64257;rm&#8217;s R&amp;D department produces X innovations according to some random 
process, where E[X] =2 and Var(X) =2. Each invention is a commercial success with probability 
p=0.2 (assume independence). The number of commercial successes in a given year are denoted by S. 
(a) Supposewehave5 newinnovationsthisyear. Whatistheprobability that S of them are commercial 
successes? -the conditional p.d.f of S given X =5 is that of a binomial, so e.g. 
P(S =2|X = x)= 5
3(0.2)3(1&#8722;0.2)2 &#8776;0.05 
(b) Given 5 innovations, what is the expected number of successes? -since S|X =5 &#8764;B(5,0.2), we 
can use the result from last class 
E[SX =5] = E[B(5,0.2)] =0.25 =1 | &#183; 
(c) What is the unconditional expected value of innovations? -By the law of iterated expectations, 
E[S]= E[E[SX]]= E[pX]=0.2E[X]=0.22 =0.4 | &#183; 
since we assumed E[X]=2. 
(d) What is the unconditional variance of S? -Recall the law of total variance: 
Var(S) = Var(E[SX])+E[Var(SX)] | |
= Var(Xp)+E[p(1&#8722;p)X]= p 2Var(X)+p(1&#8722;p)E[X]=0.042+0.162 =0.4 &#183; &#183; 
This is an example of a mixture of binomials, i.e. conditional on X, we have a binomial distribution for 
S. We can then use the law of iterated expectations to obtain the total number of successes. 
Example5 (IEM Political Markets, continued) If we look at the Republican primaries last year, much 
of the uncertainty already was resolved by Super Tuesday. Say, the conditioning variable Xt isthenumber 
4 </text>
        </slide>
        <slide>
          <slideno>11</slideno>
          <text>&#65533; &#65533; &#65533; &#65533; &#65533; &#65533; 
&#65533; for a standard normal random variable Z 
2. restatetheprobability intermsofthestandard normal c.d.f.,&#934;(): &#183;
a &#8722;&#181; b&#8722;&#181; b&#8722;&#181; a &#8722;&#181;P =&#934; &#963; &#8804;Z &#8804; &#963; &#963; &#8722;&#934; &#963; 
3. look up the values for the values of the standard normal c.d.f. at the values calculated above in 
order to obtain the probability. 
2.4 Digression: Drawing Standard Normal Random Variables 
We already sawthatitispossibleto convert uniform randomdrawsto any other continuousdistribution 
via theintegral transformation(see thelectures on transformations of random variables). Whatifyou 
don&#8217;t have a computer? Around 1900, the famous statistician Francis Galton came up with a clever 
mechanical device for simulating normal random variables using dice:1 
The three di&#64256;erent dice shown in Figure 3 were rolled one after another, while the experimenter &#64257;lls up 
alistof randomdrawsinthefollowing manner:the &#64257;rstdiegivestheactual values(youalwaysread o&#64256; 
what is on the bottom of the side of the die facing you), where the stars are &#64257;rst left empty, and later 
&#64257;lled up with rolls of the second die. Finally, the third die gives sequences of pluses and minuses which 
are put in front of the draws put down as we went along with the &#64257;rst two dice. 
The numbers on the dice were speci&#64257;cally chosen as evenly spaced percentiles of the positive half of 
the standard normal distribution in order to ensure that the outcome would in fact resemble a standard 
normal random variable. 
2.5 Functions of Standard Normals: chi-squared, t-and F-distribution 
Due to the importance of the standard normal distribution for estimation and testing, some functions of 
standard normal random variables also play an important role and are frequently tabulated in statistics 
tests. For now we&#8217;lljustgivede&#64257;nitionsfor completeness,but we&#8217;llgetback to applicationsin thelast 
third of the class. I&#8217;m notgoing togivethe correspondingp.d.f.s sincethey are oflimitpractical usefor 
us. 
De&#64257;nition 6 If Z1,Z2,. . . ,Zk are independent with Zi &#8764;N(0,1), Y 
chi-squared distribution with k degrees of freedom, in symbols = &#65533;k 
i=1 Z2 
i is said to follow a 
Y &#8764;&#967;2 
k 
Here &#8221;degrees of freedom&#8221; refers to the number of independent draws that are squared and summed up. 
The expectation of a chi-squared is given by the degrees of freedom, 
k 
Y &#8764;&#967;2 
k &#8658;E[Y]= E[Xi 2]= k 
i=1 
De&#64257;nition7 If X &#8764;N(0,1) and Y &#8764;&#967;2 , then k
Z T = &#8730;
Y &#8764;tk 
is said to follow the (student)t-distribution with k degrees of freedom. 
1See Stigler, S. (2002): Statistics on the Table 
11 </text>
        </slide>
        <slide>
          <slideno>12</slideno>
          <text>Values for D ie I 
Values for D ie II 
Values for D ie III 0.03 0.51 1.04 1.78 
2.29 2.51 2.77 3.25 
2.32 2.55 2.83 3.36 
2.35 2.59 2.90 3.49 
2.39 2.64 2.98 3.65 
2.43 2.68 3.06 4.00 
2.47 2.72 3.15 4.55 0.11 0.59 1.14 1.95 
0.19 0.67 1.25 2.15 
0.27 0.76 1.37 (2.40) 
0.35 0.85 1.50 (2.75) 
0.43 0.94 1.63 (3.60) 
+ + + + 
+ + _ + 
+ + _ _ 
+ _ + + 
+ _ + _ + + + _ _ _ + + 
_ _ + _ 
_ _ _ + 
_ _ _ _ 
+ + + 
+ + _ + _ + 
+ _ _ 
_ + + 
_ + _ 
_ _ + 
_ _ _ + _ _ + 
+ _ _ _ 
_ + + + 
_ + + _ 
_ + _ + 
_ + _ _ 
Figure 3: Three types of Galton&#8217;s dice. They are 1.25 in. cubes, date from 1890,     Image by MIT OpenCourseWare.
and are used for
simulating normally distributed random numbers. Adapted from Stigler, S. (2002): Statistics on the 
Table: The History of Statistical Concepts and Methods 
12 </text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>&#65533; &#65533; What is the p.d.f. of X? By the change of variables formula we saw earlier in this class, 
fX(x)=1 x &#8722;&#181; 1 &#8722;(x&#8722;&#181;)2 
e &#963;&#981; &#963;2 = &#8730;
2&#960;&#963; 2&#963;2 
We can extend the same argument by noting that the linear transformation of a normal random variable 
X1 is again normal. 
Proposition3 If X1 &#8764;N(&#181;,&#963;2)and X2 = a + bX1, then 
X2 &#8764;N(a + b&#181;,b2&#963;2) 
You can check this again using the change of variables formula. 
Wealreadysawthattheexpectationof thesumof n variables X1,...,Xn isthesumoftheirexpectations, 
and that the variance of n independent random variables is the sum of their variances. If the Xi&#8217;s are 
also normal, then their sum is as well: 
Proposition4 If X1,...,Xn are independent normal random variables with Xi &#8764;N(&#181;i,&#963;2), then i &#65533; &#65533; n n n &#65533; &#65533; &#65533; 
Y = Xi &#8764;N &#181;i, &#963;2 
i 
i=1 i=1 i=1 
While in the general, we&#8217;d have to go through the convolution formula we saw a few weeks ago, for the 
sum of normals, we therefore only have to compute the expectation and variance of the sum, and know 
the p.d.f. of the sum right away: 
P
1 &#8722;(y&#8722;P &#181;i)2 
fY (y)= &#65533;&#65533; e 2 &#963;2 
i 
2&#960;&#963;i 2 Density 
0 .2 .4 .6 .8 
sigma=0.5 
sigma=1 
sigma=2 
&#8722;5 0 5 
z 
Figure 2: Normal Density for Di&#64256;erent Values of &#963; 
2.3.2 Using Tabulated Values of the Standard Normal 
If X &#8764;N(&#181;,&#963;), we can give a roughestimate of the probability with which X is no further than one or 
two standard deviations away from its mean: 
P(&#181;&#8722;1&#963; &#8804;X &#8804;&#181;+1&#963;)=&#934;(1)&#8722;&#934;(&#8722;1) &#8776; 68% 
P(&#181;&#8722;2&#963; &#8804;X &#8804;&#181;+2&#963;)=&#934;(2)&#8722;&#934;(&#8722;2) &#8776; 95% 
P(&#181;&#8722;3&#963; &#8804;X &#8804;&#181;+3&#963;)=&#934;(3)&#8722;&#934;(&#8722;3) &#8776; 99.7% 
9 </text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; &#65533; n=5 
n=20 
n=50 0 .1 .2 .3 .4 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Binomial p.d.f.s for p=0.25 and different n 
0 .1 .2 .3 .4 
&#8722;4 &#8722;2 0 2 4 Densities of Standardized Binomial Random Variables 
Figure 1: Illustration of the DeMoivre-Laplace Theorem 
successes.
If n =5, the probability of having no more than 25% successes can be calculated as
5 5 45 44 1280 P(X &#8804;1.25) = P(X =0)+P(X =1) = 0(1&#8722;p)5 +1 p(1&#8722;p)4 =55 +5 55 3125 &#8776;40.96% = 
Whatif X&#732;&#8764;B &#65533; 
100, 1
5 &#65533; 
, i.e. we increase n to 100? In principle, we could calculate 
P(X&#732;&#8804;25) = P(X =0)+P(X =1)+... + P(X =25) 
So we&#8217;d have to calculate each summand separately, and since there are pretty many of those, this will be 
very cumbersome. Alternatively, we could limit ourselves to a good approximation using the DeMoivre-
Laplace Theorem. The standardized version of X&#732;isgivenby 
X&#732;&#8722;1001 &#732;
Z = &#65533; &#183; 5 = X &#8722;20 
10014 4 &#183; 55&#183; 
Therefore, 
5 
4 
P(X&#732;&#8804;25) = P(X&#732;&#8722;20 &#8804;5) = PZ &#8804;45 &#8776; 
&#8722;&#8734; &#966;(z)dz &#8776;89.44% 
How good is this approximation? I did the calculation, and I obtained P(X&#732;&#8804;25) &#8776;91.25%. If we repeat 
&#175; the same exercise for n =200, I obtain the &#8221;exact&#8221; binomial probability P(X &#8804;50) &#8776;96.55% and the 
&#175; normal approximation P(X &#8804;50) &#8776;96.15%. 
For Z &#8764;N(0,1), we also call any random variable 
X = &#181;+ &#963;Z 
a normal random variable with mean &#181; and variance &#963;2, or in symbols 
X &#8764;N(&#181;,&#963;2) 
8 </text>
        </slide>
        <slide>
          <slideno>14</slideno>
          <text>Cumulative areas under the standard normal distribution 
0 z (Cont.) 
-3 
-2.9 
-2.8 
-2.7 
-2.6 
-2.5 -2.4 
-2.3 -2.2 
-2.1 
-2.0 -1.9 -1.8 -1.7 
-1.6 
-1.5 
-1.4 
-1.3 -1.2 
-1.1 
-1.0 -0.9 -0.8 -0.7 -0.6 
-0.5 
-0.4 
-0.3 
-0.2 -0.1 -0.0 0.0013 
0.0019 
0.0026 
0.0035 
0.0047 
0.0062 0.0082 
0.0107 0.0139 
0.0179 
0.0228 0.0287 0.0359 0.0446 
0.0548 
0.0668 
0.0808 
0.0968 
0.1151 
0.1357 0.1587 0.1841 
0.2119 
0.2420 0.2743 
0.3085 
0.3446 
0.3821 
0.4207 0.4602 0.5000 0.0013 
0.0018 
0.0025 
0.0034 
0.0045 
0.0060 0.0080 
0.0104 0.0136 
0.0174 
0.0222 0.0281 0.0352 0.0436 
0.0537 
0.0655 
0.0793 
0.0951 
0.1131 
0.1335 0.1562 0.1814 
0.2090 
0.2389 0.2709 
0.3050 
0.3409 
0.3783 
0.4168 0.4562 0.4960 0.0013 
0.0017 
0.0024 
0.0033 
0.0044 
0.0059 0.0078 
0.0102 0.0132 
0.0170 
0.0217 0.0274 0.0344 0.0427 
0.0526 
0.0643 
0.0778 
0.0934 
0.1112 
0.1314 0.1539 0.1788 
0.2061 
0.2358 0.2676 
0.3015 
0.3372 
0.3745 
0.4129 0.4522 0.4920 0.0012 
0.0017 
0.0023 
0.0032 
0.0043 
0.0057 0.0075 
0.0099 0.0129 
0.0166 
0.0212 0.0268 0.0336 0.0418 
0.0516 
0.0630 
0.0764 
0.0918 
0.1093 
0.1292 0.1515 0.1762 
0.2033 
0.2327 0.2643 
0.2981 
0.3336 
0.3707 
0.4090 0.4483 0.4880 0.0012 
0.0016 
0.0023 
0.0031 
0.0041 
0.0055 0.0073 
0.0096 0.0126 
0.0162 
0.0207 0.0262 0.0329 0.0409 
0.0505 
0.0618 
0.0749 
0.0901 
0.1075 
0.1271 0.1492 0.1736 
0.2005 
0.2297 0.2611 
0.2946 
0.3300 
0.3669 
0.4052 0.4443 0.4840 0.0011 
0.0016 
0.0022 
0.0030 
0.0040 
0.0054 0.0071 
0.0094 0.0122 
0.0158 
0.0202 0.0256 0.0322 0.0401 
0.0495 
0.0606 
0.0735 
0.0885 
0.1056 
0.1251 0.1469 0.1711 
0.1977 
0.2266 0.2578 
0.2912 
0.3264 
0.3632 
0.4013 0.4404 0.4801 0.0011 
0.0015 
0.0021 
0.0029 
0.0039 
0.0052 0.0069 
0.0091 0.0119 
0.0154 
0.0197 0.0250 0.0314 0.0392 
0.0485 
0.0594 
0.0722 
0.0869 
0.1038 
0.1230 0.1446 0.1685 
0.1949 
0.2236 0.2546 
0.2877 
0.3228 
0.3594 
0.3974 0.4364 0.4761 0.0011 
0.0015 
0.0021 
0.0028 
0.0038 
0.0051 0.0068 
0.0089 0.0116 
0.0150 
0.0192 0.0244 0.0307 0.0384 
0.0475 
0.0582 
0.0708 
0.0853 
0.1020 
0.1210 0.1423 0.1660 
0.1922 
0.2206 0.2514 
0.2843 
0.3192 
0.3557 
0.3936 0.4325 0.4721 0.0010 
0.0014 
0.0020 
0.0027 
0.0037 
0.0049 0.0066 
0.0087 0.0113 
0.0146 
0.0188 0.0238 0.0300 0.0375 
0.0465 
0.0570 
0.0694 
0.0838 
0.1003 
0.1190 0.1401 0.1635 
0.1894 
0.2177 0.2483 
0.2810 
0.3156 
0.3520 
0.3897 0.4286 0.4681 0.0010 
0.0014 
0.0019 
0.0026 
0.0036 
0.0048 0.0064 
0.0084 0.0110 
0.0143 
0.0183 0.0233 0.0294 0.0367 
0.0455 
0.0559 
0.0681 
0.0823 
0.0985 
0.1170 0.1379 0.1611 
0.1867 
0.2148 0.2451 
0.2776 
0.3112 
0.3483 
0.3859 0.4247 0.4641 
0 z 1 2 3 4 5 6 7 8 9 
14
Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>10</slideno>
          <text>    
&#65533; &#65533; i.e. most of the mass of the distribution is within one or two standard deviations of the mean. It&#8217;s useful 
to remember these three quantities in order to get rough estimates of normal probabilities if you don&#8217;t 
have a tabulation of the c.d.f. at hand. 
&#963; &#963; &#963; &#963; 
&#65533; &#963; &#963; 
68% of density 
95% of density 
99.7% of density 
Since the standard normal distribution is so commonly used, you&#8217;ll      Image by MIT OpenCourseWare.
&#64257;nd tabulated values of the c.d.f. 
&#934;(z) in any statistics text. 
Often those tables only contain values z &#8804;0, but you can obtain the c.d.f. at a value &#732;z&gt; 0 using 
symmetry of the distribution: 
&#934;(&#732;z)=1&#8722;&#934;(&#8722;z&#732;) 
E.g. if we want to know P(Z &#8804;1.95), we can look up P(Z &#8804;&#8722;1.95) =0.0256, and calculate P(Z &#8804;
1.95) =1&#8722;P(Z &#8804;&#8722;1.95) =0.9744. 
0 -z z area = (-z)&#934;area = 1 - (z)&#934;
= (-z)&#934;
Ingeneral,if X &#8764;N(&#181;,&#963;), we can obtain probabilities of the typeP(a       Image by MIT OpenCourseWare.
&#8804;X&#8804;b)fora&#8804;busingthe
following steps: 
1. standardize the variable, i.e. rewriting the event as 
P(a &#8804;X &#8804;b)= P (a &#8804;&#181;+ &#963;Z &#8804;b)= Pa &#8722;&#181; &#8804;Z &#8804; b&#8722;&#181; 
&#963; &#963; 
10       </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533;	 &#65533; Iowa 
New 
Hampshire Super 
Tuesday 
Ohio, 
Texas0 .2 .4 .6 .8 Clinton/Edwards/Obama 
1/01/08 2/01/08 3/01/08 
Date 
Clinton Edwards 
Obama 
&#8226;	the Iowa caucus in which Barack Obama won against Hillary Clinton by a signi&#64257;cant margin 
&#8226;	the New Hampshire primaries which were seen as Hillary Clinton&#8217;s &#8221;comeback&#8221; after the defeat in 
Iowa 
&#8226;	the primaries in Ohio and Texas, two major states which were won by Hillary Clinton 
We can see steep changes in the conditional expectations after each of these events, illustrating how the 
market updates its &#8221;beliefs&#8221; about the candidates&#8217; chances of securing their parties nomination. 
InFinancialEconomics,thistypeof contractswhichpays1dollarif aparticularstate of natureis realized 
are also called Arrow-Debreu securities. 
An important relationship between conditional and unconditional expectation is the Law of Iterated 
Expectations(aclose &#8221;cousin&#8221; oftheLawofTotalProbability which wesawearlierinthelecture): 
Proposition1 (Law of Iterated Expectations) 
E [E[YX]]= E[Y] |
Proof: Let g(x)= E[YX = x], which is a function ofx. We can now calculate the expectation |
&#65533; &#8734;	 &#65533; &#8734; 
E[g(X)] = g(x)fX(x)dx = E[YX = x]fX(x)dx 
&#8722;&#8734;	 &#8722;&#8734; |
= &#65533; &#8734; 
&#8722;&#8734; &#65533;&#65533; &#8734; 
&#8722;&#8734; y fXY (x,y) 
fX(x) dy &#65533; 
fX(x)dx 
&#65533; &#8734; &#65533; &#8734; 
= yfXY (x,y)dydx 
&#8722;&#8734; &#8722;&#8734; &#65533; &#8734; &#65533; &#8734; 
= y fXY (x,y)dx dy 
&#8722;&#8734; &#8722;&#8734; &#65533; &#8734; 
= yfY (y)dy = E[Y] 
&#8722;&#8734; 
Proposition2 (Conditional Variance / Law of Total Variance) 
Var(Y)=Var(E[YX])+E[Var(YX)] | |
3 </text>
        </slide>
        <slide>
          <slideno>15</slideno>
          <text>Cumulative areas under the standard normal distribution (Cont.) 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 0.6 
0.7 0.8 
0.9 
1.0 1.1 1.2 1.3 
1.4 
1.5 1.6 
1.7 
1.8 
1.9 
2.0 2.1 2.2 2..3 2.4 
2.5 
2.6 
2.7 
2.8 2.9 3.0 0.5000 
0.5398 
0.5793 
0.6179 
0.6554 
0.6915 0.7257 
0.7580 0.7881 
0.8159 
0.8413 0.8643 0.8849 0.9032 
0.9192 
0.9332 0.9452 
0.9554 
0.9641 
0.9713 
0.9772 0.9821 
0.9861 
0.9893 0.9918 
0.9938 
0.9953 
0.9965 
0.9974 0.9981 0.9987 0.5040 
0.5438 
0.5832 
0.6217 
0.6591 
0.6950 0.7291 
0.7611 0.7910 
0.8186 
0.8438 0.8665 0.8869 0.9049 
0.9207 
0.9345 0.9463 
0.9564 
0.9648 
0.9719 
0.9778 0.9826 
0.9864 
0.9896 0.9920 
0.9940 
0.9955 
0.9966 
0.9975 0.9982 0.9987 0.5080 
0.5478 
0.5871 
0.6255 
0.6628 
0.6985 
0.7324 0.7642 
0.7939 
0.8212 0.8461 0.8686 0.8888 
0.9066 
0.9222 0.9357 
0.9474 
0.9573 
0.9656 
0.9726 0.9783 
0.9830 
0.9868 0.9898 
0.9922 
0.9941 
0.9956 
0.9967 
0.9976 0.9982 0.9987 0.5120 
0.5517 
0.5910 
0.6293 
0.6664 
0.7019 0.7357 
0.7673 0.7967 
0.8238 
0.8485 0.8708 0.8907 0.9082 
0.9236 
0.9370 0.9484 
0.9582 
0.9664 
0.9732 
0.9788 0.9834 
0.9871 
0.9901 0.9925 
0.9943 
0.9957 
0.9968 
0.9977 0.9983 0.9988 0.5160 
0.5557 
0.5948 
0.6331 
0.6700 
0.7054 0.7389 
0.7703 0.7995 
0.8264 
0.8508 0.8729 0.8925 0.9099 
0.9251 
0.9382 0.9495 
0.9591 
0.9671 
0.9738 
0.9793 0.9838 
0.9874 
0.9904 0.9927 
0.9945 
0.9959 
0.9969 
0.9977 0.9984 09988 0.5199 
0.5596 
0.5987 
0.6368 
0.6736 
0.7088 0.7422 
0.7734 0.8023 
0.8289 
0.8531 0.8749 0.8944 0.9115 
0.9265 
0.9394 0.9505 
0.9599 
0.9678 
0.9744 
0.9798 0.9842 
0.9878 
0.9906 0.9929 
0.9946 
0.9960 
0.9970 
0.9978 0.9984 0.9989 0.5239 
0.5636 
0.6026 
0.6406 
0.6772 
0.7123 0.7454 
0.7764 0.8051 
0.8315 
0.8554 0.8770 0.8962 0.9131 
0.9278 
0.9406 0.9515 
0.9608 
0.9686 
0.9750 
0.9803 0.9846 
0.9881 
0.9909 0.9931 
0.9948 
0.9961 
0.9971 
0.9979 0.9985 0.9989 0.5279 
0.5675 
0.6064 
0.6443 
0.6808 
0.7157 0.7486 
0.7794 0.8078 
0.8340 
0.8577 0.8790 0.8980 0.9147 
0.9292 
0.9418 0.9525 
0.9616 
0.9693 
0.9756 
0.9808 0.9850 
0.9884 
0.9911 0.9932 
0.9949 
0.9962 
0.9972 
0.9979 0.9985 0.9989 0.5319 
0.5714 
0.6103 
0.6480 
0.6844 
0.7190 0.7517 
0.7823 0.8106 
0.8365 
0.8599 0.8810 0.8997 0.9162 
0.9306 
0.9430 0.9535 
0.9625 
0.9700 
0.9762 
0.9812 0.9854 
0.9887 
0.9913 0.9934 
0.9951 
0.9963 
0.9973 
0.9980 0.9986 0.9990 0.5359 
0.5753 
0.6141 
0.6517 
0.6879 
0.7224 0.7549 
0.7852 0.8133 
0.8389 
0.8621 0.8830 0.9015 0.9177 
0.9319 
0.9441 0.9545 
0.9633 
0.9706 
0.9767 
0.9817 0.9857 
0.9890 
0.9916 0.9936 
0.9952 
0.9964 
0.9974 
0.9981 0.9986 0.9990 
0 z 1 2 3 4 5 6 7 8 9 
Source: B. W. Lindgren, Statistical Theory (New York: Macmillan. 1962), pp. 392-393. 
 15Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 14 
Konrad Menzel 
April 2, 2009 
Conditional Expectations 
Example1 Each year, a &#64257;rm&#8217;s R&amp;D department produces X innovations according to some random 
process, where E[X] =2 and Var(X) =2. Each invention is a commercial success with probability 
p =0.2 (assume independence). The number of commercial successes in a given year are denoted by S. 
Since we know that the mean of S &#8764;B(x,p)= xp, conditional on X = x innovations in a given year, xp 
of them should be successful on average. 
The conditional expectation of X given Y is the expectation of X taken over the conditional p.d.f.: 
De&#64257;nition1 
E[YX]= &#65533; &#8734; yfY |X(y|X) if Y isdiscrete y 
yfY|X(yX)dy if Y is continuous |
&#8722;&#8734; |
Note that since fY|X(y|X)carries the random variable X as its argument, the conditional expectation is 
also a random variable. However, we can also de&#64257;ne the conditional expectation of Y given a particular 
value of X, 
yfY |X(yx) if Y isdiscrete yE[YX = x]= &#65533; &#8734; yfY|X(y|
|x)dy if Y is continuous |
&#8722;&#8734; 
whichisjust a numberfor anygiven value of x as long as the conditional density is de&#64257;ned. 
Sincethecalculationgoesexactlylikebefore,onlythat wenowintegrateoverthe conditional distribution, 
won&#8217;t do a numerical example (for the problem set, just apply de&#64257;nition). Instead let&#8217;s discuss more 
qualitative examples to illustrate the di&#64256;erence between conditional and unconditional examples: 
Example2 (The Market for &#8221;Lemons&#8221;) The following is a simpli&#64257;ed version of a famous model for 
the market for used cars by the economist George Akerlof. Suppose that there are three types X of used 
cars: cars in an excellent state (&#8221;melons&#8221;), average-quality cars (&#8221;average&#8221; not in a strict, statistical, 
sense), and carsin apoor condition(&#8221;lemons&#8221;). Each type of caris equallyfrequent,i.e. 
1 P(&#8221;lemon&#8221;) = P(&#8221;average&#8221;) = P(&#8221;melon&#8221;) = 3 
Thesellerand abuyerhavethefollowing(dollar) valuations YS and YB, respectively, for each type of cars: 
Type Seller Buyer 
&#8221;Lemon&#8221; 5,000$ 6,000$ 
&#8221;Average&#8221; 6,000$ 10,000$ 
&#8221;Melon&#8221; 10,000$ 11,000$ 
1 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533; &#65533; &#65533; &#65533; The standard normal p.d.f. phi(z) 
0 .1 .2 .3 .4 
&#8722;5 0 5 
z 
2.3.1 Important Properties of the Standard Normal Distribution 
Property1 For a standard normal random variable Z, 
E[Z]=0 
and 
Var(Z)=1 
As a &#64257;rst illustration why the normal distribution is very useful, it turns out that Binomial random 
variables are approximated by the normal for a large number n oftrials: 
Theorem1 (DeMoivre-Laplace Theorem) If X &#8764;B(n,p) is a binomial random variable, then for 
any numbers c &#8804;d, 
X &#8722;np X &#8722;E[X] &#65533; d 
lim Pc &#8804;&#65533; &lt;d = lim P c&lt; &#65533; = &#981;Z(z)dz 
n&#8594;&#8734; np(1&#8722;p) n&#8594;&#8734; Var(X) &#8804;d 
c 
Notice that the transformation of the binomial variable to 
X &#8722;E[X]Z = &#65533; 
Var(X) 
is in fact a standardization. This result says that for large n, the probability that the standardized 
binomial random variable X fallsinside theinterval(c,d] is approximately the same as for a standard 
normal random variable. As an illustration, I plotted the binomial p.d.f. for increasing values of n, and 
then applied the normalization. 
For n =50,the shape of thebargraphlooksalready relatively similartothebell-shape of the normal 
density. Note that in particular the skewness of the distribution for small n (due to the small&#8221;success&#8221; 
probability p= 1
4)washes out almost entirely. 
Example6 In order to see why this type of approximation is in fact useful for practical purposes, say 
p = 1
5, and we want to calculate the probability that in a sequence of n trials, we have at least 25% 
7 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; &#65533;
Iowa Florida 
Super 
Tuesday 0 .2 .4 .6 .8 1 Giuliani/Huckabee/McCain/Romney 
12/01/07 1/01/08 2/01/08 3/01/08 
Date 
Giuliani Huckabee 
McCain Romney 
ofpledgeddelegatesbydate t, we can compare the &#8221;unconditional&#8221; means before the Iowa primaries to 
the &#8221;conditional&#8221; means after Super Tuesday in light of the law of total variance, 
Var(Yi)= E[Var(YiXt)]+Var(E[YiXt]) | |
We can see that while before the Iowa elections, the E[Yi]for the main candidates were in an interme&#173;
diate rangefrom10% to40% withlots of variation. However, afterSuperTuesday,prices(i.e. E[YiXt])|
moved close to 0 or 1, and the &#8221;wiggles&#8221; have become really tiny. So, in terms of the conditional variance 
formula, the largest part of the ex ante variance Var(Yi)was uncertainty about the conditional mean after 
SuperTuesday, Var(E[YiXt]), whereas the contribution of the conditional variance Var(YiXt) seems to | |
be relatively small. 
If we compare this to the graph for the Democratic race, for the latter, there is still a lot of movement af&#173;
ter Super Tuesday, so that conditioning on the number of pledged delegates Xt bySuperTuesdaydoesn&#8217;t 
take out much of the variance, i.e. Var(YiXt) is still considerably large. As an aside, an often cited |
reason why the Republican race was decided so much earlier is that in the Republican primaries, in each 
state,delegates are allocated notproportionally to each candidate&#8217;s vote share(whichisthe rulefor most 
primaries of the Democratic party), but the winner-takes-all rule, so that even very close victories in the 
&#64257;rst primaries can get a candidate far enough ahead to make it extremely hard for competitors to catch 
up. 
2 Special Distributions 
In the lecture, we already saw three commonly used distributions, the binomial, the uniform and the 
exponential. Over the next two lectures, we are going to expand this list by a few more important 
examples, and we&#8217;ll start with the most frequently used of all, the normal distribution. 
2.1 Recap: Distributions we already saw in Class 
De&#64257;nition2 X is binomial distributed with parameters (n,p), X &#8764;B(n,p)if its p.d.f. is given by 
&#9127; 
&#9128; n
px(1&#8722;p)n&#8722;x if x &#8712;{0,1,...,n}fX(x)= x &#9129; 0 otherwise 
5 </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; 
&#65533; 
&#65533; We showed that for X &#8764;B(n,p), 
E[X]= np 
Var(X)= np(1&#8722;p) 
De&#64257;nition3 X is uniformly distributed over the interval [a,b], X &#8764;U[a,b],ifithasp.d.f. 
if fX(x)= b&#8722;1 
a a &#8804;x &#8804;b 
0 otherwise 
De&#64257;nition4 X is exponentially distributed with parameter &#955;, X &#8764;E(&#955;),ifithasp.d.f. 
&#955;e&#8722;&#955;x if x &#8805;0 fX(x)= 0 otherwise 
2.2 Standardized Random Variable 
Sometimes, it is useful to look at the following standardization Z of a random variable X 
X &#8722;E[X]Z := &#65533; 
Var(X) 
Using the rules for expectations and variances derived in the last couple of lectures, 
E[X &#8722;E[X]] E[Z]= &#65533; =0 
Var(X) 
and 
Var(X)= Var(X &#8722;E[X]) = Var(X) =1 Var(X) Var(X) 
If we normalize random variables in this way, it&#8217;s easier to compare shapes of di&#64256;erent distributions 
independent of their scale and location. 
2.3 The Normal Distribution 
Thenormaldistributioncorrespondstoa continuousrandomvariable, anditturnsoutthatitgivesgood 
approximationsto alarge number of statistical experiments(we&#8217;ll see one examplein a second, more on 
this when we discuss the Central Limit Theorem next week). 
De&#64257;nition5 A random variable Z follows a standard normal distribution -in symbols Z &#8764;N(0,1) -if 
its p.d.f. is given by 
2 z 1 &#8722;fZ(z)= &#981;(z):= &#8730;
2&#960;e 2 
for any z &#8712;R. Its c.d.f. is denoted by 
z 
&#934;(z):= P(Z &#8804;z)= &#981;(s)ds 
&#8722;&#8734; 
Thec.d.f. of astandard normal randomvariabledoesn&#8217;thaveaclosed-formexpression(butcanlook up 
valuesintables,alsoprogrammedinany statistical softwarepackage).Thep.d.f. &#981;(z)hasacharacteristic 
bell shape and is symmetric around zero: 
6 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; 
&#65533; The &#64257;rst thing to notice is that for every type of car, the buyer&#8217;s valuation is higher than the seller&#8217;s, so 
for each type of car, trade should take place at a price between the buyer&#8217;s and the seller&#8217;s valuations. 
However, for used cars, quality is typically not evident at &#64257;rst sight, so if neither the seller nor the buyer 
know the type X of a car in question, their expected valuations are, by the law of iterated expectations 
E[YS]= E[YS&#8221;lemon&#8221;]P(&#8221;lemon&#8221;)+ E[YS&#8221;average&#8221;]P(&#8221;average&#8221;)+ E[YS&#8221;melon&#8221;]P(&#8221;melon&#8221;) | | |
1 = (5,000+6,000+10,000) =7,000 3
E[YS]= E[YB&#8221;lemon&#8221;]P(&#8221;lemon&#8221;)+ E[YB&#8221;average&#8221;]P(&#8221;average&#8221;)+ E[YB&#8221;melon&#8221;]P(&#8221;melon&#8221;) | | |
1 = (6,000+10,000+11,000) =9,000 3
so trade should still take place.
But in a more realistic setting, the seller of the used car knows more about its quality than the buyer
(e.g. history of repairs, accidents etc.) and states a price at which he is willing to sell the car. If the
seller can perfectly distinguish the three types of cars, whereas the buyer can&#8217;t, the buyer should form
expectations conditional on the seller willing to sell at the quoted price.
If the seller states a price less than 6,000 dollars, the buyer knows for sure that the car is a &#8221;lemon&#8221;
because otherwise the seller would demand at least 6,000,i.e.
E[YBYS &lt; 6000] = E[YB&#8221;lemon&#8221;] =6000 | |
and trade would take place. However, if the car was in fact a &#8221;melon&#8221;, the seller would demand at least 
10,000 dollars, whereas the buyer would pay at most 
E[YB|YS &#8804;10,000] = E[YB]=9,000 &lt; 10,000 
so that the seller won&#8217;t be able to sell the high-quality car at a reasonable price.
The reason why the market for &#8221;melons&#8221; breaks down is that in this model, the seller can&#8217;t credibly
assure the buyer that the car in question is not of lower quality, so that the buyer factors the possibility
of getting the bad deal into his calculation.
Example3 In this example, we are going to look at data on the 2008 presidential nominations from the
IEMPoliticalMarkets, aninternetplatforminwhichpeoplebetonfuturepoliticalevents(thedata can
be obtained from
http://www.biz.uiowa.edu/iem/markets/data nomination08.html).
The market works as follows: for each political candidate i, participants can buy a contract which pays
1 dollar if candidate i wins nomination Yi = 0 dollars otherwise 
At a given point in time t, participants in the market have additional outside information, which we&#8217;ll 
call Xt, as e.g. the number of delegates won so far, the &#8221;momentum&#8221; of a candidate&#8217;s campaign, or 
statements by sta&#64256; about the candidate&#8217;s campaign strategy. 
Given that additional information, the expected value of the contract is 
E[Yi|Xt = x]= yifYi|Xt (yi|x)=1&#183; P(Yi =1|Xt = x)+0&#183; P(Yi =0|Xt = x)= P(Yi|Xt) 
yi 
In other words, the dollar amount traders should be willing to pay for the contract for candidate i equals 
the probability that i wins his/her party&#8217;s nomination given the available information attime t. 
Let&#8217;s look at the prices of contracts for the main candidates of the Democratic party over the last 3 
months: I put three vertical lines for 3 events which revealed important information about the candidates&#8217; 
likelihood of winning the Democratic nomination: 
2 </text>
        </slide>
        <slide>
          <slideno>13</slideno>
          <text>For a large value k for the degrees of freedom, the t-distribution is approximated well by the standard 
normaldistribution. 
De&#64257;nition8 If Y1 &#8764;&#967;2 and Y2 &#8764;&#967;2 , then k1 k2 
Y1/k1F = Y2/k2 &#8764;F(k1,k2) 
is said to follow an F-distribution with(k1,k2)degrees of freedom. 
13 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec06/</lecture_pdf_url>
      <lectureno>6</lectureno>
      <slides>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; 
&#65533; x 
10 1 
4 
20 30 40 50 3 
4 13 
16 
x 
10 1 
1 
16 
20 30 40 50 1 
4 3 
16 1 
2 Fx(x) 
fx(x) 
Figure 4: c.d.f. and p.d.f. for a discrete   Image by MIT OpenCourseWare.
random variable
2.1 p.d.f. and c.d.f for Continuous Random Variables 
If X has a continuous distribution with p.d.f. f(x) and F (x) (I&#8217;ll drop the X subscript from now on 
wherever there are no ambiguities), then 
x 
F (x)= P (X &#8804; x)= f(t)dt 
&#8722;&#8734; 
From the fundamental theorem of calculus, we can in this case write the relationship between c.d.f. and 
p.d.f. as 
d F &#65533;(x)= F (x)= f(x)dx 
Example6 Let 
0 if x&lt; 0 F (x)= x if x &#8805; 01+x 
Is F (x)a c.d.f.? -let&#8217;s check basic properties: 
6 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; 
&#65533; &#65533; Example1 Suppose X hasp.d.f. 
ax2 if0 &lt;x&lt; 3 fX (x)= 0 otherwise 
Whatdoes a have to be? -since P (X &#8712; R)=1, the density has to integrate to 1, so a must be such that 
&#65533; &#8734; &#65533; 3
2&#65533; ax3 &#65533;3 27 1= fX (t)dt = atdt = = a &#8722;0 =9a 3 3&#8722;&#8734; 0 0 
Therefore, a = 91 .
Whatis P (1&lt;X&lt; 2)? -let&#8217;s calculate the integral
&#65533; 2 t2 23 13 7 P (1&lt;X&lt; 2) = dt = &#8722; = 9 9&#183; 39&#183; 3 27 1 
Whatis P (1&lt;X)? 
&#8734; 3 t2 27&#8722;1 26 P (1&lt;X)= fX (t)dt = dt = = 9 27 27 1 1 
1.1 Mixed Random Variables/Distributions 
Many kinds of real-world data exhibit point masses at some values mainly for two di&#64256;erent reasons: 
&#8226;	some outcomes are restricted to certain values mechanically, so a lot of probability mass tends to 
cumulate right at the corners of the range of the random variable, e.g. daily rainfall can possibly 
take any positive real value, but there are many days at which rainfall is zero. 
&#8226;	individuals taking economic decisions may respond to certain institutional rules by positioning 
themselves right at some kind of kinks or discontinuities, e.g. if we look at incomes reported to 
Social Security or the Internal Revenue Service, we observe &#8221;bunching&#8221; of individuals at the top 
ends of the tax brackets (since for those individuals, a small increase in income would mean a 
discretejump inthetax rate). 
The corresponding distributions are, strictly speaking, not continuous, because even though realizations 
can be any real-valued numbers, we can&#8217;t de&#64257;ne a probability density function as we did in the previous 
section,but we&#8217;llhavetodeal with thepoint masses separately. Some of thisisgoing to come up inyour 
econometrics classes, but we won&#8217;t spend time on this for now and only look at one example. 
Example2 The following graph is constructed using data from the Current Population Survey (CPS) 
for1979.1 
For the graph, the authors chose a subpopulation with very low income so that the fraction of the sample 
for whom the minimum wage was binding was relatively high. There are some individuals to the left of 
the 1979 value of the minimum wage presumably corresponding to employment in sectors which are in 
part exemptfrom minimum wagelaws(e.g. farming,youth employment). 
1Figure 3b) on p. 1017 in DiNardo, J., N. Fortin and T. Lemieux. &#8220;Labor Market Institutions and the Distribution of 
Wages, 1973-1992: A Semiparametric Approach.&#8221; Econometrica 64, no. 5 (1996): 1001-1044. 
2 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>Note that a c.d.f. doesn&#8217;t have to be continuous: if we de&#64257;ne the leftlimit 
F (x &#8722;)= lim F (x &#8722;h) 
h&gt;0,h&#8594;0 
andthe rightlimit 
F (x +)= lim F (x + h) 
h&gt;0,h&#8594;0 
Recall that in order to be continuous at x, F (x)must satisfy F (x&#8722;)= F (x+). This need not be true in 
general, as the following example shows: 
Example3 Consider again the experiment of rolling a die, where the random variable X corresponds 
to the number we rolled. Then the c.d.f. of X isgivenby 
&#9127; 
0 if x &lt; 1 &#9130; &#9130; &#9130; 1 &#9130; if 1 &#8804; x &lt; 2 &#9128; 6 
FX (x)= &#183; &#183; &#183; &#183; &#183; &#183; &#9130; 5 &#9130; if 5 &#8804; x &lt; 6 &#9130; 6&#9130; &#9129; 1 if x &#8805; 6 
whichhasdiscontinuousjumps at thethe values 1, 2,..., 6. 
0 1 2 3 4 5 6 ---F(x) 
F(x) 
x 1 
1 
2 
1 
6 
Figure 3: c.d.f. of a   Image by MIT OpenCourseWare.
die roll
However, by a general result from real analysis, any monotone function (hence the c.d.f. FX in 
particular) can only have countably many points of discontinuity. 
Furthermore, we always have 
Property4 Any c.d.f. is right-continuous, i.e. 
F (x)= F (x +)
We can now use our knowledge about probabilities to show some more properties of c.d.f.s
Proposition1 For any given x, 
P (X&gt;x)=1&#8722;FX (x) 
4 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 6 
Konrad Menzel 
February 24, 2009 
Examples 
Supposethatarandom variableissuchthaton someinterval[a,b] on the real axis, the probability of 
X belonging to some subinterval [a&#65533;,b&#65533;](where a &#8804; a&#65533; &#8804; b&#65533; &#8804; b) is proportional to the length of that 
subinterval. 
De&#64257;nition1 A random variable X is uniformly distributed on the interval [a,b], a&lt;b, if it has the 
probabilitydensityfunction 
1 if a &#8804; x &#8804; b fX (x)= b&#8722;a 
0 otherwise 
In symbols, we then write 
X &#8764; U[a,b] 
F(x) 
x y 
a 1 
b-a 
b 
Figure 1: p.d.f for a Uniform Random Variable, X &#8764; [a,b] 
For example, if X &#8764; U[0, 10],then 
&#65533; 4 &#65533; 4 1 1 P (3&lt;X&lt; 4) = f(t)dt = dt = 10 10 3 3 
Whatis P (3 &#8804; X &#8804; 4)? Since the probability that P (X =3) =0 = P (X = 4), this is the same as 
P (3&lt;X&lt; 4). 
1 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>2 
1.5 
1 
.5 
0 Minimum wage 1979 
1n(2) 1n(5) 1n(10) 1n(25) 
2 Figure 2: Log Wages for Female High-School    Image by MIT OpenCourseWare.
Dropouts in 1979
The Cumulative Distribution Function (c.d.f.) 
De&#64257;nition2 The cumulativedistributionfunction(c.d.f.) FX of a random variable X isde&#64257;nedfor 
each real number as 
FX (x)= P (X &#8804; x) 
Note that this de&#64257;nition is the same for discrete, continuous or mixed random variables. In particular, 
sinceweallowfor X tobediscrete,notethat P (X &#8804; x)maybedi&#64256;erentfrom P (X&lt;x),soit&#8217;simportant 
to distinguish the corresponding events. In the de&#64257;nition of the c.d.f., we&#8217;ll always use X &#8221;less or equal 
to&#8221; x. 
Since the c.d.f. is a probability, it inherits all the properties of probability functions, in particular 
Property1 The c.d.f. only takes values between 0 and 1 
0 &#8804; FX (x)&#8804; 1 for all x &#8712; R 
Also, since for x1 &lt;x2, the event X &#8804; x1 is included in X &#8804; x2, we have 
Property2 FX is nondecreasing in x,i.e. 
FX (x1)&#8804; FX (x2) for x1 &lt;x2 
If we let x &#8594;&#8722;&#8734;, the event(X &#8804; x)becomes &#8221;close&#8221; (hereI&#8217;mvery sloppy aboutwhatthatmeans) 
to the impossible event in terms of its probability of occurring, whereas if x &#8594;&#8734;, the event(X &#8804; x) 
becomes almost certain, so that we have 
Property3 
lim F (x) =0 
x&#8594;&#8722;&#8734; 
lim F (x) =1 
x&#8594;&#8734; 
3 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>Proof: From properties of probabilities, 
P (X&gt;x)=1&#8722;P (X &#8804; x)=1&#8722;FX (x) 
Similarly, 
Proposition2 For two real numbers x1 &lt;x2, 
P (x1 &lt;X &#8804; x2)= FX (x2)&#8722;FX (x1) 
Proposition3 For any x, 
P (X&lt;x)= F (x &#8722;) 
Proposition4 For any x, 
P (X = x)= F (x +)&#8722;F (x &#8722;) 
This last result means in particular that for continuous variables, P (X = x)=0forall valuesof x. 
Example4 Let&#8217;s check whether the function GX (x) in the following graph is a c.d.f. The function is 
1 
1 2 3 4 5 6 7 3 
4 
1 
2 
1 
4 G (x) 
x 
between 0 and 1, monotonically increasing, and right-continuous. Let&#8217;s     Image by MIT OpenCourseWare.
apply the last four propositions 
to this example (just reading numbers o&#64256; the graph): 
3
4 14 &#8226; P (X&gt; 4) =1&#8722;F (4)=1&#8722;= 
&#8226; P (3&lt;X &#8804; 4) = 3
4&#8722;14 = 12 
12 &#8226; P (X&lt; 4) = F (4&#8722;)= 
3
412 = 14 &#8226; P (X =4) = F (4+)&#8722;F (4&#8722;) &#8722;= 
Example5 Unlike for continuous random variables, where we have a one-line formula linking the p.d.f. 
and the c.d.f., in discrete case, have to use the results on deriving probabilities from c.d.f.s we just 
discussed. Let&#8217;s look at the relationship in another graphical example 
5 </text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>&#65533; 3 Joint Distributions of 2 Random Variables X,Y 
Inmanysituations,weareinterested not onlyinasinglerandomvariable,but may careabout relationship 
betweentwoormorevariables,e.g. whethertheoutcomeof someprocessa&#64256;ectstheoutcomeof another. 
E.g. we could look at 
&#8226;	IQs of identical twins -i.e. X would be one kid&#8217;s IQ, and Y that of her/his sibling 
&#8226;	educational attainment X andincome Y : while we could look at the distributions of income or 
educationseparately,wecanalsoplotboth variablestogetherforobservationsfromadataset. And 
in the graph it looks like there is in fact a non-trivial relationship between the variables. Income 
Years of schooling 
Figure 6: Schooling   Image by MIT OpenCourseWare.
andIncome
&#8226;	relapsetimes: sinceitisoftennotpossibletoremoveacancercompletely by surgery,wemay want 
to evaluatethe e&#64256;ectiveness of a medicalprocedure,by looking athowlong ittakes until either(a) 
a newoperationbecomesnecessary(X), or(b) thepatientdies(Y ). While we are interested in 
either outcome, both outcomes are interdependent: if the patient dies before a new operation, we 
simply don&#8217;t observe when he would have had to undergo surgery otherwise. 
In this part of the class, we will consider the properties of two (or more) random variables simultane&#173;
ously, including their relationship. We will also introduce concepts analogous to &#8221;independence&#8221; and 
&#8221;conditional probabilities&#8221; of events. 
Welet(X,Y )be apair random variablesthat(jointly) takes values(x,y), andeither variable can be 
continuous, discrete, or mixed. 
3.1 Discrete Random Variables 
Inthediscrete case,thejointp.d.f. isgivenby 
fXY (x,y)= P (X = x,Y = y) 
for any(x,y)&#8712; R2 . If {(x1,y1),..., (xn,yn)}contains allpossible values of(X,Y ),then 
n 
fXY (xi,yi)=1 
i=1 
8    </text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>&#65533; 
&#65533; &#65533; For any subset A &#8834; R2 , 
P ((X,Y )&#8712; A)= fXY (x,y) 
(x,y)&#8712;A 
Example8 In a supermarket, let X be the number of people in the regular checkout line, and Y the 
numberofpeopleintheexpressline. Thenthejointp.d.f. of X and Y could look like this: A table of this 
fXY 
0 1 Y 
2 3 4 Total 
X 0 
1 
2 
3 0.1 
0.05 
0 
0 
0.15 0.05 
0.2 
0 
0 
0.25 0.05 
0.2 
0.1 
0 
0.35 0 
0.05 
0.1 
0 
0.15 0 
0 
0.05 
0.05 
0.1 0.2 
0.5 
0.25 
0.05 
1 
form,summarizing thecell-probabilitiesfromthejointp.d.f. of (X,Y ), and the marginal probabilities on 
the sides, is also called a contingency table. As argued before, the probabilities in the table should add up 
to one, and they do. 
We can see from the entries that there seems to be some relationship between the two variables: when the 
number of individuals at the regular checkout is high, then the number of persons in the express line also 
tends to be high. 
We can also calculate probabilities for di&#64256;erent events based on the p.d.f. as given in the table: 
P (X =2) = 0+0+0.1+0.1+0.05 =0.25 
34 
P (X &#8805; 2,Y &#8805; 2) = fXY (x,y)=0.1+0.1+0.05+0+0+0.05 =0.3 
x=2 y=2 
P (|X &#8722;Y |&#8804;1) = P (X = Y )+P (|X &#8722;Y |=1) 
=0.1+0.2+0.1+0+0.05+0.05+0.2+0+0.1+0+0.05 =0.85 
9 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533; &#8226; limx&#8594;&#8722;&#8734; F (x)=0 
&#8226; limx&#8594;&#8734; F (x)=1 
&#8226; F (&#183;)is nondecreasing(can checkderivativebelow) 
What is the p.d.f. f(x)? 
0 if x&lt; 0 f(x)= F &#65533;(x)= 1 otherwise (1+x)2 
Is f(x)a p.d.f.? -well, we&#8217;ve essentially already shown that F (x)is a c.d.f. We can see right away that 
f(x)&#8805; 0 for all x 
and also, &#65533; &#8734; 
f(t)dt = lim F (x)&#8722; lim F (x)=1&#8722;0 =0 
x&#8594;&#8734; x&#8594;&#8722;&#8734; &#8722;&#8734; 
Example7 If X &#8764; U[0, 1], then its c.d.f. is 
&#9127; &#65533; x &#9128; 0 if x&lt; 0 
FX (x)= fX (t)dt = x if0 &#8804; x&lt; 1 &#9129;&#8722;&#8734; 1 if x &#8805; 1 
a 1 
x 
xb b Fx(x) 
fx(x) a 
1 
b - a 
Figure 5: p.d.f. and c.d.f. for   Image by MIT OpenCourseWare.
X &#8764;U[a,b]
7    </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec02/</lecture_pdf_url>
      <lectureno>2</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>2 De&#64257;nition1 A probability distribution on a sample space S is a collection of numbers P (A) which 
satis&#64257;es the axioms(P1)-(P3). 
Notethatthe axioms(P1)-(P3) do notpindown a unique assignment ofprobabilitiesto events. Instead, 
these axioms only give minimal requirements which any probability distribution should satisfy in order 
to be consistent with our basic intuitions of what constitutes a probability (we&#8217;ll actually check that 
below). Inprinciple anyfunction P (&#183;)satisfying thesepropertiesconstitutesavalidprobability,but we&#8217;d 
haveto see separately whetherit&#8217;s actually agooddescription of the random experiment athand, which 
is always a hard question. In part 5 of this class (&#8221;Special Distributions&#8221;), we&#8217;ll discuss a number of 
popular choices of P (&#183;)for certain standard situations. 
Some Properties of Probabilities 
Now we stillhave to convince ourselves thatthe axioms(P1)-(P3) actually are su&#64259;cient to ensure that 
ourprobability functionhastheproperties we wouldintuitively expectittohave,i.e. (1)theprobability 
that an eventhappensplustheprobability thatitdoesn&#8217;thappen should sumto one,(2) theprobability 
that the impossible event, &#8709;,happens should equal zero,(3) if an event B is contained in an event A,its 
probability can&#8217;t be greater than P (A), and(4) theprobabilityfor any event shouldbein theinterval 
[0, 1]. We&#8217;ll now prove these properties from the basic axioms. 
Proposition1 
P (AC )=1&#8722;P (A) 
Proof: By the de&#64257;nition of the complement AC , 
(P 2) Defn.&#8221;AC &#8221; (P 3) 1= P (S)= P (A &#8746;AC )= P (A)+P (AC ) 
where the last step uses that A &#8745;AC = &#8709;, i.e. that A and its complement are disjoint. Rearranging this, 
weget 
P (AC )=1&#8722;P (A) 
which is what we wanted to show &#65533; 
Proposition2 
P (&#8709;)=0 
Proof: Since &#8709;C = S, we can use the previous proposition to show that 
Prop.1 (P 2) P (&#8709;)= P (SC )=1&#8722;P (S)=1&#8722;1 =0 
Proposition3 If B &#8834; A, then P (B)&#8804;P (A). 
As an aside, cognitive psychologists found out that even though this rule seems very intuitive, people 
often violate it in everyday probabilistic reasoning.2 Proof: In order to be able to use the probability 
2E.g. in a study by the psychologists Daniel Kahneman and Amos Tversky, several people were given the following 
description of Linda: 
Linda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply 
concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations. 
Individuals who were asked to give the probability that Linda was a bank teller tended to state a lower &#64257;gure than those 
asked about the probability that she was a feminist bankteller. 
2 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>axioms, it is useful to partition the event A using properties of unions and intersections 
A = A &#8745;S = A &#8745;(B &#8746;BC )=(A &#8745;B)&#8746;(A &#8745;BC )= B &#8746;(A &#8745;BC ) 
where the last step uses that B &#8834; A impliesthat A &#8745;B = B. Nowin ordertobe ableto use axiom(P3), 
notethat B and A &#8745;BC aredisjoint: 
B &#8745;(A &#8745;BC )= B &#8745;(BC &#8745;A)=(B &#8745;BC )&#8745;A = &#8709;&#8745;A = &#8709; 
Therefore, we can conclude 
P (A)= P (B)+P (A &#8745;BC )&#8805; P (B) 
by axiom(P1) &#65533; 
Proposition4 For any event A, 0 &#8804;P (A)&#8804; 1. 
Proof: 0 &#8804; P (A)is axiom(P1). Forthe secondinequality, note(P1) alsoimpliesthat P (AC ) &#8805; 0. 
Thereforebyproposition1 
P (A)=1&#8722;P (AC )&#8804;1 
Proposition5 
P (A &#8746;B)= P (A)+P (B)&#8722;P (A &#8745;B) 
Proof: Note that, as in the proof of proposition 3, we can partition the events A and B into 
A = A &#8745;S = A &#8745;(B &#8746;BC )=(A &#8745;B)&#8746;(A &#8745;BC ) 
and in the same fashion 
B =(B &#8745;A)&#8746;(B &#8745;AC ) 
You can easily check that these are in fact partitions, i.e. each of the two pairs of sets is disjoint. 
Therefore, we can seefrom axiom(P3) that 
P (A)= P ((A &#8745;B)&#8746;(A &#8745;BC ))= P (A &#8745;B)+P (A &#8745;BC ) 
and 
P (B)= P (B &#8745;A)+P (B &#8745;AC ) 
Therefore 
P (A)+P (B)= P (A &#8745;B)+&#65533;
P (A &#8745;BC )+P (B &#8745;A)+P (B &#8745;AC )&#65533; 
= P (A &#8745;B)+P (A &#8746;B) 
by(P3) since(A &#8745;B), (A &#8745;BC ), (B &#8745;AC )is a partition of A &#8746;B (&#64257;gure 6 gives a graphical illustration 
of the idea). Rearranging the last equation gives the desired result &#65533; 
3 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
14.30 Introduction to Statistical Methods in Economics
Spring 2009
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>4 Counting Rules 
The examples we looked at so far were relatively simple in that it was easy to enumerate the outcomes 
in A and S, respectively. If S has many elements, and an event A is su&#64259;ciently complex, it may be 
very tedious and impractical to obtain n(A) and n(S) by going down the full list of outcomes. Today, 
we&#8217;ll look at combinatorics part of which gives simple rules for counting the number of combinations or 
permutations ofdiscrete objects(outcomes) corresponding to adi&#64256;erentpattern(event). 
Example2 The famous chess player Bobby Fischer (who died 3 weeks ago) eventually got bored of 
playing &#8221;classic&#8221; chess and proposed a variant in which only the 8+8 pawns are set up as usual, but the 
otherpieces(1king,1queen,2bishops,2knights,2 rooks) areputinrandompositionsonthe &#64257;rstrank, 
where each whitepiecefaces the correspondingblackpiece on the other side. Asfurther restrictions,(1) 
onebishop mustbe on ablack, the other on a white square, and(2) theking must start outbetween the 
two rooks(in order to allowfor castling). 
The idea behind this is that since chess players tend to use standard game openings which work well 
only for the standard starting positions, the new variant forces them to play more creatively if there are 
enoughpossible ways of setting up agameto makeitimpossibleforplayersto memorize openingsfor any 
constellation. But how many possible starting positions are there? 
We&#8217;ll actually do the calculation later on in the lecture today using some of the counting techniques 
introducedinthisclass. Ifyougetbored,youcanalready start &#64257;guring outa(preferably elegant) way 
of attacking the problem. 
For now, we will not explicitly talk about random experiments or probabilities, but digress on methods 
to enumerate and count outcomes which we will put to use later on in the lecture. 
4.1 Composed Experiments 
Rule1 (Multiplication Rule): If an experiment has 2 parts, where the &#64257;rst part has m possible 
outcomes, and the second part has n possible outcomes regardless of the outcome in the &#64257;rst part, then 
the experiment has m &#183; n outcomes. 
Example3 Ifapasswordisrequiredtohave8characters(letters ornumbers),thenthecorresponding 
experiment has 8 parts, each of which has 2&#183; 26+10 =62 outcomes(assuming thatthepasswordis case-
sensitive). Therefore, we get a total of 628 (roughly 218 trillion) distinct passwords. Clearly, counting 
those up by hand would not be a good idea. 
Example4 The standardASCII character set used on most computer systemshas127 characters(ex&#173;
cluding the space): each character is attributed 1 byte = 8 bit of memory. For historical reasons, the 8th 
bit was used as a &#8221;parity&#8221; bit for consistency checks to detect transmission or copying errors in the code. 
Therefore, we have an experiment of 7 parts, each of which has outcomes from {0, 1}, so we have a total 
number of 27 =128 distinct characters. 
Example5 A card deck has 52 cards, so if we draw one card each from a blue and a red deck, we get 
52&#183; 52 = 2704 possible combinations of cards (if we can&#8217;t tell ex post which deck each card came from, 
we get a smaller number of distinguishable outcomes). If, on the other hand, we draw two cards from the 
same deck without putting the &#64257;rst card back on the stash, regardless of which card we drew &#64257;rst, only 51 
cards will remain for the second draw. Of course which 51 cards areleftisgoing todepend on which card 
was drawn at &#64257;rst, but notice that this doesn&#8217;t matter for the multiplication rule. Therefore, if we draw 
two cards from the same deck, we&#8217;ll have 52&#8727; 51 =2652 possible combinations. 
5 </text>
        </slide>
        <slide>
          <slideno>8</slideno>
          <text>&#65533; &#65533; 
5 Example12 Back to Fischer Random Chess: Let&#8217;s &#64257;rst ignore the restrictions (1) and (2) about the 
rooks and bishops, i.e. allow for any allocations of the pieces on the bottom rank of the board. We have 
to allocate the 8 white (or black, this doesn&#8217;t matter) pieces onto the 8 squares in the &#64257;rst rank of the 
chessboard. Notice that this is a permutation, so that we have 8! possible orderings. However, rooks, 
knights and bishops come in pairs and for the rules of the game the &#8221;left&#8221; and the &#8221;right&#8221; piece are 
equivalent. Therefore, there are 2&#183; 2&#183; 2 possible ways of generating each starting position by exchanging 
the two rooks/knights/bishops with each other, respectively. Hence, the number of distinct games is 
8! &#65533;Games = =7! =5040 8 
As we said earlier,the actual rulesforFischerRandomChessimposefurthermorethat(1) onebishop is 
placed on ablack, andthe other on a white square, and(2) thattheking hasto start outbetweenthetwo 
rooks. For this variant, we can use the multiplication rule if we are a little clever about the order in which 
we &#64257;ll up the row: I propose that we &#64257;rst allocate the two bishops, one on a random white, the other on 
a random black square, so there are 4&#183; 4 possibilities. Next, the queen takes one out of the remaining 6 
squares(6possibilities,obviously). Nowweputthetwoknightsonany ofthe &#64257;vesquaresthatareleft. 
5 120 This is a combination, so there are = 6&#183;2 =10 ways of allocating the knights. Because of the 2 
restriction on the king and the rooks, there is always exactly one way of setting up the three pieces onto 
the three remaining free &#64257;elds. In sum, we have 
&#65533;Games =4&#183; 4&#183; 6&#183; 10&#183; 1 =960 
potential &#8221;games&#8221; to be played. 
The crucial point about the order in which we place the pieces is to make sure that we can apply the 
multiplication rule, i.e. that the way we place the &#64257;rst pieces does not a&#64256;ect the number ofpossibilities 
we have left for the remaining pieces. As far as I can see, this only matters for the bishops: Say, we 
placed therooksand theking &#64257;rstand thenputup thebishops. Thenwe&#8217;dhavetodistinguish whether(a) 
allthreepiecesareon &#64257;eldsofthesamecolor(sowe&#8217;dhave 1&#183; 4 =4 possibilities of placing the bishops 
on &#64257;eldsofdi&#64256;erentcolors),or(b) oneofthethreepiecesstandsona &#64257;eld of adi&#64256;erentcolorthanthe 
othertwo(leaving us with 2&#183; 3 =6 possibilities for the bishops). As long as we place the bishops &#64257;rst and 
the king before the two rooks, it seems to be irrelevant in which order we proceed thereafter. 
The Presidential Death Date Paradox (Recitation) 
Conspiracy theories about living and dead presidents are typically built around &#8221;weird&#8221; coincidences. 
For example, for the two American presidents who were assassinated, i.e. Lincoln and Kennedy, one 
can &#64257;nd long lists of more or less remarkable commonalities between the two -e.g. Lincoln purportedly 
had a secretary named Kennedy who had warned him not to go the theater where he was shot, whereas 
Kennedy had a secretary named Evelyn Lincoln who had warned him not to go to Dallas before his 
assassination(well,that&#8217;s atleast whatWikipedia says...). 
One particular coincidence is the fact that several of the 39 presidents who already died share the same 
death dates: Filmore and Taft both died on March 8. John Adams and Thomas Je&#64256;erson both died on 
July4thin1826,exactly50yearsafterthesigning of thedeclarationofindependence,andJamesMonroe 
died exactly &#64257;ve years later, on July 4, 1831. Is this something to be surprised about? 
Let&#8217;s &#64257;rst look at the simple probability that two given presidents died on a &#64257;xed day, say February 6, 
assuming that probabilities equal the proportion of outcomes belonging to that event: we get that there 
isonly onecombinationof thetwopresidents&#8217; deathdatesfallsonFebruary6th,butby themultiplication 
8 </text>
        </slide>
        <slide>
          <slideno>9</slideno>
          <text>ruleforenumerations,thereareatotal of3652 possiblecombinationsofdeathdates. Hencetheprobability 
for this event is 1/3652 which is an extremely small number. 
However,thereisalso alargenumber ofpairs ofpresidents anddaysintheyearwhich couldbepotential 
candidates for a double death date. Now, the probability of the event A that at least two out of the 39 
presidents died on the same day can in principle be calculated as the ratio of the number of all possible 
combinations that have one pair of presidents with the same death date, two pairs, three presidents 
on one death date, and so forth. A more elegant way to attack this problem is by noting that, since 
A &#8746;AC = S and A &#8745;AC = &#8709;, from the axioms P3 and P2 we have P (A)= P (S)&#8722;P (AC )=1&#8722;P (AC ). 
The event AC can be formulated as &#8221;all 39 dead presidents have di&#64256;erent birthdays.&#8221; If there were only 
two dead presidents, there are 364 ways in which, given the death date of the &#64257;rst, the death date of 
the second could fall on a di&#64256;erent date. You should now note that counting the number of possibilities 
of assigning di&#64256;erent death dates to each of the n presidents corresponds to the experiment of drawing 
n out of 365 days without replacement, so the number of possibilities is 365! The total number of (365&#8722;n)! . 
possible assignments of death dates to presidents corresponds to drawing dates without replacement, so 
the number is 365n . 
Hence the probability of having at least one pair of presidents with the same death date is 
365! P (A)=1&#8722;P (AC )=1&#8722; 365n(365&#8722;n)! 
which,for n = 39 is equal to about 87.82%. Using the formula, we can also calculate this probability for 
di&#64256;erent numbers of presidents: 
n P(A) 
1 0 
2 0.27% 
5 2.71% 
10 11.69% 
20 41.14% 
30 70.63% 
60 99.41% 
366 100.00% 
Aswecanseefromthelastline,oneintuitionfortheprobabilityincreasingtooneisthat weeventually 
&#8221;exhaust&#8221; the number of potential separate death dates until eventually we have more dead presidents 
thandeathdates. 
So, to resolve the paradox, while the event that two given presidents died on a &#64257;xed date would indeed 
be agreat coincidence(i.e. has a verylowprobability), with anincreasing number ofpresidents, there 
is a combinatorial explosion in the number of di&#64256;erent constellations for such an event. In other words, 
while each individual outcome remains very unlikely, the &#8221;number of potential coincidences&#8221; increases 
very steeply, so that with a high probability at least some coincidences must happen. 
Thestorybehindtheotherconspiracytheoriesispresumablythesame:peoplehavebeencombingthrough 
zillions of details trying to &#64257;nd only a relatively tiny number of stunning parallels between Lincoln and 
Kennedy. In statistics, this search strategy is commonly called &#8221;data mining,&#8221; and in this context we 
speak of those rare coincidences which actually occur as &#8221;false discoveries,&#8221; which are typically not due 
to any systematic relationships, but simply result from the sheer numbers of potential relationships that 
we might investigate or test simultaneously. 
9 </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; &#65533;&#65533; &#65533; 
&#65533; &#65533;&#65533; &#65533; Thelast exampleillustratestwotypes of experimentsthat we wanttodescribe moregenerally: sampling 
with replacement versus sampling without replacement, each of which has a di&#64256;erent counting rule. 
&#8226; n draws from a group of size N with replacement: 
N &#183; N &#183; ... &#183; N = Nn 
n times 
possible outcomes. 
&#8226; n draws from a group of size N without replacement (whereN &#8805; n): 
N(N &#8722;1)(N &#8722;2)... 3&#183; 2&#183; 1 N! PN,n := N(N &#8722;1)(N &#8722;2)... (N &#8722;(n &#8722;1)) = = (N &#8722;n)(N &#8722;(n +1))... 3&#183; 2&#183; 1(N &#8722;n)! 
possible outcomes, where k!:= 1&#183; 2&#183; ... (k &#8722;1)k (readas &#8221;k-factorial&#8221;),and wede&#64257;ne0! =1. 
In fact, both of these enumeration rules derive from the multiplication rules, but since they are very 
prominent in statistics, we treat them separately. 
4.2 Permutations 
Example6 A shu&#64260;ed deck of cards is a permutation of an ordered deck of cards: it contains each card 
exactly once, though the order will in most cases be di&#64256;erent. 
De&#64257;nition2 Any ordered rearrangement of objects is called a permutation. 
Note that generating permutations corresponds to drawing N out of a group of N without replacement. 
Example7 Dodecaphonyis a compositionschemein modern classical musicinwhich eachpieceisbased 
on a tone row inwhich each ofthetwelvenotesofthechromaticscale(C,C sharp,D,D sharp,etc. up 
to B) appears exactly once. Therefore, each tone row is a permutation of the chromatic scale, and we 
couldinprinciplecountthenumberof allpossibledistinct &#8221;melodies&#8221; (about479million). 
Example8 The famous traveling salesman problem looks at a salesman who has to visit, say, 15 towns 
inanarbitrary order,andgivendistancesbetweentowns,wearesupposed to &#64257;nd theshortestroutewhich 
passes through each town on thelist(atleast) once. Using ourformulafordrawing15 out of agroup of 
15, we can calculate that there are 15!, which is about 1.3 trillion, di&#64256;erent paths, so this is a complicated 
problem, and we won&#8217;t solve it. 
We could imagine that in each town, the salesman has to visit 5 customers. If we consider all possible 
paths from customers to customers, we get (15&#183; 5)! permutations(that&#8217;s alot!). However,it may seem 
sensible to restrict our search to travel plans according to which the salesman meets with all 5 customers 
onceheisintown(in an ordertobedetermined). There are 5! possible orders in which the salesman 
can see customers in each town, and 15! possible orders in which he can visit towns, so we can use the 
multiplication rule to calculate the number of permutations satisfying this additional restriction as 
(5!5!... 5!) 15! =(5!)1515! 
15 times 
whichisstill aninsanelyhigh number,but certainly muchlessthanthe (15&#183;5)! unrestrictedpermutations.3 
3Few people, if any, have a good intuition for the scale of factorials since k! grows extremely fast in k. Stirling&#8217;s 
6 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; 
&#13;
 &#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 2 
Konrad Menzel 
February 5, 2009 
Probability of Events 
So far, we have only looked at de&#64257;nitions and properties of events -some of them very unlikely to 
happen(e.g. Schwarzeneggerbeing elected44thpresident),othersrelatively certain -butwehaven&#8217;tsaid 
anything about the probability of events, i.e. how likely an event is to occur relative to the rest of the 
sample space. 
Formally, a probability P is de&#64257;ned as a function from a collection of events A = {A1,A2,...}in S1 to 
the real numbers, i.e. 
A &#8722;&#8594; R P : A &#65533;&#8594; P (A) 
In order to get a useful de&#64257;nition of a probability, we require any probability function P to satisfy the 
following axioms: 
(P1) P (A)&#8805; 0 for any event A &#8712;A. 
(P2) P (S)=1 -i.e. &#8221;forsure, something isgoing tohappen&#8221; 
(P3) For any sequence of disjoint sets A1,A2,..., 
&#9115; &#9118; 
P &#9117; Ai&#9120; = P (Ai) 
i&#8805;1 i&#8805;1 
As a mathematical aside, in order for these axioms (and our derivations of properties of P (A) next 
lecture) to make sense, it must in fact be true that the collection A in fact contains the event S, and 
the complements and unions of its members, and this is what constitutes a sigma-algebra as de&#64257;ned in 
the footnote on the previous page. But again, for this class, we&#8217;ll take this as given without any further 
discussion, so you can ignore this &#64257;ne print for now. 
1For a consistent de&#64257;nition of a probability, this collection of events must satisfy the following properties 
(S1) S &#8712;A 
(S2) IfA &#8712;A, then its complement AC &#8712;A 
(S3) Anycountable union of events A1,A2,... isin A,i.e. A1 &#8746;A2 &#8746;... &#8712;A 
Such a collection of events is called a sigma-algebra on S. For the purposes of this class, this is not important, and we&#8217;ll 
take it as given that the problem at hand satis&#64257;es these axioms. 
1 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; &#65533; &#65533; &#65533; &#65533; &#65533; &#65533; 4.3 Combinations 
Example9 If wewantto counthowmanydi&#64256;erentpokerhands wecandrawfrom asingledeck of cards, 
i.e. 5 cards drawn from a single deck without replacements, we don&#8217;t care about the order in which cards 
were drawn, but rather whether each of the card was drawn at all. 
De&#64257;nition3 Any unordered collection of elements is called a combination. 
Acombinationconstitutesadrawwithoutreplacementfromagroup,but sincewenowdonotcareabout 
the order of elements, we don&#8217;t want to double-count series of draws which consist of the same elements, 
only in di&#64256;erent orders. For a collection of n elements, there are n! di&#64256;erent orders in which we could 
havedrawnthem(i.e. the number ofpermutations of the n elements). Therefore the number of di&#64256;erent 
combinations of n objectsfrom N objectsis 
&#65533; outcomesfromdrawing n out of N without replacement N! CN,n = = &#65533; orders in which can draw n elements (N &#8722;n)!n! 
This number is also known as the binomial coe&#64259;cient, and often denoted as 
N N! := n (N &#8722;n)!n! 
Notethat,eventhough welook at aratiooffactorials,thebinomial coe&#64259;cient alwaystakesintegervalues 
(as it should in order for the number ofcombinations to make sense). 
52 Example10 For poker, we can use this formula to calculate that there are =2598960 possible 5 
hands. 
Example11 A functional study group should not have more than, say, 5 members (there is no peda&#173;
gogical justi&#64257;cation for this number, but I just want to keep the math from becoming too complicated). 
There are currently 28 students registered for this class. How many possibilities for viable study groups 
(includingstudents working on their own) would be possible? We&#8217;ll have to calculate the number of study 
groups for each group size 1, 2, 3, 4, 5 and addthem up, sothat(ifIdidn&#8217;t make any mistakes) there are 
28 28 28 28 28 S = + + + + =28+378+3, 276+20, 475+98, 280 =122, 437 1 2 3 4 5 
possible study groups. 
Now back to our &#8221;challenge problem&#8221; from the beginning of the class: 
approximation, which works quite well for &#8221;high&#8221; values of k is 
k! &#8776;&#8730;
2k&#960;&#8222; k &#171;k 
e 
Inthepop-sciliterature a common comparisontoillustrate extremely large numbersinvolvesthe estimated total number of 
atomsinthe observable universe, whichis about1080 (well,Idon&#8217;thave anintuitionforthateither!). Intermsoffactorials, 
1080 &#8776;59!. The number 75! can be expressed as roughly 2.51030 (two anda half million trillion trillion) times the number &#183; 
of atoms in the universe.
Sinceyou&#8217;d wantto avoid calculationsinvolving suchhigh numbers, notethatfor mostpurposes, we only havetodeal with
ratios of factorials, so we should &#64257;rst see which terms cancel, e.g. 98! 98&#183;97&#183;96&#183;95&#183;94!
= .94! 94! 
7 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>   
3 S 
A Bc 
A B B Ac BA 
Figure 1: Partition of A &#8746;B into disjoint events 
Example: &#8220;Simple&#8221; Probabilities 
Suppose we have a &#64257;nite sample space with outcomes which are ex ante symmetric in the sense that we 
have no reason to believe that either outcome is more likely to occur than another. If we let n(C)denote 
the number of outcomes in an event C, we can de&#64257;ne a probability 
n(A)P (A):= n(S) 
i.e. the probability equals the fraction of all possible outcomes in S that are included in the event 
A. This distribution is called the &#8221;simple&#8221; probability distribution or also the &#8221;logical&#8221; probability. A 
randomizationdevice(e.g. acoinoradie) forwhich each outcomeisequally likely issaidtobe fair. 
Now let&#8217;s check whether the three axioms are in fact satis&#64257;ed: 
(P1): P (A)&#8805; 0followsdirectly fromthefactthat n(&#183;)only takes(weakly) positive values. 
(P2): P (S)= n
n(
(S
S)
) =1. 
(P3): For two disjoint eventsA and B, 
n(A &#8746;B) n(A)+n(B)+n(A &#8745;B) n(A) n(B)P (A &#8746;B)= = = + = P (A)+P (B) n(S) n(S) n(S) n(S) 
For more than two sets, the argument is essentially identical. 
Example1 Suppose a fair die is rolled once. Then the sample space equals S = {1, 2,..., 6}, so n(S)= 
6. What is the probability of rolling a number strictly greater than 4? -since the event is A = {5, 6}, 
n(A) = 2 = 1 n(A)= n({5, 6})=2. Hence P (A)= n(S)63 . 
If a die is rolled twice, what is the probability that the sum of the numbers is less than or equal to 4? 
Let&#8217;s check: S = {(1, 1), (1, 2),..., (2, 1), (2, 2),..., (6, 6)}, so that n(S)=62 =36. The event 
B = &#8221;Sum of Dice &#8804; 4&#8221; = {(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (3, 1)} 
so that P (B)= n(B) = 6 = 1 
n(S) 36 6 . 
In a minute, we&#8217;ll look at more sophisticated techniques for enumerating outcomes corresponding to 
certain events. 
4 Image by MIT OpenCourseWare.</text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec13/</lecture_pdf_url>
      <lectureno>13</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; &#65533; Note that since fY|X(y|X)carries the random variable X as its argument, the conditional expectation is 
also a random variable. However, we can also de&#64257;ne the conditional expectation of Y given a particular 
value of X, 
yfY |X(y|x) if Y isdiscrete E[Y|X = x]= &#65533; &#8734;y 
&#8722;&#8734; yfY|X(y|x)dy if Y is continuous 
whichisjust a numberfor anygiven value of x as long as the conditional density is de&#64257;ned. 
Sincethecalculationgoesexactlylikebefore,onlythat wenowintegrateoverthe conditional distribution, 
won&#8217;t do a numerical example (for the problem set, just apply de&#64257;nition). Instead let&#8217;s discuss more 
qualitative examples to illustrate the di&#64256;erence between conditional and unconditional examples: 
Example3 (The Market for &#8221;Lemons&#8221;) The following is a simpli&#64257;ed version of a famous model for 
the market for used cars by the economist George Akerlof. Suppose that there are three types X of used 
cars: cars in an excellent state (&#8221;melons&#8221;), average-quality cars (&#8221;average&#8221; not in a strict, statistical, 
sense), and carsin apoor condition(&#8221;lemons&#8221;). Each type of caris equallyfrequent,i.e. 
1 P(&#8221;lemon&#8221;) = P(&#8221;average&#8221;) = P(&#8221;melon&#8221;) = 3 
Thesellerand abuyerhavethefollowing(dollar) valuations YS and YB, respectively, for each type of cars: 
Type Seller Buyer 
&#8221;Lemon&#8221; 5,000$ 6,000$ 
&#8221;Average&#8221; 6,000$ 10,000$ 
&#8221;Melon&#8221; 10,000$ 11,000$ 
The &#64257;rst thing to notice is that for every type of car, the buyer&#8217;s valuation is higher than the seller&#8217;s, so 
for each type of car, trade should take place at a price between the buyer&#8217;s and the seller&#8217;s valuations. 
However, for used cars, quality is typically not evident at &#64257;rst sight, so if neither the seller nor the buyer 
know the type X of a car in question, their expected valuations are, by the law of iterated expectations 
E[YS]=	E[YS|&#8221;lemon&#8221;]P(&#8221;lemon&#8221;)+ E[YS|&#8221;average&#8221;]P(&#8221;average&#8221;)+ E[YS|&#8221;melon&#8221;]P(&#8221;melon&#8221;) 
1 = (5,000+6,000+10,000) =7,000 3
E[YS]= E[YB|&#8221;lemon&#8221;]P(&#8221;lemon&#8221;)+ E[YB|&#8221;average&#8221;]P(&#8221;average&#8221;)+ E[YB|&#8221;melon&#8221;]P(&#8221;melon&#8221;) 
1 = (6,000+10,000+11,000) =9,000 3
so trade should still take place.
But in a more realistic setting, the seller of the used car knows more about its quality than the buyer
(e.g. history of repairs, accidents etc.) and states a price at which he is willing to sell the car. If the
seller can perfectly distinguish the three types of cars, whereas the buyer can&#8217;t, the buyer should form
expectations conditional on the seller willing to sell at the quoted price.
If the seller states a price less than 6,000 dollars, the buyer knows for sure that the car is a &#8221;lemon&#8221;
because otherwise the seller would demand at least 6,000,i.e.
E[YB|YS &lt; 6000] = E[YB|&#8221;lemon&#8221;] =6000 
and trade would take place. However, if the car was in fact a &#8221;melon&#8221;, the seller would demand at least 
10,000 dollars, whereas the buyer would pay at most 
E[YB|YS &#8804; 10,000] = E[YB]=9,000 &lt; 10,000 
5 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; 
&#65533; &#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 13 
Konrad Menzel 
March 31, 2009 
Covariance 
The covariance of X and Y is a measure of the strength of the relationship between the two random 
variables. 
De&#64257;nition1 For two random variables X and Y, the covariance is de&#64257;ned as 
Cov(X,Y)= E [(X &#8722;E[X])(Y &#8722;E[Y])] 
First,byjust applying thede&#64257;nitions, weget 
Property1 
Cov(X,X)=Var(X) 
Property2 
Cov(X,Y)=Cov(Y,X) 
Furthermore, we have the following result which is very useful to calculate covariances: 
Property3 
Cov(X,Y)= E[XY]&#8722;E[X]E[Y] 
Thisis ageneralization of the analogousproperty of variances, and theproof uses exactly the samekind 
of argument. Let&#8217;s do an example to see how this result is useful: 
Example1 Suppose X and Y havejointp.d.f. 
8xy if0 &#8804; x &#8804; y &#8804; 1 fXY (x,y)= 0 otherwise 
What is the covariance Cov(X,Y)? -Let&#8217;s calculate the components which enter according to the right-
hand side of the equation in property 7: 
&#65533; &#8734; &#8734; 11 
E[XY]= xyfXY (x,y)dxdy = 8x 2 y 2dydx 
&#8722;&#8734; &#8722;&#8734; 0 x &#65533; 1 1 1 8 = 8x 2 y 2dy dx = x 2(1&#8722;x 3)dx 
0 x 0 3 
&#65533; &#65533; &#65533;18 1 8 x3 x6 
= (x 2 &#8722;x 5)dx = &#8722; 3 0 33 6 0 
811 4 = &#8722; = 336 9 
1 </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; &#65533; &#65533; 
&#65533; &#65533; so that the seller won&#8217;t be able to sell the high-quality car at a reasonable price.
The reason why the market for &#8221;melons&#8221; breaks down is that in this model, the seller can&#8217;t credibly
assure the buyer that the car in question is not of lower quality, so that the buyer factors the possibility
of getting the bad deal into his calculation.
An important relationship between conditional and unconditional expectation is the Law of Iterated 
Expectations(aclose &#8221;cousin&#8221; oftheLawofTotalProbability which wesawearlierinthelecture): 
Proposition1 (Law of Iterated Expectations) 
E [E[Y|X]]= E[Y] 
Proof: Let g(x)= E[Y|X = x], which is a function ofx. We can now calculate the expectation 
&#65533; &#8734; &#65533; &#8734; 
E[g(X)] = g(x)fX(x)dx = E[Y|X = x]fX(x)dx 
&#8722;&#8734; &#8722;&#8734; &#65533; &#8734; &#8734; fXY (x,y) = y dy fX(x)dx 
&#8722;&#8734; &#8722;&#8734; fX(x) &#65533; &#8734; &#65533; &#8734; 
= yfXY (x,y)dydx 
&#8722;&#8734; &#8722;&#8734; &#65533; &#8734; &#65533; &#8734; 
= y fXY (x,y)dx dy 
&#8722;&#8734; &#8722;&#8734; &#65533; &#8734; 
= yfY (y)dy = E[Y] 
&#8722;&#8734; 
6 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Property7 
&#8722;1 &#8804; &#961;(X,Y)&#8804; 1 
Broadly speaking, we distinguish three cases 
&#8226; &#65533;(X,Y)&gt; 0: &#8221;X and Y are positively correlated&#8221; 
&#8226; &#65533;(X,Y)=0: &#8221;X and Y are uncorrelated&#8221; 
&#8226; &#65533;(X,Y)&lt; 0: &#8221;X and Y are negatively correlated&#8221; 
Property8 
|&#961;(X,Y)|=1 &#8660; Y = aX + b 
for some constants a &#65533;=0 and b. 
I.e. the absolute value of the correlation coe&#64259;cient equals 1 if there is a deterministic linear relationship 
between the two random variables. In that case we say that X and Y are perfectly correlated. 
Remark1 A very important principle of data analysis is that the statistical relationship between two 
random variables does not necessarily correspond to mechanical or causal statements which we would 
actually wanttomakebased onthedata. E.g. wetypically observeindatasetsthatthetimepeoplespend 
working out in the gym is positively correlated with health, but this does not necessarily mean that sports 
causes health to improve. But it could as well be that some people are so unhealthy that they wouldn&#8217;t 
even think about going to the gym. 
A more abstract way to see why correlation of X and Y and causation of Y by X areinherentlydi&#64256;er&#173;
ent concepts, notice that the covariance is symmetric in X and Y, so we can change their roles. For 
causality however, we think of a speci&#64257;c direction of the relationship, i.e. we could have X &#8594; Y or &#8221;X 
causes/a&#64256;ects Y&#8221; but simultaneously &#8221;Y doesn&#8217;t cause/a&#64256;ect X&#8221;, so we can&#8217;t change the roles of X and 
Y. Therefore: 
Correlation does not equal causation! 
(Much)more about that in your Econometrics class. 
1.1 Preview: Regression 
Say, we are interested in the relationship between a worker&#8217;s income Y and her education as measured 
with years of schooling X (for simplicitylet&#8217;sjust assume thatboth are continuous random variables). 
Then we can always rewrite the relationship between X and Y as 
Y = &#945;+ &#946;X + U 
where U is a random variable with E[U] = 0 and Cov(X,U) = 0 (in the regression context it will be 
called the residual). 
One way ofdetermining the value oftheparameters(&#945;,&#946;)is to solve 
(&#945;,&#946;)=argmin E[(Y &#8722;X&#946; &#8722;&#945;)2] 
&#945;,&#946; 
3 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; Also, by the same steps as above, 
&#65533; 1 &#65533; 1 &#65533; 1 8 E[Y] = 8x y 2dy dx = x(1&#8722;x 3)dx 30 x 0 &#65533; &#65533; &#65533;1 8 1 8 x2 x5 83 4 = (x &#8722;x 4)dx = &#8722; = &#183; = 3 0 32 5 0 310 5 
and 
&#65533; 1 1 1 8 E[X] = 8x 2 ydy dx = x 2(1&#8722;x 2)dx 
0 x 0 2 
&#65533; 1 11 8 =4(x 2 &#8722;x 4)dx =4 &#8722; = 35 15 0 
Putting all pieces together, and applying property 7, 
4 844&#183; 25&#8722;32&#183; 3 4 Cov(X,Y)= E[XY]&#8722;E[X]E[Y]= &#8722; &#183; = = 9 15 5 225 225 
We already showed that for two independent random variables X and Y, the variance of the sum equals 
the sum of variances. Here&#8217;s a generalization to random variables which are not necessariy independent: 
Property4 
Var(X + Y)=Var(X)+Var(Y)+2Cov(X,Y) 
The idea behind the proof is to apply properties 3 and 7 to get 
Var(X + Y)= E[(X + Y)2]&#8722;E[X + Y]2 
= E[X2 +2XY + Y2]&#8722;E[X]2 &#8722;2E[X]E[Y]&#8722;E[Y]2 
= E[X2]&#8722;E[X]2 + E[Y2]&#8722;E[Y]2 +2(E[XY]&#8722;E[X]E[Y]) 
= Var(X)+Var(Y)+2Cov(X,Y) 
Property5 For random variables X,Y,Z, 
Cov(X,aY + bZ + c)= aCov(X,Y)+bCov(X,Z) 
Property6 
Cov(aX + b,cY + d)= acCov(X,Y) 
Since by the last property, the covariance changes with the scale of X and Y, we would like to have a 
standardized measure which gives us the strength of the relationship between X and Y, and which is 
not a&#64256;ected by changing, say, the units of measurement of the two variables. The most frequently used 
measure of that kind is the correlation coe&#64259;cient: 
De&#64257;nition2 The correlation coe&#64259;cient of X and Y isgivenby 
Cov(X,Y)&#961;(XY)= &#65533; 
Var(X)Var(Y) 
The correlation coe&#64259;cient is normalized in a way such that 
2 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; Taking &#64257;rst-order conditions with respect to &#946; (notice that expectations are linear in their argument, so 
we can pass the derivative through the integral), we get 
d 0 = d&#946; E[(Y &#8722;X&#946; &#8722;&#945;)2] 
&#65533; 
= d 
d&#946; (y&#8722;x&#946; &#8722;&#945;)2fXY (x,y)dydx 
&#65533; 
= d 
d&#946; &#65533; 
(y&#8722;x&#946; &#8722;&#945;)2&#65533; 
fXY (x,y)dydx 
d = E [(Y &#8722;X&#946; &#8722;&#945;)2]d&#946;
= E [2X(Y &#8722;X&#946; &#8722;&#945;)] 
Similarly, taking &#64257;rst-order conditions with respect to &#945;, 
d d 0= E[(Y &#8722;X&#946; &#8722;&#945;)2]= E [(Y &#8722;X&#946; &#8722;&#945;)2]= E[2(Y &#8722;X&#946; &#8722;&#945;)] d&#945; d&#945;
Solving the last expression for &#945;, 
&#945; = E[Y]&#8722;E[X]&#946; 
Plugging this into the &#64257;rst-order condition for &#946;, we get 
0= E [X(Y &#8722;X&#946; &#8722;(E[Y]&#8722;E[X]&#946;))]= E[XY]&#8722;E[X2]&#946; &#8722;E[X]E[Y]+E[X]2&#946; 
so that we can now solve for the parameter 
E[XY]&#8722;E[X]E[Y] Cov(X,Y)&#946; = = E[X2]&#8722;E[X]2 Var(X) 
We can now verify that indeed E[U]= E[Y &#8722;X&#946; &#8722;&#945;]= 0 and Cov(X,U)= Cov(X,Y &#8722;X&#946; &#8722;&#945;)=0 
(in fact the &#64257;rst follows directlyfrom the &#64257;rst-order condition for &#945;, and the second from the &#64257;rst-order 
conditionfor &#946;). 
Then the &#8221;regression &#64257;t&#8221; &#945; + &#946;X is the part of Y whichiscorrelated with(or &#8221;explained&#8221; by) X, and 
U is the part of Y which is uncorrelated with X. The parameters &#945; and &#946; are usually called regression 
parameters or least-squares coe&#64259;cients. Linear regression is the &#8221;workhorse&#8221; of much of econometrics, 
and you&#8217;ll see this in many variations over the course of 14.32 and other econometrics classes. 
2 Conditional Expectations 
Example2 Each year, a &#64257;rm&#8217;s R&amp;D department produces X innovations according to some random 
process, where E[X] =2 and Var(X) =2. Each invention is a commercial success with probability 
p =0.2 (assume independence). The number of commercial successes in a given year are denoted by S. 
Since we know that the mean of S &#8764; B(x,p)= xp, conditional on X = x innovations in a given year, xp 
of them should be successful on average. 
The conditional expectation of X given Y is the expectation of X taken over the conditional p.d.f.: 
De&#64257;nition3 
yfY |X(y|X) if Y isdiscrete E[Y|X]= &#65533; &#8734;y 
&#8722;&#8734; yfY|X(y|X)dy if Y is continuous 
4 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec04/</lecture_pdf_url>
      <lectureno>4</lectureno>
      <slides>
        <slide>
          <slideno>7</slideno>
          <text>e.g. there is only one way candidate A can get all the votes. We can formulate the probability of each 
outcome in terms of simple probabilities, and from there we can aggregate over equivalent outcomes to 
obtain the probability for a given total number of votes. 
Remark2 Not all random events have a numerical characteristic associated with them in which we are 
interested(e.g. if theeventis &#8221;itwill raintomorrow&#8221;,wemightnotcarehowmuch). Thenwedon&#8217;thave 
to bother with random variables, but can just deal with events as before. Alternatively, we could de&#64257;ne 
a random variable which takes the value 1 if the event occurs, and 0 otherwise (we&#8217;ll use that &#8221;trick&#8221; 
sometimes in the future). 
7 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>Juliet alsoknows thatifRomeolovedher,he wouldgiveherjewelery withprobability P (J|L)=0.80, or 
a serenade with probability 
P (S|L)=0.20 
(this is actually only what Juliet thinks, keeping in mind that Romeo also loves football). If he doesn&#8217;t 
loveher anymore,hehas noidea whatJuliet wants, andhe&#8217;llgiveher a serenade(or, more realistically, 
the roses she wanted last year, or forget about Valentine&#8217;s Day altogether) with probability 
P (S|LC )=0.80 
(note that, though givinga serenade is still very embarrassing for Romeo, it&#8217;s also much cheaper). 
It turns out that Romeo ends up giving Juliet a serenade. Should she dump him right away? By Bayes&#8217; 
theorem, Juliet&#8217;s posterior beliefs about Romeo&#8217;s intentions are 
&#183; P (S|L)P (L) (1&#8722;0.8)0.95 2 19 38 P (L|S)= = = 10 20 = &#8776; 0.826 P (S|L)P (L)+P (S|LC )P (LC ) (1&#8722;0.8)0.95+0.8(1&#8722;0.95) 2 19 81 46 &#183; +10 20 10 20 
and we&#8217;ll let Juliet decide on her own whether this is still good enough for her. 
Inreal-lifesituations, mostpeoplearen&#8217;t verygood atthistypeofjudgmentsand tend tooverratethe 
reliability of a test like the ones from the last two examples -in the cognitive psychology literature, this 
phenomenon is known as base-rate neglect, where in our example &#8221;base-rate&#8221; refers to the proportions 
P (A) and P (AC ) of infected and healthy individuals, or the prior probabilities P (L) and P (LC ) of 
Romeoloving ornotlovingJuliet, respectively. If theseprobabilitiesareverydi&#64256;erent,biasesinintuitive 
reasoning can be quite severe. 
Example5 The &#8221;Monty Hall paradox&#8221;:1 There used to be a TV show in which a candidate was asked to 
choose among three doors A,B,C. Behind one ofthedoors,there was aprize(say, abrand-new washing 
machine), and behind each of the other two there was a goat. If the candidate picked the door with the 
prize, he could keep it, if he picked a door with a goat, he wouldn&#8217;t win anything. In order to make the 
game a little more interesting, after the candidate made an initial choice, the host of the show would 
always open one of the two remaining doors with a goat behind it. Now the candidate was allowed to 
switch to the other remaining door if he wanted. Would it be a good idea to switch? 
Without loss of generality, assume I picked door A initially. The unconditional probability of the prize 
being behind door A is 31 . If the prize was in fact behind door a, the host would open door b or door 
c, both of which have a goat behind them, with equal probability. If the initial guess was wrong, there is 
only one door left which was neither chosen by the candidate nor contains the prize. Therefore, given I 
initiallypicked A and the host then opened C, 
&#183; P (prizebehindA|C opened) = P (C opened|prizebehind A)P (prizebehindA)= 1
2 
1 1
3 = 1 
P (C opened) 2 3 
On the other hand 
P (C opened|prizebehind B)P (prizebehindB)1&#183; 31 2 P (prizebehindB|C opened) = = 1 = P (C opened) 2 3 
Therefore, I could increase my chances of winning the prize if I switch doors.
Intuitively, the newly opened door does not convey any information about the likelihood of the prize being
1You can read up on the debate on http://people.csail.mit.edu/carroll/probSem/Documents/Monty-NYTimes.pdf 
3 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 
&#65533; behinddoor A, since the host would not have opened it in any case -and in fact, given that we chose A, 
the events &#8221;A contains the prize&#8221; and &#8221;C is opened&#8221; are independent. However, the fact that he did not 
open B could arise from two scenarios: (1) the prize was behind A, andthehostjust choseto open C 
at random, or(2) theprize wasbehinddoor B, so the host opened door C only because he didn&#8217;t have a 
choice. Therefore, being able to rule out C only &#8221;bene&#64257;ts&#8221; event B. 
2 Recap Part 1: Probability 
Before we move onto the second chapter of thelecturelet&#8217;sjust summarize what wehavedone sofar, 
and what you should eventually should feel familiar and comfortable with: 
2.1 Counting Rules 
&#8226;	drawing n out of N with replacement: Nn possibilities 
&#8226;	drawing n out of N without replacement: (NN
&#8722;! 
n)! possibilities 
&#8226;	permutations: N!possibilities 
N &#8226;	combinations of n out of N: possibilities n 
2.2 Probabilities 
&#8226;	independence: P (AB)= P (A)P (B) 
P (AB)&#8226;	conditionalprobability P (A|B)= P (B) if P (B)&gt; 0. 
&#8226;	P (A|B)= P (A)if and only if A and B areindependent 
&#8226;	Law of Total Probability: for a partition B1,...,Bn of S, where P (Bi)&gt; 0 
n 
P (A)= P (A|Bi)P (Bi) 
i=1 
&#8226;	BayesTheorem:
P (B|Ai)P (Ai)
P (Ai|B)= P (B) 
There are also a few things we saw about probabilistic reasoning in general: 
&#8226;	use of set manipulations to reformulate event of interest into something for which it&#8217;s easier to 
calculateprobabilities(e.g. complement,partitionsetc.) 
&#8226;	the importance of base rates in converting conditional into marginal/unconditional probabilities 
(e.g. in Bayes theorem or composition e&#64256;ects in the heart surgeons example) 
&#8226;	can sometimes make dependent events A and B independent by conditioning on another event C 
(or make independent events dependent). 
4 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 4 
Konrad Menzel 
February 12, 2009 
Bayes Theorem 
In the last lecture, we introduced conditional probabilities, and we saw the Law of Total Probability 
as a way of relating the unconditional probability P (A) of an event A to the conditional probabilities 
P (A|Bi). Another important relationship between conditional probabilities is Bayes Law which relates 
the conditional probability P (A|B) to the conditional probability P (B|A), i.e. how we can revert the 
order of conditioning. This result plays an important role in many areas of statistics and probability, 
most importantly in situations in which we &#8221;learn&#8221; about the &#8221;state of the world&#8221; A from observing the 
&#8221;data&#8221; B. 
Example1 The ancientGreeks(who apparently didn&#8217;tknow much statisticsyet) noticedthat eachtime 
after a ship had sunk, all surviving seamen reported having prayed to Poseidon, the Greek god of the sea. 
From this observation, they inferred that they were in fact saved from drowning because they hadprayed. 
This example was actually brought up by the English philosopher Francis Bacon in the 16th century. 
In statistical terms, let&#8217;s de&#64257;ne the events A =&#8221;survives&#8221; and B =&#8221;prayed&#8221;, so that the question becomes 
whether praying increases the odds of survival, i.e. whether P (A|B)&gt;P (A)&#8801; p, say. The observation 
that all surviving seaman had been praying translates to P (B|A) =1. Is that information actually 
su&#64259;cient to answer the question whether praying strictly increases the chances of survival? How do we 
use the information on P (B|A)to learn about P (A|B)? 
From the de&#64257;nition of conditional probabilities, we obtain 
P (AB)= P (A|B)P (B)= P (B|A)P (A) 
Rearranging the second equality, we get 
P (B|A)P (A)P (A|B)= P (B) 
We&#8217;ve also seen that we can partition the event 
P (B)= P (B|A)P (A)+P (B|AC )P (AC ) 
sothat 
P (B|A)P (A)P (A|B)= P (B|A)P (A)+P (B|AC )P (AC ) 
We can generalize this to any partition of S as summarized in the following theorem: 
1 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>Figure1:Stroboscopicimageof acoin &#64258;ip(Courtesy ofAndrewDavidhazy and theSchool of PhotoArts 
and Sciences of Rochester Institute of Technology. Used with permission. c&#65533;AndrewDavidhazy,2007.) 
in the initial state s &#8712; S (not even taking into account external in&#64258;uences like, say, the gravitation of a 
car driving by), and no matter how we &#64258;ip the coin, it is totally impossible to control the initial position, 
velocity, etc. precisely enough to produce the desired outcome with certainty. Also, it will typically be 
impossible to solve the di&#64256;erential equations describing the system with su&#64259;cient precision. Therefore, 
we can only give probabilities for being in parts of S, which again maps to probabilities for the outcomes 
H and T . So even though there need not be any &#8221;genuine&#8221; randomness in the situation, this is how it 
plays out for us in practice. 
While this de&#64257;nition of the random variable brings out more the philosophical point how we think about 
random variables and probabilities, it is clearly not very operational, and for practical purposes, we&#8217;d 
rather stick to the &#64257;rst way of describing the problem. 
Remark1 The probability function on the sample space S induces a probability distribution for X via 
P (X &#8712; A)= P ({s &#8712; S : X(s)&#8712; A}) 
for any event A &#8834; R in the range of X. 
Eventhoughformally, X is a function from the sample space into the real numbers, we often treat it 
asavariable,i.e. wesay thatit can &#8221;takeon&#8221; variousvalueswith thecorrespondingprobabilitieswithout 
specifying its argument. In other words, for most applications, we will only specify P (X &#8712; A) without 
any referencetotheunderlying samplespace S and theprobability on S. E.g. in the coin &#64258;ip example -as 
described above -wewon&#8217;ttry&#64257;gureouttheexact relationshipbetweencoordinatesin S (initialposition, 
velocity,orientationetc. ofthecoin) and outcomes(whichisnumericallyimpossible) and aprobability 
distribution overthese coordinates,but wejust needtoknowthat P (X =1) = P (X =0) = 1
2 . 
Example8 If we toss 10 coins independently of another, we could de&#64257;ne a random variable X =(Total 
Number of Tails). We&#8217;ll analyze the distribution for this type of random variable in more detail below. 
Example9 We might be interested in the outcome of an election. Say there are 100 million voters 
and 2 candidates. Each voter can only vote for either of the candidates, so there are 2100,000,000 distinct 
outcomes in terms of which voter voted for which candidate. We could now de&#64257;ne the random variable 
X corresponding to the total number of votes for candidate A (and for elections, that&#8217;s typically all we 
care about). For each value for the number of votes, there is a corresponding number of basic outcomes, 
6 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; 
&#65533; 3 Random Variables 
Now let&#8217;s move on to the second big topic of this class, random variables. 
Example6 Flipping a coin, version I: We could de&#64257;ne a variable X which takes the value 1 if the coin 
comes up Heads H and 0 if we toss Tails T . The sample space for this random experiment is S = {H,T }, 
and the range of the random variable is {0, 1}. 
De&#64257;nition1 A real-valued random variable X is any function 
S &#8594; R X : s &#65533;&#8594; X(s) 
which maps the outcomes of an experiment to the real numbers. 
Asahistorical aside, whentheideaof randomvariableswasdeveloped around1800,therewasnorole 
for &#8221;genuine&#8221; randomness in the minds of mathematicians and other scientists. Rather, chance was seen 
as a consequence of us not having full knowledge about all parameters of a situation we are analyzing, 
and ourinability to apply the(supposedlyfullydeterministic) laws of nature topredictthe outcome of 
an experiment. A being able to do all this is known as the &#8221;Laplacean demon&#8221;, described by the famous 
mathematician Pierre Simon de Laplace as follows: 
An intellect which at any given moment knew all the forces that animate Nature and the 
mutual positions of the beings that comprise it, if this intellect were vast enough to submit 
itsdatato analysis, could condenseinto a singleformulathe movement of thegreatbodies of 
the universe and that of the lightest atom: for such an intellect nothing could be uncertain, 
andthefuturejustlikethepast wouldbepresentbeforeits eyes.2 
This view ofthe worlddoesn&#8217;tquitehold up to subsequentdevelopmentsinphysics(e.g. genuineinde&#173;
terminacy inquantumphysics) or computationaltheory(e.g. G&#168; odel&#8217;stheorem: theintellect wouldhave 
to be more complex than itself since its predictions are part of the universe it&#8217;s trying to predict), but 
it&#8217;s still what underlies our basic concept of probabilities: randomness in the world around us primarily 
re&#64258;ects our lack of information about it. 
Example7 As an illustration, here is version II of the coin &#64258;ip: in order to illustrate Laplace&#8217;s idea, we 
could think of a more complicated way of de&#64257;ning the sample space than in the &#64257;rst go above: in classical 
mechanics, we can (at least in principle) give a full description of the state of the coin (a rigid body) 
at any point in time, and then use the laws of classical mechanics to predict its full trajectory, and in 
particularwhetheritisgoingtoend up withheads(H) or tails(T ) on top. More speci&#64257;cally, we could 
describe the sample space as the state of the mechanical system at the point in time the coin is released 
intothe air. Afull(though somewhatidealized) description ofthe state ofthe systemisgivenby(1) the 
position, and(2) the velocity of the center of mass of the coin together with(3) its orientation, and(4) 
its angular momentum at a given time t0 -each of these has 3 coordinates, so S = R12 . Eachpoint s &#8712; S 
belongs to one of the two events {H,T }deterministically. If we assign values X =1 to the event H &#8834; S 
that heads are up, and X =0 for tails T , this mapping is the random variable 
X : R12 &#8594;{0, 1}, givenby X : s &#65533;&#8594; 1 if s &#8712; H 
s &#65533;&#8594; 0 otherwise, i.e. if s &#8712; T 
Since the problem is -almost literally -very knife-edged, the outcome is highly sensitive to tiny changes 
2Laplace, P. (1814): A Philosophical Essay on Probabilities 
5 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>Theorem1 (Bayes Theorem) If A1,A2,... is a partition of S, for any event B with P (B)&gt; 0 we 
can write 
P (B|Ai)P (Ai) P (B|Ai)P (Ai)P (Ai|B)= = &#65533; P (B) j&#8805;1 P (B|Aj )P (Aj) 
&#8226;	P (Ai)isthe prior probability of an event Ai (i.e. probability before experiment is run) 
&#8226;	P (Ai|B)isthe posterior probability of Ai (i.e. theprobability after we ranthe experiment andgot 
information B -as obtained from Bayes theorem) 
An entire statistical theory of optimal decisions is built on this simple idea: Bayesian Decision Theory. 
Example2 For the previous example of seamen surviving the sinking of a ship, we were able to observe 
P (B|A)=1, and the(unconditional) survival rate of seamen, P (A). However, we can also see that we 
don&#8217;t have su&#64259;cient information to answer the question whether praying strictly increases the chances of 
survival since we couldn&#8217;t observe P (B|AC ), the fraction of seamen who prayed among those who were 
going to drown. It is probably safe to assume that those, fearing for their lives, all of them prayed as well 
(implyingP (B|AC )=1), so that 
1&#183; pP (A|B)=	 = p = P (A)1&#183; p +1 &#183; (1&#8722;p) 
Inasense,thereasoning oftheancientGreeksisaninstanceof &#8221;survivorbias&#8221; (well,inaveryliteral 
sense): Bayes theorem shows us that if we can only observe the survivors, we can&#8217;t make a judgement 
about why they survived unless we know more about the subpopulation which did not survive. 
Example3 An important application of Bayes rule is how we should interpret a medical test. Suppose 
a doctor tests a patient for a very nasty disease, and we&#8217;ll call the event that the patient in fact has 
thedisease A. The test can either give a positive result -we&#8217;ll call this event B -or a negative result, 
corresponding to event BC . The test is not fully reliable in the sense that we can&#8217;t determine for sure 
whether the patient has the disease, but the probabilities of a positive test result is 
P (B|A)=99%,P (B|AC )=5% 
Finally, we know that the disease is relatively rare and a&#64256;ects 0.5% of the population which shares the 
patient&#8217;s age, sex, and other characteristics. Let&#8217;s say the test gives a positive result. What is the 
(conditional)probability that the patient does in fact have the disease? 
Bayes rule gives that 
P (B|A)P (A) P (B|A)P (A)	 0.99&#183; 0.005 P (A|B)= =	 = &#8776; 0.0905 P (B) P (B|A)P (A)+P (B|AC )P (AC )0.99&#183; 0.005+0.05&#183; 0.995 
Since the overall prevalence of the disease, P (A) is relatively low, even a positive test result gives only 
relatively weak evidence for disease. 
Example4 RomeoandJuliethavebeendatingforsometime,and comeValentine&#8217;sDay(asareminder: 
that&#8217;sSaturday),Romeo cangiveJuliet eitherjewelery, J, or a serenade, S. Juliet wantsjewelery, and 
if Romeo really loved her, he would read her wishes from her eyes, and besides, she had told Romeo about 
the jewelery two weeks earlier, during the &#64257;nal half hour of the Superbowl. Juliet also has &#64257;rst doubts 
that Romeo still loves her, an event we&#8217;ll call L. To be speci&#64257;c 
P (L)=0.95 
2 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec01/</lecture_pdf_url>
      <lectureno>1</lectureno>
      <slides>
        <slide>
          <slideno>3</slideno>
          <text>as president in November, i.e. as a &#64257;rst try we could look at the main candidates at the early stages of
the primaries:
S={Clinton, Huckabee, McCain, Obama, Paul, Romney, Schwarzenegger }
Is this a good description? - probably not: even though these are the most likely outcomes, we can&#8217;t
logically rule out that some other candidate (from either party or independent) enters the race later on,
so a more fool-proof de&#64257;nition of the random experiment would augment the sample space
&#732;S={Clinton, Huckabee, McCain, Obama, Paul, Romney, Schwarzenegger,
other Democrat, other Republican, other Independent }
but to keep things simple, let&#8217;s just ignore this possibility for now.
Some events of interest could be e.g.
&#8221;The 44th president of the US will be Republican&#8221; = {Huckabee, McCain, Paul, Romney, Schwarzenegger,
other Republican }
&#8221;The 44th president is married to the 42nd president = {Clinton }
2.2 More about Sets and Events
2.2.1 Set Inclusion &#8221; &#8834;&#8221;
The event Biscontained inAif every outcome in Balso belongs to A, or in symbols
B&#8834;Aif (s&#8712;B=&#8658;s&#8712;A)
Clearly, any event Cis contained in the sample space S, i.e.
C&#8834;Sfor any event C
and every event includes the impossible event
&#8709; &#8834;Cfor any event C
ABS
Figure 1: B&#8834;A-&#8221;Bimplies A&#8221;
IfAandBcontain each other, they are equal,
A&#8834;BandB&#8834;A=&#8658;A=B
3Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>we can see that
A&#8745;(B&#8746;C) = {Clinton } &#8745; {Clinton,Huckabee,McCain,Paul,Romney,Schwarzenegger }
={Clinton }
(A&#8745;B)&#8746;(A&#8745;C) = {Clinton } &#8746; &#8709;={Clinton }
as it should be according to the &#64257;rst distributive property.
2.2.4 Set Complement, Ac
Thecomplement ACofAis the set of outcomes in Swhich do not belong to A, i.e.
AC={s&#8712;S|s&#8712;/ A}=S\A
AS
Ac
Figure4:ComplementtoA-&#8221;notA&#8221;
Fromthede&#64257;nition,youcaneasilycheckthatcomplementshavethefollowingproperties
(AC)C=A
A&#8746;AC=S
A&#8745;AC=&#8709;
Fromthelaststatement,itfollowsthat
SC=&#8709;
andtogetherwiththe&#64257;rstproperty,thisimplies
&#8709;C=S
Oneusefulsetofrelationshipsbetweenintersectionsandunionsisthefollowing
(A&#8746;B)C=AC&#8745;BC
(A&#8745;B)C=AC&#8746;BC
6Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>polls at most a few thousand out of over a hundred potential voters. In medical trials, we try to draw
conclusions about the e&#64256;ectiveness of a drug for an entire population from only a few dozen study
participants.
If we only observe a subset of individuals (e.g. a random sample of voters in an exit poll) from a population
of interest (e.g. all voters who turned out for a primary election), there will be some uncertainty over
whether this sample was actually representative for the whole population with respect to the question
we&#8217;re after (e.g. the vote share for a particular candidate). Formalizing this for practical use makes heavy
use of probability theory.
Example 2 The controversial &#64257;rst Lancet study on civilian casualties in the Iraq war surveyed a random
sample of 1849 households (which had in total 12,801 members) across the country three and a half years
after the invasion in March 2003, and extrapolated the number of deaths reported by the surveyed household
to the total population of the whole country, which is about 29 million. The authors of the study arrived
at an estimate of about 112,000 &#8221;excess&#8221; deaths for the &#64257;rst 18 months after the invasion and stated
that &#8221;with 95% con&#64257;dence&#8221;, the actual number was between 69,000 and 155,000. We will see later on in
the course what exactly this statement means. The width of the con&#64257;dence interval around the estimate
gives a measure of the uncertainty inherent in extrapolating from a small sub-population to the entire
country. Since this is a politically and emotionally charged subject, the study triggered an intense debate
in scienti&#64257;c publications and the blogosphere - reading up on the debate will teach you a lot about how
statistics is actually &#8221;done&#8221; in practice.
2 Set Theory and Events
2.1 Random Experiments
De&#64257;nition 1 Arandom experiment is any procedure which can - at least theoretically - (a) be repeated
arbitrarily often and under identical conditions, and (b) has a well-de&#64257;ned set of possible outcomes.
A standard example for this would be a coin &#64258;ip which can produce two di&#64256;erent outcomes, heads H
or tails T(we&#8217;ll neglect the possibility that the coin ends up standing upright on its edge). Another
important type of experiments in the realm of statistics would be an exit poll after an election: say we
ask 2,000 randomly selected voters as they exit the poll stations to report which candidate they voted
for. We could in principle redraw arbitrarily many further samples of 2,000 individuals from the total
population that turned out to vote on election day, so condition (a) is satis&#64257;ed. The set of outcomes
for this experiment is the respective number of interviewed persons which reports to have voted for each
candidate on the ballot.
De&#64257;nition 2 Thesample space Sis the collection of all possible outcomes of an experiment.
For many purposes, we are not primarily interested in single outcomes, but instead group collections
of outcomes together into events . Therefore we will in the following describe the experiment in terms of
sets.
De&#64257;nition 3 Anevent Acan be any collection of outcomes (this includes individual outcomes, the empty
set, or the entire sample space).
If the realized outcome is a member of the event A, then Ais said to occur.
Let&#8217;s look at last year&#8217;s presidential race as an example. At the most elementary level, we could
describe the sample space Sas the collection of individuals who may - as a logical possibility - be elected
2</text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>14.30 Introduction to Statistical Methods in Economics
Lecture Notes 1
Konrad Menzel
February 3, 2009
1 Introduction and Overview
This class will give you an introduction to Probability Theory and the main tools of Statistics. Probability
is a mathematical formalism to describe and analyze situations in which we do not have perfect knowledge
of all relevant factors. In modern life, we are all routine consumers of statistical studies in &#64257;elds ranging
from medicine to sociology, and probabilistic reasoning is crucial to follow most of the recent debates in
economics and &#64257;nance.
In the &#64257;rst half of this class, we&#8217;ll talk about probabilities as a way of describing genuine risk - or our
subjective lack of information - over events.
Example 1 In subprime lending, banks o&#64256;ered mortgages to borrowers who were much less likely to repay
than their usual clientele. In order to manage the risks involved in lending to prospective home-owners
who do not own much that could serve as collateral, thousands of these loans were bundled and resold as
&#8221;mortgage backed securities,&#8221; i.e. the bank which made the original loans promised to pay the holder of
that paper whatever repayment it received on the loans. Eventually, there were more complicated &#64257;nancing
schemes under which the pool was divided into several &#8221;tranches&#8221;, where a &#64257;rst tranche was served &#64257;rst,
i.e. if the tranche had a nominal value of, say, 10 million dollars, anyone holding a corresponding claim
got repaid whenever the total of repayments in the pool surpassed 10 million dollars. The lower tranches
were paid out according to whatever money was left after serving the high-priority claims.
How could it be that the &#64257;rst &#8221;tranche&#8221; from a pool with many very risky loans was considered to be &#8221;safe&#8221;
when each of the underlying mortgages was not? The low-priority tranches were considered riskier - why?
And why did in the end even the &#8221;safe&#8221; securities turn out to be much riskier in retrospect than what
everyone in the market anticipated? We&#8217;ll get back to this when we talk about the Law of Large Numbers,
and under which conditions it works, and when it doesn&#8217;t.
Usually in order to answer this type of question, you&#8217;ll have to know a lot about the distribution (i.e.
the relative likelihood) of outcomes, but in some cases you&#8217;ll actually get by with much less: in some
cases you are only concerned with &#8221;typical&#8221; values of the outcome, like expectations or other moments
of a distribution. In other cases you may only be interested in an average over many repetitions of a
random experiment, and in this situation the law of large numbers and the central limit theorem can
sometimes give you good approximations without having to know much about the likelihood of di&#64256;erent
outcomes in each individual experiment.
The second half of the class deals with the question how we can learn about populations and probability
distributions from data. In any empirical science you&#8217;ll come across the problem of inductive reasoning ,
which means drawing general conclusions from a few (or even very many) observed special cases. In
political polls (&#8221;who would you vote for in the next presidential election?&#8221;), a survey institute typically
1</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare 
http://ocw.mit.edu 
14.30 Introduction to Statistical Methods in Economics
Spring 2009
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>ABA   B
AcBc
S
Figure5:Illustrationof(A&#8745;B)C=AC&#8746;BC-youcanseetherule(A&#8746;B)C=AC&#8745;BCfromthesame
graph.
2.2.5PartitionsofEvents
AandBaredisjoint(ormutuallyexclusive)iftheyhavenooutcomesincommon,i.e.
A&#8745;B=&#8709;
AcollectionofeventsA1,A2,...issaidtobeexhaustiveiftheirunionequalsS,i.e.
/uniondisplay
Ai=A1&#8746;A2&#8746;...=S
i&#8805;1
AcollectionofeventsA1,A2,...iscalledapartitionofthesamplespaceif(1)anytwodistinctevents
Ai,Aj(withi=j),AiandAjaredisjointAi&#8745;Aj=&#8709;,and(2)thecollectionA1,A2,...isexhaustive.
Inasimilarfashionwecande&#64257;nepartitionsofaneventBascollectionsofmutuallyexclusivesubevents
whoseunionequalsB.
/negationslash
A1
A2 A6 A4 A7A3 A5 A8S
Figure6:PartitionofSintoA1,A2,...,A8 
7Image by MIT OpenCourseWare.
Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>and set inclusion is transitive, i.e.
A&#8834;BandB&#8834;C=&#8658;A&#8834;C
In our presidential elections example, since (if we can trust Wikipedia, McCain was born on an American
air base in the Panama Canal zone)
&#8221;The 44th President was born in Panama&#8221; = {McCain }
&#8834;&#8221;The 44th President was born abroad&#8221; = {McCain, Schwarzenegger }
and
{McCain,Schwarzenegger } &#8834;&#8221;The 44th President is a Republican&#8221;
we can conclude that
&#8221;The 44th President was born in Panama&#8221; &#8834;&#8221;The 44th President is a Republican&#8221;
2.2.2 Unions of Sets, &#8221;&#8746; &#8221;
Theunion ofAandBis the collection of all outcomes that are members of AorB(or both, this is the
logical, inclusive &#8221;or&#8221; corresponding to the symbol &#8744;). In symbols
A&#8746;B={s&#8712;S|s&#8712;A&#8744;s&#8712;B}
The set union is symmetric:
S
A B
A   B
Figure 2: Union of AandB-&#8221;AorB&#8221;
A&#8746;B=B&#8746;A
Furthermore,
B&#8834;A=&#8658;A&#8746;B=Afor any events A, B&#8834;S
In particular,
A&#8746; &#8709;=A
A&#8746;A=A
A&#8746;S=S
It also doesn&#8217;t matter in which order we take union of sets/events (associative property):
A&#8746;B&#8746;C= (A&#8746;B)&#8746;C=A&#8746;(B&#8746;C)
4Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>2.2.3 Intersections of Sets, &#8221; &#8745;&#8221;
Theintersection ofAandBis the (possibly empty) collection of outcomes that are members of both A
andB, written as
A&#8745;B={s&#8712;S|s&#8712;A&#8743;s&#8712;B}
where &#8221;&#8743; &#8221; denotes the logical &#8221;and&#8221;. Some texts use the alternative notation A&#8745;B=AB. As the set
A   BS
A
B
Figure3:IntersectionofAandB-&#8221;AandB&#8221;
union,theintersectionissymmetric,
A&#8745;B=B&#8745;A
Also
B&#8834;A=&#8658;A&#8745;B=BforanyeventsA,B&#8834;S
Fromthisitfollowsthat
A&#8745;&#8709;=&#8709;
A&#8745;A=A
A&#8745;S=A
Again,likethesetunion,theintersectionofsetshastheassociativeproperty
A&#8745;B&#8745;C=A&#8745;(B&#8745;C)=(A&#8745;B)&#8745;C
Inaddition,setintersectionandunionhavethedistributiveproperties
A&#8745;(B&#8746;C)=(A&#8745;B)&#8746;(A&#8745;C)
and
A&#8746;(B&#8745;C)=(A&#8746;B)&#8745;(A&#8746;C)
Asanexample,fortheevents
A=&#8221;President44isaWoman&#8221;={Clinton}
B=&#8221;President44wasborninMidwest&#8221;={Clinton,Romney}
C=&#8221;President44isaRepublican&#8221;={Huckabee,McCain,Paul,Romney,Schwarzenegger}
5Image by MIT OpenCourseWare.</text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec05/</lecture_pdf_url>
      <lectureno>5</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; &#65533; &#65533; &#65533; Dividing by the length of the interval [xi&#8722;1,xi) makes sure that the area under the graph for a given 
interval equals the probability of the random variable X taking a value in that interval, i.e. we can 
calculate 
k k &#65533; xi &#65533; xk 
P (xj &#8804; X &#8804; xk)= P (xi&#8722;1 &#8804; X &#8804; xi)= hn(t)dt = hn(t)dt for xj &lt;xk 
i=j+1 i=j+1 xi&#8722;1 xj 0 .5 1 1.5 2 Density 
.5 1 1.5 2 2.5 
u 
0 .5 1 1.5 2 Density 
.5 1 1.5 2 2.5 
u 
Figure 1: Histograms of the same Distribution for 10 and 30 Bins, respectively 0 .5 1 1.5 2 Density 
.5 1 1.5 2 2.5 
u 
Figure 2: Histogram with 60 Bins and Continuous Density 
Thisisnot completely satisfyingyet, sincethisonly allows ustocalculatetheprobability of X falling 
betweenany twoof thegridpointsfrom x0 &lt;x1 &lt; ... &lt; xn,butnote.g. of asubinterval of,say,[xj ,xk]. 
We can address this by making the grid of points x1,x2,... &#64257;ner, and therefore the intervals narrower. 
If we shrink the distance between neighboring points xi&#8722;1,xi to an arbitrarily small &#8221;dx&#8221;, we&#8217;ll have a 
function h&#8734;(x)for which the probability that X liesbetween any twopoints a and b can be expressed 
5 </text>
        </slide>
        <slide>
          <slideno>7</slideno>
          <text>&#65533; 
&#65533; 
&#65533; &#65533; 1
fX (x)= b&#8722;a 
0 otherwise 
F(x) 
x y 
a 1 
b-a 
b 
Figure 4: p.d.f for a Uniform Random Variable, X &#8764; [a,b] 
&#65533; 4 &#65533; 4
1 1
10 10
3 3
ax2 if0 &lt;x&lt; 3
0 otherwise 
a &#8722;0 =9a De&#64257;nition6 A random variable X is uniformly distributed on the interval [a,b], a&lt;b, if it has the 
probabilitydensityfunction 
if a &#8804; x &#8804; b 
In symbols, we then write 
X &#8764; U[a,b] 
For example, if X &#8764; U[0, 10],then 
P (3&lt;X&lt; 4) = f(t)dt = dt = 
Whatis P (3 &#8804; X &#8804; 4)? Since the probability that P (X =3) =0 = P (X = 4), this is the same as 
P (3&lt;X&lt; 4). 
Example5 Suppose X hasp.d.f. 
fX (x)= 
Whatdoes a have to be? -since P (X &#8712; R)=1, the density has to integrate to 1, so a must be such that 
&#65533; &#8734; &#65533; 3 &#65533; 3 &#65533;3 
1= fX (t)dt = at2dt = ax 27 = 3 3
&#8722;&#8734; 0 0 
Therefore, a = 91 .
Whatis P (1&lt;X&lt; 2)? -let&#8217;s calculate the integral
&#65533; 2
t2 23 13 7
P (1&lt;X&lt; 2) = dt = &#8722; = 9 9&#183; 39&#183; 3 27
1
Whatis P (1&lt;X)? 
&#8734; 3 t2 27&#8722;1 26
P (1&lt;X)= fX (t)dt = dt = = 9 27 27
1 1
7 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; However, since we are only interested in the number X of successes, we have to take into account that 
n there are di&#64256;erent sequences with x successes. Therefore, the probability of x successesis x 
P (X = x)= np x(1&#8722;p)n&#8722;x 
x 
De&#64257;nition3 A random variable X withprobabilitydensityfunction 
&#9127; 
&#9128; n px(1&#8722;p)n&#8722;x if x &#8712;{1, 2,...,n}fX (x)= P (X = x)= x &#9129; 0 otherwise 
is said to follow a binomialdistribution withparameters p and n, written as 
X &#8764; B(n,p) 
You should notice that previously, we derived the probability distribution for every random experiment 
separately, writing down the number of possible outcomes, outcomes in each event etc. The binomial 
distribution serves as a model for a whole range of random experiments. For any given example which 
fallsintothis category, we canjustlook up theprobabilitiesfor agiven set ofparameters(n,p). 
Example4 In order to make some money o&#64256; your classmates, you obtained a bent 25 cent coin that 
comes up heads with a probability of pL = 54 . Unfortunately, that coin got mixed up with your regular 
small coins, and only after you inserted 8 out of 9 quarters into the laundromat you notice your mistake. 
Youhastily tossthe coin10 times, andit comes up headsfor atotal of8 times. Woulditbe agoodideato 
continueto rip o&#64256;yourfriends withthe old cointrick or areyou now stuck with a regular(fair) quarter 
with pF = 1
2 ? I.e. what is P (A|B)for A =&#8221;remaining coin is bent&#8221; and B =&#8221;8 heads out of 10&#8221;? 
If the coin is fair, 
P (B|AC )= 10 pF 8 (1&#8722;pF )10&#8722;8 =10 1 
8 8210 
Ifitisbent, 
P (B|A)= 10 pL8 (1&#8722;pL)10&#8722;8 = 10 48 &#183; 12 
8 8 510 
Now let&#8217;s see what Bayes theorem has to say: 
10 48 &#183;12 1 
P (B|A)P (A) 8 510 9 48 
P (A|B)= = &#65533; &#65533; &#65533; &#65533; = 48 510 &#8776; 46.21% 8 P (B|A)P (A)+P (B|AC )P (AC ) 10 48&#183;12 1 + 10 18 510 + 210 
8 510 9 8 210 9 
Therefore, it is more likely that the coin you are left with is in fact a regular quarter -which doesn&#8217;t mean 
that in total, the probability of heads is still 
4 1 P (H|B)= &#183; 46.21%+ &#183; 53.79% &#8776; 63.86% 5 2 
However a better idea would of course be to do a few more tosses. If you can repeat the experiment 
arbitrarily often, you will eventually be able to distinguish the two types of coins with an arbitrary degree 
of certainty. As an aside, you can see this exercise as a very basic example for a hypothesis test. 
Sayyougot another8heads out of another10 trials(we&#8217;ll call this event C), leaving the share of heads 
3 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 
2 at the same value as before. Then, doing the same steps as before, this time based on the &#64257;rst posterior 
P (H|B)rather than the prior P (B), the conditional probability would be 
10 48 &#183;12 
510 &#183; 46.21% 8 46.21% P (H|B &#8745;C)= &#65533; &#65533; &#65533; &#65533; = 510 &#8776; 85.51% 10 48&#183;12 10 1 46.21%+53.79%&#183; 48210 
8 510 &#183; 46.21%+ 8 210 &#183; 53.79% 
Alternatively,if wejust aggregate the two series oftrialsinto16heads out of20 trials, weget 
&#65533; &#65533; 
20 416 
16 520 
P (A|B&#65533;)= &#65533; &#65533; &#65533; &#65533; &#8776; 85.51% 20 20 416 8+ 16 520 16 220 
so that it doesn&#8217;t matter whether we update simultaneously or sequentially. This is more generally a 
desirable property of Bayesian updating: the &#64257;nal result only depends on the overall information we are 
using, not the order in which we update. 
Continuous Random Variables 
Many types of data are results from measurements of some kind: weights, lengths, incomes etc., which 
can -at least conceptually -take any value in some interval (sometimes all) of the real numbers. In 
this case, the de&#64257;nition of a probability density function for discrete random variables is not practical, 
because(a) the number ofpossible outcomesis uncountable, so we can&#8217;tjust add upprobabilities over 
single values, and(b) theprobability of any particular value on the continuum typically has to be zero. 
This is why we have to deal with this type of random variables separately from the discrete case. 
De&#64257;nition4 A random variable X has a continuousdistribution if X can take on any values in some 
interval -bounded or unbounded -of the real line. 
For discrete random variables, it was relatively straightforward to de&#64257;ne a probability density function, 
since there was only a &#64257;nite number of values. A continuous random variable can take more than count&#173;
ably many values, and therefore the derivation becomes a little bit more involved. 
The idea goes as follows: we can &#8221;discretize&#8221; the distribution by putting the possible values the random 
variable can take into &#8221;bins&#8221;, i.e. instead of looking at the probabilities P (X = x), we&#8217;ll lookat proba&#173;
bilitiesforintervals,i.e. P (x1 &#8804; X &#8804; x2). The graphical representation of this is a histogram: we &#64257;x a 
set of points x0 &lt;x1 &lt; ... &lt; xn on the real line and calculate the probabilities for X falling into each 
&#8221;bin&#8221;, i.e. interval between two subsequent points, so that P (xi&#8722;1 &#8804; X &#8804; xi). Then for values in the 
interval[x0,xn], we can de&#64257;ne a function 
&#9127; 
&#9130; P (x0&#8804;X&#8804;x1) if x &#8712; [x0,x1) &#9130; x1&#8722;x0 &#9130; &#9130; . &#9130; &#9130; . &#9130; . &#9128; 
hn(x)= P (xi&#8722;1&#8804;X&#8804;xi) if x &#8712; [xi&#8722;1,xi)xi&#8722;xi&#8722;1 &#9130; &#9130; &#9130; . &#9130; . &#9130; . &#9130; &#9130; &#9129; P (xn&#8722;1&#8804;X&#8804;xn) if x &#8712; [xn&#8722;1,xn)xn&#8722;xn&#8722;1 
4 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>1 
K &#961;(X = X) 
2 3 --- K-1 K X 1 
Note that these probabilities sum to 1. 
P(X = X) 
10 
32 
5 
32 
1 
32 
0 1 2 3 4 S X 
Note that in the die roll example, every single outcome corresponded to exactly one value of the 
random variable. In contrast for the &#64257;ve coin tosses there was a big di&#64256;erence in the number of outcomes 
corresponding to X = 2 compared to X = 0, say. So mapping outcomes into realizations of a random 
variable may lead to highly skewed distributions even though the underlying outcomes of the random 
experiment may all be equally likely. 
1.1 The Binomial Distribution 
Togeneralizethepreceding example,supposewelook at asequenceof n independentandidentical trials, 
each of which canresultineithera &#8221;success&#8221; ora &#8221;failure&#8221; (notnecessarilywith equalprobability),and 
we are interested in the total number X of successes. 
Example3 Suppose we sample 100 pieces from a batch of car parts at the producing plant for quality 
control. A piece passing the quality checks would constitute a &#8221;success&#8221;, a piece falling short of one or 
more of the criteria would be a &#8221;failure&#8221;. We are interested in the distribution of failures as a function 
of the total share of defective parts in the batch in order to infer from the sample whether we have good 
reason to believe that no more than, say, 1% of the pieces don&#8217;t meet the standards. 
Suppose the probability of a success equals p, and the probability of a failure is therefore q =1&#8722;p. 
Since the trials are independent by assumption, the probability of any given sequence of x successes and 
n &#8722;x failures in &#64257;xed order is 
p x(1&#8722;p)n&#8722;x 
2 Images by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>  &#65533; astheintegral of h&#8734;(x)from a to b. Thislimitis called theprobability density functionforacontinuous 
random variable: 
De&#64257;nition5 If random variable X has a continuous distribution, the probability density function 
(p.d.f.) of X is de&#64257;ned a positive function fX (x)such that for any interval A &#8834; R 
P (X &#8712; A)= fX (t)dt 
A 
X F(x) 
P(a x b) 
a b 
Figure 3: P.D.F. of a Continuous Random  Image by MIT OpenCourseWare.
Variable
From the axioms for a probability function, we can see that any continuous p.d.f. must satisfy 
fX (x)&#8805; 0 &#8704;x &#8712; R 
and &#65533; &#8734; 
fX (x)=1 
&#8722;&#8734; 
Hence, if we want to know P (X &#8712; A)for A =[a,b]&#8834; R, we can compute 
&#65533; b 
P (X &#8712; [a,b])= P (a &#8804; X &#8804; b)= f(t)dt 
a 
Remark1 Note that for any x &#8712; R, 
P (X = x)=0 
if X has a continuous distribution. 
This may seem a little counterintuitive in part also because we use continuous distributions to ap&#173;
proximatethings which areinfactdiscrete(e.g. income ortime unemployed). Sofarwehaven&#8217;t seen 
any examples of continuous random variables in any of the probabilities we computed. 
Examples 
Supposethatarandom variableissuchthaton someinterval[a,b] on the real axis, the probability of 
X belonging to some subinterval [a&#65533;,b&#65533;](where a &#8804; a&#65533; &#8804; b&#65533; &#8804; b) is proportional to the length of that 
subinterval. 
6 3 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; 
&#65533; 
&#65533; 
&#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; &#65533; &#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 5 
Konrad Menzel 
February 19, 2009 
We distinguish 2 di&#64256;erent types of random variables: discrete and continuous. 
Discrete Random Variables 
De&#64257;nition1 Arandomvariable X hasa discrete distributionif X cantakeononly a &#64257;nite(orcountably 
in&#64257;nite) number of values (x1,x2,...). 
De&#64257;nition2 If random variable X has a discrete distribution,the probability density function (p.d.f.) 
of X is de&#64257;ned as the function 
fX (x)= P (X = x) 
If {x1,x2,...}is the set of all possible values of X, then for any x/&#8712;{x1,x2,...}, fX (x)= 0. Also 
&#8734; 
fX (xi)=1 
i=1 
Theprobability that X &#8712; A for A &#8834; R is 
P (X &#8712; A)= fX (xi) 
xi&#8712;A 
Example1 If X is the number we rolled with a die, all integers 1, 2,..., 6 are equally likely. More 
generally, we can de&#64257;ne the discrete uniform distribution over the numbers x1,x2,...,xk byitsp.d.f. 
1 
fX (x)= k if x &#8712;{x1,x2,...,xk} 
0 otherwise 
This corresponds to the simple probabilities for an experiment with sample space S = {x1,x2,...,xk}. 
Example2 Suppose we toss 5 fair coins independently from another and de&#64257;ne a random variable X 
which is equal to the observed number of heads. Then by our counting rules, n(S) =25 = 32, and 
5 n(&#8221;k heads&#8221;)= , using the rule on combinations. Therefore k 
51 1 51 5 P (X =0) = = , P (X =1) = = 032 32 132 32, 
5110 5110 P (X =2) = = , P (X =3) = = 232 32 332 32, 
51 5 51 1 P (X =4) = = , and P (X =5) = = . 432 32 532 32 
1 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec09/</lecture_pdf_url>
      <lectureno>9</lectureno>
      <slides>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; &#65533; &#65533; &#65533; &#65533; &#65533; 
&#65533; 
&#65533; The inverse function will also be strictly monotonic, so that for 0 &#8804;x &#8804;1, the c.d.f. of the random 
variable FX (X)isgivenby 
PFX (X)&#8804;x = PF &#8722;1(FX (X))&#8804;F &#8722;1(x)= PX &#8804;F &#8722;1(x)= FX (F &#8722;1(x))= xX X X X 
(the &#64257;rst equalityuses monotonicity of F &#8722;1(), and the third the de&#64257;nition ofa c.d.f.). &#183;
Summarizing, the c.d.f. G()of the random variable F (X)isgivenby &#183;
&#9127; 
&#9128; 0 if x&lt; 0 
G(F (x))= x if0 &#8804;x&lt; 1 &#9129; 1 if x &#8805;1 
Wecaneasily check thatthisisalsothec.d.f. of auniformrandomvariableontheinterval[0, 1], so that 
F (X)has the same probability distribution as U[0, 1] &#65533; 
What is this result useful for? As an example, there are very e&#64259;cient ways of generating uniform 
random numbers with a computer. If you want to get a sample of n draws from a random variable with 
c.d.f. FX (), you can &#183;
&#8226; draw U1,...,Un &#8764;U[0, 1] 
&#8226; transform each uniform draw according to 
Xi = F &#8722;1(Ui)X 
By theargumentwemadebefore, X1, ,Xn behavelikearandomvariablewith c.d.f. FX (). Thismethod &#183; &#183;
is known as integral(orquantile) transformation. 
Example 7 Say, we have a computer program which allows us to draw a random variable U from a 
uniform distribution, but we actually want to obtain a random draw of X withp.d.f. 
1 e&#8722; 1
2x if x &#8805;0 
otherwise fX (x)= 2 
0 
We can obtain the c.d.f. of X byintegration: 
0 if x&lt; 0 FX (x)= 1&#8722;e&#8722; 1
2x if x &#8805;0 
so that the inverse of the c.d.f. is given by 
F &#8722;1(u)= &#8722;2log(1&#8722;u) for u &#8712;[0, 1] X 
If we try this using some statistics software or Excel, a histogram of the draws will look like this: 
5 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>y = X2, X ~ U [-1, 1] 
fy (y) 
1 
2 
1 y 
&#65533; &#65533; &#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; &#65533; 
&#65533; 1.3 Change of Variables Formula for One-to-One Transformations 
It is in general not very convenient to derive the density of Y fromthedensity fX (x)of X throughthe 
c.d.f.s, in particular because this involves one integration and one di&#64256;erentiation. So one might wonder 
whether there is a more direct connection between the p.d.f.s. 
Before going to the more general case, suppose u(x)= ax for some constant a&gt; 0. Then the c.d.f. of 
Y = u(X)= aX isgivenby 
yFY (y)= fX (x)dx = fX (x)dx = FX 
y aax&#8804;y x&#8804;a 
Using the chain rule, we can derive the p.d.f. of Y 
d d y 1 d 1 fY (y)= FY (y)= = FX (x)= fX (x) FX dy dy a adx a 
What is a good intuition for this? -if a&gt; 1, we could think of the transformation as stretching the axis 
on which the random variable falls. This moves any pair of points on the axis apart by a factor of a, 
butleaves constanttheprobability thatthe variablefallsbetweenthepoints. Therefore,thedistribution 
of Y is &#8221;thinned out&#8221; by a factor of a 1 compared to the distribution of X. One could visualize this by 
thinking about a lump of dough containing a number of raisins -the more we spread out the dough, the 
sparser the distribution of the raisins in the dough will be with respect to the surface of the table. 
For di&#64256;erentiable monotone transformations u()of X we have the following result &#183;
Proposition 1 Let X be a continuous random variable with known density fX (x)suchthat P (a &#8804;X &#8804;
b)=1, and Y = u(X). If u() is strictly increasing and di&#64256;erentiable on an interval [a,b], and has an &#183;
inverse s(y)= u&#8722;1(y), then the density of Y isgivenby 
fX (s(y)) &#65533;&#65533; d s(y)&#65533;&#65533; if u(b)dy u(a)&#8804;y &#8804;fY (y)= 
0 otherwise 
Notice that an analogous result is true if u(x)is strictly decreasing on[a,b]. 
Example 6 Let X be uniform on [0, 1], so it has p.d.f. 
1 if0 &#8804;x &#8804;1 fX (x)= 0 otherwise 
3 Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>XL y1 
y1 1 
Not defined 
Not defined -1Fx (y)Fx(x) 
X2 
X1 0 
1 
XL 
4 &#65533; &#65533; 
&#65533; &#65533; Whatisthep.d.f. of Y = X2? We can see that on the support of X, u(x)= x2 is strictly increasing and 
di&#64256;erentiable, so that we can use the inverse of u(), s(y)= &#8730;y to obtain the p.d.f. of Y , &#183;
&#65533; d &#65533; 1 1 if0 &#8804;&#8730;y &#8804;1 fY (y)= fX (s(y)) &#65533; dy s(y) &#65533;&#65533; = fX (&#8730;y)2&#8730;y =0 2&#8730;y 
otherwise 
Thisissimilartooneexamplewedid above, exceptthatinthepreviouscase,thesupportof X was [&#8722;1, 1], 
so that u(x)= x 2 was not monotone on the support of X. 
Itisvery importanttonotethatthisformula works only for di&#64256;erentiable one-to-one -i.e. monotone 
-transformations. In other cases, we have to stick to the more cumbersome &#8221;2-step&#8221; methods for the 
discrete and continuous case, respectively. 
1.4 Probability Integral / Quantile Transformation 
For continuous random variables, there is an interesting -and also very useful -result: the &#8221;c.d.f. of a 
c.d.f.&#8221; is that of a uniform variable in the following sense: 
Proposition 2 Let X be a continuous random variable with c.d.f. FX (x). Then the c.d.f. evaluated at 
a random draw of X, FX (X)is uniformly distributed, i.e. 
FX (X)&#8764;U[0, 1] 
You should notice that afunction of a random variableisitself a random variable(we&#8217;lldiscuss thisin 
more detail later on). 
Proof: Since the c.d.f. takes values only between zero and 1, we can already see that the c.d.f. G()of &#183;
F (X)satis&#64257;es 
G(F (X))= P (F (X)&#8804;x) =0 if x&lt; 0
G(F (X))= P (F (X)&#8804;x) =1 if x&gt; 1
Withoutlossofgenerality(i.e. only avoiding afewuninteresting extrade&#64257;nitionsorcasedistinctions), 
suppose F ()is strictly monotonic -keeping in mind that all c.d.f.s are nondecreasing. This means that &#183;
there is an inverse function F &#8722;1(), i.e. a function such that F &#8722;1(F (x))= x. &#183;
Image by MIT OpenCourseWare.</text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>0 .5 1 1.5 Density 
0 .2 .4 .6 .8 1 
Uniform Draws 
0 .1 .2 .3 .4 .5 Density 
0 5 10 15 
Exponential Draws 
Figure1:Histogramof5,000draws Ui fromaUniform(left),and thetransformation Xi = &#8722;2log(1&#8722;Ui) 
(right) 
Ifyouwanttotry afewexamplesonyourowninExcel,youcancreateuniformrandomdrawsusing the 
RAND() function. You canthenplothistogramsby clickingyourselfthroughthe menus(&#8221;Tools&#8221;&gt;&#8221;Data 
Analysis&#8221;&gt;&#8221;AnalysisTools&#8221;&gt;&#8221;Histogram&#8221;). 
6 </text>
        </slide>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; 
&#65533; 
&#65533; 
&#65533; 1.1 Discrete Case -&#8221;2-Step&#8221; Method 
If X is adiscrete random variable withp.d.f. fX (x), andY = u(X), whereu()is a known deterministic &#183;
function. Then 
fY (y)= P (Y = y)= P (u(X)= y)= fX (x) 
x:u(x)=y 
Example 3 
if 5 fX (x)= 1 x &#8712;{&#8722;2, &#8722;1, 0, 1, 2}
0 otherwise 
Thenif Y = g(X)= X,||
&#9127; 
&#9130; fX (0)= 1	if y =0 &#9130;	 5 
fY (y)= &#9128; fX (&#8722;1)+fX (1)= 52 if y =1 
&#9130; fX (&#8722;2)+fX (2)= 2 if y =2 &#9130;	 5 &#9129; 0	 otherwise 
Notethatif X isdiscrete,then Y is also discrete. 
1.2 Continuous Case -&#8221;2-Step&#8221; Method 
If X is a continuous random variable with p.d.f. fX (x), andY = u(X), then the c.d.f. of Y isgivenby 
FY (y)= P (Y &#8804;y)= P (u(X)&#8804;y)= fX (x)dx 
x:u(x)&#8804;y 
If Y is also continuous, then 
d fY (y)= FY (y)dy 
Note that even if X is continuous, Y need not be continuous. 
Example 4 Y = &#65533;X&#65533;, the largest integer smaller than X, is discrete regardless whether X is continuous 
ordiscrete. 
Example 5 
fX (x)=	21 if &#8722;1 &#8804;x &#8804;1 
0 otherwise 
Let&#8217;s look at 
Y = X2 
From X &#8712;[&#8722;1, 1], it follows that Y =[0.1]. How do we get the density of Y ? For y &#8712;[0, 1], the c.d.f. is 
&#65533; &#8730;y 
FY (y)= P (Y &#8804;y)= P (X2 &#8804;y)= P (&#8722;&#8730;y &#8804;X &#8804;&#8730;y)= 1 dx = &#8730;y 
&#8722;&#8730;y 2 
In sum &#9127; 
&#9128; 0 if y&lt; 0 
FY (y)= &#8730;y if y &#8712;[0, 1) &#9129; 1 if y &#8805;1 
Since Y is continuous, we can derive the density 
&#65533; 1d 2&#8730;y if y &#8712;[0, 1] fY (y)= FY (y)= dy 0 otherwise 
2 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 9 
Konrad Menzel 
March 10, 2009 
Functions of Random Variables 
Inthispart of thelecture we aregoing tolook atfunctions of random variables, Y = u(X). Note that Y 
is again a random variable: since X is a mapping from the sample space S into the real numbers, 
X : S R&#8594;
and u : R R, the composition of u and X is also a mapping from S into the real numbers: &#8594;
Y = uX : S R &#9702; &#8594;
Example 1 If X is the life of the &#64257;rst spark plug in a lawnmower, and Y the life of the second, we may 
be interested in the sum of the two, Z = X + Y . 
Example 2 Beforecoming toMIT,I appliedforseveralGermanfellowships, soI would receiveamonthly 
stipend of X Euros, depending on which fellowship I was going to get, and the exchange rate in, say, 
September 2005 was going to be Y Dollars per Euro. Each quantity was uncertain at the time I was 
applying,but sinceI wasgoing to spend the money intheUS,the mainquantity ofinterest wasthedollar 
amount Z = X &#8727;Y I was going to receive (at least in terms of the Dollar exchange rate, I could not 
complain). 
Wenowwanttoknowhowtoobtainthedensity and c.d.f. forthetransformed randomvariable u(X), 
so we can treat each problem involving a function of a random variable in the same way as a question 
involving only the random variable itself with a known p.d.f. 
We&#8217;ll consider three cases: 
1. underlying variable X discrete 
2. underlying variable X continuous 
3. X continuous and u(X)strictly increasing 
The last case is of course a special case of the second, but we&#8217;ll see that it&#8217;s much easier to work with. 
1 </text>
        </slide>
      </slides>
    </lecture>
    <lecture>
      <lecture_title>PDF 1</lecture_title>
      <lecture_pdf_url>https://ocw.mit.edu/courses/14-30-introduction-to-statistical-methods-in-economics-spring-2009/resources/mit14_30s09_lec10/</lecture_pdf_url>
      <lectureno>10</lectureno>
      <slides>
        <slide>
          <slideno>2</slideno>
          <text>&#65533; 
&#65533; &#65533; 
&#65533; &#65533; 
&#65533; &#65533; 
&#65533; 
&#65533; &#65533; &#65533; &#65533; 1.1 Discrete Case 
Suppose X1,...,Xn arediscrete withjointp.d.f. fX1,...,Xn (x1,...,xn), and Y1,...,Ym aregivenby m 
functions 
Y1 = u1(X1,...,Xn) 
. . . 
Ym = um(X1,...,Xn) 
If we let 
Ay := {(x1,...,xn): r1(x1,...,xn)= y1,...,um(x1,...,xn)= ym} 
thenthejointp.d.f. of Y1,...,Ym isgivenby 
fY1,...,Ym (y1,...,ym)= fX1,...,Xn (x1,...,xn) 
(x1 ,...,xn)&#8712;Ay 
Example 1 (Sum of Binomial Random Variables) Suppose X &#8764; B(m,p) and Y &#8764; B(n,p) are 
independent binomial random variables with p.d.f.s 
fX (k)= mp k(1&#8722;p)m&#8722;k 
k 
fY (k)= np k(1&#8722;p)n&#8722;k 
k 
If we de&#64257;ne Z = X + Y, what is the p.d.f. fZ (z)? Since X is the number of successes in a sequence of 
m independent trials, and Y the number of successes in n trials, both with the same success probability, 
a &#64257;rst guess would be that then Z should just be the number of successes in m + n trials with success 
probability p,i.e. Z &#8764; B(m + n,p). This turns out to be true, but we&#8217;ll &#64257;rst have to check this formally: 
P(Z = z)= P ({X =0,Y = z}or {X =1,Y = z &#8722;1}... or {X = z,Y =0}) 
z z 
= P(X = k,Y = z &#8722;k)= P(X = k)P(Y = z &#8722;k) 
k=0 k=0 
z &#65533; &#65533; &#65533; &#65533; 
= mp k(1&#8722;p)m&#8722;k np z&#8722;k(1&#8722;p)n&#8722;z+k 
k z &#8722;k 
k=0 
z &#65533; &#65533;&#65533; &#65533; 
= &#65533; m np z(1&#8722;p)n&#8722;z 
k z &#8722;k 
k=0 
Now, the term pz(1&#8722;p)n&#8722;z doesn&#8217;t depend on k, so we can pull it out of the sum. On the other hand, I 
claim that z &#65533; &#65533;&#65533; &#65533;&#65533; &#65533; &#65533; m n m + n = k z &#8722;k z 
k=0 
Wecaninfact showthisusing counting rules:by themultiplicationruleand theformulaforcombinations, 
m n the term corresponds to the number of di&#64256;erent sets we can draw which contain k k z &#8722;k 
elementsfromagroup with m members,and z&#8722;k elementsfromanothergroup with n members. Summing 
over all values of k, we get the total number of ways in which we can draw a set of z elementsfromboth 
2 </text>
        </slide>
        <slide>
          <slideno>1</slideno>
          <text>&#65533; &#65533; &#65533; &#65533; 1 14.30 Introduction to Statistical Methods in Economics 
Lecture Notes 10 
Konrad Menzel
March 12, 2009
Functions of 2 or more Random Variables 
Let&#8217;srecap whatwehave alreadylearnedaboutjointdistributions of2ormore randomvariables, say 
X1,X2,...,Xn 
&#8226; if X1,...,Xn arediscrete,theirjointp.d.f. isgivenby 
fX1 ,...,Xn (x1,...,xn)= P(X1 = x1,...,Xn = xn) 
&#8226; if X1,...,Xn are continuous,theirjointp.d.f. is apositivefunction fX1 ,...,Xn (x1,...,xn)such that 
P (X1,...,Xn)&#8712; D = ... fX1,...,Xn (x1,...,xn)dx1 ...dxn 
D 
for any D &#8834; Rn . 
&#8226; X1,...,Xn areindependentif 
P(X1 &#8712; A1,...,Xn &#8712; An)= P(X1 &#8712; A1)&#183; ...P (Xn &#8712; An) 
recall that this is equivalent to 
fX1 ,...,Xn (x1,...,xn)= fX1 (x1)&#183; ...fXn (xn) 
Weare nowgoing tolook athowwe cangeneralizefromtheunivariate casediscussed aboveto2 ormore 
dimensions. 
As for the single-dimensional case we&#8217;ll again distinguish three cases: 
1. underlying variables X1,...,Xn discrete 
2. underlying variable X1,...,Xn continuous 
3. X continuous and u(X1,...,Xn)is an n-dimensional one-to-one function 
1 </text>
        </slide>
        <slide>
          <slideno>4</slideno>
          <text>&#65533; &#65533; 
&#65533; If s1(&#183;),...,sn(&#183;)are di&#64256;erentiable on B, we de&#64257;ne the matrix 
&#9115; &#8706; &#8706; &#9118; 
&#8706;y1 s1 ... &#8706;yn s1 
&#9116; . . &#9119;J = &#9117; .. .. &#9120; 
&#8706; &#8706; ... &#8706;y1 sn &#8706;yn sn 
This matrix of partial derivatives is also called the Jacobian of the inverse transformation. For those of 
you whodidn&#8217;ttakeLinearAlgebra,it&#8217;s su&#64259;cientifyou can work with the2-by-2 case. You should also 
know that for a two-by-two matrix A,thedeterminantisgivenby 
ab det(A)=det = ad &#8722;bc cd 
Proposition 1 If the mapping of X1,...,Xn to Y1,...,Yn as outlined above is one-to-one and has a 
di&#64256;erentiableinverse s1(&#183;),...,sn(&#183;),thenthejointp.d.f. of Y1,...,Yn isgivenby 
fX1 ,...,Xn (s1(y),...,sn(y))&#183;|det(J)| if y &#8712; B =support(Y1,...,Yn)fY1,...,Yn (y1,...,yn)= 0 otherwise 
2.1 Linear Transformation 
&#9121; &#9124; X1 
Let X be a vector of random variables, i.e. X = &#9122;&#9123; ... &#9125;&#9126;, and 
Xn 
&#9121; &#9124; Y1 
Y = &#9122;&#9123; ... &#9125;&#9126; = AX 
Yn 
for an n &#215; n matrix A withdet(A) &#65533;= 0. Then the linear mapping Y = AX is one-to-one (since the 
matrixhasaninverse),and wecan &#64257;nd thejointdistributionof Y using the change of variables formula 
fY1,...,Yn (y1,...,yn)= fX1,...,Xn (x1,...,xn)|det(A&#8722;1)|=1 fX1,...,Xn (x1,...,xn)|det(A)| 
Example 2 To seehowthis mattersin economics, suppose wehave a simple(partial equilibrium) model 
forthe marketfor orangejuiceinBoston. Firms are willing to supplyquantity qs as a linear function of 
price p with coe&#64259;cients &#945;s and &#946;s 
qs = &#945;s + &#946;sp+ us 
where us is a random variable (say, sunshine hours in Florida). Consumers demand quantity qd given 
another random shock ud (sayincome): 
qd = &#945;d &#8722;&#946;dp+ ud 
In equilibrium, supply equals demand, i.e. prices are such that qs = qd = q, and price and quantity are 
jointly determined by the following relationship 
&#65533; &#65533; &#65533; &#65533; &#65533; &#65533; &#65533; &#65533; 
1 &#8722;&#946;s q &#945;s us = + 1 &#946;d p &#945;d ud 
4 </text>
        </slide>
        <slide>
          <slideno>3</slideno>
          <text>&#65533; &#65533; 
&#65533; &#65533; 
&#65533; sets combined(i.e. a set with m +n members), which, according to the formula for combinations, equals 
m + n , which is the right-hand side of the equality we wanted to prove. z 
Putting bits and pieces together, 
P(Z = z)= m + np z(1&#8722;p)n&#8722;z 
z 
so that indeed, Z &#8764; B(m + n,p). 
As a cautious note, in general the sum Z of two independent random variables X and Y from the same 
family of distributions -in this case the binomial -will not belong to that same family. In that respect, the 
binomial distribution is a very special case, and there are only very few other commonly used distributions 
which have that property. E.g. if X &#8764; B(m,pX ) and Y &#8764; B(n,pY ) with pX &#65533;pY , the derivation above = 
is not going to work anymore. 
1.2 Continuous Case 
Suppose X1,...,Xn are continuous withjointp.d.f. fX1,...,Xn (x1,...,xn), andY (let&#8217;s stickto only one 
variable to keep notation simple) is given by a function 
Y = u(X1,...,Xn) 
If we let 
By := {(x1,...,xn): u(x1,...,xn)&#8804; y} 
then the p.d.f. of Y isgivenby 
FY (y)= fX1,...,Xn (x1,...,xn)dx1 ...dxn 
(x1 ,...,xn )&#8712;By 
2 Change of Variables Formula for One-to-One Transformations 
Thisisagainaspecialcase,which worksonlyforcontinuousvariables:Let Abethesupportof X1,...,Xn, 
i.e.	 &#65533; &#65533; 
P (x1,...,xn)&#8712; A =1 
and B the induced support of Y1,...,Yn,i.e. 
(Y1,...,Yn)&#8712; B &#8660; (X1,...,Xn)&#8712; A 
Suppose Y1,...,Yn aregeneratedfrom X1,...,Xn from a di&#64256;erentiable one-to-one transformation 
Y1 = u1(X1,...,Xn) 
. . . 
Yn = un(X1,...,Xn) 
i.e. every value of(x1,...,xn)&#8712; A is mapped to a unique element(y1,...,yn)&#8712; B. We can then de&#64257;ne 
theinverse[s1(x1,...,xn),...,sn(x1,...,xn)]&#65533; suchthat 
X1 = s1(Y1,...,Yn) 
. . . 
Xn = sn(Y1,...,Yn) 
3 </text>
        </slide>
        <slide>
          <slideno>0</slideno>
          <text>MIT OpenCourseWare
http://ocw.mit.edu 
14.30  Introduction to Statistical Methods in Economics 
Spring 2009 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . </text>
        </slide>
        <slide>
          <slideno>6</slideno>
          <text>&#65533; &#65533; Therefore 
fZW (z,w)= fXY (s1(z,w),s2(z,w))= fX (s1(z,w))fY (s2(z,w))= fX (z &#8722;w)fY (w) 
We can now obtain the marginal p.d.f. of Z byintegrating thejointp.d.f. over w 
&#65533; &#8734; 
fZ (z)= fX (z &#8722;w)fY (w)dw 
&#8722;&#8734; 
which is the same formula as that obtained from the previous derivation. 
Example 5 We already saw several instances of the exponential distribution (e.g. in the lawnmower 
example). Let X and Y be independent exponential random variables with marginal p.d.f.s 
e&#8722;x if x &#8805; 0 e&#8722;y if x &#8805; 0 fX (x)= fY (y)= 0 otherwise 0 otherwise 
By the last formula, the p.d.f. of Z = X + Y isgivenby 
&#65533; &#8734; 
fZ (z)= fX (z &#8722;w)fY (w)dw 
&#8722;&#8734; &#65533; z 
= e &#8722;(z&#8722;w)e &#8722;wdw 
0 &#65533; z 
= e &#8722;z dw = ze &#8722;z 
0 
where integration limits in the second step come from the fact that the support of X and Y is restricted 
to the positive real numbers, i.e. for z&lt; 0, fX (z)is zero, whereas for z&gt; w, fY (z &#8722;w)becomes zero. 
6 </text>
        </slide>
        <slide>
          <slideno>5</slideno>
          <text>&#65533; &#65533; We may know or postulate the joint p.d.f. fU (us,ud) of the shocks (ud,us), from which we can derive 
thejointdistribution ofprice andquantity. Thisjointp.d.f. isgoing todepend crucially ontheJacobian 
(which is the matrix on the left-hand side). In this case, det(J)= &#946;d + &#946;s, so that if supply and/or 
demand have a nontrivial slope, the transformation from the shocks to price and quantity is one-to-one, 
and the resultingjointp.d.f. is 
fPQ(p,q)= fU (u1(p,q),u2(p,q))|&#946;s + &#946;d| 
This is a little too far beyond what we are going to cover in this class, but the Jacobian term |&#946;s + &#946;d| 
captures the interdependence of price and quantity through the market equilibrium. It turns out to be 
the source of what in 14.32 will be called the &#8221;simultaneity problem&#8221; which makes it very di&#64259;cult to 
estimate supply and demand separately from market outcomes. This is one of the fundamental problems 
in econometrics. 
2.2 Distribution of X + Y (Convolution) 
SupposeX and Y areindependent continuousrandomvariableswithp.d.f.s fX (x)and fY (y),respectively, 
so that the joint p.d.f. of the random variables is fXY (x,y)= fX (x)fY (y). What is the p.d.f. of 
Z = X + Y? 
Example 3 Remember that we already did an example like this in class: we were looking at the sum of 
the lives of two spark plugs in a lawnmower, and it turned out that the probability P(X + Y &#8804; z) was 
theintegral ofthejointdensity fXY (x,y)over the triangular area de&#64257;ned by {(x,y): y &#8804; z &#8722;x}. So the 
c.d.f. of Z isgivenby 
&#65533; &#8734; &#65533; z&#8722;x &#65533; &#8734; &#65533; z&#8722;x &#65533; &#8734; 
FZ (z)= P(X+Y &#8804; z)= fXY (x,y)dydx = fX (x)fY (y)dydx = fX (x)FY (z&#8722;x)dx 
&#8722;&#8734; &#8722;&#8734; &#8722;&#8734; &#8722;&#8734; &#8722;&#8734; 
From this, we can derive the density of Z, 
d &#65533; &#8734; 
fZ (z)= FZ (z)= fX (x)fY (z &#8722;x)dx dz &#8722;&#8734; 
The random variable Z = X + Y is also called the convolution of X and Y. Note that the last formula 
is valid only for the sum of independent random variables. 
Example 4 The discussion in the previous example was again along the lines of the &#8221;2-step&#8221; method, 
and one might wonder whether it would also be possible to use the shortcut through the formula for 
transformations of variables. 
The mapping from (X,Y)to Z is clearly not one-to-one, so we can&#8217;t use the formula for transformations 
of variables right away. However, we can do the following &#8221;trick&#8221;: de&#64257;ne 
Z = u1(X,Y)= X + Y 
W = u2(X,Y)= Y 
Then, the inverse transformation is de&#64257;ned as 
X = s1(Z,W)= Z &#8722;W 
Y = s2(Z,W)= W 
Then, 
1 &#8722;1 detJ =det =1 01 
5 </text>
        </slide>
      </slides>
    </lecture>
    <videos>
      <video>
        <video_url/>
        <video_title/>
        <transcript>
          <slice>
            <text_slice/>
            <time_slice/>
          </slice>
        </transcript>
      </video>
    </videos>
  </lectures>
</doc>
